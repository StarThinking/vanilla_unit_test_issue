2020-12-03 07:19:41,698 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=8
Formatting using clusterid: testClusterID
2020-12-03 07:19:42,622 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:19:42,640 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:19:42,641 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:19:42,642 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:19:42,651 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:19:42,652 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:19:42,652 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:19:42,653 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:19:42,709 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:42,714 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2020-12-03 07:19:42,715 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:19:42,715 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:19:42,722 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:19:42,723 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:19:42
2020-12-03 07:19:42,725 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:19:42,727 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:19:42,729 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-12-03 07:19:42,729 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:19:42,750 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:19:42,750 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:19:42,757 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:19:42,758 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:19:42,758 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:19:42,758 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:19:42,759 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:19:42,759 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:19:42,760 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:19:42,760 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:19:42,760 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:19:42,761 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:19:42,761 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:19:42,798 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GLOBAL serial map: bits=29 maxEntries=536870911
2020-12-03 07:19:42,799 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - USER serial map: bits=24 maxEntries=16777215
2020-12-03 07:19:42,799 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GROUP serial map: bits=24 maxEntries=16777215
2020-12-03 07:19:42,799 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - XATTR serial map: bits=24 maxEntries=16777215
2020-12-03 07:19:42,816 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:19:42,817 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:19:42,817 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-12-03 07:19:42,818 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:19:42,824 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:19:42,824 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:19:42,825 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:19:42,825 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:19:42,831 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:19:42,834 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:19:42,839 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:19:42,839 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:19:42,840 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-12-03 07:19:42,840 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:19:42,851 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:19:42,852 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:19:42,852 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:19:42,857 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:19:42,857 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:19:42,860 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:19:42,861 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:19:42,861 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-12-03 07:19:42,862 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:19:42,916 [main] INFO  namenode.FSImage (FSImage.java:format(185)) - Allocated new BlockPoolId: BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:43,122 [main] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-12-03 07:19:43,298 [main] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-12-03 07:19:43,337 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:19:43,337 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:19:43,504 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:19:43,506 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:19:43,576 [main] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-12-03 07:19:43,580 [main] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:19:43,705 [main] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:19:44,247 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:19:44,247 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:19:44,287 [main] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-12-03 07:19:44,344 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1b2abca6] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:19:44,367 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:19:44,375 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:44,397 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @4129ms
2020-12-03 07:19:44,557 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:19:44,563 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:19:44,564 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:44,577 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:19:44,580 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:19:44,581 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:19:44,581 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:19:44,621 [main] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:19:44,621 [main] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:19:44,633 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 35519
2020-12-03 07:19:44,635 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:19:44,688 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@69504ae9{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:19:44,690 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@28cda624{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:19:44,734 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@2e32ccc5{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:19:44,743 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@34cf6eff{HTTP/1.1,[http/1.1]}{localhost:35519}
2020-12-03 07:19:44,748 [main] INFO  server.Server (Server.java:doStart(419)) - Started @4481ms
2020-12-03 07:19:44,760 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:19:44,761 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:19:44,761 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:19:44,761 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:19:44,762 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:19:44,762 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:19:44,762 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:19:44,763 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:19:44,763 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:44,764 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:19:44,764 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:19:44,765 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:19:44,766 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:19:44
2020-12-03 07:19:44,766 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:19:44,766 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:19:44,766 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:19:44,766 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:19:44,771 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:19:44,772 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:19:44,772 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:19:44,772 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:19:44,773 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:19:44,773 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:19:44,773 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:19:44,774 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:19:44,774 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:19:44,774 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:19:44,775 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:19:44,775 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:19:44,775 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:19:44,776 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:19:44,776 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:19:44,777 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:19:44,777 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:19:44,780 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:19:44,781 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:19:44,781 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:19:44,781 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:19:44,781 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:19:44,782 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:19:44,782 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:19:44,782 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:19:44,782 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:19:44,783 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:19:44,784 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:19:44,784 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:19:44,784 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:19:44,785 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:19:44,785 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:19:44,785 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:19:44,785 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:19:44,786 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:19:44,786 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:19:44,845 [main] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 906@9ece31fe74eb
2020-12-03 07:19:44,918 [main] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 906@9ece31fe74eb
2020-12-03 07:19:44,922 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-12-03 07:19:44,923 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-12-03 07:19:44,923 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:19:44,924 [main] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:19:44,961 [main] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:19:44,968 [main] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:19:44,969 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-12-03 07:19:44,975 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:19:44,976 [main] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 1
2020-12-03 07:19:45,127 [main] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:19:45,128 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 338 msecs
2020-12-03 07:19:45,333 [main] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:19:45,384 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:19:45,413 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:19:45,709 [Listener at localhost/34612] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:34612 to access this namenode/service.
2020-12-03 07:19:45,713 [Listener at localhost/34612] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:19:45,730 [Listener at localhost/34612] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:19:45,741 [Listener at localhost/34612] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:19:45,742 [Listener at localhost/34612] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:19:45,743 [Listener at localhost/34612] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:19:45,743 [Listener at localhost/34612] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:19:45,746 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 0
2020-12-03 07:19:45,746 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:19:45,746 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:19:45,746 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:19:45,747 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:19:45,747 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 4 msec
2020-12-03 07:19:45,784 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:19:45,784 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:19:45,788 [Listener at localhost/34612] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:34612
2020-12-03 07:19:45,792 [Listener at localhost/34612] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:19:45,792 [Listener at localhost/34612] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:19:45,805 [Listener at localhost/34612] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 12 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:19:45,811 [CacheReplicationMonitor(1419326200)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:19:45,821 [Listener at localhost/34612] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:19:45,890 [Listener at localhost/34612] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:19:45,905 [Listener at localhost/34612] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:19:45,929 [Listener at localhost/34612] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:19:45,934 [Listener at localhost/34612] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:45,938 [Listener at localhost/34612] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:19:45,943 [Listener at localhost/34612] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:19:45,944 [Listener at localhost/34612] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:45,949 [Listener at localhost/34612] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:19:45,955 [Listener at localhost/34612] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:41902
2020-12-03 07:19:45,957 [Listener at localhost/34612] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:19:45,958 [Listener at localhost/34612] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:19:45,978 [Listener at localhost/34612] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:45,980 [Listener at localhost/34612] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:19:45,981 [Listener at localhost/34612] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:19:45,981 [Listener at localhost/34612] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:45,984 [Listener at localhost/34612] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:19:45,985 [Listener at localhost/34612] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:19:45,985 [Listener at localhost/34612] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:19:45,985 [Listener at localhost/34612] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:19:45,989 [Listener at localhost/34612] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 36573
2020-12-03 07:19:45,989 [Listener at localhost/34612] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:19:45,990 [Listener at localhost/34612] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1643d68f{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:19:45,991 [Listener at localhost/34612] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2e029d61{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:19:45,998 [Listener at localhost/34612] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7813cb11{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:19:45,999 [Listener at localhost/34612] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@bcec031{HTTP/1.1,[http/1.1]}{localhost:36573}
2020-12-03 07:19:46,000 [Listener at localhost/34612] INFO  server.Server (Server.java:doStart(419)) - Started @5733ms
2020-12-03 07:19:46,245 [Listener at localhost/34612] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:39175
2020-12-03 07:19:46,246 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3aee3976] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:19:46,247 [Listener at localhost/34612] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:19:46,248 [Listener at localhost/34612] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:19:46,265 [Listener at localhost/34612] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:19:46,267 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:19:46,274 [Listener at localhost/42343] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:42343
2020-12-03 07:19:46,499 [Listener at localhost/42343] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:19:46,501 [Listener at localhost/42343] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:19:46,512 [Thread-59] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34612 starting to offer service
2020-12-03 07:19:46,518 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:19:46,518 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:19:46,522 [Listener at localhost/42343] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:19:46,526 [Listener at localhost/42343] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:19:46,526 [Listener at localhost/42343] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:19:46,528 [Listener at localhost/42343] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:19:46,529 [Listener at localhost/42343] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:46,529 [Listener at localhost/42343] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:19:46,529 [Listener at localhost/42343] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:19:46,529 [Listener at localhost/42343] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:46,530 [Listener at localhost/42343] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:19:46,531 [Listener at localhost/42343] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:37598
2020-12-03 07:19:46,531 [Listener at localhost/42343] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:19:46,531 [Listener at localhost/42343] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:19:46,533 [Listener at localhost/42343] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:46,535 [Listener at localhost/42343] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:19:46,536 [Listener at localhost/42343] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:19:46,536 [Listener at localhost/42343] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:46,538 [Listener at localhost/42343] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:19:46,539 [Listener at localhost/42343] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:19:46,539 [Listener at localhost/42343] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:19:46,539 [Listener at localhost/42343] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:19:46,540 [Listener at localhost/42343] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 33602
2020-12-03 07:19:46,540 [Listener at localhost/42343] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:19:46,542 [Listener at localhost/42343] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@50305a{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:19:46,543 [Listener at localhost/42343] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6d511b5f{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:19:46,549 [Listener at localhost/42343] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@2449cff7{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:19:46,550 [Listener at localhost/42343] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@42a9a63e{HTTP/1.1,[http/1.1]}{localhost:33602}
2020-12-03 07:19:46,550 [Listener at localhost/42343] INFO  server.Server (Server.java:doStart(419)) - Started @6283ms
2020-12-03 07:19:46,604 [Listener at localhost/42343] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:38851
2020-12-03 07:19:46,604 [Listener at localhost/42343] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:19:46,604 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5d8445d7] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:19:46,604 [Listener at localhost/42343] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:19:46,605 [Listener at localhost/42343] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:19:46,606 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:19:46,612 [Listener at localhost/46838] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:46838
2020-12-03 07:19:46,618 [Listener at localhost/46838] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:19:46,618 [Listener at localhost/46838] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:19:46,619 [Thread-83] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34612 starting to offer service
2020-12-03 07:19:46,620 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:19:46,620 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:19:46,626 [Listener at localhost/46838] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:19:46,628 [Listener at localhost/46838] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:19:46,628 [Listener at localhost/46838] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:19:46,630 [Listener at localhost/46838] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:19:46,631 [Listener at localhost/46838] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:46,631 [Listener at localhost/46838] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:19:46,631 [Listener at localhost/46838] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:19:46,632 [Listener at localhost/46838] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:46,632 [Listener at localhost/46838] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:19:46,633 [Listener at localhost/46838] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:43627
2020-12-03 07:19:46,633 [Listener at localhost/46838] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:19:46,633 [Listener at localhost/46838] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:19:46,634 [Listener at localhost/46838] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:46,636 [Listener at localhost/46838] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:19:46,638 [Listener at localhost/46838] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:19:46,638 [Listener at localhost/46838] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:46,640 [Listener at localhost/46838] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:19:46,641 [Listener at localhost/46838] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:19:46,641 [Listener at localhost/46838] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:19:46,641 [Listener at localhost/46838] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:19:46,642 [Listener at localhost/46838] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 41218
2020-12-03 07:19:46,642 [Listener at localhost/46838] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:19:46,645 [Listener at localhost/46838] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7249dadf{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:19:46,646 [Listener at localhost/46838] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@66238be2{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:19:46,653 [Listener at localhost/46838] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1734f68{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:19:46,654 [Listener at localhost/46838] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@77b7ffa4{HTTP/1.1,[http/1.1]}{localhost:41218}
2020-12-03 07:19:46,654 [Listener at localhost/46838] INFO  server.Server (Server.java:doStart(419)) - Started @6387ms
2020-12-03 07:19:46,674 [Listener at localhost/46838] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:39407
2020-12-03 07:19:46,674 [Listener at localhost/46838] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:19:46,674 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@402f80f5] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:19:46,675 [Listener at localhost/46838] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:19:46,675 [Listener at localhost/46838] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:19:46,679 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:19:46,684 [Listener at localhost/37837] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:37837
2020-12-03 07:19:46,688 [Listener at localhost/37837] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:19:46,688 [Listener at localhost/37837] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:19:46,689 [Thread-105] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34612 starting to offer service
2020-12-03 07:19:46,691 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:19:46,691 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:19:46,694 [Listener at localhost/37837] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 3 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:19:46,695 [Listener at localhost/37837] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:19:46,696 [Listener at localhost/37837] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:19:46,698 [Listener at localhost/37837] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:19:46,698 [Listener at localhost/37837] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:46,699 [Listener at localhost/37837] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:19:46,699 [Listener at localhost/37837] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:19:46,699 [Listener at localhost/37837] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:46,700 [Listener at localhost/37837] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:19:46,700 [Listener at localhost/37837] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:41126
2020-12-03 07:19:46,701 [Listener at localhost/37837] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:19:46,701 [Listener at localhost/37837] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:19:46,702 [Listener at localhost/37837] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:46,704 [Listener at localhost/37837] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:19:46,704 [Listener at localhost/37837] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:19:46,705 [Listener at localhost/37837] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:46,707 [Listener at localhost/37837] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:19:46,707 [Listener at localhost/37837] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:19:46,708 [Listener at localhost/37837] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:19:46,708 [Listener at localhost/37837] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:19:46,709 [Listener at localhost/37837] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 44698
2020-12-03 07:19:46,709 [Listener at localhost/37837] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:19:46,711 [Listener at localhost/37837] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@ec2bf82{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:19:46,713 [Listener at localhost/37837] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6cc0bcf6{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:19:46,719 [Listener at localhost/37837] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@503d56b5{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:19:46,720 [Listener at localhost/37837] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@72bca894{HTTP/1.1,[http/1.1]}{localhost:44698}
2020-12-03 07:19:46,720 [Listener at localhost/37837] INFO  server.Server (Server.java:doStart(419)) - Started @6453ms
2020-12-03 07:19:46,785 [Listener at localhost/37837] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:35859
2020-12-03 07:19:46,786 [Listener at localhost/37837] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:19:46,786 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1fc793c2] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:19:46,786 [Listener at localhost/37837] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:19:46,786 [Listener at localhost/37837] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:19:46,787 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:19:46,791 [Listener at localhost/39032] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:39032
2020-12-03 07:19:46,795 [Listener at localhost/39032] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:19:46,795 [Listener at localhost/39032] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:19:46,796 [Thread-127] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34612 starting to offer service
2020-12-03 07:19:46,798 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:19:46,798 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:19:46,801 [Listener at localhost/39032] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 4 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:19:46,803 [Listener at localhost/39032] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:19:46,803 [Listener at localhost/39032] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:19:46,804 [Listener at localhost/39032] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:19:46,807 [Listener at localhost/39032] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:46,807 [Listener at localhost/39032] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:19:46,807 [Listener at localhost/39032] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:19:46,808 [Listener at localhost/39032] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:46,808 [Listener at localhost/39032] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:19:46,809 [Listener at localhost/39032] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:36395
2020-12-03 07:19:46,809 [Listener at localhost/39032] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:19:46,810 [Listener at localhost/39032] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:19:46,811 [Listener at localhost/39032] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:46,814 [Listener at localhost/39032] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:19:46,817 [Listener at localhost/39032] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:19:46,817 [Listener at localhost/39032] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:46,820 [Listener at localhost/39032] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:19:46,821 [Listener at localhost/39032] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:19:46,821 [Listener at localhost/39032] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:19:46,822 [Listener at localhost/39032] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:19:46,823 [Thread-83] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34612
2020-12-03 07:19:46,823 [Thread-59] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34612
2020-12-03 07:19:46,823 [Listener at localhost/39032] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 36307
2020-12-03 07:19:46,823 [Thread-127] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34612
2020-12-03 07:19:46,823 [Thread-105] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34612
2020-12-03 07:19:46,824 [Listener at localhost/39032] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:19:46,825 [Thread-59] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:19:46,825 [Thread-127] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:19:46,825 [Thread-105] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:19:46,825 [Thread-83] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:19:46,826 [Listener at localhost/39032] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7048f722{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:19:46,827 [Listener at localhost/39032] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@58a55449{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:19:46,833 [Listener at localhost/39032] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@255990cc{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:19:46,834 [Listener at localhost/39032] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@51c929ae{HTTP/1.1,[http/1.1]}{localhost:36307}
2020-12-03 07:19:46,834 [Listener at localhost/39032] INFO  server.Server (Server.java:doStart(419)) - Started @6568ms
2020-12-03 07:19:46,848 [Listener at localhost/39032] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:37600
2020-12-03 07:19:46,849 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@29d2d081] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:19:46,849 [Listener at localhost/39032] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:19:46,850 [Listener at localhost/39032] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:19:46,850 [Listener at localhost/39032] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:19:46,851 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:19:46,854 [Listener at localhost/34772] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:34772
2020-12-03 07:19:46,858 [Listener at localhost/34772] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:19:46,859 [Listener at localhost/34772] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:19:46,859 [Thread-149] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34612 starting to offer service
2020-12-03 07:19:46,861 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:19:46,861 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:19:46,864 [Thread-149] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34612
2020-12-03 07:19:46,865 [Listener at localhost/34772] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 5 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:19:46,865 [Thread-149] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:19:46,866 [Listener at localhost/34772] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:19:46,867 [Listener at localhost/34772] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:19:46,868 [Listener at localhost/34772] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:19:46,868 [Listener at localhost/34772] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:46,868 [Listener at localhost/34772] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:19:46,869 [Listener at localhost/34772] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:19:46,869 [Listener at localhost/34772] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:46,869 [Listener at localhost/34772] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:19:46,870 [Listener at localhost/34772] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:40120
2020-12-03 07:19:46,870 [Listener at localhost/34772] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:19:46,870 [Listener at localhost/34772] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:19:46,871 [Listener at localhost/34772] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:46,873 [Listener at localhost/34772] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:19:46,873 [Listener at localhost/34772] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:19:46,874 [Listener at localhost/34772] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:46,875 [Listener at localhost/34772] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:19:46,876 [Listener at localhost/34772] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:19:46,876 [Listener at localhost/34772] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:19:46,876 [Listener at localhost/34772] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:19:46,877 [Listener at localhost/34772] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 36091
2020-12-03 07:19:46,877 [Listener at localhost/34772] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:19:46,879 [Listener at localhost/34772] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6f0628de{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:19:46,879 [Listener at localhost/34772] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1e392345{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:19:46,885 [Listener at localhost/34772] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1bdaa23d{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:19:46,886 [Listener at localhost/34772] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@79f227a9{HTTP/1.1,[http/1.1]}{localhost:36091}
2020-12-03 07:19:46,886 [Listener at localhost/34772] INFO  server.Server (Server.java:doStart(419)) - Started @6619ms
2020-12-03 07:19:46,900 [Listener at localhost/34772] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:35198
2020-12-03 07:19:46,900 [Listener at localhost/34772] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:19:46,900 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@50d68830] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:19:46,900 [Listener at localhost/34772] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:19:46,901 [Listener at localhost/34772] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:19:46,902 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:19:46,905 [Listener at localhost/34379] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:34379
2020-12-03 07:19:46,909 [Listener at localhost/34379] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:19:46,909 [Listener at localhost/34379] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:19:46,910 [Thread-171] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34612 starting to offer service
2020-12-03 07:19:46,911 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:19:46,912 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:19:46,914 [Thread-171] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34612
2020-12-03 07:19:46,915 [Listener at localhost/34379] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 6 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:19:46,915 [Thread-171] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:19:46,916 [Listener at localhost/34379] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:19:46,916 [Listener at localhost/34379] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:19:46,917 [Listener at localhost/34379] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:19:46,918 [Listener at localhost/34379] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:46,918 [Listener at localhost/34379] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:19:46,919 [Listener at localhost/34379] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:19:46,919 [Listener at localhost/34379] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:46,919 [Listener at localhost/34379] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:19:46,920 [Listener at localhost/34379] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:41753
2020-12-03 07:19:46,920 [Listener at localhost/34379] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:19:46,920 [Listener at localhost/34379] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:19:46,921 [Listener at localhost/34379] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:46,921 [Thread-127] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/in_use.lock acquired by nodename 906@9ece31fe74eb
2020-12-03 07:19:46,921 [Thread-59] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 906@9ece31fe74eb
2020-12-03 07:19:46,921 [Thread-105] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 906@9ece31fe74eb
2020-12-03 07:19:46,921 [Thread-83] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 906@9ece31fe74eb
2020-12-03 07:19:46,921 [Thread-149] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/in_use.lock acquired by nodename 906@9ece31fe74eb
2020-12-03 07:19:46,922 [Thread-127] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 is not formatted for namespace 662464899. Formatting...
2020-12-03 07:19:46,922 [Thread-149] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 is not formatted for namespace 662464899. Formatting...
2020-12-03 07:19:46,922 [Thread-105] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 is not formatted for namespace 662464899. Formatting...
2020-12-03 07:19:46,922 [Thread-83] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 is not formatted for namespace 662464899. Formatting...
2020-12-03 07:19:46,923 [Thread-59] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 662464899. Formatting...
2020-12-03 07:19:46,923 [Listener at localhost/34379] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:19:46,923 [Thread-127] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-28904309-f21d-4622-b590-65c20013b1c7 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 
2020-12-03 07:19:46,924 [Thread-149] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-47ca938b-a40d-4407-b093-5825baebb00c for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 
2020-12-03 07:19:46,923 [Thread-83] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-0bb00b44-1a33-4c83-8050-95766856105e for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 
2020-12-03 07:19:46,923 [Thread-105] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-6f70985c-ac30-47d0-891a-02298a52a999 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 
2020-12-03 07:19:46,924 [Listener at localhost/34379] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:19:46,924 [Thread-59] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-9c05f2e3-34b6-4594-b06f-9365cd2a0a2f for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-12-03 07:19:46,924 [Listener at localhost/34379] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:46,926 [Listener at localhost/34379] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:19:46,927 [Listener at localhost/34379] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:19:46,927 [Listener at localhost/34379] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:19:46,927 [Listener at localhost/34379] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:19:46,928 [Listener at localhost/34379] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 40502
2020-12-03 07:19:46,928 [Listener at localhost/34379] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:19:46,929 [Listener at localhost/34379] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3e792ce3{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:19:46,930 [Listener at localhost/34379] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@26f143ed{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:19:46,936 [Listener at localhost/34379] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@61a5b4ae{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:19:46,937 [Listener at localhost/34379] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3a71c100{HTTP/1.1,[http/1.1]}{localhost:40502}
2020-12-03 07:19:46,938 [Listener at localhost/34379] INFO  server.Server (Server.java:doStart(419)) - Started @6671ms
2020-12-03 07:19:46,952 [Listener at localhost/34379] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:44140
2020-12-03 07:19:46,952 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@f325091] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:19:46,952 [Listener at localhost/34379] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:19:46,952 [Listener at localhost/34379] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:19:46,953 [Listener at localhost/34379] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:19:46,954 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:19:46,957 [Listener at localhost/33519] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:33519
2020-12-03 07:19:46,961 [Listener at localhost/33519] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:19:46,961 [Listener at localhost/33519] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:19:46,962 [Thread-193] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34612 starting to offer service
2020-12-03 07:19:46,964 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:19:46,964 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:19:46,967 [Thread-193] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34612
2020-12-03 07:19:46,968 [Thread-193] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:19:46,968 [Listener at localhost/33519] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 7 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:19:46,969 [Listener at localhost/33519] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:19:46,970 [Listener at localhost/33519] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:19:46,971 [Listener at localhost/33519] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:19:46,972 [Listener at localhost/33519] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:46,972 [Listener at localhost/33519] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:19:46,972 [Listener at localhost/33519] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:19:46,972 [Listener at localhost/33519] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:46,973 [Listener at localhost/33519] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:19:46,973 [Listener at localhost/33519] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:40379
2020-12-03 07:19:46,973 [Listener at localhost/33519] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:19:46,974 [Listener at localhost/33519] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:19:46,975 [Listener at localhost/33519] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:46,976 [Listener at localhost/33519] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:19:46,977 [Listener at localhost/33519] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:19:46,977 [Listener at localhost/33519] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:46,979 [Listener at localhost/33519] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:19:46,979 [Listener at localhost/33519] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:19:46,979 [Listener at localhost/33519] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:19:46,980 [Listener at localhost/33519] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:19:46,980 [Listener at localhost/33519] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 41515
2020-12-03 07:19:46,980 [Listener at localhost/33519] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:19:46,981 [Thread-171] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/in_use.lock acquired by nodename 906@9ece31fe74eb
2020-12-03 07:19:46,983 [Thread-171] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 is not formatted for namespace 662464899. Formatting...
2020-12-03 07:19:46,983 [Thread-171] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-e89d6108-2324-4b34-addb-9670aed7d37d for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 
2020-12-03 07:19:46,984 [Listener at localhost/33519] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@74a9c4b0{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:19:46,985 [Listener at localhost/33519] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1c05a54d{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:19:46,990 [Listener at localhost/33519] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@51bde877{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:19:46,991 [Listener at localhost/33519] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@60b85ba1{HTTP/1.1,[http/1.1]}{localhost:41515}
2020-12-03 07:19:46,991 [Listener at localhost/33519] INFO  server.Server (Server.java:doStart(419)) - Started @6725ms
2020-12-03 07:19:47,025 [Thread-193] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/in_use.lock acquired by nodename 906@9ece31fe74eb
2020-12-03 07:19:47,028 [Thread-193] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 is not formatted for namespace 662464899. Formatting...
2020-12-03 07:19:47,029 [Thread-193] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-0b503d65-8d01-49ef-8e43-291aff1d549a for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 
2020-12-03 07:19:47,071 [Listener at localhost/33519] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:35523
2020-12-03 07:19:47,073 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@117632cf] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:19:47,073 [Listener at localhost/33519] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:19:47,073 [Listener at localhost/33519] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:19:47,074 [Listener at localhost/33519] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:19:47,076 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:19:47,081 [Listener at localhost/34054] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:34054
2020-12-03 07:19:47,088 [Listener at localhost/34054] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:19:47,088 [Listener at localhost/34054] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:19:47,089 [Thread-215] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34612 starting to offer service
2020-12-03 07:19:47,091 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:19:47,091 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:19:47,098 [Thread-215] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34612
2020-12-03 07:19:47,099 [Thread-215] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:19:47,176 [Thread-215] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/in_use.lock acquired by nodename 906@9ece31fe74eb
2020-12-03 07:19:47,177 [Thread-215] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 is not formatted for namespace 662464899. Formatting...
2020-12-03 07:19:47,177 [Thread-215] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-3a17eb31-b33e-4a9a-a80f-9b182d8e1248 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 
2020-12-03 07:19:47,279 [Thread-83] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 906@9ece31fe74eb
2020-12-03 07:19:47,279 [Thread-59] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 906@9ece31fe74eb
2020-12-03 07:19:47,279 [Thread-149] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/in_use.lock acquired by nodename 906@9ece31fe74eb
2020-12-03 07:19:47,279 [Thread-105] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 906@9ece31fe74eb
2020-12-03 07:19:47,279 [Thread-149] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 is not formatted for namespace 662464899. Formatting...
2020-12-03 07:19:47,279 [Thread-171] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/in_use.lock acquired by nodename 906@9ece31fe74eb
2020-12-03 07:19:47,279 [Thread-127] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/in_use.lock acquired by nodename 906@9ece31fe74eb
2020-12-03 07:19:47,279 [Thread-59] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 662464899. Formatting...
2020-12-03 07:19:47,279 [Thread-83] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 is not formatted for namespace 662464899. Formatting...
2020-12-03 07:19:47,280 [Thread-127] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 is not formatted for namespace 662464899. Formatting...
2020-12-03 07:19:47,280 [Thread-171] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 is not formatted for namespace 662464899. Formatting...
2020-12-03 07:19:47,280 [Thread-105] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 is not formatted for namespace 662464899. Formatting...
2020-12-03 07:19:47,280 [Thread-83] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-0e3fa327-8df7-42f0-8bbd-411a1ebd4305 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 
2020-12-03 07:19:47,281 [Thread-105] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-ca7c16c8-a7cd-40c3-9072-e5e55f35ba2f for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 
2020-12-03 07:19:47,281 [Thread-127] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-8d7e7ea8-c1a7-4424-9e6e-68f075bb1fe6 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 
2020-12-03 07:19:47,281 [Thread-171] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-3571474c-359b-4f98-94a4-8b83a1d0652c for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 
2020-12-03 07:19:47,281 [Thread-149] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-9de9d331-cfd4-450a-96bf-6bed8d407bd9 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 
2020-12-03 07:19:47,281 [Thread-59] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-cd676010-abda-483c-a6ea-b69676538fc2 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-12-03 07:19:47,354 [Thread-193] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/in_use.lock acquired by nodename 906@9ece31fe74eb
2020-12-03 07:19:47,355 [Thread-193] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 is not formatted for namespace 662464899. Formatting...
2020-12-03 07:19:47,355 [Thread-193] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-5b6b1a9c-9c26-49bb-9bbd-60b622efa680 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 
2020-12-03 07:19:47,451 [Thread-215] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/in_use.lock acquired by nodename 906@9ece31fe74eb
2020-12-03 07:19:47,451 [Thread-215] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 is not formatted for namespace 662464899. Formatting...
2020-12-03 07:19:47,451 [Thread-215] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-a91ecbc1-38a0-4aee-a8bb-57f2ff2f9937 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 
2020-12-03 07:19:47,504 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:47,504 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:47,504 [Thread-127] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:47,504 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:47,504 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:47,504 [Thread-171] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:47,504 [Thread-127] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:47,504 [Thread-59] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:47,504 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:47,504 [Thread-105] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:47,505 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-464449197-172.17.0.6-1606979982896 is not formatted. Formatting ...
2020-12-03 07:19:47,505 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 and block pool id BP-464449197-172.17.0.6-1606979982896 is not formatted. Formatting ...
2020-12-03 07:19:47,505 [Thread-127] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 and block pool id BP-464449197-172.17.0.6-1606979982896 is not formatted. Formatting ...
2020-12-03 07:19:47,505 [Thread-149] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:47,506 [Thread-127] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-464449197-172.17.0.6-1606979982896 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-464449197-172.17.0.6-1606979982896/current
2020-12-03 07:19:47,506 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-464449197-172.17.0.6-1606979982896 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-464449197-172.17.0.6-1606979982896/current
2020-12-03 07:19:47,505 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-464449197-172.17.0.6-1606979982896 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-464449197-172.17.0.6-1606979982896/current
2020-12-03 07:19:47,505 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 and block pool id BP-464449197-172.17.0.6-1606979982896 is not formatted. Formatting ...
2020-12-03 07:19:47,505 [Thread-83] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:47,506 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-464449197-172.17.0.6-1606979982896 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-464449197-172.17.0.6-1606979982896/current
2020-12-03 07:19:47,507 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 and block pool id BP-464449197-172.17.0.6-1606979982896 is not formatted. Formatting ...
2020-12-03 07:19:47,506 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 and block pool id BP-464449197-172.17.0.6-1606979982896 is not formatted. Formatting ...
2020-12-03 07:19:47,507 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-464449197-172.17.0.6-1606979982896 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-464449197-172.17.0.6-1606979982896/current
2020-12-03 07:19:47,507 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-464449197-172.17.0.6-1606979982896 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-464449197-172.17.0.6-1606979982896/current
2020-12-03 07:19:47,516 [Thread-193] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:47,517 [Thread-193] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:47,517 [Thread-193] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 and block pool id BP-464449197-172.17.0.6-1606979982896 is not formatted. Formatting ...
2020-12-03 07:19:47,517 [Thread-193] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-464449197-172.17.0.6-1606979982896 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-464449197-172.17.0.6-1606979982896/current
2020-12-03 07:19:47,546 [IPC Server handler 9 on default port 34612] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:47,553 [Listener at localhost/34054] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:47,553 [Listener at localhost/34054] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:47,644 [Thread-215] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:47,644 [Thread-215] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:47,645 [Thread-215] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 and block pool id BP-464449197-172.17.0.6-1606979982896 is not formatted. Formatting ...
2020-12-03 07:19:47,645 [Thread-215] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-464449197-172.17.0.6-1606979982896 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-464449197-172.17.0.6-1606979982896/current
2020-12-03 07:19:47,655 [IPC Server handler 7 on default port 34612] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:47,656 [Listener at localhost/34054] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:47,657 [Listener at localhost/34054] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:47,759 [IPC Server handler 0 on default port 34612] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:47,759 [Listener at localhost/34054] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:47,759 [Listener at localhost/34054] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:47,807 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:47,807 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:47,807 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:47,807 [Thread-149] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:47,807 [Thread-59] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:47,808 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 and block pool id BP-464449197-172.17.0.6-1606979982896 is not formatted. Formatting ...
2020-12-03 07:19:47,808 [Thread-105] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:47,808 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-464449197-172.17.0.6-1606979982896 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-464449197-172.17.0.6-1606979982896/current
2020-12-03 07:19:47,808 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 and block pool id BP-464449197-172.17.0.6-1606979982896 is not formatted. Formatting ...
2020-12-03 07:19:47,808 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-464449197-172.17.0.6-1606979982896 is not formatted. Formatting ...
2020-12-03 07:19:47,808 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-464449197-172.17.0.6-1606979982896 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-464449197-172.17.0.6-1606979982896/current
2020-12-03 07:19:47,808 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-464449197-172.17.0.6-1606979982896 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-464449197-172.17.0.6-1606979982896/current
2020-12-03 07:19:47,810 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:47,810 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:47,810 [Thread-127] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:47,810 [Thread-171] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:47,810 [Thread-83] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:47,811 [Thread-127] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:47,811 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 and block pool id BP-464449197-172.17.0.6-1606979982896 is not formatted. Formatting ...
2020-12-03 07:19:47,811 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 and block pool id BP-464449197-172.17.0.6-1606979982896 is not formatted. Formatting ...
2020-12-03 07:19:47,811 [Thread-127] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 and block pool id BP-464449197-172.17.0.6-1606979982896 is not formatted. Formatting ...
2020-12-03 07:19:47,811 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-464449197-172.17.0.6-1606979982896 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-464449197-172.17.0.6-1606979982896/current
2020-12-03 07:19:47,811 [Thread-127] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-464449197-172.17.0.6-1606979982896 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-464449197-172.17.0.6-1606979982896/current
2020-12-03 07:19:47,811 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-464449197-172.17.0.6-1606979982896 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-464449197-172.17.0.6-1606979982896/current
2020-12-03 07:19:47,838 [Thread-193] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:47,838 [Thread-193] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:47,839 [Thread-193] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 and block pool id BP-464449197-172.17.0.6-1606979982896 is not formatted. Formatting ...
2020-12-03 07:19:47,839 [Thread-193] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-464449197-172.17.0.6-1606979982896 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-464449197-172.17.0.6-1606979982896/current
2020-12-03 07:19:47,862 [IPC Server handler 4 on default port 34612] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:47,863 [Listener at localhost/34054] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:47,863 [Listener at localhost/34054] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:47,934 [Thread-215] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:47,934 [Thread-215] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:47,934 [Thread-215] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 and block pool id BP-464449197-172.17.0.6-1606979982896 is not formatted. Formatting ...
2020-12-03 07:19:47,934 [Thread-215] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-464449197-172.17.0.6-1606979982896 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-464449197-172.17.0.6-1606979982896/current
2020-12-03 07:19:47,965 [IPC Server handler 8 on default port 34612] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:47,966 [Listener at localhost/34054] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:47,966 [Listener at localhost/34054] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:48,043 [Thread-105] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=662464899;bpid=BP-464449197-172.17.0.6-1606979982896;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=662464899;c=1606979982896;bpid=BP-464449197-172.17.0.6-1606979982896;dnuuid=null
2020-12-03 07:19:48,043 [Thread-59] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=662464899;bpid=BP-464449197-172.17.0.6-1606979982896;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=662464899;c=1606979982896;bpid=BP-464449197-172.17.0.6-1606979982896;dnuuid=null
2020-12-03 07:19:48,043 [Thread-149] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=662464899;bpid=BP-464449197-172.17.0.6-1606979982896;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=662464899;c=1606979982896;bpid=BP-464449197-172.17.0.6-1606979982896;dnuuid=null
2020-12-03 07:19:48,043 [Thread-171] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=662464899;bpid=BP-464449197-172.17.0.6-1606979982896;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=662464899;c=1606979982896;bpid=BP-464449197-172.17.0.6-1606979982896;dnuuid=null
2020-12-03 07:19:48,043 [Thread-127] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=662464899;bpid=BP-464449197-172.17.0.6-1606979982896;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=662464899;c=1606979982896;bpid=BP-464449197-172.17.0.6-1606979982896;dnuuid=null
2020-12-03 07:19:48,043 [Thread-83] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=662464899;bpid=BP-464449197-172.17.0.6-1606979982896;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=662464899;c=1606979982896;bpid=BP-464449197-172.17.0.6-1606979982896;dnuuid=null
2020-12-03 07:19:48,068 [IPC Server handler 6 on default port 34612] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:48,069 [Listener at localhost/34054] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:48,069 [Listener at localhost/34054] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:48,102 [Thread-193] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=662464899;bpid=BP-464449197-172.17.0.6-1606979982896;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=662464899;c=1606979982896;bpid=BP-464449197-172.17.0.6-1606979982896;dnuuid=null
2020-12-03 07:19:48,170 [Thread-215] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=662464899;bpid=BP-464449197-172.17.0.6-1606979982896;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=662464899;c=1606979982896;bpid=BP-464449197-172.17.0.6-1606979982896;dnuuid=null
2020-12-03 07:19:48,171 [IPC Server handler 9 on default port 34612] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:48,171 [Listener at localhost/34054] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:48,171 [Listener at localhost/34054] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:48,274 [IPC Server handler 7 on default port 34612] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:48,275 [Listener at localhost/34054] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:48,276 [Listener at localhost/34054] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:48,313 [Thread-127] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 2b5a1500-a27d-403f-b7e5-7837081de87c
2020-12-03 07:19:48,313 [Thread-149] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 309f7fa0-0c59-4920-a6f9-56c2485276d8
2020-12-03 07:19:48,313 [Thread-59] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID ec6135ad-ddf0-47a2-866e-c2a0a646b3ea
2020-12-03 07:19:48,313 [Thread-83] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID ba28613b-b481-4768-b4d4-cf44e7144ddf
2020-12-03 07:19:48,313 [Thread-171] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID edec627a-465f-4532-ab74-3f78e8a40769
2020-12-03 07:19:48,313 [Thread-105] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 01c12b1d-d7d2-421e-986c-c593ac806eae
2020-12-03 07:19:48,357 [Thread-193] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID baa99858-a351-4f23-95d3-417a6368fdb3
2020-12-03 07:19:48,378 [IPC Server handler 0 on default port 34612] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:48,378 [Listener at localhost/34054] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:48,378 [Listener at localhost/34054] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:48,430 [Thread-215] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 1840bbdd-b765-44bd-8c75-9f95ec61318d
2020-12-03 07:19:48,446 [Thread-171] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-e89d6108-2324-4b34-addb-9670aed7d37d
2020-12-03 07:19:48,446 [Thread-171] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, StorageType: DISK
2020-12-03 07:19:48,448 [Thread-105] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-6f70985c-ac30-47d0-891a-02298a52a999
2020-12-03 07:19:48,446 [Thread-215] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-3a17eb31-b33e-4a9a-a80f-9b182d8e1248
2020-12-03 07:19:48,446 [Thread-193] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-0b503d65-8d01-49ef-8e43-291aff1d549a
2020-12-03 07:19:48,446 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-9c05f2e3-34b6-4594-b06f-9365cd2a0a2f
2020-12-03 07:19:48,449 [Thread-105] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, StorageType: DISK
2020-12-03 07:19:48,450 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-12-03 07:19:48,450 [Thread-193] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, StorageType: DISK
2020-12-03 07:19:48,447 [Thread-149] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-47ca938b-a40d-4407-b093-5825baebb00c
2020-12-03 07:19:48,447 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-0bb00b44-1a33-4c83-8050-95766856105e
2020-12-03 07:19:48,449 [Thread-215] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, StorageType: DISK
2020-12-03 07:19:48,447 [Thread-127] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-28904309-f21d-4622-b590-65c20013b1c7
2020-12-03 07:19:48,451 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: DISK
2020-12-03 07:19:48,451 [Thread-149] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, StorageType: DISK
2020-12-03 07:19:48,451 [Thread-171] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-3571474c-359b-4f98-94a4-8b83a1d0652c
2020-12-03 07:19:48,451 [Thread-127] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, StorageType: DISK
2020-12-03 07:19:48,452 [Thread-171] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, StorageType: DISK
2020-12-03 07:19:48,453 [Thread-193] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-5b6b1a9c-9c26-49bb-9bbd-60b622efa680
2020-12-03 07:19:48,453 [Thread-193] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, StorageType: DISK
2020-12-03 07:19:48,455 [Thread-149] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-9de9d331-cfd4-450a-96bf-6bed8d407bd9
2020-12-03 07:19:48,455 [Thread-149] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, StorageType: DISK
2020-12-03 07:19:48,457 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-0e3fa327-8df7-42f0-8bbd-411a1ebd4305
2020-12-03 07:19:48,457 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: DISK
2020-12-03 07:19:48,459 [Thread-193] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:19:48,459 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:19:48,459 [Thread-149] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:19:48,459 [Thread-171] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:19:48,459 [Thread-215] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-a91ecbc1-38a0-4aee-a8bb-57f2ff2f9937
2020-12-03 07:19:48,460 [Thread-215] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, StorageType: DISK
2020-12-03 07:19:48,460 [Thread-215] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:19:48,461 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-cd676010-abda-483c-a6ea-b69676538fc2
2020-12-03 07:19:48,462 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-12-03 07:19:48,462 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:19:48,463 [Thread-105] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-ca7c16c8-a7cd-40c3-9072-e5e55f35ba2f
2020-12-03 07:19:48,464 [Thread-105] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, StorageType: DISK
2020-12-03 07:19:48,464 [Thread-105] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:19:48,469 [Thread-59] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:19:48,470 [Thread-215] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:19:48,471 [Thread-171] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:19:48,472 [Thread-149] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:19:48,473 [Thread-83] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:19:48,474 [Thread-193] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:19:48,475 [Thread-127] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-8d7e7ea8-c1a7-4424-9e6e-68f075bb1fe6
2020-12-03 07:19:48,475 [Thread-127] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, StorageType: DISK
2020-12-03 07:19:48,476 [Thread-127] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:19:48,476 [Thread-105] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:19:48,478 [Thread-127] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:19:48,478 [Thread-59] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:19:48,478 [Thread-149] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:19:48,479 [Thread-127] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:19:48,478 [Thread-215] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:19:48,478 [Thread-83] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:19:48,478 [Thread-105] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:19:48,478 [Thread-193] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:19:48,478 [Thread-171] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:19:48,480 [IPC Server handler 1 on default port 34612] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:48,481 [Thread-127] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:19:48,481 [Thread-149] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:19:48,481 [Thread-83] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:19:48,481 [Thread-171] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:19:48,481 [Thread-193] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:19:48,481 [Thread-59] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:19:48,481 [Thread-215] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:19:48,481 [Thread-105] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:19:48,484 [Thread-215] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:19:48,483 [Thread-59] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:19:48,483 [Thread-193] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:19:48,482 [Thread-171] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:19:48,481 [Thread-83] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:19:48,481 [Listener at localhost/34054] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:48,485 [Listener at localhost/34054] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:48,481 [Thread-149] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:19:48,481 [Thread-127] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:19:48,486 [Thread-149] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:48,485 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:48,485 [Thread-171] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:48,485 [Thread-193] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:48,485 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:48,485 [Thread-215] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:48,484 [Thread-105] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:19:48,486 [Thread-127] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:48,486 [Thread-245] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-12-03 07:19:48,486 [Thread-105] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:48,487 [Thread-246] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:19:48,487 [Thread-249] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:19:48,487 [Thread-247] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11...
2020-12-03 07:19:48,487 [Thread-251] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-12-03 07:19:48,487 [Thread-248] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13...
2020-12-03 07:19:48,487 [Thread-256] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:19:48,487 [Thread-250] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15...
2020-12-03 07:19:48,488 [Thread-253] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-12-03 07:19:48,488 [Thread-252] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12...
2020-12-03 07:19:48,488 [Thread-260] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-12-03 07:19:48,488 [Thread-254] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:19:48,488 [Thread-258] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:19:48,488 [Thread-255] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:19:48,488 [Thread-257] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14...
2020-12-03 07:19:48,488 [Thread-259] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16...
2020-12-03 07:19:48,553 [Thread-251] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-464449197-172.17.0.6-1606979982896 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 65ms
2020-12-03 07:19:48,565 [Thread-259] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-464449197-172.17.0.6-1606979982896 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16: 76ms
2020-12-03 07:19:48,566 [Thread-252] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-464449197-172.17.0.6-1606979982896 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12: 79ms
2020-12-03 07:19:48,570 [Thread-246] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-464449197-172.17.0.6-1606979982896 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 84ms
2020-12-03 07:19:48,578 [Thread-249] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-464449197-172.17.0.6-1606979982896 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 91ms
2020-12-03 07:19:48,579 [Thread-258] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-464449197-172.17.0.6-1606979982896 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 90ms
2020-12-03 07:19:48,588 [IPC Server handler 3 on default port 34612] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:48,588 [Listener at localhost/34054] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:48,589 [Listener at localhost/34054] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:48,590 [Thread-260] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-464449197-172.17.0.6-1606979982896 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 102ms
2020-12-03 07:19:48,590 [Thread-256] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-464449197-172.17.0.6-1606979982896 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 103ms
2020-12-03 07:19:48,590 [Thread-250] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-464449197-172.17.0.6-1606979982896 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15: 103ms
2020-12-03 07:19:48,591 [Thread-105] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-464449197-172.17.0.6-1606979982896: 104ms
2020-12-03 07:19:48,591 [Thread-215] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-464449197-172.17.0.6-1606979982896: 104ms
2020-12-03 07:19:48,591 [Thread-248] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-464449197-172.17.0.6-1606979982896 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13: 103ms
2020-12-03 07:19:48,594 [Thread-277] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:19:48,594 [Thread-278] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15...
2020-12-03 07:19:48,594 [Thread-280] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16...
2020-12-03 07:19:48,594 [Thread-279] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:19:48,594 [Thread-247] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-464449197-172.17.0.6-1606979982896 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11: 106ms
2020-12-03 07:19:48,594 [Thread-254] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-464449197-172.17.0.6-1606979982896 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 105ms
2020-12-03 07:19:48,595 [Thread-171] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-464449197-172.17.0.6-1606979982896: 108ms
2020-12-03 07:19:48,595 [Thread-279] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-464449197-172.17.0.6-1606979982896/current/replicas doesn't exist 
2020-12-03 07:19:48,595 [Thread-255] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-464449197-172.17.0.6-1606979982896 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 106ms
2020-12-03 07:19:48,595 [Thread-280] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-464449197-172.17.0.6-1606979982896/current/replicas doesn't exist 
2020-12-03 07:19:48,595 [Thread-253] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-464449197-172.17.0.6-1606979982896 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 107ms
2020-12-03 07:19:48,596 [Thread-281] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11...
2020-12-03 07:19:48,594 [Thread-278] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-464449197-172.17.0.6-1606979982896/current/replicas doesn't exist 
2020-12-03 07:19:48,594 [Thread-277] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-464449197-172.17.0.6-1606979982896/current/replicas doesn't exist 
2020-12-03 07:19:48,596 [Thread-245] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-464449197-172.17.0.6-1606979982896 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 109ms
2020-12-03 07:19:48,596 [Thread-281] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-464449197-172.17.0.6-1606979982896/current/replicas doesn't exist 
2020-12-03 07:19:48,596 [Thread-127] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-464449197-172.17.0.6-1606979982896: 109ms
2020-12-03 07:19:48,596 [Thread-280] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16: 3ms
2020-12-03 07:19:48,597 [Thread-283] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-12-03 07:19:48,596 [Thread-282] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12...
2020-12-03 07:19:48,598 [Thread-279] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 4ms
2020-12-03 07:19:48,595 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-464449197-172.17.0.6-1606979982896: 109ms
2020-12-03 07:19:48,595 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-464449197-172.17.0.6-1606979982896: 110ms
2020-12-03 07:19:48,599 [Thread-284] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-12-03 07:19:48,598 [Thread-282] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-464449197-172.17.0.6-1606979982896/current/replicas doesn't exist 
2020-12-03 07:19:48,598 [Thread-281] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11: 3ms
2020-12-03 07:19:48,598 [Thread-283] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-464449197-172.17.0.6-1606979982896/current/replicas doesn't exist 
2020-12-03 07:19:48,600 [Thread-287] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:19:48,600 [Thread-283] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 3ms
2020-12-03 07:19:48,598 [Thread-277] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 4ms
2020-12-03 07:19:48,597 [Thread-278] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15: 3ms
2020-12-03 07:19:48,596 [Thread-257] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-464449197-172.17.0.6-1606979982896 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14: 108ms
2020-12-03 07:19:48,596 [Thread-149] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-464449197-172.17.0.6-1606979982896: 111ms
2020-12-03 07:19:48,600 [Thread-193] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-464449197-172.17.0.6-1606979982896: 114ms
2020-12-03 07:19:48,600 [Thread-215] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-464449197-172.17.0.6-1606979982896: 8ms
2020-12-03 07:19:48,601 [Thread-289] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-12-03 07:19:48,600 [Thread-105] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-464449197-172.17.0.6-1606979982896: 8ms
2020-12-03 07:19:48,600 [Thread-287] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-464449197-172.17.0.6-1606979982896/current/replicas doesn't exist 
2020-12-03 07:19:48,600 [Thread-288] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:19:48,601 [Thread-292] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14...
2020-12-03 07:19:48,601 [Thread-288] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-464449197-172.17.0.6-1606979982896/current/replicas doesn't exist 
2020-12-03 07:19:48,601 [Thread-292] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-464449197-172.17.0.6-1606979982896/current/replicas doesn't exist 
2020-12-03 07:19:48,600 [Thread-282] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12: 1ms
2020-12-03 07:19:48,601 [Thread-288] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 1ms
2020-12-03 07:19:48,601 [Thread-171] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-464449197-172.17.0.6-1606979982896: 6ms
2020-12-03 07:19:48,599 [Thread-286] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:19:48,599 [Thread-284] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-464449197-172.17.0.6-1606979982896/current/replicas doesn't exist 
2020-12-03 07:19:48,603 [Thread-286] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-464449197-172.17.0.6-1606979982896/current/replicas doesn't exist 
2020-12-03 07:19:48,603 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:19:48,599 [Thread-285] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:19:48,604 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:19:48,604 [Thread-284] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 5ms
2020-12-03 07:19:48,604 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:19:48,604 [Thread-286] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 2ms
2020-12-03 07:19:48,604 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:19:48,603 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:19:48,603 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:19:48,601 [Thread-292] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14: 0ms
2020-12-03 07:19:48,601 [Thread-287] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 2ms
2020-12-03 07:19:48,607 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-3571474c-359b-4f98-94a4-8b83a1d0652c): finished scanning block pool BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:48,601 [Thread-291] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-12-03 07:19:48,601 [Thread-289] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-464449197-172.17.0.6-1606979982896/current/replicas doesn't exist 
2020-12-03 07:19:48,601 [Thread-290] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13...
2020-12-03 07:19:48,608 [Thread-291] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-464449197-172.17.0.6-1606979982896/current/replicas doesn't exist 
2020-12-03 07:19:48,608 [Thread-290] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-464449197-172.17.0.6-1606979982896/current/replicas doesn't exist 
2020-12-03 07:19:48,607 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-e89d6108-2324-4b34-addb-9670aed7d37d): finished scanning block pool BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:48,606 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-ca7c16c8-a7cd-40c3-9072-e5e55f35ba2f): finished scanning block pool BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:48,608 [Thread-290] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13: 1ms
2020-12-03 07:19:48,608 [Thread-289] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 8ms
2020-12-03 07:19:48,606 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-3a17eb31-b33e-4a9a-a80f-9b182d8e1248): finished scanning block pool BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:48,606 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-a91ecbc1-38a0-4aee-a8bb-57f2ff2f9937): finished scanning block pool BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:48,606 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-6f70985c-ac30-47d0-891a-02298a52a999): finished scanning block pool BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:48,605 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-464449197-172.17.0.6-1606979982896: 6ms
2020-12-03 07:19:48,605 [Thread-127] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-464449197-172.17.0.6-1606979982896: 8ms
2020-12-03 07:19:48,604 [Thread-285] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-464449197-172.17.0.6-1606979982896/current/replicas doesn't exist 
2020-12-03 07:19:48,610 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:19:48,610 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:19:48,609 [Thread-193] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-464449197-172.17.0.6-1606979982896: 9ms
2020-12-03 07:19:48,608 [Thread-291] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 1ms
2020-12-03 07:19:48,610 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-0e3fa327-8df7-42f0-8bbd-411a1ebd4305): finished scanning block pool BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:48,610 [Thread-285] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 6ms
2020-12-03 07:19:48,610 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:19:48,610 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:19:48,611 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-464449197-172.17.0.6-1606979982896: 12ms
2020-12-03 07:19:48,611 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:19:48,610 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:19:48,610 [Thread-149] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-464449197-172.17.0.6-1606979982896: 10ms
2020-12-03 07:19:48,611 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-5b6b1a9c-9c26-49bb-9bbd-60b622efa680): finished scanning block pool BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:48,611 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:19:48,611 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-8d7e7ea8-c1a7-4424-9e6e-68f075bb1fe6): finished scanning block pool BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:48,611 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-28904309-f21d-4622-b590-65c20013b1c7): finished scanning block pool BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:48,612 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:19:48,611 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:19:48,611 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-0b503d65-8d01-49ef-8e43-291aff1d549a): finished scanning block pool BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:48,612 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-9de9d331-cfd4-450a-96bf-6bed8d407bd9): finished scanning block pool BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:48,611 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:19:48,612 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-47ca938b-a40d-4407-b093-5825baebb00c): finished scanning block pool BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:48,612 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-9c05f2e3-34b6-4594-b06f-9365cd2a0a2f): finished scanning block pool BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:48,612 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-cd676010-abda-483c-a6ea-b69676538fc2): finished scanning block pool BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:48,614 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-0bb00b44-1a33-4c83-8050-95766856105e): finished scanning block pool BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:48,627 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-e89d6108-2324-4b34-addb-9670aed7d37d): no suitable block pools found to scan.  Waiting 1814399976 ms.
2020-12-03 07:19:48,627 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-0bb00b44-1a33-4c83-8050-95766856105e): no suitable block pools found to scan.  Waiting 1814399983 ms.
2020-12-03 07:19:48,628 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-9c05f2e3-34b6-4594-b06f-9365cd2a0a2f): no suitable block pools found to scan.  Waiting 1814399984 ms.
2020-12-03 07:19:48,627 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-47ca938b-a40d-4407-b093-5825baebb00c): no suitable block pools found to scan.  Waiting 1814399984 ms.
2020-12-03 07:19:48,628 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-9de9d331-cfd4-450a-96bf-6bed8d407bd9): no suitable block pools found to scan.  Waiting 1814399984 ms.
2020-12-03 07:19:48,628 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-28904309-f21d-4622-b590-65c20013b1c7): no suitable block pools found to scan.  Waiting 1814399982 ms.
2020-12-03 07:19:48,628 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-3571474c-359b-4f98-94a4-8b83a1d0652c): no suitable block pools found to scan.  Waiting 1814399975 ms.
2020-12-03 07:19:48,628 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-0b503d65-8d01-49ef-8e43-291aff1d549a): no suitable block pools found to scan.  Waiting 1814399982 ms.
2020-12-03 07:19:48,628 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-5b6b1a9c-9c26-49bb-9bbd-60b622efa680): no suitable block pools found to scan.  Waiting 1814399982 ms.
2020-12-03 07:19:48,628 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-3a17eb31-b33e-4a9a-a80f-9b182d8e1248): no suitable block pools found to scan.  Waiting 1814399975 ms.
2020-12-03 07:19:48,628 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-8d7e7ea8-c1a7-4424-9e6e-68f075bb1fe6): no suitable block pools found to scan.  Waiting 1814399982 ms.
2020-12-03 07:19:48,628 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-cd676010-abda-483c-a6ea-b69676538fc2): no suitable block pools found to scan.  Waiting 1814399983 ms.
2020-12-03 07:19:48,628 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-a91ecbc1-38a0-4aee-a8bb-57f2ff2f9937): no suitable block pools found to scan.  Waiting 1814399975 ms.
2020-12-03 07:19:48,628 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-6f70985c-ac30-47d0-891a-02298a52a999): no suitable block pools found to scan.  Waiting 1814399975 ms.
2020-12-03 07:19:48,628 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-ca7c16c8-a7cd-40c3-9072-e5e55f35ba2f): no suitable block pools found to scan.  Waiting 1814399975 ms.
2020-12-03 07:19:48,629 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-0e3fa327-8df7-42f0-8bbd-411a1ebd4305): no suitable block pools found to scan.  Waiting 1814399981 ms.
2020-12-03 07:19:48,636 [Thread-59] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 10:54 AM with interval of 21600000ms
2020-12-03 07:19:48,636 [Thread-105] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 10:33 AM with interval of 21600000ms
2020-12-03 07:19:48,636 [Thread-127] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:29 AM with interval of 21600000ms
2020-12-03 07:19:48,636 [Thread-171] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 9:01 AM with interval of 21600000ms
2020-12-03 07:19:48,636 [Thread-149] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 12:59 PM with interval of 21600000ms
2020-12-03 07:19:48,636 [Thread-83] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 12:15 PM with interval of 21600000ms
2020-12-03 07:19:48,636 [Thread-193] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 9:34 AM with interval of 21600000ms
2020-12-03 07:19:48,640 [Thread-215] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 9:44 AM with interval of 21600000ms
2020-12-03 07:19:48,649 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-464449197-172.17.0.6-1606979982896 (Datanode Uuid 01c12b1d-d7d2-421e-986c-c593ac806eae) service to localhost/127.0.0.1:34612 beginning handshake with NN
2020-12-03 07:19:48,649 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-464449197-172.17.0.6-1606979982896 (Datanode Uuid ba28613b-b481-4768-b4d4-cf44e7144ddf) service to localhost/127.0.0.1:34612 beginning handshake with NN
2020-12-03 07:19:48,649 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-464449197-172.17.0.6-1606979982896 (Datanode Uuid ec6135ad-ddf0-47a2-866e-c2a0a646b3ea) service to localhost/127.0.0.1:34612 beginning handshake with NN
2020-12-03 07:19:48,649 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-464449197-172.17.0.6-1606979982896 (Datanode Uuid 1840bbdd-b765-44bd-8c75-9f95ec61318d) service to localhost/127.0.0.1:34612 beginning handshake with NN
2020-12-03 07:19:48,649 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-464449197-172.17.0.6-1606979982896 (Datanode Uuid 309f7fa0-0c59-4920-a6f9-56c2485276d8) service to localhost/127.0.0.1:34612 beginning handshake with NN
2020-12-03 07:19:48,649 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-464449197-172.17.0.6-1606979982896 (Datanode Uuid edec627a-465f-4532-ab74-3f78e8a40769) service to localhost/127.0.0.1:34612 beginning handshake with NN
2020-12-03 07:19:48,649 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-464449197-172.17.0.6-1606979982896 (Datanode Uuid 2b5a1500-a27d-403f-b7e5-7837081de87c) service to localhost/127.0.0.1:34612 beginning handshake with NN
2020-12-03 07:19:48,649 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-464449197-172.17.0.6-1606979982896 (Datanode Uuid baa99858-a351-4f23-95d3-417a6368fdb3) service to localhost/127.0.0.1:34612 beginning handshake with NN
2020-12-03 07:19:48,668 [IPC Server handler 5 on default port 34612] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:43627, datanodeUuid=01c12b1d-d7d2-421e-986c-c593ac806eae, infoPort=39407, infoSecurePort=0, ipcPort=37837, storageInfo=lv=-57;cid=testClusterID;nsid=662464899;c=1606979982896) storage 01c12b1d-d7d2-421e-986c-c593ac806eae
2020-12-03 07:19:48,670 [IPC Server handler 5 on default port 34612] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:43627
2020-12-03 07:19:48,670 [IPC Server handler 5 on default port 34612] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 01c12b1d-d7d2-421e-986c-c593ac806eae (127.0.0.1:43627).
2020-12-03 07:19:48,674 [IPC Server handler 4 on default port 34612] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:40379, datanodeUuid=1840bbdd-b765-44bd-8c75-9f95ec61318d, infoPort=35523, infoSecurePort=0, ipcPort=34054, storageInfo=lv=-57;cid=testClusterID;nsid=662464899;c=1606979982896) storage 1840bbdd-b765-44bd-8c75-9f95ec61318d
2020-12-03 07:19:48,674 [IPC Server handler 4 on default port 34612] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:40379
2020-12-03 07:19:48,675 [IPC Server handler 4 on default port 34612] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 1840bbdd-b765-44bd-8c75-9f95ec61318d (127.0.0.1:40379).
2020-12-03 07:19:48,675 [IPC Server handler 2 on default port 34612] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:36395, datanodeUuid=309f7fa0-0c59-4920-a6f9-56c2485276d8, infoPort=37600, infoSecurePort=0, ipcPort=34772, storageInfo=lv=-57;cid=testClusterID;nsid=662464899;c=1606979982896) storage 309f7fa0-0c59-4920-a6f9-56c2485276d8
2020-12-03 07:19:48,675 [IPC Server handler 2 on default port 34612] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36395
2020-12-03 07:19:48,675 [IPC Server handler 2 on default port 34612] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 309f7fa0-0c59-4920-a6f9-56c2485276d8 (127.0.0.1:36395).
2020-12-03 07:19:48,676 [IPC Server handler 8 on default port 34612] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:37598, datanodeUuid=ba28613b-b481-4768-b4d4-cf44e7144ddf, infoPort=38851, infoSecurePort=0, ipcPort=46838, storageInfo=lv=-57;cid=testClusterID;nsid=662464899;c=1606979982896) storage ba28613b-b481-4768-b4d4-cf44e7144ddf
2020-12-03 07:19:48,676 [IPC Server handler 8 on default port 34612] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:37598
2020-12-03 07:19:48,676 [IPC Server handler 8 on default port 34612] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN ba28613b-b481-4768-b4d4-cf44e7144ddf (127.0.0.1:37598).
2020-12-03 07:19:48,676 [IPC Server handler 6 on default port 34612] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:41753, datanodeUuid=baa99858-a351-4f23-95d3-417a6368fdb3, infoPort=44140, infoSecurePort=0, ipcPort=33519, storageInfo=lv=-57;cid=testClusterID;nsid=662464899;c=1606979982896) storage baa99858-a351-4f23-95d3-417a6368fdb3
2020-12-03 07:19:48,677 [IPC Server handler 6 on default port 34612] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41753
2020-12-03 07:19:48,677 [IPC Server handler 6 on default port 34612] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN baa99858-a351-4f23-95d3-417a6368fdb3 (127.0.0.1:41753).
2020-12-03 07:19:48,677 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-464449197-172.17.0.6-1606979982896 (Datanode Uuid 01c12b1d-d7d2-421e-986c-c593ac806eae) service to localhost/127.0.0.1:34612 successfully registered with NN
2020-12-03 07:19:48,677 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-464449197-172.17.0.6-1606979982896 (Datanode Uuid 309f7fa0-0c59-4920-a6f9-56c2485276d8) service to localhost/127.0.0.1:34612 successfully registered with NN
2020-12-03 07:19:48,677 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-464449197-172.17.0.6-1606979982896 (Datanode Uuid ba28613b-b481-4768-b4d4-cf44e7144ddf) service to localhost/127.0.0.1:34612 successfully registered with NN
2020-12-03 07:19:48,677 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-464449197-172.17.0.6-1606979982896 (Datanode Uuid 1840bbdd-b765-44bd-8c75-9f95ec61318d) service to localhost/127.0.0.1:34612 successfully registered with NN
2020-12-03 07:19:48,678 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:34612 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:19:48,677 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:34612 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:19:48,677 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:34612 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:19:48,677 [IPC Server handler 9 on default port 34612] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:41126, datanodeUuid=2b5a1500-a27d-403f-b7e5-7837081de87c, infoPort=35859, infoSecurePort=0, ipcPort=39032, storageInfo=lv=-57;cid=testClusterID;nsid=662464899;c=1606979982896) storage 2b5a1500-a27d-403f-b7e5-7837081de87c
2020-12-03 07:19:48,678 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-464449197-172.17.0.6-1606979982896 (Datanode Uuid baa99858-a351-4f23-95d3-417a6368fdb3) service to localhost/127.0.0.1:34612 successfully registered with NN
2020-12-03 07:19:48,678 [IPC Server handler 9 on default port 34612] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41126
2020-12-03 07:19:48,678 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:34612 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:19:48,678 [IPC Server handler 9 on default port 34612] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 2b5a1500-a27d-403f-b7e5-7837081de87c (127.0.0.1:41126).
2020-12-03 07:19:48,679 [IPC Server handler 7 on default port 34612] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:41902, datanodeUuid=ec6135ad-ddf0-47a2-866e-c2a0a646b3ea, infoPort=39175, infoSecurePort=0, ipcPort=42343, storageInfo=lv=-57;cid=testClusterID;nsid=662464899;c=1606979982896) storage ec6135ad-ddf0-47a2-866e-c2a0a646b3ea
2020-12-03 07:19:48,678 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:34612 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:19:48,680 [IPC Server handler 7 on default port 34612] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41902
2020-12-03 07:19:48,680 [IPC Server handler 7 on default port 34612] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN ec6135ad-ddf0-47a2-866e-c2a0a646b3ea (127.0.0.1:41902).
2020-12-03 07:19:48,680 [IPC Server handler 0 on default port 34612] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:40120, datanodeUuid=edec627a-465f-4532-ab74-3f78e8a40769, infoPort=35198, infoSecurePort=0, ipcPort=34379, storageInfo=lv=-57;cid=testClusterID;nsid=662464899;c=1606979982896) storage edec627a-465f-4532-ab74-3f78e8a40769
2020-12-03 07:19:48,681 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-464449197-172.17.0.6-1606979982896 (Datanode Uuid 2b5a1500-a27d-403f-b7e5-7837081de87c) service to localhost/127.0.0.1:34612 successfully registered with NN
2020-12-03 07:19:48,681 [IPC Server handler 0 on default port 34612] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:40120
2020-12-03 07:19:48,681 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:34612 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:19:48,681 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-464449197-172.17.0.6-1606979982896 (Datanode Uuid ec6135ad-ddf0-47a2-866e-c2a0a646b3ea) service to localhost/127.0.0.1:34612 successfully registered with NN
2020-12-03 07:19:48,681 [IPC Server handler 0 on default port 34612] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN edec627a-465f-4532-ab74-3f78e8a40769 (127.0.0.1:40120).
2020-12-03 07:19:48,682 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:34612 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:19:48,682 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-464449197-172.17.0.6-1606979982896 (Datanode Uuid edec627a-465f-4532-ab74-3f78e8a40769) service to localhost/127.0.0.1:34612 successfully registered with NN
2020-12-03 07:19:48,683 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:34612 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:19:48,696 [IPC Server handler 1 on default port 34612] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:48,705 [IPC Server handler 3 on default port 34612] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-0b503d65-8d01-49ef-8e43-291aff1d549a for DN 127.0.0.1:41753
2020-12-03 07:19:48,707 [IPC Server handler 3 on default port 34612] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-5b6b1a9c-9c26-49bb-9bbd-60b622efa680 for DN 127.0.0.1:41753
2020-12-03 07:19:48,707 [IPC Server handler 9 on default port 34612] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-9c05f2e3-34b6-4594-b06f-9365cd2a0a2f for DN 127.0.0.1:41902
2020-12-03 07:19:48,709 [IPC Server handler 9 on default port 34612] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-cd676010-abda-483c-a6ea-b69676538fc2 for DN 127.0.0.1:41902
2020-12-03 07:19:48,709 [IPC Server handler 6 on default port 34612] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-28904309-f21d-4622-b590-65c20013b1c7 for DN 127.0.0.1:41126
2020-12-03 07:19:48,709 [IPC Server handler 6 on default port 34612] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-8d7e7ea8-c1a7-4424-9e6e-68f075bb1fe6 for DN 127.0.0.1:41126
2020-12-03 07:19:48,710 [IPC Server handler 2 on default port 34612] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-3a17eb31-b33e-4a9a-a80f-9b182d8e1248 for DN 127.0.0.1:40379
2020-12-03 07:19:48,710 [IPC Server handler 2 on default port 34612] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-a91ecbc1-38a0-4aee-a8bb-57f2ff2f9937 for DN 127.0.0.1:40379
2020-12-03 07:19:48,710 [IPC Server handler 4 on default port 34612] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-0bb00b44-1a33-4c83-8050-95766856105e for DN 127.0.0.1:37598
2020-12-03 07:19:48,710 [IPC Server handler 4 on default port 34612] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-0e3fa327-8df7-42f0-8bbd-411a1ebd4305 for DN 127.0.0.1:37598
2020-12-03 07:19:48,710 [IPC Server handler 8 on default port 34612] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-6f70985c-ac30-47d0-891a-02298a52a999 for DN 127.0.0.1:43627
2020-12-03 07:19:48,710 [IPC Server handler 8 on default port 34612] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-ca7c16c8-a7cd-40c3-9072-e5e55f35ba2f for DN 127.0.0.1:43627
2020-12-03 07:19:48,711 [Listener at localhost/34054] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2798)) - No heartbeat from DataNode: 127.0.0.1:36395
2020-12-03 07:19:48,711 [Listener at localhost/34054] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:48,711 [IPC Server handler 5 on default port 34612] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-e89d6108-2324-4b34-addb-9670aed7d37d for DN 127.0.0.1:40120
2020-12-03 07:19:48,711 [IPC Server handler 5 on default port 34612] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-3571474c-359b-4f98-94a4-8b83a1d0652c for DN 127.0.0.1:40120
2020-12-03 07:19:48,711 [IPC Server handler 7 on default port 34612] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-47ca938b-a40d-4407-b093-5825baebb00c for DN 127.0.0.1:36395
2020-12-03 07:19:48,711 [IPC Server handler 7 on default port 34612] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-9de9d331-cfd4-450a-96bf-6bed8d407bd9 for DN 127.0.0.1:36395
2020-12-03 07:19:48,748 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xb6804bcf7360fc34: Processing first storage report for DS-0e3fa327-8df7-42f0-8bbd-411a1ebd4305 from datanode ba28613b-b481-4768-b4d4-cf44e7144ddf
2020-12-03 07:19:48,750 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xb6804bcf7360fc34: from storage DS-0e3fa327-8df7-42f0-8bbd-411a1ebd4305 node DatanodeRegistration(127.0.0.1:37598, datanodeUuid=ba28613b-b481-4768-b4d4-cf44e7144ddf, infoPort=38851, infoSecurePort=0, ipcPort=46838, storageInfo=lv=-57;cid=testClusterID;nsid=662464899;c=1606979982896), blocks: 0, hasStaleStorage: true, processing time: 2 msecs, invalidatedBlocks: 0
2020-12-03 07:19:48,750 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x6e485f6f307fa5e6: Processing first storage report for DS-8d7e7ea8-c1a7-4424-9e6e-68f075bb1fe6 from datanode 2b5a1500-a27d-403f-b7e5-7837081de87c
2020-12-03 07:19:48,750 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x6e485f6f307fa5e6: from storage DS-8d7e7ea8-c1a7-4424-9e6e-68f075bb1fe6 node DatanodeRegistration(127.0.0.1:41126, datanodeUuid=2b5a1500-a27d-403f-b7e5-7837081de87c, infoPort=35859, infoSecurePort=0, ipcPort=39032, storageInfo=lv=-57;cid=testClusterID;nsid=662464899;c=1606979982896), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:19:48,750 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xd2ef2c77d655a8be: Processing first storage report for DS-9c05f2e3-34b6-4594-b06f-9365cd2a0a2f from datanode ec6135ad-ddf0-47a2-866e-c2a0a646b3ea
2020-12-03 07:19:48,750 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xd2ef2c77d655a8be: from storage DS-9c05f2e3-34b6-4594-b06f-9365cd2a0a2f node DatanodeRegistration(127.0.0.1:41902, datanodeUuid=ec6135ad-ddf0-47a2-866e-c2a0a646b3ea, infoPort=39175, infoSecurePort=0, ipcPort=42343, storageInfo=lv=-57;cid=testClusterID;nsid=662464899;c=1606979982896), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:19:48,750 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x6a261e8387929042: Processing first storage report for DS-ca7c16c8-a7cd-40c3-9072-e5e55f35ba2f from datanode 01c12b1d-d7d2-421e-986c-c593ac806eae
2020-12-03 07:19:48,750 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x6a261e8387929042: from storage DS-ca7c16c8-a7cd-40c3-9072-e5e55f35ba2f node DatanodeRegistration(127.0.0.1:43627, datanodeUuid=01c12b1d-d7d2-421e-986c-c593ac806eae, infoPort=39407, infoSecurePort=0, ipcPort=37837, storageInfo=lv=-57;cid=testClusterID;nsid=662464899;c=1606979982896), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:19:48,751 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x74f82a0c5725c7d1: Processing first storage report for DS-a91ecbc1-38a0-4aee-a8bb-57f2ff2f9937 from datanode 1840bbdd-b765-44bd-8c75-9f95ec61318d
2020-12-03 07:19:48,751 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x74f82a0c5725c7d1: from storage DS-a91ecbc1-38a0-4aee-a8bb-57f2ff2f9937 node DatanodeRegistration(127.0.0.1:40379, datanodeUuid=1840bbdd-b765-44bd-8c75-9f95ec61318d, infoPort=35523, infoSecurePort=0, ipcPort=34054, storageInfo=lv=-57;cid=testClusterID;nsid=662464899;c=1606979982896), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:19:48,751 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x3aa74a2e25d2533: Processing first storage report for DS-0b503d65-8d01-49ef-8e43-291aff1d549a from datanode baa99858-a351-4f23-95d3-417a6368fdb3
2020-12-03 07:19:48,751 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x3aa74a2e25d2533: from storage DS-0b503d65-8d01-49ef-8e43-291aff1d549a node DatanodeRegistration(127.0.0.1:41753, datanodeUuid=baa99858-a351-4f23-95d3-417a6368fdb3, infoPort=44140, infoSecurePort=0, ipcPort=33519, storageInfo=lv=-57;cid=testClusterID;nsid=662464899;c=1606979982896), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:19:48,751 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xb6804bcf7360fc34: Processing first storage report for DS-0bb00b44-1a33-4c83-8050-95766856105e from datanode ba28613b-b481-4768-b4d4-cf44e7144ddf
2020-12-03 07:19:48,751 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xb6804bcf7360fc34: from storage DS-0bb00b44-1a33-4c83-8050-95766856105e node DatanodeRegistration(127.0.0.1:37598, datanodeUuid=ba28613b-b481-4768-b4d4-cf44e7144ddf, infoPort=38851, infoSecurePort=0, ipcPort=46838, storageInfo=lv=-57;cid=testClusterID;nsid=662464899;c=1606979982896), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:19:48,751 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x6e485f6f307fa5e6: Processing first storage report for DS-28904309-f21d-4622-b590-65c20013b1c7 from datanode 2b5a1500-a27d-403f-b7e5-7837081de87c
2020-12-03 07:19:48,751 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x6e485f6f307fa5e6: from storage DS-28904309-f21d-4622-b590-65c20013b1c7 node DatanodeRegistration(127.0.0.1:41126, datanodeUuid=2b5a1500-a27d-403f-b7e5-7837081de87c, infoPort=35859, infoSecurePort=0, ipcPort=39032, storageInfo=lv=-57;cid=testClusterID;nsid=662464899;c=1606979982896), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:19:48,752 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xd2ef2c77d655a8be: Processing first storage report for DS-cd676010-abda-483c-a6ea-b69676538fc2 from datanode ec6135ad-ddf0-47a2-866e-c2a0a646b3ea
2020-12-03 07:19:48,752 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xd2ef2c77d655a8be: from storage DS-cd676010-abda-483c-a6ea-b69676538fc2 node DatanodeRegistration(127.0.0.1:41902, datanodeUuid=ec6135ad-ddf0-47a2-866e-c2a0a646b3ea, infoPort=39175, infoSecurePort=0, ipcPort=42343, storageInfo=lv=-57;cid=testClusterID;nsid=662464899;c=1606979982896), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:19:48,753 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x6a261e8387929042: Processing first storage report for DS-6f70985c-ac30-47d0-891a-02298a52a999 from datanode 01c12b1d-d7d2-421e-986c-c593ac806eae
2020-12-03 07:19:48,753 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x6a261e8387929042: from storage DS-6f70985c-ac30-47d0-891a-02298a52a999 node DatanodeRegistration(127.0.0.1:43627, datanodeUuid=01c12b1d-d7d2-421e-986c-c593ac806eae, infoPort=39407, infoSecurePort=0, ipcPort=37837, storageInfo=lv=-57;cid=testClusterID;nsid=662464899;c=1606979982896), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:19:48,753 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x74f82a0c5725c7d1: Processing first storage report for DS-3a17eb31-b33e-4a9a-a80f-9b182d8e1248 from datanode 1840bbdd-b765-44bd-8c75-9f95ec61318d
2020-12-03 07:19:48,753 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x74f82a0c5725c7d1: from storage DS-3a17eb31-b33e-4a9a-a80f-9b182d8e1248 node DatanodeRegistration(127.0.0.1:40379, datanodeUuid=1840bbdd-b765-44bd-8c75-9f95ec61318d, infoPort=35523, infoSecurePort=0, ipcPort=34054, storageInfo=lv=-57;cid=testClusterID;nsid=662464899;c=1606979982896), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:19:48,753 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x3aa74a2e25d2533: Processing first storage report for DS-5b6b1a9c-9c26-49bb-9bbd-60b622efa680 from datanode baa99858-a351-4f23-95d3-417a6368fdb3
2020-12-03 07:19:48,753 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x3aa74a2e25d2533: from storage DS-5b6b1a9c-9c26-49bb-9bbd-60b622efa680 node DatanodeRegistration(127.0.0.1:41753, datanodeUuid=baa99858-a351-4f23-95d3-417a6368fdb3, infoPort=44140, infoSecurePort=0, ipcPort=33519, storageInfo=lv=-57;cid=testClusterID;nsid=662464899;c=1606979982896), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:19:48,778 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x3aa74a2e25d2533,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 5 msec to generate and 48 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:19:48,778 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x74f82a0c5725c7d1,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 5 msec to generate and 48 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:19:48,778 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xb6804bcf7360fc34,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 5 msec to generate and 48 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:19:48,778 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xd2ef2c77d655a8be,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 5 msec to generate and 48 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:19:48,778 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x6a261e8387929042,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 5 msec to generate and 50 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:19:48,778 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x6e485f6f307fa5e6,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 48 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:19:48,778 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:48,778 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:48,778 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:48,778 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:48,778 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:48,778 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:48,816 [IPC Server handler 4 on default port 34612] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:48,819 [Listener at localhost/34054] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:19:48,825 [IPC Server handler 3 on default port 34612] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:48,827 [Listener at localhost/34054] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:19:49,238 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xa8a2bc1373afb6b9: Processing first storage report for DS-9de9d331-cfd4-450a-96bf-6bed8d407bd9 from datanode 309f7fa0-0c59-4920-a6f9-56c2485276d8
2020-12-03 07:19:49,239 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xa8a2bc1373afb6b9: from storage DS-9de9d331-cfd4-450a-96bf-6bed8d407bd9 node DatanodeRegistration(127.0.0.1:36395, datanodeUuid=309f7fa0-0c59-4920-a6f9-56c2485276d8, infoPort=37600, infoSecurePort=0, ipcPort=34772, storageInfo=lv=-57;cid=testClusterID;nsid=662464899;c=1606979982896), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:19:49,239 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xa8a2bc1373afb6b9: Processing first storage report for DS-47ca938b-a40d-4407-b093-5825baebb00c from datanode 309f7fa0-0c59-4920-a6f9-56c2485276d8
2020-12-03 07:19:49,239 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xa8a2bc1373afb6b9: from storage DS-47ca938b-a40d-4407-b093-5825baebb00c node DatanodeRegistration(127.0.0.1:36395, datanodeUuid=309f7fa0-0c59-4920-a6f9-56c2485276d8, infoPort=37600, infoSecurePort=0, ipcPort=34772, storageInfo=lv=-57;cid=testClusterID;nsid=662464899;c=1606979982896), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:19:49,240 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xa8a2bc1373afb6b9,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:19:49,240 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:49,340 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x1ca6e9c171a24888: Processing first storage report for DS-e89d6108-2324-4b34-addb-9670aed7d37d from datanode edec627a-465f-4532-ab74-3f78e8a40769
2020-12-03 07:19:49,340 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x1ca6e9c171a24888: from storage DS-e89d6108-2324-4b34-addb-9670aed7d37d node DatanodeRegistration(127.0.0.1:40120, datanodeUuid=edec627a-465f-4532-ab74-3f78e8a40769, infoPort=35198, infoSecurePort=0, ipcPort=34379, storageInfo=lv=-57;cid=testClusterID;nsid=662464899;c=1606979982896), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:19:49,340 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x1ca6e9c171a24888: Processing first storage report for DS-3571474c-359b-4f98-94a4-8b83a1d0652c from datanode edec627a-465f-4532-ab74-3f78e8a40769
2020-12-03 07:19:49,340 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x1ca6e9c171a24888: from storage DS-3571474c-359b-4f98-94a4-8b83a1d0652c node DatanodeRegistration(127.0.0.1:40120, datanodeUuid=edec627a-465f-4532-ab74-3f78e8a40769, infoPort=35198, infoSecurePort=0, ipcPort=34379, storageInfo=lv=-57;cid=testClusterID;nsid=662464899;c=1606979982896), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:19:49,341 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x1ca6e9c171a24888,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:19:49,341 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:49,733 [Listener at localhost/34054] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:19:49,734 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@74e47444] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:19:49,736 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-9c05f2e3-34b6-4594-b06f-9365cd2a0a2f) exiting.
2020-12-03 07:19:49,736 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-cd676010-abda-483c-a6ea-b69676538fc2) exiting.
2020-12-03 07:19:49,840 [Listener at localhost/34054] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@7813cb11{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:19:49,847 [Listener at localhost/34054] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@bcec031{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:19:49,847 [Listener at localhost/34054] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2e029d61{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:19:49,848 [Listener at localhost/34054] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1643d68f{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:19:49,851 [Listener at localhost/34054] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 42343
2020-12-03 07:19:49,857 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:19:49,859 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:19:49,861 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:19:49,862 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-464449197-172.17.0.6-1606979982896 (Datanode Uuid ec6135ad-ddf0-47a2-866e-c2a0a646b3ea) service to localhost/127.0.0.1:34612
2020-12-03 07:19:49,863 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-464449197-172.17.0.6-1606979982896 (Datanode Uuid ec6135ad-ddf0-47a2-866e-c2a0a646b3ea)
2020-12-03 07:19:49,863 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:49,864 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-464449197-172.17.0.6-1606979982896] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:19:49,865 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-464449197-172.17.0.6-1606979982896] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:19:49,872 [Listener at localhost/34054] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:19:49,872 [Listener at localhost/34054] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:19:49,873 [Listener at localhost/34054] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:19:49,873 [Listener at localhost/34054] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:19:49,880 [Listener at localhost/34054] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:19:49,882 [Listener at localhost/34054] INFO  hdfs.StateChange (DatanodeManager.java:removeDeadDatanode(754)) - BLOCK* removeDeadDatanode: lost heartbeat from 127.0.0.1:41902, removeBlocksFromBlockMap true
2020-12-03 07:19:49,884 [Listener at localhost/34054] INFO  net.NetworkTopology (NetworkTopology.java:remove(219)) - Removing a node: /default-rack/127.0.0.1:41902
2020-12-03 07:19:49,885 [Listener at localhost/34054] INFO  blockmanagement.HeartbeatManager (HeartbeatManager.java:startDecommission(261)) - Dead node 127.0.0.1:41902 is decommissioned immediately.
2020-12-03 07:19:49,885 [Listener at localhost/34054] INFO  blockmanagement.HeartbeatManager (HeartbeatManager.java:stopDecommission(304)) - Stopping decommissioning of dead node 127.0.0.1:41902
2020-12-03 07:19:49,886 [Listener at localhost/34054] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:19:49,886 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@327120c8] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:19:49,888 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-0e3fa327-8df7-42f0-8bbd-411a1ebd4305) exiting.
2020-12-03 07:19:49,888 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-0bb00b44-1a33-4c83-8050-95766856105e) exiting.
2020-12-03 07:19:49,909 [Listener at localhost/34054] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@2449cff7{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:19:49,910 [Listener at localhost/34054] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@42a9a63e{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:19:49,911 [Listener at localhost/34054] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6d511b5f{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:19:49,911 [Listener at localhost/34054] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@50305a{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:19:49,912 [Listener at localhost/34054] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 46838
2020-12-03 07:19:49,918 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:19:49,919 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:19:49,923 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:19:49,931 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-464449197-172.17.0.6-1606979982896 (Datanode Uuid ba28613b-b481-4768-b4d4-cf44e7144ddf) service to localhost/127.0.0.1:34612
2020-12-03 07:19:49,931 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-464449197-172.17.0.6-1606979982896 (Datanode Uuid ba28613b-b481-4768-b4d4-cf44e7144ddf)
2020-12-03 07:19:49,931 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:49,932 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-464449197-172.17.0.6-1606979982896] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:19:49,932 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-464449197-172.17.0.6-1606979982896] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:19:49,936 [Listener at localhost/34054] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:19:49,937 [Listener at localhost/34054] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:19:49,938 [Listener at localhost/34054] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:19:49,938 [Listener at localhost/34054] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:19:49,940 [Listener at localhost/34054] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:19:49,940 [Listener at localhost/34054] INFO  hdfs.StateChange (DatanodeManager.java:removeDeadDatanode(754)) - BLOCK* removeDeadDatanode: lost heartbeat from 127.0.0.1:37598, removeBlocksFromBlockMap true
2020-12-03 07:19:49,941 [Listener at localhost/34054] INFO  net.NetworkTopology (NetworkTopology.java:remove(219)) - Removing a node: /default-rack/127.0.0.1:37598
2020-12-03 07:19:49,941 [Listener at localhost/34054] INFO  blockmanagement.HeartbeatManager (HeartbeatManager.java:startMaintenance(272)) - Dead node 127.0.0.1:37598 is put in maintenance state immediately.
2020-12-03 07:19:49,941 [Listener at localhost/34054] INFO  blockmanagement.HeartbeatManager (HeartbeatManager.java:stopMaintenance(292)) - Stopping maintenance of dead node 127.0.0.1:37598
2020-12-03 07:19:49,942 [Listener at localhost/34054] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:19:49,942 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@2db2cd5] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:19:49,946 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-6f70985c-ac30-47d0-891a-02298a52a999) exiting.
2020-12-03 07:19:49,946 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-ca7c16c8-a7cd-40c3-9072-e5e55f35ba2f) exiting.
2020-12-03 07:19:49,968 [Listener at localhost/34054] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1734f68{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:19:49,969 [Listener at localhost/34054] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@77b7ffa4{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:19:49,969 [Listener at localhost/34054] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@66238be2{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:19:49,970 [Listener at localhost/34054] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7249dadf{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:19:49,971 [Listener at localhost/34054] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 37837
2020-12-03 07:19:49,973 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:19:49,974 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:19:49,975 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:19:49,976 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-464449197-172.17.0.6-1606979982896 (Datanode Uuid 01c12b1d-d7d2-421e-986c-c593ac806eae) service to localhost/127.0.0.1:34612
2020-12-03 07:19:49,976 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-464449197-172.17.0.6-1606979982896 (Datanode Uuid 01c12b1d-d7d2-421e-986c-c593ac806eae)
2020-12-03 07:19:49,976 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:49,977 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-464449197-172.17.0.6-1606979982896] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:19:49,980 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-464449197-172.17.0.6-1606979982896] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:19:49,984 [Listener at localhost/34054] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:19:49,984 [Listener at localhost/34054] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:19:49,985 [Listener at localhost/34054] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:19:49,986 [Listener at localhost/34054] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:19:49,989 [Listener at localhost/34054] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:19:49,989 [Listener at localhost/34054] INFO  hdfs.StateChange (DatanodeManager.java:removeDeadDatanode(754)) - BLOCK* removeDeadDatanode: lost heartbeat from 127.0.0.1:43627, removeBlocksFromBlockMap true
2020-12-03 07:19:49,990 [Listener at localhost/34054] INFO  net.NetworkTopology (NetworkTopology.java:remove(219)) - Removing a node: /default-rack/127.0.0.1:43627
2020-12-03 07:19:49,990 [Listener at localhost/34054] INFO  blockmanagement.HeartbeatManager (HeartbeatManager.java:startDecommission(261)) - Dead node 127.0.0.1:43627 is decommissioned immediately.
2020-12-03 07:19:49,990 [Listener at localhost/34054] INFO  blockmanagement.HeartbeatManager (HeartbeatManager.java:stopDecommission(304)) - Stopping decommissioning of dead node 127.0.0.1:43627
2020-12-03 07:19:49,990 [Listener at localhost/34054] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:19:49,992 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@7db0565c] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:19:49,992 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-28904309-f21d-4622-b590-65c20013b1c7) exiting.
2020-12-03 07:19:49,999 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-8d7e7ea8-c1a7-4424-9e6e-68f075bb1fe6) exiting.
2020-12-03 07:19:50,024 [Listener at localhost/34054] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@503d56b5{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:19:50,030 [Listener at localhost/34054] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@72bca894{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:19:50,030 [Listener at localhost/34054] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6cc0bcf6{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:19:50,031 [Listener at localhost/34054] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@ec2bf82{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:19:50,032 [Listener at localhost/34054] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 39032
2020-12-03 07:19:50,037 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:19:50,037 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:19:50,039 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:19:50,042 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-464449197-172.17.0.6-1606979982896 (Datanode Uuid 2b5a1500-a27d-403f-b7e5-7837081de87c) service to localhost/127.0.0.1:34612
2020-12-03 07:19:50,042 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-464449197-172.17.0.6-1606979982896 (Datanode Uuid 2b5a1500-a27d-403f-b7e5-7837081de87c)
2020-12-03 07:19:50,042 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:50,043 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-464449197-172.17.0.6-1606979982896] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:19:50,043 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-464449197-172.17.0.6-1606979982896] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:19:50,053 [Listener at localhost/34054] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:19:50,054 [Listener at localhost/34054] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:19:50,056 [Listener at localhost/34054] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:19:50,056 [Listener at localhost/34054] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:19:50,061 [Listener at localhost/34054] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:19:50,062 [Listener at localhost/34054] INFO  hdfs.StateChange (DatanodeManager.java:removeDeadDatanode(754)) - BLOCK* removeDeadDatanode: lost heartbeat from 127.0.0.1:41126, removeBlocksFromBlockMap true
2020-12-03 07:19:50,062 [Listener at localhost/34054] INFO  net.NetworkTopology (NetworkTopology.java:remove(219)) - Removing a node: /default-rack/127.0.0.1:41126
2020-12-03 07:19:50,063 [Listener at localhost/34054] INFO  blockmanagement.HeartbeatManager (HeartbeatManager.java:startMaintenance(272)) - Dead node 127.0.0.1:41126 is put in maintenance state immediately.
2020-12-03 07:19:50,063 [Listener at localhost/34054] INFO  blockmanagement.HeartbeatManager (HeartbeatManager.java:stopMaintenance(292)) - Stopping maintenance of dead node 127.0.0.1:41126
2020-12-03 07:19:50,063 [Listener at localhost/34054] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopDataNode(2331)) - MiniDFSCluster Stopping DataNode 127.0.0.1:40379 from a total of 8 datanodes.
2020-12-03 07:19:50,064 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@66b72664] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:19:50,068 [Listener at localhost/34054] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:19:50,071 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-3a17eb31-b33e-4a9a-a80f-9b182d8e1248) exiting.
2020-12-03 07:19:50,075 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-a91ecbc1-38a0-4aee-a8bb-57f2ff2f9937) exiting.
2020-12-03 07:19:50,096 [Listener at localhost/34054] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@51bde877{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:19:50,097 [Listener at localhost/34054] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@60b85ba1{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:19:50,098 [Listener at localhost/34054] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1c05a54d{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:19:50,099 [Listener at localhost/34054] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@74a9c4b0{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:19:50,104 [Listener at localhost/34054] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 34054
2020-12-03 07:19:50,110 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:19:50,111 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:19:50,111 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:19:50,111 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-464449197-172.17.0.6-1606979982896 (Datanode Uuid 1840bbdd-b765-44bd-8c75-9f95ec61318d) service to localhost/127.0.0.1:34612
2020-12-03 07:19:50,111 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-464449197-172.17.0.6-1606979982896 (Datanode Uuid 1840bbdd-b765-44bd-8c75-9f95ec61318d)
2020-12-03 07:19:50,120 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:50,121 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-464449197-172.17.0.6-1606979982896] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:19:50,121 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-464449197-172.17.0.6-1606979982896] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:19:50,137 [Listener at localhost/34054] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:19:50,137 [Listener at localhost/34054] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:19:50,140 [Listener at localhost/34054] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:19:50,140 [Listener at localhost/34054] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:19:50,144 [Listener at localhost/34054] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:19:50,146 [Listener at localhost/34054] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:19:50,146 [Listener at localhost/34054] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:19:50,147 [Listener at localhost/34054] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:19:50,150 [Listener at localhost/34054] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:50,150 [Listener at localhost/34054] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:19:50,150 [Listener at localhost/34054] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:19:50,151 [Listener at localhost/34054] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:50,151 [Listener at localhost/34054] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:19:50,152 [Listener at localhost/34054] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:39367
2020-12-03 07:19:50,152 [Listener at localhost/34054] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:19:50,152 [Listener at localhost/34054] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:19:50,153 [Listener at localhost/34054] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:50,155 [Listener at localhost/34054] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:19:50,155 [Listener at localhost/34054] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:19:50,156 [Listener at localhost/34054] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:50,157 [Listener at localhost/34054] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:19:50,158 [Listener at localhost/34054] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:19:50,158 [Listener at localhost/34054] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:19:50,158 [Listener at localhost/34054] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:19:50,159 [Listener at localhost/34054] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 35264
2020-12-03 07:19:50,160 [Listener at localhost/34054] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:19:50,161 [Listener at localhost/34054] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7dd00705{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:19:50,162 [Listener at localhost/34054] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@d176a31{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:19:50,168 [Listener at localhost/34054] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@27b71f50{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:19:50,169 [Listener at localhost/34054] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@383790cf{HTTP/1.1,[http/1.1]}{localhost:35264}
2020-12-03 07:19:50,172 [Listener at localhost/34054] INFO  server.Server (Server.java:doStart(419)) - Started @9905ms
2020-12-03 07:19:50,199 [Listener at localhost/34054] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:46306
2020-12-03 07:19:50,200 [Listener at localhost/34054] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:19:50,200 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@131fcb6f] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:19:50,200 [Listener at localhost/34054] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:19:50,201 [Listener at localhost/34054] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:19:50,201 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:19:50,208 [Listener at localhost/41846] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:41846
2020-12-03 07:19:50,244 [Listener at localhost/41846] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:19:50,245 [Listener at localhost/41846] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:19:50,245 [Thread-328] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34612 starting to offer service
2020-12-03 07:19:50,279 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:19:50,279 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:19:50,280 [Listener at localhost/41846] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:restartDataNodes(2519)) - Restarted DataNode 7
2020-12-03 07:19:50,281 [Listener at localhost/41846] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopDataNode(2331)) - MiniDFSCluster Stopping DataNode 127.0.0.1:41753 from a total of 8 datanodes.
2020-12-03 07:19:50,281 [Listener at localhost/41846] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:19:50,281 [Thread-328] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34612
2020-12-03 07:19:50,282 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@70f43b45] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:19:50,288 [Thread-328] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:19:50,292 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-5b6b1a9c-9c26-49bb-9bbd-60b622efa680) exiting.
2020-12-03 07:19:50,288 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-0b503d65-8d01-49ef-8e43-291aff1d549a) exiting.
2020-12-03 07:19:50,319 [Listener at localhost/41846] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@61a5b4ae{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:19:50,320 [Listener at localhost/41846] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@3a71c100{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:19:50,320 [Listener at localhost/41846] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@26f143ed{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:19:50,321 [Listener at localhost/41846] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3e792ce3{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:19:50,323 [Listener at localhost/41846] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 33519
2020-12-03 07:19:50,330 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:19:50,330 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:19:50,330 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-464449197-172.17.0.6-1606979982896 (Datanode Uuid baa99858-a351-4f23-95d3-417a6368fdb3) service to localhost/127.0.0.1:34612
2020-12-03 07:19:50,330 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:19:50,334 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-464449197-172.17.0.6-1606979982896 (Datanode Uuid baa99858-a351-4f23-95d3-417a6368fdb3)
2020-12-03 07:19:50,334 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:50,335 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-464449197-172.17.0.6-1606979982896] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:19:50,338 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-464449197-172.17.0.6-1606979982896] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:19:50,347 [Listener at localhost/41846] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:19:50,347 [Listener at localhost/41846] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:19:50,351 [Listener at localhost/41846] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:19:50,351 [Listener at localhost/41846] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:19:50,356 [Listener at localhost/41846] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:19:50,358 [Listener at localhost/41846] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:19:50,358 [Listener at localhost/41846] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:19:50,360 [Thread-328] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/in_use.lock acquired by nodename 906@9ece31fe74eb
2020-12-03 07:19:50,360 [Listener at localhost/41846] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:19:50,365 [Listener at localhost/41846] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:50,365 [Listener at localhost/41846] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:19:50,365 [Listener at localhost/41846] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:19:50,366 [Listener at localhost/41846] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:50,366 [Listener at localhost/41846] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:19:50,367 [Listener at localhost/41846] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:42420
2020-12-03 07:19:50,367 [Listener at localhost/41846] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:19:50,368 [Listener at localhost/41846] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:19:50,369 [Listener at localhost/41846] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:50,371 [Listener at localhost/41846] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:19:50,372 [Listener at localhost/41846] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:19:50,372 [Listener at localhost/41846] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:50,374 [Listener at localhost/41846] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:19:50,374 [Listener at localhost/41846] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:19:50,374 [Listener at localhost/41846] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:19:50,374 [Listener at localhost/41846] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:19:50,375 [Listener at localhost/41846] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 41443
2020-12-03 07:19:50,375 [Listener at localhost/41846] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:19:50,377 [Listener at localhost/41846] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@55b8dbda{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:19:50,378 [Listener at localhost/41846] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3a022576{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:19:50,385 [Listener at localhost/41846] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@55cff952{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:19:50,389 [Listener at localhost/41846] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@660591fb{HTTP/1.1,[http/1.1]}{localhost:41443}
2020-12-03 07:19:50,390 [Listener at localhost/41846] INFO  server.Server (Server.java:doStart(419)) - Started @10123ms
2020-12-03 07:19:50,414 [Listener at localhost/41846] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:41829
2020-12-03 07:19:50,415 [Listener at localhost/41846] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:19:50,415 [Listener at localhost/41846] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:19:50,415 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@8c46918] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:19:50,416 [Listener at localhost/41846] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:19:50,417 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:19:50,424 [Listener at localhost/38349] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:38349
2020-12-03 07:19:50,427 [Thread-328] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/in_use.lock acquired by nodename 906@9ece31fe74eb
2020-12-03 07:19:50,466 [Listener at localhost/38349] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:19:50,467 [Listener at localhost/38349] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:19:50,468 [Thread-350] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34612 starting to offer service
2020-12-03 07:19:50,476 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:19:50,477 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:19:50,504 [Listener at localhost/38349] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:restartDataNodes(2519)) - Restarted DataNode 6
2020-12-03 07:19:50,504 [Listener at localhost/38349] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopDataNode(2331)) - MiniDFSCluster Stopping DataNode 127.0.0.1:40120 from a total of 8 datanodes.
2020-12-03 07:19:50,505 [Listener at localhost/38349] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:19:50,505 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@33c2bd] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:19:50,539 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-3571474c-359b-4f98-94a4-8b83a1d0652c) exiting.
2020-12-03 07:19:50,539 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-e89d6108-2324-4b34-addb-9670aed7d37d) exiting.
2020-12-03 07:19:50,540 [Thread-350] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34612
2020-12-03 07:19:50,544 [Thread-350] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:19:50,553 [Thread-328] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:50,553 [Thread-328] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:50,568 [Listener at localhost/38349] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1bdaa23d{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:19:50,569 [Listener at localhost/38349] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@79f227a9{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:19:50,569 [Listener at localhost/38349] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1e392345{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:19:50,570 [Listener at localhost/38349] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6f0628de{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:19:50,572 [Listener at localhost/38349] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 34379
2020-12-03 07:19:50,572 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:19:50,578 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:19:50,578 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:19:50,578 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-464449197-172.17.0.6-1606979982896 (Datanode Uuid edec627a-465f-4532-ab74-3f78e8a40769) service to localhost/127.0.0.1:34612
2020-12-03 07:19:50,579 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-464449197-172.17.0.6-1606979982896 (Datanode Uuid edec627a-465f-4532-ab74-3f78e8a40769)
2020-12-03 07:19:50,579 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:50,579 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-464449197-172.17.0.6-1606979982896] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:19:50,579 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-464449197-172.17.0.6-1606979982896] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:19:50,590 [Thread-350] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/in_use.lock acquired by nodename 906@9ece31fe74eb
2020-12-03 07:19:50,596 [Listener at localhost/38349] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:19:50,597 [Listener at localhost/38349] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:19:50,601 [Listener at localhost/38349] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:19:50,601 [Listener at localhost/38349] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:19:50,607 [Listener at localhost/38349] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:19:50,609 [Listener at localhost/38349] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:19:50,609 [Listener at localhost/38349] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:19:50,610 [Listener at localhost/38349] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:19:50,613 [Listener at localhost/38349] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:50,613 [Listener at localhost/38349] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:19:50,614 [Listener at localhost/38349] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:19:50,614 [Listener at localhost/38349] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:50,614 [Listener at localhost/38349] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:19:50,615 [Listener at localhost/38349] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:35235
2020-12-03 07:19:50,615 [Listener at localhost/38349] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:19:50,615 [Listener at localhost/38349] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:19:50,616 [Listener at localhost/38349] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:50,618 [Listener at localhost/38349] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:19:50,618 [Listener at localhost/38349] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:19:50,619 [Listener at localhost/38349] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:50,621 [Listener at localhost/38349] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:19:50,622 [Listener at localhost/38349] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:19:50,622 [Listener at localhost/38349] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:19:50,623 [Listener at localhost/38349] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:19:50,624 [Listener at localhost/38349] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 35555
2020-12-03 07:19:50,624 [Listener at localhost/38349] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:19:50,626 [Listener at localhost/38349] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5e39850{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:19:50,627 [Listener at localhost/38349] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@398474a2{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:19:50,633 [Listener at localhost/38349] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@41c204a0{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:19:50,638 [Listener at localhost/38349] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@64138b0c{HTTP/1.1,[http/1.1]}{localhost:35555}
2020-12-03 07:19:50,638 [Listener at localhost/38349] INFO  server.Server (Server.java:doStart(419)) - Started @10371ms
2020-12-03 07:19:50,641 [Thread-328] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:50,642 [Thread-328] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:50,663 [Listener at localhost/38349] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:45934
2020-12-03 07:19:50,663 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@22d9c961] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:19:50,663 [Listener at localhost/38349] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:19:50,664 [Listener at localhost/38349] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:19:50,664 [Listener at localhost/38349] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:19:50,665 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:19:50,673 [Listener at localhost/43944] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:43944
2020-12-03 07:19:50,709 [Thread-328] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=662464899;bpid=BP-464449197-172.17.0.6-1606979982896;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=662464899;c=1606979982896;bpid=BP-464449197-172.17.0.6-1606979982896;dnuuid=1840bbdd-b765-44bd-8c75-9f95ec61318d
2020-12-03 07:19:50,718 [Thread-328] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-3a17eb31-b33e-4a9a-a80f-9b182d8e1248
2020-12-03 07:19:50,723 [Thread-328] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, StorageType: DISK
2020-12-03 07:19:50,725 [Listener at localhost/43944] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:19:50,726 [Listener at localhost/43944] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:19:50,726 [Thread-328] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-a91ecbc1-38a0-4aee-a8bb-57f2ff2f9937
2020-12-03 07:19:50,727 [Thread-328] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, StorageType: DISK
2020-12-03 07:19:50,727 [Thread-374] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34612 starting to offer service
2020-12-03 07:19:50,728 [Thread-328] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:19:50,738 [Thread-350] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/in_use.lock acquired by nodename 906@9ece31fe74eb
2020-12-03 07:19:50,742 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:19:50,742 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:19:50,744 [Thread-328] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:19:50,755 [Listener at localhost/43944] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:restartDataNodes(2519)) - Restarted DataNode 5
2020-12-03 07:19:50,755 [Listener at localhost/43944] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopDataNode(2331)) - MiniDFSCluster Stopping DataNode 127.0.0.1:36395 from a total of 8 datanodes.
2020-12-03 07:19:50,756 [Thread-374] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34612
2020-12-03 07:19:50,756 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@3e2fc448] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:19:50,756 [Listener at localhost/43944] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:19:50,762 [Thread-328] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:19:50,761 [Thread-374] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:19:50,768 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-47ca938b-a40d-4407-b093-5825baebb00c) exiting.
2020-12-03 07:19:50,768 [Thread-328] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:19:50,768 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-9de9d331-cfd4-450a-96bf-6bed8d407bd9) exiting.
2020-12-03 07:19:50,768 [Thread-328] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:19:50,793 [Thread-328] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:50,794 [Thread-386] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16...
2020-12-03 07:19:50,794 [Thread-385] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15...
2020-12-03 07:19:50,797 [Thread-385] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-464449197-172.17.0.6-1606979982896/current: 24576
2020-12-03 07:19:50,801 [Thread-386] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-464449197-172.17.0.6-1606979982896/current: 24576
2020-12-03 07:19:50,804 [Thread-350] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:50,804 [Thread-350] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:50,810 [Thread-386] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-464449197-172.17.0.6-1606979982896 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16: 17ms
2020-12-03 07:19:50,811 [Thread-385] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-464449197-172.17.0.6-1606979982896 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15: 17ms
2020-12-03 07:19:50,819 [Thread-328] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-464449197-172.17.0.6-1606979982896: 26ms
2020-12-03 07:19:50,824 [Thread-387] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15...
2020-12-03 07:19:50,824 [Thread-387] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-464449197-172.17.0.6-1606979982896/current/replicas doesn't exist 
2020-12-03 07:19:50,824 [Thread-388] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16...
2020-12-03 07:19:50,824 [Thread-388] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-464449197-172.17.0.6-1606979982896/current/replicas doesn't exist 
2020-12-03 07:19:50,824 [Thread-387] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15: 1ms
2020-12-03 07:19:50,825 [Thread-388] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16: 1ms
2020-12-03 07:19:50,825 [Thread-328] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-464449197-172.17.0.6-1606979982896: 6ms
2020-12-03 07:19:50,832 [Listener at localhost/43944] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@255990cc{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:19:50,833 [Listener at localhost/43944] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@51c929ae{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:19:50,834 [Listener at localhost/43944] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@58a55449{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:19:50,834 [Listener at localhost/43944] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7048f722{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:19:50,836 [Listener at localhost/43944] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 34772
2020-12-03 07:19:50,845 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:19:50,850 [Thread-374] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/in_use.lock acquired by nodename 906@9ece31fe74eb
2020-12-03 07:19:50,851 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:19:50,852 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:19:50,852 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-3a17eb31-b33e-4a9a-a80f-9b182d8e1248): no suitable block pools found to scan.  Waiting 1814397751 ms.
2020-12-03 07:19:50,852 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-464449197-172.17.0.6-1606979982896 (Datanode Uuid 309f7fa0-0c59-4920-a6f9-56c2485276d8) service to localhost/127.0.0.1:34612
2020-12-03 07:19:50,852 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-a91ecbc1-38a0-4aee-a8bb-57f2ff2f9937): no suitable block pools found to scan.  Waiting 1814397751 ms.
2020-12-03 07:19:50,852 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-464449197-172.17.0.6-1606979982896 (Datanode Uuid 309f7fa0-0c59-4920-a6f9-56c2485276d8)
2020-12-03 07:19:50,852 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:50,853 [Thread-328] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 12:55 PM with interval of 21600000ms
2020-12-03 07:19:50,853 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-464449197-172.17.0.6-1606979982896] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:19:50,860 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-464449197-172.17.0.6-1606979982896 (Datanode Uuid 1840bbdd-b765-44bd-8c75-9f95ec61318d) service to localhost/127.0.0.1:34612 beginning handshake with NN
2020-12-03 07:19:50,860 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-464449197-172.17.0.6-1606979982896] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:19:50,887 [Listener at localhost/43944] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:19:50,887 [Listener at localhost/43944] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:19:50,887 [IPC Server handler 5 on default port 34612] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:39367, datanodeUuid=1840bbdd-b765-44bd-8c75-9f95ec61318d, infoPort=46306, infoSecurePort=0, ipcPort=41846, storageInfo=lv=-57;cid=testClusterID;nsid=662464899;c=1606979982896) storage 1840bbdd-b765-44bd-8c75-9f95ec61318d
2020-12-03 07:19:50,892 [Listener at localhost/43944] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:19:50,892 [Listener at localhost/43944] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:19:50,892 [IPC Server handler 5 on default port 34612] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1078)) - BLOCK* registerDatanode: 127.0.0.1:40379 is replaced by DatanodeRegistration(127.0.0.1:39367, datanodeUuid=1840bbdd-b765-44bd-8c75-9f95ec61318d, infoPort=46306, infoSecurePort=0, ipcPort=41846, storageInfo=lv=-57;cid=testClusterID;nsid=662464899;c=1606979982896) with the same storageID 1840bbdd-b765-44bd-8c75-9f95ec61318d
2020-12-03 07:19:50,904 [Listener at localhost/43944] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:19:50,906 [Listener at localhost/43944] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:19:50,906 [Listener at localhost/43944] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:19:50,908 [Listener at localhost/43944] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:19:50,908 [IPC Server handler 5 on default port 34612] INFO  net.NetworkTopology (NetworkTopology.java:remove(219)) - Removing a node: /default-rack/127.0.0.1:40379
2020-12-03 07:19:50,917 [Listener at localhost/43944] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:50,918 [Listener at localhost/43944] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:19:50,918 [IPC Server handler 5 on default port 34612] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:39367
2020-12-03 07:19:50,918 [Listener at localhost/43944] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:19:50,918 [Listener at localhost/43944] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:50,919 [Listener at localhost/43944] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:19:50,919 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-464449197-172.17.0.6-1606979982896 (Datanode Uuid 1840bbdd-b765-44bd-8c75-9f95ec61318d) service to localhost/127.0.0.1:34612 successfully registered with NN
2020-12-03 07:19:50,919 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:34612 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:19:50,919 [Listener at localhost/43944] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:42173
2020-12-03 07:19:50,920 [Listener at localhost/43944] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:19:50,920 [Listener at localhost/43944] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:19:50,969 [Listener at localhost/43944] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:50,972 [Listener at localhost/43944] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:19:50,972 [Listener at localhost/43944] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:19:50,973 [Listener at localhost/43944] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:50,974 [Thread-374] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/in_use.lock acquired by nodename 906@9ece31fe74eb
2020-12-03 07:19:50,976 [Listener at localhost/43944] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:19:50,976 [Listener at localhost/43944] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:19:50,977 [Listener at localhost/43944] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:19:50,977 [Listener at localhost/43944] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:19:50,978 [Listener at localhost/43944] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 40580
2020-12-03 07:19:50,978 [Listener at localhost/43944] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:19:50,980 [Listener at localhost/43944] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7d755813{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:19:50,981 [Listener at localhost/43944] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@63da207f{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:19:50,983 [Thread-350] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:50,983 [Thread-350] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:51,005 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xe5826b4fa97fda17: Processing first storage report for DS-a91ecbc1-38a0-4aee-a8bb-57f2ff2f9937 from datanode 1840bbdd-b765-44bd-8c75-9f95ec61318d
2020-12-03 07:19:51,005 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xe5826b4fa97fda17: from storage DS-a91ecbc1-38a0-4aee-a8bb-57f2ff2f9937 node DatanodeRegistration(127.0.0.1:39367, datanodeUuid=1840bbdd-b765-44bd-8c75-9f95ec61318d, infoPort=46306, infoSecurePort=0, ipcPort=41846, storageInfo=lv=-57;cid=testClusterID;nsid=662464899;c=1606979982896), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:19:51,006 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xe5826b4fa97fda17: Processing first storage report for DS-3a17eb31-b33e-4a9a-a80f-9b182d8e1248 from datanode 1840bbdd-b765-44bd-8c75-9f95ec61318d
2020-12-03 07:19:51,006 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xe5826b4fa97fda17: from storage DS-3a17eb31-b33e-4a9a-a80f-9b182d8e1248 node DatanodeRegistration(127.0.0.1:39367, datanodeUuid=1840bbdd-b765-44bd-8c75-9f95ec61318d, infoPort=46306, infoSecurePort=0, ipcPort=41846, storageInfo=lv=-57;cid=testClusterID;nsid=662464899;c=1606979982896), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:19:51,012 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xe5826b4fa97fda17,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 4 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:19:51,012 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:51,028 [Listener at localhost/43944] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@30506c0d{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:19:51,029 [Listener at localhost/43944] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1dcca8d3{HTTP/1.1,[http/1.1]}{localhost:40580}
2020-12-03 07:19:51,035 [Listener at localhost/43944] INFO  server.Server (Server.java:doStart(419)) - Started @10768ms
2020-12-03 07:19:51,050 [Thread-350] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=662464899;bpid=BP-464449197-172.17.0.6-1606979982896;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=662464899;c=1606979982896;bpid=BP-464449197-172.17.0.6-1606979982896;dnuuid=baa99858-a351-4f23-95d3-417a6368fdb3
2020-12-03 07:19:51,051 [Thread-374] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:51,064 [Thread-374] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:51,066 [Thread-350] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-0b503d65-8d01-49ef-8e43-291aff1d549a
2020-12-03 07:19:51,075 [Thread-350] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, StorageType: DISK
2020-12-03 07:19:51,085 [Listener at localhost/43944] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:35777
2020-12-03 07:19:51,085 [Thread-350] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-5b6b1a9c-9c26-49bb-9bbd-60b622efa680
2020-12-03 07:19:51,126 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@52a70627] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:19:51,126 [Listener at localhost/43944] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:19:51,126 [Listener at localhost/43944] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:19:51,126 [Thread-350] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, StorageType: DISK
2020-12-03 07:19:51,127 [Listener at localhost/43944] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:19:51,127 [Thread-350] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:19:51,127 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:19:51,134 [Thread-350] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:19:51,135 [Thread-350] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:19:51,135 [Thread-350] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:19:51,135 [Thread-350] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:19:51,139 [Thread-350] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:51,139 [Thread-402] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13...
2020-12-03 07:19:51,140 [Listener at localhost/42345] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:42345
2020-12-03 07:19:51,141 [Thread-404] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14...
2020-12-03 07:19:51,143 [Thread-374] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:51,143 [Thread-402] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-464449197-172.17.0.6-1606979982896/current: 24576
2020-12-03 07:19:51,143 [Thread-404] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-464449197-172.17.0.6-1606979982896/current: 24576
2020-12-03 07:19:51,143 [Thread-374] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:51,201 [Thread-374] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=662464899;bpid=BP-464449197-172.17.0.6-1606979982896;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=662464899;c=1606979982896;bpid=BP-464449197-172.17.0.6-1606979982896;dnuuid=edec627a-465f-4532-ab74-3f78e8a40769
2020-12-03 07:19:51,214 [Thread-404] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-464449197-172.17.0.6-1606979982896 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14: 72ms
2020-12-03 07:19:51,219 [Thread-402] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-464449197-172.17.0.6-1606979982896 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13: 79ms
2020-12-03 07:19:51,249 [Thread-350] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-464449197-172.17.0.6-1606979982896: 109ms
2020-12-03 07:19:51,254 [Thread-374] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-e89d6108-2324-4b34-addb-9670aed7d37d
2020-12-03 07:19:51,254 [Thread-374] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, StorageType: DISK
2020-12-03 07:19:51,259 [Thread-407] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14...
2020-12-03 07:19:51,260 [Thread-407] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-464449197-172.17.0.6-1606979982896/current/replicas doesn't exist 
2020-12-03 07:19:51,260 [Thread-407] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14: 1ms
2020-12-03 07:19:51,254 [Thread-406] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13...
2020-12-03 07:19:51,281 [Thread-406] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-464449197-172.17.0.6-1606979982896/current/replicas doesn't exist 
2020-12-03 07:19:51,331 [Thread-406] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13: 49ms
2020-12-03 07:19:51,331 [Thread-350] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-464449197-172.17.0.6-1606979982896: 83ms
2020-12-03 07:19:51,332 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-5b6b1a9c-9c26-49bb-9bbd-60b622efa680): no suitable block pools found to scan.  Waiting 1814397278 ms.
2020-12-03 07:19:51,333 [Thread-350] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:21 AM with interval of 21600000ms
2020-12-03 07:19:51,339 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-464449197-172.17.0.6-1606979982896 (Datanode Uuid baa99858-a351-4f23-95d3-417a6368fdb3) service to localhost/127.0.0.1:34612 beginning handshake with NN
2020-12-03 07:19:51,341 [IPC Server handler 1 on default port 34612] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:42420, datanodeUuid=baa99858-a351-4f23-95d3-417a6368fdb3, infoPort=41829, infoSecurePort=0, ipcPort=38349, storageInfo=lv=-57;cid=testClusterID;nsid=662464899;c=1606979982896) storage baa99858-a351-4f23-95d3-417a6368fdb3
2020-12-03 07:19:51,341 [IPC Server handler 1 on default port 34612] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1078)) - BLOCK* registerDatanode: 127.0.0.1:41753 is replaced by DatanodeRegistration(127.0.0.1:42420, datanodeUuid=baa99858-a351-4f23-95d3-417a6368fdb3, infoPort=41829, infoSecurePort=0, ipcPort=38349, storageInfo=lv=-57;cid=testClusterID;nsid=662464899;c=1606979982896) with the same storageID baa99858-a351-4f23-95d3-417a6368fdb3
2020-12-03 07:19:51,341 [IPC Server handler 1 on default port 34612] INFO  net.NetworkTopology (NetworkTopology.java:remove(219)) - Removing a node: /default-rack/127.0.0.1:41753
2020-12-03 07:19:51,342 [IPC Server handler 1 on default port 34612] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:42420
2020-12-03 07:19:51,344 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-0b503d65-8d01-49ef-8e43-291aff1d549a): no suitable block pools found to scan.  Waiting 1814397271 ms.
2020-12-03 07:19:51,346 [Listener at localhost/42345] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:19:51,347 [Listener at localhost/42345] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:19:51,348 [Thread-413] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34612 starting to offer service
2020-12-03 07:19:51,348 [Thread-374] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-3571474c-359b-4f98-94a4-8b83a1d0652c
2020-12-03 07:19:51,375 [Thread-374] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, StorageType: DISK
2020-12-03 07:19:51,375 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-464449197-172.17.0.6-1606979982896 (Datanode Uuid baa99858-a351-4f23-95d3-417a6368fdb3) service to localhost/127.0.0.1:34612 successfully registered with NN
2020-12-03 07:19:51,401 [Thread-374] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:19:51,401 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:19:51,391 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:19:51,422 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:34612 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:19:51,438 [Listener at localhost/42345] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:restartDataNodes(2519)) - Restarted DataNode 4
2020-12-03 07:19:51,438 [Listener at localhost/42345] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopDataNode(2331)) - MiniDFSCluster Stopping DataNode 127.0.0.1:41126 from a total of 8 datanodes.
2020-12-03 07:19:51,438 [Listener at localhost/42345] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(341)) - DirectoryScanner: shutdown has been called, but periodic scanner not started
2020-12-03 07:19:51,439 [Thread-374] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:19:51,439 [Thread-413] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34612
2020-12-03 07:19:51,439 [Listener at localhost/42345] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 39032
2020-12-03 07:19:51,439 [Thread-374] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:19:51,440 [Thread-374] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:19:51,440 [Thread-374] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:19:51,444 [Thread-413] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:19:51,451 [Thread-374] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:51,451 [Listener at localhost/42345] WARN  util.MBeans (MBeans.java:unregister(145)) - Error unregistering Hadoop:service=DataNode,name=FSDatasetState-2b5a1500-a27d-403f-b7e5-7837081de87c
javax.management.InstanceNotFoundException: Hadoop:service=DataNode,name=FSDatasetState-2b5a1500-a27d-403f-b7e5-7837081de87c
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getMBean(DefaultMBeanServerInterceptor.java:1095)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.exclusiveUnregisterMBean(DefaultMBeanServerInterceptor.java:427)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.unregisterMBean(DefaultMBeanServerInterceptor.java:415)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.unregisterMBean(JmxMBeanServer.java:546)
	at org.apache.hadoop.metrics2.util.MBeans.unregister(MBeans.java:143)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.shutdown(FsDatasetImpl.java:2293)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.shutdown(DataNode.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.stopDataNode(MiniDFSCluster.java:2335)
	at org.apache.hadoop.hdfs.MiniDFSCluster.restartDataNode(MiniDFSCluster.java:2482)
	at org.apache.hadoop.hdfs.MiniDFSCluster.restartDataNode(MiniDFSCluster.java:2469)
	at org.apache.hadoop.hdfs.MiniDFSCluster.restartDataNodes(MiniDFSCluster.java:2517)
	at org.apache.hadoop.hdfs.MiniDFSCluster.restartDataNodes(MiniDFSCluster.java:2528)
	at org.apache.hadoop.hdfs.server.namenode.TestNamenodeCapacityReport.testXceiverCountInternal(TestNamenodeCapacityReport.java:254)
	at org.apache.hadoop.hdfs.server.namenode.TestNamenodeCapacityReport.testXceiverCount(TestNamenodeCapacityReport.java:199)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2020-12-03 07:19:51,460 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x21ca87d29fbb0973: Processing first storage report for DS-0b503d65-8d01-49ef-8e43-291aff1d549a from datanode baa99858-a351-4f23-95d3-417a6368fdb3
2020-12-03 07:19:51,464 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x21ca87d29fbb0973: from storage DS-0b503d65-8d01-49ef-8e43-291aff1d549a node DatanodeRegistration(127.0.0.1:42420, datanodeUuid=baa99858-a351-4f23-95d3-417a6368fdb3, infoPort=41829, infoSecurePort=0, ipcPort=38349, storageInfo=lv=-57;cid=testClusterID;nsid=662464899;c=1606979982896), blocks: 0, hasStaleStorage: false, processing time: 4 msecs, invalidatedBlocks: 0
2020-12-03 07:19:51,464 [Listener at localhost/42345] WARN  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(191)) - AsyncDiskService has already shut down.
2020-12-03 07:19:51,464 [Listener at localhost/42345] WARN  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(175)) - AsyncLazyPersistService has already shut down.
2020-12-03 07:19:51,465 [Listener at localhost/42345] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:19:51,466 [Listener at localhost/42345] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:19:51,466 [Listener at localhost/42345] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:19:51,452 [Thread-426] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12...
2020-12-03 07:19:51,452 [Thread-425] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11...
2020-12-03 07:19:51,464 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x21ca87d29fbb0973: Processing first storage report for DS-5b6b1a9c-9c26-49bb-9bbd-60b622efa680 from datanode baa99858-a351-4f23-95d3-417a6368fdb3
2020-12-03 07:19:51,468 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x21ca87d29fbb0973: from storage DS-5b6b1a9c-9c26-49bb-9bbd-60b622efa680 node DatanodeRegistration(127.0.0.1:42420, datanodeUuid=baa99858-a351-4f23-95d3-417a6368fdb3, infoPort=41829, infoSecurePort=0, ipcPort=38349, storageInfo=lv=-57;cid=testClusterID;nsid=662464899;c=1606979982896), blocks: 0, hasStaleStorage: false, processing time: 3 msecs, invalidatedBlocks: 0
2020-12-03 07:19:51,468 [Listener at localhost/42345] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:19:51,469 [Thread-425] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-464449197-172.17.0.6-1606979982896/current: 24576
2020-12-03 07:19:51,468 [Thread-426] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-464449197-172.17.0.6-1606979982896/current: 24576
2020-12-03 07:19:51,469 [Listener at localhost/42345] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:51,474 [Listener at localhost/42345] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:19:51,475 [Listener at localhost/42345] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:19:51,475 [Listener at localhost/42345] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:51,481 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x21ca87d29fbb0973,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 16 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:19:51,481 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:51,486 [Listener at localhost/42345] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:19:51,486 [Listener at localhost/42345] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:35226
2020-12-03 07:19:51,487 [Listener at localhost/42345] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:19:51,487 [Listener at localhost/42345] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:19:51,488 [Listener at localhost/42345] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:51,489 [Listener at localhost/42345] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:19:51,490 [Listener at localhost/42345] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:19:51,490 [Listener at localhost/42345] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:51,493 [Listener at localhost/42345] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:19:51,493 [Listener at localhost/42345] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:19:51,494 [Listener at localhost/42345] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:19:51,494 [Listener at localhost/42345] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:19:51,495 [Thread-426] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-464449197-172.17.0.6-1606979982896 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12: 27ms
2020-12-03 07:19:51,495 [Listener at localhost/42345] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 38417
2020-12-03 07:19:51,496 [Listener at localhost/42345] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:19:51,503 [Listener at localhost/42345] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1e6cc850{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:19:51,504 [Listener at localhost/42345] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7ec58feb{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:19:51,504 [Thread-425] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-464449197-172.17.0.6-1606979982896 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11: 36ms
2020-12-03 07:19:51,504 [Thread-374] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-464449197-172.17.0.6-1606979982896: 53ms
2020-12-03 07:19:51,505 [Thread-432] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11...
2020-12-03 07:19:51,505 [Thread-433] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12...
2020-12-03 07:19:51,505 [Thread-432] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-464449197-172.17.0.6-1606979982896/current/replicas doesn't exist 
2020-12-03 07:19:51,505 [Thread-433] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-464449197-172.17.0.6-1606979982896/current/replicas doesn't exist 
2020-12-03 07:19:51,505 [Thread-432] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11: 1ms
2020-12-03 07:19:51,505 [Thread-433] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12: 1ms
2020-12-03 07:19:51,506 [Thread-374] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-464449197-172.17.0.6-1606979982896: 1ms
2020-12-03 07:19:51,506 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-3571474c-359b-4f98-94a4-8b83a1d0652c): no suitable block pools found to scan.  Waiting 1814397097 ms.
2020-12-03 07:19:51,507 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-e89d6108-2324-4b34-addb-9670aed7d37d): no suitable block pools found to scan.  Waiting 1814397096 ms.
2020-12-03 07:19:51,507 [Thread-374] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 7:20 AM with interval of 21600000ms
2020-12-03 07:19:51,513 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-464449197-172.17.0.6-1606979982896 (Datanode Uuid edec627a-465f-4532-ab74-3f78e8a40769) service to localhost/127.0.0.1:34612 beginning handshake with NN
2020-12-03 07:19:51,516 [IPC Server handler 5 on default port 34612] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35235, datanodeUuid=edec627a-465f-4532-ab74-3f78e8a40769, infoPort=45934, infoSecurePort=0, ipcPort=43944, storageInfo=lv=-57;cid=testClusterID;nsid=662464899;c=1606979982896) storage edec627a-465f-4532-ab74-3f78e8a40769
2020-12-03 07:19:51,516 [IPC Server handler 5 on default port 34612] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1078)) - BLOCK* registerDatanode: 127.0.0.1:40120 is replaced by DatanodeRegistration(127.0.0.1:35235, datanodeUuid=edec627a-465f-4532-ab74-3f78e8a40769, infoPort=45934, infoSecurePort=0, ipcPort=43944, storageInfo=lv=-57;cid=testClusterID;nsid=662464899;c=1606979982896) with the same storageID edec627a-465f-4532-ab74-3f78e8a40769
2020-12-03 07:19:51,516 [IPC Server handler 5 on default port 34612] INFO  net.NetworkTopology (NetworkTopology.java:remove(219)) - Removing a node: /default-rack/127.0.0.1:40120
2020-12-03 07:19:51,516 [IPC Server handler 5 on default port 34612] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:35235
2020-12-03 07:19:51,517 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-464449197-172.17.0.6-1606979982896 (Datanode Uuid edec627a-465f-4532-ab74-3f78e8a40769) service to localhost/127.0.0.1:34612 successfully registered with NN
2020-12-03 07:19:51,517 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:34612 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:19:51,527 [Thread-413] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/in_use.lock acquired by nodename 906@9ece31fe74eb
2020-12-03 07:19:51,537 [Listener at localhost/42345] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5cd61783{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:19:51,544 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xe2d837358817d1b6: Processing first storage report for DS-e89d6108-2324-4b34-addb-9670aed7d37d from datanode edec627a-465f-4532-ab74-3f78e8a40769
2020-12-03 07:19:51,544 [Listener at localhost/42345] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@59429fac{HTTP/1.1,[http/1.1]}{localhost:38417}
2020-12-03 07:19:51,544 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xe2d837358817d1b6: from storage DS-e89d6108-2324-4b34-addb-9670aed7d37d node DatanodeRegistration(127.0.0.1:35235, datanodeUuid=edec627a-465f-4532-ab74-3f78e8a40769, infoPort=45934, infoSecurePort=0, ipcPort=43944, storageInfo=lv=-57;cid=testClusterID;nsid=662464899;c=1606979982896), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:19:51,545 [Listener at localhost/42345] INFO  server.Server (Server.java:doStart(419)) - Started @11278ms
2020-12-03 07:19:51,545 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xe2d837358817d1b6: Processing first storage report for DS-3571474c-359b-4f98-94a4-8b83a1d0652c from datanode edec627a-465f-4532-ab74-3f78e8a40769
2020-12-03 07:19:51,545 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xe2d837358817d1b6: from storage DS-3571474c-359b-4f98-94a4-8b83a1d0652c node DatanodeRegistration(127.0.0.1:35235, datanodeUuid=edec627a-465f-4532-ab74-3f78e8a40769, infoPort=45934, infoSecurePort=0, ipcPort=43944, storageInfo=lv=-57;cid=testClusterID;nsid=662464899;c=1606979982896), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:19:51,553 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xe2d837358817d1b6,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 10 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:19:51,553 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:51,581 [Listener at localhost/42345] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:35351
2020-12-03 07:19:51,582 [Listener at localhost/42345] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:19:51,582 [Listener at localhost/42345] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:19:51,582 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@26e412ef] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:19:51,583 [Listener at localhost/42345] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:19:51,584 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:19:51,593 [Listener at localhost/45810] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:45810
2020-12-03 07:19:51,594 [Thread-413] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/in_use.lock acquired by nodename 906@9ece31fe74eb
2020-12-03 07:19:51,639 [Thread-413] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:51,640 [Thread-413] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:51,661 [Listener at localhost/45810] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:19:51,662 [Listener at localhost/45810] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:19:51,670 [Thread-443] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34612 starting to offer service
2020-12-03 07:19:51,683 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:19:51,683 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:19:51,710 [Listener at localhost/45810] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:restartDataNodes(2519)) - Restarted DataNode 3
2020-12-03 07:19:51,711 [Listener at localhost/45810] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopDataNode(2331)) - MiniDFSCluster Stopping DataNode 127.0.0.1:43627 from a total of 8 datanodes.
2020-12-03 07:19:51,711 [Listener at localhost/45810] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(341)) - DirectoryScanner: shutdown has been called, but periodic scanner not started
2020-12-03 07:19:51,711 [Listener at localhost/45810] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 37837
2020-12-03 07:19:51,712 [Listener at localhost/45810] WARN  util.MBeans (MBeans.java:unregister(145)) - Error unregistering Hadoop:service=DataNode,name=FSDatasetState-01c12b1d-d7d2-421e-986c-c593ac806eae
javax.management.InstanceNotFoundException: Hadoop:service=DataNode,name=FSDatasetState-01c12b1d-d7d2-421e-986c-c593ac806eae
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getMBean(DefaultMBeanServerInterceptor.java:1095)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.exclusiveUnregisterMBean(DefaultMBeanServerInterceptor.java:427)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.unregisterMBean(DefaultMBeanServerInterceptor.java:415)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.unregisterMBean(JmxMBeanServer.java:546)
	at org.apache.hadoop.metrics2.util.MBeans.unregister(MBeans.java:143)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.shutdown(FsDatasetImpl.java:2293)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.shutdown(DataNode.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.stopDataNode(MiniDFSCluster.java:2335)
	at org.apache.hadoop.hdfs.MiniDFSCluster.restartDataNode(MiniDFSCluster.java:2482)
	at org.apache.hadoop.hdfs.MiniDFSCluster.restartDataNode(MiniDFSCluster.java:2469)
	at org.apache.hadoop.hdfs.MiniDFSCluster.restartDataNodes(MiniDFSCluster.java:2517)
	at org.apache.hadoop.hdfs.MiniDFSCluster.restartDataNodes(MiniDFSCluster.java:2528)
	at org.apache.hadoop.hdfs.server.namenode.TestNamenodeCapacityReport.testXceiverCountInternal(TestNamenodeCapacityReport.java:254)
	at org.apache.hadoop.hdfs.server.namenode.TestNamenodeCapacityReport.testXceiverCount(TestNamenodeCapacityReport.java:199)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2020-12-03 07:19:51,713 [Listener at localhost/45810] WARN  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(191)) - AsyncDiskService has already shut down.
2020-12-03 07:19:51,713 [Listener at localhost/45810] WARN  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(175)) - AsyncLazyPersistService has already shut down.
2020-12-03 07:19:51,714 [Listener at localhost/45810] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:19:51,722 [Listener at localhost/45810] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:19:51,723 [Thread-443] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34612
2020-12-03 07:19:51,724 [Listener at localhost/45810] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:19:51,749 [Thread-443] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:19:51,751 [Listener at localhost/45810] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:19:51,752 [Listener at localhost/45810] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:51,752 [Listener at localhost/45810] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:19:51,753 [Listener at localhost/45810] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:19:51,753 [Listener at localhost/45810] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:51,753 [Listener at localhost/45810] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:19:51,754 [Listener at localhost/45810] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:43233
2020-12-03 07:19:51,754 [Listener at localhost/45810] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:19:51,755 [Listener at localhost/45810] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:19:51,762 [Listener at localhost/45810] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:51,764 [Listener at localhost/45810] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:19:51,765 [Listener at localhost/45810] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:19:51,765 [Listener at localhost/45810] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:51,767 [Listener at localhost/45810] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:19:51,767 [Listener at localhost/45810] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:19:51,767 [Listener at localhost/45810] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:19:51,767 [Listener at localhost/45810] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:19:51,768 [Listener at localhost/45810] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 37244
2020-12-03 07:19:51,769 [Listener at localhost/45810] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:19:51,770 [Listener at localhost/45810] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@61c76850{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:19:51,771 [Listener at localhost/45810] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2a22ad2b{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:19:51,779 [Listener at localhost/45810] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@2098d37d{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:19:51,779 [Listener at localhost/45810] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@77b9d0c7{HTTP/1.1,[http/1.1]}{localhost:37244}
2020-12-03 07:19:51,780 [Listener at localhost/45810] INFO  server.Server (Server.java:doStart(419)) - Started @11513ms
2020-12-03 07:19:51,813 [Listener at localhost/45810] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:34627
2020-12-03 07:19:51,814 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@127f9161] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:19:51,814 [Listener at localhost/45810] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:19:51,814 [Listener at localhost/45810] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:19:51,815 [Listener at localhost/45810] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:19:51,816 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:19:51,823 [Listener at localhost/44520] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:44520
2020-12-03 07:19:51,913 [Listener at localhost/44520] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:19:51,914 [Listener at localhost/44520] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:19:51,914 [Thread-465] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34612 starting to offer service
2020-12-03 07:19:51,915 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:19:51,915 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:19:51,933 [Thread-465] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34612
2020-12-03 07:19:51,944 [Listener at localhost/44520] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:restartDataNodes(2519)) - Restarted DataNode 2
2020-12-03 07:19:51,944 [Listener at localhost/44520] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopDataNode(2331)) - MiniDFSCluster Stopping DataNode 127.0.0.1:37598 from a total of 8 datanodes.
2020-12-03 07:19:51,944 [Listener at localhost/44520] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(341)) - DirectoryScanner: shutdown has been called, but periodic scanner not started
2020-12-03 07:19:51,950 [Thread-465] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:19:51,950 [Listener at localhost/44520] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 46838
2020-12-03 07:19:51,950 [Listener at localhost/44520] WARN  util.MBeans (MBeans.java:unregister(145)) - Error unregistering Hadoop:service=DataNode,name=FSDatasetState-ba28613b-b481-4768-b4d4-cf44e7144ddf
javax.management.InstanceNotFoundException: Hadoop:service=DataNode,name=FSDatasetState-ba28613b-b481-4768-b4d4-cf44e7144ddf
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getMBean(DefaultMBeanServerInterceptor.java:1095)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.exclusiveUnregisterMBean(DefaultMBeanServerInterceptor.java:427)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.unregisterMBean(DefaultMBeanServerInterceptor.java:415)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.unregisterMBean(JmxMBeanServer.java:546)
	at org.apache.hadoop.metrics2.util.MBeans.unregister(MBeans.java:143)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.shutdown(FsDatasetImpl.java:2293)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.shutdown(DataNode.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.stopDataNode(MiniDFSCluster.java:2335)
	at org.apache.hadoop.hdfs.MiniDFSCluster.restartDataNode(MiniDFSCluster.java:2482)
	at org.apache.hadoop.hdfs.MiniDFSCluster.restartDataNode(MiniDFSCluster.java:2469)
	at org.apache.hadoop.hdfs.MiniDFSCluster.restartDataNodes(MiniDFSCluster.java:2517)
	at org.apache.hadoop.hdfs.MiniDFSCluster.restartDataNodes(MiniDFSCluster.java:2528)
	at org.apache.hadoop.hdfs.server.namenode.TestNamenodeCapacityReport.testXceiverCountInternal(TestNamenodeCapacityReport.java:254)
	at org.apache.hadoop.hdfs.server.namenode.TestNamenodeCapacityReport.testXceiverCount(TestNamenodeCapacityReport.java:199)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2020-12-03 07:19:51,955 [Listener at localhost/44520] WARN  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(191)) - AsyncDiskService has already shut down.
2020-12-03 07:19:51,956 [Listener at localhost/44520] WARN  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(175)) - AsyncLazyPersistService has already shut down.
2020-12-03 07:19:51,956 [Listener at localhost/44520] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:19:51,957 [Listener at localhost/44520] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:19:51,958 [Listener at localhost/44520] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:19:51,959 [Listener at localhost/44520] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:19:52,005 [Thread-443] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/in_use.lock acquired by nodename 906@9ece31fe74eb
2020-12-03 07:19:52,026 [Listener at localhost/44520] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:52,026 [Listener at localhost/44520] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:19:52,103 [Listener at localhost/44520] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:19:52,103 [Listener at localhost/44520] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:52,104 [Listener at localhost/44520] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:19:52,105 [Thread-465] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 906@9ece31fe74eb
2020-12-03 07:19:52,105 [Listener at localhost/44520] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:33060
2020-12-03 07:19:52,105 [Listener at localhost/44520] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:19:52,105 [Listener at localhost/44520] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:19:52,107 [Listener at localhost/44520] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:52,109 [Listener at localhost/44520] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:19:52,110 [Listener at localhost/44520] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:19:52,110 [Listener at localhost/44520] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:52,111 [Thread-413] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:52,112 [Thread-413] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:52,113 [Listener at localhost/44520] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:19:52,114 [Listener at localhost/44520] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:19:52,114 [Listener at localhost/44520] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:19:52,115 [Listener at localhost/44520] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:19:52,120 [Listener at localhost/44520] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 39391
2020-12-03 07:19:52,120 [Listener at localhost/44520] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:19:52,123 [Listener at localhost/44520] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3c0fbd3a{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:19:52,124 [Listener at localhost/44520] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@54562ea6{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:19:52,213 [Thread-413] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=662464899;bpid=BP-464449197-172.17.0.6-1606979982896;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=662464899;c=1606979982896;bpid=BP-464449197-172.17.0.6-1606979982896;dnuuid=309f7fa0-0c59-4920-a6f9-56c2485276d8
2020-12-03 07:19:52,223 [Thread-443] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/in_use.lock acquired by nodename 906@9ece31fe74eb
2020-12-03 07:19:52,242 [Thread-413] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-47ca938b-a40d-4407-b093-5825baebb00c
2020-12-03 07:19:52,242 [Thread-413] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, StorageType: DISK
2020-12-03 07:19:52,274 [Thread-465] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 906@9ece31fe74eb
2020-12-03 07:19:52,476 [Thread-413] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-9de9d331-cfd4-450a-96bf-6bed8d407bd9
2020-12-03 07:19:52,476 [Thread-413] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, StorageType: DISK
2020-12-03 07:19:52,477 [Thread-413] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:19:52,478 [Thread-413] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:19:52,479 [Thread-413] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:19:52,479 [Thread-413] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:19:52,479 [Thread-413] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:19:52,479 [Thread-413] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:52,486 [Thread-483] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-12-03 07:19:52,487 [Thread-484] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-12-03 07:19:52,489 [Thread-484] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-464449197-172.17.0.6-1606979982896/current: 24576
2020-12-03 07:19:52,489 [Thread-483] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-464449197-172.17.0.6-1606979982896/current: 24576
2020-12-03 07:19:52,503 [Thread-465] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:52,503 [Thread-465] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:52,504 [Thread-443] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:52,504 [Thread-443] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:52,513 [Thread-484] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-464449197-172.17.0.6-1606979982896 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 27ms
2020-12-03 07:19:52,514 [Thread-483] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-464449197-172.17.0.6-1606979982896 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 28ms
2020-12-03 07:19:52,545 [Listener at localhost/44520] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6892cc6f{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:19:52,557 [Thread-413] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-464449197-172.17.0.6-1606979982896: 78ms
2020-12-03 07:19:52,560 [Thread-485] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-12-03 07:19:52,561 [Thread-485] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-464449197-172.17.0.6-1606979982896/current/replicas doesn't exist 
2020-12-03 07:19:52,561 [Thread-485] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 1ms
2020-12-03 07:19:52,565 [Listener at localhost/44520] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6fd1660{HTTP/1.1,[http/1.1]}{localhost:39391}
2020-12-03 07:19:52,566 [Thread-486] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-12-03 07:19:52,566 [Listener at localhost/44520] INFO  server.Server (Server.java:doStart(419)) - Started @12299ms
2020-12-03 07:19:52,566 [Thread-486] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-464449197-172.17.0.6-1606979982896/current/replicas doesn't exist 
2020-12-03 07:19:52,567 [Thread-486] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 1ms
2020-12-03 07:19:52,567 [Thread-413] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-464449197-172.17.0.6-1606979982896: 9ms
2020-12-03 07:19:52,570 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-47ca938b-a40d-4407-b093-5825baebb00c): no suitable block pools found to scan.  Waiting 1814396041 ms.
2020-12-03 07:19:52,571 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-9de9d331-cfd4-450a-96bf-6bed8d407bd9): no suitable block pools found to scan.  Waiting 1814396041 ms.
2020-12-03 07:19:52,571 [Thread-413] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 9:48 AM with interval of 21600000ms
2020-12-03 07:19:52,573 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-464449197-172.17.0.6-1606979982896 (Datanode Uuid 309f7fa0-0c59-4920-a6f9-56c2485276d8) service to localhost/127.0.0.1:34612 beginning handshake with NN
2020-12-03 07:19:52,574 [IPC Server handler 6 on default port 34612] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:42173, datanodeUuid=309f7fa0-0c59-4920-a6f9-56c2485276d8, infoPort=35777, infoSecurePort=0, ipcPort=42345, storageInfo=lv=-57;cid=testClusterID;nsid=662464899;c=1606979982896) storage 309f7fa0-0c59-4920-a6f9-56c2485276d8
2020-12-03 07:19:52,575 [IPC Server handler 6 on default port 34612] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1078)) - BLOCK* registerDatanode: 127.0.0.1:36395 is replaced by DatanodeRegistration(127.0.0.1:42173, datanodeUuid=309f7fa0-0c59-4920-a6f9-56c2485276d8, infoPort=35777, infoSecurePort=0, ipcPort=42345, storageInfo=lv=-57;cid=testClusterID;nsid=662464899;c=1606979982896) with the same storageID 309f7fa0-0c59-4920-a6f9-56c2485276d8
2020-12-03 07:19:52,575 [IPC Server handler 6 on default port 34612] INFO  net.NetworkTopology (NetworkTopology.java:remove(219)) - Removing a node: /default-rack/127.0.0.1:36395
2020-12-03 07:19:52,575 [IPC Server handler 6 on default port 34612] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:42173
2020-12-03 07:19:52,576 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-464449197-172.17.0.6-1606979982896 (Datanode Uuid 309f7fa0-0c59-4920-a6f9-56c2485276d8) service to localhost/127.0.0.1:34612 successfully registered with NN
2020-12-03 07:19:52,576 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:34612 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:19:52,597 [Thread-465] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:52,597 [Thread-465] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:52,600 [Thread-443] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:52,601 [Thread-443] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:52,605 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xb3b5e4f0e0adb54e: Processing first storage report for DS-9de9d331-cfd4-450a-96bf-6bed8d407bd9 from datanode 309f7fa0-0c59-4920-a6f9-56c2485276d8
2020-12-03 07:19:52,606 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xb3b5e4f0e0adb54e: from storage DS-9de9d331-cfd4-450a-96bf-6bed8d407bd9 node DatanodeRegistration(127.0.0.1:42173, datanodeUuid=309f7fa0-0c59-4920-a6f9-56c2485276d8, infoPort=35777, infoSecurePort=0, ipcPort=42345, storageInfo=lv=-57;cid=testClusterID;nsid=662464899;c=1606979982896), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:19:52,606 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xb3b5e4f0e0adb54e: Processing first storage report for DS-47ca938b-a40d-4407-b093-5825baebb00c from datanode 309f7fa0-0c59-4920-a6f9-56c2485276d8
2020-12-03 07:19:52,606 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xb3b5e4f0e0adb54e: from storage DS-47ca938b-a40d-4407-b093-5825baebb00c node DatanodeRegistration(127.0.0.1:42173, datanodeUuid=309f7fa0-0c59-4920-a6f9-56c2485276d8, infoPort=35777, infoSecurePort=0, ipcPort=42345, storageInfo=lv=-57;cid=testClusterID;nsid=662464899;c=1606979982896), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:19:52,616 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xb3b5e4f0e0adb54e,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:19:52,622 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:52,619 [Listener at localhost/44520] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:36743
2020-12-03 07:19:52,627 [Listener at localhost/44520] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:19:52,627 [Listener at localhost/44520] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:19:52,627 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5e8604bf] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:19:52,629 [Listener at localhost/44520] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:19:52,631 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:19:52,644 [Listener at localhost/40709] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:40709
2020-12-03 07:19:52,658 [Listener at localhost/40709] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:19:52,658 [Listener at localhost/40709] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:19:52,659 [Thread-496] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34612 starting to offer service
2020-12-03 07:19:52,666 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:19:52,668 [Listener at localhost/40709] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:restartDataNodes(2519)) - Restarted DataNode 1
2020-12-03 07:19:52,668 [Thread-465] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=662464899;bpid=BP-464449197-172.17.0.6-1606979982896;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=662464899;c=1606979982896;bpid=BP-464449197-172.17.0.6-1606979982896;dnuuid=01c12b1d-d7d2-421e-986c-c593ac806eae
2020-12-03 07:19:52,669 [Listener at localhost/40709] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopDataNode(2331)) - MiniDFSCluster Stopping DataNode 127.0.0.1:41902 from a total of 8 datanodes.
2020-12-03 07:19:52,669 [Listener at localhost/40709] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(341)) - DirectoryScanner: shutdown has been called, but periodic scanner not started
2020-12-03 07:19:52,669 [Listener at localhost/40709] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 42343
2020-12-03 07:19:52,670 [Listener at localhost/40709] WARN  util.MBeans (MBeans.java:unregister(145)) - Error unregistering Hadoop:service=DataNode,name=FSDatasetState-ec6135ad-ddf0-47a2-866e-c2a0a646b3ea
javax.management.InstanceNotFoundException: Hadoop:service=DataNode,name=FSDatasetState-ec6135ad-ddf0-47a2-866e-c2a0a646b3ea
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getMBean(DefaultMBeanServerInterceptor.java:1095)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.exclusiveUnregisterMBean(DefaultMBeanServerInterceptor.java:427)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.unregisterMBean(DefaultMBeanServerInterceptor.java:415)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.unregisterMBean(JmxMBeanServer.java:546)
	at org.apache.hadoop.metrics2.util.MBeans.unregister(MBeans.java:143)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.shutdown(FsDatasetImpl.java:2293)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.shutdown(DataNode.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.stopDataNode(MiniDFSCluster.java:2335)
	at org.apache.hadoop.hdfs.MiniDFSCluster.restartDataNode(MiniDFSCluster.java:2482)
	at org.apache.hadoop.hdfs.MiniDFSCluster.restartDataNode(MiniDFSCluster.java:2469)
	at org.apache.hadoop.hdfs.MiniDFSCluster.restartDataNodes(MiniDFSCluster.java:2517)
	at org.apache.hadoop.hdfs.MiniDFSCluster.restartDataNodes(MiniDFSCluster.java:2528)
	at org.apache.hadoop.hdfs.server.namenode.TestNamenodeCapacityReport.testXceiverCountInternal(TestNamenodeCapacityReport.java:254)
	at org.apache.hadoop.hdfs.server.namenode.TestNamenodeCapacityReport.testXceiverCount(TestNamenodeCapacityReport.java:199)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2020-12-03 07:19:52,670 [Listener at localhost/40709] WARN  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(191)) - AsyncDiskService has already shut down.
2020-12-03 07:19:52,671 [Listener at localhost/40709] WARN  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(175)) - AsyncLazyPersistService has already shut down.
2020-12-03 07:19:52,672 [Listener at localhost/40709] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:19:52,683 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:19:52,692 [Thread-443] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=662464899;bpid=BP-464449197-172.17.0.6-1606979982896;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=662464899;c=1606979982896;bpid=BP-464449197-172.17.0.6-1606979982896;dnuuid=2b5a1500-a27d-403f-b7e5-7837081de87c
2020-12-03 07:19:52,693 [Listener at localhost/40709] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:19:52,694 [Thread-496] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34612
2020-12-03 07:19:52,695 [Listener at localhost/40709] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:19:52,700 [Listener at localhost/40709] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:19:52,701 [Listener at localhost/40709] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:52,701 [Listener at localhost/40709] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:19:52,702 [Listener at localhost/40709] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:19:52,702 [Listener at localhost/40709] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:52,702 [Listener at localhost/40709] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:19:52,717 [Thread-496] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:19:52,718 [Thread-443] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-28904309-f21d-4622-b590-65c20013b1c7
2020-12-03 07:19:52,718 [Thread-443] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, StorageType: DISK
2020-12-03 07:19:52,729 [Thread-465] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-6f70985c-ac30-47d0-891a-02298a52a999
2020-12-03 07:19:52,728 [Listener at localhost/40709] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:45400
2020-12-03 07:19:52,735 [Thread-443] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-8d7e7ea8-c1a7-4424-9e6e-68f075bb1fe6
2020-12-03 07:19:52,735 [Thread-443] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, StorageType: DISK
2020-12-03 07:19:52,735 [Listener at localhost/40709] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:19:52,736 [Listener at localhost/40709] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:19:52,736 [Thread-443] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:19:52,736 [Thread-465] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, StorageType: DISK
2020-12-03 07:19:52,737 [Listener at localhost/40709] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:52,739 [Thread-443] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:19:52,739 [Listener at localhost/40709] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:19:52,740 [Thread-443] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:19:52,740 [Listener at localhost/40709] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:19:52,740 [Thread-443] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:19:52,740 [Listener at localhost/40709] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:52,741 [Thread-443] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:19:52,741 [Thread-443] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:52,742 [Thread-513] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-12-03 07:19:52,742 [Thread-514] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-12-03 07:19:52,743 [Listener at localhost/40709] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:19:52,754 [Listener at localhost/40709] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:19:52,754 [Listener at localhost/40709] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:19:52,754 [Listener at localhost/40709] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:19:52,760 [Thread-513] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-464449197-172.17.0.6-1606979982896/current: 24576
2020-12-03 07:19:52,761 [Thread-514] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-464449197-172.17.0.6-1606979982896/current: 24576
2020-12-03 07:19:52,764 [Listener at localhost/40709] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 39385
2020-12-03 07:19:52,764 [Listener at localhost/40709] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:19:52,765 [Thread-465] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-ca7c16c8-a7cd-40c3-9072-e5e55f35ba2f
2020-12-03 07:19:52,766 [Thread-465] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, StorageType: DISK
2020-12-03 07:19:52,775 [Thread-496] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 906@9ece31fe74eb
2020-12-03 07:19:52,805 [Thread-465] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:19:52,808 [Thread-465] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:19:52,843 [Thread-513] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-464449197-172.17.0.6-1606979982896 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 101ms
2020-12-03 07:19:52,850 [Thread-514] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-464449197-172.17.0.6-1606979982896 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 108ms
2020-12-03 07:19:52,853 [Thread-443] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-464449197-172.17.0.6-1606979982896: 111ms
2020-12-03 07:19:52,865 [Thread-517] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-12-03 07:19:52,865 [Thread-517] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-464449197-172.17.0.6-1606979982896/current/replicas doesn't exist 
2020-12-03 07:19:52,865 [Thread-517] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 1ms
2020-12-03 07:19:52,865 [Thread-519] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-12-03 07:19:52,866 [Thread-519] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-464449197-172.17.0.6-1606979982896/current/replicas doesn't exist 
2020-12-03 07:19:52,866 [Thread-465] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:19:52,866 [Thread-465] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:19:52,866 [Thread-519] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 1ms
2020-12-03 07:19:52,866 [Listener at localhost/40709] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6a84bc3f{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:19:52,866 [Thread-465] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:19:52,880 [Thread-465] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:52,880 [Thread-520] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:19:52,880 [Thread-521] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:19:52,875 [Thread-443] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-464449197-172.17.0.6-1606979982896: 23ms
2020-12-03 07:19:52,880 [Listener at localhost/40709] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4930539b{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:19:52,882 [Thread-520] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-464449197-172.17.0.6-1606979982896/current: 24576
2020-12-03 07:19:52,882 [Thread-521] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-464449197-172.17.0.6-1606979982896/current: 24576
2020-12-03 07:19:52,887 [Thread-496] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 906@9ece31fe74eb
2020-12-03 07:19:52,888 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-8d7e7ea8-c1a7-4424-9e6e-68f075bb1fe6): no suitable block pools found to scan.  Waiting 1814395722 ms.
2020-12-03 07:19:52,887 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-28904309-f21d-4622-b590-65c20013b1c7): no suitable block pools found to scan.  Waiting 1814395723 ms.
2020-12-03 07:19:52,899 [Thread-443] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:20 AM with interval of 21600000ms
2020-12-03 07:19:52,901 [Listener at localhost/40709] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6fc3e1a4{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:19:52,902 [Listener at localhost/40709] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3fa76c61{HTTP/1.1,[http/1.1]}{localhost:39385}
2020-12-03 07:19:52,902 [Listener at localhost/40709] INFO  server.Server (Server.java:doStart(419)) - Started @12635ms
2020-12-03 07:19:52,916 [Thread-520] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-464449197-172.17.0.6-1606979982896 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 36ms
2020-12-03 07:19:52,924 [Thread-521] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-464449197-172.17.0.6-1606979982896 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 43ms
2020-12-03 07:19:52,924 [Thread-465] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-464449197-172.17.0.6-1606979982896: 43ms
2020-12-03 07:19:52,924 [Thread-525] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:19:52,924 [Thread-526] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:19:52,925 [Thread-525] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-464449197-172.17.0.6-1606979982896/current/replicas doesn't exist 
2020-12-03 07:19:52,925 [Thread-526] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-464449197-172.17.0.6-1606979982896/current/replicas doesn't exist 
2020-12-03 07:19:52,925 [Thread-525] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 1ms
2020-12-03 07:19:52,925 [Thread-526] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 1ms
2020-12-03 07:19:52,925 [Thread-465] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-464449197-172.17.0.6-1606979982896: 1ms
2020-12-03 07:19:52,926 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-ca7c16c8-a7cd-40c3-9072-e5e55f35ba2f): no suitable block pools found to scan.  Waiting 1814395677 ms.
2020-12-03 07:19:52,927 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-6f70985c-ac30-47d0-891a-02298a52a999): no suitable block pools found to scan.  Waiting 1814395676 ms.
2020-12-03 07:19:52,927 [Thread-465] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 8:06 AM with interval of 21600000ms
2020-12-03 07:19:52,937 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-464449197-172.17.0.6-1606979982896 (Datanode Uuid 01c12b1d-d7d2-421e-986c-c593ac806eae) service to localhost/127.0.0.1:34612 beginning handshake with NN
2020-12-03 07:19:52,940 [IPC Server handler 4 on default port 34612] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:43233, datanodeUuid=01c12b1d-d7d2-421e-986c-c593ac806eae, infoPort=34627, infoSecurePort=0, ipcPort=44520, storageInfo=lv=-57;cid=testClusterID;nsid=662464899;c=1606979982896) storage 01c12b1d-d7d2-421e-986c-c593ac806eae
2020-12-03 07:19:52,940 [IPC Server handler 4 on default port 34612] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1078)) - BLOCK* registerDatanode: 127.0.0.1:43627 is replaced by DatanodeRegistration(127.0.0.1:43233, datanodeUuid=01c12b1d-d7d2-421e-986c-c593ac806eae, infoPort=34627, infoSecurePort=0, ipcPort=44520, storageInfo=lv=-57;cid=testClusterID;nsid=662464899;c=1606979982896) with the same storageID 01c12b1d-d7d2-421e-986c-c593ac806eae
2020-12-03 07:19:52,940 [IPC Server handler 4 on default port 34612] INFO  net.NetworkTopology (NetworkTopology.java:remove(219)) - Removing a node: /default-rack/127.0.0.1:43627
2020-12-03 07:19:52,941 [IPC Server handler 4 on default port 34612] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:43233
2020-12-03 07:19:52,941 [IPC Server handler 4 on default port 34612] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateFailedStorage(562)) - [DISK]DS-ca7c16c8-a7cd-40c3-9072-e5e55f35ba2f:NORMAL:127.0.0.1:43233 failed.
2020-12-03 07:19:52,941 [IPC Server handler 4 on default port 34612] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateFailedStorage(562)) - [DISK]DS-6f70985c-ac30-47d0-891a-02298a52a999:NORMAL:127.0.0.1:43233 failed.
2020-12-03 07:19:52,941 [IPC Server handler 4 on default port 34612] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:pruneStorageMap(548)) - Removed storage [DISK]DS-ca7c16c8-a7cd-40c3-9072-e5e55f35ba2f:FAILED:127.0.0.1:43233 from DataNode 127.0.0.1:43233
2020-12-03 07:19:52,942 [IPC Server handler 4 on default port 34612] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:pruneStorageMap(548)) - Removed storage [DISK]DS-6f70985c-ac30-47d0-891a-02298a52a999:FAILED:127.0.0.1:43233 from DataNode 127.0.0.1:43233
2020-12-03 07:19:52,947 [Listener at localhost/40709] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:41348
2020-12-03 07:19:52,948 [Listener at localhost/40709] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:19:52,948 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-464449197-172.17.0.6-1606979982896 (Datanode Uuid 01c12b1d-d7d2-421e-986c-c593ac806eae) service to localhost/127.0.0.1:34612 successfully registered with NN
2020-12-03 07:19:52,948 [Listener at localhost/40709] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:19:52,948 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@29ea78b1] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:19:52,948 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:34612 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:19:52,949 [Listener at localhost/40709] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:19:52,953 [IPC Server handler 3 on default port 34612] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-6f70985c-ac30-47d0-891a-02298a52a999 for DN 127.0.0.1:43233
2020-12-03 07:19:52,952 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-464449197-172.17.0.6-1606979982896 (Datanode Uuid 2b5a1500-a27d-403f-b7e5-7837081de87c) service to localhost/127.0.0.1:34612 beginning handshake with NN
2020-12-03 07:19:52,954 [IPC Server handler 3 on default port 34612] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-ca7c16c8-a7cd-40c3-9072-e5e55f35ba2f for DN 127.0.0.1:43233
2020-12-03 07:19:52,954 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:19:52,958 [IPC Server handler 3 on default port 34612] WARN  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:requestLease(230)) - DN 01c12b1d-d7d2-421e-986c-c593ac806eae (127.0.0.1:43233) requested a lease even though it wasn't yet registered.  Registering now.
2020-12-03 07:19:52,958 [IPC Server handler 3 on default port 34612] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 01c12b1d-d7d2-421e-986c-c593ac806eae (127.0.0.1:43233).
2020-12-03 07:19:52,959 [IPC Server handler 2 on default port 34612] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35226, datanodeUuid=2b5a1500-a27d-403f-b7e5-7837081de87c, infoPort=35351, infoSecurePort=0, ipcPort=45810, storageInfo=lv=-57;cid=testClusterID;nsid=662464899;c=1606979982896) storage 2b5a1500-a27d-403f-b7e5-7837081de87c
2020-12-03 07:19:52,959 [IPC Server handler 2 on default port 34612] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1078)) - BLOCK* registerDatanode: 127.0.0.1:41126 is replaced by DatanodeRegistration(127.0.0.1:35226, datanodeUuid=2b5a1500-a27d-403f-b7e5-7837081de87c, infoPort=35351, infoSecurePort=0, ipcPort=45810, storageInfo=lv=-57;cid=testClusterID;nsid=662464899;c=1606979982896) with the same storageID 2b5a1500-a27d-403f-b7e5-7837081de87c
2020-12-03 07:19:52,959 [IPC Server handler 2 on default port 34612] INFO  net.NetworkTopology (NetworkTopology.java:remove(219)) - Removing a node: /default-rack/127.0.0.1:41126
2020-12-03 07:19:52,960 [IPC Server handler 2 on default port 34612] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:35226
2020-12-03 07:19:52,960 [IPC Server handler 2 on default port 34612] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateFailedStorage(562)) - [DISK]DS-8d7e7ea8-c1a7-4424-9e6e-68f075bb1fe6:NORMAL:127.0.0.1:35226 failed.
2020-12-03 07:19:52,960 [IPC Server handler 2 on default port 34612] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateFailedStorage(562)) - [DISK]DS-28904309-f21d-4622-b590-65c20013b1c7:NORMAL:127.0.0.1:35226 failed.
2020-12-03 07:19:52,960 [IPC Server handler 2 on default port 34612] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:pruneStorageMap(548)) - Removed storage [DISK]DS-8d7e7ea8-c1a7-4424-9e6e-68f075bb1fe6:FAILED:127.0.0.1:35226 from DataNode 127.0.0.1:35226
2020-12-03 07:19:52,961 [IPC Server handler 2 on default port 34612] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:pruneStorageMap(548)) - Removed storage [DISK]DS-28904309-f21d-4622-b590-65c20013b1c7:FAILED:127.0.0.1:35226 from DataNode 127.0.0.1:35226
2020-12-03 07:19:52,961 [Listener at localhost/36982] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:36982
2020-12-03 07:19:52,968 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x42c846120fa8f9b6: Processing first storage report for DS-ca7c16c8-a7cd-40c3-9072-e5e55f35ba2f from datanode 01c12b1d-d7d2-421e-986c-c593ac806eae
2020-12-03 07:19:52,969 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x42c846120fa8f9b6: from storage DS-ca7c16c8-a7cd-40c3-9072-e5e55f35ba2f node DatanodeRegistration(127.0.0.1:43233, datanodeUuid=01c12b1d-d7d2-421e-986c-c593ac806eae, infoPort=34627, infoSecurePort=0, ipcPort=44520, storageInfo=lv=-57;cid=testClusterID;nsid=662464899;c=1606979982896), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:19:52,969 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x42c846120fa8f9b6: Processing first storage report for DS-6f70985c-ac30-47d0-891a-02298a52a999 from datanode 01c12b1d-d7d2-421e-986c-c593ac806eae
2020-12-03 07:19:52,969 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x42c846120fa8f9b6: from storage DS-6f70985c-ac30-47d0-891a-02298a52a999 node DatanodeRegistration(127.0.0.1:43233, datanodeUuid=01c12b1d-d7d2-421e-986c-c593ac806eae, infoPort=34627, infoSecurePort=0, ipcPort=44520, storageInfo=lv=-57;cid=testClusterID;nsid=662464899;c=1606979982896), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:19:52,972 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-464449197-172.17.0.6-1606979982896 (Datanode Uuid 2b5a1500-a27d-403f-b7e5-7837081de87c) service to localhost/127.0.0.1:34612 successfully registered with NN
2020-12-03 07:19:52,972 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:34612 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:19:52,977 [Listener at localhost/36982] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:19:52,978 [Listener at localhost/36982] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:19:52,978 [IPC Server handler 8 on default port 34612] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-28904309-f21d-4622-b590-65c20013b1c7 for DN 127.0.0.1:35226
2020-12-03 07:19:52,978 [IPC Server handler 8 on default port 34612] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-8d7e7ea8-c1a7-4424-9e6e-68f075bb1fe6 for DN 127.0.0.1:35226
2020-12-03 07:19:52,979 [IPC Server handler 8 on default port 34612] WARN  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:requestLease(230)) - DN 2b5a1500-a27d-403f-b7e5-7837081de87c (127.0.0.1:35226) requested a lease even though it wasn't yet registered.  Registering now.
2020-12-03 07:19:52,979 [IPC Server handler 8 on default port 34612] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 2b5a1500-a27d-403f-b7e5-7837081de87c (127.0.0.1:35226).
2020-12-03 07:19:52,979 [Thread-536] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34612 starting to offer service
2020-12-03 07:19:52,979 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x42c846120fa8f9b6,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 15 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:19:52,979 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:53,010 [Listener at localhost/36982] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:restartDataNodes(2519)) - Restarted DataNode 0
2020-12-03 07:19:53,015 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:19:53,011 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:19:53,035 [Thread-496] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:53,036 [Thread-496] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:53,041 [IPC Server handler 0 on default port 34612] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:53,042 [Thread-536] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34612
2020-12-03 07:19:53,041 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x347903fb25958f34: Processing first storage report for DS-8d7e7ea8-c1a7-4424-9e6e-68f075bb1fe6 from datanode 2b5a1500-a27d-403f-b7e5-7837081de87c
2020-12-03 07:19:53,043 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x347903fb25958f34: from storage DS-8d7e7ea8-c1a7-4424-9e6e-68f075bb1fe6 node DatanodeRegistration(127.0.0.1:35226, datanodeUuid=2b5a1500-a27d-403f-b7e5-7837081de87c, infoPort=35351, infoSecurePort=0, ipcPort=45810, storageInfo=lv=-57;cid=testClusterID;nsid=662464899;c=1606979982896), blocks: 0, hasStaleStorage: true, processing time: 2 msecs, invalidatedBlocks: 0
2020-12-03 07:19:53,043 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x347903fb25958f34: Processing first storage report for DS-28904309-f21d-4622-b590-65c20013b1c7 from datanode 2b5a1500-a27d-403f-b7e5-7837081de87c
2020-12-03 07:19:53,043 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x347903fb25958f34: from storage DS-28904309-f21d-4622-b590-65c20013b1c7 node DatanodeRegistration(127.0.0.1:35226, datanodeUuid=2b5a1500-a27d-403f-b7e5-7837081de87c, infoPort=35351, infoSecurePort=0, ipcPort=45810, storageInfo=lv=-57;cid=testClusterID;nsid=662464899;c=1606979982896), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:19:53,046 [Thread-536] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:19:53,049 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x347903fb25958f34,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 40 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:19:53,049 [Listener at localhost/36982] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:53,049 [Listener at localhost/36982] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:53,049 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:53,091 [Thread-496] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:53,092 [Thread-496] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:53,116 [Thread-536] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 906@9ece31fe74eb
2020-12-03 07:19:53,154 [Thread-496] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=662464899;bpid=BP-464449197-172.17.0.6-1606979982896;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=662464899;c=1606979982896;bpid=BP-464449197-172.17.0.6-1606979982896;dnuuid=ba28613b-b481-4768-b4d4-cf44e7144ddf
2020-12-03 07:19:53,155 [IPC Server handler 9 on default port 34612] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:53,159 [Thread-496] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-0bb00b44-1a33-4c83-8050-95766856105e
2020-12-03 07:19:53,159 [Thread-496] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: DISK
2020-12-03 07:19:53,159 [Listener at localhost/36982] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:53,160 [Listener at localhost/36982] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:53,160 [Thread-496] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-0e3fa327-8df7-42f0-8bbd-411a1ebd4305
2020-12-03 07:19:53,160 [Thread-496] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: DISK
2020-12-03 07:19:53,161 [Thread-496] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:19:53,161 [Thread-496] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:19:53,162 [Thread-496] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:19:53,162 [Thread-496] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:19:53,162 [Thread-496] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:19:53,162 [Thread-496] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:53,163 [Thread-549] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:19:53,163 [Thread-550] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:19:53,166 [Thread-549] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-464449197-172.17.0.6-1606979982896/current: 24576
2020-12-03 07:19:53,166 [Thread-550] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-464449197-172.17.0.6-1606979982896/current: 24576
2020-12-03 07:19:53,176 [Thread-549] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-464449197-172.17.0.6-1606979982896 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 13ms
2020-12-03 07:19:53,177 [Thread-550] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-464449197-172.17.0.6-1606979982896 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 14ms
2020-12-03 07:19:53,177 [Thread-496] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-464449197-172.17.0.6-1606979982896: 14ms
2020-12-03 07:19:53,183 [Thread-551] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:19:53,183 [Thread-552] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:19:53,183 [Thread-551] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-464449197-172.17.0.6-1606979982896/current/replicas doesn't exist 
2020-12-03 07:19:53,183 [Thread-552] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-464449197-172.17.0.6-1606979982896/current/replicas doesn't exist 
2020-12-03 07:19:53,184 [Thread-551] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 1ms
2020-12-03 07:19:53,185 [Thread-552] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 1ms
2020-12-03 07:19:53,185 [Thread-496] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-464449197-172.17.0.6-1606979982896: 9ms
2020-12-03 07:19:53,186 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-0bb00b44-1a33-4c83-8050-95766856105e): no suitable block pools found to scan.  Waiting 1814395424 ms.
2020-12-03 07:19:53,186 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-0e3fa327-8df7-42f0-8bbd-411a1ebd4305): no suitable block pools found to scan.  Waiting 1814395424 ms.
2020-12-03 07:19:53,187 [Thread-496] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 9:05 AM with interval of 21600000ms
2020-12-03 07:19:53,189 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-464449197-172.17.0.6-1606979982896 (Datanode Uuid ba28613b-b481-4768-b4d4-cf44e7144ddf) service to localhost/127.0.0.1:34612 beginning handshake with NN
2020-12-03 07:19:53,190 [IPC Server handler 1 on default port 34612] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:33060, datanodeUuid=ba28613b-b481-4768-b4d4-cf44e7144ddf, infoPort=36743, infoSecurePort=0, ipcPort=40709, storageInfo=lv=-57;cid=testClusterID;nsid=662464899;c=1606979982896) storage ba28613b-b481-4768-b4d4-cf44e7144ddf
2020-12-03 07:19:53,190 [IPC Server handler 1 on default port 34612] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1078)) - BLOCK* registerDatanode: 127.0.0.1:37598 is replaced by DatanodeRegistration(127.0.0.1:33060, datanodeUuid=ba28613b-b481-4768-b4d4-cf44e7144ddf, infoPort=36743, infoSecurePort=0, ipcPort=40709, storageInfo=lv=-57;cid=testClusterID;nsid=662464899;c=1606979982896) with the same storageID ba28613b-b481-4768-b4d4-cf44e7144ddf
2020-12-03 07:19:53,190 [IPC Server handler 1 on default port 34612] INFO  net.NetworkTopology (NetworkTopology.java:remove(219)) - Removing a node: /default-rack/127.0.0.1:37598
2020-12-03 07:19:53,191 [IPC Server handler 1 on default port 34612] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:33060
2020-12-03 07:19:53,191 [IPC Server handler 1 on default port 34612] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateFailedStorage(562)) - [DISK]DS-0e3fa327-8df7-42f0-8bbd-411a1ebd4305:NORMAL:127.0.0.1:33060 failed.
2020-12-03 07:19:53,191 [IPC Server handler 1 on default port 34612] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateFailedStorage(562)) - [DISK]DS-0bb00b44-1a33-4c83-8050-95766856105e:NORMAL:127.0.0.1:33060 failed.
2020-12-03 07:19:53,191 [IPC Server handler 1 on default port 34612] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:pruneStorageMap(548)) - Removed storage [DISK]DS-0bb00b44-1a33-4c83-8050-95766856105e:FAILED:127.0.0.1:33060 from DataNode 127.0.0.1:33060
2020-12-03 07:19:53,191 [IPC Server handler 1 on default port 34612] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:pruneStorageMap(548)) - Removed storage [DISK]DS-0e3fa327-8df7-42f0-8bbd-411a1ebd4305:FAILED:127.0.0.1:33060 from DataNode 127.0.0.1:33060
2020-12-03 07:19:53,192 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-464449197-172.17.0.6-1606979982896 (Datanode Uuid ba28613b-b481-4768-b4d4-cf44e7144ddf) service to localhost/127.0.0.1:34612 successfully registered with NN
2020-12-03 07:19:53,192 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:34612 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:19:53,195 [IPC Server handler 4 on default port 34612] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-0bb00b44-1a33-4c83-8050-95766856105e for DN 127.0.0.1:33060
2020-12-03 07:19:53,195 [IPC Server handler 4 on default port 34612] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-0e3fa327-8df7-42f0-8bbd-411a1ebd4305 for DN 127.0.0.1:33060
2020-12-03 07:19:53,196 [IPC Server handler 4 on default port 34612] WARN  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:requestLease(230)) - DN ba28613b-b481-4768-b4d4-cf44e7144ddf (127.0.0.1:33060) requested a lease even though it wasn't yet registered.  Registering now.
2020-12-03 07:19:53,196 [IPC Server handler 4 on default port 34612] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN ba28613b-b481-4768-b4d4-cf44e7144ddf (127.0.0.1:33060).
2020-12-03 07:19:53,199 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x8a811fe4c8955e8d: Processing first storage report for DS-0e3fa327-8df7-42f0-8bbd-411a1ebd4305 from datanode ba28613b-b481-4768-b4d4-cf44e7144ddf
2020-12-03 07:19:53,200 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x8a811fe4c8955e8d: from storage DS-0e3fa327-8df7-42f0-8bbd-411a1ebd4305 node DatanodeRegistration(127.0.0.1:33060, datanodeUuid=ba28613b-b481-4768-b4d4-cf44e7144ddf, infoPort=36743, infoSecurePort=0, ipcPort=40709, storageInfo=lv=-57;cid=testClusterID;nsid=662464899;c=1606979982896), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:19:53,200 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x8a811fe4c8955e8d: Processing first storage report for DS-0bb00b44-1a33-4c83-8050-95766856105e from datanode ba28613b-b481-4768-b4d4-cf44e7144ddf
2020-12-03 07:19:53,200 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x8a811fe4c8955e8d: from storage DS-0bb00b44-1a33-4c83-8050-95766856105e node DatanodeRegistration(127.0.0.1:33060, datanodeUuid=ba28613b-b481-4768-b4d4-cf44e7144ddf, infoPort=36743, infoSecurePort=0, ipcPort=40709, storageInfo=lv=-57;cid=testClusterID;nsid=662464899;c=1606979982896), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:19:53,203 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x8a811fe4c8955e8d,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:19:53,203 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:53,221 [Thread-536] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 906@9ece31fe74eb
2020-12-03 07:19:53,262 [IPC Server handler 2 on default port 34612] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:53,264 [Listener at localhost/36982] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:53,264 [Listener at localhost/36982] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:53,268 [Thread-536] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:53,269 [Thread-536] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:53,325 [Thread-536] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:53,326 [Thread-536] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:53,355 [Thread-536] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=662464899;bpid=BP-464449197-172.17.0.6-1606979982896;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=662464899;c=1606979982896;bpid=BP-464449197-172.17.0.6-1606979982896;dnuuid=ec6135ad-ddf0-47a2-866e-c2a0a646b3ea
2020-12-03 07:19:53,359 [Thread-536] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-9c05f2e3-34b6-4594-b06f-9365cd2a0a2f
2020-12-03 07:19:53,359 [Thread-536] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-12-03 07:19:53,366 [Thread-536] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-cd676010-abda-483c-a6ea-b69676538fc2
2020-12-03 07:19:53,366 [Thread-536] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-12-03 07:19:53,366 [Thread-536] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:19:53,367 [IPC Server handler 5 on default port 34612] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:53,372 [Thread-536] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:19:53,372 [Thread-536] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:19:53,373 [Thread-536] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:19:53,373 [Thread-536] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:19:53,374 [Thread-536] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:53,375 [Listener at localhost/36982] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:53,375 [Listener at localhost/36982] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:53,375 [Thread-558] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:19:53,375 [Thread-559] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:19:53,377 [Thread-558] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-464449197-172.17.0.6-1606979982896/current: 24576
2020-12-03 07:19:53,377 [Thread-559] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-464449197-172.17.0.6-1606979982896/current: 24576
2020-12-03 07:19:53,386 [Thread-558] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-464449197-172.17.0.6-1606979982896 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 11ms
2020-12-03 07:19:53,389 [Thread-559] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-464449197-172.17.0.6-1606979982896 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 14ms
2020-12-03 07:19:53,390 [Thread-536] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-464449197-172.17.0.6-1606979982896: 15ms
2020-12-03 07:19:53,390 [Thread-560] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:19:53,390 [Thread-561] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:19:53,390 [Thread-560] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-464449197-172.17.0.6-1606979982896/current/replicas doesn't exist 
2020-12-03 07:19:53,390 [Thread-561] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-464449197-172.17.0.6-1606979982896/current/replicas doesn't exist 
2020-12-03 07:19:53,391 [Thread-560] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 0ms
2020-12-03 07:19:53,392 [Thread-561] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-464449197-172.17.0.6-1606979982896 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 1ms
2020-12-03 07:19:53,392 [Thread-536] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-464449197-172.17.0.6-1606979982896: 2ms
2020-12-03 07:19:53,393 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-9c05f2e3-34b6-4594-b06f-9365cd2a0a2f): no suitable block pools found to scan.  Waiting 1814395218 ms.
2020-12-03 07:19:53,394 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-cd676010-abda-483c-a6ea-b69676538fc2): no suitable block pools found to scan.  Waiting 1814395217 ms.
2020-12-03 07:19:53,394 [Thread-536] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 7:46 AM with interval of 21600000ms
2020-12-03 07:19:53,396 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-464449197-172.17.0.6-1606979982896 (Datanode Uuid ec6135ad-ddf0-47a2-866e-c2a0a646b3ea) service to localhost/127.0.0.1:34612 beginning handshake with NN
2020-12-03 07:19:53,397 [IPC Server handler 8 on default port 34612] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:45400, datanodeUuid=ec6135ad-ddf0-47a2-866e-c2a0a646b3ea, infoPort=41348, infoSecurePort=0, ipcPort=36982, storageInfo=lv=-57;cid=testClusterID;nsid=662464899;c=1606979982896) storage ec6135ad-ddf0-47a2-866e-c2a0a646b3ea
2020-12-03 07:19:53,398 [IPC Server handler 8 on default port 34612] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1078)) - BLOCK* registerDatanode: 127.0.0.1:41902 is replaced by DatanodeRegistration(127.0.0.1:45400, datanodeUuid=ec6135ad-ddf0-47a2-866e-c2a0a646b3ea, infoPort=41348, infoSecurePort=0, ipcPort=36982, storageInfo=lv=-57;cid=testClusterID;nsid=662464899;c=1606979982896) with the same storageID ec6135ad-ddf0-47a2-866e-c2a0a646b3ea
2020-12-03 07:19:53,398 [IPC Server handler 8 on default port 34612] INFO  net.NetworkTopology (NetworkTopology.java:remove(219)) - Removing a node: /default-rack/127.0.0.1:41902
2020-12-03 07:19:53,398 [IPC Server handler 8 on default port 34612] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:45400
2020-12-03 07:19:53,398 [IPC Server handler 8 on default port 34612] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateFailedStorage(562)) - [DISK]DS-9c05f2e3-34b6-4594-b06f-9365cd2a0a2f:NORMAL:127.0.0.1:45400 failed.
2020-12-03 07:19:53,398 [IPC Server handler 8 on default port 34612] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateFailedStorage(562)) - [DISK]DS-cd676010-abda-483c-a6ea-b69676538fc2:NORMAL:127.0.0.1:45400 failed.
2020-12-03 07:19:53,398 [IPC Server handler 8 on default port 34612] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:pruneStorageMap(548)) - Removed storage [DISK]DS-9c05f2e3-34b6-4594-b06f-9365cd2a0a2f:FAILED:127.0.0.1:45400 from DataNode 127.0.0.1:45400
2020-12-03 07:19:53,398 [IPC Server handler 8 on default port 34612] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:pruneStorageMap(548)) - Removed storage [DISK]DS-cd676010-abda-483c-a6ea-b69676538fc2:FAILED:127.0.0.1:45400 from DataNode 127.0.0.1:45400
2020-12-03 07:19:53,399 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-464449197-172.17.0.6-1606979982896 (Datanode Uuid ec6135ad-ddf0-47a2-866e-c2a0a646b3ea) service to localhost/127.0.0.1:34612 successfully registered with NN
2020-12-03 07:19:53,400 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:34612 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:19:53,402 [IPC Server handler 7 on default port 34612] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-9c05f2e3-34b6-4594-b06f-9365cd2a0a2f for DN 127.0.0.1:45400
2020-12-03 07:19:53,402 [IPC Server handler 7 on default port 34612] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-cd676010-abda-483c-a6ea-b69676538fc2 for DN 127.0.0.1:45400
2020-12-03 07:19:53,403 [IPC Server handler 7 on default port 34612] WARN  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:requestLease(230)) - DN ec6135ad-ddf0-47a2-866e-c2a0a646b3ea (127.0.0.1:45400) requested a lease even though it wasn't yet registered.  Registering now.
2020-12-03 07:19:53,403 [IPC Server handler 7 on default port 34612] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN ec6135ad-ddf0-47a2-866e-c2a0a646b3ea (127.0.0.1:45400).
2020-12-03 07:19:53,405 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x39c8a4e55ec7b7f7: Processing first storage report for DS-9c05f2e3-34b6-4594-b06f-9365cd2a0a2f from datanode ec6135ad-ddf0-47a2-866e-c2a0a646b3ea
2020-12-03 07:19:53,405 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x39c8a4e55ec7b7f7: from storage DS-9c05f2e3-34b6-4594-b06f-9365cd2a0a2f node DatanodeRegistration(127.0.0.1:45400, datanodeUuid=ec6135ad-ddf0-47a2-866e-c2a0a646b3ea, infoPort=41348, infoSecurePort=0, ipcPort=36982, storageInfo=lv=-57;cid=testClusterID;nsid=662464899;c=1606979982896), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:19:53,405 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x39c8a4e55ec7b7f7: Processing first storage report for DS-cd676010-abda-483c-a6ea-b69676538fc2 from datanode ec6135ad-ddf0-47a2-866e-c2a0a646b3ea
2020-12-03 07:19:53,405 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x39c8a4e55ec7b7f7: from storage DS-cd676010-abda-483c-a6ea-b69676538fc2 node DatanodeRegistration(127.0.0.1:45400, datanodeUuid=ec6135ad-ddf0-47a2-866e-c2a0a646b3ea, infoPort=41348, infoSecurePort=0, ipcPort=36982, storageInfo=lv=-57;cid=testClusterID;nsid=662464899;c=1606979982896), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:19:53,406 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x39c8a4e55ec7b7f7,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:19:53,406 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:19:53,478 [IPC Server handler 6 on default port 34612] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:53,479 [Listener at localhost/36982] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:19:53,562 [IPC Server handler 9 on default port 34612] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/f0	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:19:53,638 [IPC Server handler 1 on default port 34612] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:33060, 127.0.0.1:39367, 127.0.0.1:42420 for /f0
2020-12-03 07:19:53,664 [Thread-565] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:53,761 [DataXceiver for client DFSClient_NONMAPREDUCE_-609930347_1 at /127.0.0.1:51926 [Receiving block BP-464449197-172.17.0.6-1606979982896:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-464449197-172.17.0.6-1606979982896:blk_1073741825_1001 src: /127.0.0.1:51926 dest: /127.0.0.1:33060
2020-12-03 07:19:53,788 [DataXceiver for client DFSClient_NONMAPREDUCE_-609930347_1 at /127.0.0.1:51926 [Receiving block BP-464449197-172.17.0.6-1606979982896:blk_1073741825_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:53,794 [DataXceiver for client DFSClient_NONMAPREDUCE_-609930347_1 at /127.0.0.1:42178 [Receiving block BP-464449197-172.17.0.6-1606979982896:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-464449197-172.17.0.6-1606979982896:blk_1073741825_1001 src: /127.0.0.1:42178 dest: /127.0.0.1:39367
2020-12-03 07:19:53,797 [DataXceiver for client DFSClient_NONMAPREDUCE_-609930347_1 at /127.0.0.1:42178 [Receiving block BP-464449197-172.17.0.6-1606979982896:blk_1073741825_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:53,801 [DataXceiver for client DFSClient_NONMAPREDUCE_-609930347_1 at /127.0.0.1:59112 [Receiving block BP-464449197-172.17.0.6-1606979982896:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-464449197-172.17.0.6-1606979982896:blk_1073741825_1001 src: /127.0.0.1:59112 dest: /127.0.0.1:42420
2020-12-03 07:19:54,047 [IPC Server handler 5 on default port 34612] INFO  hdfs.StateChange (FSNamesystem.java:fsync(3361)) - BLOCK* fsync: /f0 for DFSClient_NONMAPREDUCE_-609930347_1
2020-12-03 07:19:54,052 [IPC Server handler 8 on default port 34612] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/f1	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:19:54,068 [IPC Server handler 7 on default port 34612] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741826_1002, replicas=127.0.0.1:35235, 127.0.0.1:42420, 127.0.0.1:42173 for /f1
2020-12-03 07:19:54,095 [Thread-574] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:54,099 [DataXceiver for client DFSClient_NONMAPREDUCE_-609930347_1 at /127.0.0.1:57578 [Receiving block BP-464449197-172.17.0.6-1606979982896:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-464449197-172.17.0.6-1606979982896:blk_1073741826_1002 src: /127.0.0.1:57578 dest: /127.0.0.1:35235
2020-12-03 07:19:54,101 [DataXceiver for client DFSClient_NONMAPREDUCE_-609930347_1 at /127.0.0.1:57578 [Receiving block BP-464449197-172.17.0.6-1606979982896:blk_1073741826_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:54,112 [DataXceiver for client DFSClient_NONMAPREDUCE_-609930347_1 at /127.0.0.1:59116 [Receiving block BP-464449197-172.17.0.6-1606979982896:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-464449197-172.17.0.6-1606979982896:blk_1073741826_1002 src: /127.0.0.1:59116 dest: /127.0.0.1:42420
2020-12-03 07:19:54,114 [DataXceiver for client DFSClient_NONMAPREDUCE_-609930347_1 at /127.0.0.1:59116 [Receiving block BP-464449197-172.17.0.6-1606979982896:blk_1073741826_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:54,118 [DataXceiver for client DFSClient_NONMAPREDUCE_-609930347_1 at /127.0.0.1:44294 [Receiving block BP-464449197-172.17.0.6-1606979982896:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-464449197-172.17.0.6-1606979982896:blk_1073741826_1002 src: /127.0.0.1:44294 dest: /127.0.0.1:42173
2020-12-03 07:19:54,327 [IPC Server handler 0 on default port 34612] INFO  hdfs.StateChange (FSNamesystem.java:fsync(3361)) - BLOCK* fsync: /f1 for DFSClient_NONMAPREDUCE_-609930347_1
2020-12-03 07:19:54,334 [IPC Server handler 6 on default port 34612] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/f2	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:19:54,344 [IPC Server handler 9 on default port 34612] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741827_1003, replicas=127.0.0.1:43233, 127.0.0.1:42420, 127.0.0.1:35226 for /f2
2020-12-03 07:19:54,349 [Thread-582] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:54,354 [DataXceiver for client DFSClient_NONMAPREDUCE_-609930347_1 at /127.0.0.1:38200 [Receiving block BP-464449197-172.17.0.6-1606979982896:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-464449197-172.17.0.6-1606979982896:blk_1073741827_1003 src: /127.0.0.1:38200 dest: /127.0.0.1:43233
2020-12-03 07:19:54,355 [DataXceiver for client DFSClient_NONMAPREDUCE_-609930347_1 at /127.0.0.1:38200 [Receiving block BP-464449197-172.17.0.6-1606979982896:blk_1073741827_1003]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:54,368 [DataXceiver for client DFSClient_NONMAPREDUCE_-609930347_1 at /127.0.0.1:59122 [Receiving block BP-464449197-172.17.0.6-1606979982896:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-464449197-172.17.0.6-1606979982896:blk_1073741827_1003 src: /127.0.0.1:59122 dest: /127.0.0.1:42420
2020-12-03 07:19:54,369 [DataXceiver for client DFSClient_NONMAPREDUCE_-609930347_1 at /127.0.0.1:59122 [Receiving block BP-464449197-172.17.0.6-1606979982896:blk_1073741827_1003]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:54,384 [DataXceiver for client DFSClient_NONMAPREDUCE_-609930347_1 at /127.0.0.1:60122 [Receiving block BP-464449197-172.17.0.6-1606979982896:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-464449197-172.17.0.6-1606979982896:blk_1073741827_1003 src: /127.0.0.1:60122 dest: /127.0.0.1:35226
2020-12-03 07:19:54,642 [IPC Server handler 5 on default port 34612] INFO  hdfs.StateChange (FSNamesystem.java:fsync(3361)) - BLOCK* fsync: /f2 for DFSClient_NONMAPREDUCE_-609930347_1
2020-12-03 07:19:54,661 [IPC Server handler 8 on default port 34612] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/f3	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:19:54,672 [IPC Server handler 7 on default port 34612] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741828_1004, replicas=127.0.0.1:45400, 127.0.0.1:43233, 127.0.0.1:39367 for /f3
2020-12-03 07:19:54,677 [Thread-590] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:54,681 [DataXceiver for client DFSClient_NONMAPREDUCE_-609930347_1 at /127.0.0.1:57644 [Receiving block BP-464449197-172.17.0.6-1606979982896:blk_1073741828_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-464449197-172.17.0.6-1606979982896:blk_1073741828_1004 src: /127.0.0.1:57644 dest: /127.0.0.1:45400
2020-12-03 07:19:54,682 [DataXceiver for client DFSClient_NONMAPREDUCE_-609930347_1 at /127.0.0.1:57644 [Receiving block BP-464449197-172.17.0.6-1606979982896:blk_1073741828_1004]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:54,686 [DataXceiver for client DFSClient_NONMAPREDUCE_-609930347_1 at /127.0.0.1:38208 [Receiving block BP-464449197-172.17.0.6-1606979982896:blk_1073741828_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-464449197-172.17.0.6-1606979982896:blk_1073741828_1004 src: /127.0.0.1:38208 dest: /127.0.0.1:43233
2020-12-03 07:19:54,688 [DataXceiver for client DFSClient_NONMAPREDUCE_-609930347_1 at /127.0.0.1:38208 [Receiving block BP-464449197-172.17.0.6-1606979982896:blk_1073741828_1004]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:54,692 [DataXceiver for client DFSClient_NONMAPREDUCE_-609930347_1 at /127.0.0.1:42198 [Receiving block BP-464449197-172.17.0.6-1606979982896:blk_1073741828_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-464449197-172.17.0.6-1606979982896:blk_1073741828_1004 src: /127.0.0.1:42198 dest: /127.0.0.1:39367
2020-12-03 07:19:54,851 [IPC Server handler 0 on default port 34612] INFO  hdfs.StateChange (FSNamesystem.java:fsync(3361)) - BLOCK* fsync: /f3 for DFSClient_NONMAPREDUCE_-609930347_1
2020-12-03 07:19:54,855 [IPC Server handler 6 on default port 34612] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/f4	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:19:54,869 [IPC Server handler 9 on default port 34612] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741829_1005, replicas=127.0.0.1:42173, 127.0.0.1:39367, 127.0.0.1:45400 for /f4
2020-12-03 07:19:54,881 [Thread-598] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:54,884 [DataXceiver for client DFSClient_NONMAPREDUCE_-609930347_1 at /127.0.0.1:44308 [Receiving block BP-464449197-172.17.0.6-1606979982896:blk_1073741829_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-464449197-172.17.0.6-1606979982896:blk_1073741829_1005 src: /127.0.0.1:44308 dest: /127.0.0.1:42173
2020-12-03 07:19:54,886 [DataXceiver for client DFSClient_NONMAPREDUCE_-609930347_1 at /127.0.0.1:44308 [Receiving block BP-464449197-172.17.0.6-1606979982896:blk_1073741829_1005]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:54,895 [DataXceiver for client DFSClient_NONMAPREDUCE_-609930347_1 at /127.0.0.1:42202 [Receiving block BP-464449197-172.17.0.6-1606979982896:blk_1073741829_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-464449197-172.17.0.6-1606979982896:blk_1073741829_1005 src: /127.0.0.1:42202 dest: /127.0.0.1:39367
2020-12-03 07:19:54,897 [DataXceiver for client DFSClient_NONMAPREDUCE_-609930347_1 at /127.0.0.1:42202 [Receiving block BP-464449197-172.17.0.6-1606979982896:blk_1073741829_1005]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:54,900 [DataXceiver for client DFSClient_NONMAPREDUCE_-609930347_1 at /127.0.0.1:57654 [Receiving block BP-464449197-172.17.0.6-1606979982896:blk_1073741829_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-464449197-172.17.0.6-1606979982896:blk_1073741829_1005 src: /127.0.0.1:57654 dest: /127.0.0.1:45400
2020-12-03 07:19:55,067 [IPC Server handler 1 on default port 34612] INFO  hdfs.StateChange (FSNamesystem.java:fsync(3361)) - BLOCK* fsync: /f4 for DFSClient_NONMAPREDUCE_-609930347_1
2020-12-03 07:19:55,975 [Listener at localhost/36982] INFO  blockmanagement.DatanodeAdminManager (DatanodeAdminManager.java:startDecommission(216)) - Starting decommission of 127.0.0.1:39367 [DISK]DS-a91ecbc1-38a0-4aee-a8bb-57f2ff2f9937:NORMAL:127.0.0.1:39367 with 0 blocks
2020-12-03 07:19:55,975 [Listener at localhost/36982] INFO  blockmanagement.DatanodeAdminManager (DatanodeAdminManager.java:startDecommission(216)) - Starting decommission of 127.0.0.1:39367 [DISK]DS-3a17eb31-b33e-4a9a-a80f-9b182d8e1248:NORMAL:127.0.0.1:39367 with 0 blocks
2020-12-03 07:19:56,176 [Listener at localhost/36982] INFO  blockmanagement.HeartbeatManager (HeartbeatManager.java:startMaintenance(281)) - MinReplicationToBeInMaintenance is set to zero. 127.0.0.1:42420 is put in maintenance state immediately.
2020-12-03 07:19:56,377 [Listener at localhost/36982] INFO  blockmanagement.DatanodeAdminManager (DatanodeAdminManager.java:startDecommission(216)) - Starting decommission of 127.0.0.1:35235 [DISK]DS-e89d6108-2324-4b34-addb-9670aed7d37d:NORMAL:127.0.0.1:35235 with 0 blocks
2020-12-03 07:19:56,377 [Listener at localhost/36982] INFO  blockmanagement.DatanodeAdminManager (DatanodeAdminManager.java:startDecommission(216)) - Starting decommission of 127.0.0.1:35235 [DISK]DS-3571474c-359b-4f98-94a4-8b83a1d0652c:NORMAL:127.0.0.1:35235 with 0 blocks
2020-12-03 07:19:56,628 [PacketResponder: BP-464449197-172.17.0.6-1606979982896:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59112, dest: /127.0.0.1:42420, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-609930347_1, offset: 0, srvID: baa99858-a351-4f23-95d3-417a6368fdb3, blockid: BP-464449197-172.17.0.6-1606979982896:blk_1073741825_1001, duration(ns): 2798580464
2020-12-03 07:19:56,629 [PacketResponder: BP-464449197-172.17.0.6-1606979982896:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-464449197-172.17.0.6-1606979982896:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:56,632 [PacketResponder: BP-464449197-172.17.0.6-1606979982896:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42420]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:42178, dest: /127.0.0.1:39367, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-609930347_1, offset: 0, srvID: 1840bbdd-b765-44bd-8c75-9f95ec61318d, blockid: BP-464449197-172.17.0.6-1606979982896:blk_1073741825_1001, duration(ns): 2805228260
2020-12-03 07:19:56,651 [PacketResponder: BP-464449197-172.17.0.6-1606979982896:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42420]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-464449197-172.17.0.6-1606979982896:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42420] terminating
2020-12-03 07:19:56,661 [PacketResponder: BP-464449197-172.17.0.6-1606979982896:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:39367, 127.0.0.1:42420]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:51926, dest: /127.0.0.1:33060, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-609930347_1, offset: 0, srvID: ba28613b-b481-4768-b4d4-cf44e7144ddf, blockid: BP-464449197-172.17.0.6-1606979982896:blk_1073741825_1001, duration(ns): 2831513900
2020-12-03 07:19:56,661 [PacketResponder: BP-464449197-172.17.0.6-1606979982896:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:39367, 127.0.0.1:42420]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-464449197-172.17.0.6-1606979982896:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:39367, 127.0.0.1:42420] terminating
2020-12-03 07:19:56,682 [IPC Server handler 5 on default port 34612] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /f0 is closed by DFSClient_NONMAPREDUCE_-609930347_1
2020-12-03 07:19:57,610 [PacketResponder: BP-464449197-172.17.0.6-1606979982896:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:44294, dest: /127.0.0.1:42173, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-609930347_1, offset: 0, srvID: 309f7fa0-0c59-4920-a6f9-56c2485276d8, blockid: BP-464449197-172.17.0.6-1606979982896:blk_1073741826_1002, duration(ns): 3486665628
2020-12-03 07:19:57,611 [PacketResponder: BP-464449197-172.17.0.6-1606979982896:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-464449197-172.17.0.6-1606979982896:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:57,626 [PacketResponder: BP-464449197-172.17.0.6-1606979982896:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42173]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59116, dest: /127.0.0.1:42420, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-609930347_1, offset: 0, srvID: baa99858-a351-4f23-95d3-417a6368fdb3, blockid: BP-464449197-172.17.0.6-1606979982896:blk_1073741826_1002, duration(ns): 3495184564
2020-12-03 07:19:57,626 [PacketResponder: BP-464449197-172.17.0.6-1606979982896:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42173]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-464449197-172.17.0.6-1606979982896:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42173] terminating
2020-12-03 07:19:57,636 [PacketResponder: BP-464449197-172.17.0.6-1606979982896:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42420, 127.0.0.1:42173]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57578, dest: /127.0.0.1:35235, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-609930347_1, offset: 0, srvID: edec627a-465f-4532-ab74-3f78e8a40769, blockid: BP-464449197-172.17.0.6-1606979982896:blk_1073741826_1002, duration(ns): 3498831994
2020-12-03 07:19:57,636 [PacketResponder: BP-464449197-172.17.0.6-1606979982896:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42420, 127.0.0.1:42173]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-464449197-172.17.0.6-1606979982896:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42420, 127.0.0.1:42173] terminating
2020-12-03 07:19:57,647 [IPC Server handler 7 on default port 34612] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /f1 is closed by DFSClient_NONMAPREDUCE_-609930347_1
2020-12-03 07:19:57,743 [DatanodeAdminMonitor-0] INFO  BlockStateChange (DatanodeAdminManager.java:logBlockReplicationInfo(407)) - Block: blk_1073741826_1002, Expected Replicas: 3, live replicas: 1, corrupt replicas: 0, decommissioned replicas: 0, decommissioning replicas: 1, maintenance replicas: 1, live entering maintenance replicas: 0, excess replicas: 0, Is Open File: false, Datanodes having this block: 127.0.0.1:42173 127.0.0.1:42420 127.0.0.1:35235 , Current Datanode: 127.0.0.1:35235, Is current datanode decommissioning: true, Is current datanode entering maintenance: false
2020-12-03 07:19:57,745 [DatanodeAdminMonitor-0] INFO  BlockStateChange (DatanodeAdminManager.java:logBlockReplicationInfo(407)) - Block: blk_1073741825_1001, Expected Replicas: 3, live replicas: 1, corrupt replicas: 0, decommissioned replicas: 0, decommissioning replicas: 1, maintenance replicas: 1, live entering maintenance replicas: 0, excess replicas: 0, Is Open File: false, Datanodes having this block: 127.0.0.1:42420 127.0.0.1:39367 127.0.0.1:33060 , Current Datanode: 127.0.0.1:39367, Is current datanode decommissioning: true, Is current datanode entering maintenance: false
2020-12-03 07:19:57,746 [DatanodeAdminMonitor-0] INFO  blockmanagement.DatanodeAdminManager (DatanodeAdminManager.java:run(510)) - Checked 2 blocks and 3 nodes this tick
2020-12-03 07:19:57,878 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (DataNode.java:transferBlock(2358)) - DatanodeRegistration(127.0.0.1:35235, datanodeUuid=edec627a-465f-4532-ab74-3f78e8a40769, infoPort=45934, infoSecurePort=0, ipcPort=43944, storageInfo=lv=-57;cid=testClusterID;nsid=662464899;c=1606979982896) Starting thread to transfer BP-464449197-172.17.0.6-1606979982896:blk_1073741826_1002 to 127.0.0.1:43233 
2020-12-03 07:19:57,886 [org.apache.hadoop.hdfs.server.datanode.DataNode$DataTransfer@50835001] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:57,905 [DataXceiver for client  at /127.0.0.1:38218 [Receiving block BP-464449197-172.17.0.6-1606979982896:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-464449197-172.17.0.6-1606979982896:blk_1073741826_1002 src: /127.0.0.1:38218 dest: /127.0.0.1:43233
2020-12-03 07:19:57,908 [org.apache.hadoop.hdfs.server.datanode.DataNode$DataTransfer@50835001] INFO  datanode.DataNode (DataNode.java:run(2571)) - DataTransfer, at 127.0.0.1:35235: Transmitted BP-464449197-172.17.0.6-1606979982896:blk_1073741826_1002 (numBytes=1) to /127.0.0.1:43233
2020-12-03 07:19:57,913 [DataXceiver for client  at /127.0.0.1:38218 [Receiving block BP-464449197-172.17.0.6-1606979982896:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(931)) - Received BP-464449197-172.17.0.6-1606979982896:blk_1073741826_1002 src: /127.0.0.1:38218 dest: /127.0.0.1:43233 of size 1
2020-12-03 07:19:58,567 [PacketResponder: BP-464449197-172.17.0.6-1606979982896:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60122, dest: /127.0.0.1:35226, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-609930347_1, offset: 0, srvID: 2b5a1500-a27d-403f-b7e5-7837081de87c, blockid: BP-464449197-172.17.0.6-1606979982896:blk_1073741827_1003, duration(ns): 4150615201
2020-12-03 07:19:58,568 [PacketResponder: BP-464449197-172.17.0.6-1606979982896:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-464449197-172.17.0.6-1606979982896:blk_1073741827_1003, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:58,584 [PacketResponder: BP-464449197-172.17.0.6-1606979982896:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:35226]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59122, dest: /127.0.0.1:42420, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-609930347_1, offset: 0, srvID: baa99858-a351-4f23-95d3-417a6368fdb3, blockid: BP-464449197-172.17.0.6-1606979982896:blk_1073741827_1003, duration(ns): 4157194079
2020-12-03 07:19:58,585 [PacketResponder: BP-464449197-172.17.0.6-1606979982896:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:35226]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-464449197-172.17.0.6-1606979982896:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:35226] terminating
2020-12-03 07:19:58,587 [PacketResponder: BP-464449197-172.17.0.6-1606979982896:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42420, 127.0.0.1:35226]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38200, dest: /127.0.0.1:43233, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-609930347_1, offset: 0, srvID: 01c12b1d-d7d2-421e-986c-c593ac806eae, blockid: BP-464449197-172.17.0.6-1606979982896:blk_1073741827_1003, duration(ns): 4174036161
2020-12-03 07:19:58,587 [PacketResponder: BP-464449197-172.17.0.6-1606979982896:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42420, 127.0.0.1:35226]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-464449197-172.17.0.6-1606979982896:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42420, 127.0.0.1:35226] terminating
2020-12-03 07:19:58,590 [IPC Server handler 9 on default port 34612] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /f2 is closed by DFSClient_NONMAPREDUCE_-609930347_1
2020-12-03 07:19:58,608 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (DataNode.java:transferBlock(2358)) - DatanodeRegistration(127.0.0.1:39367, datanodeUuid=1840bbdd-b765-44bd-8c75-9f95ec61318d, infoPort=46306, infoSecurePort=0, ipcPort=41846, storageInfo=lv=-57;cid=testClusterID;nsid=662464899;c=1606979982896) Starting thread to transfer BP-464449197-172.17.0.6-1606979982896:blk_1073741825_1001 to 127.0.0.1:35226 
2020-12-03 07:19:58,616 [org.apache.hadoop.hdfs.server.datanode.DataNode$DataTransfer@8edc4a2] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:58,621 [org.apache.hadoop.hdfs.server.datanode.DataNode$DataTransfer@8edc4a2] INFO  datanode.DataNode (DataNode.java:run(2571)) - DataTransfer, at 127.0.0.1:39367: Transmitted BP-464449197-172.17.0.6-1606979982896:blk_1073741825_1001 (numBytes=1) to /127.0.0.1:35226
2020-12-03 07:19:58,628 [DataXceiver for client  at /127.0.0.1:60138 [Receiving block BP-464449197-172.17.0.6-1606979982896:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-464449197-172.17.0.6-1606979982896:blk_1073741825_1001 src: /127.0.0.1:60138 dest: /127.0.0.1:35226
2020-12-03 07:19:58,631 [DataXceiver for client  at /127.0.0.1:60138 [Receiving block BP-464449197-172.17.0.6-1606979982896:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(931)) - Received BP-464449197-172.17.0.6-1606979982896:blk_1073741825_1001 src: /127.0.0.1:60138 dest: /127.0.0.1:35226 of size 1
2020-12-03 07:19:59,510 [PacketResponder: BP-464449197-172.17.0.6-1606979982896:blk_1073741828_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:42198, dest: /127.0.0.1:39367, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-609930347_1, offset: 0, srvID: 1840bbdd-b765-44bd-8c75-9f95ec61318d, blockid: BP-464449197-172.17.0.6-1606979982896:blk_1073741828_1004, duration(ns): 4815098767
2020-12-03 07:19:59,512 [PacketResponder: BP-464449197-172.17.0.6-1606979982896:blk_1073741828_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-464449197-172.17.0.6-1606979982896:blk_1073741828_1004, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:59,516 [PacketResponder: BP-464449197-172.17.0.6-1606979982896:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:39367]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38208, dest: /127.0.0.1:43233, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-609930347_1, offset: 0, srvID: 01c12b1d-d7d2-421e-986c-c593ac806eae, blockid: BP-464449197-172.17.0.6-1606979982896:blk_1073741828_1004, duration(ns): 4815366729
2020-12-03 07:19:59,516 [PacketResponder: BP-464449197-172.17.0.6-1606979982896:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:39367]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-464449197-172.17.0.6-1606979982896:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:39367] terminating
2020-12-03 07:19:59,520 [PacketResponder: BP-464449197-172.17.0.6-1606979982896:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:43233, 127.0.0.1:39367]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57644, dest: /127.0.0.1:45400, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-609930347_1, offset: 0, srvID: ec6135ad-ddf0-47a2-866e-c2a0a646b3ea, blockid: BP-464449197-172.17.0.6-1606979982896:blk_1073741828_1004, duration(ns): 4813671508
2020-12-03 07:19:59,521 [PacketResponder: BP-464449197-172.17.0.6-1606979982896:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:43233, 127.0.0.1:39367]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-464449197-172.17.0.6-1606979982896:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:43233, 127.0.0.1:39367] terminating
2020-12-03 07:19:59,525 [IPC Server handler 4 on default port 34612] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /f3 is closed by DFSClient_NONMAPREDUCE_-609930347_1
2020-12-03 07:20:00,442 [PacketResponder: BP-464449197-172.17.0.6-1606979982896:blk_1073741829_1005, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57654, dest: /127.0.0.1:45400, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-609930347_1, offset: 0, srvID: ec6135ad-ddf0-47a2-866e-c2a0a646b3ea, blockid: BP-464449197-172.17.0.6-1606979982896:blk_1073741829_1005, duration(ns): 5533032352
2020-12-03 07:20:00,442 [PacketResponder: BP-464449197-172.17.0.6-1606979982896:blk_1073741829_1005, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-464449197-172.17.0.6-1606979982896:blk_1073741829_1005, type=LAST_IN_PIPELINE terminating
2020-12-03 07:20:00,445 [PacketResponder: BP-464449197-172.17.0.6-1606979982896:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:45400]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:42202, dest: /127.0.0.1:39367, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-609930347_1, offset: 0, srvID: 1840bbdd-b765-44bd-8c75-9f95ec61318d, blockid: BP-464449197-172.17.0.6-1606979982896:blk_1073741829_1005, duration(ns): 5536265624
2020-12-03 07:20:00,445 [PacketResponder: BP-464449197-172.17.0.6-1606979982896:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:45400]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-464449197-172.17.0.6-1606979982896:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:45400] terminating
2020-12-03 07:20:00,450 [PacketResponder: BP-464449197-172.17.0.6-1606979982896:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:39367, 127.0.0.1:45400]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:44308, dest: /127.0.0.1:42173, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-609930347_1, offset: 0, srvID: 309f7fa0-0c59-4920-a6f9-56c2485276d8, blockid: BP-464449197-172.17.0.6-1606979982896:blk_1073741829_1005, duration(ns): 5531767355
2020-12-03 07:20:00,450 [PacketResponder: BP-464449197-172.17.0.6-1606979982896:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:39367, 127.0.0.1:45400]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-464449197-172.17.0.6-1606979982896:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:39367, 127.0.0.1:45400] terminating
2020-12-03 07:20:00,455 [IPC Server handler 5 on default port 34612] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /f4 is closed by DFSClient_NONMAPREDUCE_-609930347_1
2020-12-03 07:20:00,739 [DatanodeAdminMonitor-0] INFO  blockmanagement.DatanodeAdminManager (DatanodeAdminManager.java:setDecommissioned(332)) - Decommissioning complete for node 127.0.0.1:35235
2020-12-03 07:20:00,740 [DatanodeAdminMonitor-0] INFO  BlockStateChange (DatanodeAdminManager.java:logBlockReplicationInfo(407)) - Block: blk_1073741828_1004, Expected Replicas: 3, live replicas: 2, corrupt replicas: 0, decommissioned replicas: 0, decommissioning replicas: 1, maintenance replicas: 0, live entering maintenance replicas: 0, excess replicas: 0, Is Open File: false, Datanodes having this block: 127.0.0.1:39367 127.0.0.1:43233 127.0.0.1:45400 , Current Datanode: 127.0.0.1:39367, Is current datanode decommissioning: true, Is current datanode entering maintenance: false
2020-12-03 07:20:00,740 [DatanodeAdminMonitor-0] INFO  blockmanagement.DatanodeAdminManager (DatanodeAdminManager.java:run(510)) - Checked 6 blocks and 3 nodes this tick
2020-12-03 07:20:00,768 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (DataNode.java:transferBlock(2358)) - DatanodeRegistration(127.0.0.1:42173, datanodeUuid=309f7fa0-0c59-4920-a6f9-56c2485276d8, infoPort=35777, infoSecurePort=0, ipcPort=42345, storageInfo=lv=-57;cid=testClusterID;nsid=662464899;c=1606979982896) Starting thread to transfer BP-464449197-172.17.0.6-1606979982896:blk_1073741829_1005 to 127.0.0.1:35226 
2020-12-03 07:20:00,770 [org.apache.hadoop.hdfs.server.datanode.DataNode$DataTransfer@20e4c35c] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:00,772 [DataXceiver for client  at /127.0.0.1:60140 [Receiving block BP-464449197-172.17.0.6-1606979982896:blk_1073741829_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-464449197-172.17.0.6-1606979982896:blk_1073741829_1005 src: /127.0.0.1:60140 dest: /127.0.0.1:35226
2020-12-03 07:20:00,772 [org.apache.hadoop.hdfs.server.datanode.DataNode$DataTransfer@20e4c35c] INFO  datanode.DataNode (DataNode.java:run(2571)) - DataTransfer, at 127.0.0.1:42173: Transmitted BP-464449197-172.17.0.6-1606979982896:blk_1073741829_1005 (numBytes=1) to /127.0.0.1:35226
2020-12-03 07:20:00,773 [DataXceiver for client  at /127.0.0.1:60140 [Receiving block BP-464449197-172.17.0.6-1606979982896:blk_1073741829_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(931)) - Received BP-464449197-172.17.0.6-1606979982896:blk_1073741829_1005 src: /127.0.0.1:60140 dest: /127.0.0.1:35226 of size 1
2020-12-03 07:20:01,172 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (DataNode.java:transferBlock(2358)) - DatanodeRegistration(127.0.0.1:45400, datanodeUuid=ec6135ad-ddf0-47a2-866e-c2a0a646b3ea, infoPort=41348, infoSecurePort=0, ipcPort=36982, storageInfo=lv=-57;cid=testClusterID;nsid=662464899;c=1606979982896) Starting thread to transfer BP-464449197-172.17.0.6-1606979982896:blk_1073741828_1004 to 127.0.0.1:35226 
2020-12-03 07:20:01,173 [org.apache.hadoop.hdfs.server.datanode.DataNode$DataTransfer@1cc1fb4e] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:01,177 [org.apache.hadoop.hdfs.server.datanode.DataNode$DataTransfer@1cc1fb4e] INFO  datanode.DataNode (DataNode.java:run(2571)) - DataTransfer, at 127.0.0.1:45400: Transmitted BP-464449197-172.17.0.6-1606979982896:blk_1073741828_1004 (numBytes=1) to /127.0.0.1:35226
2020-12-03 07:20:01,178 [DataXceiver for client  at /127.0.0.1:60142 [Receiving block BP-464449197-172.17.0.6-1606979982896:blk_1073741828_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-464449197-172.17.0.6-1606979982896:blk_1073741828_1004 src: /127.0.0.1:60142 dest: /127.0.0.1:35226
2020-12-03 07:20:01,179 [DataXceiver for client  at /127.0.0.1:60142 [Receiving block BP-464449197-172.17.0.6-1606979982896:blk_1073741828_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(931)) - Received BP-464449197-172.17.0.6-1606979982896:blk_1073741828_1004 src: /127.0.0.1:60142 dest: /127.0.0.1:35226 of size 1
2020-12-03 07:20:01,370 [Listener at localhost/36982] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:01,371 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@614aeccc] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:01,376 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-a91ecbc1-38a0-4aee-a8bb-57f2ff2f9937) exiting.
2020-12-03 07:20:01,377 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-3a17eb31-b33e-4a9a-a80f-9b182d8e1248) exiting.
2020-12-03 07:20:01,405 [Listener at localhost/36982] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@27b71f50{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:01,407 [Listener at localhost/36982] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@383790cf{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:01,409 [Listener at localhost/36982] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@d176a31{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:01,410 [Listener at localhost/36982] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7dd00705{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:01,411 [Listener at localhost/36982] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 41846
2020-12-03 07:20:01,418 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:01,421 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:01,423 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:01,424 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-464449197-172.17.0.6-1606979982896 (Datanode Uuid 1840bbdd-b765-44bd-8c75-9f95ec61318d) service to localhost/127.0.0.1:34612
2020-12-03 07:20:01,424 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-464449197-172.17.0.6-1606979982896 (Datanode Uuid 1840bbdd-b765-44bd-8c75-9f95ec61318d)
2020-12-03 07:20:01,424 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:20:01,429 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-464449197-172.17.0.6-1606979982896] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:01,429 [Listener at localhost/36982] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:01,430 [Listener at localhost/36982] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:01,430 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-464449197-172.17.0.6-1606979982896] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:01,435 [Listener at localhost/36982] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:01,436 [Listener at localhost/36982] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:01,438 [Listener at localhost/36982] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:01,439 [Listener at localhost/36982] INFO  hdfs.StateChange (DatanodeManager.java:removeDeadDatanode(754)) - BLOCK* removeDeadDatanode: lost heartbeat from 127.0.0.1:39367, removeBlocksFromBlockMap true
2020-12-03 07:20:01,441 [Listener at localhost/36982] INFO  net.NetworkTopology (NetworkTopology.java:remove(219)) - Removing a node: /default-rack/127.0.0.1:39367
2020-12-03 07:20:01,442 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@441cc260] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:01,442 [Listener at localhost/36982] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:01,444 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-0b503d65-8d01-49ef-8e43-291aff1d549a) exiting.
2020-12-03 07:20:01,445 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-5b6b1a9c-9c26-49bb-9bbd-60b622efa680) exiting.
2020-12-03 07:20:01,493 [Listener at localhost/36982] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@55cff952{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:01,494 [Listener at localhost/36982] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@660591fb{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:01,494 [Listener at localhost/36982] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3a022576{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:01,495 [Listener at localhost/36982] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@55b8dbda{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:01,515 [Listener at localhost/36982] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 38349
2020-12-03 07:20:01,531 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:01,531 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:01,533 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:01,533 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-464449197-172.17.0.6-1606979982896 (Datanode Uuid baa99858-a351-4f23-95d3-417a6368fdb3) service to localhost/127.0.0.1:34612
2020-12-03 07:20:01,534 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-464449197-172.17.0.6-1606979982896 (Datanode Uuid baa99858-a351-4f23-95d3-417a6368fdb3)
2020-12-03 07:20:01,534 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:20:01,535 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-464449197-172.17.0.6-1606979982896] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:01,535 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-464449197-172.17.0.6-1606979982896] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:01,537 [Listener at localhost/36982] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:01,537 [Listener at localhost/36982] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:01,539 [Listener at localhost/36982] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:01,539 [Listener at localhost/36982] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:01,549 [Listener at localhost/36982] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:01,550 [Listener at localhost/36982] INFO  hdfs.StateChange (DatanodeManager.java:removeDeadDatanode(754)) - BLOCK* removeDeadDatanode: lost heartbeat from 127.0.0.1:42420, removeBlocksFromBlockMap false
2020-12-03 07:20:01,550 [Listener at localhost/36982] INFO  net.NetworkTopology (NetworkTopology.java:remove(219)) - Removing a node: /default-rack/127.0.0.1:42420
2020-12-03 07:20:01,551 [Listener at localhost/36982] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:01,555 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-e89d6108-2324-4b34-addb-9670aed7d37d) exiting.
2020-12-03 07:20:01,559 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-3571474c-359b-4f98-94a4-8b83a1d0652c) exiting.
2020-12-03 07:20:01,559 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@4abf3f0] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:01,719 [Listener at localhost/36982] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@41c204a0{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:01,720 [Listener at localhost/36982] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@64138b0c{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:01,720 [Listener at localhost/36982] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@398474a2{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:01,721 [Listener at localhost/36982] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5e39850{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:01,722 [Listener at localhost/36982] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 43944
2020-12-03 07:20:01,726 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:01,726 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:01,728 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:01,728 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-464449197-172.17.0.6-1606979982896 (Datanode Uuid edec627a-465f-4532-ab74-3f78e8a40769) service to localhost/127.0.0.1:34612
2020-12-03 07:20:01,728 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-464449197-172.17.0.6-1606979982896 (Datanode Uuid edec627a-465f-4532-ab74-3f78e8a40769)
2020-12-03 07:20:01,728 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:20:01,729 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-464449197-172.17.0.6-1606979982896] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:01,730 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-464449197-172.17.0.6-1606979982896] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:01,732 [Listener at localhost/36982] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:01,732 [Listener at localhost/36982] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:01,734 [Listener at localhost/36982] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:01,734 [Listener at localhost/36982] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:01,734 [Listener at localhost/36982] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:01,734 [Listener at localhost/36982] INFO  hdfs.StateChange (DatanodeManager.java:removeDeadDatanode(754)) - BLOCK* removeDeadDatanode: lost heartbeat from 127.0.0.1:35235, removeBlocksFromBlockMap true
2020-12-03 07:20:01,735 [Listener at localhost/36982] INFO  net.NetworkTopology (NetworkTopology.java:remove(219)) - Removing a node: /default-rack/127.0.0.1:35235
2020-12-03 07:20:01,735 [Listener at localhost/36982] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:01,735 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@24fabd0f] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:01,743 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-9de9d331-cfd4-450a-96bf-6bed8d407bd9) exiting.
2020-12-03 07:20:01,745 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-47ca938b-a40d-4407-b093-5825baebb00c) exiting.
2020-12-03 07:20:01,767 [Listener at localhost/36982] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@30506c0d{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:01,768 [Listener at localhost/36982] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@1dcca8d3{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:01,769 [Listener at localhost/36982] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@63da207f{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:01,769 [Listener at localhost/36982] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7d755813{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:01,770 [Listener at localhost/36982] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 42345
2020-12-03 07:20:01,784 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:01,784 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:01,787 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:01,788 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-464449197-172.17.0.6-1606979982896 (Datanode Uuid 309f7fa0-0c59-4920-a6f9-56c2485276d8) service to localhost/127.0.0.1:34612
2020-12-03 07:20:01,788 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-464449197-172.17.0.6-1606979982896 (Datanode Uuid 309f7fa0-0c59-4920-a6f9-56c2485276d8)
2020-12-03 07:20:01,788 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:20:01,789 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-464449197-172.17.0.6-1606979982896] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:01,790 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-464449197-172.17.0.6-1606979982896] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:01,792 [Listener at localhost/36982] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:01,792 [Listener at localhost/36982] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:01,794 [Listener at localhost/36982] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:01,794 [Listener at localhost/36982] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:01,795 [Listener at localhost/36982] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:01,795 [Listener at localhost/36982] INFO  hdfs.StateChange (DatanodeManager.java:removeDeadDatanode(754)) - BLOCK* removeDeadDatanode: lost heartbeat from 127.0.0.1:42173, removeBlocksFromBlockMap true
2020-12-03 07:20:01,796 [Listener at localhost/36982] INFO  net.NetworkTopology (NetworkTopology.java:remove(219)) - Removing a node: /default-rack/127.0.0.1:42173
2020-12-03 07:20:01,797 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@78e89bfe] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:01,797 [Listener at localhost/36982] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:01,800 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-28904309-f21d-4622-b590-65c20013b1c7) exiting.
2020-12-03 07:20:01,801 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-8d7e7ea8-c1a7-4424-9e6e-68f075bb1fe6) exiting.
2020-12-03 07:20:01,828 [Listener at localhost/36982] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5cd61783{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:01,832 [Listener at localhost/36982] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@59429fac{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:01,832 [Listener at localhost/36982] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7ec58feb{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:01,833 [Listener at localhost/36982] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1e6cc850{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:01,835 [Listener at localhost/36982] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 45810
2020-12-03 07:20:01,836 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:01,844 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:01,844 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-464449197-172.17.0.6-1606979982896 (Datanode Uuid 2b5a1500-a27d-403f-b7e5-7837081de87c) service to localhost/127.0.0.1:34612
2020-12-03 07:20:01,844 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-464449197-172.17.0.6-1606979982896 (Datanode Uuid 2b5a1500-a27d-403f-b7e5-7837081de87c)
2020-12-03 07:20:01,844 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:20:01,844 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:01,846 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-464449197-172.17.0.6-1606979982896] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:01,847 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-464449197-172.17.0.6-1606979982896] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:01,849 [Listener at localhost/36982] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:01,852 [Listener at localhost/36982] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:01,855 [Listener at localhost/36982] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:01,856 [Listener at localhost/36982] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:01,857 [Listener at localhost/36982] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-12-03 07:20:01,859 [Listener at localhost/36982] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-12-03 07:20:01,861 [Listener at localhost/36982] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-12-03 07:20:01,863 [Listener at localhost/36982] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:01,864 [Listener at localhost/36982] INFO  hdfs.StateChange (DatanodeManager.java:removeDeadDatanode(754)) - BLOCK* removeDeadDatanode: lost heartbeat from 127.0.0.1:35226, removeBlocksFromBlockMap true
2020-12-03 07:20:01,865 [Listener at localhost/36982] INFO  net.NetworkTopology (NetworkTopology.java:remove(219)) - Removing a node: /default-rack/127.0.0.1:35226
2020-12-03 07:20:01,866 [Listener at localhost/36982] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:01,867 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@257cc1fc] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:01,871 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-6f70985c-ac30-47d0-891a-02298a52a999) exiting.
2020-12-03 07:20:01,871 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-ca7c16c8-a7cd-40c3-9072-e5e55f35ba2f) exiting.
2020-12-03 07:20:01,906 [Listener at localhost/36982] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@2098d37d{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:01,908 [Listener at localhost/36982] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@77b9d0c7{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:01,908 [Listener at localhost/36982] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2a22ad2b{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:01,909 [Listener at localhost/36982] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@61c76850{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:01,912 [Listener at localhost/36982] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 44520
2020-12-03 07:20:01,913 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:01,914 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-464449197-172.17.0.6-1606979982896 (Datanode Uuid 01c12b1d-d7d2-421e-986c-c593ac806eae) service to localhost/127.0.0.1:34612
2020-12-03 07:20:01,914 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-464449197-172.17.0.6-1606979982896 (Datanode Uuid 01c12b1d-d7d2-421e-986c-c593ac806eae)
2020-12-03 07:20:01,914 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:20:01,915 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:01,915 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:01,915 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-464449197-172.17.0.6-1606979982896] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:01,922 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-464449197-172.17.0.6-1606979982896] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:01,925 [Listener at localhost/36982] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:01,926 [Listener at localhost/36982] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:01,953 [Listener at localhost/36982] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:01,953 [Listener at localhost/36982] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:01,954 [Listener at localhost/36982] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:01,955 [Listener at localhost/36982] INFO  hdfs.StateChange (DatanodeManager.java:removeDeadDatanode(754)) - BLOCK* removeDeadDatanode: lost heartbeat from 127.0.0.1:43233, removeBlocksFromBlockMap true
2020-12-03 07:20:01,955 [Listener at localhost/36982] INFO  net.NetworkTopology (NetworkTopology.java:remove(219)) - Removing a node: /default-rack/127.0.0.1:43233
2020-12-03 07:20:01,956 [Listener at localhost/36982] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:01,956 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@7351a16e] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:01,960 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-0bb00b44-1a33-4c83-8050-95766856105e) exiting.
2020-12-03 07:20:01,966 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-0e3fa327-8df7-42f0-8bbd-411a1ebd4305) exiting.
2020-12-03 07:20:02,001 [Listener at localhost/36982] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6892cc6f{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:02,002 [Listener at localhost/36982] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6fd1660{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:02,002 [Listener at localhost/36982] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@54562ea6{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:02,003 [Listener at localhost/36982] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3c0fbd3a{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:02,016 [Listener at localhost/36982] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 40709
2020-12-03 07:20:02,024 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:02,034 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:02,034 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:02,034 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-464449197-172.17.0.6-1606979982896 (Datanode Uuid ba28613b-b481-4768-b4d4-cf44e7144ddf) service to localhost/127.0.0.1:34612
2020-12-03 07:20:02,034 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-464449197-172.17.0.6-1606979982896 (Datanode Uuid ba28613b-b481-4768-b4d4-cf44e7144ddf)
2020-12-03 07:20:02,035 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:20:02,036 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-464449197-172.17.0.6-1606979982896] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:02,039 [Listener at localhost/36982] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:02,039 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-464449197-172.17.0.6-1606979982896] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:02,040 [Listener at localhost/36982] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:02,043 [Listener at localhost/36982] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:02,044 [Listener at localhost/36982] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:02,046 [Listener at localhost/36982] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:02,046 [Listener at localhost/36982] INFO  hdfs.StateChange (DatanodeManager.java:removeDeadDatanode(754)) - BLOCK* removeDeadDatanode: lost heartbeat from 127.0.0.1:33060, removeBlocksFromBlockMap true
2020-12-03 07:20:02,047 [Listener at localhost/36982] INFO  net.NetworkTopology (NetworkTopology.java:remove(219)) - Removing a node: /default-rack/127.0.0.1:33060
2020-12-03 07:20:02,047 [Listener at localhost/36982] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:02,047 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@9a2ec9b] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:02,053 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-cd676010-abda-483c-a6ea-b69676538fc2) exiting.
2020-12-03 07:20:02,053 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-9c05f2e3-34b6-4594-b06f-9365cd2a0a2f) exiting.
2020-12-03 07:20:02,072 [Listener at localhost/36982] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6fc3e1a4{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:02,073 [Listener at localhost/36982] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@3fa76c61{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:02,073 [Listener at localhost/36982] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4930539b{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:02,074 [Listener at localhost/36982] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6a84bc3f{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:02,076 [Listener at localhost/36982] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 36982
2020-12-03 07:20:02,079 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:02,079 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:02,096 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:02,096 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-464449197-172.17.0.6-1606979982896 (Datanode Uuid ec6135ad-ddf0-47a2-866e-c2a0a646b3ea) service to localhost/127.0.0.1:34612
2020-12-03 07:20:02,096 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-464449197-172.17.0.6-1606979982896 (Datanode Uuid ec6135ad-ddf0-47a2-866e-c2a0a646b3ea)
2020-12-03 07:20:02,096 [BP-464449197-172.17.0.6-1606979982896 heartbeating to localhost/127.0.0.1:34612] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-464449197-172.17.0.6-1606979982896
2020-12-03 07:20:02,098 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-464449197-172.17.0.6-1606979982896] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:02,107 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-464449197-172.17.0.6-1606979982896] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:02,118 [Listener at localhost/36982] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:02,118 [Listener at localhost/36982] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:02,122 [Listener at localhost/36982] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:02,122 [Listener at localhost/36982] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:02,123 [Listener at localhost/36982] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:02,123 [Listener at localhost/36982] INFO  hdfs.StateChange (DatanodeManager.java:removeDeadDatanode(754)) - BLOCK* removeDeadDatanode: lost heartbeat from 127.0.0.1:45400, removeBlocksFromBlockMap true
2020-12-03 07:20:02,124 [Listener at localhost/36982] INFO  net.NetworkTopology (NetworkTopology.java:remove(219)) - Removing a node: /default-rack/127.0.0.1:45400
2020-12-03 07:20:02,125 [Listener at localhost/36982] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:20:02,231 [Listener at localhost/36982] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 7
2020-12-03 07:20:02,231 [Listener at localhost/36982] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(341)) - DirectoryScanner: shutdown has been called, but periodic scanner not started
2020-12-03 07:20:02,232 [Listener at localhost/36982] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 36982
2020-12-03 07:20:02,232 [Listener at localhost/36982] WARN  util.MBeans (MBeans.java:unregister(145)) - Error unregistering Hadoop:service=DataNode,name=FSDatasetState-ec6135ad-ddf0-47a2-866e-c2a0a646b3ea
javax.management.InstanceNotFoundException: Hadoop:service=DataNode,name=FSDatasetState-ec6135ad-ddf0-47a2-866e-c2a0a646b3ea
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getMBean(DefaultMBeanServerInterceptor.java:1095)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.exclusiveUnregisterMBean(DefaultMBeanServerInterceptor.java:427)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.unregisterMBean(DefaultMBeanServerInterceptor.java:415)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.unregisterMBean(JmxMBeanServer.java:546)
	at org.apache.hadoop.metrics2.util.MBeans.unregister(MBeans.java:143)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.shutdown(FsDatasetImpl.java:2293)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.shutdown(DataNode.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdownDataNode(MiniDFSCluster.java:2099)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdownDataNodes(MiniDFSCluster.java:2089)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2068)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2042)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2035)
	at org.apache.hadoop.hdfs.server.namenode.TestNamenodeCapacityReport.testXceiverCountInternal(TestNamenodeCapacityReport.java:345)
	at org.apache.hadoop.hdfs.server.namenode.TestNamenodeCapacityReport.testXceiverCount(TestNamenodeCapacityReport.java:199)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2020-12-03 07:20:02,233 [Listener at localhost/36982] WARN  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(191)) - AsyncDiskService has already shut down.
2020-12-03 07:20:02,233 [Listener at localhost/36982] WARN  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(175)) - AsyncLazyPersistService has already shut down.
2020-12-03 07:20:02,233 [Listener at localhost/36982] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:02,233 [Listener at localhost/36982] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 6
2020-12-03 07:20:02,233 [Listener at localhost/36982] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(341)) - DirectoryScanner: shutdown has been called, but periodic scanner not started
2020-12-03 07:20:02,233 [Listener at localhost/36982] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 40709
2020-12-03 07:20:02,233 [Listener at localhost/36982] WARN  util.MBeans (MBeans.java:unregister(145)) - Error unregistering Hadoop:service=DataNode,name=FSDatasetState-ba28613b-b481-4768-b4d4-cf44e7144ddf
javax.management.InstanceNotFoundException: Hadoop:service=DataNode,name=FSDatasetState-ba28613b-b481-4768-b4d4-cf44e7144ddf
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getMBean(DefaultMBeanServerInterceptor.java:1095)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.exclusiveUnregisterMBean(DefaultMBeanServerInterceptor.java:427)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.unregisterMBean(DefaultMBeanServerInterceptor.java:415)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.unregisterMBean(JmxMBeanServer.java:546)
	at org.apache.hadoop.metrics2.util.MBeans.unregister(MBeans.java:143)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.shutdown(FsDatasetImpl.java:2293)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.shutdown(DataNode.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdownDataNode(MiniDFSCluster.java:2099)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdownDataNodes(MiniDFSCluster.java:2089)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2068)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2042)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2035)
	at org.apache.hadoop.hdfs.server.namenode.TestNamenodeCapacityReport.testXceiverCountInternal(TestNamenodeCapacityReport.java:345)
	at org.apache.hadoop.hdfs.server.namenode.TestNamenodeCapacityReport.testXceiverCount(TestNamenodeCapacityReport.java:199)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2020-12-03 07:20:02,234 [Listener at localhost/36982] WARN  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(191)) - AsyncDiskService has already shut down.
2020-12-03 07:20:02,234 [Listener at localhost/36982] WARN  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(175)) - AsyncLazyPersistService has already shut down.
2020-12-03 07:20:02,234 [Listener at localhost/36982] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:02,234 [Listener at localhost/36982] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 5
2020-12-03 07:20:02,234 [Listener at localhost/36982] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(341)) - DirectoryScanner: shutdown has been called, but periodic scanner not started
2020-12-03 07:20:02,235 [Listener at localhost/36982] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 44520
2020-12-03 07:20:02,235 [Listener at localhost/36982] WARN  util.MBeans (MBeans.java:unregister(145)) - Error unregistering Hadoop:service=DataNode,name=FSDatasetState-01c12b1d-d7d2-421e-986c-c593ac806eae
javax.management.InstanceNotFoundException: Hadoop:service=DataNode,name=FSDatasetState-01c12b1d-d7d2-421e-986c-c593ac806eae
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getMBean(DefaultMBeanServerInterceptor.java:1095)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.exclusiveUnregisterMBean(DefaultMBeanServerInterceptor.java:427)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.unregisterMBean(DefaultMBeanServerInterceptor.java:415)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.unregisterMBean(JmxMBeanServer.java:546)
	at org.apache.hadoop.metrics2.util.MBeans.unregister(MBeans.java:143)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.shutdown(FsDatasetImpl.java:2293)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.shutdown(DataNode.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdownDataNode(MiniDFSCluster.java:2099)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdownDataNodes(MiniDFSCluster.java:2089)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2068)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2042)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2035)
	at org.apache.hadoop.hdfs.server.namenode.TestNamenodeCapacityReport.testXceiverCountInternal(TestNamenodeCapacityReport.java:345)
	at org.apache.hadoop.hdfs.server.namenode.TestNamenodeCapacityReport.testXceiverCount(TestNamenodeCapacityReport.java:199)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2020-12-03 07:20:02,236 [Listener at localhost/36982] WARN  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(191)) - AsyncDiskService has already shut down.
2020-12-03 07:20:02,236 [Listener at localhost/36982] WARN  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(175)) - AsyncLazyPersistService has already shut down.
2020-12-03 07:20:02,236 [Listener at localhost/36982] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:02,236 [Listener at localhost/36982] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 4
2020-12-03 07:20:02,237 [Listener at localhost/36982] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(341)) - DirectoryScanner: shutdown has been called, but periodic scanner not started
2020-12-03 07:20:02,237 [Listener at localhost/36982] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 45810
2020-12-03 07:20:02,237 [Listener at localhost/36982] WARN  util.MBeans (MBeans.java:unregister(145)) - Error unregistering Hadoop:service=DataNode,name=FSDatasetState-2b5a1500-a27d-403f-b7e5-7837081de87c
javax.management.InstanceNotFoundException: Hadoop:service=DataNode,name=FSDatasetState-2b5a1500-a27d-403f-b7e5-7837081de87c
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getMBean(DefaultMBeanServerInterceptor.java:1095)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.exclusiveUnregisterMBean(DefaultMBeanServerInterceptor.java:427)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.unregisterMBean(DefaultMBeanServerInterceptor.java:415)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.unregisterMBean(JmxMBeanServer.java:546)
	at org.apache.hadoop.metrics2.util.MBeans.unregister(MBeans.java:143)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.shutdown(FsDatasetImpl.java:2293)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.shutdown(DataNode.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdownDataNode(MiniDFSCluster.java:2099)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdownDataNodes(MiniDFSCluster.java:2089)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2068)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2042)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2035)
	at org.apache.hadoop.hdfs.server.namenode.TestNamenodeCapacityReport.testXceiverCountInternal(TestNamenodeCapacityReport.java:345)
	at org.apache.hadoop.hdfs.server.namenode.TestNamenodeCapacityReport.testXceiverCount(TestNamenodeCapacityReport.java:199)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2020-12-03 07:20:02,237 [Listener at localhost/36982] WARN  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(191)) - AsyncDiskService has already shut down.
2020-12-03 07:20:02,238 [Listener at localhost/36982] WARN  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(175)) - AsyncLazyPersistService has already shut down.
2020-12-03 07:20:02,238 [Listener at localhost/36982] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:02,238 [Listener at localhost/36982] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 3
2020-12-03 07:20:02,238 [Listener at localhost/36982] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(341)) - DirectoryScanner: shutdown has been called, but periodic scanner not started
2020-12-03 07:20:02,238 [Listener at localhost/36982] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 42345
2020-12-03 07:20:02,238 [Listener at localhost/36982] WARN  util.MBeans (MBeans.java:unregister(145)) - Error unregistering Hadoop:service=DataNode,name=FSDatasetState-309f7fa0-0c59-4920-a6f9-56c2485276d8
javax.management.InstanceNotFoundException: Hadoop:service=DataNode,name=FSDatasetState-309f7fa0-0c59-4920-a6f9-56c2485276d8
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getMBean(DefaultMBeanServerInterceptor.java:1095)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.exclusiveUnregisterMBean(DefaultMBeanServerInterceptor.java:427)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.unregisterMBean(DefaultMBeanServerInterceptor.java:415)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.unregisterMBean(JmxMBeanServer.java:546)
	at org.apache.hadoop.metrics2.util.MBeans.unregister(MBeans.java:143)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.shutdown(FsDatasetImpl.java:2293)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.shutdown(DataNode.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdownDataNode(MiniDFSCluster.java:2099)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdownDataNodes(MiniDFSCluster.java:2089)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2068)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2042)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2035)
	at org.apache.hadoop.hdfs.server.namenode.TestNamenodeCapacityReport.testXceiverCountInternal(TestNamenodeCapacityReport.java:345)
	at org.apache.hadoop.hdfs.server.namenode.TestNamenodeCapacityReport.testXceiverCount(TestNamenodeCapacityReport.java:199)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2020-12-03 07:20:02,239 [Listener at localhost/36982] WARN  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(191)) - AsyncDiskService has already shut down.
2020-12-03 07:20:02,239 [Listener at localhost/36982] WARN  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(175)) - AsyncLazyPersistService has already shut down.
2020-12-03 07:20:02,239 [Listener at localhost/36982] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:02,240 [Listener at localhost/36982] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 2
2020-12-03 07:20:02,240 [Listener at localhost/36982] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(341)) - DirectoryScanner: shutdown has been called, but periodic scanner not started
2020-12-03 07:20:02,240 [Listener at localhost/36982] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 43944
2020-12-03 07:20:02,240 [Listener at localhost/36982] WARN  util.MBeans (MBeans.java:unregister(145)) - Error unregistering Hadoop:service=DataNode,name=FSDatasetState-edec627a-465f-4532-ab74-3f78e8a40769
javax.management.InstanceNotFoundException: Hadoop:service=DataNode,name=FSDatasetState-edec627a-465f-4532-ab74-3f78e8a40769
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getMBean(DefaultMBeanServerInterceptor.java:1095)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.exclusiveUnregisterMBean(DefaultMBeanServerInterceptor.java:427)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.unregisterMBean(DefaultMBeanServerInterceptor.java:415)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.unregisterMBean(JmxMBeanServer.java:546)
	at org.apache.hadoop.metrics2.util.MBeans.unregister(MBeans.java:143)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.shutdown(FsDatasetImpl.java:2293)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.shutdown(DataNode.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdownDataNode(MiniDFSCluster.java:2099)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdownDataNodes(MiniDFSCluster.java:2089)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2068)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2042)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2035)
	at org.apache.hadoop.hdfs.server.namenode.TestNamenodeCapacityReport.testXceiverCountInternal(TestNamenodeCapacityReport.java:345)
	at org.apache.hadoop.hdfs.server.namenode.TestNamenodeCapacityReport.testXceiverCount(TestNamenodeCapacityReport.java:199)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2020-12-03 07:20:02,241 [Listener at localhost/36982] WARN  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(191)) - AsyncDiskService has already shut down.
2020-12-03 07:20:02,241 [Listener at localhost/36982] WARN  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(175)) - AsyncLazyPersistService has already shut down.
2020-12-03 07:20:02,241 [Listener at localhost/36982] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:02,242 [Listener at localhost/36982] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 1
2020-12-03 07:20:02,242 [Listener at localhost/36982] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(341)) - DirectoryScanner: shutdown has been called, but periodic scanner not started
2020-12-03 07:20:02,242 [Listener at localhost/36982] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 38349
2020-12-03 07:20:02,242 [Listener at localhost/36982] WARN  util.MBeans (MBeans.java:unregister(145)) - Error unregistering Hadoop:service=DataNode,name=FSDatasetState-baa99858-a351-4f23-95d3-417a6368fdb3
javax.management.InstanceNotFoundException: Hadoop:service=DataNode,name=FSDatasetState-baa99858-a351-4f23-95d3-417a6368fdb3
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getMBean(DefaultMBeanServerInterceptor.java:1095)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.exclusiveUnregisterMBean(DefaultMBeanServerInterceptor.java:427)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.unregisterMBean(DefaultMBeanServerInterceptor.java:415)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.unregisterMBean(JmxMBeanServer.java:546)
	at org.apache.hadoop.metrics2.util.MBeans.unregister(MBeans.java:143)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.shutdown(FsDatasetImpl.java:2293)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.shutdown(DataNode.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdownDataNode(MiniDFSCluster.java:2099)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdownDataNodes(MiniDFSCluster.java:2089)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2068)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2042)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2035)
	at org.apache.hadoop.hdfs.server.namenode.TestNamenodeCapacityReport.testXceiverCountInternal(TestNamenodeCapacityReport.java:345)
	at org.apache.hadoop.hdfs.server.namenode.TestNamenodeCapacityReport.testXceiverCount(TestNamenodeCapacityReport.java:199)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2020-12-03 07:20:02,243 [Listener at localhost/36982] WARN  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(191)) - AsyncDiskService has already shut down.
2020-12-03 07:20:02,243 [Listener at localhost/36982] WARN  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(175)) - AsyncLazyPersistService has already shut down.
2020-12-03 07:20:02,243 [Listener at localhost/36982] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:02,244 [Listener at localhost/36982] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:20:02,244 [Listener at localhost/36982] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(341)) - DirectoryScanner: shutdown has been called, but periodic scanner not started
2020-12-03 07:20:02,244 [Listener at localhost/36982] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 41846
2020-12-03 07:20:02,244 [Listener at localhost/36982] WARN  util.MBeans (MBeans.java:unregister(145)) - Error unregistering Hadoop:service=DataNode,name=FSDatasetState-1840bbdd-b765-44bd-8c75-9f95ec61318d
javax.management.InstanceNotFoundException: Hadoop:service=DataNode,name=FSDatasetState-1840bbdd-b765-44bd-8c75-9f95ec61318d
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getMBean(DefaultMBeanServerInterceptor.java:1095)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.exclusiveUnregisterMBean(DefaultMBeanServerInterceptor.java:427)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.unregisterMBean(DefaultMBeanServerInterceptor.java:415)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.unregisterMBean(JmxMBeanServer.java:546)
	at org.apache.hadoop.metrics2.util.MBeans.unregister(MBeans.java:143)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.shutdown(FsDatasetImpl.java:2293)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.shutdown(DataNode.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdownDataNode(MiniDFSCluster.java:2099)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdownDataNodes(MiniDFSCluster.java:2089)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2068)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2042)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2035)
	at org.apache.hadoop.hdfs.server.namenode.TestNamenodeCapacityReport.testXceiverCountInternal(TestNamenodeCapacityReport.java:345)
	at org.apache.hadoop.hdfs.server.namenode.TestNamenodeCapacityReport.testXceiverCount(TestNamenodeCapacityReport.java:199)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2020-12-03 07:20:02,245 [Listener at localhost/36982] WARN  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(191)) - AsyncDiskService has already shut down.
2020-12-03 07:20:02,245 [Listener at localhost/36982] WARN  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(175)) - AsyncLazyPersistService has already shut down.
2020-12-03 07:20:02,245 [Listener at localhost/36982] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:02,246 [Listener at localhost/36982] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:20:02,246 [Listener at localhost/36982] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:20:02,247 [Listener at localhost/36982] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 1, 31
2020-12-03 07:20:02,247 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@3d484181] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:20:02,248 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@7894f09b] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:20:02,250 [Listener at localhost/36982] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 32 Total time for transactions(ms): 60 Number of transactions batched in Syncs: 6 Number of syncs: 27 SyncTimes(ms): 5 2 
2020-12-03 07:20:02,251 [Listener at localhost/36982] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000032
2020-12-03 07:20:02,252 [Listener at localhost/36982] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000032
2020-12-03 07:20:02,253 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:20:02,253 [CacheReplicationMonitor(1419326200)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:20:02,254 [Listener at localhost/36982] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 34612
2020-12-03 07:20:02,255 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:02,256 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:20:02,274 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:20:02,274 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:02,322 [Listener at localhost/36982] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:20:02,322 [Listener at localhost/36982] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:20:02,324 [Listener at localhost/36982] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@2e32ccc5{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:20:02,334 [Listener at localhost/36982] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@34cf6eff{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:02,335 [Listener at localhost/36982] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@28cda624{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:02,336 [Listener at localhost/36982] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@69504ae9{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:02,381 [Listener at localhost/36982] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=8
Formatting using clusterid: testClusterID
2020-12-03 07:20:02,385 [Listener at localhost/36982] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:20:02,386 [Listener at localhost/36982] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:20:02,386 [Listener at localhost/36982] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:20:02,386 [Listener at localhost/36982] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:20:02,386 [Listener at localhost/36982] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:20:02,386 [Listener at localhost/36982] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:20:02,386 [Listener at localhost/36982] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:20:02,387 [Listener at localhost/36982] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:20:02,387 [Listener at localhost/36982] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:02,387 [Listener at localhost/36982] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:20:02,388 [Listener at localhost/36982] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:20:02,388 [Listener at localhost/36982] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:20:02,388 [Listener at localhost/36982] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:20:02
2020-12-03 07:20:02,388 [Listener at localhost/36982] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:20:02,388 [Listener at localhost/36982] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:02,389 [Listener at localhost/36982] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:20:02,389 [Listener at localhost/36982] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:20:02,399 [Listener at localhost/36982] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:20:02,400 [Listener at localhost/36982] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:20:02,400 [Listener at localhost/36982] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:20:02,400 [Listener at localhost/36982] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:20:02,400 [Listener at localhost/36982] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:20:02,400 [Listener at localhost/36982] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:20:02,401 [Listener at localhost/36982] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:20:02,401 [Listener at localhost/36982] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:20:02,401 [Listener at localhost/36982] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:20:02,401 [Listener at localhost/36982] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:20:02,401 [Listener at localhost/36982] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:20:02,401 [Listener at localhost/36982] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:20:02,401 [Listener at localhost/36982] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:20:02,402 [Listener at localhost/36982] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:20:02,402 [Listener at localhost/36982] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:02,402 [Listener at localhost/36982] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:20:02,402 [Listener at localhost/36982] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:20:02,409 [Listener at localhost/36982] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:20:02,409 [Listener at localhost/36982] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:20:02,410 [Listener at localhost/36982] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:20:02,410 [Listener at localhost/36982] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:20:02,410 [Listener at localhost/36982] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:20:02,410 [Listener at localhost/36982] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:20:02,410 [Listener at localhost/36982] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:20:02,410 [Listener at localhost/36982] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:02,411 [Listener at localhost/36982] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:20:02,411 [Listener at localhost/36982] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:20:02,413 [Listener at localhost/36982] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:20:02,414 [Listener at localhost/36982] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:20:02,414 [Listener at localhost/36982] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:20:02,414 [Listener at localhost/36982] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:20:02,414 [Listener at localhost/36982] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:20:02,414 [Listener at localhost/36982] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:20:02,414 [Listener at localhost/36982] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:02,415 [Listener at localhost/36982] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:20:02,415 [Listener at localhost/36982] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:20:02,416 [Listener at localhost/36982] INFO  namenode.FSImage (FSImage.java:format(185)) - Allocated new BlockPoolId: BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:02,508 [Listener at localhost/36982] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-12-03 07:20:02,576 [Listener at localhost/36982] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-12-03 07:20:02,597 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:20:02,599 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:20:02,603 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 417 bytes saved in 0 seconds .
2020-12-03 07:20:02,608 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 417 bytes saved in 0 seconds .
2020-12-03 07:20:02,655 [Listener at localhost/36982] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-12-03 07:20:02,658 [Listener at localhost/36982] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:20:02,661 [Listener at localhost/36982] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:20:02,663 [Listener at localhost/36982] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:20:02,663 [Listener at localhost/36982] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:20:02,665 [Listener at localhost/36982] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-12-03 07:20:02,720 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5e1218b4] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:02,721 [Listener at localhost/36982] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:20:02,721 [Listener at localhost/36982] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:02,723 [Listener at localhost/36982] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:02,723 [Listener at localhost/36982] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:20:02,724 [Listener at localhost/36982] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:02,726 [Listener at localhost/36982] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:02,726 [Listener at localhost/36982] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:20:02,727 [Listener at localhost/36982] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:02,727 [Listener at localhost/36982] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:02,729 [Listener at localhost/36982] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:20:02,729 [Listener at localhost/36982] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:20:02,730 [Listener at localhost/36982] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 36202
2020-12-03 07:20:02,730 [Listener at localhost/36982] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:02,732 [Listener at localhost/36982] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@63fdffcd{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:02,733 [Listener at localhost/36982] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@66f659e6{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:02,739 [Listener at localhost/36982] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@77c7ed8e{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:20:02,740 [Listener at localhost/36982] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@453d496b{HTTP/1.1,[http/1.1]}{localhost:36202}
2020-12-03 07:20:02,756 [Listener at localhost/36982] INFO  server.Server (Server.java:doStart(419)) - Started @22489ms
2020-12-03 07:20:02,760 [Listener at localhost/36982] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:20:02,760 [Listener at localhost/36982] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:20:02,761 [Listener at localhost/36982] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:20:02,761 [Listener at localhost/36982] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:20:02,761 [Listener at localhost/36982] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:20:02,761 [Listener at localhost/36982] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:20:02,762 [Listener at localhost/36982] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:20:02,762 [Listener at localhost/36982] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:20:02,763 [Listener at localhost/36982] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:02,763 [Listener at localhost/36982] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:20:02,763 [Listener at localhost/36982] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:20:02,764 [Listener at localhost/36982] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:20:02,764 [Listener at localhost/36982] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:20:02
2020-12-03 07:20:02,764 [Listener at localhost/36982] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:20:02,764 [Listener at localhost/36982] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:02,765 [Listener at localhost/36982] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:20:02,765 [Listener at localhost/36982] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:20:02,794 [Listener at localhost/36982] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:20:02,795 [Listener at localhost/36982] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:20:02,802 [Listener at localhost/36982] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:20:02,802 [Listener at localhost/36982] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:20:02,803 [Listener at localhost/36982] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:20:02,803 [Listener at localhost/36982] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:20:02,803 [Listener at localhost/36982] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:20:02,803 [Listener at localhost/36982] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:20:02,804 [Listener at localhost/36982] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:20:02,806 [Listener at localhost/36982] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:20:02,806 [Listener at localhost/36982] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:20:02,806 [Listener at localhost/36982] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:20:02,807 [Listener at localhost/36982] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:20:02,807 [Listener at localhost/36982] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:20:02,807 [Listener at localhost/36982] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:02,808 [Listener at localhost/36982] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:20:02,808 [Listener at localhost/36982] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:20:02,812 [Listener at localhost/36982] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:20:02,813 [Listener at localhost/36982] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:20:02,813 [Listener at localhost/36982] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:20:02,813 [Listener at localhost/36982] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:20:02,813 [Listener at localhost/36982] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:20:02,814 [Listener at localhost/36982] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:20:02,814 [Listener at localhost/36982] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:20:02,814 [Listener at localhost/36982] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:02,814 [Listener at localhost/36982] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:20:02,815 [Listener at localhost/36982] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:20:02,816 [Listener at localhost/36982] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:20:02,816 [Listener at localhost/36982] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:20:02,816 [Listener at localhost/36982] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:20:02,816 [Listener at localhost/36982] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:20:02,817 [Listener at localhost/36982] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:20:02,817 [Listener at localhost/36982] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:20:02,817 [Listener at localhost/36982] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:02,817 [Listener at localhost/36982] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:20:02,817 [Listener at localhost/36982] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:20:02,879 [Listener at localhost/36982] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 906@9ece31fe74eb
2020-12-03 07:20:02,972 [Listener at localhost/36982] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 906@9ece31fe74eb
2020-12-03 07:20:02,975 [Listener at localhost/36982] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-12-03 07:20:02,976 [Listener at localhost/36982] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-12-03 07:20:02,976 [Listener at localhost/36982] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:20:02,977 [Listener at localhost/36982] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:20:02,984 [Listener at localhost/36982] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:20:02,987 [Listener at localhost/36982] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:20:02,987 [Listener at localhost/36982] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-12-03 07:20:02,988 [Listener at localhost/36982] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:20:02,989 [Listener at localhost/36982] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 1
2020-12-03 07:20:03,124 [Listener at localhost/36982] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:20:03,125 [Listener at localhost/36982] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 304 msecs
2020-12-03 07:20:03,125 [Listener at localhost/36982] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:20:03,126 [Listener at localhost/36982] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:03,128 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:03,139 [Listener at localhost/45965] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:45965 to access this namenode/service.
2020-12-03 07:20:03,140 [Listener at localhost/45965] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:20:03,239 [Listener at localhost/45965] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:20:03,241 [Listener at localhost/45965] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:20:03,241 [Listener at localhost/45965] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:20:03,241 [Listener at localhost/45965] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:20:03,241 [Listener at localhost/45965] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:20:03,249 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 0
2020-12-03 07:20:03,249 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:20:03,249 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:20:03,249 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:20:03,249 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:20:03,249 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 8 msec
2020-12-03 07:20:03,252 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:03,252 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:03,268 [Listener at localhost/45965] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:45965
2020-12-03 07:20:03,269 [Listener at localhost/45965] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:20:03,269 [Listener at localhost/45965] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:20:03,275 [Listener at localhost/45965] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 4 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:20:03,280 [CacheReplicationMonitor(289740522)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:20:03,320 [Listener at localhost/45965] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:20:03,322 [Listener at localhost/45965] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:20:03,322 [Listener at localhost/45965] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:20:03,323 [Listener at localhost/45965] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:03,329 [Listener at localhost/45965] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:03,329 [Listener at localhost/45965] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:03,329 [Listener at localhost/45965] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:03,330 [Listener at localhost/45965] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:03,330 [Listener at localhost/45965] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:03,331 [Listener at localhost/45965] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:33969
2020-12-03 07:20:03,331 [Listener at localhost/45965] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:03,331 [Listener at localhost/45965] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:03,334 [Listener at localhost/45965] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:03,336 [Listener at localhost/45965] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:03,336 [Listener at localhost/45965] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:03,337 [Listener at localhost/45965] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:03,339 [Listener at localhost/45965] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:03,340 [Listener at localhost/45965] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:03,340 [Listener at localhost/45965] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:03,340 [Listener at localhost/45965] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:03,341 [Listener at localhost/45965] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 45767
2020-12-03 07:20:03,341 [Listener at localhost/45965] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:03,343 [Listener at localhost/45965] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@14379273{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:03,344 [Listener at localhost/45965] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@17740dae{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:03,351 [Listener at localhost/45965] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5136207f{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:20:03,357 [Listener at localhost/45965] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@14dd6bf{HTTP/1.1,[http/1.1]}{localhost:45767}
2020-12-03 07:20:03,357 [Listener at localhost/45965] INFO  server.Server (Server.java:doStart(419)) - Started @23090ms
2020-12-03 07:20:03,389 [Listener at localhost/45965] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:40274
2020-12-03 07:20:03,389 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3fdecce] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:03,389 [Listener at localhost/45965] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:03,390 [Listener at localhost/45965] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:03,390 [Listener at localhost/45965] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:03,391 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:03,421 [Listener at localhost/39687] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:39687
2020-12-03 07:20:03,482 [Listener at localhost/39687] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:20:03,482 [Listener at localhost/39687] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:20:03,484 [Thread-669] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45965 starting to offer service
2020-12-03 07:20:03,485 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:03,515 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:03,521 [Listener at localhost/39687] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:20:03,528 [Listener at localhost/39687] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:20:03,547 [Thread-669] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45965
2020-12-03 07:20:03,554 [Thread-669] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:03,559 [Listener at localhost/39687] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:20:03,574 [Listener at localhost/39687] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:03,575 [Listener at localhost/39687] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:03,580 [Listener at localhost/39687] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:03,580 [Listener at localhost/39687] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:03,581 [Listener at localhost/39687] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:03,581 [Listener at localhost/39687] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:03,582 [Listener at localhost/39687] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:40040
2020-12-03 07:20:03,582 [Listener at localhost/39687] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:03,582 [Listener at localhost/39687] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:03,583 [Listener at localhost/39687] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:03,612 [Listener at localhost/39687] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:03,613 [Listener at localhost/39687] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:03,613 [Thread-669] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 906@9ece31fe74eb
2020-12-03 07:20:03,613 [Listener at localhost/39687] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:03,613 [Thread-669] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 864125735. Formatting...
2020-12-03 07:20:03,614 [Thread-669] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-d45d6d51-9d05-49c1-a03f-41a2411d1148 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-12-03 07:20:03,636 [Listener at localhost/39687] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:03,637 [Listener at localhost/39687] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:03,637 [Listener at localhost/39687] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:03,637 [Listener at localhost/39687] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:03,639 [Listener at localhost/39687] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 45089
2020-12-03 07:20:03,640 [Listener at localhost/39687] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:03,643 [Listener at localhost/39687] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3c904f1e{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:03,644 [Listener at localhost/39687] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@d56aaa6{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:03,652 [Listener at localhost/39687] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@557286ad{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:20:03,657 [Listener at localhost/39687] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@b10a26d{HTTP/1.1,[http/1.1]}{localhost:45089}
2020-12-03 07:20:03,658 [Listener at localhost/39687] INFO  server.Server (Server.java:doStart(419)) - Started @23391ms
2020-12-03 07:20:03,698 [Listener at localhost/39687] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:42550
2020-12-03 07:20:03,699 [Listener at localhost/39687] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:03,699 [Listener at localhost/39687] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:03,699 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7e4d2287] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:03,700 [Listener at localhost/39687] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:03,701 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:03,704 [Listener at localhost/42283] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:42283
2020-12-03 07:20:03,734 [Thread-669] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 906@9ece31fe74eb
2020-12-03 07:20:03,735 [Thread-669] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 864125735. Formatting...
2020-12-03 07:20:03,735 [Thread-669] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-b3c09d28-5beb-480c-a8f7-27abf33879fa for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-12-03 07:20:03,783 [Listener at localhost/42283] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:20:03,784 [Listener at localhost/42283] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:20:03,784 [Thread-692] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45965 starting to offer service
2020-12-03 07:20:03,788 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:03,788 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:03,833 [Thread-669] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:03,833 [Thread-669] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:03,833 [Thread-669] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-1804082424-172.17.0.6-1606980002416 is not formatted. Formatting ...
2020-12-03 07:20:03,833 [Thread-669] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1804082424-172.17.0.6-1606980002416 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1804082424-172.17.0.6-1606980002416/current
2020-12-03 07:20:03,846 [Thread-692] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45965
2020-12-03 07:20:03,850 [Thread-692] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:03,861 [Listener at localhost/42283] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:20:03,862 [Listener at localhost/42283] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:20:03,863 [Listener at localhost/42283] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:20:03,863 [Listener at localhost/42283] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:03,864 [Listener at localhost/42283] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:03,864 [Listener at localhost/42283] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:03,865 [Listener at localhost/42283] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:03,865 [Listener at localhost/42283] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:03,865 [Listener at localhost/42283] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:03,866 [Listener at localhost/42283] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:39218
2020-12-03 07:20:03,866 [Listener at localhost/42283] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:03,866 [Listener at localhost/42283] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:03,867 [Listener at localhost/42283] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:03,869 [Listener at localhost/42283] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:03,873 [Listener at localhost/42283] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:03,874 [Listener at localhost/42283] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:03,876 [Listener at localhost/42283] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:03,877 [Listener at localhost/42283] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:03,877 [Listener at localhost/42283] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:03,877 [Listener at localhost/42283] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:03,878 [Listener at localhost/42283] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 46326
2020-12-03 07:20:03,878 [Listener at localhost/42283] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:03,880 [Listener at localhost/42283] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@8bffb8b{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:03,880 [Listener at localhost/42283] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@10ee04df{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:03,888 [Listener at localhost/42283] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@43034809{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:20:03,888 [Listener at localhost/42283] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@39e67516{HTTP/1.1,[http/1.1]}{localhost:46326}
2020-12-03 07:20:03,888 [Listener at localhost/42283] INFO  server.Server (Server.java:doStart(419)) - Started @23622ms
2020-12-03 07:20:03,918 [Listener at localhost/42283] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:36862
2020-12-03 07:20:03,919 [Thread-692] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 906@9ece31fe74eb
2020-12-03 07:20:03,920 [Thread-692] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 is not formatted for namespace 864125735. Formatting...
2020-12-03 07:20:03,920 [Thread-692] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-8bb132b5-cd57-4c73-9bc1-319b35c80433 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 
2020-12-03 07:20:03,922 [Listener at localhost/42283] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:03,922 [Listener at localhost/42283] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:03,928 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4bb003e9] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:03,932 [Listener at localhost/42283] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:03,933 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:03,940 [Listener at localhost/37261] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:37261
2020-12-03 07:20:03,958 [Thread-669] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:03,958 [Thread-669] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:03,959 [Thread-669] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-1804082424-172.17.0.6-1606980002416 is not formatted. Formatting ...
2020-12-03 07:20:03,959 [Thread-669] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1804082424-172.17.0.6-1606980002416 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1804082424-172.17.0.6-1606980002416/current
2020-12-03 07:20:03,976 [Listener at localhost/37261] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:20:03,976 [Listener at localhost/37261] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:20:03,978 [Thread-714] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45965 starting to offer service
2020-12-03 07:20:03,990 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:03,990 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:03,994 [Thread-714] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45965
2020-12-03 07:20:03,997 [Thread-714] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:03,997 [Listener at localhost/37261] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 3 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:20:03,999 [Listener at localhost/37261] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:20:03,999 [Listener at localhost/37261] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:20:04,000 [Listener at localhost/37261] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:04,003 [Listener at localhost/37261] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:04,003 [Listener at localhost/37261] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:04,004 [Listener at localhost/37261] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:04,004 [Listener at localhost/37261] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:04,004 [Listener at localhost/37261] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:04,018 [Listener at localhost/37261] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:33010
2020-12-03 07:20:04,020 [Listener at localhost/37261] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:04,026 [Listener at localhost/37261] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:04,053 [Listener at localhost/37261] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:04,055 [Listener at localhost/37261] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:04,056 [Listener at localhost/37261] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:04,056 [Listener at localhost/37261] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:04,058 [Listener at localhost/37261] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:04,058 [Listener at localhost/37261] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:04,058 [Listener at localhost/37261] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:04,058 [Listener at localhost/37261] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:04,059 [Listener at localhost/37261] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 39104
2020-12-03 07:20:04,059 [Listener at localhost/37261] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:04,061 [Listener at localhost/37261] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@184dbacc{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:04,062 [Listener at localhost/37261] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@359ff4d9{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:04,067 [Listener at localhost/37261] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@30501e60{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:20:04,067 [Listener at localhost/37261] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@289778cd{HTTP/1.1,[http/1.1]}{localhost:39104}
2020-12-03 07:20:04,068 [Listener at localhost/37261] INFO  server.Server (Server.java:doStart(419)) - Started @23801ms
2020-12-03 07:20:04,085 [Thread-714] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 906@9ece31fe74eb
2020-12-03 07:20:04,087 [Thread-714] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 is not formatted for namespace 864125735. Formatting...
2020-12-03 07:20:04,098 [Thread-714] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-f419cf0c-b1ed-45ba-adce-834ed42a8b9d for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 
2020-12-03 07:20:04,133 [Thread-692] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 906@9ece31fe74eb
2020-12-03 07:20:04,147 [Thread-669] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=864125735;bpid=BP-1804082424-172.17.0.6-1606980002416;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=864125735;c=1606980002416;bpid=BP-1804082424-172.17.0.6-1606980002416;dnuuid=null
2020-12-03 07:20:04,147 [Thread-692] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 is not formatted for namespace 864125735. Formatting...
2020-12-03 07:20:04,139 [Listener at localhost/37261] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:35466
2020-12-03 07:20:04,147 [Thread-692] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-b474ebdb-2378-43e8-b4f8-eddd6e6af004 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 
2020-12-03 07:20:04,148 [Listener at localhost/37261] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:04,148 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7c2312fa] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:04,148 [Listener at localhost/37261] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:04,148 [Listener at localhost/37261] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:04,149 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:04,154 [Listener at localhost/44957] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:44957
2020-12-03 07:20:04,166 [Listener at localhost/44957] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:20:04,167 [Listener at localhost/44957] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:20:04,168 [Thread-736] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45965 starting to offer service
2020-12-03 07:20:04,177 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:04,179 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:04,181 [Thread-736] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45965
2020-12-03 07:20:04,185 [Thread-736] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:04,186 [Listener at localhost/44957] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 4 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:20:04,187 [Listener at localhost/44957] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:20:04,187 [Listener at localhost/44957] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:20:04,189 [Listener at localhost/44957] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:04,190 [Listener at localhost/44957] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:04,190 [Listener at localhost/44957] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:04,191 [Listener at localhost/44957] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:04,191 [Listener at localhost/44957] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:04,191 [Listener at localhost/44957] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:04,192 [Listener at localhost/44957] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:42042
2020-12-03 07:20:04,192 [Listener at localhost/44957] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:04,192 [Listener at localhost/44957] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:04,193 [Listener at localhost/44957] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:04,194 [Listener at localhost/44957] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:04,195 [Listener at localhost/44957] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:04,195 [Listener at localhost/44957] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:04,196 [Listener at localhost/44957] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:04,197 [Listener at localhost/44957] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:04,197 [Listener at localhost/44957] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:04,197 [Listener at localhost/44957] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:04,198 [Listener at localhost/44957] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 34573
2020-12-03 07:20:04,198 [Listener at localhost/44957] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:04,199 [Listener at localhost/44957] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@13f9ad9{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:04,200 [Listener at localhost/44957] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@21f8e55f{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:04,204 [Listener at localhost/44957] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7b4acdc2{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:20:04,205 [Listener at localhost/44957] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@26a262d6{HTTP/1.1,[http/1.1]}{localhost:34573}
2020-12-03 07:20:04,205 [Listener at localhost/44957] INFO  server.Server (Server.java:doStart(419)) - Started @23938ms
2020-12-03 07:20:04,232 [Listener at localhost/44957] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:40958
2020-12-03 07:20:04,232 [Listener at localhost/44957] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:04,233 [Listener at localhost/44957] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:04,233 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@58f07f02] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:04,234 [Listener at localhost/44957] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:04,236 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:04,242 [Listener at localhost/39229] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:39229
2020-12-03 07:20:04,248 [Listener at localhost/39229] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:20:04,248 [Listener at localhost/39229] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:20:04,249 [Thread-758] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45965 starting to offer service
2020-12-03 07:20:04,251 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:04,256 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:04,258 [Thread-758] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45965
2020-12-03 07:20:04,262 [Thread-758] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:04,264 [Listener at localhost/39229] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 5 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:20:04,275 [Listener at localhost/39229] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:20:04,293 [Listener at localhost/39229] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:20:04,294 [Listener at localhost/39229] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:04,295 [Listener at localhost/39229] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:04,296 [Listener at localhost/39229] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:04,296 [Listener at localhost/39229] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:04,296 [Listener at localhost/39229] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:04,296 [Listener at localhost/39229] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:04,297 [Listener at localhost/39229] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:44728
2020-12-03 07:20:04,297 [Thread-736] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/in_use.lock acquired by nodename 906@9ece31fe74eb
2020-12-03 07:20:04,297 [Listener at localhost/39229] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:04,298 [Listener at localhost/39229] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:04,298 [Thread-736] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 is not formatted for namespace 864125735. Formatting...
2020-12-03 07:20:04,298 [Thread-736] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-c0dee4e4-fa07-40af-b816-6f0b88fb9f12 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 
2020-12-03 07:20:04,299 [Listener at localhost/39229] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:04,301 [Listener at localhost/39229] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:04,302 [Listener at localhost/39229] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:04,302 [Listener at localhost/39229] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:04,304 [Listener at localhost/39229] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:04,304 [Listener at localhost/39229] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:04,304 [Listener at localhost/39229] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:04,304 [Listener at localhost/39229] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:04,305 [Listener at localhost/39229] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 45954
2020-12-03 07:20:04,305 [Listener at localhost/39229] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:04,307 [Listener at localhost/39229] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5c9ac4cc{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:04,308 [Listener at localhost/39229] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2264e43c{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:04,313 [Listener at localhost/39229] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@4ad3d266{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:20:04,314 [Listener at localhost/39229] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3533df16{HTTP/1.1,[http/1.1]}{localhost:45954}
2020-12-03 07:20:04,314 [Listener at localhost/39229] INFO  server.Server (Server.java:doStart(419)) - Started @24047ms
2020-12-03 07:20:04,331 [Listener at localhost/39229] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:45743
2020-12-03 07:20:04,331 [Listener at localhost/39229] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:04,331 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4038cd3a] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:04,331 [Listener at localhost/39229] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:04,332 [Listener at localhost/39229] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:04,333 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:04,336 [Listener at localhost/41968] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:41968
2020-12-03 07:20:04,340 [Listener at localhost/41968] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:20:04,341 [Listener at localhost/41968] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:20:04,341 [Thread-780] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45965 starting to offer service
2020-12-03 07:20:04,342 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:04,342 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:04,348 [Listener at localhost/41968] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 6 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:20:04,349 [Listener at localhost/41968] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:20:04,349 [Listener at localhost/41968] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:20:04,351 [Listener at localhost/41968] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:04,351 [Listener at localhost/41968] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:04,356 [Listener at localhost/41968] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:04,363 [Thread-714] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 906@9ece31fe74eb
2020-12-03 07:20:04,364 [Thread-714] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 is not formatted for namespace 864125735. Formatting...
2020-12-03 07:20:04,363 [Thread-758] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/in_use.lock acquired by nodename 906@9ece31fe74eb
2020-12-03 07:20:04,364 [Thread-714] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-65455744-ec66-4856-99b0-9225eafc9da5 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 
2020-12-03 07:20:04,364 [Thread-758] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 is not formatted for namespace 864125735. Formatting...
2020-12-03 07:20:04,364 [Thread-758] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-ee267448-1a4d-452b-be30-3480ab792404 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 
2020-12-03 07:20:04,374 [Thread-669] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID c5ae0664-cc27-4ff3-9558-7d39c9eabf00
2020-12-03 07:20:04,377 [Listener at localhost/41968] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:04,377 [Thread-669] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-d45d6d51-9d05-49c1-a03f-41a2411d1148
2020-12-03 07:20:04,377 [Thread-669] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-12-03 07:20:04,377 [Thread-780] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45965
2020-12-03 07:20:04,377 [Listener at localhost/41968] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:04,379 [Thread-780] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:04,384 [Listener at localhost/41968] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:04,386 [Listener at localhost/41968] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:46071
2020-12-03 07:20:04,386 [Listener at localhost/41968] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:04,386 [Listener at localhost/41968] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:04,384 [Thread-669] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-b3c09d28-5beb-480c-a8f7-27abf33879fa
2020-12-03 07:20:04,387 [Thread-669] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-12-03 07:20:04,387 [Listener at localhost/41968] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:04,387 [Thread-669] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:04,389 [Thread-669] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:20:04,389 [Listener at localhost/41968] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:04,389 [Thread-669] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:20:04,389 [Listener at localhost/41968] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:04,389 [Thread-669] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:20:04,390 [Thread-669] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:20:04,390 [Listener at localhost/41968] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:04,390 [Thread-669] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:04,391 [Thread-796] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:20:04,391 [Thread-692] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:04,391 [Thread-795] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:20:04,392 [Thread-692] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:04,392 [Thread-692] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 and block pool id BP-1804082424-172.17.0.6-1606980002416 is not formatted. Formatting ...
2020-12-03 07:20:04,392 [Thread-692] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1804082424-172.17.0.6-1606980002416 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1804082424-172.17.0.6-1606980002416/current
2020-12-03 07:20:04,392 [Listener at localhost/41968] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:04,393 [Listener at localhost/41968] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:04,393 [Listener at localhost/41968] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:04,393 [Listener at localhost/41968] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:04,394 [Listener at localhost/41968] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 42438
2020-12-03 07:20:04,394 [Listener at localhost/41968] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:04,396 [Listener at localhost/41968] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6145b81e{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:04,397 [Listener at localhost/41968] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@64b7225f{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:04,404 [Listener at localhost/41968] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@66153688{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:20:04,405 [Listener at localhost/41968] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@455824ad{HTTP/1.1,[http/1.1]}{localhost:42438}
2020-12-03 07:20:04,405 [Listener at localhost/41968] INFO  server.Server (Server.java:doStart(419)) - Started @24138ms
2020-12-03 07:20:04,427 [Thread-796] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1804082424-172.17.0.6-1606980002416 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 36ms
2020-12-03 07:20:04,429 [Thread-795] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1804082424-172.17.0.6-1606980002416 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 38ms
2020-12-03 07:20:04,430 [Thread-669] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1804082424-172.17.0.6-1606980002416: 39ms
2020-12-03 07:20:04,430 [Thread-802] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:20:04,430 [Thread-803] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:20:04,430 [Thread-802] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1804082424-172.17.0.6-1606980002416/current/replicas doesn't exist 
2020-12-03 07:20:04,430 [Thread-803] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1804082424-172.17.0.6-1606980002416/current/replicas doesn't exist 
2020-12-03 07:20:04,433 [Thread-802] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 3ms
2020-12-03 07:20:04,433 [Thread-803] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 3ms
2020-12-03 07:20:04,434 [Thread-669] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416: 4ms
2020-12-03 07:20:04,434 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:20:04,434 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:20:04,434 [Thread-669] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 8:44 AM with interval of 21600000ms
2020-12-03 07:20:04,434 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-b3c09d28-5beb-480c-a8f7-27abf33879fa): finished scanning block pool BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:04,435 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-d45d6d51-9d05-49c1-a03f-41a2411d1148): finished scanning block pool BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:04,436 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1804082424-172.17.0.6-1606980002416 (Datanode Uuid c5ae0664-cc27-4ff3-9558-7d39c9eabf00) service to localhost/127.0.0.1:45965 beginning handshake with NN
2020-12-03 07:20:04,438 [IPC Server handler 2 on default port 45965] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:33969, datanodeUuid=c5ae0664-cc27-4ff3-9558-7d39c9eabf00, infoPort=40274, infoSecurePort=0, ipcPort=39687, storageInfo=lv=-57;cid=testClusterID;nsid=864125735;c=1606980002416) storage c5ae0664-cc27-4ff3-9558-7d39c9eabf00
2020-12-03 07:20:04,438 [IPC Server handler 2 on default port 45965] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:33969
2020-12-03 07:20:04,438 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-b3c09d28-5beb-480c-a8f7-27abf33879fa): no suitable block pools found to scan.  Waiting 1814399996 ms.
2020-12-03 07:20:04,438 [IPC Server handler 2 on default port 45965] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN c5ae0664-cc27-4ff3-9558-7d39c9eabf00 (127.0.0.1:33969).
2020-12-03 07:20:04,438 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-d45d6d51-9d05-49c1-a03f-41a2411d1148): no suitable block pools found to scan.  Waiting 1814399996 ms.
2020-12-03 07:20:04,440 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1804082424-172.17.0.6-1606980002416 (Datanode Uuid c5ae0664-cc27-4ff3-9558-7d39c9eabf00) service to localhost/127.0.0.1:45965 successfully registered with NN
2020-12-03 07:20:04,440 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:45965 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:04,442 [IPC Server handler 3 on default port 45965] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d45d6d51-9d05-49c1-a03f-41a2411d1148 for DN 127.0.0.1:33969
2020-12-03 07:20:04,442 [IPC Server handler 3 on default port 45965] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-b3c09d28-5beb-480c-a8f7-27abf33879fa for DN 127.0.0.1:33969
2020-12-03 07:20:04,446 [Listener at localhost/41968] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:43356
2020-12-03 07:20:04,446 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x3428411b077bf331: Processing first storage report for DS-b3c09d28-5beb-480c-a8f7-27abf33879fa from datanode c5ae0664-cc27-4ff3-9558-7d39c9eabf00
2020-12-03 07:20:04,446 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x3428411b077bf331: from storage DS-b3c09d28-5beb-480c-a8f7-27abf33879fa node DatanodeRegistration(127.0.0.1:33969, datanodeUuid=c5ae0664-cc27-4ff3-9558-7d39c9eabf00, infoPort=40274, infoSecurePort=0, ipcPort=39687, storageInfo=lv=-57;cid=testClusterID;nsid=864125735;c=1606980002416), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:20:04,446 [Listener at localhost/41968] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:04,447 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@70f31322] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:04,447 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x3428411b077bf331: Processing first storage report for DS-d45d6d51-9d05-49c1-a03f-41a2411d1148 from datanode c5ae0664-cc27-4ff3-9558-7d39c9eabf00
2020-12-03 07:20:04,447 [Listener at localhost/41968] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:04,447 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x3428411b077bf331: from storage DS-d45d6d51-9d05-49c1-a03f-41a2411d1148 node DatanodeRegistration(127.0.0.1:33969, datanodeUuid=c5ae0664-cc27-4ff3-9558-7d39c9eabf00, infoPort=40274, infoSecurePort=0, ipcPort=39687, storageInfo=lv=-57;cid=testClusterID;nsid=864125735;c=1606980002416), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:20:04,448 [Listener at localhost/41968] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:04,448 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x3428411b077bf331,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:04,448 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:04,449 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:04,453 [Listener at localhost/45406] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:45406
2020-12-03 07:20:04,458 [Listener at localhost/45406] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:20:04,458 [Listener at localhost/45406] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:20:04,459 [Thread-813] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45965 starting to offer service
2020-12-03 07:20:04,460 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:04,460 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:04,462 [Thread-813] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45965
2020-12-03 07:20:04,463 [Thread-813] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:04,464 [Listener at localhost/45406] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 7 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:20:04,465 [Listener at localhost/45406] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:20:04,466 [Listener at localhost/45406] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:20:04,466 [Listener at localhost/45406] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:04,469 [Listener at localhost/45406] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:04,469 [Listener at localhost/45406] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:04,469 [Listener at localhost/45406] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:04,469 [Listener at localhost/45406] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:04,470 [Listener at localhost/45406] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:04,470 [Listener at localhost/45406] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:35620
2020-12-03 07:20:04,470 [Listener at localhost/45406] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:04,471 [Listener at localhost/45406] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:04,471 [Thread-780] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/in_use.lock acquired by nodename 906@9ece31fe74eb
2020-12-03 07:20:04,471 [Thread-780] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 is not formatted for namespace 864125735. Formatting...
2020-12-03 07:20:04,472 [Listener at localhost/45406] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:04,472 [Thread-780] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-2846ef14-7d0f-45aa-b4f1-52040a358f03 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 
2020-12-03 07:20:04,473 [Listener at localhost/45406] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:04,474 [Listener at localhost/45406] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:04,474 [Listener at localhost/45406] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:04,475 [Listener at localhost/45406] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:04,476 [Listener at localhost/45406] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:04,476 [Listener at localhost/45406] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:04,476 [Listener at localhost/45406] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:04,477 [Listener at localhost/45406] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 41690
2020-12-03 07:20:04,477 [Listener at localhost/45406] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:04,478 [Listener at localhost/45406] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@77a2aa4a{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:04,479 [Listener at localhost/45406] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2b917fb0{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:04,483 [Listener at localhost/45406] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6bf13698{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:20:04,485 [Listener at localhost/45406] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@299270eb{HTTP/1.1,[http/1.1]}{localhost:41690}
2020-12-03 07:20:04,485 [Listener at localhost/45406] INFO  server.Server (Server.java:doStart(419)) - Started @24218ms
2020-12-03 07:20:04,501 [Listener at localhost/45406] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:40386
2020-12-03 07:20:04,502 [Listener at localhost/45406] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:04,502 [Listener at localhost/45406] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:04,502 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@69fa8e76] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:04,502 [Listener at localhost/45406] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:04,503 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:04,507 [Listener at localhost/46668] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:46668
2020-12-03 07:20:04,512 [Listener at localhost/46668] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:20:04,513 [Listener at localhost/46668] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:20:04,514 [Thread-835] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45965 starting to offer service
2020-12-03 07:20:04,515 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:04,515 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:04,521 [Thread-835] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45965
2020-12-03 07:20:04,522 [Thread-835] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:04,526 [IPC Server handler 7 on default port 45965] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:04,527 [Listener at localhost/46668] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:04,527 [Listener at localhost/46668] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:04,553 [Thread-813] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/in_use.lock acquired by nodename 906@9ece31fe74eb
2020-12-03 07:20:04,553 [Thread-813] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 is not formatted for namespace 864125735. Formatting...
2020-12-03 07:20:04,556 [Thread-813] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-e393a8d1-0f5b-4659-b3f3-ec668d265860 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 
2020-12-03 07:20:04,627 [Thread-835] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/in_use.lock acquired by nodename 906@9ece31fe74eb
2020-12-03 07:20:04,628 [Thread-835] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 is not formatted for namespace 864125735. Formatting...
2020-12-03 07:20:04,628 [Thread-835] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-1d5f4027-0413-4b3d-bce3-7989772d6afc for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 
2020-12-03 07:20:04,629 [IPC Server handler 1 on default port 45965] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:04,631 [Listener at localhost/46668] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:04,631 [Listener at localhost/46668] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:04,638 [Thread-714] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:04,638 [Thread-692] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:04,638 [Thread-714] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:04,638 [Thread-692] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:04,638 [Thread-714] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 and block pool id BP-1804082424-172.17.0.6-1606980002416 is not formatted. Formatting ...
2020-12-03 07:20:04,639 [Thread-692] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 and block pool id BP-1804082424-172.17.0.6-1606980002416 is not formatted. Formatting ...
2020-12-03 07:20:04,639 [Thread-714] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1804082424-172.17.0.6-1606980002416 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1804082424-172.17.0.6-1606980002416/current
2020-12-03 07:20:04,639 [Thread-692] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1804082424-172.17.0.6-1606980002416 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1804082424-172.17.0.6-1606980002416/current
2020-12-03 07:20:04,683 [Thread-736] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/in_use.lock acquired by nodename 906@9ece31fe74eb
2020-12-03 07:20:04,684 [Thread-736] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 is not formatted for namespace 864125735. Formatting...
2020-12-03 07:20:04,685 [Thread-736] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-43a9d23d-614e-4a58-99ac-e73442c82f51 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 
2020-12-03 07:20:04,733 [IPC Server handler 8 on default port 45965] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:04,734 [Listener at localhost/46668] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:04,734 [Listener at localhost/46668] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:04,765 [Thread-758] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/in_use.lock acquired by nodename 906@9ece31fe74eb
2020-12-03 07:20:04,766 [Thread-758] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 is not formatted for namespace 864125735. Formatting...
2020-12-03 07:20:04,766 [Thread-758] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-512a29a1-592b-4a6b-9e0b-372194c82b1f for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 
2020-12-03 07:20:04,836 [IPC Server handler 9 on default port 45965] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:04,837 [Listener at localhost/46668] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:04,837 [Listener at localhost/46668] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:04,884 [Thread-780] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/in_use.lock acquired by nodename 906@9ece31fe74eb
2020-12-03 07:20:04,884 [Thread-780] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 is not formatted for namespace 864125735. Formatting...
2020-12-03 07:20:04,885 [Thread-780] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-fde66b64-bf3d-4e52-a9d8-47e9e976c8ea for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 
2020-12-03 07:20:04,885 [Thread-692] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=864125735;bpid=BP-1804082424-172.17.0.6-1606980002416;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=864125735;c=1606980002416;bpid=BP-1804082424-172.17.0.6-1606980002416;dnuuid=null
2020-12-03 07:20:04,895 [Thread-714] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:04,896 [Thread-714] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:04,896 [Thread-714] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 and block pool id BP-1804082424-172.17.0.6-1606980002416 is not formatted. Formatting ...
2020-12-03 07:20:04,896 [Thread-714] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1804082424-172.17.0.6-1606980002416 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1804082424-172.17.0.6-1606980002416/current
2020-12-03 07:20:04,938 [IPC Server handler 0 on default port 45965] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:04,940 [Listener at localhost/46668] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:04,940 [Listener at localhost/46668] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:04,959 [Thread-813] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/in_use.lock acquired by nodename 906@9ece31fe74eb
2020-12-03 07:20:04,960 [Thread-813] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 is not formatted for namespace 864125735. Formatting...
2020-12-03 07:20:04,961 [Thread-813] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-034e39a9-7d42-4606-aaed-1b5bf00d1e13 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 
2020-12-03 07:20:04,970 [Thread-736] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:04,970 [Thread-736] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:04,970 [Thread-736] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 and block pool id BP-1804082424-172.17.0.6-1606980002416 is not formatted. Formatting ...
2020-12-03 07:20:04,970 [Thread-736] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1804082424-172.17.0.6-1606980002416 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1804082424-172.17.0.6-1606980002416/current
2020-12-03 07:20:05,027 [Thread-835] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/in_use.lock acquired by nodename 906@9ece31fe74eb
2020-12-03 07:20:05,028 [Thread-835] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 is not formatted for namespace 864125735. Formatting...
2020-12-03 07:20:05,030 [Thread-835] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-9430fa01-b843-4ce1-b229-c4ef32f58568 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 
2020-12-03 07:20:05,035 [Thread-758] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:05,036 [Thread-758] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:05,036 [Thread-758] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 and block pool id BP-1804082424-172.17.0.6-1606980002416 is not formatted. Formatting ...
2020-12-03 07:20:05,036 [Thread-758] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1804082424-172.17.0.6-1606980002416 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1804082424-172.17.0.6-1606980002416/current
2020-12-03 07:20:05,041 [IPC Server handler 2 on default port 45965] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:05,042 [Listener at localhost/46668] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:05,042 [Listener at localhost/46668] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:05,144 [IPC Server handler 3 on default port 45965] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:05,145 [Listener at localhost/46668] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:05,145 [Listener at localhost/46668] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:05,164 [Thread-692] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 2ed09fef-76ca-4e59-b76b-c7e5fbb353e7
2020-12-03 07:20:05,164 [Thread-714] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=864125735;bpid=BP-1804082424-172.17.0.6-1606980002416;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=864125735;c=1606980002416;bpid=BP-1804082424-172.17.0.6-1606980002416;dnuuid=null
2020-12-03 07:20:05,166 [Thread-692] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-8bb132b5-cd57-4c73-9bc1-319b35c80433
2020-12-03 07:20:05,166 [Thread-692] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: DISK
2020-12-03 07:20:05,175 [Thread-692] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-b474ebdb-2378-43e8-b4f8-eddd6e6af004
2020-12-03 07:20:05,185 [Thread-692] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: DISK
2020-12-03 07:20:05,185 [Thread-692] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:05,187 [Thread-692] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:20:05,187 [Thread-692] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:20:05,187 [Thread-692] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:20:05,187 [Thread-692] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:20:05,188 [Thread-692] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:05,188 [Thread-849] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:20:05,188 [Thread-850] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:20:05,197 [Thread-780] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:05,197 [Thread-780] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:05,197 [Thread-780] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 and block pool id BP-1804082424-172.17.0.6-1606980002416 is not formatted. Formatting ...
2020-12-03 07:20:05,198 [Thread-780] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1804082424-172.17.0.6-1606980002416 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1804082424-172.17.0.6-1606980002416/current
2020-12-03 07:20:05,220 [Thread-849] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1804082424-172.17.0.6-1606980002416 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 31ms
2020-12-03 07:20:05,220 [Thread-850] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1804082424-172.17.0.6-1606980002416 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 32ms
2020-12-03 07:20:05,220 [Thread-692] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1804082424-172.17.0.6-1606980002416: 33ms
2020-12-03 07:20:05,221 [Thread-853] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:20:05,221 [Thread-854] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:20:05,221 [Thread-853] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1804082424-172.17.0.6-1606980002416/current/replicas doesn't exist 
2020-12-03 07:20:05,221 [Thread-854] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1804082424-172.17.0.6-1606980002416/current/replicas doesn't exist 
2020-12-03 07:20:05,221 [Thread-853] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 1ms
2020-12-03 07:20:05,221 [Thread-854] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 1ms
2020-12-03 07:20:05,221 [Thread-692] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416: 1ms
2020-12-03 07:20:05,222 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:20:05,222 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:20:05,222 [Thread-692] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 7:47 AM with interval of 21600000ms
2020-12-03 07:20:05,222 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-b474ebdb-2378-43e8-b4f8-eddd6e6af004): finished scanning block pool BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:05,222 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-8bb132b5-cd57-4c73-9bc1-319b35c80433): finished scanning block pool BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:05,224 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1804082424-172.17.0.6-1606980002416 (Datanode Uuid 2ed09fef-76ca-4e59-b76b-c7e5fbb353e7) service to localhost/127.0.0.1:45965 beginning handshake with NN
2020-12-03 07:20:05,224 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-b474ebdb-2378-43e8-b4f8-eddd6e6af004): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-12-03 07:20:05,224 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-8bb132b5-cd57-4c73-9bc1-319b35c80433): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-12-03 07:20:05,225 [IPC Server handler 4 on default port 45965] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:40040, datanodeUuid=2ed09fef-76ca-4e59-b76b-c7e5fbb353e7, infoPort=42550, infoSecurePort=0, ipcPort=42283, storageInfo=lv=-57;cid=testClusterID;nsid=864125735;c=1606980002416) storage 2ed09fef-76ca-4e59-b76b-c7e5fbb353e7
2020-12-03 07:20:05,225 [IPC Server handler 4 on default port 45965] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:40040
2020-12-03 07:20:05,225 [IPC Server handler 4 on default port 45965] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 2ed09fef-76ca-4e59-b76b-c7e5fbb353e7 (127.0.0.1:40040).
2020-12-03 07:20:05,226 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1804082424-172.17.0.6-1606980002416 (Datanode Uuid 2ed09fef-76ca-4e59-b76b-c7e5fbb353e7) service to localhost/127.0.0.1:45965 successfully registered with NN
2020-12-03 07:20:05,226 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:45965 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:05,237 [Thread-736] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:05,238 [Thread-736] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:05,238 [Thread-736] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 and block pool id BP-1804082424-172.17.0.6-1606980002416 is not formatted. Formatting ...
2020-12-03 07:20:05,238 [Thread-736] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1804082424-172.17.0.6-1606980002416 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1804082424-172.17.0.6-1606980002416/current
2020-12-03 07:20:05,242 [Thread-813] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:05,242 [Thread-813] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:05,242 [Thread-813] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 and block pool id BP-1804082424-172.17.0.6-1606980002416 is not formatted. Formatting ...
2020-12-03 07:20:05,242 [Thread-813] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1804082424-172.17.0.6-1606980002416 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1804082424-172.17.0.6-1606980002416/current
2020-12-03 07:20:05,243 [IPC Server handler 5 on default port 45965] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-8bb132b5-cd57-4c73-9bc1-319b35c80433 for DN 127.0.0.1:40040
2020-12-03 07:20:05,245 [IPC Server handler 5 on default port 45965] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-b474ebdb-2378-43e8-b4f8-eddd6e6af004 for DN 127.0.0.1:40040
2020-12-03 07:20:05,246 [IPC Server handler 6 on default port 45965] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:05,247 [Listener at localhost/46668] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:05,251 [Listener at localhost/46668] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:05,247 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x728d5a234158edd3: Processing first storage report for DS-b474ebdb-2378-43e8-b4f8-eddd6e6af004 from datanode 2ed09fef-76ca-4e59-b76b-c7e5fbb353e7
2020-12-03 07:20:05,251 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x728d5a234158edd3: from storage DS-b474ebdb-2378-43e8-b4f8-eddd6e6af004 node DatanodeRegistration(127.0.0.1:40040, datanodeUuid=2ed09fef-76ca-4e59-b76b-c7e5fbb353e7, infoPort=42550, infoSecurePort=0, ipcPort=42283, storageInfo=lv=-57;cid=testClusterID;nsid=864125735;c=1606980002416), blocks: 0, hasStaleStorage: true, processing time: 4 msecs, invalidatedBlocks: 0
2020-12-03 07:20:05,252 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x728d5a234158edd3: Processing first storage report for DS-8bb132b5-cd57-4c73-9bc1-319b35c80433 from datanode 2ed09fef-76ca-4e59-b76b-c7e5fbb353e7
2020-12-03 07:20:05,252 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x728d5a234158edd3: from storage DS-8bb132b5-cd57-4c73-9bc1-319b35c80433 node DatanodeRegistration(127.0.0.1:40040, datanodeUuid=2ed09fef-76ca-4e59-b76b-c7e5fbb353e7, infoPort=42550, infoSecurePort=0, ipcPort=42283, storageInfo=lv=-57;cid=testClusterID;nsid=864125735;c=1606980002416), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:05,253 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x728d5a234158edd3,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 7 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:05,254 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:05,317 [Thread-835] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:05,317 [Thread-835] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:05,317 [Thread-835] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 and block pool id BP-1804082424-172.17.0.6-1606980002416 is not formatted. Formatting ...
2020-12-03 07:20:05,318 [Thread-835] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1804082424-172.17.0.6-1606980002416 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1804082424-172.17.0.6-1606980002416/current
2020-12-03 07:20:05,322 [Thread-758] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:05,322 [Thread-758] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:05,323 [Thread-758] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 and block pool id BP-1804082424-172.17.0.6-1606980002416 is not formatted. Formatting ...
2020-12-03 07:20:05,323 [Thread-758] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1804082424-172.17.0.6-1606980002416 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1804082424-172.17.0.6-1606980002416/current
2020-12-03 07:20:05,353 [IPC Server handler 1 on default port 45965] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:05,354 [Listener at localhost/46668] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:05,354 [Listener at localhost/46668] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:05,456 [IPC Server handler 8 on default port 45965] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:05,457 [Listener at localhost/46668] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:05,457 [Listener at localhost/46668] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:05,467 [Thread-714] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID de098be8-3b57-427f-9f60-e85f3df9f694
2020-12-03 07:20:05,469 [Thread-714] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-f419cf0c-b1ed-45ba-adce-834ed42a8b9d
2020-12-03 07:20:05,470 [Thread-714] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, StorageType: DISK
2020-12-03 07:20:05,471 [Thread-714] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-65455744-ec66-4856-99b0-9225eafc9da5
2020-12-03 07:20:05,472 [Thread-714] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, StorageType: DISK
2020-12-03 07:20:05,473 [Thread-714] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:05,474 [Thread-714] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:20:05,474 [Thread-714] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:20:05,475 [Thread-714] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:20:05,475 [Thread-714] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:20:05,476 [Thread-714] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:05,477 [Thread-860] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:20:05,481 [Thread-780] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:05,482 [Thread-780] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:05,482 [Thread-780] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 and block pool id BP-1804082424-172.17.0.6-1606980002416 is not formatted. Formatting ...
2020-12-03 07:20:05,482 [Thread-780] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1804082424-172.17.0.6-1606980002416 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1804082424-172.17.0.6-1606980002416/current
2020-12-03 07:20:05,483 [Thread-861] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:20:05,511 [Thread-860] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1804082424-172.17.0.6-1606980002416 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 33ms
2020-12-03 07:20:05,513 [Thread-861] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1804082424-172.17.0.6-1606980002416 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 30ms
2020-12-03 07:20:05,513 [Thread-714] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1804082424-172.17.0.6-1606980002416: 36ms
2020-12-03 07:20:05,513 [Thread-864] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:20:05,513 [Thread-865] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:20:05,513 [Thread-864] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1804082424-172.17.0.6-1606980002416/current/replicas doesn't exist 
2020-12-03 07:20:05,513 [Thread-865] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1804082424-172.17.0.6-1606980002416/current/replicas doesn't exist 
2020-12-03 07:20:05,514 [Thread-864] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 0ms
2020-12-03 07:20:05,514 [Thread-865] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 0ms
2020-12-03 07:20:05,514 [Thread-714] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416: 2ms
2020-12-03 07:20:05,514 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:20:05,514 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:20:05,515 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-65455744-ec66-4856-99b0-9225eafc9da5): finished scanning block pool BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:05,515 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-f419cf0c-b1ed-45ba-adce-834ed42a8b9d): finished scanning block pool BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:05,515 [Thread-714] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 7:32 AM with interval of 21600000ms
2020-12-03 07:20:05,515 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-65455744-ec66-4856-99b0-9225eafc9da5): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:20:05,515 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-f419cf0c-b1ed-45ba-adce-834ed42a8b9d): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:20:05,518 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1804082424-172.17.0.6-1606980002416 (Datanode Uuid de098be8-3b57-427f-9f60-e85f3df9f694) service to localhost/127.0.0.1:45965 beginning handshake with NN
2020-12-03 07:20:05,520 [IPC Server handler 9 on default port 45965] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:39218, datanodeUuid=de098be8-3b57-427f-9f60-e85f3df9f694, infoPort=36862, infoSecurePort=0, ipcPort=37261, storageInfo=lv=-57;cid=testClusterID;nsid=864125735;c=1606980002416) storage de098be8-3b57-427f-9f60-e85f3df9f694
2020-12-03 07:20:05,520 [IPC Server handler 9 on default port 45965] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:39218
2020-12-03 07:20:05,520 [IPC Server handler 9 on default port 45965] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN de098be8-3b57-427f-9f60-e85f3df9f694 (127.0.0.1:39218).
2020-12-03 07:20:05,521 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1804082424-172.17.0.6-1606980002416 (Datanode Uuid de098be8-3b57-427f-9f60-e85f3df9f694) service to localhost/127.0.0.1:45965 successfully registered with NN
2020-12-03 07:20:05,521 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:45965 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:05,524 [IPC Server handler 0 on default port 45965] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-f419cf0c-b1ed-45ba-adce-834ed42a8b9d for DN 127.0.0.1:39218
2020-12-03 07:20:05,524 [IPC Server handler 0 on default port 45965] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-65455744-ec66-4856-99b0-9225eafc9da5 for DN 127.0.0.1:39218
2020-12-03 07:20:05,526 [Thread-736] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=864125735;bpid=BP-1804082424-172.17.0.6-1606980002416;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=864125735;c=1606980002416;bpid=BP-1804082424-172.17.0.6-1606980002416;dnuuid=null
2020-12-03 07:20:05,526 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x65a5a7da7883bc49: Processing first storage report for DS-65455744-ec66-4856-99b0-9225eafc9da5 from datanode de098be8-3b57-427f-9f60-e85f3df9f694
2020-12-03 07:20:05,526 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x65a5a7da7883bc49: from storage DS-65455744-ec66-4856-99b0-9225eafc9da5 node DatanodeRegistration(127.0.0.1:39218, datanodeUuid=de098be8-3b57-427f-9f60-e85f3df9f694, infoPort=36862, infoSecurePort=0, ipcPort=37261, storageInfo=lv=-57;cid=testClusterID;nsid=864125735;c=1606980002416), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:05,527 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x65a5a7da7883bc49: Processing first storage report for DS-f419cf0c-b1ed-45ba-adce-834ed42a8b9d from datanode de098be8-3b57-427f-9f60-e85f3df9f694
2020-12-03 07:20:05,527 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x65a5a7da7883bc49: from storage DS-f419cf0c-b1ed-45ba-adce-834ed42a8b9d node DatanodeRegistration(127.0.0.1:39218, datanodeUuid=de098be8-3b57-427f-9f60-e85f3df9f694, infoPort=36862, infoSecurePort=0, ipcPort=37261, storageInfo=lv=-57;cid=testClusterID;nsid=864125735;c=1606980002416), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:05,528 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x65a5a7da7883bc49,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:05,528 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:05,533 [Thread-813] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:05,533 [Thread-813] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:05,533 [Thread-813] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 and block pool id BP-1804082424-172.17.0.6-1606980002416 is not formatted. Formatting ...
2020-12-03 07:20:05,533 [Thread-813] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1804082424-172.17.0.6-1606980002416 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1804082424-172.17.0.6-1606980002416/current
2020-12-03 07:20:05,559 [IPC Server handler 3 on default port 45965] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:05,560 [Listener at localhost/46668] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:05,561 [Listener at localhost/46668] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:05,633 [Thread-758] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=864125735;bpid=BP-1804082424-172.17.0.6-1606980002416;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=864125735;c=1606980002416;bpid=BP-1804082424-172.17.0.6-1606980002416;dnuuid=null
2020-12-03 07:20:05,641 [Thread-835] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:05,642 [Thread-835] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:05,642 [Thread-835] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 and block pool id BP-1804082424-172.17.0.6-1606980002416 is not formatted. Formatting ...
2020-12-03 07:20:05,642 [Thread-835] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1804082424-172.17.0.6-1606980002416 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1804082424-172.17.0.6-1606980002416/current
2020-12-03 07:20:05,662 [IPC Server handler 4 on default port 45965] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:05,664 [Listener at localhost/46668] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:05,664 [Listener at localhost/46668] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:05,733 [Thread-780] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=864125735;bpid=BP-1804082424-172.17.0.6-1606980002416;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=864125735;c=1606980002416;bpid=BP-1804082424-172.17.0.6-1606980002416;dnuuid=null
2020-12-03 07:20:05,765 [IPC Server handler 5 on default port 45965] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:05,767 [Listener at localhost/46668] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:05,767 [Listener at localhost/46668] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:05,785 [Thread-736] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 9acfc918-b97f-4fcf-8bea-64439f1ae0ea
2020-12-03 07:20:05,785 [Thread-813] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=864125735;bpid=BP-1804082424-172.17.0.6-1606980002416;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=864125735;c=1606980002416;bpid=BP-1804082424-172.17.0.6-1606980002416;dnuuid=null
2020-12-03 07:20:05,788 [Thread-736] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-c0dee4e4-fa07-40af-b816-6f0b88fb9f12
2020-12-03 07:20:05,788 [Thread-736] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, StorageType: DISK
2020-12-03 07:20:05,792 [Thread-736] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-43a9d23d-614e-4a58-99ac-e73442c82f51
2020-12-03 07:20:05,792 [Thread-736] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, StorageType: DISK
2020-12-03 07:20:05,792 [Thread-736] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:05,793 [Thread-736] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:20:05,794 [Thread-736] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:20:05,794 [Thread-736] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:20:05,795 [Thread-736] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:20:05,795 [Thread-736] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:05,795 [Thread-871] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-12-03 07:20:05,800 [Thread-872] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-12-03 07:20:05,839 [Thread-758] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID e8690573-6d95-48a1-9ba7-5b1be3fa4816
2020-12-03 07:20:05,839 [Thread-835] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=864125735;bpid=BP-1804082424-172.17.0.6-1606980002416;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=864125735;c=1606980002416;bpid=BP-1804082424-172.17.0.6-1606980002416;dnuuid=null
2020-12-03 07:20:05,842 [Thread-758] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-ee267448-1a4d-452b-be30-3480ab792404
2020-12-03 07:20:05,842 [Thread-758] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, StorageType: DISK
2020-12-03 07:20:05,844 [Thread-758] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-512a29a1-592b-4a6b-9e0b-372194c82b1f
2020-12-03 07:20:05,844 [Thread-758] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, StorageType: DISK
2020-12-03 07:20:05,844 [Thread-758] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:05,845 [Thread-758] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:20:05,846 [Thread-758] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:20:05,846 [Thread-758] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:20:05,846 [Thread-758] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:20:05,847 [Thread-758] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:05,847 [Thread-877] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-12-03 07:20:05,847 [Thread-878] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-12-03 07:20:05,848 [Thread-871] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1804082424-172.17.0.6-1606980002416 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 48ms
2020-12-03 07:20:05,848 [Thread-872] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1804082424-172.17.0.6-1606980002416 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 47ms
2020-12-03 07:20:05,851 [Thread-736] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1804082424-172.17.0.6-1606980002416: 56ms
2020-12-03 07:20:05,855 [Thread-879] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-12-03 07:20:05,856 [Thread-879] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1804082424-172.17.0.6-1606980002416/current/replicas doesn't exist 
2020-12-03 07:20:05,856 [Thread-879] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 1ms
2020-12-03 07:20:05,862 [Thread-880] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-12-03 07:20:05,863 [Thread-880] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1804082424-172.17.0.6-1606980002416/current/replicas doesn't exist 
2020-12-03 07:20:05,864 [Thread-880] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 1ms
2020-12-03 07:20:05,864 [Thread-736] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416: 13ms
2020-12-03 07:20:05,864 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:20:05,865 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:20:05,865 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-43a9d23d-614e-4a58-99ac-e73442c82f51): finished scanning block pool BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:05,865 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-c0dee4e4-fa07-40af-b816-6f0b88fb9f12): finished scanning block pool BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:05,865 [Thread-736] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 10:17 AM with interval of 21600000ms
2020-12-03 07:20:05,865 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-c0dee4e4-fa07-40af-b816-6f0b88fb9f12): no suitable block pools found to scan.  Waiting 1814400000 ms.
2020-12-03 07:20:05,865 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-43a9d23d-614e-4a58-99ac-e73442c82f51): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:20:05,865 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1804082424-172.17.0.6-1606980002416 (Datanode Uuid 9acfc918-b97f-4fcf-8bea-64439f1ae0ea) service to localhost/127.0.0.1:45965 beginning handshake with NN
2020-12-03 07:20:05,867 [IPC Server handler 6 on default port 45965] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:33010, datanodeUuid=9acfc918-b97f-4fcf-8bea-64439f1ae0ea, infoPort=35466, infoSecurePort=0, ipcPort=44957, storageInfo=lv=-57;cid=testClusterID;nsid=864125735;c=1606980002416) storage 9acfc918-b97f-4fcf-8bea-64439f1ae0ea
2020-12-03 07:20:05,867 [IPC Server handler 6 on default port 45965] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:33010
2020-12-03 07:20:05,867 [IPC Server handler 6 on default port 45965] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 9acfc918-b97f-4fcf-8bea-64439f1ae0ea (127.0.0.1:33010).
2020-12-03 07:20:05,869 [IPC Server handler 7 on default port 45965] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:05,869 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1804082424-172.17.0.6-1606980002416 (Datanode Uuid 9acfc918-b97f-4fcf-8bea-64439f1ae0ea) service to localhost/127.0.0.1:45965 successfully registered with NN
2020-12-03 07:20:05,869 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:45965 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:05,873 [Listener at localhost/46668] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:05,873 [Listener at localhost/46668] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:05,874 [IPC Server handler 1 on default port 45965] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c0dee4e4-fa07-40af-b816-6f0b88fb9f12 for DN 127.0.0.1:33010
2020-12-03 07:20:05,874 [IPC Server handler 1 on default port 45965] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-43a9d23d-614e-4a58-99ac-e73442c82f51 for DN 127.0.0.1:33010
2020-12-03 07:20:05,876 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x4f9e71391c4ce680: Processing first storage report for DS-43a9d23d-614e-4a58-99ac-e73442c82f51 from datanode 9acfc918-b97f-4fcf-8bea-64439f1ae0ea
2020-12-03 07:20:05,876 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x4f9e71391c4ce680: from storage DS-43a9d23d-614e-4a58-99ac-e73442c82f51 node DatanodeRegistration(127.0.0.1:33010, datanodeUuid=9acfc918-b97f-4fcf-8bea-64439f1ae0ea, infoPort=35466, infoSecurePort=0, ipcPort=44957, storageInfo=lv=-57;cid=testClusterID;nsid=864125735;c=1606980002416), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:05,876 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x4f9e71391c4ce680: Processing first storage report for DS-c0dee4e4-fa07-40af-b816-6f0b88fb9f12 from datanode 9acfc918-b97f-4fcf-8bea-64439f1ae0ea
2020-12-03 07:20:05,876 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x4f9e71391c4ce680: from storage DS-c0dee4e4-fa07-40af-b816-6f0b88fb9f12 node DatanodeRegistration(127.0.0.1:33010, datanodeUuid=9acfc918-b97f-4fcf-8bea-64439f1ae0ea, infoPort=35466, infoSecurePort=0, ipcPort=44957, storageInfo=lv=-57;cid=testClusterID;nsid=864125735;c=1606980002416), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:20:05,877 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x4f9e71391c4ce680,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:05,877 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:05,883 [Thread-877] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1804082424-172.17.0.6-1606980002416 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 36ms
2020-12-03 07:20:05,885 [Thread-878] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1804082424-172.17.0.6-1606980002416 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 38ms
2020-12-03 07:20:05,885 [Thread-758] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1804082424-172.17.0.6-1606980002416: 39ms
2020-12-03 07:20:05,886 [Thread-886] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-12-03 07:20:05,886 [Thread-887] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-12-03 07:20:05,886 [Thread-886] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1804082424-172.17.0.6-1606980002416/current/replicas doesn't exist 
2020-12-03 07:20:05,886 [Thread-887] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1804082424-172.17.0.6-1606980002416/current/replicas doesn't exist 
2020-12-03 07:20:05,886 [Thread-886] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 1ms
2020-12-03 07:20:05,886 [Thread-887] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 1ms
2020-12-03 07:20:05,886 [Thread-758] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416: 1ms
2020-12-03 07:20:05,887 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:20:05,887 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:20:05,887 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-512a29a1-592b-4a6b-9e0b-372194c82b1f): finished scanning block pool BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:05,887 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-ee267448-1a4d-452b-be30-3480ab792404): finished scanning block pool BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:05,887 [Thread-758] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:07 AM with interval of 21600000ms
2020-12-03 07:20:05,888 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1804082424-172.17.0.6-1606980002416 (Datanode Uuid e8690573-6d95-48a1-9ba7-5b1be3fa4816) service to localhost/127.0.0.1:45965 beginning handshake with NN
2020-12-03 07:20:05,888 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-512a29a1-592b-4a6b-9e0b-372194c82b1f): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:20:05,888 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-ee267448-1a4d-452b-be30-3480ab792404): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:20:05,889 [IPC Server handler 9 on default port 45965] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:42042, datanodeUuid=e8690573-6d95-48a1-9ba7-5b1be3fa4816, infoPort=40958, infoSecurePort=0, ipcPort=39229, storageInfo=lv=-57;cid=testClusterID;nsid=864125735;c=1606980002416) storage e8690573-6d95-48a1-9ba7-5b1be3fa4816
2020-12-03 07:20:05,889 [IPC Server handler 9 on default port 45965] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:42042
2020-12-03 07:20:05,889 [IPC Server handler 9 on default port 45965] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN e8690573-6d95-48a1-9ba7-5b1be3fa4816 (127.0.0.1:42042).
2020-12-03 07:20:05,890 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1804082424-172.17.0.6-1606980002416 (Datanode Uuid e8690573-6d95-48a1-9ba7-5b1be3fa4816) service to localhost/127.0.0.1:45965 successfully registered with NN
2020-12-03 07:20:05,890 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:45965 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:05,892 [IPC Server handler 0 on default port 45965] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-ee267448-1a4d-452b-be30-3480ab792404 for DN 127.0.0.1:42042
2020-12-03 07:20:05,893 [IPC Server handler 0 on default port 45965] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-512a29a1-592b-4a6b-9e0b-372194c82b1f for DN 127.0.0.1:42042
2020-12-03 07:20:05,894 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xb95b60f1e6499df: Processing first storage report for DS-ee267448-1a4d-452b-be30-3480ab792404 from datanode e8690573-6d95-48a1-9ba7-5b1be3fa4816
2020-12-03 07:20:05,895 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xb95b60f1e6499df: from storage DS-ee267448-1a4d-452b-be30-3480ab792404 node DatanodeRegistration(127.0.0.1:42042, datanodeUuid=e8690573-6d95-48a1-9ba7-5b1be3fa4816, infoPort=40958, infoSecurePort=0, ipcPort=39229, storageInfo=lv=-57;cid=testClusterID;nsid=864125735;c=1606980002416), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:05,895 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xb95b60f1e6499df: Processing first storage report for DS-512a29a1-592b-4a6b-9e0b-372194c82b1f from datanode e8690573-6d95-48a1-9ba7-5b1be3fa4816
2020-12-03 07:20:05,895 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xb95b60f1e6499df: from storage DS-512a29a1-592b-4a6b-9e0b-372194c82b1f node DatanodeRegistration(127.0.0.1:42042, datanodeUuid=e8690573-6d95-48a1-9ba7-5b1be3fa4816, infoPort=40958, infoSecurePort=0, ipcPort=39229, storageInfo=lv=-57;cid=testClusterID;nsid=864125735;c=1606980002416), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:05,896 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xb95b60f1e6499df,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:05,896 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:05,944 [Thread-780] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 2df0ed89-2351-4d4d-8341-dd4497968a1f
2020-12-03 07:20:05,946 [Thread-780] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-2846ef14-7d0f-45aa-b4f1-52040a358f03
2020-12-03 07:20:05,946 [Thread-780] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, StorageType: DISK
2020-12-03 07:20:05,947 [Thread-780] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-fde66b64-bf3d-4e52-a9d8-47e9e976c8ea
2020-12-03 07:20:05,947 [Thread-780] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, StorageType: DISK
2020-12-03 07:20:05,947 [Thread-780] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:05,948 [Thread-780] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:20:05,948 [Thread-780] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:20:05,948 [Thread-780] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:20:05,949 [Thread-780] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:20:05,949 [Thread-780] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:05,949 [Thread-893] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11...
2020-12-03 07:20:05,949 [Thread-894] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12...
2020-12-03 07:20:05,975 [IPC Server handler 3 on default port 45965] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:05,976 [Listener at localhost/46668] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:05,976 [Listener at localhost/46668] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:05,977 [Thread-893] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1804082424-172.17.0.6-1606980002416 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11: 27ms
2020-12-03 07:20:05,978 [Thread-894] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1804082424-172.17.0.6-1606980002416 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12: 29ms
2020-12-03 07:20:05,978 [Thread-780] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1804082424-172.17.0.6-1606980002416: 30ms
2020-12-03 07:20:05,979 [Thread-897] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11...
2020-12-03 07:20:05,979 [Thread-898] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12...
2020-12-03 07:20:05,979 [Thread-897] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1804082424-172.17.0.6-1606980002416/current/replicas doesn't exist 
2020-12-03 07:20:05,979 [Thread-898] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1804082424-172.17.0.6-1606980002416/current/replicas doesn't exist 
2020-12-03 07:20:05,979 [Thread-897] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11: 1ms
2020-12-03 07:20:05,979 [Thread-898] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12: 1ms
2020-12-03 07:20:05,979 [Thread-780] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416: 1ms
2020-12-03 07:20:05,980 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:20:05,980 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:20:05,980 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-2846ef14-7d0f-45aa-b4f1-52040a358f03): finished scanning block pool BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:05,980 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-fde66b64-bf3d-4e52-a9d8-47e9e976c8ea): finished scanning block pool BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:05,980 [Thread-780] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:58 AM with interval of 21600000ms
2020-12-03 07:20:05,981 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-2846ef14-7d0f-45aa-b4f1-52040a358f03): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:20:05,981 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1804082424-172.17.0.6-1606980002416 (Datanode Uuid 2df0ed89-2351-4d4d-8341-dd4497968a1f) service to localhost/127.0.0.1:45965 beginning handshake with NN
2020-12-03 07:20:05,981 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-fde66b64-bf3d-4e52-a9d8-47e9e976c8ea): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:20:05,982 [IPC Server handler 4 on default port 45965] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:44728, datanodeUuid=2df0ed89-2351-4d4d-8341-dd4497968a1f, infoPort=45743, infoSecurePort=0, ipcPort=41968, storageInfo=lv=-57;cid=testClusterID;nsid=864125735;c=1606980002416) storage 2df0ed89-2351-4d4d-8341-dd4497968a1f
2020-12-03 07:20:05,982 [IPC Server handler 4 on default port 45965] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:44728
2020-12-03 07:20:05,982 [IPC Server handler 4 on default port 45965] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 2df0ed89-2351-4d4d-8341-dd4497968a1f (127.0.0.1:44728).
2020-12-03 07:20:05,983 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1804082424-172.17.0.6-1606980002416 (Datanode Uuid 2df0ed89-2351-4d4d-8341-dd4497968a1f) service to localhost/127.0.0.1:45965 successfully registered with NN
2020-12-03 07:20:05,983 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:45965 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:05,985 [IPC Server handler 5 on default port 45965] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-2846ef14-7d0f-45aa-b4f1-52040a358f03 for DN 127.0.0.1:44728
2020-12-03 07:20:05,985 [IPC Server handler 5 on default port 45965] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-fde66b64-bf3d-4e52-a9d8-47e9e976c8ea for DN 127.0.0.1:44728
2020-12-03 07:20:05,986 [Thread-813] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID b038b1a4-65c2-42df-90ed-7eefd1a46770
2020-12-03 07:20:05,986 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x5bc01ab4344e243d: Processing first storage report for DS-2846ef14-7d0f-45aa-b4f1-52040a358f03 from datanode 2df0ed89-2351-4d4d-8341-dd4497968a1f
2020-12-03 07:20:05,986 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x5bc01ab4344e243d: from storage DS-2846ef14-7d0f-45aa-b4f1-52040a358f03 node DatanodeRegistration(127.0.0.1:44728, datanodeUuid=2df0ed89-2351-4d4d-8341-dd4497968a1f, infoPort=45743, infoSecurePort=0, ipcPort=41968, storageInfo=lv=-57;cid=testClusterID;nsid=864125735;c=1606980002416), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:05,987 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x5bc01ab4344e243d: Processing first storage report for DS-fde66b64-bf3d-4e52-a9d8-47e9e976c8ea from datanode 2df0ed89-2351-4d4d-8341-dd4497968a1f
2020-12-03 07:20:05,987 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x5bc01ab4344e243d: from storage DS-fde66b64-bf3d-4e52-a9d8-47e9e976c8ea node DatanodeRegistration(127.0.0.1:44728, datanodeUuid=2df0ed89-2351-4d4d-8341-dd4497968a1f, infoPort=45743, infoSecurePort=0, ipcPort=41968, storageInfo=lv=-57;cid=testClusterID;nsid=864125735;c=1606980002416), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:05,987 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x5bc01ab4344e243d,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:05,987 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:05,987 [Thread-813] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-e393a8d1-0f5b-4659-b3f3-ec668d265860
2020-12-03 07:20:05,988 [Thread-813] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, StorageType: DISK
2020-12-03 07:20:05,988 [Thread-813] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-034e39a9-7d42-4606-aaed-1b5bf00d1e13
2020-12-03 07:20:05,988 [Thread-813] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, StorageType: DISK
2020-12-03 07:20:05,989 [Thread-813] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:05,990 [Thread-813] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:20:05,990 [Thread-813] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:20:05,990 [Thread-813] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:20:05,990 [Thread-813] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:20:05,990 [Thread-813] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:05,991 [Thread-904] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13...
2020-12-03 07:20:05,991 [Thread-905] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14...
2020-12-03 07:20:06,020 [Thread-904] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1804082424-172.17.0.6-1606980002416 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13: 29ms
2020-12-03 07:20:06,025 [Thread-905] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1804082424-172.17.0.6-1606980002416 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14: 35ms
2020-12-03 07:20:06,026 [Thread-813] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1804082424-172.17.0.6-1606980002416: 35ms
2020-12-03 07:20:06,026 [Thread-908] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13...
2020-12-03 07:20:06,026 [Thread-909] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14...
2020-12-03 07:20:06,027 [Thread-909] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1804082424-172.17.0.6-1606980002416/current/replicas doesn't exist 
2020-12-03 07:20:06,027 [Thread-908] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1804082424-172.17.0.6-1606980002416/current/replicas doesn't exist 
2020-12-03 07:20:06,027 [Thread-909] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14: 1ms
2020-12-03 07:20:06,028 [Thread-908] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13: 1ms
2020-12-03 07:20:06,028 [Thread-813] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416: 2ms
2020-12-03 07:20:06,028 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:20:06,029 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-034e39a9-7d42-4606-aaed-1b5bf00d1e13): finished scanning block pool BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:06,029 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:20:06,029 [Thread-813] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:18 AM with interval of 21600000ms
2020-12-03 07:20:06,029 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-e393a8d1-0f5b-4659-b3f3-ec668d265860): finished scanning block pool BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:06,029 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-034e39a9-7d42-4606-aaed-1b5bf00d1e13): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:20:06,029 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1804082424-172.17.0.6-1606980002416 (Datanode Uuid b038b1a4-65c2-42df-90ed-7eefd1a46770) service to localhost/127.0.0.1:45965 beginning handshake with NN
2020-12-03 07:20:06,030 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-e393a8d1-0f5b-4659-b3f3-ec668d265860): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-12-03 07:20:06,031 [IPC Server handler 7 on default port 45965] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:46071, datanodeUuid=b038b1a4-65c2-42df-90ed-7eefd1a46770, infoPort=43356, infoSecurePort=0, ipcPort=45406, storageInfo=lv=-57;cid=testClusterID;nsid=864125735;c=1606980002416) storage b038b1a4-65c2-42df-90ed-7eefd1a46770
2020-12-03 07:20:06,031 [IPC Server handler 7 on default port 45965] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:46071
2020-12-03 07:20:06,032 [IPC Server handler 7 on default port 45965] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN b038b1a4-65c2-42df-90ed-7eefd1a46770 (127.0.0.1:46071).
2020-12-03 07:20:06,033 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1804082424-172.17.0.6-1606980002416 (Datanode Uuid b038b1a4-65c2-42df-90ed-7eefd1a46770) service to localhost/127.0.0.1:45965 successfully registered with NN
2020-12-03 07:20:06,033 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:45965 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:06,034 [Thread-835] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 29c10e8f-bd24-491d-a369-fc3d4333f678
2020-12-03 07:20:06,035 [IPC Server handler 1 on default port 45965] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-e393a8d1-0f5b-4659-b3f3-ec668d265860 for DN 127.0.0.1:46071
2020-12-03 07:20:06,035 [IPC Server handler 1 on default port 45965] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-034e39a9-7d42-4606-aaed-1b5bf00d1e13 for DN 127.0.0.1:46071
2020-12-03 07:20:06,039 [Thread-835] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-1d5f4027-0413-4b3d-bce3-7989772d6afc
2020-12-03 07:20:06,040 [Thread-835] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, StorageType: DISK
2020-12-03 07:20:06,040 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x8ee5ecd1881e3c91: Processing first storage report for DS-034e39a9-7d42-4606-aaed-1b5bf00d1e13 from datanode b038b1a4-65c2-42df-90ed-7eefd1a46770
2020-12-03 07:20:06,040 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x8ee5ecd1881e3c91: from storage DS-034e39a9-7d42-4606-aaed-1b5bf00d1e13 node DatanodeRegistration(127.0.0.1:46071, datanodeUuid=b038b1a4-65c2-42df-90ed-7eefd1a46770, infoPort=43356, infoSecurePort=0, ipcPort=45406, storageInfo=lv=-57;cid=testClusterID;nsid=864125735;c=1606980002416), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:20:06,040 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x8ee5ecd1881e3c91: Processing first storage report for DS-e393a8d1-0f5b-4659-b3f3-ec668d265860 from datanode b038b1a4-65c2-42df-90ed-7eefd1a46770
2020-12-03 07:20:06,040 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x8ee5ecd1881e3c91: from storage DS-e393a8d1-0f5b-4659-b3f3-ec668d265860 node DatanodeRegistration(127.0.0.1:46071, datanodeUuid=b038b1a4-65c2-42df-90ed-7eefd1a46770, infoPort=43356, infoSecurePort=0, ipcPort=45406, storageInfo=lv=-57;cid=testClusterID;nsid=864125735;c=1606980002416), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:06,041 [Thread-835] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-9430fa01-b843-4ce1-b229-c4ef32f58568
2020-12-03 07:20:06,041 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x8ee5ecd1881e3c91,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 5 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:06,041 [Thread-835] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, StorageType: DISK
2020-12-03 07:20:06,041 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:06,042 [Thread-835] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:06,043 [Thread-835] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:20:06,044 [Thread-835] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:20:06,044 [Thread-835] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:20:06,044 [Thread-835] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:20:06,044 [Thread-835] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:06,045 [Thread-915] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15...
2020-12-03 07:20:06,047 [Thread-916] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16...
2020-12-03 07:20:06,080 [IPC Server handler 9 on default port 45965] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:06,081 [Listener at localhost/46668] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:06,082 [Listener at localhost/46668] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:06,101 [Thread-915] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1804082424-172.17.0.6-1606980002416 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15: 55ms
2020-12-03 07:20:06,116 [Thread-916] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1804082424-172.17.0.6-1606980002416 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16: 69ms
2020-12-03 07:20:06,117 [Thread-835] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1804082424-172.17.0.6-1606980002416: 72ms
2020-12-03 07:20:06,117 [Thread-920] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16...
2020-12-03 07:20:06,118 [Thread-920] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1804082424-172.17.0.6-1606980002416/current/replicas doesn't exist 
2020-12-03 07:20:06,118 [Thread-920] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16: 1ms
2020-12-03 07:20:06,123 [Thread-919] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15...
2020-12-03 07:20:06,123 [Thread-919] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1804082424-172.17.0.6-1606980002416/current/replicas doesn't exist 
2020-12-03 07:20:06,124 [Thread-919] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15: 0ms
2020-12-03 07:20:06,124 [Thread-835] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416: 7ms
2020-12-03 07:20:06,125 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:20:06,125 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:20:06,125 [Thread-835] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 7:49 AM with interval of 21600000ms
2020-12-03 07:20:06,125 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-1d5f4027-0413-4b3d-bce3-7989772d6afc): finished scanning block pool BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:06,125 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-9430fa01-b843-4ce1-b229-c4ef32f58568): finished scanning block pool BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:06,126 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1804082424-172.17.0.6-1606980002416 (Datanode Uuid 29c10e8f-bd24-491d-a369-fc3d4333f678) service to localhost/127.0.0.1:45965 beginning handshake with NN
2020-12-03 07:20:06,126 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-1d5f4027-0413-4b3d-bce3-7989772d6afc): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-12-03 07:20:06,126 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-9430fa01-b843-4ce1-b229-c4ef32f58568): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:20:06,127 [IPC Server handler 0 on default port 45965] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35620, datanodeUuid=29c10e8f-bd24-491d-a369-fc3d4333f678, infoPort=40386, infoSecurePort=0, ipcPort=46668, storageInfo=lv=-57;cid=testClusterID;nsid=864125735;c=1606980002416) storage 29c10e8f-bd24-491d-a369-fc3d4333f678
2020-12-03 07:20:06,127 [IPC Server handler 0 on default port 45965] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:35620
2020-12-03 07:20:06,127 [IPC Server handler 0 on default port 45965] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 29c10e8f-bd24-491d-a369-fc3d4333f678 (127.0.0.1:35620).
2020-12-03 07:20:06,129 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1804082424-172.17.0.6-1606980002416 (Datanode Uuid 29c10e8f-bd24-491d-a369-fc3d4333f678) service to localhost/127.0.0.1:45965 successfully registered with NN
2020-12-03 07:20:06,129 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:45965 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:06,132 [IPC Server handler 2 on default port 45965] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-1d5f4027-0413-4b3d-bce3-7989772d6afc for DN 127.0.0.1:35620
2020-12-03 07:20:06,132 [IPC Server handler 2 on default port 45965] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-9430fa01-b843-4ce1-b229-c4ef32f58568 for DN 127.0.0.1:35620
2020-12-03 07:20:06,136 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x8f4025870f0c9541: Processing first storage report for DS-1d5f4027-0413-4b3d-bce3-7989772d6afc from datanode 29c10e8f-bd24-491d-a369-fc3d4333f678
2020-12-03 07:20:06,136 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x8f4025870f0c9541: from storage DS-1d5f4027-0413-4b3d-bce3-7989772d6afc node DatanodeRegistration(127.0.0.1:35620, datanodeUuid=29c10e8f-bd24-491d-a369-fc3d4333f678, infoPort=40386, infoSecurePort=0, ipcPort=46668, storageInfo=lv=-57;cid=testClusterID;nsid=864125735;c=1606980002416), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:06,136 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x8f4025870f0c9541: Processing first storage report for DS-9430fa01-b843-4ce1-b229-c4ef32f58568 from datanode 29c10e8f-bd24-491d-a369-fc3d4333f678
2020-12-03 07:20:06,136 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x8f4025870f0c9541: from storage DS-9430fa01-b843-4ce1-b229-c4ef32f58568 node DatanodeRegistration(127.0.0.1:35620, datanodeUuid=29c10e8f-bd24-491d-a369-fc3d4333f678, infoPort=40386, infoSecurePort=0, ipcPort=46668, storageInfo=lv=-57;cid=testClusterID;nsid=864125735;c=1606980002416), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:06,137 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x8f4025870f0c9541,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:06,137 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:06,184 [IPC Server handler 4 on default port 45965] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:06,186 [Listener at localhost/46668] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:20:06,190 [IPC Server handler 5 on default port 45965] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:06,191 [Listener at localhost/46668] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:20:07,094 [Listener at localhost/46668] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:07,094 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@33b082c5] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:07,096 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-d45d6d51-9d05-49c1-a03f-41a2411d1148) exiting.
2020-12-03 07:20:07,096 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-b3c09d28-5beb-480c-a8f7-27abf33879fa) exiting.
2020-12-03 07:20:07,126 [Listener at localhost/46668] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5136207f{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:07,127 [Listener at localhost/46668] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@14dd6bf{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:07,128 [Listener at localhost/46668] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@17740dae{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:07,128 [Listener at localhost/46668] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@14379273{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:07,129 [Listener at localhost/46668] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 39687
2020-12-03 07:20:07,130 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:07,130 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:07,132 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:07,132 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1804082424-172.17.0.6-1606980002416 (Datanode Uuid c5ae0664-cc27-4ff3-9558-7d39c9eabf00) service to localhost/127.0.0.1:45965
2020-12-03 07:20:07,132 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1804082424-172.17.0.6-1606980002416 (Datanode Uuid c5ae0664-cc27-4ff3-9558-7d39c9eabf00)
2020-12-03 07:20:07,133 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:07,134 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1804082424-172.17.0.6-1606980002416] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:07,135 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1804082424-172.17.0.6-1606980002416] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:07,137 [Listener at localhost/46668] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:07,138 [Listener at localhost/46668] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:07,138 [Listener at localhost/46668] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:07,138 [Listener at localhost/46668] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:07,140 [Listener at localhost/46668] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:07,141 [Listener at localhost/46668] INFO  hdfs.StateChange (DatanodeManager.java:removeDeadDatanode(754)) - BLOCK* removeDeadDatanode: lost heartbeat from 127.0.0.1:33969, removeBlocksFromBlockMap true
2020-12-03 07:20:07,142 [Listener at localhost/46668] INFO  net.NetworkTopology (NetworkTopology.java:remove(219)) - Removing a node: /default-rack/127.0.0.1:33969
2020-12-03 07:20:07,143 [Listener at localhost/46668] INFO  blockmanagement.HeartbeatManager (HeartbeatManager.java:startDecommission(261)) - Dead node 127.0.0.1:33969 is decommissioned immediately.
2020-12-03 07:20:07,143 [Listener at localhost/46668] INFO  blockmanagement.HeartbeatManager (HeartbeatManager.java:stopDecommission(304)) - Stopping decommissioning of dead node 127.0.0.1:33969
2020-12-03 07:20:07,143 [Listener at localhost/46668] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:07,143 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@5246a3b3] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:07,144 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-8bb132b5-cd57-4c73-9bc1-319b35c80433) exiting.
2020-12-03 07:20:07,145 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-b474ebdb-2378-43e8-b4f8-eddd6e6af004) exiting.
2020-12-03 07:20:07,174 [Listener at localhost/46668] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@557286ad{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:07,175 [Listener at localhost/46668] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@b10a26d{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:07,175 [Listener at localhost/46668] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@d56aaa6{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:07,176 [Listener at localhost/46668] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3c904f1e{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:07,181 [Listener at localhost/46668] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 42283
2020-12-03 07:20:07,184 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:07,184 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:07,184 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:07,186 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1804082424-172.17.0.6-1606980002416 (Datanode Uuid 2ed09fef-76ca-4e59-b76b-c7e5fbb353e7) service to localhost/127.0.0.1:45965
2020-12-03 07:20:07,186 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1804082424-172.17.0.6-1606980002416 (Datanode Uuid 2ed09fef-76ca-4e59-b76b-c7e5fbb353e7)
2020-12-03 07:20:07,186 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:07,187 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1804082424-172.17.0.6-1606980002416] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:07,188 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1804082424-172.17.0.6-1606980002416] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:07,191 [Listener at localhost/46668] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:07,191 [Listener at localhost/46668] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:07,192 [Listener at localhost/46668] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:07,192 [Listener at localhost/46668] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:07,194 [Listener at localhost/46668] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:07,194 [Listener at localhost/46668] INFO  hdfs.StateChange (DatanodeManager.java:removeDeadDatanode(754)) - BLOCK* removeDeadDatanode: lost heartbeat from 127.0.0.1:40040, removeBlocksFromBlockMap true
2020-12-03 07:20:07,195 [Listener at localhost/46668] INFO  net.NetworkTopology (NetworkTopology.java:remove(219)) - Removing a node: /default-rack/127.0.0.1:40040
2020-12-03 07:20:07,195 [Listener at localhost/46668] INFO  blockmanagement.HeartbeatManager (HeartbeatManager.java:startMaintenance(272)) - Dead node 127.0.0.1:40040 is put in maintenance state immediately.
2020-12-03 07:20:07,195 [Listener at localhost/46668] INFO  blockmanagement.HeartbeatManager (HeartbeatManager.java:stopMaintenance(292)) - Stopping maintenance of dead node 127.0.0.1:40040
2020-12-03 07:20:07,196 [Listener at localhost/46668] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:07,196 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@25c53f74] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:07,197 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-65455744-ec66-4856-99b0-9225eafc9da5) exiting.
2020-12-03 07:20:07,197 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-f419cf0c-b1ed-45ba-adce-834ed42a8b9d) exiting.
2020-12-03 07:20:07,214 [Listener at localhost/46668] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@43034809{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:07,215 [Listener at localhost/46668] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@39e67516{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:07,215 [Listener at localhost/46668] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@10ee04df{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:07,215 [Listener at localhost/46668] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@8bffb8b{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:07,218 [Listener at localhost/46668] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 37261
2020-12-03 07:20:07,219 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:07,219 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:07,219 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:07,229 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1804082424-172.17.0.6-1606980002416 (Datanode Uuid de098be8-3b57-427f-9f60-e85f3df9f694) service to localhost/127.0.0.1:45965
2020-12-03 07:20:07,229 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1804082424-172.17.0.6-1606980002416 (Datanode Uuid de098be8-3b57-427f-9f60-e85f3df9f694)
2020-12-03 07:20:07,229 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:07,230 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1804082424-172.17.0.6-1606980002416] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:07,233 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1804082424-172.17.0.6-1606980002416] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:07,236 [Listener at localhost/46668] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:07,236 [Listener at localhost/46668] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:07,237 [Listener at localhost/46668] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:07,237 [Listener at localhost/46668] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:07,240 [Listener at localhost/46668] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:07,240 [Listener at localhost/46668] INFO  hdfs.StateChange (DatanodeManager.java:removeDeadDatanode(754)) - BLOCK* removeDeadDatanode: lost heartbeat from 127.0.0.1:39218, removeBlocksFromBlockMap true
2020-12-03 07:20:07,240 [Listener at localhost/46668] INFO  net.NetworkTopology (NetworkTopology.java:remove(219)) - Removing a node: /default-rack/127.0.0.1:39218
2020-12-03 07:20:07,241 [Listener at localhost/46668] INFO  blockmanagement.HeartbeatManager (HeartbeatManager.java:startDecommission(261)) - Dead node 127.0.0.1:39218 is decommissioned immediately.
2020-12-03 07:20:07,241 [Listener at localhost/46668] INFO  blockmanagement.HeartbeatManager (HeartbeatManager.java:stopDecommission(304)) - Stopping decommissioning of dead node 127.0.0.1:39218
2020-12-03 07:20:07,241 [Listener at localhost/46668] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:07,241 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@8ff5094] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:07,247 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-43a9d23d-614e-4a58-99ac-e73442c82f51) exiting.
2020-12-03 07:20:07,247 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-c0dee4e4-fa07-40af-b816-6f0b88fb9f12) exiting.
2020-12-03 07:20:07,266 [Listener at localhost/46668] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@30501e60{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:07,267 [Listener at localhost/46668] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@289778cd{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:07,267 [Listener at localhost/46668] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@359ff4d9{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:07,268 [Listener at localhost/46668] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@184dbacc{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:07,282 [Listener at localhost/46668] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 44957
2020-12-03 07:20:07,283 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:07,283 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:07,283 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:07,283 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1804082424-172.17.0.6-1606980002416 (Datanode Uuid 9acfc918-b97f-4fcf-8bea-64439f1ae0ea) service to localhost/127.0.0.1:45965
2020-12-03 07:20:07,283 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1804082424-172.17.0.6-1606980002416 (Datanode Uuid 9acfc918-b97f-4fcf-8bea-64439f1ae0ea)
2020-12-03 07:20:07,286 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:07,286 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1804082424-172.17.0.6-1606980002416] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:07,287 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1804082424-172.17.0.6-1606980002416] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:07,302 [Listener at localhost/46668] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:07,303 [Listener at localhost/46668] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:07,310 [Listener at localhost/46668] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:07,310 [Listener at localhost/46668] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:07,314 [Listener at localhost/46668] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:07,314 [Listener at localhost/46668] INFO  hdfs.StateChange (DatanodeManager.java:removeDeadDatanode(754)) - BLOCK* removeDeadDatanode: lost heartbeat from 127.0.0.1:33010, removeBlocksFromBlockMap true
2020-12-03 07:20:07,314 [Listener at localhost/46668] INFO  net.NetworkTopology (NetworkTopology.java:remove(219)) - Removing a node: /default-rack/127.0.0.1:33010
2020-12-03 07:20:07,315 [Listener at localhost/46668] INFO  blockmanagement.HeartbeatManager (HeartbeatManager.java:startMaintenance(272)) - Dead node 127.0.0.1:33010 is put in maintenance state immediately.
2020-12-03 07:20:07,315 [Listener at localhost/46668] INFO  blockmanagement.HeartbeatManager (HeartbeatManager.java:stopMaintenance(292)) - Stopping maintenance of dead node 127.0.0.1:33010
2020-12-03 07:20:07,315 [Listener at localhost/46668] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopDataNode(2331)) - MiniDFSCluster Stopping DataNode 127.0.0.1:35620 from a total of 8 datanodes.
2020-12-03 07:20:07,316 [Listener at localhost/46668] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:07,316 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@1cb7936c] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:07,318 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-1d5f4027-0413-4b3d-bce3-7989772d6afc) exiting.
2020-12-03 07:20:07,318 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-9430fa01-b843-4ce1-b229-c4ef32f58568) exiting.
2020-12-03 07:20:07,339 [Listener at localhost/46668] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6bf13698{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:07,340 [Listener at localhost/46668] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@299270eb{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:07,340 [Listener at localhost/46668] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2b917fb0{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:07,341 [Listener at localhost/46668] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@77a2aa4a{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:07,349 [Listener at localhost/46668] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 46668
2020-12-03 07:20:07,349 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:07,350 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:07,350 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:07,350 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1804082424-172.17.0.6-1606980002416 (Datanode Uuid 29c10e8f-bd24-491d-a369-fc3d4333f678) service to localhost/127.0.0.1:45965
2020-12-03 07:20:07,351 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1804082424-172.17.0.6-1606980002416 (Datanode Uuid 29c10e8f-bd24-491d-a369-fc3d4333f678)
2020-12-03 07:20:07,353 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:07,354 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1804082424-172.17.0.6-1606980002416] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:07,354 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1804082424-172.17.0.6-1606980002416] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:07,360 [Listener at localhost/46668] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:07,361 [Listener at localhost/46668] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:07,361 [Listener at localhost/46668] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:07,361 [Listener at localhost/46668] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:07,365 [Listener at localhost/46668] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:07,367 [Listener at localhost/46668] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:20:07,368 [Listener at localhost/46668] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:20:07,369 [Listener at localhost/46668] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:07,369 [Listener at localhost/46668] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:07,370 [Listener at localhost/46668] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:07,370 [Listener at localhost/46668] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:07,370 [Listener at localhost/46668] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:07,371 [Listener at localhost/46668] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:07,373 [Listener at localhost/46668] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:36870
2020-12-03 07:20:07,373 [Listener at localhost/46668] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:07,373 [Listener at localhost/46668] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:07,374 [Listener at localhost/46668] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:07,377 [Listener at localhost/46668] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:07,378 [Listener at localhost/46668] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:07,378 [Listener at localhost/46668] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:07,381 [Listener at localhost/46668] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:07,382 [Listener at localhost/46668] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:07,382 [Listener at localhost/46668] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:07,382 [Listener at localhost/46668] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:07,383 [Listener at localhost/46668] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 41055
2020-12-03 07:20:07,383 [Listener at localhost/46668] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:07,385 [Listener at localhost/46668] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3491e86e{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:07,386 [Listener at localhost/46668] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@409986fe{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:07,394 [Listener at localhost/46668] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@36361ddb{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:20:07,397 [Listener at localhost/46668] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@41fed14f{HTTP/1.1,[http/1.1]}{localhost:41055}
2020-12-03 07:20:07,397 [Listener at localhost/46668] INFO  server.Server (Server.java:doStart(419)) - Started @27131ms
2020-12-03 07:20:07,422 [Listener at localhost/46668] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:43743
2020-12-03 07:20:07,422 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@a33b4e3] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:07,422 [Listener at localhost/46668] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:07,422 [Listener at localhost/46668] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:07,423 [Listener at localhost/46668] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:07,424 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:07,429 [Listener at localhost/42318] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:42318
2020-12-03 07:20:07,463 [Listener at localhost/42318] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:20:07,464 [Listener at localhost/42318] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:20:07,465 [Thread-935] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45965 starting to offer service
2020-12-03 07:20:07,469 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:07,469 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:07,475 [Listener at localhost/42318] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:restartDataNodes(2519)) - Restarted DataNode 7
2020-12-03 07:20:07,475 [Listener at localhost/42318] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopDataNode(2331)) - MiniDFSCluster Stopping DataNode 127.0.0.1:46071 from a total of 8 datanodes.
2020-12-03 07:20:07,475 [Thread-935] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45965
2020-12-03 07:20:07,479 [Listener at localhost/42318] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:07,479 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@38c2c309] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:07,479 [Thread-935] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:07,481 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-e393a8d1-0f5b-4659-b3f3-ec668d265860) exiting.
2020-12-03 07:20:07,479 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-034e39a9-7d42-4606-aaed-1b5bf00d1e13) exiting.
2020-12-03 07:20:07,500 [Listener at localhost/42318] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@66153688{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:07,501 [Listener at localhost/42318] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@455824ad{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:07,501 [Listener at localhost/42318] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@64b7225f{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:07,502 [Listener at localhost/42318] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6145b81e{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:07,506 [Listener at localhost/42318] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 45406
2020-12-03 07:20:07,508 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:07,508 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:07,508 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:07,508 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1804082424-172.17.0.6-1606980002416 (Datanode Uuid b038b1a4-65c2-42df-90ed-7eefd1a46770) service to localhost/127.0.0.1:45965
2020-12-03 07:20:07,508 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1804082424-172.17.0.6-1606980002416 (Datanode Uuid b038b1a4-65c2-42df-90ed-7eefd1a46770)
2020-12-03 07:20:07,512 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:07,513 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1804082424-172.17.0.6-1606980002416] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:07,513 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1804082424-172.17.0.6-1606980002416] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:07,517 [Thread-935] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/in_use.lock acquired by nodename 906@9ece31fe74eb
2020-12-03 07:20:07,521 [Listener at localhost/42318] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:07,521 [Listener at localhost/42318] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:07,521 [Listener at localhost/42318] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:07,521 [Listener at localhost/42318] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:07,525 [Listener at localhost/42318] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:07,526 [Listener at localhost/42318] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:20:07,526 [Listener at localhost/42318] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:20:07,527 [Listener at localhost/42318] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:07,527 [Listener at localhost/42318] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:07,527 [Listener at localhost/42318] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:07,528 [Listener at localhost/42318] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:07,528 [Listener at localhost/42318] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:07,528 [Listener at localhost/42318] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:07,529 [Listener at localhost/42318] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:45553
2020-12-03 07:20:07,529 [Listener at localhost/42318] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:07,529 [Listener at localhost/42318] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:07,530 [Listener at localhost/42318] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:07,531 [Listener at localhost/42318] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:07,532 [Listener at localhost/42318] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:07,532 [Listener at localhost/42318] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:07,533 [Listener at localhost/42318] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:07,534 [Listener at localhost/42318] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:07,534 [Listener at localhost/42318] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:07,534 [Listener at localhost/42318] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:07,534 [Listener at localhost/42318] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 45559
2020-12-03 07:20:07,535 [Listener at localhost/42318] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:07,536 [Listener at localhost/42318] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5533dc72{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:07,536 [Listener at localhost/42318] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@64fc097e{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:07,541 [Listener at localhost/42318] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6dd82486{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:20:07,541 [Listener at localhost/42318] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@56078cea{HTTP/1.1,[http/1.1]}{localhost:45559}
2020-12-03 07:20:07,545 [Listener at localhost/42318] INFO  server.Server (Server.java:doStart(419)) - Started @27278ms
2020-12-03 07:20:07,562 [Listener at localhost/42318] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:40774
2020-12-03 07:20:07,562 [Listener at localhost/42318] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:07,562 [Listener at localhost/42318] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:07,562 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@36fcf6c0] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:07,563 [Listener at localhost/42318] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:07,563 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:07,567 [Listener at localhost/35874] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:35874
2020-12-03 07:20:07,606 [Listener at localhost/35874] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:20:07,606 [Listener at localhost/35874] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:20:07,607 [Thread-957] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45965 starting to offer service
2020-12-03 07:20:07,611 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:07,611 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:07,617 [Listener at localhost/35874] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:restartDataNodes(2519)) - Restarted DataNode 6
2020-12-03 07:20:07,617 [Thread-957] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45965
2020-12-03 07:20:07,618 [Listener at localhost/35874] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopDataNode(2331)) - MiniDFSCluster Stopping DataNode 127.0.0.1:44728 from a total of 8 datanodes.
2020-12-03 07:20:07,621 [Thread-957] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:07,621 [Listener at localhost/35874] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:07,621 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@7c75db8b] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:07,628 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-2846ef14-7d0f-45aa-b4f1-52040a358f03) exiting.
2020-12-03 07:20:07,635 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-fde66b64-bf3d-4e52-a9d8-47e9e976c8ea) exiting.
2020-12-03 07:20:07,642 [Thread-935] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/in_use.lock acquired by nodename 906@9ece31fe74eb
2020-12-03 07:20:07,655 [Listener at localhost/35874] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@4ad3d266{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:07,656 [Listener at localhost/35874] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@3533df16{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:07,656 [Listener at localhost/35874] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2264e43c{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:07,657 [Listener at localhost/35874] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5c9ac4cc{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:07,661 [Listener at localhost/35874] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 41968
2020-12-03 07:20:07,662 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:07,662 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:07,662 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:07,662 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1804082424-172.17.0.6-1606980002416 (Datanode Uuid 2df0ed89-2351-4d4d-8341-dd4497968a1f) service to localhost/127.0.0.1:45965
2020-12-03 07:20:07,662 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1804082424-172.17.0.6-1606980002416 (Datanode Uuid 2df0ed89-2351-4d4d-8341-dd4497968a1f)
2020-12-03 07:20:07,665 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:07,665 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1804082424-172.17.0.6-1606980002416] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:07,668 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1804082424-172.17.0.6-1606980002416] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:07,686 [Thread-957] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/in_use.lock acquired by nodename 906@9ece31fe74eb
2020-12-03 07:20:07,686 [Listener at localhost/35874] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:07,686 [Listener at localhost/35874] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:07,686 [Listener at localhost/35874] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:07,687 [Listener at localhost/35874] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:07,692 [Listener at localhost/35874] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:07,693 [Listener at localhost/35874] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:20:07,693 [Listener at localhost/35874] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:20:07,694 [Listener at localhost/35874] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:07,695 [Listener at localhost/35874] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:07,695 [Listener at localhost/35874] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:07,695 [Listener at localhost/35874] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:07,695 [Listener at localhost/35874] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:07,696 [Listener at localhost/35874] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:07,696 [Listener at localhost/35874] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:45527
2020-12-03 07:20:07,696 [Listener at localhost/35874] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:07,696 [Listener at localhost/35874] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:07,697 [Listener at localhost/35874] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:07,698 [Listener at localhost/35874] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:07,699 [Listener at localhost/35874] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:07,699 [Listener at localhost/35874] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:07,701 [Listener at localhost/35874] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:07,701 [Listener at localhost/35874] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:07,701 [Listener at localhost/35874] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:07,701 [Listener at localhost/35874] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:07,702 [Listener at localhost/35874] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 38061
2020-12-03 07:20:07,702 [Listener at localhost/35874] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:07,703 [Listener at localhost/35874] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7c29adc8{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:07,704 [Listener at localhost/35874] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4bbb49b0{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:07,709 [Listener at localhost/35874] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7afbf561{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:20:07,709 [Listener at localhost/35874] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2f98635e{HTTP/1.1,[http/1.1]}{localhost:38061}
2020-12-03 07:20:07,713 [Listener at localhost/35874] INFO  server.Server (Server.java:doStart(419)) - Started @27446ms
2020-12-03 07:20:07,733 [Listener at localhost/35874] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:32957
2020-12-03 07:20:07,733 [Listener at localhost/35874] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:07,734 [Listener at localhost/35874] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:07,733 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6b0615ae] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:07,734 [Listener at localhost/35874] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:07,735 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:07,739 [Listener at localhost/41780] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:41780
2020-12-03 07:20:07,745 [Thread-935] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:07,745 [Thread-935] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:07,790 [Listener at localhost/41780] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:20:07,790 [Listener at localhost/41780] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:20:07,791 [Thread-979] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45965 starting to offer service
2020-12-03 07:20:07,795 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:07,795 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:07,799 [Listener at localhost/41780] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:restartDataNodes(2519)) - Restarted DataNode 5
2020-12-03 07:20:07,799 [Listener at localhost/41780] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopDataNode(2331)) - MiniDFSCluster Stopping DataNode 127.0.0.1:42042 from a total of 8 datanodes.
2020-12-03 07:20:07,799 [Listener at localhost/41780] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:07,799 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@56ac5c80] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:07,800 [Thread-979] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45965
2020-12-03 07:20:07,803 [Thread-979] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:07,803 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-512a29a1-592b-4a6b-9e0b-372194c82b1f) exiting.
2020-12-03 07:20:07,803 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-ee267448-1a4d-452b-be30-3480ab792404) exiting.
2020-12-03 07:20:07,830 [Thread-935] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:07,830 [Thread-935] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:07,840 [Listener at localhost/41780] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@7b4acdc2{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:07,841 [Listener at localhost/41780] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@26a262d6{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:07,841 [Listener at localhost/41780] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@21f8e55f{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:07,841 [Listener at localhost/41780] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@13f9ad9{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:07,847 [Listener at localhost/41780] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 39229
2020-12-03 07:20:07,847 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:07,847 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:07,848 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:07,848 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1804082424-172.17.0.6-1606980002416 (Datanode Uuid e8690573-6d95-48a1-9ba7-5b1be3fa4816) service to localhost/127.0.0.1:45965
2020-12-03 07:20:07,848 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1804082424-172.17.0.6-1606980002416 (Datanode Uuid e8690573-6d95-48a1-9ba7-5b1be3fa4816)
2020-12-03 07:20:07,851 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:07,852 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1804082424-172.17.0.6-1606980002416] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:07,856 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1804082424-172.17.0.6-1606980002416] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:07,859 [Listener at localhost/41780] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:07,859 [Listener at localhost/41780] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:07,859 [Listener at localhost/41780] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:07,859 [Listener at localhost/41780] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:07,867 [Listener at localhost/41780] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:07,869 [Listener at localhost/41780] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:20:07,869 [Listener at localhost/41780] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:20:07,882 [Thread-957] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/in_use.lock acquired by nodename 906@9ece31fe74eb
2020-12-03 07:20:07,882 [Thread-979] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/in_use.lock acquired by nodename 906@9ece31fe74eb
2020-12-03 07:20:07,889 [Listener at localhost/41780] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:07,890 [Listener at localhost/41780] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:07,890 [Listener at localhost/41780] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:07,891 [Listener at localhost/41780] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:07,891 [Listener at localhost/41780] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:07,891 [Listener at localhost/41780] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:07,892 [Listener at localhost/41780] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:35680
2020-12-03 07:20:07,892 [Listener at localhost/41780] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:07,893 [Listener at localhost/41780] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:07,897 [Listener at localhost/41780] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:07,899 [Listener at localhost/41780] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:07,900 [Listener at localhost/41780] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:07,900 [Listener at localhost/41780] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:07,902 [Listener at localhost/41780] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:07,903 [Listener at localhost/41780] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:07,903 [Listener at localhost/41780] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:07,903 [Listener at localhost/41780] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:07,904 [Listener at localhost/41780] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 45931
2020-12-03 07:20:07,904 [Listener at localhost/41780] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:07,935 [Listener at localhost/41780] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7b78ed6a{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:07,939 [Listener at localhost/41780] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6ec65b5e{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:07,946 [Thread-935] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=864125735;bpid=BP-1804082424-172.17.0.6-1606980002416;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=864125735;c=1606980002416;bpid=BP-1804082424-172.17.0.6-1606980002416;dnuuid=29c10e8f-bd24-491d-a369-fc3d4333f678
2020-12-03 07:20:07,948 [Thread-935] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-1d5f4027-0413-4b3d-bce3-7989772d6afc
2020-12-03 07:20:07,948 [Thread-935] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, StorageType: DISK
2020-12-03 07:20:07,949 [Thread-935] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-9430fa01-b843-4ce1-b229-c4ef32f58568
2020-12-03 07:20:07,949 [Thread-935] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, StorageType: DISK
2020-12-03 07:20:07,949 [Thread-935] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:07,950 [Thread-935] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:20:07,951 [Thread-935] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:20:07,952 [Thread-935] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:20:07,952 [Thread-935] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:20:07,952 [Thread-935] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:07,952 [Thread-997] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15...
2020-12-03 07:20:07,954 [Thread-997] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1804082424-172.17.0.6-1606980002416/current: 24576
2020-12-03 07:20:07,954 [Thread-998] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16...
2020-12-03 07:20:07,955 [Thread-998] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1804082424-172.17.0.6-1606980002416/current: 24576
2020-12-03 07:20:07,961 [Listener at localhost/41780] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@756b58a7{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:20:07,967 [Listener at localhost/41780] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2cc04358{HTTP/1.1,[http/1.1]}{localhost:45931}
2020-12-03 07:20:07,967 [Listener at localhost/41780] INFO  server.Server (Server.java:doStart(419)) - Started @27700ms
2020-12-03 07:20:07,969 [Thread-997] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1804082424-172.17.0.6-1606980002416 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15: 17ms
2020-12-03 07:20:07,975 [Thread-998] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1804082424-172.17.0.6-1606980002416 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16: 20ms
2020-12-03 07:20:07,975 [Thread-935] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1804082424-172.17.0.6-1606980002416: 23ms
2020-12-03 07:20:07,976 [Thread-999] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15...
2020-12-03 07:20:07,976 [Thread-999] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1804082424-172.17.0.6-1606980002416/current/replicas doesn't exist 
2020-12-03 07:20:07,976 [Thread-1000] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16...
2020-12-03 07:20:07,976 [Thread-1000] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1804082424-172.17.0.6-1606980002416/current/replicas doesn't exist 
2020-12-03 07:20:07,976 [Thread-999] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15: 1ms
2020-12-03 07:20:07,976 [Thread-1000] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16: 1ms
2020-12-03 07:20:07,976 [Thread-935] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416: 1ms
2020-12-03 07:20:07,977 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-1d5f4027-0413-4b3d-bce3-7989772d6afc): no suitable block pools found to scan.  Waiting 1814398147 ms.
2020-12-03 07:20:07,977 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-9430fa01-b843-4ce1-b229-c4ef32f58568): no suitable block pools found to scan.  Waiting 1814398148 ms.
2020-12-03 07:20:07,978 [Thread-935] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:01 AM with interval of 21600000ms
2020-12-03 07:20:07,989 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1804082424-172.17.0.6-1606980002416 (Datanode Uuid 29c10e8f-bd24-491d-a369-fc3d4333f678) service to localhost/127.0.0.1:45965 beginning handshake with NN
2020-12-03 07:20:07,990 [Thread-957] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:07,990 [Thread-957] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:07,991 [IPC Server handler 4 on default port 45965] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:36870, datanodeUuid=29c10e8f-bd24-491d-a369-fc3d4333f678, infoPort=43743, infoSecurePort=0, ipcPort=42318, storageInfo=lv=-57;cid=testClusterID;nsid=864125735;c=1606980002416) storage 29c10e8f-bd24-491d-a369-fc3d4333f678
2020-12-03 07:20:07,992 [IPC Server handler 4 on default port 45965] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1078)) - BLOCK* registerDatanode: 127.0.0.1:35620 is replaced by DatanodeRegistration(127.0.0.1:36870, datanodeUuid=29c10e8f-bd24-491d-a369-fc3d4333f678, infoPort=43743, infoSecurePort=0, ipcPort=42318, storageInfo=lv=-57;cid=testClusterID;nsid=864125735;c=1606980002416) with the same storageID 29c10e8f-bd24-491d-a369-fc3d4333f678
2020-12-03 07:20:07,992 [IPC Server handler 4 on default port 45965] INFO  net.NetworkTopology (NetworkTopology.java:remove(219)) - Removing a node: /default-rack/127.0.0.1:35620
2020-12-03 07:20:07,992 [IPC Server handler 4 on default port 45965] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36870
2020-12-03 07:20:07,993 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1804082424-172.17.0.6-1606980002416 (Datanode Uuid 29c10e8f-bd24-491d-a369-fc3d4333f678) service to localhost/127.0.0.1:45965 successfully registered with NN
2020-12-03 07:20:07,993 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:45965 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:08,005 [Listener at localhost/41780] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:37819
2020-12-03 07:20:08,006 [Listener at localhost/41780] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:08,006 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@45e22def] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:08,006 [Listener at localhost/41780] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:08,007 [Listener at localhost/41780] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:08,008 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:08,009 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x4f7feb816d892674: Processing first storage report for DS-1d5f4027-0413-4b3d-bce3-7989772d6afc from datanode 29c10e8f-bd24-491d-a369-fc3d4333f678
2020-12-03 07:20:08,009 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x4f7feb816d892674: from storage DS-1d5f4027-0413-4b3d-bce3-7989772d6afc node DatanodeRegistration(127.0.0.1:36870, datanodeUuid=29c10e8f-bd24-491d-a369-fc3d4333f678, infoPort=43743, infoSecurePort=0, ipcPort=42318, storageInfo=lv=-57;cid=testClusterID;nsid=864125735;c=1606980002416), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:08,009 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x4f7feb816d892674: Processing first storage report for DS-9430fa01-b843-4ce1-b229-c4ef32f58568 from datanode 29c10e8f-bd24-491d-a369-fc3d4333f678
2020-12-03 07:20:08,009 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x4f7feb816d892674: from storage DS-9430fa01-b843-4ce1-b229-c4ef32f58568 node DatanodeRegistration(127.0.0.1:36870, datanodeUuid=29c10e8f-bd24-491d-a369-fc3d4333f678, infoPort=43743, infoSecurePort=0, ipcPort=42318, storageInfo=lv=-57;cid=testClusterID;nsid=864125735;c=1606980002416), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:08,016 [Listener at localhost/34326] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:34326
2020-12-03 07:20:08,016 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x4f7feb816d892674,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 9 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:08,016 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:08,036 [Thread-979] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/in_use.lock acquired by nodename 906@9ece31fe74eb
2020-12-03 07:20:08,081 [Listener at localhost/34326] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:20:08,083 [Listener at localhost/34326] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:20:08,084 [Thread-1010] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45965 starting to offer service
2020-12-03 07:20:08,089 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:08,090 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:08,101 [Listener at localhost/34326] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:restartDataNodes(2519)) - Restarted DataNode 4
2020-12-03 07:20:08,101 [Listener at localhost/34326] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopDataNode(2331)) - MiniDFSCluster Stopping DataNode 127.0.0.1:33010 from a total of 8 datanodes.
2020-12-03 07:20:08,101 [Listener at localhost/34326] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(341)) - DirectoryScanner: shutdown has been called, but periodic scanner not started
2020-12-03 07:20:08,101 [Thread-1010] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45965
2020-12-03 07:20:08,102 [Listener at localhost/34326] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 44957
2020-12-03 07:20:08,106 [Thread-1010] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:08,106 [Listener at localhost/34326] WARN  util.MBeans (MBeans.java:unregister(145)) - Error unregistering Hadoop:service=DataNode,name=FSDatasetState-9acfc918-b97f-4fcf-8bea-64439f1ae0ea
javax.management.InstanceNotFoundException: Hadoop:service=DataNode,name=FSDatasetState-9acfc918-b97f-4fcf-8bea-64439f1ae0ea
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getMBean(DefaultMBeanServerInterceptor.java:1095)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.exclusiveUnregisterMBean(DefaultMBeanServerInterceptor.java:427)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.unregisterMBean(DefaultMBeanServerInterceptor.java:415)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.unregisterMBean(JmxMBeanServer.java:546)
	at org.apache.hadoop.metrics2.util.MBeans.unregister(MBeans.java:143)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.shutdown(FsDatasetImpl.java:2293)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.shutdown(DataNode.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.stopDataNode(MiniDFSCluster.java:2335)
	at org.apache.hadoop.hdfs.MiniDFSCluster.restartDataNode(MiniDFSCluster.java:2482)
	at org.apache.hadoop.hdfs.MiniDFSCluster.restartDataNode(MiniDFSCluster.java:2469)
	at org.apache.hadoop.hdfs.MiniDFSCluster.restartDataNodes(MiniDFSCluster.java:2517)
	at org.apache.hadoop.hdfs.MiniDFSCluster.restartDataNodes(MiniDFSCluster.java:2528)
	at org.apache.hadoop.hdfs.server.namenode.TestNamenodeCapacityReport.testXceiverCountInternal(TestNamenodeCapacityReport.java:254)
	at org.apache.hadoop.hdfs.server.namenode.TestNamenodeCapacityReport.testXceiverCount(TestNamenodeCapacityReport.java:200)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2020-12-03 07:20:08,111 [Listener at localhost/34326] WARN  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(191)) - AsyncDiskService has already shut down.
2020-12-03 07:20:08,111 [Listener at localhost/34326] WARN  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(175)) - AsyncLazyPersistService has already shut down.
2020-12-03 07:20:08,111 [Listener at localhost/34326] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:08,107 [Thread-957] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:08,112 [Thread-957] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:08,112 [Listener at localhost/34326] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:20:08,113 [Listener at localhost/34326] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:20:08,114 [Listener at localhost/34326] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:08,114 [Listener at localhost/34326] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:08,114 [Listener at localhost/34326] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:08,115 [Listener at localhost/34326] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:08,115 [Listener at localhost/34326] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:08,115 [Listener at localhost/34326] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:08,116 [Listener at localhost/34326] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:34244
2020-12-03 07:20:08,116 [Listener at localhost/34326] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:08,116 [Listener at localhost/34326] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:08,117 [Listener at localhost/34326] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:08,119 [Listener at localhost/34326] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:08,119 [Listener at localhost/34326] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:08,119 [Listener at localhost/34326] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:08,121 [Listener at localhost/34326] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:08,121 [Listener at localhost/34326] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:08,121 [Listener at localhost/34326] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:08,122 [Listener at localhost/34326] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:08,122 [Listener at localhost/34326] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 37788
2020-12-03 07:20:08,122 [Listener at localhost/34326] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:08,124 [Listener at localhost/34326] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7ed9499e{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:08,124 [Listener at localhost/34326] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5b275174{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:08,129 [Listener at localhost/34326] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1ff55ff{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:20:08,130 [Listener at localhost/34326] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@351f2244{HTTP/1.1,[http/1.1]}{localhost:37788}
2020-12-03 07:20:08,135 [Listener at localhost/34326] INFO  server.Server (Server.java:doStart(419)) - Started @27868ms
2020-12-03 07:20:08,139 [Thread-979] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:08,139 [Thread-979] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:08,160 [Listener at localhost/34326] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:43697
2020-12-03 07:20:08,161 [Listener at localhost/34326] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:08,161 [Listener at localhost/34326] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:08,161 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@51a8313b] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:08,162 [Listener at localhost/34326] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:08,162 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:08,169 [Listener at localhost/38727] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:38727
2020-12-03 07:20:08,199 [Thread-1010] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/in_use.lock acquired by nodename 906@9ece31fe74eb
2020-12-03 07:20:08,201 [Thread-957] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=864125735;bpid=BP-1804082424-172.17.0.6-1606980002416;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=864125735;c=1606980002416;bpid=BP-1804082424-172.17.0.6-1606980002416;dnuuid=b038b1a4-65c2-42df-90ed-7eefd1a46770
2020-12-03 07:20:08,235 [Thread-957] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-e393a8d1-0f5b-4659-b3f3-ec668d265860
2020-12-03 07:20:08,236 [Thread-957] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, StorageType: DISK
2020-12-03 07:20:08,236 [Listener at localhost/38727] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:20:08,236 [Listener at localhost/38727] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:20:08,237 [Thread-1033] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45965 starting to offer service
2020-12-03 07:20:08,242 [Thread-957] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-034e39a9-7d42-4606-aaed-1b5bf00d1e13
2020-12-03 07:20:08,242 [Thread-957] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, StorageType: DISK
2020-12-03 07:20:08,242 [Thread-957] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:08,242 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:08,243 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:08,249 [Thread-1033] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45965
2020-12-03 07:20:08,252 [Thread-1033] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:08,252 [Thread-957] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:20:08,252 [Listener at localhost/38727] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:restartDataNodes(2519)) - Restarted DataNode 3
2020-12-03 07:20:08,253 [Listener at localhost/38727] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopDataNode(2331)) - MiniDFSCluster Stopping DataNode 127.0.0.1:39218 from a total of 8 datanodes.
2020-12-03 07:20:08,253 [Listener at localhost/38727] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(341)) - DirectoryScanner: shutdown has been called, but periodic scanner not started
2020-12-03 07:20:08,253 [Listener at localhost/38727] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 37261
2020-12-03 07:20:08,253 [Thread-957] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:20:08,253 [Listener at localhost/38727] WARN  util.MBeans (MBeans.java:unregister(145)) - Error unregistering Hadoop:service=DataNode,name=FSDatasetState-de098be8-3b57-427f-9f60-e85f3df9f694
javax.management.InstanceNotFoundException: Hadoop:service=DataNode,name=FSDatasetState-de098be8-3b57-427f-9f60-e85f3df9f694
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getMBean(DefaultMBeanServerInterceptor.java:1095)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.exclusiveUnregisterMBean(DefaultMBeanServerInterceptor.java:427)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.unregisterMBean(DefaultMBeanServerInterceptor.java:415)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.unregisterMBean(JmxMBeanServer.java:546)
	at org.apache.hadoop.metrics2.util.MBeans.unregister(MBeans.java:143)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.shutdown(FsDatasetImpl.java:2293)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.shutdown(DataNode.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.stopDataNode(MiniDFSCluster.java:2335)
	at org.apache.hadoop.hdfs.MiniDFSCluster.restartDataNode(MiniDFSCluster.java:2482)
	at org.apache.hadoop.hdfs.MiniDFSCluster.restartDataNode(MiniDFSCluster.java:2469)
	at org.apache.hadoop.hdfs.MiniDFSCluster.restartDataNodes(MiniDFSCluster.java:2517)
	at org.apache.hadoop.hdfs.MiniDFSCluster.restartDataNodes(MiniDFSCluster.java:2528)
	at org.apache.hadoop.hdfs.server.namenode.TestNamenodeCapacityReport.testXceiverCountInternal(TestNamenodeCapacityReport.java:254)
	at org.apache.hadoop.hdfs.server.namenode.TestNamenodeCapacityReport.testXceiverCount(TestNamenodeCapacityReport.java:200)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2020-12-03 07:20:08,254 [Listener at localhost/38727] WARN  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(191)) - AsyncDiskService has already shut down.
2020-12-03 07:20:08,254 [Listener at localhost/38727] WARN  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(175)) - AsyncLazyPersistService has already shut down.
2020-12-03 07:20:08,253 [Thread-957] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:20:08,254 [Listener at localhost/38727] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:08,254 [Thread-957] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:20:08,254 [Thread-957] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:08,255 [Thread-1045] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13...
2020-12-03 07:20:08,255 [Thread-1046] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14...
2020-12-03 07:20:08,255 [Listener at localhost/38727] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:20:08,256 [Listener at localhost/38727] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:20:08,256 [Thread-1045] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1804082424-172.17.0.6-1606980002416/current: 24576
2020-12-03 07:20:08,256 [Thread-1046] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1804082424-172.17.0.6-1606980002416/current: 24576
2020-12-03 07:20:08,256 [Listener at localhost/38727] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:08,257 [Listener at localhost/38727] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:08,257 [Listener at localhost/38727] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:08,257 [Listener at localhost/38727] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:08,258 [Listener at localhost/38727] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:08,258 [Listener at localhost/38727] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:08,258 [Listener at localhost/38727] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:36836
2020-12-03 07:20:08,258 [Listener at localhost/38727] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:08,259 [Listener at localhost/38727] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:08,259 [Listener at localhost/38727] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:08,261 [Listener at localhost/38727] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:08,261 [Listener at localhost/38727] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:08,262 [Listener at localhost/38727] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:08,263 [Listener at localhost/38727] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:08,263 [Listener at localhost/38727] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:08,264 [Listener at localhost/38727] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:08,264 [Listener at localhost/38727] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:08,264 [Thread-1045] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1804082424-172.17.0.6-1606980002416 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13: 10ms
2020-12-03 07:20:08,264 [Thread-1046] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1804082424-172.17.0.6-1606980002416 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14: 9ms
2020-12-03 07:20:08,264 [Thread-957] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1804082424-172.17.0.6-1606980002416: 10ms
2020-12-03 07:20:08,264 [Listener at localhost/38727] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 34983
2020-12-03 07:20:08,265 [Listener at localhost/38727] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:08,265 [Thread-1049] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13...
2020-12-03 07:20:08,265 [Thread-1050] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14...
2020-12-03 07:20:08,265 [Thread-1049] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1804082424-172.17.0.6-1606980002416/current/replicas doesn't exist 
2020-12-03 07:20:08,265 [Thread-1050] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1804082424-172.17.0.6-1606980002416/current/replicas doesn't exist 
2020-12-03 07:20:08,265 [Thread-1049] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13: 1ms
2020-12-03 07:20:08,266 [Thread-1050] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14: 0ms
2020-12-03 07:20:08,266 [Thread-957] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416: 1ms
2020-12-03 07:20:08,266 [Listener at localhost/38727] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2b5183ec{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:08,266 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-034e39a9-7d42-4606-aaed-1b5bf00d1e13): no suitable block pools found to scan.  Waiting 1814397762 ms.
2020-12-03 07:20:08,266 [Listener at localhost/38727] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@572e6fd9{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:08,267 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-e393a8d1-0f5b-4659-b3f3-ec668d265860): no suitable block pools found to scan.  Waiting 1814397761 ms.
2020-12-03 07:20:08,267 [Thread-957] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 1:00 PM with interval of 21600000ms
2020-12-03 07:20:08,272 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1804082424-172.17.0.6-1606980002416 (Datanode Uuid b038b1a4-65c2-42df-90ed-7eefd1a46770) service to localhost/127.0.0.1:45965 beginning handshake with NN
2020-12-03 07:20:08,273 [IPC Server handler 8 on default port 45965] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:45553, datanodeUuid=b038b1a4-65c2-42df-90ed-7eefd1a46770, infoPort=40774, infoSecurePort=0, ipcPort=35874, storageInfo=lv=-57;cid=testClusterID;nsid=864125735;c=1606980002416) storage b038b1a4-65c2-42df-90ed-7eefd1a46770
2020-12-03 07:20:08,273 [IPC Server handler 8 on default port 45965] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1078)) - BLOCK* registerDatanode: 127.0.0.1:46071 is replaced by DatanodeRegistration(127.0.0.1:45553, datanodeUuid=b038b1a4-65c2-42df-90ed-7eefd1a46770, infoPort=40774, infoSecurePort=0, ipcPort=35874, storageInfo=lv=-57;cid=testClusterID;nsid=864125735;c=1606980002416) with the same storageID b038b1a4-65c2-42df-90ed-7eefd1a46770
2020-12-03 07:20:08,273 [IPC Server handler 8 on default port 45965] INFO  net.NetworkTopology (NetworkTopology.java:remove(219)) - Removing a node: /default-rack/127.0.0.1:46071
2020-12-03 07:20:08,273 [IPC Server handler 8 on default port 45965] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:45553
2020-12-03 07:20:08,274 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1804082424-172.17.0.6-1606980002416 (Datanode Uuid b038b1a4-65c2-42df-90ed-7eefd1a46770) service to localhost/127.0.0.1:45965 successfully registered with NN
2020-12-03 07:20:08,274 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:45965 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:08,280 [Listener at localhost/38727] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1c6c6f24{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:20:08,290 [Listener at localhost/38727] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2eb917d0{HTTP/1.1,[http/1.1]}{localhost:34983}
2020-12-03 07:20:08,290 [Listener at localhost/38727] INFO  server.Server (Server.java:doStart(419)) - Started @28023ms
2020-12-03 07:20:08,292 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x6988ca626e5a44a1: Processing first storage report for DS-034e39a9-7d42-4606-aaed-1b5bf00d1e13 from datanode b038b1a4-65c2-42df-90ed-7eefd1a46770
2020-12-03 07:20:08,292 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x6988ca626e5a44a1: from storage DS-034e39a9-7d42-4606-aaed-1b5bf00d1e13 node DatanodeRegistration(127.0.0.1:45553, datanodeUuid=b038b1a4-65c2-42df-90ed-7eefd1a46770, infoPort=40774, infoSecurePort=0, ipcPort=35874, storageInfo=lv=-57;cid=testClusterID;nsid=864125735;c=1606980002416), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:08,292 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x6988ca626e5a44a1: Processing first storage report for DS-e393a8d1-0f5b-4659-b3f3-ec668d265860 from datanode b038b1a4-65c2-42df-90ed-7eefd1a46770
2020-12-03 07:20:08,292 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x6988ca626e5a44a1: from storage DS-e393a8d1-0f5b-4659-b3f3-ec668d265860 node DatanodeRegistration(127.0.0.1:45553, datanodeUuid=b038b1a4-65c2-42df-90ed-7eefd1a46770, infoPort=40774, infoSecurePort=0, ipcPort=35874, storageInfo=lv=-57;cid=testClusterID;nsid=864125735;c=1606980002416), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:08,293 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x6988ca626e5a44a1,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:08,293 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:08,299 [Thread-979] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:08,300 [Thread-979] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:08,475 [Thread-979] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=864125735;bpid=BP-1804082424-172.17.0.6-1606980002416;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=864125735;c=1606980002416;bpid=BP-1804082424-172.17.0.6-1606980002416;dnuuid=2df0ed89-2351-4d4d-8341-dd4497968a1f
2020-12-03 07:20:08,477 [Thread-979] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-2846ef14-7d0f-45aa-b4f1-52040a358f03
2020-12-03 07:20:08,478 [Thread-979] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, StorageType: DISK
2020-12-03 07:20:08,488 [Listener at localhost/38727] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:37274
2020-12-03 07:20:08,489 [Listener at localhost/38727] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:08,489 [Listener at localhost/38727] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:08,489 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@73437222] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:08,490 [Listener at localhost/38727] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:08,491 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:08,507 [Thread-1033] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/in_use.lock acquired by nodename 906@9ece31fe74eb
2020-12-03 07:20:08,517 [Thread-979] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-fde66b64-bf3d-4e52-a9d8-47e9e976c8ea
2020-12-03 07:20:08,518 [Thread-979] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, StorageType: DISK
2020-12-03 07:20:08,518 [Thread-979] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:08,519 [Thread-979] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:20:08,521 [Thread-979] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:20:08,521 [Thread-979] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:20:08,521 [Thread-979] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:20:08,521 [Thread-979] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:08,522 [Thread-1063] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12...
2020-12-03 07:20:08,523 [Thread-1063] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1804082424-172.17.0.6-1606980002416/current: 24576
2020-12-03 07:20:08,524 [Listener at localhost/43963] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:43963
2020-12-03 07:20:08,525 [Thread-1062] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11...
2020-12-03 07:20:08,526 [Thread-1062] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1804082424-172.17.0.6-1606980002416/current: 24576
2020-12-03 07:20:08,532 [Thread-1063] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1804082424-172.17.0.6-1606980002416 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12: 10ms
2020-12-03 07:20:08,537 [Thread-1062] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1804082424-172.17.0.6-1606980002416 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11: 13ms
2020-12-03 07:20:08,537 [Thread-979] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1804082424-172.17.0.6-1606980002416: 16ms
2020-12-03 07:20:08,586 [Thread-1010] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/in_use.lock acquired by nodename 906@9ece31fe74eb
2020-12-03 07:20:08,595 [Thread-1065] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11...
2020-12-03 07:20:08,595 [Thread-1066] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12...
2020-12-03 07:20:08,596 [Thread-1065] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1804082424-172.17.0.6-1606980002416/current/replicas doesn't exist 
2020-12-03 07:20:08,596 [Thread-1066] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1804082424-172.17.0.6-1606980002416/current/replicas doesn't exist 
2020-12-03 07:20:08,596 [Thread-1065] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11: 1ms
2020-12-03 07:20:08,596 [Thread-1066] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12: 1ms
2020-12-03 07:20:08,596 [Thread-979] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416: 59ms
2020-12-03 07:20:08,598 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-fde66b64-bf3d-4e52-a9d8-47e9e976c8ea): no suitable block pools found to scan.  Waiting 1814397383 ms.
2020-12-03 07:20:08,598 [Thread-979] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 10:51 AM with interval of 21600000ms
2020-12-03 07:20:08,603 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1804082424-172.17.0.6-1606980002416 (Datanode Uuid 2df0ed89-2351-4d4d-8341-dd4497968a1f) service to localhost/127.0.0.1:45965 beginning handshake with NN
2020-12-03 07:20:08,625 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-2846ef14-7d0f-45aa-b4f1-52040a358f03): no suitable block pools found to scan.  Waiting 1814397357 ms.
2020-12-03 07:20:08,625 [Listener at localhost/43963] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:20:08,626 [Listener at localhost/43963] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:20:08,627 [Thread-1072] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45965 starting to offer service
2020-12-03 07:20:08,628 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:08,628 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:08,629 [Listener at localhost/43963] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:restartDataNodes(2519)) - Restarted DataNode 2
2020-12-03 07:20:08,629 [Listener at localhost/43963] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopDataNode(2331)) - MiniDFSCluster Stopping DataNode 127.0.0.1:40040 from a total of 8 datanodes.
2020-12-03 07:20:08,630 [Listener at localhost/43963] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(341)) - DirectoryScanner: shutdown has been called, but periodic scanner not started
2020-12-03 07:20:08,630 [Listener at localhost/43963] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 42283
2020-12-03 07:20:08,630 [Listener at localhost/43963] WARN  util.MBeans (MBeans.java:unregister(145)) - Error unregistering Hadoop:service=DataNode,name=FSDatasetState-2ed09fef-76ca-4e59-b76b-c7e5fbb353e7
javax.management.InstanceNotFoundException: Hadoop:service=DataNode,name=FSDatasetState-2ed09fef-76ca-4e59-b76b-c7e5fbb353e7
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getMBean(DefaultMBeanServerInterceptor.java:1095)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.exclusiveUnregisterMBean(DefaultMBeanServerInterceptor.java:427)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.unregisterMBean(DefaultMBeanServerInterceptor.java:415)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.unregisterMBean(JmxMBeanServer.java:546)
	at org.apache.hadoop.metrics2.util.MBeans.unregister(MBeans.java:143)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.shutdown(FsDatasetImpl.java:2293)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.shutdown(DataNode.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.stopDataNode(MiniDFSCluster.java:2335)
	at org.apache.hadoop.hdfs.MiniDFSCluster.restartDataNode(MiniDFSCluster.java:2482)
	at org.apache.hadoop.hdfs.MiniDFSCluster.restartDataNode(MiniDFSCluster.java:2469)
	at org.apache.hadoop.hdfs.MiniDFSCluster.restartDataNodes(MiniDFSCluster.java:2517)
	at org.apache.hadoop.hdfs.MiniDFSCluster.restartDataNodes(MiniDFSCluster.java:2528)
	at org.apache.hadoop.hdfs.server.namenode.TestNamenodeCapacityReport.testXceiverCountInternal(TestNamenodeCapacityReport.java:254)
	at org.apache.hadoop.hdfs.server.namenode.TestNamenodeCapacityReport.testXceiverCount(TestNamenodeCapacityReport.java:200)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2020-12-03 07:20:08,632 [Listener at localhost/43963] WARN  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(191)) - AsyncDiskService has already shut down.
2020-12-03 07:20:08,632 [Listener at localhost/43963] WARN  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(175)) - AsyncLazyPersistService has already shut down.
2020-12-03 07:20:08,632 [Listener at localhost/43963] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:08,633 [Listener at localhost/43963] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:20:08,634 [Listener at localhost/43963] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:20:08,635 [Listener at localhost/43963] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:08,635 [Listener at localhost/43963] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:08,636 [Listener at localhost/43963] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:08,636 [Listener at localhost/43963] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:08,636 [Listener at localhost/43963] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:08,637 [Listener at localhost/43963] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:08,638 [Listener at localhost/43963] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:35571
2020-12-03 07:20:08,638 [Listener at localhost/43963] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:08,638 [Listener at localhost/43963] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:08,640 [Listener at localhost/43963] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:08,642 [Listener at localhost/43963] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:08,642 [Listener at localhost/43963] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:08,642 [Listener at localhost/43963] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:08,644 [Listener at localhost/43963] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:08,645 [Listener at localhost/43963] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:08,645 [Listener at localhost/43963] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:08,645 [Listener at localhost/43963] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:08,646 [Listener at localhost/43963] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 35847
2020-12-03 07:20:08,646 [Listener at localhost/43963] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:08,648 [Listener at localhost/43963] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@8ee0c23{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:08,649 [Listener at localhost/43963] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4dc8c0ea{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:08,655 [Listener at localhost/43963] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@46731692{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:20:08,667 [Listener at localhost/43963] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@782bf610{HTTP/1.1,[http/1.1]}{localhost:35847}
2020-12-03 07:20:08,667 [Listener at localhost/43963] INFO  server.Server (Server.java:doStart(419)) - Started @28400ms
2020-12-03 07:20:08,667 [IPC Server handler 2 on default port 45965] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:45527, datanodeUuid=2df0ed89-2351-4d4d-8341-dd4497968a1f, infoPort=32957, infoSecurePort=0, ipcPort=41780, storageInfo=lv=-57;cid=testClusterID;nsid=864125735;c=1606980002416) storage 2df0ed89-2351-4d4d-8341-dd4497968a1f
2020-12-03 07:20:08,668 [IPC Server handler 2 on default port 45965] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1078)) - BLOCK* registerDatanode: 127.0.0.1:44728 is replaced by DatanodeRegistration(127.0.0.1:45527, datanodeUuid=2df0ed89-2351-4d4d-8341-dd4497968a1f, infoPort=32957, infoSecurePort=0, ipcPort=41780, storageInfo=lv=-57;cid=testClusterID;nsid=864125735;c=1606980002416) with the same storageID 2df0ed89-2351-4d4d-8341-dd4497968a1f
2020-12-03 07:20:08,668 [IPC Server handler 2 on default port 45965] INFO  net.NetworkTopology (NetworkTopology.java:remove(219)) - Removing a node: /default-rack/127.0.0.1:44728
2020-12-03 07:20:08,668 [IPC Server handler 2 on default port 45965] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:45527
2020-12-03 07:20:08,669 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1804082424-172.17.0.6-1606980002416 (Datanode Uuid 2df0ed89-2351-4d4d-8341-dd4497968a1f) service to localhost/127.0.0.1:45965 successfully registered with NN
2020-12-03 07:20:08,669 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:45965 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:08,676 [Thread-1072] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45965
2020-12-03 07:20:08,686 [Thread-1072] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:08,686 [Thread-1033] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/in_use.lock acquired by nodename 906@9ece31fe74eb
2020-12-03 07:20:08,697 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xa75bd0227026eacd: Processing first storage report for DS-2846ef14-7d0f-45aa-b4f1-52040a358f03 from datanode 2df0ed89-2351-4d4d-8341-dd4497968a1f
2020-12-03 07:20:08,698 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xa75bd0227026eacd: from storage DS-2846ef14-7d0f-45aa-b4f1-52040a358f03 node DatanodeRegistration(127.0.0.1:45527, datanodeUuid=2df0ed89-2351-4d4d-8341-dd4497968a1f, infoPort=32957, infoSecurePort=0, ipcPort=41780, storageInfo=lv=-57;cid=testClusterID;nsid=864125735;c=1606980002416), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:08,698 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xa75bd0227026eacd: Processing first storage report for DS-fde66b64-bf3d-4e52-a9d8-47e9e976c8ea from datanode 2df0ed89-2351-4d4d-8341-dd4497968a1f
2020-12-03 07:20:08,698 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xa75bd0227026eacd: from storage DS-fde66b64-bf3d-4e52-a9d8-47e9e976c8ea node DatanodeRegistration(127.0.0.1:45527, datanodeUuid=2df0ed89-2351-4d4d-8341-dd4497968a1f, infoPort=32957, infoSecurePort=0, ipcPort=41780, storageInfo=lv=-57;cid=testClusterID;nsid=864125735;c=1606980002416), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:20:08,699 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xa75bd0227026eacd,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 23 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:08,699 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:08,709 [Thread-1010] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:08,709 [Thread-1010] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:08,726 [Listener at localhost/43963] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:36419
2020-12-03 07:20:08,727 [Listener at localhost/43963] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:08,727 [Listener at localhost/43963] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:08,727 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@73fc518f] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:08,728 [Listener at localhost/43963] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:08,729 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:08,737 [Listener at localhost/33709] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:33709
2020-12-03 07:20:08,772 [Thread-1072] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 906@9ece31fe74eb
2020-12-03 07:20:08,781 [Thread-1010] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:08,781 [Thread-1033] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:08,781 [Thread-1010] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:08,781 [Thread-1033] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:08,806 [Listener at localhost/33709] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:20:08,806 [Listener at localhost/33709] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:20:08,807 [Thread-1094] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45965 starting to offer service
2020-12-03 07:20:08,807 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:08,819 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:08,823 [Thread-1094] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45965
2020-12-03 07:20:08,827 [Thread-1094] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:08,828 [Listener at localhost/33709] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:restartDataNodes(2519)) - Restarted DataNode 1
2020-12-03 07:20:08,828 [Listener at localhost/33709] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopDataNode(2331)) - MiniDFSCluster Stopping DataNode 127.0.0.1:33969 from a total of 8 datanodes.
2020-12-03 07:20:08,828 [Listener at localhost/33709] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(341)) - DirectoryScanner: shutdown has been called, but periodic scanner not started
2020-12-03 07:20:08,829 [Listener at localhost/33709] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 39687
2020-12-03 07:20:08,829 [Listener at localhost/33709] WARN  util.MBeans (MBeans.java:unregister(145)) - Error unregistering Hadoop:service=DataNode,name=FSDatasetState-c5ae0664-cc27-4ff3-9558-7d39c9eabf00
javax.management.InstanceNotFoundException: Hadoop:service=DataNode,name=FSDatasetState-c5ae0664-cc27-4ff3-9558-7d39c9eabf00
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getMBean(DefaultMBeanServerInterceptor.java:1095)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.exclusiveUnregisterMBean(DefaultMBeanServerInterceptor.java:427)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.unregisterMBean(DefaultMBeanServerInterceptor.java:415)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.unregisterMBean(JmxMBeanServer.java:546)
	at org.apache.hadoop.metrics2.util.MBeans.unregister(MBeans.java:143)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.shutdown(FsDatasetImpl.java:2293)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.shutdown(DataNode.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.stopDataNode(MiniDFSCluster.java:2335)
	at org.apache.hadoop.hdfs.MiniDFSCluster.restartDataNode(MiniDFSCluster.java:2482)
	at org.apache.hadoop.hdfs.MiniDFSCluster.restartDataNode(MiniDFSCluster.java:2469)
	at org.apache.hadoop.hdfs.MiniDFSCluster.restartDataNodes(MiniDFSCluster.java:2517)
	at org.apache.hadoop.hdfs.MiniDFSCluster.restartDataNodes(MiniDFSCluster.java:2528)
	at org.apache.hadoop.hdfs.server.namenode.TestNamenodeCapacityReport.testXceiverCountInternal(TestNamenodeCapacityReport.java:254)
	at org.apache.hadoop.hdfs.server.namenode.TestNamenodeCapacityReport.testXceiverCount(TestNamenodeCapacityReport.java:200)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2020-12-03 07:20:08,830 [Listener at localhost/33709] WARN  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(191)) - AsyncDiskService has already shut down.
2020-12-03 07:20:08,830 [Listener at localhost/33709] WARN  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(175)) - AsyncLazyPersistService has already shut down.
2020-12-03 07:20:08,830 [Listener at localhost/33709] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:08,832 [Listener at localhost/33709] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:20:08,832 [Listener at localhost/33709] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:20:08,833 [Listener at localhost/33709] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:08,833 [Listener at localhost/33709] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:08,833 [Listener at localhost/33709] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:08,834 [Listener at localhost/33709] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:08,834 [Listener at localhost/33709] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:08,834 [Listener at localhost/33709] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:08,835 [Listener at localhost/33709] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:36292
2020-12-03 07:20:08,835 [Listener at localhost/33709] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:08,835 [Listener at localhost/33709] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:08,836 [Listener at localhost/33709] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:08,838 [Listener at localhost/33709] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:08,839 [Listener at localhost/33709] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:08,839 [Listener at localhost/33709] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:08,840 [Listener at localhost/33709] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:08,841 [Listener at localhost/33709] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:08,841 [Listener at localhost/33709] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:08,841 [Listener at localhost/33709] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:08,842 [Listener at localhost/33709] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 37228
2020-12-03 07:20:08,842 [Listener at localhost/33709] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:08,844 [Listener at localhost/33709] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@24b4d544{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:08,844 [Listener at localhost/33709] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@54657dd2{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:08,851 [Listener at localhost/33709] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3964d79{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:20:08,852 [Listener at localhost/33709] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@62db0521{HTTP/1.1,[http/1.1]}{localhost:37228}
2020-12-03 07:20:08,866 [Thread-1010] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=864125735;bpid=BP-1804082424-172.17.0.6-1606980002416;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=864125735;c=1606980002416;bpid=BP-1804082424-172.17.0.6-1606980002416;dnuuid=e8690573-6d95-48a1-9ba7-5b1be3fa4816
2020-12-03 07:20:08,868 [Listener at localhost/33709] INFO  server.Server (Server.java:doStart(419)) - Started @28601ms
2020-12-03 07:20:08,870 [Thread-1010] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-ee267448-1a4d-452b-be30-3480ab792404
2020-12-03 07:20:08,870 [Thread-1010] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, StorageType: DISK
2020-12-03 07:20:08,873 [Thread-1010] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-512a29a1-592b-4a6b-9e0b-372194c82b1f
2020-12-03 07:20:08,873 [Thread-1010] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, StorageType: DISK
2020-12-03 07:20:08,873 [Thread-1010] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:08,874 [Thread-1010] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:20:08,875 [Thread-1010] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:20:08,875 [Thread-1010] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:20:08,878 [Thread-1033] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:08,879 [Thread-1033] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:08,889 [Thread-1010] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:20:08,889 [Thread-1010] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:08,890 [Thread-1112] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-12-03 07:20:08,890 [Thread-1113] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-12-03 07:20:08,891 [Thread-1113] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1804082424-172.17.0.6-1606980002416/current: 24576
2020-12-03 07:20:08,891 [Thread-1112] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1804082424-172.17.0.6-1606980002416/current: 24576
2020-12-03 07:20:08,905 [Thread-1094] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 906@9ece31fe74eb
2020-12-03 07:20:08,906 [Listener at localhost/33709] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:38100
2020-12-03 07:20:08,907 [Listener at localhost/33709] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:08,907 [Listener at localhost/33709] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:08,907 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6ef1a1b9] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:08,908 [Listener at localhost/33709] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:08,912 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:08,927 [Thread-1113] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1804082424-172.17.0.6-1606980002416 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 36ms
2020-12-03 07:20:08,937 [Listener at localhost/41792] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:41792
2020-12-03 07:20:08,938 [Thread-1112] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1804082424-172.17.0.6-1606980002416 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 49ms
2020-12-03 07:20:08,938 [Thread-1010] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1804082424-172.17.0.6-1606980002416: 49ms
2020-12-03 07:20:08,965 [Thread-1072] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 906@9ece31fe74eb
2020-12-03 07:20:08,966 [Thread-1033] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=864125735;bpid=BP-1804082424-172.17.0.6-1606980002416;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=864125735;c=1606980002416;bpid=BP-1804082424-172.17.0.6-1606980002416;dnuuid=9acfc918-b97f-4fcf-8bea-64439f1ae0ea
2020-12-03 07:20:09,003 [Thread-1118] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-12-03 07:20:09,007 [Thread-1119] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-12-03 07:20:09,009 [Thread-1118] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1804082424-172.17.0.6-1606980002416/current/replicas doesn't exist 
2020-12-03 07:20:09,009 [Thread-1119] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1804082424-172.17.0.6-1606980002416/current/replicas doesn't exist 
2020-12-03 07:20:09,010 [Thread-1119] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 0ms
2020-12-03 07:20:09,010 [Thread-1118] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 0ms
2020-12-03 07:20:09,010 [Thread-1010] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416: 72ms
2020-12-03 07:20:09,012 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-ee267448-1a4d-452b-be30-3480ab792404): no suitable block pools found to scan.  Waiting 1814396875 ms.
2020-12-03 07:20:09,012 [Thread-1010] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 8:32 AM with interval of 21600000ms
2020-12-03 07:20:09,013 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-512a29a1-592b-4a6b-9e0b-372194c82b1f): no suitable block pools found to scan.  Waiting 1814396874 ms.
2020-12-03 07:20:09,013 [Listener at localhost/41792] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:20:09,014 [Listener at localhost/41792] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:20:09,020 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1804082424-172.17.0.6-1606980002416 (Datanode Uuid e8690573-6d95-48a1-9ba7-5b1be3fa4816) service to localhost/127.0.0.1:45965 beginning handshake with NN
2020-12-03 07:20:09,020 [Thread-1125] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45965 starting to offer service
2020-12-03 07:20:09,026 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:09,027 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:09,027 [IPC Server handler 7 on default port 45965] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35680, datanodeUuid=e8690573-6d95-48a1-9ba7-5b1be3fa4816, infoPort=37819, infoSecurePort=0, ipcPort=34326, storageInfo=lv=-57;cid=testClusterID;nsid=864125735;c=1606980002416) storage e8690573-6d95-48a1-9ba7-5b1be3fa4816
2020-12-03 07:20:09,027 [Thread-1033] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-c0dee4e4-fa07-40af-b816-6f0b88fb9f12
2020-12-03 07:20:09,033 [Thread-1033] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, StorageType: DISK
2020-12-03 07:20:09,033 [Listener at localhost/41792] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:restartDataNodes(2519)) - Restarted DataNode 0
2020-12-03 07:20:09,035 [Thread-1125] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45965
2020-12-03 07:20:09,035 [Thread-1033] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-43a9d23d-614e-4a58-99ac-e73442c82f51
2020-12-03 07:20:09,033 [IPC Server handler 7 on default port 45965] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1078)) - BLOCK* registerDatanode: 127.0.0.1:42042 is replaced by DatanodeRegistration(127.0.0.1:35680, datanodeUuid=e8690573-6d95-48a1-9ba7-5b1be3fa4816, infoPort=37819, infoSecurePort=0, ipcPort=34326, storageInfo=lv=-57;cid=testClusterID;nsid=864125735;c=1606980002416) with the same storageID e8690573-6d95-48a1-9ba7-5b1be3fa4816
2020-12-03 07:20:09,039 [Thread-1033] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, StorageType: DISK
2020-12-03 07:20:09,039 [Thread-1125] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:09,039 [IPC Server handler 7 on default port 45965] INFO  net.NetworkTopology (NetworkTopology.java:remove(219)) - Removing a node: /default-rack/127.0.0.1:42042
2020-12-03 07:20:09,040 [IPC Server handler 7 on default port 45965] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:35680
2020-12-03 07:20:09,040 [Thread-1033] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:09,041 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1804082424-172.17.0.6-1606980002416 (Datanode Uuid e8690573-6d95-48a1-9ba7-5b1be3fa4816) service to localhost/127.0.0.1:45965 successfully registered with NN
2020-12-03 07:20:09,041 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:45965 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:09,041 [Thread-1033] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:20:09,045 [IPC Server handler 8 on default port 45965] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:09,045 [Thread-1033] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:20:09,045 [Thread-1033] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:20:09,045 [Thread-1033] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:20:09,046 [Thread-1033] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:09,046 [Thread-1138] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-12-03 07:20:09,046 [Thread-1139] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-12-03 07:20:09,046 [Listener at localhost/41792] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:09,047 [Listener at localhost/41792] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:09,047 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xb688b6d2de21e8b6: Processing first storage report for DS-ee267448-1a4d-452b-be30-3480ab792404 from datanode e8690573-6d95-48a1-9ba7-5b1be3fa4816
2020-12-03 07:20:09,047 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xb688b6d2de21e8b6: from storage DS-ee267448-1a4d-452b-be30-3480ab792404 node DatanodeRegistration(127.0.0.1:35680, datanodeUuid=e8690573-6d95-48a1-9ba7-5b1be3fa4816, infoPort=37819, infoSecurePort=0, ipcPort=34326, storageInfo=lv=-57;cid=testClusterID;nsid=864125735;c=1606980002416), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:09,047 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xb688b6d2de21e8b6: Processing first storage report for DS-512a29a1-592b-4a6b-9e0b-372194c82b1f from datanode e8690573-6d95-48a1-9ba7-5b1be3fa4816
2020-12-03 07:20:09,048 [Thread-1139] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1804082424-172.17.0.6-1606980002416/current: 24576
2020-12-03 07:20:09,048 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xb688b6d2de21e8b6: from storage DS-512a29a1-592b-4a6b-9e0b-372194c82b1f node DatanodeRegistration(127.0.0.1:35680, datanodeUuid=e8690573-6d95-48a1-9ba7-5b1be3fa4816, infoPort=37819, infoSecurePort=0, ipcPort=34326, storageInfo=lv=-57;cid=testClusterID;nsid=864125735;c=1606980002416), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:09,048 [Thread-1138] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1804082424-172.17.0.6-1606980002416/current: 24576
2020-12-03 07:20:09,048 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xb688b6d2de21e8b6,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:09,049 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:09,056 [Thread-1138] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1804082424-172.17.0.6-1606980002416 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 10ms
2020-12-03 07:20:09,059 [Thread-1139] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1804082424-172.17.0.6-1606980002416 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 13ms
2020-12-03 07:20:09,059 [Thread-1033] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1804082424-172.17.0.6-1606980002416: 14ms
2020-12-03 07:20:09,060 [Thread-1140] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-12-03 07:20:09,060 [Thread-1141] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-12-03 07:20:09,060 [Thread-1140] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1804082424-172.17.0.6-1606980002416/current/replicas doesn't exist 
2020-12-03 07:20:09,060 [Thread-1141] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1804082424-172.17.0.6-1606980002416/current/replicas doesn't exist 
2020-12-03 07:20:09,060 [Thread-1140] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 1ms
2020-12-03 07:20:09,060 [Thread-1141] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 1ms
2020-12-03 07:20:09,061 [Thread-1033] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416: 1ms
2020-12-03 07:20:09,061 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-43a9d23d-614e-4a58-99ac-e73442c82f51): no suitable block pools found to scan.  Waiting 1814396803 ms.
2020-12-03 07:20:09,061 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-c0dee4e4-fa07-40af-b816-6f0b88fb9f12): no suitable block pools found to scan.  Waiting 1814396804 ms.
2020-12-03 07:20:09,062 [Thread-1033] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:16 AM with interval of 21600000ms
2020-12-03 07:20:09,067 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1804082424-172.17.0.6-1606980002416 (Datanode Uuid 9acfc918-b97f-4fcf-8bea-64439f1ae0ea) service to localhost/127.0.0.1:45965 beginning handshake with NN
2020-12-03 07:20:09,068 [IPC Server handler 2 on default port 45965] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34244, datanodeUuid=9acfc918-b97f-4fcf-8bea-64439f1ae0ea, infoPort=43697, infoSecurePort=0, ipcPort=38727, storageInfo=lv=-57;cid=testClusterID;nsid=864125735;c=1606980002416) storage 9acfc918-b97f-4fcf-8bea-64439f1ae0ea
2020-12-03 07:20:09,068 [IPC Server handler 2 on default port 45965] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1078)) - BLOCK* registerDatanode: 127.0.0.1:33010 is replaced by DatanodeRegistration(127.0.0.1:34244, datanodeUuid=9acfc918-b97f-4fcf-8bea-64439f1ae0ea, infoPort=43697, infoSecurePort=0, ipcPort=38727, storageInfo=lv=-57;cid=testClusterID;nsid=864125735;c=1606980002416) with the same storageID 9acfc918-b97f-4fcf-8bea-64439f1ae0ea
2020-12-03 07:20:09,068 [IPC Server handler 2 on default port 45965] INFO  net.NetworkTopology (NetworkTopology.java:remove(219)) - Removing a node: /default-rack/127.0.0.1:33010
2020-12-03 07:20:09,068 [IPC Server handler 2 on default port 45965] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:34244
2020-12-03 07:20:09,069 [IPC Server handler 2 on default port 45965] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateFailedStorage(562)) - [DISK]DS-43a9d23d-614e-4a58-99ac-e73442c82f51:NORMAL:127.0.0.1:34244 failed.
2020-12-03 07:20:09,069 [IPC Server handler 2 on default port 45965] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateFailedStorage(562)) - [DISK]DS-c0dee4e4-fa07-40af-b816-6f0b88fb9f12:NORMAL:127.0.0.1:34244 failed.
2020-12-03 07:20:09,069 [IPC Server handler 2 on default port 45965] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:pruneStorageMap(548)) - Removed storage [DISK]DS-43a9d23d-614e-4a58-99ac-e73442c82f51:FAILED:127.0.0.1:34244 from DataNode 127.0.0.1:34244
2020-12-03 07:20:09,069 [IPC Server handler 2 on default port 45965] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:pruneStorageMap(548)) - Removed storage [DISK]DS-c0dee4e4-fa07-40af-b816-6f0b88fb9f12:FAILED:127.0.0.1:34244 from DataNode 127.0.0.1:34244
2020-12-03 07:20:09,069 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1804082424-172.17.0.6-1606980002416 (Datanode Uuid 9acfc918-b97f-4fcf-8bea-64439f1ae0ea) service to localhost/127.0.0.1:45965 successfully registered with NN
2020-12-03 07:20:09,070 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:45965 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:09,076 [IPC Server handler 4 on default port 45965] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c0dee4e4-fa07-40af-b816-6f0b88fb9f12 for DN 127.0.0.1:34244
2020-12-03 07:20:09,076 [IPC Server handler 4 on default port 45965] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-43a9d23d-614e-4a58-99ac-e73442c82f51 for DN 127.0.0.1:34244
2020-12-03 07:20:09,076 [IPC Server handler 4 on default port 45965] WARN  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:requestLease(230)) - DN 9acfc918-b97f-4fcf-8bea-64439f1ae0ea (127.0.0.1:34244) requested a lease even though it wasn't yet registered.  Registering now.
2020-12-03 07:20:09,076 [IPC Server handler 4 on default port 45965] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 9acfc918-b97f-4fcf-8bea-64439f1ae0ea (127.0.0.1:34244).
2020-12-03 07:20:09,077 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x2878c414b3189924: Processing first storage report for DS-43a9d23d-614e-4a58-99ac-e73442c82f51 from datanode 9acfc918-b97f-4fcf-8bea-64439f1ae0ea
2020-12-03 07:20:09,078 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x2878c414b3189924: from storage DS-43a9d23d-614e-4a58-99ac-e73442c82f51 node DatanodeRegistration(127.0.0.1:34244, datanodeUuid=9acfc918-b97f-4fcf-8bea-64439f1ae0ea, infoPort=43697, infoSecurePort=0, ipcPort=38727, storageInfo=lv=-57;cid=testClusterID;nsid=864125735;c=1606980002416), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:09,078 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x2878c414b3189924: Processing first storage report for DS-c0dee4e4-fa07-40af-b816-6f0b88fb9f12 from datanode 9acfc918-b97f-4fcf-8bea-64439f1ae0ea
2020-12-03 07:20:09,078 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x2878c414b3189924: from storage DS-c0dee4e4-fa07-40af-b816-6f0b88fb9f12 node DatanodeRegistration(127.0.0.1:34244, datanodeUuid=9acfc918-b97f-4fcf-8bea-64439f1ae0ea, infoPort=43697, infoSecurePort=0, ipcPort=38727, storageInfo=lv=-57;cid=testClusterID;nsid=864125735;c=1606980002416), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:09,078 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x2878c414b3189924,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:09,078 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:09,083 [Thread-1072] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:09,084 [Thread-1072] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:09,111 [Thread-1094] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 906@9ece31fe74eb
2020-12-03 07:20:09,111 [Thread-1125] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 906@9ece31fe74eb
2020-12-03 07:20:09,148 [IPC Server handler 3 on default port 45965] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:09,149 [Listener at localhost/41792] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:09,149 [Listener at localhost/41792] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:09,179 [Thread-1072] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:09,179 [Thread-1072] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:09,217 [Thread-1094] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:09,217 [Thread-1094] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:09,250 [IPC Server handler 6 on default port 45965] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:09,252 [Listener at localhost/41792] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:09,252 [Listener at localhost/41792] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:09,270 [Thread-1072] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=864125735;bpid=BP-1804082424-172.17.0.6-1606980002416;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=864125735;c=1606980002416;bpid=BP-1804082424-172.17.0.6-1606980002416;dnuuid=de098be8-3b57-427f-9f60-e85f3df9f694
2020-12-03 07:20:09,272 [Thread-1072] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-f419cf0c-b1ed-45ba-adce-834ed42a8b9d
2020-12-03 07:20:09,272 [Thread-1072] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, StorageType: DISK
2020-12-03 07:20:09,273 [Thread-1072] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-65455744-ec66-4856-99b0-9225eafc9da5
2020-12-03 07:20:09,273 [Thread-1072] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, StorageType: DISK
2020-12-03 07:20:09,273 [Thread-1072] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:09,274 [Thread-1072] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:20:09,275 [Thread-1072] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:20:09,276 [Thread-1072] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:20:09,276 [Thread-1072] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:20:09,276 [Thread-1072] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:09,276 [Thread-1147] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:20:09,276 [Thread-1148] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:20:09,278 [Thread-1148] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1804082424-172.17.0.6-1606980002416/current: 24576
2020-12-03 07:20:09,278 [Thread-1147] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1804082424-172.17.0.6-1606980002416/current: 24576
2020-12-03 07:20:09,286 [Thread-1148] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1804082424-172.17.0.6-1606980002416 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 10ms
2020-12-03 07:20:09,287 [Thread-1147] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1804082424-172.17.0.6-1606980002416 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 11ms
2020-12-03 07:20:09,287 [Thread-1072] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1804082424-172.17.0.6-1606980002416: 12ms
2020-12-03 07:20:09,288 [Thread-1149] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:20:09,288 [Thread-1150] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:20:09,288 [Thread-1149] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1804082424-172.17.0.6-1606980002416/current/replicas doesn't exist 
2020-12-03 07:20:09,288 [Thread-1150] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1804082424-172.17.0.6-1606980002416/current/replicas doesn't exist 
2020-12-03 07:20:09,288 [Thread-1149] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 1ms
2020-12-03 07:20:09,288 [Thread-1150] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 1ms
2020-12-03 07:20:09,289 [Thread-1072] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416: 1ms
2020-12-03 07:20:09,289 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-65455744-ec66-4856-99b0-9225eafc9da5): no suitable block pools found to scan.  Waiting 1814396225 ms.
2020-12-03 07:20:09,289 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-f419cf0c-b1ed-45ba-adce-834ed42a8b9d): no suitable block pools found to scan.  Waiting 1814396225 ms.
2020-12-03 07:20:09,290 [Thread-1072] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 8:45 AM with interval of 21600000ms
2020-12-03 07:20:09,295 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1804082424-172.17.0.6-1606980002416 (Datanode Uuid de098be8-3b57-427f-9f60-e85f3df9f694) service to localhost/127.0.0.1:45965 beginning handshake with NN
2020-12-03 07:20:09,296 [IPC Server handler 1 on default port 45965] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:36836, datanodeUuid=de098be8-3b57-427f-9f60-e85f3df9f694, infoPort=37274, infoSecurePort=0, ipcPort=43963, storageInfo=lv=-57;cid=testClusterID;nsid=864125735;c=1606980002416) storage de098be8-3b57-427f-9f60-e85f3df9f694
2020-12-03 07:20:09,296 [IPC Server handler 1 on default port 45965] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1078)) - BLOCK* registerDatanode: 127.0.0.1:39218 is replaced by DatanodeRegistration(127.0.0.1:36836, datanodeUuid=de098be8-3b57-427f-9f60-e85f3df9f694, infoPort=37274, infoSecurePort=0, ipcPort=43963, storageInfo=lv=-57;cid=testClusterID;nsid=864125735;c=1606980002416) with the same storageID de098be8-3b57-427f-9f60-e85f3df9f694
2020-12-03 07:20:09,297 [IPC Server handler 1 on default port 45965] INFO  net.NetworkTopology (NetworkTopology.java:remove(219)) - Removing a node: /default-rack/127.0.0.1:39218
2020-12-03 07:20:09,297 [IPC Server handler 1 on default port 45965] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36836
2020-12-03 07:20:09,297 [IPC Server handler 1 on default port 45965] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateFailedStorage(562)) - [DISK]DS-65455744-ec66-4856-99b0-9225eafc9da5:NORMAL:127.0.0.1:36836 failed.
2020-12-03 07:20:09,297 [IPC Server handler 1 on default port 45965] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateFailedStorage(562)) - [DISK]DS-f419cf0c-b1ed-45ba-adce-834ed42a8b9d:NORMAL:127.0.0.1:36836 failed.
2020-12-03 07:20:09,297 [IPC Server handler 1 on default port 45965] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:pruneStorageMap(548)) - Removed storage [DISK]DS-65455744-ec66-4856-99b0-9225eafc9da5:FAILED:127.0.0.1:36836 from DataNode 127.0.0.1:36836
2020-12-03 07:20:09,297 [IPC Server handler 1 on default port 45965] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:pruneStorageMap(548)) - Removed storage [DISK]DS-f419cf0c-b1ed-45ba-adce-834ed42a8b9d:FAILED:127.0.0.1:36836 from DataNode 127.0.0.1:36836
2020-12-03 07:20:09,298 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1804082424-172.17.0.6-1606980002416 (Datanode Uuid de098be8-3b57-427f-9f60-e85f3df9f694) service to localhost/127.0.0.1:45965 successfully registered with NN
2020-12-03 07:20:09,298 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:45965 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:09,304 [IPC Server handler 7 on default port 45965] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-f419cf0c-b1ed-45ba-adce-834ed42a8b9d for DN 127.0.0.1:36836
2020-12-03 07:20:09,304 [IPC Server handler 7 on default port 45965] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-65455744-ec66-4856-99b0-9225eafc9da5 for DN 127.0.0.1:36836
2020-12-03 07:20:09,305 [IPC Server handler 7 on default port 45965] WARN  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:requestLease(230)) - DN de098be8-3b57-427f-9f60-e85f3df9f694 (127.0.0.1:36836) requested a lease even though it wasn't yet registered.  Registering now.
2020-12-03 07:20:09,305 [IPC Server handler 7 on default port 45965] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN de098be8-3b57-427f-9f60-e85f3df9f694 (127.0.0.1:36836).
2020-12-03 07:20:09,308 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x6feec2d74d8d531d: Processing first storage report for DS-65455744-ec66-4856-99b0-9225eafc9da5 from datanode de098be8-3b57-427f-9f60-e85f3df9f694
2020-12-03 07:20:09,308 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x6feec2d74d8d531d: from storage DS-65455744-ec66-4856-99b0-9225eafc9da5 node DatanodeRegistration(127.0.0.1:36836, datanodeUuid=de098be8-3b57-427f-9f60-e85f3df9f694, infoPort=37274, infoSecurePort=0, ipcPort=43963, storageInfo=lv=-57;cid=testClusterID;nsid=864125735;c=1606980002416), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:20:09,308 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x6feec2d74d8d531d: Processing first storage report for DS-f419cf0c-b1ed-45ba-adce-834ed42a8b9d from datanode de098be8-3b57-427f-9f60-e85f3df9f694
2020-12-03 07:20:09,308 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x6feec2d74d8d531d: from storage DS-f419cf0c-b1ed-45ba-adce-834ed42a8b9d node DatanodeRegistration(127.0.0.1:36836, datanodeUuid=de098be8-3b57-427f-9f60-e85f3df9f694, infoPort=37274, infoSecurePort=0, ipcPort=43963, storageInfo=lv=-57;cid=testClusterID;nsid=864125735;c=1606980002416), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:09,309 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x6feec2d74d8d531d,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:09,309 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:09,312 [Thread-1125] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 906@9ece31fe74eb
2020-12-03 07:20:09,322 [Thread-1094] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:09,323 [Thread-1094] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:09,353 [IPC Server handler 8 on default port 45965] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:09,354 [Listener at localhost/41792] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:09,354 [Listener at localhost/41792] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:09,391 [Thread-1125] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:09,391 [Thread-1125] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:09,411 [Thread-1094] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=864125735;bpid=BP-1804082424-172.17.0.6-1606980002416;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=864125735;c=1606980002416;bpid=BP-1804082424-172.17.0.6-1606980002416;dnuuid=2ed09fef-76ca-4e59-b76b-c7e5fbb353e7
2020-12-03 07:20:09,414 [Thread-1094] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-8bb132b5-cd57-4c73-9bc1-319b35c80433
2020-12-03 07:20:09,414 [Thread-1094] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: DISK
2020-12-03 07:20:09,419 [Thread-1094] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-b474ebdb-2378-43e8-b4f8-eddd6e6af004
2020-12-03 07:20:09,419 [Thread-1094] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: DISK
2020-12-03 07:20:09,420 [Thread-1094] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:09,421 [Thread-1094] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:20:09,431 [Thread-1094] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:20:09,431 [Thread-1094] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:20:09,431 [Thread-1094] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:20:09,440 [Thread-1094] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:09,445 [Thread-1156] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:20:09,446 [Thread-1156] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1804082424-172.17.0.6-1606980002416/current: 24576
2020-12-03 07:20:09,447 [Thread-1157] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:20:09,448 [Thread-1157] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1804082424-172.17.0.6-1606980002416/current: 24576
2020-12-03 07:20:09,461 [Thread-1157] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1804082424-172.17.0.6-1606980002416 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 15ms
2020-12-03 07:20:09,464 [IPC Server handler 0 on default port 45965] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:09,466 [Listener at localhost/41792] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:09,466 [Listener at localhost/41792] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:09,468 [Thread-1156] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1804082424-172.17.0.6-1606980002416 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 22ms
2020-12-03 07:20:09,468 [Thread-1094] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1804082424-172.17.0.6-1606980002416: 27ms
2020-12-03 07:20:09,469 [Thread-1158] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:20:09,469 [Thread-1158] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1804082424-172.17.0.6-1606980002416/current/replicas doesn't exist 
2020-12-03 07:20:09,469 [Thread-1159] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:20:09,469 [Thread-1159] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1804082424-172.17.0.6-1606980002416/current/replicas doesn't exist 
2020-12-03 07:20:09,469 [Thread-1158] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 1ms
2020-12-03 07:20:09,469 [Thread-1159] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 0ms
2020-12-03 07:20:09,470 [Thread-1094] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416: 1ms
2020-12-03 07:20:09,471 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-b474ebdb-2378-43e8-b4f8-eddd6e6af004): no suitable block pools found to scan.  Waiting 1814395751 ms.
2020-12-03 07:20:09,471 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-8bb132b5-cd57-4c73-9bc1-319b35c80433): no suitable block pools found to scan.  Waiting 1814395751 ms.
2020-12-03 07:20:09,477 [Thread-1094] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 9:38 AM with interval of 21600000ms
2020-12-03 07:20:09,486 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1804082424-172.17.0.6-1606980002416 (Datanode Uuid 2ed09fef-76ca-4e59-b76b-c7e5fbb353e7) service to localhost/127.0.0.1:45965 beginning handshake with NN
2020-12-03 07:20:09,487 [IPC Server handler 2 on default port 45965] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35571, datanodeUuid=2ed09fef-76ca-4e59-b76b-c7e5fbb353e7, infoPort=36419, infoSecurePort=0, ipcPort=33709, storageInfo=lv=-57;cid=testClusterID;nsid=864125735;c=1606980002416) storage 2ed09fef-76ca-4e59-b76b-c7e5fbb353e7
2020-12-03 07:20:09,487 [IPC Server handler 2 on default port 45965] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1078)) - BLOCK* registerDatanode: 127.0.0.1:40040 is replaced by DatanodeRegistration(127.0.0.1:35571, datanodeUuid=2ed09fef-76ca-4e59-b76b-c7e5fbb353e7, infoPort=36419, infoSecurePort=0, ipcPort=33709, storageInfo=lv=-57;cid=testClusterID;nsid=864125735;c=1606980002416) with the same storageID 2ed09fef-76ca-4e59-b76b-c7e5fbb353e7
2020-12-03 07:20:09,487 [IPC Server handler 2 on default port 45965] INFO  net.NetworkTopology (NetworkTopology.java:remove(219)) - Removing a node: /default-rack/127.0.0.1:40040
2020-12-03 07:20:09,487 [IPC Server handler 2 on default port 45965] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:35571
2020-12-03 07:20:09,487 [IPC Server handler 2 on default port 45965] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateFailedStorage(562)) - [DISK]DS-b474ebdb-2378-43e8-b4f8-eddd6e6af004:NORMAL:127.0.0.1:35571 failed.
2020-12-03 07:20:09,487 [IPC Server handler 2 on default port 45965] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateFailedStorage(562)) - [DISK]DS-8bb132b5-cd57-4c73-9bc1-319b35c80433:NORMAL:127.0.0.1:35571 failed.
2020-12-03 07:20:09,487 [IPC Server handler 2 on default port 45965] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:pruneStorageMap(548)) - Removed storage [DISK]DS-b474ebdb-2378-43e8-b4f8-eddd6e6af004:FAILED:127.0.0.1:35571 from DataNode 127.0.0.1:35571
2020-12-03 07:20:09,487 [IPC Server handler 2 on default port 45965] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:pruneStorageMap(548)) - Removed storage [DISK]DS-8bb132b5-cd57-4c73-9bc1-319b35c80433:FAILED:127.0.0.1:35571 from DataNode 127.0.0.1:35571
2020-12-03 07:20:09,488 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1804082424-172.17.0.6-1606980002416 (Datanode Uuid 2ed09fef-76ca-4e59-b76b-c7e5fbb353e7) service to localhost/127.0.0.1:45965 successfully registered with NN
2020-12-03 07:20:09,488 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:45965 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:09,492 [IPC Server handler 4 on default port 45965] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-8bb132b5-cd57-4c73-9bc1-319b35c80433 for DN 127.0.0.1:35571
2020-12-03 07:20:09,492 [IPC Server handler 4 on default port 45965] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-b474ebdb-2378-43e8-b4f8-eddd6e6af004 for DN 127.0.0.1:35571
2020-12-03 07:20:09,492 [IPC Server handler 4 on default port 45965] WARN  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:requestLease(230)) - DN 2ed09fef-76ca-4e59-b76b-c7e5fbb353e7 (127.0.0.1:35571) requested a lease even though it wasn't yet registered.  Registering now.
2020-12-03 07:20:09,493 [IPC Server handler 4 on default port 45965] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 2ed09fef-76ca-4e59-b76b-c7e5fbb353e7 (127.0.0.1:35571).
2020-12-03 07:20:09,493 [Thread-1125] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:09,493 [Thread-1125] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:09,494 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x16ce388262bbdbd5: Processing first storage report for DS-b474ebdb-2378-43e8-b4f8-eddd6e6af004 from datanode 2ed09fef-76ca-4e59-b76b-c7e5fbb353e7
2020-12-03 07:20:09,494 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x16ce388262bbdbd5: from storage DS-b474ebdb-2378-43e8-b4f8-eddd6e6af004 node DatanodeRegistration(127.0.0.1:35571, datanodeUuid=2ed09fef-76ca-4e59-b76b-c7e5fbb353e7, infoPort=36419, infoSecurePort=0, ipcPort=33709, storageInfo=lv=-57;cid=testClusterID;nsid=864125735;c=1606980002416), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:09,500 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x16ce388262bbdbd5: Processing first storage report for DS-8bb132b5-cd57-4c73-9bc1-319b35c80433 from datanode 2ed09fef-76ca-4e59-b76b-c7e5fbb353e7
2020-12-03 07:20:09,500 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x16ce388262bbdbd5: from storage DS-8bb132b5-cd57-4c73-9bc1-319b35c80433 node DatanodeRegistration(127.0.0.1:35571, datanodeUuid=2ed09fef-76ca-4e59-b76b-c7e5fbb353e7, infoPort=36419, infoSecurePort=0, ipcPort=33709, storageInfo=lv=-57;cid=testClusterID;nsid=864125735;c=1606980002416), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:20:09,501 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x16ce388262bbdbd5,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 7 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:09,501 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:09,560 [Thread-1125] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=864125735;bpid=BP-1804082424-172.17.0.6-1606980002416;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=864125735;c=1606980002416;bpid=BP-1804082424-172.17.0.6-1606980002416;dnuuid=c5ae0664-cc27-4ff3-9558-7d39c9eabf00
2020-12-03 07:20:09,568 [Thread-1125] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-d45d6d51-9d05-49c1-a03f-41a2411d1148
2020-12-03 07:20:09,568 [Thread-1125] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-12-03 07:20:09,570 [IPC Server handler 3 on default port 45965] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:09,575 [Thread-1125] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-b3c09d28-5beb-480c-a8f7-27abf33879fa
2020-12-03 07:20:09,578 [Thread-1125] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-12-03 07:20:09,579 [Thread-1125] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:09,580 [Thread-1125] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:20:09,594 [Listener at localhost/41792] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:09,594 [Listener at localhost/41792] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:09,611 [Thread-1125] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:20:09,611 [Thread-1125] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:20:09,612 [Thread-1125] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:20:09,616 [Thread-1125] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:09,621 [Thread-1165] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:20:09,622 [Thread-1166] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:20:09,622 [Thread-1165] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1804082424-172.17.0.6-1606980002416/current: 24576
2020-12-03 07:20:09,622 [Thread-1166] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1804082424-172.17.0.6-1606980002416/current: 24576
2020-12-03 07:20:09,630 [Thread-1165] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1804082424-172.17.0.6-1606980002416 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 8ms
2020-12-03 07:20:09,631 [Thread-1166] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1804082424-172.17.0.6-1606980002416 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 9ms
2020-12-03 07:20:09,631 [Thread-1125] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1804082424-172.17.0.6-1606980002416: 16ms
2020-12-03 07:20:09,634 [Thread-1167] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:20:09,634 [Thread-1167] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1804082424-172.17.0.6-1606980002416/current/replicas doesn't exist 
2020-12-03 07:20:09,635 [Thread-1167] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 1ms
2020-12-03 07:20:09,638 [Thread-1168] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:20:09,638 [Thread-1168] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1804082424-172.17.0.6-1606980002416/current/replicas doesn't exist 
2020-12-03 07:20:09,639 [Thread-1168] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 0ms
2020-12-03 07:20:09,639 [Thread-1125] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1804082424-172.17.0.6-1606980002416: 7ms
2020-12-03 07:20:09,639 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-b3c09d28-5beb-480c-a8f7-27abf33879fa): no suitable block pools found to scan.  Waiting 1814394795 ms.
2020-12-03 07:20:09,640 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-d45d6d51-9d05-49c1-a03f-41a2411d1148): no suitable block pools found to scan.  Waiting 1814394794 ms.
2020-12-03 07:20:09,640 [Thread-1125] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 12:13 PM with interval of 21600000ms
2020-12-03 07:20:09,643 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1804082424-172.17.0.6-1606980002416 (Datanode Uuid c5ae0664-cc27-4ff3-9558-7d39c9eabf00) service to localhost/127.0.0.1:45965 beginning handshake with NN
2020-12-03 07:20:09,644 [IPC Server handler 6 on default port 45965] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:36292, datanodeUuid=c5ae0664-cc27-4ff3-9558-7d39c9eabf00, infoPort=38100, infoSecurePort=0, ipcPort=41792, storageInfo=lv=-57;cid=testClusterID;nsid=864125735;c=1606980002416) storage c5ae0664-cc27-4ff3-9558-7d39c9eabf00
2020-12-03 07:20:09,644 [IPC Server handler 6 on default port 45965] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1078)) - BLOCK* registerDatanode: 127.0.0.1:33969 is replaced by DatanodeRegistration(127.0.0.1:36292, datanodeUuid=c5ae0664-cc27-4ff3-9558-7d39c9eabf00, infoPort=38100, infoSecurePort=0, ipcPort=41792, storageInfo=lv=-57;cid=testClusterID;nsid=864125735;c=1606980002416) with the same storageID c5ae0664-cc27-4ff3-9558-7d39c9eabf00
2020-12-03 07:20:09,644 [IPC Server handler 6 on default port 45965] INFO  net.NetworkTopology (NetworkTopology.java:remove(219)) - Removing a node: /default-rack/127.0.0.1:33969
2020-12-03 07:20:09,645 [IPC Server handler 6 on default port 45965] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36292
2020-12-03 07:20:09,645 [IPC Server handler 6 on default port 45965] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateFailedStorage(562)) - [DISK]DS-b3c09d28-5beb-480c-a8f7-27abf33879fa:NORMAL:127.0.0.1:36292 failed.
2020-12-03 07:20:09,645 [IPC Server handler 6 on default port 45965] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateFailedStorage(562)) - [DISK]DS-d45d6d51-9d05-49c1-a03f-41a2411d1148:NORMAL:127.0.0.1:36292 failed.
2020-12-03 07:20:09,645 [IPC Server handler 6 on default port 45965] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:pruneStorageMap(548)) - Removed storage [DISK]DS-b3c09d28-5beb-480c-a8f7-27abf33879fa:FAILED:127.0.0.1:36292 from DataNode 127.0.0.1:36292
2020-12-03 07:20:09,645 [IPC Server handler 6 on default port 45965] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:pruneStorageMap(548)) - Removed storage [DISK]DS-d45d6d51-9d05-49c1-a03f-41a2411d1148:FAILED:127.0.0.1:36292 from DataNode 127.0.0.1:36292
2020-12-03 07:20:09,646 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1804082424-172.17.0.6-1606980002416 (Datanode Uuid c5ae0664-cc27-4ff3-9558-7d39c9eabf00) service to localhost/127.0.0.1:45965 successfully registered with NN
2020-12-03 07:20:09,646 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:45965 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:09,650 [IPC Server handler 1 on default port 45965] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d45d6d51-9d05-49c1-a03f-41a2411d1148 for DN 127.0.0.1:36292
2020-12-03 07:20:09,650 [IPC Server handler 1 on default port 45965] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-b3c09d28-5beb-480c-a8f7-27abf33879fa for DN 127.0.0.1:36292
2020-12-03 07:20:09,650 [IPC Server handler 1 on default port 45965] WARN  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:requestLease(230)) - DN c5ae0664-cc27-4ff3-9558-7d39c9eabf00 (127.0.0.1:36292) requested a lease even though it wasn't yet registered.  Registering now.
2020-12-03 07:20:09,650 [IPC Server handler 1 on default port 45965] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN c5ae0664-cc27-4ff3-9558-7d39c9eabf00 (127.0.0.1:36292).
2020-12-03 07:20:09,651 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x253c984735f4de26: Processing first storage report for DS-b3c09d28-5beb-480c-a8f7-27abf33879fa from datanode c5ae0664-cc27-4ff3-9558-7d39c9eabf00
2020-12-03 07:20:09,652 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x253c984735f4de26: from storage DS-b3c09d28-5beb-480c-a8f7-27abf33879fa node DatanodeRegistration(127.0.0.1:36292, datanodeUuid=c5ae0664-cc27-4ff3-9558-7d39c9eabf00, infoPort=38100, infoSecurePort=0, ipcPort=41792, storageInfo=lv=-57;cid=testClusterID;nsid=864125735;c=1606980002416), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:09,652 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x253c984735f4de26: Processing first storage report for DS-d45d6d51-9d05-49c1-a03f-41a2411d1148 from datanode c5ae0664-cc27-4ff3-9558-7d39c9eabf00
2020-12-03 07:20:09,652 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x253c984735f4de26: from storage DS-d45d6d51-9d05-49c1-a03f-41a2411d1148 node DatanodeRegistration(127.0.0.1:36292, datanodeUuid=c5ae0664-cc27-4ff3-9558-7d39c9eabf00, infoPort=38100, infoSecurePort=0, ipcPort=41792, storageInfo=lv=-57;cid=testClusterID;nsid=864125735;c=1606980002416), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:09,652 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x253c984735f4de26,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:09,652 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:09,700 [IPC Server handler 9 on default port 45965] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:09,704 [Listener at localhost/41792] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:20:09,707 [IPC Server handler 8 on default port 45965] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/f0	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:20:09,730 [IPC Server handler 0 on default port 45965] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:36836, 127.0.0.1:35680, 127.0.0.1:34244 for /f0
2020-12-03 07:20:09,733 [Thread-1172] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:09,735 [DataXceiver for client DFSClient_NONMAPREDUCE_-1078971504_1 at /127.0.0.1:34660 [Receiving block BP-1804082424-172.17.0.6-1606980002416:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1804082424-172.17.0.6-1606980002416:blk_1073741825_1001 src: /127.0.0.1:34660 dest: /127.0.0.1:36836
2020-12-03 07:20:09,737 [DataXceiver for client DFSClient_NONMAPREDUCE_-1078971504_1 at /127.0.0.1:34660 [Receiving block BP-1804082424-172.17.0.6-1606980002416:blk_1073741825_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:09,737 [DataXceiver for client DFSClient_NONMAPREDUCE_-1078971504_1 at /127.0.0.1:35026 [Receiving block BP-1804082424-172.17.0.6-1606980002416:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1804082424-172.17.0.6-1606980002416:blk_1073741825_1001 src: /127.0.0.1:35026 dest: /127.0.0.1:35680
2020-12-03 07:20:09,738 [DataXceiver for client DFSClient_NONMAPREDUCE_-1078971504_1 at /127.0.0.1:35026 [Receiving block BP-1804082424-172.17.0.6-1606980002416:blk_1073741825_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:09,739 [DataXceiver for client DFSClient_NONMAPREDUCE_-1078971504_1 at /127.0.0.1:53042 [Receiving block BP-1804082424-172.17.0.6-1606980002416:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1804082424-172.17.0.6-1606980002416:blk_1073741825_1001 src: /127.0.0.1:53042 dest: /127.0.0.1:34244
2020-12-03 07:20:09,916 [IPC Server handler 4 on default port 45965] INFO  hdfs.StateChange (FSNamesystem.java:fsync(3361)) - BLOCK* fsync: /f0 for DFSClient_NONMAPREDUCE_-1078971504_1
2020-12-03 07:20:09,919 [IPC Server handler 5 on default port 45965] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/f1	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:20:09,924 [IPC Server handler 3 on default port 45965] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741826_1002, replicas=127.0.0.1:35680, 127.0.0.1:35571, 127.0.0.1:36870 for /f1
2020-12-03 07:20:09,926 [Thread-1181] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:09,927 [DataXceiver for client DFSClient_NONMAPREDUCE_-1078971504_1 at /127.0.0.1:35030 [Receiving block BP-1804082424-172.17.0.6-1606980002416:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1804082424-172.17.0.6-1606980002416:blk_1073741826_1002 src: /127.0.0.1:35030 dest: /127.0.0.1:35680
2020-12-03 07:20:09,928 [DataXceiver for client DFSClient_NONMAPREDUCE_-1078971504_1 at /127.0.0.1:35030 [Receiving block BP-1804082424-172.17.0.6-1606980002416:blk_1073741826_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:09,930 [DataXceiver for client DFSClient_NONMAPREDUCE_-1078971504_1 at /127.0.0.1:38400 [Receiving block BP-1804082424-172.17.0.6-1606980002416:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1804082424-172.17.0.6-1606980002416:blk_1073741826_1002 src: /127.0.0.1:38400 dest: /127.0.0.1:35571
2020-12-03 07:20:09,931 [DataXceiver for client DFSClient_NONMAPREDUCE_-1078971504_1 at /127.0.0.1:38400 [Receiving block BP-1804082424-172.17.0.6-1606980002416:blk_1073741826_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:09,933 [DataXceiver for client DFSClient_NONMAPREDUCE_-1078971504_1 at /127.0.0.1:39780 [Receiving block BP-1804082424-172.17.0.6-1606980002416:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1804082424-172.17.0.6-1606980002416:blk_1073741826_1002 src: /127.0.0.1:39780 dest: /127.0.0.1:36870
2020-12-03 07:20:10,166 [IPC Server handler 6 on default port 45965] INFO  hdfs.StateChange (FSNamesystem.java:fsync(3361)) - BLOCK* fsync: /f1 for DFSClient_NONMAPREDUCE_-1078971504_1
2020-12-03 07:20:10,169 [IPC Server handler 1 on default port 45965] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/f2	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:20:10,172 [IPC Server handler 7 on default port 45965] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741827_1003, replicas=127.0.0.1:45553, 127.0.0.1:36870, 127.0.0.1:36292 for /f2
2020-12-03 07:20:10,176 [Thread-1189] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:10,182 [DataXceiver for client DFSClient_NONMAPREDUCE_-1078971504_1 at /127.0.0.1:42974 [Receiving block BP-1804082424-172.17.0.6-1606980002416:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1804082424-172.17.0.6-1606980002416:blk_1073741827_1003 src: /127.0.0.1:42974 dest: /127.0.0.1:45553
2020-12-03 07:20:10,183 [DataXceiver for client DFSClient_NONMAPREDUCE_-1078971504_1 at /127.0.0.1:42974 [Receiving block BP-1804082424-172.17.0.6-1606980002416:blk_1073741827_1003]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:10,187 [DataXceiver for client DFSClient_NONMAPREDUCE_-1078971504_1 at /127.0.0.1:39786 [Receiving block BP-1804082424-172.17.0.6-1606980002416:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1804082424-172.17.0.6-1606980002416:blk_1073741827_1003 src: /127.0.0.1:39786 dest: /127.0.0.1:36870
2020-12-03 07:20:10,189 [DataXceiver for client DFSClient_NONMAPREDUCE_-1078971504_1 at /127.0.0.1:39786 [Receiving block BP-1804082424-172.17.0.6-1606980002416:blk_1073741827_1003]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:10,193 [DataXceiver for client DFSClient_NONMAPREDUCE_-1078971504_1 at /127.0.0.1:47360 [Receiving block BP-1804082424-172.17.0.6-1606980002416:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1804082424-172.17.0.6-1606980002416:blk_1073741827_1003 src: /127.0.0.1:47360 dest: /127.0.0.1:36292
2020-12-03 07:20:10,409 [IPC Server handler 9 on default port 45965] INFO  hdfs.StateChange (FSNamesystem.java:fsync(3361)) - BLOCK* fsync: /f2 for DFSClient_NONMAPREDUCE_-1078971504_1
2020-12-03 07:20:10,412 [IPC Server handler 8 on default port 45965] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/f3	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:20:10,418 [IPC Server handler 0 on default port 45965] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741828_1004, replicas=127.0.0.1:35680, 127.0.0.1:34244, 127.0.0.1:36292 for /f3
2020-12-03 07:20:10,419 [Thread-1197] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:10,421 [DataXceiver for client DFSClient_NONMAPREDUCE_-1078971504_1 at /127.0.0.1:35044 [Receiving block BP-1804082424-172.17.0.6-1606980002416:blk_1073741828_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1804082424-172.17.0.6-1606980002416:blk_1073741828_1004 src: /127.0.0.1:35044 dest: /127.0.0.1:35680
2020-12-03 07:20:10,423 [DataXceiver for client DFSClient_NONMAPREDUCE_-1078971504_1 at /127.0.0.1:35044 [Receiving block BP-1804082424-172.17.0.6-1606980002416:blk_1073741828_1004]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:10,424 [DataXceiver for client DFSClient_NONMAPREDUCE_-1078971504_1 at /127.0.0.1:53060 [Receiving block BP-1804082424-172.17.0.6-1606980002416:blk_1073741828_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1804082424-172.17.0.6-1606980002416:blk_1073741828_1004 src: /127.0.0.1:53060 dest: /127.0.0.1:34244
2020-12-03 07:20:10,425 [DataXceiver for client DFSClient_NONMAPREDUCE_-1078971504_1 at /127.0.0.1:53060 [Receiving block BP-1804082424-172.17.0.6-1606980002416:blk_1073741828_1004]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:10,426 [DataXceiver for client DFSClient_NONMAPREDUCE_-1078971504_1 at /127.0.0.1:47366 [Receiving block BP-1804082424-172.17.0.6-1606980002416:blk_1073741828_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1804082424-172.17.0.6-1606980002416:blk_1073741828_1004 src: /127.0.0.1:47366 dest: /127.0.0.1:36292
2020-12-03 07:20:10,673 [IPC Server handler 2 on default port 45965] INFO  hdfs.StateChange (FSNamesystem.java:fsync(3361)) - BLOCK* fsync: /f3 for DFSClient_NONMAPREDUCE_-1078971504_1
2020-12-03 07:20:10,677 [IPC Server handler 4 on default port 45965] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/f4	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:20:10,684 [IPC Server handler 5 on default port 45965] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741829_1005, replicas=127.0.0.1:36836, 127.0.0.1:34244, 127.0.0.1:45553 for /f4
2020-12-03 07:20:10,687 [Thread-1205] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:10,688 [DataXceiver for client DFSClient_NONMAPREDUCE_-1078971504_1 at /127.0.0.1:34686 [Receiving block BP-1804082424-172.17.0.6-1606980002416:blk_1073741829_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1804082424-172.17.0.6-1606980002416:blk_1073741829_1005 src: /127.0.0.1:34686 dest: /127.0.0.1:36836
2020-12-03 07:20:10,689 [DataXceiver for client DFSClient_NONMAPREDUCE_-1078971504_1 at /127.0.0.1:34686 [Receiving block BP-1804082424-172.17.0.6-1606980002416:blk_1073741829_1005]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:10,690 [DataXceiver for client DFSClient_NONMAPREDUCE_-1078971504_1 at /127.0.0.1:53066 [Receiving block BP-1804082424-172.17.0.6-1606980002416:blk_1073741829_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1804082424-172.17.0.6-1606980002416:blk_1073741829_1005 src: /127.0.0.1:53066 dest: /127.0.0.1:34244
2020-12-03 07:20:10,691 [DataXceiver for client DFSClient_NONMAPREDUCE_-1078971504_1 at /127.0.0.1:53066 [Receiving block BP-1804082424-172.17.0.6-1606980002416:blk_1073741829_1005]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:10,696 [DataXceiver for client DFSClient_NONMAPREDUCE_-1078971504_1 at /127.0.0.1:42990 [Receiving block BP-1804082424-172.17.0.6-1606980002416:blk_1073741829_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1804082424-172.17.0.6-1606980002416:blk_1073741829_1005 src: /127.0.0.1:42990 dest: /127.0.0.1:45553
2020-12-03 07:20:10,857 [IPC Server handler 3 on default port 45965] INFO  hdfs.StateChange (FSNamesystem.java:fsync(3361)) - BLOCK* fsync: /f4 for DFSClient_NONMAPREDUCE_-1078971504_1
2020-12-03 07:20:11,760 [Listener at localhost/41792] INFO  blockmanagement.DatanodeAdminManager (DatanodeAdminManager.java:startDecommission(216)) - Starting decommission of 127.0.0.1:36870 [DISK]DS-1d5f4027-0413-4b3d-bce3-7989772d6afc:NORMAL:127.0.0.1:36870 with 0 blocks
2020-12-03 07:20:11,760 [Listener at localhost/41792] INFO  blockmanagement.DatanodeAdminManager (DatanodeAdminManager.java:startDecommission(216)) - Starting decommission of 127.0.0.1:36870 [DISK]DS-9430fa01-b843-4ce1-b229-c4ef32f58568:NORMAL:127.0.0.1:36870 with 0 blocks
2020-12-03 07:20:11,961 [Listener at localhost/41792] INFO  blockmanagement.DatanodeAdminManager (DatanodeAdminManager.java:startMaintenance(267)) - Starting maintenance of 127.0.0.1:45553 [DISK]DS-034e39a9-7d42-4606-aaed-1b5bf00d1e13:NORMAL:127.0.0.1:45553 with 0 blocks
2020-12-03 07:20:11,961 [Listener at localhost/41792] INFO  blockmanagement.DatanodeAdminManager (DatanodeAdminManager.java:startMaintenance(267)) - Starting maintenance of 127.0.0.1:45553 [DISK]DS-e393a8d1-0f5b-4659-b3f3-ec668d265860:NORMAL:127.0.0.1:45553 with 0 blocks
2020-12-03 07:20:12,162 [Listener at localhost/41792] INFO  blockmanagement.DatanodeAdminManager (DatanodeAdminManager.java:startDecommission(216)) - Starting decommission of 127.0.0.1:45527 [DISK]DS-2846ef14-7d0f-45aa-b4f1-52040a358f03:NORMAL:127.0.0.1:45527 with 0 blocks
2020-12-03 07:20:12,162 [Listener at localhost/41792] INFO  blockmanagement.DatanodeAdminManager (DatanodeAdminManager.java:startDecommission(216)) - Starting decommission of 127.0.0.1:45527 [DISK]DS-fde66b64-bf3d-4e52-a9d8-47e9e976c8ea:NORMAL:127.0.0.1:45527 with 0 blocks
2020-12-03 07:20:12,243 [DatanodeAdminMonitor-0] INFO  blockmanagement.DatanodeAdminManager (DatanodeAdminManager.java:setDecommissioned(332)) - Decommissioning complete for node 127.0.0.1:36870
2020-12-03 07:20:12,244 [DatanodeAdminMonitor-0] INFO  blockmanagement.DatanodeAdminManager (DatanodeAdminManager.java:setDecommissioned(332)) - Decommissioning complete for node 127.0.0.1:45527
2020-12-03 07:20:12,245 [DatanodeAdminMonitor-0] INFO  blockmanagement.DatanodeAdminManager (DatanodeAdminManager.java:setInMaintenance(337)) - Node 127.0.0.1:45553 has entered maintenance mode.
2020-12-03 07:20:12,245 [DatanodeAdminMonitor-0] INFO  blockmanagement.DatanodeAdminManager (DatanodeAdminManager.java:run(510)) - Checked 0 blocks and 3 nodes this tick
2020-12-03 07:20:12,379 [PacketResponder: BP-1804082424-172.17.0.6-1606980002416:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:53042, dest: /127.0.0.1:34244, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1078971504_1, offset: 0, srvID: 9acfc918-b97f-4fcf-8bea-64439f1ae0ea, blockid: BP-1804082424-172.17.0.6-1606980002416:blk_1073741825_1001, duration(ns): 2637103246
2020-12-03 07:20:12,380 [PacketResponder: BP-1804082424-172.17.0.6-1606980002416:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1804082424-172.17.0.6-1606980002416:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:20:12,383 [PacketResponder: BP-1804082424-172.17.0.6-1606980002416:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34244]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:35026, dest: /127.0.0.1:35680, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1078971504_1, offset: 0, srvID: e8690573-6d95-48a1-9ba7-5b1be3fa4816, blockid: BP-1804082424-172.17.0.6-1606980002416:blk_1073741825_1001, duration(ns): 2640059827
2020-12-03 07:20:12,383 [PacketResponder: BP-1804082424-172.17.0.6-1606980002416:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34244]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1804082424-172.17.0.6-1606980002416:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34244] terminating
2020-12-03 07:20:12,386 [PacketResponder: BP-1804082424-172.17.0.6-1606980002416:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:35680, 127.0.0.1:34244]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:34660, dest: /127.0.0.1:36836, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1078971504_1, offset: 0, srvID: de098be8-3b57-427f-9f60-e85f3df9f694, blockid: BP-1804082424-172.17.0.6-1606980002416:blk_1073741825_1001, duration(ns): 2638279359
2020-12-03 07:20:12,386 [PacketResponder: BP-1804082424-172.17.0.6-1606980002416:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:35680, 127.0.0.1:34244]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1804082424-172.17.0.6-1606980002416:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:35680, 127.0.0.1:34244] terminating
2020-12-03 07:20:12,391 [IPC Server handler 8 on default port 45965] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /f0 is closed by DFSClient_NONMAPREDUCE_-1078971504_1
2020-12-03 07:20:13,313 [PacketResponder: BP-1804082424-172.17.0.6-1606980002416:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39780, dest: /127.0.0.1:36870, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1078971504_1, offset: 0, srvID: 29c10e8f-bd24-491d-a369-fc3d4333f678, blockid: BP-1804082424-172.17.0.6-1606980002416:blk_1073741826_1002, duration(ns): 3376005771
2020-12-03 07:20:13,313 [PacketResponder: BP-1804082424-172.17.0.6-1606980002416:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1804082424-172.17.0.6-1606980002416:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2020-12-03 07:20:13,320 [PacketResponder: BP-1804082424-172.17.0.6-1606980002416:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:36870]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38400, dest: /127.0.0.1:35571, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1078971504_1, offset: 0, srvID: 2ed09fef-76ca-4e59-b76b-c7e5fbb353e7, blockid: BP-1804082424-172.17.0.6-1606980002416:blk_1073741826_1002, duration(ns): 3378319904
2020-12-03 07:20:13,321 [PacketResponder: BP-1804082424-172.17.0.6-1606980002416:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:36870]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1804082424-172.17.0.6-1606980002416:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:36870] terminating
2020-12-03 07:20:13,322 [PacketResponder: BP-1804082424-172.17.0.6-1606980002416:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:35571, 127.0.0.1:36870]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:35030, dest: /127.0.0.1:35680, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1078971504_1, offset: 0, srvID: e8690573-6d95-48a1-9ba7-5b1be3fa4816, blockid: BP-1804082424-172.17.0.6-1606980002416:blk_1073741826_1002, duration(ns): 3385903451
2020-12-03 07:20:13,323 [PacketResponder: BP-1804082424-172.17.0.6-1606980002416:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:35571, 127.0.0.1:36870]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1804082424-172.17.0.6-1606980002416:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:35571, 127.0.0.1:36870] terminating
2020-12-03 07:20:13,325 [IPC Server handler 8 on default port 45965] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2995)) - BLOCK* blk_1073741826_1002 is COMMITTED but not COMPLETE(numNodes= 1 >=  minimum = 1) in file /f1
2020-12-03 07:20:13,728 [IPC Server handler 3 on default port 45965] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /f1 is closed by DFSClient_NONMAPREDUCE_-1078971504_1
2020-12-03 07:20:14,636 [PacketResponder: BP-1804082424-172.17.0.6-1606980002416:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:47360, dest: /127.0.0.1:36292, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1078971504_1, offset: 0, srvID: c5ae0664-cc27-4ff3-9558-7d39c9eabf00, blockid: BP-1804082424-172.17.0.6-1606980002416:blk_1073741827_1003, duration(ns): 4435895659
2020-12-03 07:20:14,636 [PacketResponder: BP-1804082424-172.17.0.6-1606980002416:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1804082424-172.17.0.6-1606980002416:blk_1073741827_1003, type=LAST_IN_PIPELINE terminating
2020-12-03 07:20:14,638 [PacketResponder: BP-1804082424-172.17.0.6-1606980002416:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:36292]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39786, dest: /127.0.0.1:36870, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1078971504_1, offset: 0, srvID: 29c10e8f-bd24-491d-a369-fc3d4333f678, blockid: BP-1804082424-172.17.0.6-1606980002416:blk_1073741827_1003, duration(ns): 4437214824
2020-12-03 07:20:14,638 [PacketResponder: BP-1804082424-172.17.0.6-1606980002416:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:36292]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1804082424-172.17.0.6-1606980002416:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:36292] terminating
2020-12-03 07:20:14,639 [PacketResponder: BP-1804082424-172.17.0.6-1606980002416:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:36870, 127.0.0.1:36292]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:42974, dest: /127.0.0.1:45553, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1078971504_1, offset: 0, srvID: b038b1a4-65c2-42df-90ed-7eefd1a46770, blockid: BP-1804082424-172.17.0.6-1606980002416:blk_1073741827_1003, duration(ns): 4438296096
2020-12-03 07:20:14,640 [PacketResponder: BP-1804082424-172.17.0.6-1606980002416:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:36870, 127.0.0.1:36292]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1804082424-172.17.0.6-1606980002416:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:36870, 127.0.0.1:36292] terminating
2020-12-03 07:20:14,641 [IPC Server handler 7 on default port 45965] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /f2 is closed by DFSClient_NONMAPREDUCE_-1078971504_1
2020-12-03 07:20:15,240 [DatanodeAdminMonitor-0] INFO  blockmanagement.DatanodeAdminManager (DatanodeAdminManager.java:run(510)) - Checked 0 blocks and 1 nodes this tick
2020-12-03 07:20:15,251 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (DataNode.java:transferBlock(2358)) - DatanodeRegistration(127.0.0.1:35571, datanodeUuid=2ed09fef-76ca-4e59-b76b-c7e5fbb353e7, infoPort=36419, infoSecurePort=0, ipcPort=33709, storageInfo=lv=-57;cid=testClusterID;nsid=864125735;c=1606980002416) Starting thread to transfer BP-1804082424-172.17.0.6-1606980002416:blk_1073741826_1002 to 127.0.0.1:34244 
2020-12-03 07:20:15,252 [org.apache.hadoop.hdfs.server.datanode.DataNode$DataTransfer@3b4a2c22] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:15,253 [DataXceiver for client  at /127.0.0.1:53082 [Receiving block BP-1804082424-172.17.0.6-1606980002416:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1804082424-172.17.0.6-1606980002416:blk_1073741826_1002 src: /127.0.0.1:53082 dest: /127.0.0.1:34244
2020-12-03 07:20:15,254 [org.apache.hadoop.hdfs.server.datanode.DataNode$DataTransfer@3b4a2c22] INFO  datanode.DataNode (DataNode.java:run(2571)) - DataTransfer, at 127.0.0.1:35571: Transmitted BP-1804082424-172.17.0.6-1606980002416:blk_1073741826_1002 (numBytes=1) to /127.0.0.1:34244
2020-12-03 07:20:15,256 [DataXceiver for client  at /127.0.0.1:53082 [Receiving block BP-1804082424-172.17.0.6-1606980002416:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(931)) - Received BP-1804082424-172.17.0.6-1606980002416:blk_1073741826_1002 src: /127.0.0.1:53082 dest: /127.0.0.1:34244 of size 1
2020-12-03 07:20:15,350 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (DataNode.java:transferBlock(2358)) - DatanodeRegistration(127.0.0.1:36292, datanodeUuid=c5ae0664-cc27-4ff3-9558-7d39c9eabf00, infoPort=38100, infoSecurePort=0, ipcPort=41792, storageInfo=lv=-57;cid=testClusterID;nsid=864125735;c=1606980002416) Starting thread to transfer BP-1804082424-172.17.0.6-1606980002416:blk_1073741827_1003 to 127.0.0.1:34244 
2020-12-03 07:20:15,351 [org.apache.hadoop.hdfs.server.datanode.DataNode$DataTransfer@1ba9a45a] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:15,353 [DataXceiver for client  at /127.0.0.1:53084 [Receiving block BP-1804082424-172.17.0.6-1606980002416:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1804082424-172.17.0.6-1606980002416:blk_1073741827_1003 src: /127.0.0.1:53084 dest: /127.0.0.1:34244
2020-12-03 07:20:15,353 [org.apache.hadoop.hdfs.server.datanode.DataNode$DataTransfer@1ba9a45a] INFO  datanode.DataNode (DataNode.java:run(2571)) - DataTransfer, at 127.0.0.1:36292: Transmitted BP-1804082424-172.17.0.6-1606980002416:blk_1073741827_1003 (numBytes=1) to /127.0.0.1:34244
2020-12-03 07:20:15,354 [DataXceiver for client  at /127.0.0.1:53084 [Receiving block BP-1804082424-172.17.0.6-1606980002416:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(931)) - Received BP-1804082424-172.17.0.6-1606980002416:blk_1073741827_1003 src: /127.0.0.1:53084 dest: /127.0.0.1:34244 of size 1
2020-12-03 07:20:15,554 [PacketResponder: BP-1804082424-172.17.0.6-1606980002416:blk_1073741828_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:47366, dest: /127.0.0.1:36292, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1078971504_1, offset: 0, srvID: c5ae0664-cc27-4ff3-9558-7d39c9eabf00, blockid: BP-1804082424-172.17.0.6-1606980002416:blk_1073741828_1004, duration(ns): 5124684167
2020-12-03 07:20:15,554 [PacketResponder: BP-1804082424-172.17.0.6-1606980002416:blk_1073741828_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1804082424-172.17.0.6-1606980002416:blk_1073741828_1004, type=LAST_IN_PIPELINE terminating
2020-12-03 07:20:15,555 [PacketResponder: BP-1804082424-172.17.0.6-1606980002416:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:36292]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:53060, dest: /127.0.0.1:34244, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1078971504_1, offset: 0, srvID: 9acfc918-b97f-4fcf-8bea-64439f1ae0ea, blockid: BP-1804082424-172.17.0.6-1606980002416:blk_1073741828_1004, duration(ns): 5128280500
2020-12-03 07:20:15,556 [PacketResponder: BP-1804082424-172.17.0.6-1606980002416:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:36292]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1804082424-172.17.0.6-1606980002416:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:36292] terminating
2020-12-03 07:20:15,556 [PacketResponder: BP-1804082424-172.17.0.6-1606980002416:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34244, 127.0.0.1:36292]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:35044, dest: /127.0.0.1:35680, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1078971504_1, offset: 0, srvID: e8690573-6d95-48a1-9ba7-5b1be3fa4816, blockid: BP-1804082424-172.17.0.6-1606980002416:blk_1073741828_1004, duration(ns): 5127602910
2020-12-03 07:20:15,557 [PacketResponder: BP-1804082424-172.17.0.6-1606980002416:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34244, 127.0.0.1:36292]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1804082424-172.17.0.6-1606980002416:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34244, 127.0.0.1:36292] terminating
2020-12-03 07:20:15,559 [IPC Server handler 2 on default port 45965] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /f3 is closed by DFSClient_NONMAPREDUCE_-1078971504_1
2020-12-03 07:20:16,471 [PacketResponder: BP-1804082424-172.17.0.6-1606980002416:blk_1073741829_1005, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:42990, dest: /127.0.0.1:45553, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1078971504_1, offset: 0, srvID: b038b1a4-65c2-42df-90ed-7eefd1a46770, blockid: BP-1804082424-172.17.0.6-1606980002416:blk_1073741829_1005, duration(ns): 5771319463
2020-12-03 07:20:16,471 [PacketResponder: BP-1804082424-172.17.0.6-1606980002416:blk_1073741829_1005, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1804082424-172.17.0.6-1606980002416:blk_1073741829_1005, type=LAST_IN_PIPELINE terminating
2020-12-03 07:20:16,472 [PacketResponder: BP-1804082424-172.17.0.6-1606980002416:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:45553]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:53066, dest: /127.0.0.1:34244, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1078971504_1, offset: 0, srvID: 9acfc918-b97f-4fcf-8bea-64439f1ae0ea, blockid: BP-1804082424-172.17.0.6-1606980002416:blk_1073741829_1005, duration(ns): 5774670016
2020-12-03 07:20:16,472 [PacketResponder: BP-1804082424-172.17.0.6-1606980002416:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:45553]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1804082424-172.17.0.6-1606980002416:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:45553] terminating
2020-12-03 07:20:16,473 [PacketResponder: BP-1804082424-172.17.0.6-1606980002416:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34244, 127.0.0.1:45553]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:34686, dest: /127.0.0.1:36836, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1078971504_1, offset: 0, srvID: de098be8-3b57-427f-9f60-e85f3df9f694, blockid: BP-1804082424-172.17.0.6-1606980002416:blk_1073741829_1005, duration(ns): 5773884359
2020-12-03 07:20:16,474 [PacketResponder: BP-1804082424-172.17.0.6-1606980002416:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34244, 127.0.0.1:45553]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1804082424-172.17.0.6-1606980002416:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34244, 127.0.0.1:45553] terminating
2020-12-03 07:20:16,476 [IPC Server handler 5 on default port 45965] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /f4 is closed by DFSClient_NONMAPREDUCE_-1078971504_1
2020-12-03 07:20:17,387 [Listener at localhost/41792] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:17,389 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-1d5f4027-0413-4b3d-bce3-7989772d6afc) exiting.
2020-12-03 07:20:17,390 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-9430fa01-b843-4ce1-b229-c4ef32f58568) exiting.
2020-12-03 07:20:17,387 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@76f856a8] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:17,435 [Listener at localhost/41792] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@36361ddb{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:17,440 [Listener at localhost/41792] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@41fed14f{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:17,452 [Listener at localhost/41792] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@409986fe{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:17,464 [Listener at localhost/41792] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3491e86e{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:17,473 [Listener at localhost/41792] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 42318
2020-12-03 07:20:17,475 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:17,477 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:17,478 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:17,478 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1804082424-172.17.0.6-1606980002416 (Datanode Uuid 29c10e8f-bd24-491d-a369-fc3d4333f678) service to localhost/127.0.0.1:45965
2020-12-03 07:20:17,478 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1804082424-172.17.0.6-1606980002416 (Datanode Uuid 29c10e8f-bd24-491d-a369-fc3d4333f678)
2020-12-03 07:20:17,479 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:17,480 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1804082424-172.17.0.6-1606980002416] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:17,482 [Listener at localhost/41792] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:17,482 [Listener at localhost/41792] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:17,484 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1804082424-172.17.0.6-1606980002416] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:17,484 [Listener at localhost/41792] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:17,484 [Listener at localhost/41792] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:17,492 [Listener at localhost/41792] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:17,493 [Listener at localhost/41792] INFO  hdfs.StateChange (DatanodeManager.java:removeDeadDatanode(754)) - BLOCK* removeDeadDatanode: lost heartbeat from 127.0.0.1:36870, removeBlocksFromBlockMap true
2020-12-03 07:20:17,493 [Listener at localhost/41792] INFO  net.NetworkTopology (NetworkTopology.java:remove(219)) - Removing a node: /default-rack/127.0.0.1:36870
2020-12-03 07:20:17,494 [Listener at localhost/41792] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:17,494 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@5ff90645] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:17,505 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-e393a8d1-0f5b-4659-b3f3-ec668d265860) exiting.
2020-12-03 07:20:17,505 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-034e39a9-7d42-4606-aaed-1b5bf00d1e13) exiting.
2020-12-03 07:20:17,583 [Listener at localhost/41792] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6dd82486{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:17,596 [Listener at localhost/41792] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@56078cea{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:17,597 [Listener at localhost/41792] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@64fc097e{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:17,600 [Listener at localhost/41792] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5533dc72{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:17,604 [Listener at localhost/41792] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 35874
2020-12-03 07:20:17,616 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:17,632 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:17,635 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:17,635 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1804082424-172.17.0.6-1606980002416 (Datanode Uuid b038b1a4-65c2-42df-90ed-7eefd1a46770) service to localhost/127.0.0.1:45965
2020-12-03 07:20:17,635 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1804082424-172.17.0.6-1606980002416 (Datanode Uuid b038b1a4-65c2-42df-90ed-7eefd1a46770)
2020-12-03 07:20:17,636 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:17,639 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1804082424-172.17.0.6-1606980002416] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:17,640 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1804082424-172.17.0.6-1606980002416] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:17,647 [Listener at localhost/41792] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:17,648 [Listener at localhost/41792] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:17,659 [Listener at localhost/41792] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:17,660 [Listener at localhost/41792] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:17,725 [Listener at localhost/41792] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:17,726 [Listener at localhost/41792] INFO  hdfs.StateChange (DatanodeManager.java:removeDeadDatanode(754)) - BLOCK* removeDeadDatanode: lost heartbeat from 127.0.0.1:45553, removeBlocksFromBlockMap false
2020-12-03 07:20:17,726 [Listener at localhost/41792] INFO  net.NetworkTopology (NetworkTopology.java:remove(219)) - Removing a node: /default-rack/127.0.0.1:45553
2020-12-03 07:20:17,726 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@38320e34] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:17,727 [Listener at localhost/41792] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:17,729 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-2846ef14-7d0f-45aa-b4f1-52040a358f03) exiting.
2020-12-03 07:20:17,729 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-fde66b64-bf3d-4e52-a9d8-47e9e976c8ea) exiting.
2020-12-03 07:20:17,784 [Listener at localhost/41792] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@7afbf561{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:17,785 [Listener at localhost/41792] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2f98635e{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:17,785 [Listener at localhost/41792] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4bbb49b0{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:17,786 [Listener at localhost/41792] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7c29adc8{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:17,787 [Listener at localhost/41792] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 41780
2020-12-03 07:20:17,793 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:17,794 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:17,794 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:17,794 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1804082424-172.17.0.6-1606980002416 (Datanode Uuid 2df0ed89-2351-4d4d-8341-dd4497968a1f) service to localhost/127.0.0.1:45965
2020-12-03 07:20:17,794 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1804082424-172.17.0.6-1606980002416 (Datanode Uuid 2df0ed89-2351-4d4d-8341-dd4497968a1f)
2020-12-03 07:20:17,794 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:17,801 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1804082424-172.17.0.6-1606980002416] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:17,805 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1804082424-172.17.0.6-1606980002416] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:17,807 [Listener at localhost/41792] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:17,807 [Listener at localhost/41792] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:17,826 [Listener at localhost/41792] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:17,827 [Listener at localhost/41792] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:17,828 [Listener at localhost/41792] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:17,829 [Listener at localhost/41792] INFO  hdfs.StateChange (DatanodeManager.java:removeDeadDatanode(754)) - BLOCK* removeDeadDatanode: lost heartbeat from 127.0.0.1:45527, removeBlocksFromBlockMap true
2020-12-03 07:20:17,829 [Listener at localhost/41792] INFO  net.NetworkTopology (NetworkTopology.java:remove(219)) - Removing a node: /default-rack/127.0.0.1:45527
2020-12-03 07:20:17,830 [Listener at localhost/41792] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:17,830 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@3ffb3598] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:17,832 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-512a29a1-592b-4a6b-9e0b-372194c82b1f) exiting.
2020-12-03 07:20:17,832 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-ee267448-1a4d-452b-be30-3480ab792404) exiting.
2020-12-03 07:20:17,865 [Listener at localhost/41792] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@756b58a7{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:17,871 [Listener at localhost/41792] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2cc04358{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:17,872 [Listener at localhost/41792] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6ec65b5e{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:17,872 [Listener at localhost/41792] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7b78ed6a{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:17,885 [Listener at localhost/41792] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 34326
2020-12-03 07:20:17,885 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:17,890 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:17,890 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:17,890 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1804082424-172.17.0.6-1606980002416 (Datanode Uuid e8690573-6d95-48a1-9ba7-5b1be3fa4816) service to localhost/127.0.0.1:45965
2020-12-03 07:20:17,891 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1804082424-172.17.0.6-1606980002416 (Datanode Uuid e8690573-6d95-48a1-9ba7-5b1be3fa4816)
2020-12-03 07:20:17,891 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:17,892 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1804082424-172.17.0.6-1606980002416] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:17,897 [Listener at localhost/41792] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:17,897 [Listener at localhost/41792] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:17,897 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1804082424-172.17.0.6-1606980002416] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:17,899 [Listener at localhost/41792] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:17,900 [Listener at localhost/41792] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:17,900 [Listener at localhost/41792] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:17,901 [Listener at localhost/41792] INFO  hdfs.StateChange (DatanodeManager.java:removeDeadDatanode(754)) - BLOCK* removeDeadDatanode: lost heartbeat from 127.0.0.1:35680, removeBlocksFromBlockMap true
2020-12-03 07:20:17,901 [Listener at localhost/41792] INFO  net.NetworkTopology (NetworkTopology.java:remove(219)) - Removing a node: /default-rack/127.0.0.1:35680
2020-12-03 07:20:17,902 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@3d7b1f1c] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:17,903 [Listener at localhost/41792] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:17,906 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-43a9d23d-614e-4a58-99ac-e73442c82f51) exiting.
2020-12-03 07:20:17,906 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-c0dee4e4-fa07-40af-b816-6f0b88fb9f12) exiting.
2020-12-03 07:20:17,963 [Listener at localhost/41792] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1ff55ff{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:17,964 [Listener at localhost/41792] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@351f2244{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:17,964 [Listener at localhost/41792] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5b275174{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:17,970 [Listener at localhost/41792] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7ed9499e{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:18,001 [Listener at localhost/41792] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 38727
2020-12-03 07:20:18,002 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:18,002 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:18,007 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:18,007 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1804082424-172.17.0.6-1606980002416 (Datanode Uuid 9acfc918-b97f-4fcf-8bea-64439f1ae0ea) service to localhost/127.0.0.1:45965
2020-12-03 07:20:18,007 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1804082424-172.17.0.6-1606980002416 (Datanode Uuid 9acfc918-b97f-4fcf-8bea-64439f1ae0ea)
2020-12-03 07:20:18,008 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:18,010 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1804082424-172.17.0.6-1606980002416] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:18,010 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1804082424-172.17.0.6-1606980002416] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:18,020 [Listener at localhost/41792] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:18,020 [Listener at localhost/41792] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:18,024 [Listener at localhost/41792] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:18,025 [Listener at localhost/41792] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:18,025 [Listener at localhost/41792] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-12-03 07:20:18,028 [Listener at localhost/41792] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-12-03 07:20:18,028 [Listener at localhost/41792] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-12-03 07:20:18,029 [Listener at localhost/41792] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:18,029 [Listener at localhost/41792] INFO  hdfs.StateChange (DatanodeManager.java:removeDeadDatanode(754)) - BLOCK* removeDeadDatanode: lost heartbeat from 127.0.0.1:34244, removeBlocksFromBlockMap true
2020-12-03 07:20:18,030 [Listener at localhost/41792] INFO  net.NetworkTopology (NetworkTopology.java:remove(219)) - Removing a node: /default-rack/127.0.0.1:34244
2020-12-03 07:20:18,031 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@1416a80a] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:18,031 [Listener at localhost/41792] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:18,036 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-65455744-ec66-4856-99b0-9225eafc9da5) exiting.
2020-12-03 07:20:18,044 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-f419cf0c-b1ed-45ba-adce-834ed42a8b9d) exiting.
2020-12-03 07:20:18,114 [Listener at localhost/41792] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1c6c6f24{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:18,122 [Listener at localhost/41792] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2eb917d0{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:18,123 [Listener at localhost/41792] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@572e6fd9{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:18,124 [Listener at localhost/41792] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2b5183ec{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:18,138 [Listener at localhost/41792] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 43963
2020-12-03 07:20:18,146 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:18,163 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:18,163 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:18,163 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1804082424-172.17.0.6-1606980002416 (Datanode Uuid de098be8-3b57-427f-9f60-e85f3df9f694) service to localhost/127.0.0.1:45965
2020-12-03 07:20:18,164 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1804082424-172.17.0.6-1606980002416 (Datanode Uuid de098be8-3b57-427f-9f60-e85f3df9f694)
2020-12-03 07:20:18,164 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:18,166 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1804082424-172.17.0.6-1606980002416] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:18,171 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1804082424-172.17.0.6-1606980002416] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:18,172 [Listener at localhost/41792] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:18,173 [Listener at localhost/41792] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:18,177 [Listener at localhost/41792] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:18,177 [Listener at localhost/41792] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:18,180 [Listener at localhost/41792] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:18,180 [Listener at localhost/41792] INFO  hdfs.StateChange (DatanodeManager.java:removeDeadDatanode(754)) - BLOCK* removeDeadDatanode: lost heartbeat from 127.0.0.1:36836, removeBlocksFromBlockMap true
2020-12-03 07:20:18,181 [Listener at localhost/41792] INFO  net.NetworkTopology (NetworkTopology.java:remove(219)) - Removing a node: /default-rack/127.0.0.1:36836
2020-12-03 07:20:18,182 [Listener at localhost/41792] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:18,182 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@aa149ed] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:18,187 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-b474ebdb-2378-43e8-b4f8-eddd6e6af004) exiting.
2020-12-03 07:20:18,187 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-8bb132b5-cd57-4c73-9bc1-319b35c80433) exiting.
2020-12-03 07:20:18,240 [Listener at localhost/41792] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@46731692{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:18,240 [DatanodeAdminMonitor-0] INFO  blockmanagement.DatanodeAdminManager (DatanodeAdminManager.java:run(510)) - Checked 0 blocks and 1 nodes this tick
2020-12-03 07:20:18,241 [Listener at localhost/41792] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@782bf610{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:18,242 [Listener at localhost/41792] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4dc8c0ea{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:18,242 [Listener at localhost/41792] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@8ee0c23{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:18,244 [Listener at localhost/41792] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 33709
2020-12-03 07:20:18,245 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:18,245 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:18,245 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:18,265 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1804082424-172.17.0.6-1606980002416 (Datanode Uuid 2ed09fef-76ca-4e59-b76b-c7e5fbb353e7) service to localhost/127.0.0.1:45965
2020-12-03 07:20:18,265 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1804082424-172.17.0.6-1606980002416 (Datanode Uuid 2ed09fef-76ca-4e59-b76b-c7e5fbb353e7)
2020-12-03 07:20:18,265 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:18,267 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1804082424-172.17.0.6-1606980002416] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:18,279 [Listener at localhost/41792] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:18,279 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1804082424-172.17.0.6-1606980002416] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:18,279 [Listener at localhost/41792] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:18,284 [Listener at localhost/41792] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:18,285 [Listener at localhost/41792] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:18,285 [Listener at localhost/41792] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:18,285 [Listener at localhost/41792] INFO  hdfs.StateChange (DatanodeManager.java:removeDeadDatanode(754)) - BLOCK* removeDeadDatanode: lost heartbeat from 127.0.0.1:35571, removeBlocksFromBlockMap true
2020-12-03 07:20:18,286 [Listener at localhost/41792] INFO  net.NetworkTopology (NetworkTopology.java:remove(219)) - Removing a node: /default-rack/127.0.0.1:35571
2020-12-03 07:20:18,286 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@3abfe845] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:18,287 [Listener at localhost/41792] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:18,294 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-b3c09d28-5beb-480c-a8f7-27abf33879fa) exiting.
2020-12-03 07:20:18,295 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-d45d6d51-9d05-49c1-a03f-41a2411d1148) exiting.
2020-12-03 07:20:18,315 [Listener at localhost/41792] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@3964d79{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:18,327 [Listener at localhost/41792] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@62db0521{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:18,340 [Listener at localhost/41792] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@54657dd2{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:18,352 [Listener at localhost/41792] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@24b4d544{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:18,392 [Listener at localhost/41792] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 41792
2020-12-03 07:20:18,394 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:18,401 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:18,403 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:18,403 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1804082424-172.17.0.6-1606980002416 (Datanode Uuid c5ae0664-cc27-4ff3-9558-7d39c9eabf00) service to localhost/127.0.0.1:45965
2020-12-03 07:20:18,403 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1804082424-172.17.0.6-1606980002416 (Datanode Uuid c5ae0664-cc27-4ff3-9558-7d39c9eabf00)
2020-12-03 07:20:18,404 [BP-1804082424-172.17.0.6-1606980002416 heartbeating to localhost/127.0.0.1:45965] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1804082424-172.17.0.6-1606980002416
2020-12-03 07:20:18,405 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1804082424-172.17.0.6-1606980002416] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:18,411 [Listener at localhost/41792] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:18,411 [Listener at localhost/41792] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:18,417 [Listener at localhost/41792] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:18,418 [Listener at localhost/41792] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:18,418 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1804082424-172.17.0.6-1606980002416] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:18,419 [Listener at localhost/41792] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:18,419 [Listener at localhost/41792] INFO  hdfs.StateChange (DatanodeManager.java:removeDeadDatanode(754)) - BLOCK* removeDeadDatanode: lost heartbeat from 127.0.0.1:36292, removeBlocksFromBlockMap true
2020-12-03 07:20:18,420 [Listener at localhost/41792] INFO  net.NetworkTopology (NetworkTopology.java:remove(219)) - Removing a node: /default-rack/127.0.0.1:36292
2020-12-03 07:20:18,420 [Listener at localhost/41792] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:20:18,522 [Listener at localhost/41792] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 7
2020-12-03 07:20:18,523 [Listener at localhost/41792] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(341)) - DirectoryScanner: shutdown has been called, but periodic scanner not started
2020-12-03 07:20:18,524 [Listener at localhost/41792] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 41792
2020-12-03 07:20:18,524 [Listener at localhost/41792] WARN  util.MBeans (MBeans.java:unregister(145)) - Error unregistering Hadoop:service=DataNode,name=FSDatasetState-c5ae0664-cc27-4ff3-9558-7d39c9eabf00
javax.management.InstanceNotFoundException: Hadoop:service=DataNode,name=FSDatasetState-c5ae0664-cc27-4ff3-9558-7d39c9eabf00
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getMBean(DefaultMBeanServerInterceptor.java:1095)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.exclusiveUnregisterMBean(DefaultMBeanServerInterceptor.java:427)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.unregisterMBean(DefaultMBeanServerInterceptor.java:415)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.unregisterMBean(JmxMBeanServer.java:546)
	at org.apache.hadoop.metrics2.util.MBeans.unregister(MBeans.java:143)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.shutdown(FsDatasetImpl.java:2293)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.shutdown(DataNode.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdownDataNode(MiniDFSCluster.java:2099)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdownDataNodes(MiniDFSCluster.java:2089)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2068)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2042)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2035)
	at org.apache.hadoop.hdfs.server.namenode.TestNamenodeCapacityReport.testXceiverCountInternal(TestNamenodeCapacityReport.java:345)
	at org.apache.hadoop.hdfs.server.namenode.TestNamenodeCapacityReport.testXceiverCount(TestNamenodeCapacityReport.java:200)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2020-12-03 07:20:18,526 [Listener at localhost/41792] WARN  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(191)) - AsyncDiskService has already shut down.
2020-12-03 07:20:18,526 [Listener at localhost/41792] WARN  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(175)) - AsyncLazyPersistService has already shut down.
2020-12-03 07:20:18,526 [Listener at localhost/41792] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:18,527 [Listener at localhost/41792] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 6
2020-12-03 07:20:18,527 [Listener at localhost/41792] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(341)) - DirectoryScanner: shutdown has been called, but periodic scanner not started
2020-12-03 07:20:18,530 [Listener at localhost/41792] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 33709
2020-12-03 07:20:18,530 [Listener at localhost/41792] WARN  util.MBeans (MBeans.java:unregister(145)) - Error unregistering Hadoop:service=DataNode,name=FSDatasetState-2ed09fef-76ca-4e59-b76b-c7e5fbb353e7
javax.management.InstanceNotFoundException: Hadoop:service=DataNode,name=FSDatasetState-2ed09fef-76ca-4e59-b76b-c7e5fbb353e7
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getMBean(DefaultMBeanServerInterceptor.java:1095)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.exclusiveUnregisterMBean(DefaultMBeanServerInterceptor.java:427)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.unregisterMBean(DefaultMBeanServerInterceptor.java:415)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.unregisterMBean(JmxMBeanServer.java:546)
	at org.apache.hadoop.metrics2.util.MBeans.unregister(MBeans.java:143)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.shutdown(FsDatasetImpl.java:2293)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.shutdown(DataNode.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdownDataNode(MiniDFSCluster.java:2099)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdownDataNodes(MiniDFSCluster.java:2089)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2068)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2042)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2035)
	at org.apache.hadoop.hdfs.server.namenode.TestNamenodeCapacityReport.testXceiverCountInternal(TestNamenodeCapacityReport.java:345)
	at org.apache.hadoop.hdfs.server.namenode.TestNamenodeCapacityReport.testXceiverCount(TestNamenodeCapacityReport.java:200)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2020-12-03 07:20:18,531 [Listener at localhost/41792] WARN  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(191)) - AsyncDiskService has already shut down.
2020-12-03 07:20:18,531 [Listener at localhost/41792] WARN  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(175)) - AsyncLazyPersistService has already shut down.
2020-12-03 07:20:18,531 [Listener at localhost/41792] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:18,532 [Listener at localhost/41792] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 5
2020-12-03 07:20:18,532 [Listener at localhost/41792] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(341)) - DirectoryScanner: shutdown has been called, but periodic scanner not started
2020-12-03 07:20:18,532 [Listener at localhost/41792] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 43963
2020-12-03 07:20:18,533 [Listener at localhost/41792] WARN  util.MBeans (MBeans.java:unregister(145)) - Error unregistering Hadoop:service=DataNode,name=FSDatasetState-de098be8-3b57-427f-9f60-e85f3df9f694
javax.management.InstanceNotFoundException: Hadoop:service=DataNode,name=FSDatasetState-de098be8-3b57-427f-9f60-e85f3df9f694
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getMBean(DefaultMBeanServerInterceptor.java:1095)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.exclusiveUnregisterMBean(DefaultMBeanServerInterceptor.java:427)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.unregisterMBean(DefaultMBeanServerInterceptor.java:415)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.unregisterMBean(JmxMBeanServer.java:546)
	at org.apache.hadoop.metrics2.util.MBeans.unregister(MBeans.java:143)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.shutdown(FsDatasetImpl.java:2293)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.shutdown(DataNode.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdownDataNode(MiniDFSCluster.java:2099)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdownDataNodes(MiniDFSCluster.java:2089)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2068)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2042)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2035)
	at org.apache.hadoop.hdfs.server.namenode.TestNamenodeCapacityReport.testXceiverCountInternal(TestNamenodeCapacityReport.java:345)
	at org.apache.hadoop.hdfs.server.namenode.TestNamenodeCapacityReport.testXceiverCount(TestNamenodeCapacityReport.java:200)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2020-12-03 07:20:18,533 [Listener at localhost/41792] WARN  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(191)) - AsyncDiskService has already shut down.
2020-12-03 07:20:18,533 [Listener at localhost/41792] WARN  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(175)) - AsyncLazyPersistService has already shut down.
2020-12-03 07:20:18,534 [Listener at localhost/41792] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:18,534 [Listener at localhost/41792] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 4
2020-12-03 07:20:18,534 [Listener at localhost/41792] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(341)) - DirectoryScanner: shutdown has been called, but periodic scanner not started
2020-12-03 07:20:18,539 [Listener at localhost/41792] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 38727
2020-12-03 07:20:18,540 [Listener at localhost/41792] WARN  util.MBeans (MBeans.java:unregister(145)) - Error unregistering Hadoop:service=DataNode,name=FSDatasetState-9acfc918-b97f-4fcf-8bea-64439f1ae0ea
javax.management.InstanceNotFoundException: Hadoop:service=DataNode,name=FSDatasetState-9acfc918-b97f-4fcf-8bea-64439f1ae0ea
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getMBean(DefaultMBeanServerInterceptor.java:1095)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.exclusiveUnregisterMBean(DefaultMBeanServerInterceptor.java:427)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.unregisterMBean(DefaultMBeanServerInterceptor.java:415)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.unregisterMBean(JmxMBeanServer.java:546)
	at org.apache.hadoop.metrics2.util.MBeans.unregister(MBeans.java:143)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.shutdown(FsDatasetImpl.java:2293)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.shutdown(DataNode.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdownDataNode(MiniDFSCluster.java:2099)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdownDataNodes(MiniDFSCluster.java:2089)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2068)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2042)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2035)
	at org.apache.hadoop.hdfs.server.namenode.TestNamenodeCapacityReport.testXceiverCountInternal(TestNamenodeCapacityReport.java:345)
	at org.apache.hadoop.hdfs.server.namenode.TestNamenodeCapacityReport.testXceiverCount(TestNamenodeCapacityReport.java:200)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2020-12-03 07:20:18,564 [Listener at localhost/41792] WARN  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(191)) - AsyncDiskService has already shut down.
2020-12-03 07:20:18,565 [Listener at localhost/41792] WARN  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(175)) - AsyncLazyPersistService has already shut down.
2020-12-03 07:20:18,565 [Listener at localhost/41792] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:18,565 [Listener at localhost/41792] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 3
2020-12-03 07:20:18,565 [Listener at localhost/41792] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(341)) - DirectoryScanner: shutdown has been called, but periodic scanner not started
2020-12-03 07:20:18,566 [Listener at localhost/41792] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 34326
2020-12-03 07:20:18,566 [Listener at localhost/41792] WARN  util.MBeans (MBeans.java:unregister(145)) - Error unregistering Hadoop:service=DataNode,name=FSDatasetState-e8690573-6d95-48a1-9ba7-5b1be3fa4816
javax.management.InstanceNotFoundException: Hadoop:service=DataNode,name=FSDatasetState-e8690573-6d95-48a1-9ba7-5b1be3fa4816
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getMBean(DefaultMBeanServerInterceptor.java:1095)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.exclusiveUnregisterMBean(DefaultMBeanServerInterceptor.java:427)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.unregisterMBean(DefaultMBeanServerInterceptor.java:415)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.unregisterMBean(JmxMBeanServer.java:546)
	at org.apache.hadoop.metrics2.util.MBeans.unregister(MBeans.java:143)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.shutdown(FsDatasetImpl.java:2293)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.shutdown(DataNode.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdownDataNode(MiniDFSCluster.java:2099)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdownDataNodes(MiniDFSCluster.java:2089)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2068)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2042)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2035)
	at org.apache.hadoop.hdfs.server.namenode.TestNamenodeCapacityReport.testXceiverCountInternal(TestNamenodeCapacityReport.java:345)
	at org.apache.hadoop.hdfs.server.namenode.TestNamenodeCapacityReport.testXceiverCount(TestNamenodeCapacityReport.java:200)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2020-12-03 07:20:18,566 [Listener at localhost/41792] WARN  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(191)) - AsyncDiskService has already shut down.
2020-12-03 07:20:18,567 [Listener at localhost/41792] WARN  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(175)) - AsyncLazyPersistService has already shut down.
2020-12-03 07:20:18,567 [Listener at localhost/41792] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:18,567 [Listener at localhost/41792] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 2
2020-12-03 07:20:18,567 [Listener at localhost/41792] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(341)) - DirectoryScanner: shutdown has been called, but periodic scanner not started
2020-12-03 07:20:18,568 [Listener at localhost/41792] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 41780
2020-12-03 07:20:18,568 [Listener at localhost/41792] WARN  util.MBeans (MBeans.java:unregister(145)) - Error unregistering Hadoop:service=DataNode,name=FSDatasetState-2df0ed89-2351-4d4d-8341-dd4497968a1f
javax.management.InstanceNotFoundException: Hadoop:service=DataNode,name=FSDatasetState-2df0ed89-2351-4d4d-8341-dd4497968a1f
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getMBean(DefaultMBeanServerInterceptor.java:1095)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.exclusiveUnregisterMBean(DefaultMBeanServerInterceptor.java:427)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.unregisterMBean(DefaultMBeanServerInterceptor.java:415)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.unregisterMBean(JmxMBeanServer.java:546)
	at org.apache.hadoop.metrics2.util.MBeans.unregister(MBeans.java:143)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.shutdown(FsDatasetImpl.java:2293)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.shutdown(DataNode.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdownDataNode(MiniDFSCluster.java:2099)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdownDataNodes(MiniDFSCluster.java:2089)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2068)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2042)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2035)
	at org.apache.hadoop.hdfs.server.namenode.TestNamenodeCapacityReport.testXceiverCountInternal(TestNamenodeCapacityReport.java:345)
	at org.apache.hadoop.hdfs.server.namenode.TestNamenodeCapacityReport.testXceiverCount(TestNamenodeCapacityReport.java:200)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2020-12-03 07:20:18,568 [Listener at localhost/41792] WARN  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(191)) - AsyncDiskService has already shut down.
2020-12-03 07:20:18,568 [Listener at localhost/41792] WARN  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(175)) - AsyncLazyPersistService has already shut down.
2020-12-03 07:20:18,569 [Listener at localhost/41792] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:18,569 [Listener at localhost/41792] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 1
2020-12-03 07:20:18,569 [Listener at localhost/41792] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(341)) - DirectoryScanner: shutdown has been called, but periodic scanner not started
2020-12-03 07:20:18,569 [Listener at localhost/41792] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 35874
2020-12-03 07:20:18,570 [Listener at localhost/41792] WARN  util.MBeans (MBeans.java:unregister(145)) - Error unregistering Hadoop:service=DataNode,name=FSDatasetState-b038b1a4-65c2-42df-90ed-7eefd1a46770
javax.management.InstanceNotFoundException: Hadoop:service=DataNode,name=FSDatasetState-b038b1a4-65c2-42df-90ed-7eefd1a46770
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getMBean(DefaultMBeanServerInterceptor.java:1095)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.exclusiveUnregisterMBean(DefaultMBeanServerInterceptor.java:427)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.unregisterMBean(DefaultMBeanServerInterceptor.java:415)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.unregisterMBean(JmxMBeanServer.java:546)
	at org.apache.hadoop.metrics2.util.MBeans.unregister(MBeans.java:143)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.shutdown(FsDatasetImpl.java:2293)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.shutdown(DataNode.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdownDataNode(MiniDFSCluster.java:2099)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdownDataNodes(MiniDFSCluster.java:2089)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2068)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2042)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2035)
	at org.apache.hadoop.hdfs.server.namenode.TestNamenodeCapacityReport.testXceiverCountInternal(TestNamenodeCapacityReport.java:345)
	at org.apache.hadoop.hdfs.server.namenode.TestNamenodeCapacityReport.testXceiverCount(TestNamenodeCapacityReport.java:200)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2020-12-03 07:20:18,570 [Listener at localhost/41792] WARN  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(191)) - AsyncDiskService has already shut down.
2020-12-03 07:20:18,570 [Listener at localhost/41792] WARN  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(175)) - AsyncLazyPersistService has already shut down.
2020-12-03 07:20:18,570 [Listener at localhost/41792] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:18,571 [Listener at localhost/41792] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:20:18,571 [Listener at localhost/41792] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(341)) - DirectoryScanner: shutdown has been called, but periodic scanner not started
2020-12-03 07:20:18,571 [Listener at localhost/41792] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 42318
2020-12-03 07:20:18,571 [Listener at localhost/41792] WARN  util.MBeans (MBeans.java:unregister(145)) - Error unregistering Hadoop:service=DataNode,name=FSDatasetState-29c10e8f-bd24-491d-a369-fc3d4333f678
javax.management.InstanceNotFoundException: Hadoop:service=DataNode,name=FSDatasetState-29c10e8f-bd24-491d-a369-fc3d4333f678
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getMBean(DefaultMBeanServerInterceptor.java:1095)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.exclusiveUnregisterMBean(DefaultMBeanServerInterceptor.java:427)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.unregisterMBean(DefaultMBeanServerInterceptor.java:415)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.unregisterMBean(JmxMBeanServer.java:546)
	at org.apache.hadoop.metrics2.util.MBeans.unregister(MBeans.java:143)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.shutdown(FsDatasetImpl.java:2293)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.shutdown(DataNode.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdownDataNode(MiniDFSCluster.java:2099)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdownDataNodes(MiniDFSCluster.java:2089)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2068)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2042)
	at org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2035)
	at org.apache.hadoop.hdfs.server.namenode.TestNamenodeCapacityReport.testXceiverCountInternal(TestNamenodeCapacityReport.java:345)
	at org.apache.hadoop.hdfs.server.namenode.TestNamenodeCapacityReport.testXceiverCount(TestNamenodeCapacityReport.java:200)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2020-12-03 07:20:18,572 [Listener at localhost/41792] WARN  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(191)) - AsyncDiskService has already shut down.
2020-12-03 07:20:18,572 [Listener at localhost/41792] WARN  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(175)) - AsyncLazyPersistService has already shut down.
2020-12-03 07:20:18,572 [Listener at localhost/41792] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:18,572 [Listener at localhost/41792] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:20:18,572 [Listener at localhost/41792] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:20:18,573 [Listener at localhost/41792] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 1, 31
2020-12-03 07:20:18,573 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@79d743e6] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:20:18,574 [Listener at localhost/41792] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 32 Total time for transactions(ms): 19 Number of transactions batched in Syncs: 6 Number of syncs: 27 SyncTimes(ms): 9 4 
2020-12-03 07:20:18,575 [Listener at localhost/41792] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000032
2020-12-03 07:20:18,576 [Listener at localhost/41792] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000032
2020-12-03 07:20:18,575 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@776802b0] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:20:18,576 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:20:18,577 [CacheReplicationMonitor(289740522)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:20:18,577 [Listener at localhost/41792] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 45965
2020-12-03 07:20:18,578 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:20:18,583 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:18,584 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:20:18,585 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:18,594 [Listener at localhost/41792] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:20:18,594 [Listener at localhost/41792] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:20:18,600 [Listener at localhost/41792] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@77c7ed8e{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:20:18,620 [Listener at localhost/41792] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@453d496b{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:18,620 [Listener at localhost/41792] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@66f659e6{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:18,621 [Listener at localhost/41792] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@63fdffcd{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
msx-rc 0
