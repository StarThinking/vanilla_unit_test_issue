2020-12-03 07:21:44,475 [main] INFO  mover.TestStorageMover (TestStorageMover.java:testHotWarmColdDirs(600)) - testHotWarmColdDirs
2020-12-03 07:21:44,542 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=6
Formatting using clusterid: testClusterID
2020-12-03 07:21:45,341 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:21:45,357 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:21:45,360 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:21:45,360 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:21:45,369 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:21:45,370 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:21:45,370 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:21:45,371 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:21:45,411 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:45,417 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2020-12-03 07:21:45,418 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:45,418 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=20, effected=1000
2020-12-03 07:21:45,418 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:21:45,419 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:45,426 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:21:45,427 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:21:45
2020-12-03 07:21:45,430 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:21:45,430 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:45,433 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-12-03 07:21:45,434 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:21:45,452 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:45,453 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:45,454 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:21:45,454 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:21:45,457 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.redundancy.interval.seconds(2) assuming SECONDS
2020-12-03 07:21:45,458 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:45,464 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:21:45,465 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:21:45,465 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:21:45,466 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:21:45,467 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:21:45,467 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:21:45,468 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:21:45,468 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:21:45,468 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 2000ms
2020-12-03 07:21:45,469 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:21:45,469 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:21:45,526 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GLOBAL serial map: bits=29 maxEntries=536870911
2020-12-03 07:21:45,527 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - USER serial map: bits=24 maxEntries=16777215
2020-12-03 07:21:45,527 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GROUP serial map: bits=24 maxEntries=16777215
2020-12-03 07:21:45,528 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - XATTR serial map: bits=24 maxEntries=16777215
2020-12-03 07:21:45,543 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:21:45,544 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:45,544 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-12-03 07:21:45,545 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:21:45,551 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:21:45,551 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:21:45,552 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:21:45,552 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:21:45,558 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:21:45,561 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:21:45,566 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:21:45,566 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:45,567 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-12-03 07:21:45,567 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:21:45,580 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:21:45,580 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:21:45,580 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:21:45,586 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:21:45,586 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:21:45,590 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:21:45,591 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:45,591 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-12-03 07:21:45,592 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:21:45,635 [main] INFO  namenode.FSImage (FSImage.java:format(185)) - Allocated new BlockPoolId: BP-112083932-172.17.0.7-1606980105622
2020-12-03 07:21:45,725 [main] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-12-03 07:21:45,894 [main] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-12-03 07:21:45,930 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:21:45,930 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:21:46,063 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:21:46,063 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:21:46,123 [main] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-12-03 07:21:46,126 [main] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:21:46,241 [main] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:21:46,667 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:21:46,668 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:21:46,712 [main] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-12-03 07:21:46,774 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1de76cc7] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:21:46,797 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:21:46,802 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:46,817 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @3443ms
2020-12-03 07:21:46,946 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:21:46,950 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:21:46,950 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:46,959 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:21:46,962 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:21:46,962 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:21:46,962 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:21:46,993 [main] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:21:46,993 [main] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:21:47,003 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 45017
2020-12-03 07:21:47,006 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:21:47,060 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5c7bfdc1{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:21:47,061 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@71687585{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:21:47,107 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7a3793c7{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:21:47,117 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7189bcba{HTTP/1.1,[http/1.1]}{localhost:45017}
2020-12-03 07:21:47,117 [main] INFO  server.Server (Server.java:doStart(419)) - Started @3743ms
2020-12-03 07:21:47,129 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:21:47,130 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:21:47,130 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:21:47,130 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:21:47,131 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:21:47,131 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:21:47,131 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:21:47,132 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:21:47,132 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:47,133 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:47,133 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=20, effected=1000
2020-12-03 07:21:47,133 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:21:47,134 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:47,134 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:21:47,135 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:21:47
2020-12-03 07:21:47,135 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:21:47,135 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:47,136 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:21:47,136 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:21:47,140 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:47,140 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:47,141 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:21:47,141 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:21:47,141 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.redundancy.interval.seconds(2) assuming SECONDS
2020-12-03 07:21:47,141 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:47,142 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:21:47,142 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:21:47,142 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:21:47,143 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:21:47,143 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:21:47,144 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:21:47,144 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:21:47,144 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:21:47,145 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 2000ms
2020-12-03 07:21:47,145 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:21:47,145 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:21:47,146 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:21:47,146 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:47,146 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:21:47,147 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:21:47,148 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:21:47,149 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:21:47,149 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:21:47,149 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:21:47,149 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:21:47,149 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:21:47,150 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:21:47,150 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:47,150 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:21:47,150 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:21:47,151 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:21:47,151 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:21:47,151 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:21:47,152 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:21:47,152 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:21:47,152 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:21:47,152 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:47,153 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:21:47,153 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:21:47,263 [main] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 5889@47e84f296739
2020-12-03 07:21:47,341 [main] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 5889@47e84f296739
2020-12-03 07:21:47,345 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-12-03 07:21:47,345 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-12-03 07:21:47,346 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:21:47,346 [main] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:21:47,379 [main] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:21:47,386 [main] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:21:47,386 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-12-03 07:21:47,391 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:21:47,392 [main] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 1
2020-12-03 07:21:47,612 [main] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:21:47,613 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 457 msecs
2020-12-03 07:21:47,815 [main] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:21:47,874 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:21:47,901 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:21:48,185 [Listener at localhost/44902] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:44902 to access this namenode/service.
2020-12-03 07:21:48,188 [Listener at localhost/44902] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:21:48,206 [Listener at localhost/44902] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:21:48,218 [Listener at localhost/44902] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:21:48,218 [Listener at localhost/44902] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:21:48,219 [Listener at localhost/44902] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:21:48,219 [Listener at localhost/44902] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:21:48,222 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 0
2020-12-03 07:21:48,222 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:21:48,223 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:21:48,223 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:21:48,223 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:21:48,223 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 5 msec
2020-12-03 07:21:48,252 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:21:48,252 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:21:48,256 [Listener at localhost/44902] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:44902
2020-12-03 07:21:48,261 [Listener at localhost/44902] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:21:48,261 [Listener at localhost/44902] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:21:48,269 [Listener at localhost/44902] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 7 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:21:48,273 [CacheReplicationMonitor(954627498)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:21:48,276 [Listener at localhost/44902] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:21:48,343 [Listener at localhost/44902] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:21:48,364 [Listener at localhost/44902] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:21:48,382 [Listener at localhost/44902] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:21:48,388 [Listener at localhost/44902] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:48,392 [Listener at localhost/44902] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:21:48,398 [Listener at localhost/44902] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:21:48,399 [Listener at localhost/44902] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:48,400 [Listener at localhost/44902] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:48,400 [Listener at localhost/44902] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:48,406 [Listener at localhost/44902] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:21:48,415 [Listener at localhost/44902] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:40228
2020-12-03 07:21:48,417 [Listener at localhost/44902] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:21:48,417 [Listener at localhost/44902] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:21:48,436 [Listener at localhost/44902] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:48,438 [Listener at localhost/44902] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:21:48,439 [Listener at localhost/44902] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:21:48,439 [Listener at localhost/44902] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:48,441 [Listener at localhost/44902] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:21:48,442 [Listener at localhost/44902] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:21:48,443 [Listener at localhost/44902] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:21:48,443 [Listener at localhost/44902] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:21:48,446 [Listener at localhost/44902] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 38195
2020-12-03 07:21:48,447 [Listener at localhost/44902] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:21:48,449 [Listener at localhost/44902] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7a7471ce{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:21:48,450 [Listener at localhost/44902] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@62e70ea3{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:21:48,458 [Listener at localhost/44902] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@61526469{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:21:48,459 [Listener at localhost/44902] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@274872f8{HTTP/1.1,[http/1.1]}{localhost:38195}
2020-12-03 07:21:48,459 [Listener at localhost/44902] INFO  server.Server (Server.java:doStart(419)) - Started @5085ms
2020-12-03 07:21:48,758 [Listener at localhost/44902] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:35466
2020-12-03 07:21:48,759 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@200a26bc] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:21:48,760 [Listener at localhost/44902] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:21:48,761 [Listener at localhost/44902] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:21:48,956 [Listener at localhost/44902] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:21:48,957 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:21:48,964 [Listener at localhost/41630] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:41630
2020-12-03 07:21:48,980 [Listener at localhost/41630] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:21:48,982 [Listener at localhost/41630] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:21:48,994 [Thread-59] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44902 starting to offer service
2020-12-03 07:21:49,000 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:21:49,000 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:21:49,004 [Listener at localhost/41630] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3,[ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:21:49,006 [Listener at localhost/41630] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:21:49,007 [Listener at localhost/41630] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:21:49,008 [Listener at localhost/41630] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:21:49,009 [Listener at localhost/41630] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:49,009 [Listener at localhost/41630] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:21:49,010 [Listener at localhost/41630] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:21:49,010 [Listener at localhost/41630] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:49,010 [Listener at localhost/41630] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:49,010 [Listener at localhost/41630] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:49,011 [Listener at localhost/41630] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:21:49,011 [Listener at localhost/41630] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:32936
2020-12-03 07:21:49,012 [Listener at localhost/41630] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:21:49,012 [Listener at localhost/41630] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:21:49,013 [Listener at localhost/41630] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:49,014 [Listener at localhost/41630] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:21:49,015 [Listener at localhost/41630] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:21:49,015 [Listener at localhost/41630] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:49,018 [Listener at localhost/41630] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:21:49,019 [Listener at localhost/41630] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:21:49,019 [Listener at localhost/41630] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:21:49,019 [Listener at localhost/41630] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:21:49,020 [Listener at localhost/41630] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 34080
2020-12-03 07:21:49,020 [Listener at localhost/41630] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:21:49,022 [Listener at localhost/41630] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@24be2d9c{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:21:49,023 [Listener at localhost/41630] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@aec50a1{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:21:49,030 [Listener at localhost/41630] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@29ad44e3{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:21:49,031 [Listener at localhost/41630] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@15bcf458{HTTP/1.1,[http/1.1]}{localhost:34080}
2020-12-03 07:21:49,032 [Listener at localhost/41630] INFO  server.Server (Server.java:doStart(419)) - Started @5658ms
2020-12-03 07:21:49,106 [Listener at localhost/41630] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:46144
2020-12-03 07:21:49,108 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@43c67247] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:21:49,108 [Listener at localhost/41630] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:21:49,108 [Listener at localhost/41630] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:21:49,109 [Listener at localhost/41630] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:21:49,110 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:21:49,123 [Listener at localhost/43123] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:43123
2020-12-03 07:21:49,129 [Listener at localhost/43123] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:21:49,130 [Listener at localhost/43123] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:21:49,131 [Thread-83] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44902 starting to offer service
2020-12-03 07:21:49,133 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:21:49,134 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:21:49,138 [Listener at localhost/43123] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5,[ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:21:49,140 [Listener at localhost/43123] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:21:49,140 [Listener at localhost/43123] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:21:49,143 [Listener at localhost/43123] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:21:49,144 [Listener at localhost/43123] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:49,144 [Listener at localhost/43123] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:21:49,145 [Listener at localhost/43123] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:21:49,145 [Listener at localhost/43123] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:49,146 [Listener at localhost/43123] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:49,146 [Listener at localhost/43123] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:49,147 [Listener at localhost/43123] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:21:49,148 [Listener at localhost/43123] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:46191
2020-12-03 07:21:49,148 [Listener at localhost/43123] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:21:49,148 [Listener at localhost/43123] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:21:49,158 [Listener at localhost/43123] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:49,163 [Listener at localhost/43123] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:21:49,165 [Listener at localhost/43123] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:21:49,165 [Listener at localhost/43123] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:49,169 [Listener at localhost/43123] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:21:49,170 [Listener at localhost/43123] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:21:49,171 [Listener at localhost/43123] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:21:49,171 [Listener at localhost/43123] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:21:49,173 [Listener at localhost/43123] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 45635
2020-12-03 07:21:49,174 [Listener at localhost/43123] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:21:49,180 [Listener at localhost/43123] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1e11bc55{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:21:49,181 [Listener at localhost/43123] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@70e0accd{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:21:49,192 [Listener at localhost/43123] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3d4d3fe7{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:21:49,194 [Listener at localhost/43123] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@65f87a2c{HTTP/1.1,[http/1.1]}{localhost:45635}
2020-12-03 07:21:49,194 [Listener at localhost/43123] INFO  server.Server (Server.java:doStart(419)) - Started @5820ms
2020-12-03 07:21:49,228 [Listener at localhost/43123] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:38566
2020-12-03 07:21:49,228 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6ce1f601] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:21:49,228 [Listener at localhost/43123] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:21:49,229 [Listener at localhost/43123] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:21:49,229 [Listener at localhost/43123] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:21:49,231 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:21:49,245 [Listener at localhost/41609] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:41609
2020-12-03 07:21:49,252 [Listener at localhost/41609] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:21:49,253 [Listener at localhost/41609] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:21:49,254 [Thread-105] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44902 starting to offer service
2020-12-03 07:21:49,254 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:21:49,256 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:21:49,260 [Listener at localhost/41609] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 3 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7,[ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:21:49,262 [Listener at localhost/41609] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:21:49,263 [Listener at localhost/41609] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:21:49,264 [Listener at localhost/41609] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:21:49,265 [Listener at localhost/41609] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:49,265 [Listener at localhost/41609] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:21:49,265 [Listener at localhost/41609] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:21:49,266 [Listener at localhost/41609] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:49,266 [Listener at localhost/41609] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:49,266 [Listener at localhost/41609] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:49,266 [Listener at localhost/41609] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:21:49,268 [Listener at localhost/41609] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:33330
2020-12-03 07:21:49,268 [Listener at localhost/41609] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:21:49,268 [Listener at localhost/41609] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:21:49,270 [Listener at localhost/41609] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:49,272 [Listener at localhost/41609] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:21:49,273 [Listener at localhost/41609] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:21:49,273 [Listener at localhost/41609] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:49,276 [Listener at localhost/41609] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:21:49,277 [Listener at localhost/41609] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:21:49,278 [Listener at localhost/41609] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:21:49,278 [Listener at localhost/41609] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:21:49,279 [Listener at localhost/41609] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 44705
2020-12-03 07:21:49,280 [Listener at localhost/41609] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:21:49,284 [Listener at localhost/41609] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@49a64d82{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:21:49,285 [Listener at localhost/41609] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@66d23e4a{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:21:49,295 [Listener at localhost/41609] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@37d3d232{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:21:49,296 [Listener at localhost/41609] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@30c0ccff{HTTP/1.1,[http/1.1]}{localhost:44705}
2020-12-03 07:21:49,296 [Listener at localhost/41609] INFO  server.Server (Server.java:doStart(419)) - Started @5922ms
2020-12-03 07:21:49,447 [Listener at localhost/41609] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:37559
2020-12-03 07:21:49,450 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@22db8f4] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:21:49,450 [Listener at localhost/41609] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:21:49,451 [Listener at localhost/41609] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:21:49,452 [Listener at localhost/41609] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:21:49,457 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:21:49,462 [Listener at localhost/33221] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:33221
2020-12-03 07:21:49,466 [Listener at localhost/33221] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:21:49,466 [Listener at localhost/33221] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:21:49,467 [Thread-127] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44902 starting to offer service
2020-12-03 07:21:49,469 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:21:49,469 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:21:49,476 [Listener at localhost/33221] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 4 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9,[ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:21:49,482 [Listener at localhost/33221] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:21:49,483 [Listener at localhost/33221] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:21:49,484 [Thread-83] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44902
2020-12-03 07:21:49,485 [Listener at localhost/33221] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:21:49,485 [Thread-59] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44902
2020-12-03 07:21:49,485 [Thread-105] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44902
2020-12-03 07:21:49,485 [Thread-127] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44902
2020-12-03 07:21:49,486 [Listener at localhost/33221] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:49,487 [Thread-83] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:21:49,487 [Thread-59] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:21:49,487 [Thread-127] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:21:49,487 [Thread-105] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:21:49,487 [Listener at localhost/33221] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:21:49,489 [Listener at localhost/33221] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:21:49,489 [Listener at localhost/33221] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:49,490 [Listener at localhost/33221] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:49,490 [Listener at localhost/33221] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:49,490 [Listener at localhost/33221] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:21:49,491 [Listener at localhost/33221] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:41276
2020-12-03 07:21:49,491 [Listener at localhost/33221] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:21:49,491 [Listener at localhost/33221] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:21:49,493 [Listener at localhost/33221] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:49,494 [Listener at localhost/33221] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:21:49,495 [Listener at localhost/33221] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:21:49,495 [Listener at localhost/33221] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:49,510 [Listener at localhost/33221] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:21:49,511 [Listener at localhost/33221] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:21:49,512 [Listener at localhost/33221] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:21:49,512 [Listener at localhost/33221] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:21:49,513 [Listener at localhost/33221] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 39493
2020-12-03 07:21:49,513 [Listener at localhost/33221] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:21:49,517 [Listener at localhost/33221] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7728643a{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:21:49,518 [Listener at localhost/33221] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5167268{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:21:49,525 [Listener at localhost/33221] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1bc53649{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:21:49,526 [Listener at localhost/33221] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@88d6f9b{HTTP/1.1,[http/1.1]}{localhost:39493}
2020-12-03 07:21:49,526 [Listener at localhost/33221] INFO  server.Server (Server.java:doStart(419)) - Started @6152ms
2020-12-03 07:21:49,541 [Listener at localhost/33221] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:35624
2020-12-03 07:21:49,542 [Listener at localhost/33221] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:21:49,542 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@475b7792] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:21:49,542 [Listener at localhost/33221] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:21:49,543 [Listener at localhost/33221] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:21:49,544 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:21:49,548 [Listener at localhost/36273] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:36273
2020-12-03 07:21:49,552 [Listener at localhost/36273] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:21:49,553 [Listener at localhost/36273] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:21:49,553 [Thread-149] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44902 starting to offer service
2020-12-03 07:21:49,555 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:21:49,556 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:21:49,558 [Listener at localhost/36273] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 5 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11,[ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:21:49,559 [Thread-149] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44902
2020-12-03 07:21:49,559 [Thread-149] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:21:49,560 [Listener at localhost/36273] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:21:49,561 [Listener at localhost/36273] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:21:49,562 [Listener at localhost/36273] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:21:49,562 [Listener at localhost/36273] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:49,562 [Listener at localhost/36273] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:21:49,563 [Listener at localhost/36273] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:21:49,563 [Listener at localhost/36273] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:49,563 [Listener at localhost/36273] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:49,563 [Listener at localhost/36273] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:49,564 [Listener at localhost/36273] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:21:49,564 [Listener at localhost/36273] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:32811
2020-12-03 07:21:49,565 [Listener at localhost/36273] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:21:49,565 [Listener at localhost/36273] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:21:49,566 [Listener at localhost/36273] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:49,568 [Listener at localhost/36273] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:21:49,569 [Listener at localhost/36273] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:21:49,569 [Listener at localhost/36273] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:49,571 [Listener at localhost/36273] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:21:49,572 [Listener at localhost/36273] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:21:49,573 [Listener at localhost/36273] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:21:49,573 [Listener at localhost/36273] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:21:49,574 [Listener at localhost/36273] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 46245
2020-12-03 07:21:49,574 [Listener at localhost/36273] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:21:49,576 [Listener at localhost/36273] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@27dc79f7{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:21:49,577 [Listener at localhost/36273] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3aaf4f07{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:21:49,578 [Thread-59] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 5889@47e84f296739
2020-12-03 07:21:49,578 [Thread-127] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/in_use.lock acquired by nodename 5889@47e84f296739
2020-12-03 07:21:49,578 [Thread-105] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 5889@47e84f296739
2020-12-03 07:21:49,578 [Thread-83] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 5889@47e84f296739
2020-12-03 07:21:49,580 [Thread-83] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 is not formatted for namespace 543616343. Formatting...
2020-12-03 07:21:49,580 [Thread-127] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 is not formatted for namespace 543616343. Formatting...
2020-12-03 07:21:49,580 [Thread-105] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 is not formatted for namespace 543616343. Formatting...
2020-12-03 07:21:49,580 [Thread-59] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 543616343. Formatting...
2020-12-03 07:21:49,581 [Thread-83] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-c5bce671-868b-4fa8-afa7-49e9ec5526a2 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 
2020-12-03 07:21:49,581 [Thread-59] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-98c5da98-47d1-4ec8-8c42-db45703eedeb for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-12-03 07:21:49,581 [Thread-127] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-d75ea7b4-2fee-44a5-844d-faa34ba6681d for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 
2020-12-03 07:21:49,583 [Thread-105] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-dfbdbbaa-c98a-4ba8-8504-1c726531280a for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 
2020-12-03 07:21:49,585 [Listener at localhost/36273] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@a23a01d{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:21:49,586 [Listener at localhost/36273] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4acf72b6{HTTP/1.1,[http/1.1]}{localhost:46245}
2020-12-03 07:21:49,586 [Listener at localhost/36273] INFO  server.Server (Server.java:doStart(419)) - Started @6212ms
2020-12-03 07:21:49,602 [Listener at localhost/36273] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:38406
2020-12-03 07:21:49,603 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3301500b] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:21:49,603 [Listener at localhost/36273] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:21:49,603 [Listener at localhost/36273] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:21:49,604 [Listener at localhost/36273] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:21:49,604 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:21:49,609 [Listener at localhost/37726] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:37726
2020-12-03 07:21:49,613 [Listener at localhost/37726] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:21:49,614 [Listener at localhost/37726] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:21:49,615 [Thread-171] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44902 starting to offer service
2020-12-03 07:21:49,616 [Thread-149] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/in_use.lock acquired by nodename 5889@47e84f296739
2020-12-03 07:21:49,617 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:21:49,617 [Thread-149] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 is not formatted for namespace 543616343. Formatting...
2020-12-03 07:21:49,618 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:21:49,618 [Thread-149] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-d45ac532-8cf5-4065-bea9-b33e7114dc7d for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 
2020-12-03 07:21:49,629 [Thread-171] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44902
2020-12-03 07:21:49,633 [Thread-171] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:21:49,707 [Thread-171] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/in_use.lock acquired by nodename 5889@47e84f296739
2020-12-03 07:21:49,708 [Thread-171] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 is not formatted for namespace 543616343. Formatting...
2020-12-03 07:21:49,708 [Thread-171] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-1bb59e4f-55f8-43b4-92c0-6f9216074971 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 
2020-12-03 07:21:49,873 [Thread-83] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 5889@47e84f296739
2020-12-03 07:21:49,873 [Thread-105] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 5889@47e84f296739
2020-12-03 07:21:49,874 [Thread-83] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 is not formatted for namespace 543616343. Formatting...
2020-12-03 07:21:49,874 [Thread-83] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-d4b106f7-6476-43e5-bebc-4d76f054903f for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 
2020-12-03 07:21:49,875 [Thread-59] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 5889@47e84f296739
2020-12-03 07:21:49,875 [Thread-59] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 543616343. Formatting...
2020-12-03 07:21:49,875 [Thread-59] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-45d26ee9-5330-4328-a6f5-9d5cae8072d4 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-12-03 07:21:49,874 [Thread-105] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 is not formatted for namespace 543616343. Formatting...
2020-12-03 07:21:49,876 [Thread-105] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-ae119148-187a-42b8-a576-43913a2cea7b for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 
2020-12-03 07:21:49,876 [Thread-127] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/in_use.lock acquired by nodename 5889@47e84f296739
2020-12-03 07:21:49,877 [Thread-127] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 is not formatted for namespace 543616343. Formatting...
2020-12-03 07:21:49,877 [Thread-127] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-8e084a11-8a03-4947-83b2-a2598a529f6c for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 
2020-12-03 07:21:49,930 [Thread-149] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/in_use.lock acquired by nodename 5889@47e84f296739
2020-12-03 07:21:49,931 [Thread-149] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 is not formatted for namespace 543616343. Formatting...
2020-12-03 07:21:49,931 [Thread-149] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-0e0d2a62-0a95-4405-ac61-c36d0ad42c39 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 
2020-12-03 07:21:50,028 [Thread-171] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/in_use.lock acquired by nodename 5889@47e84f296739
2020-12-03 07:21:50,029 [Thread-171] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 is not formatted for namespace 543616343. Formatting...
2020-12-03 07:21:50,029 [Thread-171] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-7ba7554c-5ca9-4cc9-a977-6f21fc38dd76 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 
2020-12-03 07:21:50,075 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-112083932-172.17.0.7-1606980105622
2020-12-03 07:21:50,075 [Thread-127] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-112083932-172.17.0.7-1606980105622
2020-12-03 07:21:50,075 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-112083932-172.17.0.7-1606980105622
2020-12-03 07:21:50,076 [Thread-127] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-112083932-172.17.0.7-1606980105622
2020-12-03 07:21:50,076 [Thread-105] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-112083932-172.17.0.7-1606980105622
2020-12-03 07:21:50,076 [Thread-83] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-112083932-172.17.0.7-1606980105622
2020-12-03 07:21:50,078 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 and block pool id BP-112083932-172.17.0.7-1606980105622 is not formatted. Formatting ...
2020-12-03 07:21:50,078 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 and block pool id BP-112083932-172.17.0.7-1606980105622 is not formatted. Formatting ...
2020-12-03 07:21:50,078 [Thread-127] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 and block pool id BP-112083932-172.17.0.7-1606980105622 is not formatted. Formatting ...
2020-12-03 07:21:50,078 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-112083932-172.17.0.7-1606980105622 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-112083932-172.17.0.7-1606980105622/current
2020-12-03 07:21:50,078 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-112083932-172.17.0.7-1606980105622 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-112083932-172.17.0.7-1606980105622/current
2020-12-03 07:21:50,078 [Thread-127] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-112083932-172.17.0.7-1606980105622 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-112083932-172.17.0.7-1606980105622/current
2020-12-03 07:21:50,079 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-112083932-172.17.0.7-1606980105622
2020-12-03 07:21:50,079 [Thread-59] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-112083932-172.17.0.7-1606980105622
2020-12-03 07:21:50,080 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-112083932-172.17.0.7-1606980105622 is not formatted. Formatting ...
2020-12-03 07:21:50,080 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-112083932-172.17.0.7-1606980105622 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-112083932-172.17.0.7-1606980105622/current
2020-12-03 07:21:50,124 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-112083932-172.17.0.7-1606980105622
2020-12-03 07:21:50,124 [Thread-149] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-112083932-172.17.0.7-1606980105622
2020-12-03 07:21:50,125 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 and block pool id BP-112083932-172.17.0.7-1606980105622 is not formatted. Formatting ...
2020-12-03 07:21:50,125 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-112083932-172.17.0.7-1606980105622 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-112083932-172.17.0.7-1606980105622/current
2020-12-03 07:21:50,244 [IPC Server handler 7 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:50,253 [Listener at localhost/37726] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:50,253 [Listener at localhost/37726] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:50,267 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-112083932-172.17.0.7-1606980105622
2020-12-03 07:21:50,268 [Thread-171] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-112083932-172.17.0.7-1606980105622
2020-12-03 07:21:50,268 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 and block pool id BP-112083932-172.17.0.7-1606980105622 is not formatted. Formatting ...
2020-12-03 07:21:50,268 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-112083932-172.17.0.7-1606980105622 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-112083932-172.17.0.7-1606980105622/current
2020-12-03 07:21:50,319 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-112083932-172.17.0.7-1606980105622
2020-12-03 07:21:50,319 [Thread-59] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-112083932-172.17.0.7-1606980105622
2020-12-03 07:21:50,319 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-112083932-172.17.0.7-1606980105622
2020-12-03 07:21:50,319 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-112083932-172.17.0.7-1606980105622 is not formatted. Formatting ...
2020-12-03 07:21:50,319 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-112083932-172.17.0.7-1606980105622 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-112083932-172.17.0.7-1606980105622/current
2020-12-03 07:21:50,320 [Thread-83] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-112083932-172.17.0.7-1606980105622
2020-12-03 07:21:50,320 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 and block pool id BP-112083932-172.17.0.7-1606980105622 is not formatted. Formatting ...
2020-12-03 07:21:50,320 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-112083932-172.17.0.7-1606980105622 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-112083932-172.17.0.7-1606980105622/current
2020-12-03 07:21:50,321 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-112083932-172.17.0.7-1606980105622
2020-12-03 07:21:50,321 [Thread-105] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-112083932-172.17.0.7-1606980105622
2020-12-03 07:21:50,321 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 and block pool id BP-112083932-172.17.0.7-1606980105622 is not formatted. Formatting ...
2020-12-03 07:21:50,321 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-112083932-172.17.0.7-1606980105622 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-112083932-172.17.0.7-1606980105622/current
2020-12-03 07:21:50,322 [Thread-127] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-112083932-172.17.0.7-1606980105622
2020-12-03 07:21:50,322 [Thread-127] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-112083932-172.17.0.7-1606980105622
2020-12-03 07:21:50,322 [Thread-127] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 and block pool id BP-112083932-172.17.0.7-1606980105622 is not formatted. Formatting ...
2020-12-03 07:21:50,323 [Thread-127] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-112083932-172.17.0.7-1606980105622 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-112083932-172.17.0.7-1606980105622/current
2020-12-03 07:21:50,357 [IPC Server handler 1 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:50,358 [Listener at localhost/37726] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:50,358 [Listener at localhost/37726] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:50,385 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-112083932-172.17.0.7-1606980105622
2020-12-03 07:21:50,385 [Thread-149] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-112083932-172.17.0.7-1606980105622
2020-12-03 07:21:50,386 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 and block pool id BP-112083932-172.17.0.7-1606980105622 is not formatted. Formatting ...
2020-12-03 07:21:50,386 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-112083932-172.17.0.7-1606980105622 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-112083932-172.17.0.7-1606980105622/current
2020-12-03 07:21:50,460 [IPC Server handler 4 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:50,461 [Listener at localhost/37726] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:50,461 [Listener at localhost/37726] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:50,532 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-112083932-172.17.0.7-1606980105622
2020-12-03 07:21:50,533 [Thread-171] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-112083932-172.17.0.7-1606980105622
2020-12-03 07:21:50,533 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 and block pool id BP-112083932-172.17.0.7-1606980105622 is not formatted. Formatting ...
2020-12-03 07:21:50,533 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-112083932-172.17.0.7-1606980105622 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-112083932-172.17.0.7-1606980105622/current
2020-12-03 07:21:50,564 [IPC Server handler 3 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:50,564 [Listener at localhost/37726] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:50,565 [Listener at localhost/37726] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:50,569 [Thread-59] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=543616343;bpid=BP-112083932-172.17.0.7-1606980105622;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=543616343;c=1606980105622;bpid=BP-112083932-172.17.0.7-1606980105622;dnuuid=null
2020-12-03 07:21:50,569 [Thread-127] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=543616343;bpid=BP-112083932-172.17.0.7-1606980105622;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=543616343;c=1606980105622;bpid=BP-112083932-172.17.0.7-1606980105622;dnuuid=null
2020-12-03 07:21:50,569 [Thread-105] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=543616343;bpid=BP-112083932-172.17.0.7-1606980105622;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=543616343;c=1606980105622;bpid=BP-112083932-172.17.0.7-1606980105622;dnuuid=null
2020-12-03 07:21:50,572 [Thread-83] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=543616343;bpid=BP-112083932-172.17.0.7-1606980105622;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=543616343;c=1606980105622;bpid=BP-112083932-172.17.0.7-1606980105622;dnuuid=null
2020-12-03 07:21:50,638 [Thread-149] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=543616343;bpid=BP-112083932-172.17.0.7-1606980105622;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=543616343;c=1606980105622;bpid=BP-112083932-172.17.0.7-1606980105622;dnuuid=null
2020-12-03 07:21:50,667 [IPC Server handler 7 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:50,667 [Listener at localhost/37726] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:50,668 [Listener at localhost/37726] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:50,770 [IPC Server handler 2 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:50,771 [Listener at localhost/37726] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:50,771 [Listener at localhost/37726] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:50,842 [Thread-171] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=543616343;bpid=BP-112083932-172.17.0.7-1606980105622;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=543616343;c=1606980105622;bpid=BP-112083932-172.17.0.7-1606980105622;dnuuid=null
2020-12-03 07:21:50,873 [IPC Server handler 8 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:50,874 [Listener at localhost/37726] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:50,874 [Listener at localhost/37726] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:50,918 [Thread-127] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 0237cc88-214f-4ecc-9fca-2ef3974ab7eb
2020-12-03 07:21:50,919 [Thread-59] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 4531fc3a-8c15-42c0-ad49-f6505a50dcea
2020-12-03 07:21:50,918 [Thread-105] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 7b793216-748f-4be6-a144-367935ffbafb
2020-12-03 07:21:50,918 [Thread-83] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID fc258908-e76f-48a7-8279-3420f46782bd
2020-12-03 07:21:50,975 [Thread-149] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 002461fc-4aa8-4d26-86c3-971092b194a6
2020-12-03 07:21:50,980 [IPC Server handler 9 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:50,981 [Listener at localhost/37726] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:50,981 [Listener at localhost/37726] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:51,067 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-98c5da98-47d1-4ec8-8c42-db45703eedeb
2020-12-03 07:21:51,068 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-12-03 07:21:51,067 [Thread-127] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-d75ea7b4-2fee-44a5-844d-faa34ba6681d
2020-12-03 07:21:51,069 [Thread-127] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, StorageType: DISK
2020-12-03 07:21:51,068 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-c5bce671-868b-4fa8-afa7-49e9ec5526a2
2020-12-03 07:21:51,068 [Thread-105] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-dfbdbbaa-c98a-4ba8-8504-1c726531280a
2020-12-03 07:21:51,070 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: DISK
2020-12-03 07:21:51,068 [Thread-149] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-d45ac532-8cf5-4065-bea9-b33e7114dc7d
2020-12-03 07:21:51,070 [Thread-105] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, StorageType: DISK
2020-12-03 07:21:51,071 [Thread-149] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, StorageType: DISK
2020-12-03 07:21:51,071 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-45d26ee9-5330-4328-a6f5-9d5cae8072d4
2020-12-03 07:21:51,071 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: ARCHIVE
2020-12-03 07:21:51,073 [Thread-149] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-0e0d2a62-0a95-4405-ac61-c36d0ad42c39
2020-12-03 07:21:51,074 [Thread-149] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, StorageType: ARCHIVE
2020-12-03 07:21:51,075 [Thread-105] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-ae119148-187a-42b8-a576-43913a2cea7b
2020-12-03 07:21:51,075 [Thread-105] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, StorageType: ARCHIVE
2020-12-03 07:21:51,077 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-d4b106f7-6476-43e5-bebc-4d76f054903f
2020-12-03 07:21:51,077 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: ARCHIVE
2020-12-03 07:21:51,078 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:21:51,078 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:21:51,078 [Thread-105] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:21:51,079 [Thread-149] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:21:51,079 [Thread-127] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-8e084a11-8a03-4947-83b2-a2598a529f6c
2020-12-03 07:21:51,080 [Thread-127] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, StorageType: ARCHIVE
2020-12-03 07:21:51,080 [Thread-127] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:21:51,083 [IPC Server handler 1 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:51,084 [Listener at localhost/37726] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:51,084 [Listener at localhost/37726] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:51,086 [Thread-105] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:21:51,087 [Thread-83] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:21:51,088 [Thread-59] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:21:51,089 [Thread-127] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:21:51,090 [Thread-149] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:21:51,096 [Thread-105] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:21:51,098 [Thread-59] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:21:51,096 [Thread-127] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:21:51,098 [Thread-83] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:21:51,098 [Thread-149] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:21:51,100 [Thread-149] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:21:51,100 [Thread-83] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:21:51,100 [Thread-105] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:21:51,100 [Thread-127] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:21:51,100 [Thread-59] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:21:51,101 [Thread-127] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:21:51,101 [Thread-105] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:21:51,100 [Thread-83] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:21:51,100 [Thread-149] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:21:51,102 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-112083932-172.17.0.7-1606980105622
2020-12-03 07:21:51,102 [Thread-127] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-112083932-172.17.0.7-1606980105622
2020-12-03 07:21:51,101 [Thread-59] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:21:51,102 [Thread-149] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-112083932-172.17.0.7-1606980105622
2020-12-03 07:21:51,102 [Thread-105] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-112083932-172.17.0.7-1606980105622
2020-12-03 07:21:51,103 [Thread-195] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-112083932-172.17.0.7-1606980105622 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:21:51,103 [Thread-198] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-112083932-172.17.0.7-1606980105622 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-12-03 07:21:51,104 [Thread-200] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-112083932-172.17.0.7-1606980105622 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-12-03 07:21:51,104 [Thread-199] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-112083932-172.17.0.7-1606980105622 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:21:51,104 [Thread-196] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-112083932-172.17.0.7-1606980105622 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-12-03 07:21:51,104 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-112083932-172.17.0.7-1606980105622
2020-12-03 07:21:51,105 [Thread-202] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-112083932-172.17.0.7-1606980105622 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:21:51,105 [Thread-201] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-112083932-172.17.0.7-1606980105622 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-12-03 07:21:51,105 [Thread-203] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-112083932-172.17.0.7-1606980105622 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:21:51,106 [Thread-204] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-112083932-172.17.0.7-1606980105622 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:21:51,104 [Thread-197] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-112083932-172.17.0.7-1606980105622 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:21:51,121 [Thread-171] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID d756da44-2378-4af0-be27-9028065cb33e
2020-12-03 07:21:51,126 [Thread-171] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-1bb59e4f-55f8-43b4-92c0-6f9216074971
2020-12-03 07:21:51,127 [Thread-171] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, StorageType: DISK
2020-12-03 07:21:51,129 [Thread-171] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-7ba7554c-5ca9-4cc9-a977-6f21fc38dd76
2020-12-03 07:21:51,129 [Thread-171] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, StorageType: ARCHIVE
2020-12-03 07:21:51,130 [Thread-171] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:21:51,132 [Thread-171] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:21:51,135 [Thread-171] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:21:51,135 [Thread-171] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:21:51,135 [Thread-171] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:21:51,136 [Thread-171] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-112083932-172.17.0.7-1606980105622
2020-12-03 07:21:51,136 [Thread-212] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-112083932-172.17.0.7-1606980105622 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11...
2020-12-03 07:21:51,137 [Thread-213] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-112083932-172.17.0.7-1606980105622 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12...
2020-12-03 07:21:51,180 [Thread-204] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-112083932-172.17.0.7-1606980105622 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 74ms
2020-12-03 07:21:51,182 [Thread-198] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-112083932-172.17.0.7-1606980105622 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 79ms
2020-12-03 07:21:51,183 [Thread-202] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-112083932-172.17.0.7-1606980105622 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 78ms
2020-12-03 07:21:51,184 [Thread-203] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-112083932-172.17.0.7-1606980105622 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 79ms
2020-12-03 07:21:51,185 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-112083932-172.17.0.7-1606980105622: 79ms
2020-12-03 07:21:51,186 [Thread-196] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-112083932-172.17.0.7-1606980105622 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 80ms
2020-12-03 07:21:51,189 [Thread-221] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-112083932-172.17.0.7-1606980105622 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:21:51,189 [Thread-222] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-112083932-172.17.0.7-1606980105622 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:21:51,189 [Thread-221] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-112083932-172.17.0.7-1606980105622/current/replicas doesn't exist 
2020-12-03 07:21:51,189 [Thread-195] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-112083932-172.17.0.7-1606980105622 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 86ms
2020-12-03 07:21:51,190 [Thread-213] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-112083932-172.17.0.7-1606980105622 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12: 53ms
2020-12-03 07:21:51,189 [Thread-222] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-112083932-172.17.0.7-1606980105622/current/replicas doesn't exist 
2020-12-03 07:21:51,190 [IPC Server handler 4 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:51,190 [Thread-212] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-112083932-172.17.0.7-1606980105622 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11: 54ms
2020-12-03 07:21:51,191 [Thread-171] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-112083932-172.17.0.7-1606980105622: 55ms
2020-12-03 07:21:51,191 [Thread-199] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-112083932-172.17.0.7-1606980105622 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 87ms
2020-12-03 07:21:51,191 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-112083932-172.17.0.7-1606980105622: 89ms
2020-12-03 07:21:51,196 [Thread-223] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-112083932-172.17.0.7-1606980105622 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11...
2020-12-03 07:21:51,196 [Thread-223] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-112083932-172.17.0.7-1606980105622/current/replicas doesn't exist 
2020-12-03 07:21:51,196 [Thread-222] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-112083932-172.17.0.7-1606980105622 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 7ms
2020-12-03 07:21:51,196 [Listener at localhost/37726] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:51,197 [Listener at localhost/37726] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:51,196 [Thread-221] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-112083932-172.17.0.7-1606980105622 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 7ms
2020-12-03 07:21:51,197 [Thread-226] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-112083932-172.17.0.7-1606980105622 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:21:51,197 [Thread-224] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-112083932-172.17.0.7-1606980105622 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12...
2020-12-03 07:21:51,197 [Thread-223] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-112083932-172.17.0.7-1606980105622 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11: 0ms
2020-12-03 07:21:51,196 [Thread-225] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-112083932-172.17.0.7-1606980105622 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:21:51,198 [Thread-200] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-112083932-172.17.0.7-1606980105622 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 94ms
2020-12-03 07:21:51,198 [Thread-225] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-112083932-172.17.0.7-1606980105622/current/replicas doesn't exist 
2020-12-03 07:21:51,198 [Thread-224] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-112083932-172.17.0.7-1606980105622/current/replicas doesn't exist 
2020-12-03 07:21:51,198 [Thread-226] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-112083932-172.17.0.7-1606980105622/current/replicas doesn't exist 
2020-12-03 07:21:51,198 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-112083932-172.17.0.7-1606980105622: 9ms
2020-12-03 07:21:51,199 [Thread-224] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-112083932-172.17.0.7-1606980105622 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12: 1ms
2020-12-03 07:21:51,199 [Thread-225] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-112083932-172.17.0.7-1606980105622 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 1ms
2020-12-03 07:21:51,199 [Thread-197] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-112083932-172.17.0.7-1606980105622 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 92ms
2020-12-03 07:21:51,202 [Thread-105] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-112083932-172.17.0.7-1606980105622: 100ms
2020-12-03 07:21:51,198 [Thread-201] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-112083932-172.17.0.7-1606980105622 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 93ms
2020-12-03 07:21:51,198 [Thread-127] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-112083932-172.17.0.7-1606980105622: 96ms
2020-12-03 07:21:51,203 [Thread-227] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-112083932-172.17.0.7-1606980105622 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:21:51,202 [Thread-171] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-112083932-172.17.0.7-1606980105622: 11ms
2020-12-03 07:21:51,200 [Thread-226] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-112083932-172.17.0.7-1606980105622 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 2ms
2020-12-03 07:21:51,203 [Thread-229] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-112083932-172.17.0.7-1606980105622 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-12-03 07:21:51,203 [Thread-227] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-112083932-172.17.0.7-1606980105622/current/replicas doesn't exist 
2020-12-03 07:21:51,203 [Thread-149] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-112083932-172.17.0.7-1606980105622: 101ms
2020-12-03 07:21:51,203 [Thread-228] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-112083932-172.17.0.7-1606980105622 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:21:51,203 [Thread-229] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-112083932-172.17.0.7-1606980105622/current/replicas doesn't exist 
2020-12-03 07:21:51,203 [Thread-228] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-112083932-172.17.0.7-1606980105622/current/replicas doesn't exist 
2020-12-03 07:21:51,203 [Thread-230] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-112083932-172.17.0.7-1606980105622 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-12-03 07:21:51,203 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-112083932-172.17.0.7-1606980105622: 12ms
2020-12-03 07:21:51,204 [Thread-230] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-112083932-172.17.0.7-1606980105622/current/replicas doesn't exist 
2020-12-03 07:21:51,204 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-112083932-172.17.0.7-1606980105622 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:21:51,204 [Thread-228] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-112083932-172.17.0.7-1606980105622 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 1ms
2020-12-03 07:21:51,205 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-112083932-172.17.0.7-1606980105622 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:21:51,204 [Thread-229] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-112083932-172.17.0.7-1606980105622 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 1ms
2020-12-03 07:21:51,204 [Thread-231] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-112083932-172.17.0.7-1606980105622 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-12-03 07:21:51,203 [Thread-227] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-112083932-172.17.0.7-1606980105622 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 0ms
2020-12-03 07:21:51,205 [Thread-230] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-112083932-172.17.0.7-1606980105622 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 1ms
2020-12-03 07:21:51,205 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-112083932-172.17.0.7-1606980105622 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:21:51,205 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-112083932-172.17.0.7-1606980105622 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:21:51,205 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-112083932-172.17.0.7-1606980105622 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:21:51,210 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-1bb59e4f-55f8-43b4-92c0-6f9216074971): finished scanning block pool BP-112083932-172.17.0.7-1606980105622
2020-12-03 07:21:51,205 [Thread-232] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-112083932-172.17.0.7-1606980105622 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-12-03 07:21:51,204 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-112083932-172.17.0.7-1606980105622 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:21:51,210 [Thread-232] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-112083932-172.17.0.7-1606980105622/current/replicas doesn't exist 
2020-12-03 07:21:51,210 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-98c5da98-47d1-4ec8-8c42-db45703eedeb): finished scanning block pool BP-112083932-172.17.0.7-1606980105622
2020-12-03 07:21:51,210 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-7ba7554c-5ca9-4cc9-a977-6f21fc38dd76): finished scanning block pool BP-112083932-172.17.0.7-1606980105622
2020-12-03 07:21:51,210 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-c5bce671-868b-4fa8-afa7-49e9ec5526a2): finished scanning block pool BP-112083932-172.17.0.7-1606980105622
2020-12-03 07:21:51,210 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-d4b106f7-6476-43e5-bebc-4d76f054903f): finished scanning block pool BP-112083932-172.17.0.7-1606980105622
2020-12-03 07:21:51,210 [Thread-127] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-112083932-172.17.0.7-1606980105622: 8ms
2020-12-03 07:21:51,210 [Thread-105] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-112083932-172.17.0.7-1606980105622: 7ms
2020-12-03 07:21:51,210 [Thread-231] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-112083932-172.17.0.7-1606980105622/current/replicas doesn't exist 
2020-12-03 07:21:51,212 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-112083932-172.17.0.7-1606980105622 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:21:51,212 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-112083932-172.17.0.7-1606980105622 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:21:51,212 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-112083932-172.17.0.7-1606980105622 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:21:51,212 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-8e084a11-8a03-4947-83b2-a2598a529f6c): finished scanning block pool BP-112083932-172.17.0.7-1606980105622
2020-12-03 07:21:51,212 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-ae119148-187a-42b8-a576-43913a2cea7b): finished scanning block pool BP-112083932-172.17.0.7-1606980105622
2020-12-03 07:21:51,212 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-dfbdbbaa-c98a-4ba8-8504-1c726531280a): finished scanning block pool BP-112083932-172.17.0.7-1606980105622
2020-12-03 07:21:51,211 [Thread-232] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-112083932-172.17.0.7-1606980105622 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 1ms
2020-12-03 07:21:51,211 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-45d26ee9-5330-4328-a6f5-9d5cae8072d4): finished scanning block pool BP-112083932-172.17.0.7-1606980105622
2020-12-03 07:21:51,212 [Thread-231] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-112083932-172.17.0.7-1606980105622 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 3ms
2020-12-03 07:21:51,212 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-112083932-172.17.0.7-1606980105622 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:21:51,213 [Thread-149] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-112083932-172.17.0.7-1606980105622: 10ms
2020-12-03 07:21:51,214 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-d75ea7b4-2fee-44a5-844d-faa34ba6681d): finished scanning block pool BP-112083932-172.17.0.7-1606980105622
2020-12-03 07:21:51,214 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-112083932-172.17.0.7-1606980105622 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:21:51,214 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-0e0d2a62-0a95-4405-ac61-c36d0ad42c39): finished scanning block pool BP-112083932-172.17.0.7-1606980105622
2020-12-03 07:21:51,214 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-112083932-172.17.0.7-1606980105622 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:21:51,215 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-d45ac532-8cf5-4065-bea9-b33e7114dc7d): finished scanning block pool BP-112083932-172.17.0.7-1606980105622
2020-12-03 07:21:51,230 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-0e0d2a62-0a95-4405-ac61-c36d0ad42c39): no suitable block pools found to scan.  Waiting 1814399984 ms.
2020-12-03 07:21:51,230 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-8e084a11-8a03-4947-83b2-a2598a529f6c): no suitable block pools found to scan.  Waiting 1814399982 ms.
2020-12-03 07:21:51,230 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-98c5da98-47d1-4ec8-8c42-db45703eedeb): no suitable block pools found to scan.  Waiting 1814399974 ms.
2020-12-03 07:21:51,230 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-ae119148-187a-42b8-a576-43913a2cea7b): no suitable block pools found to scan.  Waiting 1814399982 ms.
2020-12-03 07:21:51,230 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-45d26ee9-5330-4328-a6f5-9d5cae8072d4): no suitable block pools found to scan.  Waiting 1814399974 ms.
2020-12-03 07:21:51,231 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-dfbdbbaa-c98a-4ba8-8504-1c726531280a): no suitable block pools found to scan.  Waiting 1814399981 ms.
2020-12-03 07:21:51,231 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-d4b106f7-6476-43e5-bebc-4d76f054903f): no suitable block pools found to scan.  Waiting 1814399975 ms.
2020-12-03 07:21:51,231 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-d75ea7b4-2fee-44a5-844d-faa34ba6681d): no suitable block pools found to scan.  Waiting 1814399982 ms.
2020-12-03 07:21:51,230 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-1bb59e4f-55f8-43b4-92c0-6f9216074971): no suitable block pools found to scan.  Waiting 1814399974 ms.
2020-12-03 07:21:51,230 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-d45ac532-8cf5-4065-bea9-b33e7114dc7d): no suitable block pools found to scan.  Waiting 1814399984 ms.
2020-12-03 07:21:51,230 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-7ba7554c-5ca9-4cc9-a977-6f21fc38dd76): no suitable block pools found to scan.  Waiting 1814399974 ms.
2020-12-03 07:21:51,231 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-c5bce671-868b-4fa8-afa7-49e9ec5526a2): no suitable block pools found to scan.  Waiting 1814399973 ms.
2020-12-03 07:21:51,235 [Thread-171] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:48 AM with interval of 21600000ms
2020-12-03 07:21:51,235 [Thread-59] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 9:31 AM with interval of 21600000ms
2020-12-03 07:21:51,236 [Thread-105] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:09 AM with interval of 21600000ms
2020-12-03 07:21:51,237 [Thread-149] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 1:05 PM with interval of 21600000ms
2020-12-03 07:21:51,241 [Thread-83] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 7:29 AM with interval of 21600000ms
2020-12-03 07:21:51,244 [Thread-127] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 8:00 AM with interval of 21600000ms
2020-12-03 07:21:51,250 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-112083932-172.17.0.7-1606980105622 (Datanode Uuid 7b793216-748f-4be6-a144-367935ffbafb) service to localhost/127.0.0.1:44902 beginning handshake with NN
2020-12-03 07:21:51,256 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-112083932-172.17.0.7-1606980105622 (Datanode Uuid fc258908-e76f-48a7-8279-3420f46782bd) service to localhost/127.0.0.1:44902 beginning handshake with NN
2020-12-03 07:21:51,256 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-112083932-172.17.0.7-1606980105622 (Datanode Uuid d756da44-2378-4af0-be27-9028065cb33e) service to localhost/127.0.0.1:44902 beginning handshake with NN
2020-12-03 07:21:51,256 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-112083932-172.17.0.7-1606980105622 (Datanode Uuid 4531fc3a-8c15-42c0-ad49-f6505a50dcea) service to localhost/127.0.0.1:44902 beginning handshake with NN
2020-12-03 07:21:51,256 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-112083932-172.17.0.7-1606980105622 (Datanode Uuid 0237cc88-214f-4ecc-9fca-2ef3974ab7eb) service to localhost/127.0.0.1:44902 beginning handshake with NN
2020-12-03 07:21:51,256 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-112083932-172.17.0.7-1606980105622 (Datanode Uuid 002461fc-4aa8-4d26-86c3-971092b194a6) service to localhost/127.0.0.1:44902 beginning handshake with NN
2020-12-03 07:21:51,267 [IPC Server handler 6 on default port 44902] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:40228, datanodeUuid=4531fc3a-8c15-42c0-ad49-f6505a50dcea, infoPort=35466, infoSecurePort=0, ipcPort=41630, storageInfo=lv=-57;cid=testClusterID;nsid=543616343;c=1606980105622) storage 4531fc3a-8c15-42c0-ad49-f6505a50dcea
2020-12-03 07:21:51,269 [IPC Server handler 6 on default port 44902] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:40228
2020-12-03 07:21:51,270 [IPC Server handler 6 on default port 44902] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 4531fc3a-8c15-42c0-ad49-f6505a50dcea (127.0.0.1:40228).
2020-12-03 07:21:51,272 [IPC Server handler 5 on default port 44902] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:32936, datanodeUuid=fc258908-e76f-48a7-8279-3420f46782bd, infoPort=46144, infoSecurePort=0, ipcPort=43123, storageInfo=lv=-57;cid=testClusterID;nsid=543616343;c=1606980105622) storage fc258908-e76f-48a7-8279-3420f46782bd
2020-12-03 07:21:51,272 [IPC Server handler 5 on default port 44902] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:32936
2020-12-03 07:21:51,272 [IPC Server handler 5 on default port 44902] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN fc258908-e76f-48a7-8279-3420f46782bd (127.0.0.1:32936).
2020-12-03 07:21:51,272 [IPC Server handler 0 on default port 44902] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:46191, datanodeUuid=7b793216-748f-4be6-a144-367935ffbafb, infoPort=38566, infoSecurePort=0, ipcPort=41609, storageInfo=lv=-57;cid=testClusterID;nsid=543616343;c=1606980105622) storage 7b793216-748f-4be6-a144-367935ffbafb
2020-12-03 07:21:51,273 [IPC Server handler 0 on default port 44902] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:46191
2020-12-03 07:21:51,273 [IPC Server handler 0 on default port 44902] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 7b793216-748f-4be6-a144-367935ffbafb (127.0.0.1:46191).
2020-12-03 07:21:51,273 [IPC Server handler 3 on default port 44902] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:33330, datanodeUuid=0237cc88-214f-4ecc-9fca-2ef3974ab7eb, infoPort=37559, infoSecurePort=0, ipcPort=33221, storageInfo=lv=-57;cid=testClusterID;nsid=543616343;c=1606980105622) storage 0237cc88-214f-4ecc-9fca-2ef3974ab7eb
2020-12-03 07:21:51,273 [IPC Server handler 3 on default port 44902] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:33330
2020-12-03 07:21:51,274 [IPC Server handler 3 on default port 44902] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 0237cc88-214f-4ecc-9fca-2ef3974ab7eb (127.0.0.1:33330).
2020-12-03 07:21:51,274 [IPC Server handler 2 on default port 44902] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:32811, datanodeUuid=d756da44-2378-4af0-be27-9028065cb33e, infoPort=38406, infoSecurePort=0, ipcPort=37726, storageInfo=lv=-57;cid=testClusterID;nsid=543616343;c=1606980105622) storage d756da44-2378-4af0-be27-9028065cb33e
2020-12-03 07:21:51,274 [IPC Server handler 2 on default port 44902] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:32811
2020-12-03 07:21:51,274 [IPC Server handler 2 on default port 44902] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN d756da44-2378-4af0-be27-9028065cb33e (127.0.0.1:32811).
2020-12-03 07:21:51,275 [IPC Server handler 7 on default port 44902] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:41276, datanodeUuid=002461fc-4aa8-4d26-86c3-971092b194a6, infoPort=35624, infoSecurePort=0, ipcPort=36273, storageInfo=lv=-57;cid=testClusterID;nsid=543616343;c=1606980105622) storage 002461fc-4aa8-4d26-86c3-971092b194a6
2020-12-03 07:21:51,275 [IPC Server handler 7 on default port 44902] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41276
2020-12-03 07:21:51,275 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-112083932-172.17.0.7-1606980105622 (Datanode Uuid 4531fc3a-8c15-42c0-ad49-f6505a50dcea) service to localhost/127.0.0.1:44902 successfully registered with NN
2020-12-03 07:21:51,275 [IPC Server handler 7 on default port 44902] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 002461fc-4aa8-4d26-86c3-971092b194a6 (127.0.0.1:41276).
2020-12-03 07:21:51,275 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-112083932-172.17.0.7-1606980105622 (Datanode Uuid 7b793216-748f-4be6-a144-367935ffbafb) service to localhost/127.0.0.1:44902 successfully registered with NN
2020-12-03 07:21:51,275 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-112083932-172.17.0.7-1606980105622 (Datanode Uuid d756da44-2378-4af0-be27-9028065cb33e) service to localhost/127.0.0.1:44902 successfully registered with NN
2020-12-03 07:21:51,276 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:44902 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-12-03 07:21:51,275 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-112083932-172.17.0.7-1606980105622 (Datanode Uuid fc258908-e76f-48a7-8279-3420f46782bd) service to localhost/127.0.0.1:44902 successfully registered with NN
2020-12-03 07:21:51,275 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:44902 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-12-03 07:21:51,276 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:44902 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-12-03 07:21:51,276 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-112083932-172.17.0.7-1606980105622 (Datanode Uuid 0237cc88-214f-4ecc-9fca-2ef3974ab7eb) service to localhost/127.0.0.1:44902 successfully registered with NN
2020-12-03 07:21:51,276 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:44902 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-12-03 07:21:51,276 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:44902 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-12-03 07:21:51,276 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-112083932-172.17.0.7-1606980105622 (Datanode Uuid 002461fc-4aa8-4d26-86c3-971092b194a6) service to localhost/127.0.0.1:44902 successfully registered with NN
2020-12-03 07:21:51,278 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:44902 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-12-03 07:21:51,298 [IPC Server handler 8 on default port 44902] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d75ea7b4-2fee-44a5-844d-faa34ba6681d for DN 127.0.0.1:33330
2020-12-03 07:21:51,299 [IPC Server handler 8 on default port 44902] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-8e084a11-8a03-4947-83b2-a2598a529f6c for DN 127.0.0.1:33330
2020-12-03 07:21:51,300 [IPC Server handler 3 on default port 44902] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d45ac532-8cf5-4065-bea9-b33e7114dc7d for DN 127.0.0.1:41276
2020-12-03 07:21:51,301 [IPC Server handler 3 on default port 44902] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-0e0d2a62-0a95-4405-ac61-c36d0ad42c39 for DN 127.0.0.1:41276
2020-12-03 07:21:51,301 [IPC Server handler 6 on default port 44902] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c5bce671-868b-4fa8-afa7-49e9ec5526a2 for DN 127.0.0.1:32936
2020-12-03 07:21:51,301 [IPC Server handler 6 on default port 44902] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d4b106f7-6476-43e5-bebc-4d76f054903f for DN 127.0.0.1:32936
2020-12-03 07:21:51,302 [IPC Server handler 4 on default port 44902] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-1bb59e4f-55f8-43b4-92c0-6f9216074971 for DN 127.0.0.1:32811
2020-12-03 07:21:51,303 [IPC Server handler 4 on default port 44902] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-7ba7554c-5ca9-4cc9-a977-6f21fc38dd76 for DN 127.0.0.1:32811
2020-12-03 07:21:51,303 [IPC Server handler 1 on default port 44902] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-98c5da98-47d1-4ec8-8c42-db45703eedeb for DN 127.0.0.1:40228
2020-12-03 07:21:51,304 [IPC Server handler 0 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:51,304 [IPC Server handler 1 on default port 44902] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-45d26ee9-5330-4328-a6f5-9d5cae8072d4 for DN 127.0.0.1:40228
2020-12-03 07:21:51,305 [IPC Server handler 9 on default port 44902] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-dfbdbbaa-c98a-4ba8-8504-1c726531280a for DN 127.0.0.1:46191
2020-12-03 07:21:51,305 [IPC Server handler 9 on default port 44902] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-ae119148-187a-42b8-a576-43913a2cea7b for DN 127.0.0.1:46191
2020-12-03 07:21:51,311 [Listener at localhost/37726] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2798)) - No heartbeat from DataNode: 127.0.0.1:32811
2020-12-03 07:21:51,311 [Listener at localhost/37726] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:51,341 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x219f0ed3ff786fa4: Processing first storage report for DS-0e0d2a62-0a95-4405-ac61-c36d0ad42c39 from datanode 002461fc-4aa8-4d26-86c3-971092b194a6
2020-12-03 07:21:51,344 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x219f0ed3ff786fa4: from storage DS-0e0d2a62-0a95-4405-ac61-c36d0ad42c39 node DatanodeRegistration(127.0.0.1:41276, datanodeUuid=002461fc-4aa8-4d26-86c3-971092b194a6, infoPort=35624, infoSecurePort=0, ipcPort=36273, storageInfo=lv=-57;cid=testClusterID;nsid=543616343;c=1606980105622), blocks: 0, hasStaleStorage: true, processing time: 3 msecs, invalidatedBlocks: 0
2020-12-03 07:21:51,344 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xf8fb16a3530b4cf3: Processing first storage report for DS-8e084a11-8a03-4947-83b2-a2598a529f6c from datanode 0237cc88-214f-4ecc-9fca-2ef3974ab7eb
2020-12-03 07:21:51,344 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xf8fb16a3530b4cf3: from storage DS-8e084a11-8a03-4947-83b2-a2598a529f6c node DatanodeRegistration(127.0.0.1:33330, datanodeUuid=0237cc88-214f-4ecc-9fca-2ef3974ab7eb, infoPort=37559, infoSecurePort=0, ipcPort=33221, storageInfo=lv=-57;cid=testClusterID;nsid=543616343;c=1606980105622), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:51,344 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x2af71878c25e8975: Processing first storage report for DS-7ba7554c-5ca9-4cc9-a977-6f21fc38dd76 from datanode d756da44-2378-4af0-be27-9028065cb33e
2020-12-03 07:21:51,345 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x2af71878c25e8975: from storage DS-7ba7554c-5ca9-4cc9-a977-6f21fc38dd76 node DatanodeRegistration(127.0.0.1:32811, datanodeUuid=d756da44-2378-4af0-be27-9028065cb33e, infoPort=38406, infoSecurePort=0, ipcPort=37726, storageInfo=lv=-57;cid=testClusterID;nsid=543616343;c=1606980105622), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:51,345 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xc4cf9a8c92a7c44a: Processing first storage report for DS-ae119148-187a-42b8-a576-43913a2cea7b from datanode 7b793216-748f-4be6-a144-367935ffbafb
2020-12-03 07:21:51,345 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xc4cf9a8c92a7c44a: from storage DS-ae119148-187a-42b8-a576-43913a2cea7b node DatanodeRegistration(127.0.0.1:46191, datanodeUuid=7b793216-748f-4be6-a144-367935ffbafb, infoPort=38566, infoSecurePort=0, ipcPort=41609, storageInfo=lv=-57;cid=testClusterID;nsid=543616343;c=1606980105622), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:51,345 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xfc8314b2c08b8c8c: Processing first storage report for DS-c5bce671-868b-4fa8-afa7-49e9ec5526a2 from datanode fc258908-e76f-48a7-8279-3420f46782bd
2020-12-03 07:21:51,346 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xfc8314b2c08b8c8c: from storage DS-c5bce671-868b-4fa8-afa7-49e9ec5526a2 node DatanodeRegistration(127.0.0.1:32936, datanodeUuid=fc258908-e76f-48a7-8279-3420f46782bd, infoPort=46144, infoSecurePort=0, ipcPort=43123, storageInfo=lv=-57;cid=testClusterID;nsid=543616343;c=1606980105622), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:51,346 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x34913344e47fcf66: Processing first storage report for DS-98c5da98-47d1-4ec8-8c42-db45703eedeb from datanode 4531fc3a-8c15-42c0-ad49-f6505a50dcea
2020-12-03 07:21:51,346 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x34913344e47fcf66: from storage DS-98c5da98-47d1-4ec8-8c42-db45703eedeb node DatanodeRegistration(127.0.0.1:40228, datanodeUuid=4531fc3a-8c15-42c0-ad49-f6505a50dcea, infoPort=35466, infoSecurePort=0, ipcPort=41630, storageInfo=lv=-57;cid=testClusterID;nsid=543616343;c=1606980105622), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:51,347 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xf8fb16a3530b4cf3: Processing first storage report for DS-d75ea7b4-2fee-44a5-844d-faa34ba6681d from datanode 0237cc88-214f-4ecc-9fca-2ef3974ab7eb
2020-12-03 07:21:51,347 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xf8fb16a3530b4cf3: from storage DS-d75ea7b4-2fee-44a5-844d-faa34ba6681d node DatanodeRegistration(127.0.0.1:33330, datanodeUuid=0237cc88-214f-4ecc-9fca-2ef3974ab7eb, infoPort=37559, infoSecurePort=0, ipcPort=33221, storageInfo=lv=-57;cid=testClusterID;nsid=543616343;c=1606980105622), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:21:51,347 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xc4cf9a8c92a7c44a: Processing first storage report for DS-dfbdbbaa-c98a-4ba8-8504-1c726531280a from datanode 7b793216-748f-4be6-a144-367935ffbafb
2020-12-03 07:21:51,347 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xc4cf9a8c92a7c44a: from storage DS-dfbdbbaa-c98a-4ba8-8504-1c726531280a node DatanodeRegistration(127.0.0.1:46191, datanodeUuid=7b793216-748f-4be6-a144-367935ffbafb, infoPort=38566, infoSecurePort=0, ipcPort=41609, storageInfo=lv=-57;cid=testClusterID;nsid=543616343;c=1606980105622), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:51,347 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xfc8314b2c08b8c8c: Processing first storage report for DS-d4b106f7-6476-43e5-bebc-4d76f054903f from datanode fc258908-e76f-48a7-8279-3420f46782bd
2020-12-03 07:21:51,347 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xfc8314b2c08b8c8c: from storage DS-d4b106f7-6476-43e5-bebc-4d76f054903f node DatanodeRegistration(127.0.0.1:32936, datanodeUuid=fc258908-e76f-48a7-8279-3420f46782bd, infoPort=46144, infoSecurePort=0, ipcPort=43123, storageInfo=lv=-57;cid=testClusterID;nsid=543616343;c=1606980105622), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:51,348 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x2af71878c25e8975: Processing first storage report for DS-1bb59e4f-55f8-43b4-92c0-6f9216074971 from datanode d756da44-2378-4af0-be27-9028065cb33e
2020-12-03 07:21:51,348 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x2af71878c25e8975: from storage DS-1bb59e4f-55f8-43b4-92c0-6f9216074971 node DatanodeRegistration(127.0.0.1:32811, datanodeUuid=d756da44-2378-4af0-be27-9028065cb33e, infoPort=38406, infoSecurePort=0, ipcPort=37726, storageInfo=lv=-57;cid=testClusterID;nsid=543616343;c=1606980105622), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:51,348 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x34913344e47fcf66: Processing first storage report for DS-45d26ee9-5330-4328-a6f5-9d5cae8072d4 from datanode 4531fc3a-8c15-42c0-ad49-f6505a50dcea
2020-12-03 07:21:51,348 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x34913344e47fcf66: from storage DS-45d26ee9-5330-4328-a6f5-9d5cae8072d4 node DatanodeRegistration(127.0.0.1:40228, datanodeUuid=4531fc3a-8c15-42c0-ad49-f6505a50dcea, infoPort=35466, infoSecurePort=0, ipcPort=41630, storageInfo=lv=-57;cid=testClusterID;nsid=543616343;c=1606980105622), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:51,348 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x219f0ed3ff786fa4: Processing first storage report for DS-d45ac532-8cf5-4065-bea9-b33e7114dc7d from datanode 002461fc-4aa8-4d26-86c3-971092b194a6
2020-12-03 07:21:51,349 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x219f0ed3ff786fa4: from storage DS-d45ac532-8cf5-4065-bea9-b33e7114dc7d node DatanodeRegistration(127.0.0.1:41276, datanodeUuid=002461fc-4aa8-4d26-86c3-971092b194a6, infoPort=35624, infoSecurePort=0, ipcPort=36273, storageInfo=lv=-57;cid=testClusterID;nsid=543616343;c=1606980105622), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:51,372 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x219f0ed3ff786fa4,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 47 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:21:51,372 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xc4cf9a8c92a7c44a,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 5 msec to generate and 46 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:21:51,373 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x34913344e47fcf66,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 49 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:21:51,373 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x2af71878c25e8975,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 50 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:21:51,373 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-112083932-172.17.0.7-1606980105622
2020-12-03 07:21:51,374 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xfc8314b2c08b8c8c,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 5 msec to generate and 46 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:21:51,374 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-112083932-172.17.0.7-1606980105622
2020-12-03 07:21:51,373 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-112083932-172.17.0.7-1606980105622
2020-12-03 07:21:51,373 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-112083932-172.17.0.7-1606980105622
2020-12-03 07:21:51,373 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xf8fb16a3530b4cf3,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 47 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:21:51,373 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-112083932-172.17.0.7-1606980105622
2020-12-03 07:21:51,375 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-112083932-172.17.0.7-1606980105622
2020-12-03 07:21:51,414 [IPC Server handler 9 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:51,418 [Listener at localhost/37726] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:21:51,429 [IPC Server handler 8 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:51,431 [Listener at localhost/37726] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:21:51,454 [IPC Server handler 4 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/hot	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:21:51,474 [IPC Server handler 6 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/warm	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:21:51,478 [IPC Server handler 5 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/cold	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:21:51,480 [IPC Server handler 1 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/cold	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:21:51,521 [IPC Server handler 7 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/cold/file0	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:21:51,560 [IPC Server handler 2 on default port 44902] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(427)) - storageTypes={DISK=3}
2020-12-03 07:21:51,562 [IPC Server handler 2 on default port 44902] DEBUG blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseRemoteRack(719)) - Failed to choose remote rack (location = ~/default-rack), fallback to local rack
org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy$NotEnoughReplicasException: 
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRandom(BlockPlacementPolicyDefault.java:852)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRemoteRack(BlockPlacementPolicyDefault.java:714)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTargetInOrder(BlockPlacementPolicyDefault.java:519)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:437)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:309)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:149)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:174)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2211)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2789)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:892)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:574)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
2020-12-03 07:21:51,564 [IPC Server handler 2 on default port 44902] DEBUG blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseRemoteRack(719)) - Failed to choose remote rack (location = ~/default-rack), fallback to local rack
org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy$NotEnoughReplicasException: 
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRandom(BlockPlacementPolicyDefault.java:852)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRemoteRack(BlockPlacementPolicyDefault.java:714)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTargetInOrder(BlockPlacementPolicyDefault.java:528)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:437)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:309)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:149)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:174)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2211)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2789)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:892)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:574)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
2020-12-03 07:21:51,568 [IPC Server handler 2 on default port 44902] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:40228, 127.0.0.1:41276, 127.0.0.1:46191 for /cold/file0
2020-12-03 07:21:51,585 [Thread-251] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:51,674 [Thread-251] TRACE datatransfer.DataTransferProtocol (Sender.java:send(79)) - Sending DataTransferOp OpWriteBlockProto: header {
  baseHeader {
    block {
      poolId: "BP-112083932-172.17.0.7-1606980105622"
      blockId: 1073741825
      generationStamp: 1001
      numBytes: 1024
    }
    token {
      identifier: ""
      password: ""
      kind: ""
      service: ""
    }
  }
  clientName: "DFSClient_NONMAPREDUCE_-391545094_1"
}
targets {
  id {
    ipAddr: "127.0.0.1"
    hostName: "127.0.0.1"
    datanodeUuid: "002461fc-4aa8-4d26-86c3-971092b194a6"
    xferPort: 41276
    infoPort: 35624
    ipcPort: 36273
    infoSecurePort: 0
  }
  capacity: 1922244395008
  dfsUsed: 49152
  remaining: 1198465425408
  blockPoolUsed: 49152
  lastUpdate: 1606980111301
  xceiverCount: 1
  location: "/default-rack"
  nonDfsUsed: 626087215104
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 141100224
  lastBlockReportTime: 1606980111349
  lastBlockReportMonotonic: 141100272
  numBlocks: 0
}
targets {
  id {
    ipAddr: "127.0.0.1"
    hostName: "127.0.0.1"
    datanodeUuid: "7b793216-748f-4be6-a144-367935ffbafb"
    xferPort: 46191
    infoPort: 38566
    ipcPort: 41609
    infoSecurePort: 0
  }
  capacity: 1922244395008
  dfsUsed: 49152
  remaining: 1198465425408
  blockPoolUsed: 49152
  lastUpdate: 1606980111306
  xceiverCount: 1
  location: "/default-rack"
  nonDfsUsed: 626087215104
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 141100229
  lastBlockReportTime: 1606980111349
  lastBlockReportMonotonic: 141100272
  numBlocks: 0
}
stage: PIPELINE_SETUP_CREATE
pipelineSize: 3
minBytesRcvd: 0
maxBytesRcvd: 0
latestGenerationStamp: 0
requestedChecksum {
  type: CHECKSUM_CRC32C
  bytesPerChecksum: 512
}
cachingStrategy {
}
storageType: DISK
targetStorageTypes: DISK
targetStorageTypes: DISK
allowLazyPersist: false
pinning: false
targetPinnings: false
storageId: "DS-98c5da98-47d1-4ec8-8c42-db45703eedeb"
targetStorageIds: "DS-d45ac532-8cf5-4065-bea9-b33e7114dc7d"
targetStorageIds: "DS-dfbdbbaa-c98a-4ba8-8504-1c726531280a"

2020-12-03 07:21:51,678 [DataXceiver for client DFSClient_NONMAPREDUCE_-391545094_1 at /127.0.0.1:38418 [Receiving block BP-112083932-172.17.0.7-1606980105622:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-112083932-172.17.0.7-1606980105622:blk_1073741825_1001 src: /127.0.0.1:38418 dest: /127.0.0.1:40228
2020-12-03 07:21:51,706 [DataXceiver for client DFSClient_NONMAPREDUCE_-391545094_1 at /127.0.0.1:38418 [Receiving block BP-112083932-172.17.0.7-1606980105622:blk_1073741825_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:51,713 [DataXceiver for client DFSClient_NONMAPREDUCE_-391545094_1 at /127.0.0.1:38418 [Receiving block BP-112083932-172.17.0.7-1606980105622:blk_1073741825_1001]] TRACE datatransfer.DataTransferProtocol (Sender.java:send(79)) - Sending DataTransferOp OpWriteBlockProto: header {
  baseHeader {
    block {
      poolId: "BP-112083932-172.17.0.7-1606980105622"
      blockId: 1073741825
      generationStamp: 1001
      numBytes: 1024
    }
    token {
      identifier: ""
      password: ""
      kind: ""
      service: ""
    }
  }
  clientName: "DFSClient_NONMAPREDUCE_-391545094_1"
}
targets {
  id {
    ipAddr: "127.0.0.1"
    hostName: "127.0.0.1"
    datanodeUuid: "7b793216-748f-4be6-a144-367935ffbafb"
    xferPort: 46191
    infoPort: 38566
    ipcPort: 41609
    infoSecurePort: 0
  }
  capacity: 1922244395008
  dfsUsed: 49152
  remaining: 1198465425408
  blockPoolUsed: 49152
  lastUpdate: 1606980111306
  xceiverCount: 1
  location: "/default-rack"
  nonDfsUsed: 626087215104
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 141100229
  lastBlockReportTime: 1606980111349
  lastBlockReportMonotonic: 141100272
  numBlocks: 0
}
source {
  id {
    ipAddr: ""
    hostName: ""
    datanodeUuid: ""
    xferPort: 0
    infoPort: 0
    ipcPort: 0
    infoSecurePort: 0
  }
  capacity: 0
  dfsUsed: 0
  remaining: 0
  blockPoolUsed: 0
  lastUpdate: 0
  xceiverCount: 0
  nonDfsUsed: 0
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 0
  lastBlockReportTime: 0
  lastBlockReportMonotonic: 0
  numBlocks: 0
}
stage: PIPELINE_SETUP_CREATE
pipelineSize: 3
minBytesRcvd: 0
maxBytesRcvd: 0
latestGenerationStamp: 0
requestedChecksum {
  type: CHECKSUM_CRC32C
  bytesPerChecksum: 512
}
cachingStrategy {
}
storageType: DISK
targetStorageTypes: DISK
allowLazyPersist: false
pinning: false
storageId: "DS-d45ac532-8cf5-4065-bea9-b33e7114dc7d"
targetStorageIds: "DS-dfbdbbaa-c98a-4ba8-8504-1c726531280a"

2020-12-03 07:21:51,714 [DataXceiver for client DFSClient_NONMAPREDUCE_-391545094_1 at /127.0.0.1:37090 [Receiving block BP-112083932-172.17.0.7-1606980105622:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-112083932-172.17.0.7-1606980105622:blk_1073741825_1001 src: /127.0.0.1:37090 dest: /127.0.0.1:41276
2020-12-03 07:21:51,717 [DataXceiver for client DFSClient_NONMAPREDUCE_-391545094_1 at /127.0.0.1:37090 [Receiving block BP-112083932-172.17.0.7-1606980105622:blk_1073741825_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:51,721 [DataXceiver for client DFSClient_NONMAPREDUCE_-391545094_1 at /127.0.0.1:37090 [Receiving block BP-112083932-172.17.0.7-1606980105622:blk_1073741825_1001]] TRACE datatransfer.DataTransferProtocol (Sender.java:send(79)) - Sending DataTransferOp OpWriteBlockProto: header {
  baseHeader {
    block {
      poolId: "BP-112083932-172.17.0.7-1606980105622"
      blockId: 1073741825
      generationStamp: 1001
      numBytes: 1024
    }
    token {
      identifier: ""
      password: ""
      kind: ""
      service: ""
    }
  }
  clientName: "DFSClient_NONMAPREDUCE_-391545094_1"
}
source {
  id {
    ipAddr: ""
    hostName: ""
    datanodeUuid: ""
    xferPort: 0
    infoPort: 0
    ipcPort: 0
    infoSecurePort: 0
  }
  capacity: 0
  dfsUsed: 0
  remaining: 0
  blockPoolUsed: 0
  lastUpdate: 0
  xceiverCount: 0
  nonDfsUsed: 0
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 0
  lastBlockReportTime: 0
  lastBlockReportMonotonic: 0
  numBlocks: 0
}
stage: PIPELINE_SETUP_CREATE
pipelineSize: 3
minBytesRcvd: 0
maxBytesRcvd: 0
latestGenerationStamp: 0
requestedChecksum {
  type: CHECKSUM_CRC32C
  bytesPerChecksum: 512
}
cachingStrategy {
}
storageType: DISK
allowLazyPersist: false
pinning: false
storageId: "DS-dfbdbbaa-c98a-4ba8-8504-1c726531280a"

2020-12-03 07:21:51,722 [DataXceiver for client DFSClient_NONMAPREDUCE_-391545094_1 at /127.0.0.1:58254 [Receiving block BP-112083932-172.17.0.7-1606980105622:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-112083932-172.17.0.7-1606980105622:blk_1073741825_1001 src: /127.0.0.1:58254 dest: /127.0.0.1:46191
2020-12-03 07:21:52,144 [PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58254, dest: /127.0.0.1:46191, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-391545094_1, offset: 0, srvID: 7b793216-748f-4be6-a144-367935ffbafb, blockid: BP-112083932-172.17.0.7-1606980105622:blk_1073741825_1001, duration(ns): 17101568
2020-12-03 07:21:52,145 [PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:21:52,149 [PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46191]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37090, dest: /127.0.0.1:41276, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-391545094_1, offset: 0, srvID: 002461fc-4aa8-4d26-86c3-971092b194a6, blockid: BP-112083932-172.17.0.7-1606980105622:blk_1073741825_1001, duration(ns): 413406784
2020-12-03 07:21:52,150 [PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46191]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46191] terminating
2020-12-03 07:21:52,153 [PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:41276, 127.0.0.1:46191]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38418, dest: /127.0.0.1:40228, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-391545094_1, offset: 0, srvID: 4531fc3a-8c15-42c0-ad49-f6505a50dcea, blockid: BP-112083932-172.17.0.7-1606980105622:blk_1073741825_1001, duration(ns): 418254852
2020-12-03 07:21:52,153 [PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:41276, 127.0.0.1:46191]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:41276, 127.0.0.1:46191] terminating
2020-12-03 07:21:52,162 [IPC Server handler 3 on default port 44902] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2995)) - BLOCK* blk_1073741825_1001 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /cold/file0
2020-12-03 07:21:52,568 [IPC Server handler 8 on default port 44902] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /cold/file0 is closed by DFSClient_NONMAPREDUCE_-391545094_1
2020-12-03 07:21:52,571 [IPC Server handler 9 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/cold	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:21:52,574 [IPC Server handler 4 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/cold/file1	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:21:52,578 [IPC Server handler 3 on default port 44902] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(427)) - storageTypes={DISK=3}
2020-12-03 07:21:52,578 [IPC Server handler 3 on default port 44902] DEBUG blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseRemoteRack(719)) - Failed to choose remote rack (location = ~/default-rack), fallback to local rack
org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy$NotEnoughReplicasException: 
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRandom(BlockPlacementPolicyDefault.java:852)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRemoteRack(BlockPlacementPolicyDefault.java:714)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTargetInOrder(BlockPlacementPolicyDefault.java:519)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:437)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:309)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:149)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:174)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2211)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2789)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:892)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:574)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
2020-12-03 07:21:52,579 [IPC Server handler 3 on default port 44902] DEBUG blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseRemoteRack(719)) - Failed to choose remote rack (location = ~/default-rack), fallback to local rack
org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy$NotEnoughReplicasException: 
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRandom(BlockPlacementPolicyDefault.java:852)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRemoteRack(BlockPlacementPolicyDefault.java:714)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTargetInOrder(BlockPlacementPolicyDefault.java:528)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:437)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:309)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:149)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:174)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2211)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2789)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:892)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:574)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
2020-12-03 07:21:52,580 [IPC Server handler 3 on default port 44902] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741826_1002, replicas=127.0.0.1:32936, 127.0.0.1:32811, 127.0.0.1:33330 for /cold/file1
2020-12-03 07:21:52,582 [Thread-260] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:52,585 [Thread-260] TRACE datatransfer.DataTransferProtocol (Sender.java:send(79)) - Sending DataTransferOp OpWriteBlockProto: header {
  baseHeader {
    block {
      poolId: "BP-112083932-172.17.0.7-1606980105622"
      blockId: 1073741826
      generationStamp: 1002
      numBytes: 1024
    }
    token {
      identifier: ""
      password: ""
      kind: ""
      service: ""
    }
  }
  clientName: "DFSClient_NONMAPREDUCE_-391545094_1"
}
targets {
  id {
    ipAddr: "127.0.0.1"
    hostName: "127.0.0.1"
    datanodeUuid: "d756da44-2378-4af0-be27-9028065cb33e"
    xferPort: 32811
    infoPort: 38406
    ipcPort: 37726
    infoSecurePort: 0
  }
  capacity: 1922244395008
  dfsUsed: 49152
  remaining: 1198464253952
  blockPoolUsed: 49152
  lastUpdate: 1606980112278
  xceiverCount: 1
  location: "/default-rack"
  nonDfsUsed: 626088386560
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 141101201
  lastBlockReportTime: 1606980111349
  lastBlockReportMonotonic: 141100272
  numBlocks: 0
}
targets {
  id {
    ipAddr: "127.0.0.1"
    hostName: "127.0.0.1"
    datanodeUuid: "0237cc88-214f-4ecc-9fca-2ef3974ab7eb"
    xferPort: 33330
    infoPort: 37559
    ipcPort: 33221
    infoSecurePort: 0
  }
  capacity: 1922244395008
  dfsUsed: 49152
  remaining: 1198464253952
  blockPoolUsed: 49152
  lastUpdate: 1606980112283
  xceiverCount: 1
  location: "/default-rack"
  nonDfsUsed: 626088386560
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 141101206
  lastBlockReportTime: 1606980111349
  lastBlockReportMonotonic: 141100272
  numBlocks: 0
}
stage: PIPELINE_SETUP_CREATE
pipelineSize: 3
minBytesRcvd: 0
maxBytesRcvd: 0
latestGenerationStamp: 0
requestedChecksum {
  type: CHECKSUM_CRC32C
  bytesPerChecksum: 512
}
cachingStrategy {
}
storageType: DISK
targetStorageTypes: DISK
targetStorageTypes: DISK
allowLazyPersist: false
pinning: false
targetPinnings: false
storageId: "DS-c5bce671-868b-4fa8-afa7-49e9ec5526a2"
targetStorageIds: "DS-1bb59e4f-55f8-43b4-92c0-6f9216074971"
targetStorageIds: "DS-d75ea7b4-2fee-44a5-844d-faa34ba6681d"

2020-12-03 07:21:52,586 [DataXceiver for client DFSClient_NONMAPREDUCE_-391545094_1 at /127.0.0.1:56362 [Receiving block BP-112083932-172.17.0.7-1606980105622:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-112083932-172.17.0.7-1606980105622:blk_1073741826_1002 src: /127.0.0.1:56362 dest: /127.0.0.1:32936
2020-12-03 07:21:52,587 [DataXceiver for client DFSClient_NONMAPREDUCE_-391545094_1 at /127.0.0.1:56362 [Receiving block BP-112083932-172.17.0.7-1606980105622:blk_1073741826_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:52,589 [DataXceiver for client DFSClient_NONMAPREDUCE_-391545094_1 at /127.0.0.1:56362 [Receiving block BP-112083932-172.17.0.7-1606980105622:blk_1073741826_1002]] TRACE datatransfer.DataTransferProtocol (Sender.java:send(79)) - Sending DataTransferOp OpWriteBlockProto: header {
  baseHeader {
    block {
      poolId: "BP-112083932-172.17.0.7-1606980105622"
      blockId: 1073741826
      generationStamp: 1002
      numBytes: 1024
    }
    token {
      identifier: ""
      password: ""
      kind: ""
      service: ""
    }
  }
  clientName: "DFSClient_NONMAPREDUCE_-391545094_1"
}
targets {
  id {
    ipAddr: "127.0.0.1"
    hostName: "127.0.0.1"
    datanodeUuid: "0237cc88-214f-4ecc-9fca-2ef3974ab7eb"
    xferPort: 33330
    infoPort: 37559
    ipcPort: 33221
    infoSecurePort: 0
  }
  capacity: 1922244395008
  dfsUsed: 49152
  remaining: 1198464253952
  blockPoolUsed: 49152
  lastUpdate: 1606980112283
  xceiverCount: 1
  location: "/default-rack"
  nonDfsUsed: 626088386560
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 141101206
  lastBlockReportTime: 1606980111349
  lastBlockReportMonotonic: 141100272
  numBlocks: 0
}
source {
  id {
    ipAddr: ""
    hostName: ""
    datanodeUuid: ""
    xferPort: 0
    infoPort: 0
    ipcPort: 0
    infoSecurePort: 0
  }
  capacity: 0
  dfsUsed: 0
  remaining: 0
  blockPoolUsed: 0
  lastUpdate: 0
  xceiverCount: 0
  nonDfsUsed: 0
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 0
  lastBlockReportTime: 0
  lastBlockReportMonotonic: 0
  numBlocks: 0
}
stage: PIPELINE_SETUP_CREATE
pipelineSize: 3
minBytesRcvd: 0
maxBytesRcvd: 0
latestGenerationStamp: 0
requestedChecksum {
  type: CHECKSUM_CRC32C
  bytesPerChecksum: 512
}
cachingStrategy {
}
storageType: DISK
targetStorageTypes: DISK
allowLazyPersist: false
pinning: false
storageId: "DS-1bb59e4f-55f8-43b4-92c0-6f9216074971"
targetStorageIds: "DS-d75ea7b4-2fee-44a5-844d-faa34ba6681d"

2020-12-03 07:21:52,591 [DataXceiver for client DFSClient_NONMAPREDUCE_-391545094_1 at /127.0.0.1:58278 [Receiving block BP-112083932-172.17.0.7-1606980105622:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-112083932-172.17.0.7-1606980105622:blk_1073741826_1002 src: /127.0.0.1:58278 dest: /127.0.0.1:32811
2020-12-03 07:21:52,592 [DataXceiver for client DFSClient_NONMAPREDUCE_-391545094_1 at /127.0.0.1:58278 [Receiving block BP-112083932-172.17.0.7-1606980105622:blk_1073741826_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:52,594 [DataXceiver for client DFSClient_NONMAPREDUCE_-391545094_1 at /127.0.0.1:58278 [Receiving block BP-112083932-172.17.0.7-1606980105622:blk_1073741826_1002]] TRACE datatransfer.DataTransferProtocol (Sender.java:send(79)) - Sending DataTransferOp OpWriteBlockProto: header {
  baseHeader {
    block {
      poolId: "BP-112083932-172.17.0.7-1606980105622"
      blockId: 1073741826
      generationStamp: 1002
      numBytes: 1024
    }
    token {
      identifier: ""
      password: ""
      kind: ""
      service: ""
    }
  }
  clientName: "DFSClient_NONMAPREDUCE_-391545094_1"
}
source {
  id {
    ipAddr: ""
    hostName: ""
    datanodeUuid: ""
    xferPort: 0
    infoPort: 0
    ipcPort: 0
    infoSecurePort: 0
  }
  capacity: 0
  dfsUsed: 0
  remaining: 0
  blockPoolUsed: 0
  lastUpdate: 0
  xceiverCount: 0
  nonDfsUsed: 0
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 0
  lastBlockReportTime: 0
  lastBlockReportMonotonic: 0
  numBlocks: 0
}
stage: PIPELINE_SETUP_CREATE
pipelineSize: 3
minBytesRcvd: 0
maxBytesRcvd: 0
latestGenerationStamp: 0
requestedChecksum {
  type: CHECKSUM_CRC32C
  bytesPerChecksum: 512
}
cachingStrategy {
}
storageType: DISK
allowLazyPersist: false
pinning: false
storageId: "DS-d75ea7b4-2fee-44a5-844d-faa34ba6681d"

2020-12-03 07:21:52,595 [DataXceiver for client DFSClient_NONMAPREDUCE_-391545094_1 at /127.0.0.1:40814 [Receiving block BP-112083932-172.17.0.7-1606980105622:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-112083932-172.17.0.7-1606980105622:blk_1073741826_1002 src: /127.0.0.1:40814 dest: /127.0.0.1:33330
2020-12-03 07:21:52,606 [PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40814, dest: /127.0.0.1:33330, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-391545094_1, offset: 0, srvID: 0237cc88-214f-4ecc-9fca-2ef3974ab7eb, blockid: BP-112083932-172.17.0.7-1606980105622:blk_1073741826_1002, duration(ns): 9080282
2020-12-03 07:21:52,607 [PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2020-12-03 07:21:52,611 [PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:33330]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58278, dest: /127.0.0.1:32811, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-391545094_1, offset: 0, srvID: d756da44-2378-4af0-be27-9028065cb33e, blockid: BP-112083932-172.17.0.7-1606980105622:blk_1073741826_1002, duration(ns): 13399497
2020-12-03 07:21:52,612 [PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:33330]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:33330] terminating
2020-12-03 07:21:52,616 [PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:32811, 127.0.0.1:33330]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56362, dest: /127.0.0.1:32936, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-391545094_1, offset: 0, srvID: fc258908-e76f-48a7-8279-3420f46782bd, blockid: BP-112083932-172.17.0.7-1606980105622:blk_1073741826_1002, duration(ns): 17588373
2020-12-03 07:21:52,616 [PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:32811, 127.0.0.1:33330]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:32811, 127.0.0.1:33330] terminating
2020-12-03 07:21:52,619 [IPC Server handler 7 on default port 44902] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /cold/file1 is closed by DFSClient_NONMAPREDUCE_-391545094_1
2020-12-03 07:21:52,623 [IPC Server handler 2 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/cold	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:21:52,626 [IPC Server handler 0 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/cold/file2	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:21:52,629 [IPC Server handler 8 on default port 44902] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(427)) - storageTypes={DISK=3}
2020-12-03 07:21:52,630 [IPC Server handler 8 on default port 44902] DEBUG blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseRemoteRack(719)) - Failed to choose remote rack (location = ~/default-rack), fallback to local rack
org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy$NotEnoughReplicasException: 
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRandom(BlockPlacementPolicyDefault.java:852)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRemoteRack(BlockPlacementPolicyDefault.java:714)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTargetInOrder(BlockPlacementPolicyDefault.java:519)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:437)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:309)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:149)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:174)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2211)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2789)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:892)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:574)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
2020-12-03 07:21:52,630 [IPC Server handler 8 on default port 44902] DEBUG blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseRemoteRack(719)) - Failed to choose remote rack (location = ~/default-rack), fallback to local rack
org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy$NotEnoughReplicasException: 
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRandom(BlockPlacementPolicyDefault.java:852)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRemoteRack(BlockPlacementPolicyDefault.java:714)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTargetInOrder(BlockPlacementPolicyDefault.java:528)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:437)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:309)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:149)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:174)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2211)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2789)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:892)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:574)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
2020-12-03 07:21:52,631 [IPC Server handler 8 on default port 44902] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741827_1003, replicas=127.0.0.1:32811, 127.0.0.1:40228, 127.0.0.1:32936 for /cold/file2
2020-12-03 07:21:52,633 [Thread-268] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:52,635 [Thread-268] TRACE datatransfer.DataTransferProtocol (Sender.java:send(79)) - Sending DataTransferOp OpWriteBlockProto: header {
  baseHeader {
    block {
      poolId: "BP-112083932-172.17.0.7-1606980105622"
      blockId: 1073741827
      generationStamp: 1003
      numBytes: 1024
    }
    token {
      identifier: ""
      password: ""
      kind: ""
      service: ""
    }
  }
  clientName: "DFSClient_NONMAPREDUCE_-391545094_1"
}
targets {
  id {
    ipAddr: "127.0.0.1"
    hostName: "127.0.0.1"
    datanodeUuid: "4531fc3a-8c15-42c0-ad49-f6505a50dcea"
    xferPort: 40228
    infoPort: 35466
    ipcPort: 41630
    infoSecurePort: 0
  }
  capacity: 1922244395008
  dfsUsed: 49675
  remaining: 1198464253952
  blockPoolUsed: 49675
  lastUpdate: 1606980112285
  xceiverCount: 1
  location: "/default-rack"
  nonDfsUsed: 626088386037
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 141101208
  lastBlockReportTime: 1606980111349
  lastBlockReportMonotonic: 141100272
  numBlocks: 0
}
targets {
  id {
    ipAddr: "127.0.0.1"
    hostName: "127.0.0.1"
    datanodeUuid: "fc258908-e76f-48a7-8279-3420f46782bd"
    xferPort: 32936
    infoPort: 46144
    ipcPort: 43123
    infoSecurePort: 0
  }
  capacity: 1922244395008
  dfsUsed: 49152
  remaining: 1198464253952
  blockPoolUsed: 49152
  lastUpdate: 1606980112278
  xceiverCount: 1
  location: "/default-rack"
  nonDfsUsed: 626088386560
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 141101200
  lastBlockReportTime: 1606980111349
  lastBlockReportMonotonic: 141100272
  numBlocks: 0
}
stage: PIPELINE_SETUP_CREATE
pipelineSize: 3
minBytesRcvd: 0
maxBytesRcvd: 0
latestGenerationStamp: 0
requestedChecksum {
  type: CHECKSUM_CRC32C
  bytesPerChecksum: 512
}
cachingStrategy {
}
storageType: DISK
targetStorageTypes: DISK
targetStorageTypes: DISK
allowLazyPersist: false
pinning: false
targetPinnings: false
storageId: "DS-1bb59e4f-55f8-43b4-92c0-6f9216074971"
targetStorageIds: "DS-98c5da98-47d1-4ec8-8c42-db45703eedeb"
targetStorageIds: "DS-c5bce671-868b-4fa8-afa7-49e9ec5526a2"

2020-12-03 07:21:52,636 [DataXceiver for client DFSClient_NONMAPREDUCE_-391545094_1 at /127.0.0.1:58282 [Receiving block BP-112083932-172.17.0.7-1606980105622:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-112083932-172.17.0.7-1606980105622:blk_1073741827_1003 src: /127.0.0.1:58282 dest: /127.0.0.1:32811
2020-12-03 07:21:52,637 [DataXceiver for client DFSClient_NONMAPREDUCE_-391545094_1 at /127.0.0.1:58282 [Receiving block BP-112083932-172.17.0.7-1606980105622:blk_1073741827_1003]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:52,640 [DataXceiver for client DFSClient_NONMAPREDUCE_-391545094_1 at /127.0.0.1:58282 [Receiving block BP-112083932-172.17.0.7-1606980105622:blk_1073741827_1003]] TRACE datatransfer.DataTransferProtocol (Sender.java:send(79)) - Sending DataTransferOp OpWriteBlockProto: header {
  baseHeader {
    block {
      poolId: "BP-112083932-172.17.0.7-1606980105622"
      blockId: 1073741827
      generationStamp: 1003
      numBytes: 1024
    }
    token {
      identifier: ""
      password: ""
      kind: ""
      service: ""
    }
  }
  clientName: "DFSClient_NONMAPREDUCE_-391545094_1"
}
targets {
  id {
    ipAddr: "127.0.0.1"
    hostName: "127.0.0.1"
    datanodeUuid: "fc258908-e76f-48a7-8279-3420f46782bd"
    xferPort: 32936
    infoPort: 46144
    ipcPort: 43123
    infoSecurePort: 0
  }
  capacity: 1922244395008
  dfsUsed: 49152
  remaining: 1198464253952
  blockPoolUsed: 49152
  lastUpdate: 1606980112278
  xceiverCount: 1
  location: "/default-rack"
  nonDfsUsed: 626088386560
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 141101200
  lastBlockReportTime: 1606980111349
  lastBlockReportMonotonic: 141100272
  numBlocks: 0
}
source {
  id {
    ipAddr: ""
    hostName: ""
    datanodeUuid: ""
    xferPort: 0
    infoPort: 0
    ipcPort: 0
    infoSecurePort: 0
  }
  capacity: 0
  dfsUsed: 0
  remaining: 0
  blockPoolUsed: 0
  lastUpdate: 0
  xceiverCount: 0
  nonDfsUsed: 0
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 0
  lastBlockReportTime: 0
  lastBlockReportMonotonic: 0
  numBlocks: 0
}
stage: PIPELINE_SETUP_CREATE
pipelineSize: 3
minBytesRcvd: 0
maxBytesRcvd: 0
latestGenerationStamp: 0
requestedChecksum {
  type: CHECKSUM_CRC32C
  bytesPerChecksum: 512
}
cachingStrategy {
}
storageType: DISK
targetStorageTypes: DISK
allowLazyPersist: false
pinning: false
storageId: "DS-98c5da98-47d1-4ec8-8c42-db45703eedeb"
targetStorageIds: "DS-c5bce671-868b-4fa8-afa7-49e9ec5526a2"

2020-12-03 07:21:52,641 [DataXceiver for client DFSClient_NONMAPREDUCE_-391545094_1 at /127.0.0.1:38458 [Receiving block BP-112083932-172.17.0.7-1606980105622:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-112083932-172.17.0.7-1606980105622:blk_1073741827_1003 src: /127.0.0.1:38458 dest: /127.0.0.1:40228
2020-12-03 07:21:52,642 [DataXceiver for client DFSClient_NONMAPREDUCE_-391545094_1 at /127.0.0.1:38458 [Receiving block BP-112083932-172.17.0.7-1606980105622:blk_1073741827_1003]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:52,643 [DataXceiver for client DFSClient_NONMAPREDUCE_-391545094_1 at /127.0.0.1:38458 [Receiving block BP-112083932-172.17.0.7-1606980105622:blk_1073741827_1003]] TRACE datatransfer.DataTransferProtocol (Sender.java:send(79)) - Sending DataTransferOp OpWriteBlockProto: header {
  baseHeader {
    block {
      poolId: "BP-112083932-172.17.0.7-1606980105622"
      blockId: 1073741827
      generationStamp: 1003
      numBytes: 1024
    }
    token {
      identifier: ""
      password: ""
      kind: ""
      service: ""
    }
  }
  clientName: "DFSClient_NONMAPREDUCE_-391545094_1"
}
source {
  id {
    ipAddr: ""
    hostName: ""
    datanodeUuid: ""
    xferPort: 0
    infoPort: 0
    ipcPort: 0
    infoSecurePort: 0
  }
  capacity: 0
  dfsUsed: 0
  remaining: 0
  blockPoolUsed: 0
  lastUpdate: 0
  xceiverCount: 0
  nonDfsUsed: 0
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 0
  lastBlockReportTime: 0
  lastBlockReportMonotonic: 0
  numBlocks: 0
}
stage: PIPELINE_SETUP_CREATE
pipelineSize: 3
minBytesRcvd: 0
maxBytesRcvd: 0
latestGenerationStamp: 0
requestedChecksum {
  type: CHECKSUM_CRC32C
  bytesPerChecksum: 512
}
cachingStrategy {
}
storageType: DISK
allowLazyPersist: false
pinning: false
storageId: "DS-c5bce671-868b-4fa8-afa7-49e9ec5526a2"

2020-12-03 07:21:52,644 [DataXceiver for client DFSClient_NONMAPREDUCE_-391545094_1 at /127.0.0.1:56372 [Receiving block BP-112083932-172.17.0.7-1606980105622:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-112083932-172.17.0.7-1606980105622:blk_1073741827_1003 src: /127.0.0.1:56372 dest: /127.0.0.1:32936
2020-12-03 07:21:52,657 [PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56372, dest: /127.0.0.1:32936, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-391545094_1, offset: 0, srvID: fc258908-e76f-48a7-8279-3420f46782bd, blockid: BP-112083932-172.17.0.7-1606980105622:blk_1073741827_1003, duration(ns): 9914287
2020-12-03 07:21:52,657 [PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741827_1003, type=LAST_IN_PIPELINE terminating
2020-12-03 07:21:52,660 [PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:32936]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38458, dest: /127.0.0.1:40228, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-391545094_1, offset: 0, srvID: 4531fc3a-8c15-42c0-ad49-f6505a50dcea, blockid: BP-112083932-172.17.0.7-1606980105622:blk_1073741827_1003, duration(ns): 12922490
2020-12-03 07:21:52,660 [PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:32936]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:32936] terminating
2020-12-03 07:21:52,670 [PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:40228, 127.0.0.1:32936]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58282, dest: /127.0.0.1:32811, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-391545094_1, offset: 0, srvID: d756da44-2378-4af0-be27-9028065cb33e, blockid: BP-112083932-172.17.0.7-1606980105622:blk_1073741827_1003, duration(ns): 17483442
2020-12-03 07:21:52,670 [PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:40228, 127.0.0.1:32936]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:40228, 127.0.0.1:32936] terminating
2020-12-03 07:21:52,672 [IPC Server handler 6 on default port 44902] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /cold/file2 is closed by DFSClient_NONMAPREDUCE_-391545094_1
2020-12-03 07:21:52,675 [IPC Server handler 5 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/hot	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:21:52,677 [IPC Server handler 1 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/hot/file0	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:21:52,690 [IPC Server handler 7 on default port 44902] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(427)) - storageTypes={DISK=3}
2020-12-03 07:21:52,692 [IPC Server handler 7 on default port 44902] DEBUG blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseRemoteRack(719)) - Failed to choose remote rack (location = ~/default-rack), fallback to local rack
org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy$NotEnoughReplicasException: 
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRandom(BlockPlacementPolicyDefault.java:852)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRemoteRack(BlockPlacementPolicyDefault.java:714)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTargetInOrder(BlockPlacementPolicyDefault.java:519)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:437)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:309)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:149)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:174)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2211)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2789)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:892)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:574)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
2020-12-03 07:21:52,693 [IPC Server handler 7 on default port 44902] DEBUG blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseRemoteRack(719)) - Failed to choose remote rack (location = ~/default-rack), fallback to local rack
org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy$NotEnoughReplicasException: 
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRandom(BlockPlacementPolicyDefault.java:852)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRemoteRack(BlockPlacementPolicyDefault.java:714)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTargetInOrder(BlockPlacementPolicyDefault.java:528)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:437)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:309)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:149)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:174)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2211)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2789)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:892)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:574)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
2020-12-03 07:21:52,695 [IPC Server handler 7 on default port 44902] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741828_1004, replicas=127.0.0.1:46191, 127.0.0.1:32936, 127.0.0.1:40228 for /hot/file0
2020-12-03 07:21:52,699 [Thread-276] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:52,741 [Thread-276] TRACE datatransfer.DataTransferProtocol (Sender.java:send(79)) - Sending DataTransferOp OpWriteBlockProto: header {
  baseHeader {
    block {
      poolId: "BP-112083932-172.17.0.7-1606980105622"
      blockId: 1073741828
      generationStamp: 1004
      numBytes: 1024
    }
    token {
      identifier: ""
      password: ""
      kind: ""
      service: ""
    }
  }
  clientName: "DFSClient_NONMAPREDUCE_-391545094_1"
}
targets {
  id {
    ipAddr: "127.0.0.1"
    hostName: "127.0.0.1"
    datanodeUuid: "fc258908-e76f-48a7-8279-3420f46782bd"
    xferPort: 32936
    infoPort: 46144
    ipcPort: 43123
    infoSecurePort: 0
  }
  capacity: 1922244395008
  dfsUsed: 49152
  remaining: 1198464253952
  blockPoolUsed: 49152
  lastUpdate: 1606980112278
  xceiverCount: 1
  location: "/default-rack"
  nonDfsUsed: 626088386560
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 141101200
  lastBlockReportTime: 1606980111349
  lastBlockReportMonotonic: 141100272
  numBlocks: 0
}
targets {
  id {
    ipAddr: "127.0.0.1"
    hostName: "127.0.0.1"
    datanodeUuid: "4531fc3a-8c15-42c0-ad49-f6505a50dcea"
    xferPort: 40228
    infoPort: 35466
    ipcPort: 41630
    infoSecurePort: 0
  }
  capacity: 1922244395008
  dfsUsed: 49675
  remaining: 1198464253952
  blockPoolUsed: 49675
  lastUpdate: 1606980112285
  xceiverCount: 1
  location: "/default-rack"
  nonDfsUsed: 626088386037
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 141101208
  lastBlockReportTime: 1606980111349
  lastBlockReportMonotonic: 141100272
  numBlocks: 0
}
stage: PIPELINE_SETUP_CREATE
pipelineSize: 3
minBytesRcvd: 0
maxBytesRcvd: 0
latestGenerationStamp: 0
requestedChecksum {
  type: CHECKSUM_CRC32C
  bytesPerChecksum: 512
}
cachingStrategy {
}
storageType: DISK
targetStorageTypes: DISK
targetStorageTypes: DISK
allowLazyPersist: false
pinning: false
targetPinnings: false
storageId: "DS-dfbdbbaa-c98a-4ba8-8504-1c726531280a"
targetStorageIds: "DS-c5bce671-868b-4fa8-afa7-49e9ec5526a2"
targetStorageIds: "DS-98c5da98-47d1-4ec8-8c42-db45703eedeb"

2020-12-03 07:21:52,743 [DataXceiver for client DFSClient_NONMAPREDUCE_-391545094_1 at /127.0.0.1:58294 [Receiving block BP-112083932-172.17.0.7-1606980105622:blk_1073741828_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-112083932-172.17.0.7-1606980105622:blk_1073741828_1004 src: /127.0.0.1:58294 dest: /127.0.0.1:46191
2020-12-03 07:21:52,744 [DataXceiver for client DFSClient_NONMAPREDUCE_-391545094_1 at /127.0.0.1:58294 [Receiving block BP-112083932-172.17.0.7-1606980105622:blk_1073741828_1004]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:52,746 [DataXceiver for client DFSClient_NONMAPREDUCE_-391545094_1 at /127.0.0.1:58294 [Receiving block BP-112083932-172.17.0.7-1606980105622:blk_1073741828_1004]] TRACE datatransfer.DataTransferProtocol (Sender.java:send(79)) - Sending DataTransferOp OpWriteBlockProto: header {
  baseHeader {
    block {
      poolId: "BP-112083932-172.17.0.7-1606980105622"
      blockId: 1073741828
      generationStamp: 1004
      numBytes: 1024
    }
    token {
      identifier: ""
      password: ""
      kind: ""
      service: ""
    }
  }
  clientName: "DFSClient_NONMAPREDUCE_-391545094_1"
}
targets {
  id {
    ipAddr: "127.0.0.1"
    hostName: "127.0.0.1"
    datanodeUuid: "4531fc3a-8c15-42c0-ad49-f6505a50dcea"
    xferPort: 40228
    infoPort: 35466
    ipcPort: 41630
    infoSecurePort: 0
  }
  capacity: 1922244395008
  dfsUsed: 49675
  remaining: 1198464253952
  blockPoolUsed: 49675
  lastUpdate: 1606980112285
  xceiverCount: 1
  location: "/default-rack"
  nonDfsUsed: 626088386037
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 141101208
  lastBlockReportTime: 1606980111349
  lastBlockReportMonotonic: 141100272
  numBlocks: 0
}
source {
  id {
    ipAddr: ""
    hostName: ""
    datanodeUuid: ""
    xferPort: 0
    infoPort: 0
    ipcPort: 0
    infoSecurePort: 0
  }
  capacity: 0
  dfsUsed: 0
  remaining: 0
  blockPoolUsed: 0
  lastUpdate: 0
  xceiverCount: 0
  nonDfsUsed: 0
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 0
  lastBlockReportTime: 0
  lastBlockReportMonotonic: 0
  numBlocks: 0
}
stage: PIPELINE_SETUP_CREATE
pipelineSize: 3
minBytesRcvd: 0
maxBytesRcvd: 0
latestGenerationStamp: 0
requestedChecksum {
  type: CHECKSUM_CRC32C
  bytesPerChecksum: 512
}
cachingStrategy {
}
storageType: DISK
targetStorageTypes: DISK
allowLazyPersist: false
pinning: false
storageId: "DS-c5bce671-868b-4fa8-afa7-49e9ec5526a2"
targetStorageIds: "DS-98c5da98-47d1-4ec8-8c42-db45703eedeb"

2020-12-03 07:21:52,751 [DataXceiver for client DFSClient_NONMAPREDUCE_-391545094_1 at /127.0.0.1:56376 [Receiving block BP-112083932-172.17.0.7-1606980105622:blk_1073741828_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-112083932-172.17.0.7-1606980105622:blk_1073741828_1004 src: /127.0.0.1:56376 dest: /127.0.0.1:32936
2020-12-03 07:21:52,769 [DataXceiver for client DFSClient_NONMAPREDUCE_-391545094_1 at /127.0.0.1:56376 [Receiving block BP-112083932-172.17.0.7-1606980105622:blk_1073741828_1004]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:52,771 [DataXceiver for client DFSClient_NONMAPREDUCE_-391545094_1 at /127.0.0.1:56376 [Receiving block BP-112083932-172.17.0.7-1606980105622:blk_1073741828_1004]] TRACE datatransfer.DataTransferProtocol (Sender.java:send(79)) - Sending DataTransferOp OpWriteBlockProto: header {
  baseHeader {
    block {
      poolId: "BP-112083932-172.17.0.7-1606980105622"
      blockId: 1073741828
      generationStamp: 1004
      numBytes: 1024
    }
    token {
      identifier: ""
      password: ""
      kind: ""
      service: ""
    }
  }
  clientName: "DFSClient_NONMAPREDUCE_-391545094_1"
}
source {
  id {
    ipAddr: ""
    hostName: ""
    datanodeUuid: ""
    xferPort: 0
    infoPort: 0
    ipcPort: 0
    infoSecurePort: 0
  }
  capacity: 0
  dfsUsed: 0
  remaining: 0
  blockPoolUsed: 0
  lastUpdate: 0
  xceiverCount: 0
  nonDfsUsed: 0
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 0
  lastBlockReportTime: 0
  lastBlockReportMonotonic: 0
  numBlocks: 0
}
stage: PIPELINE_SETUP_CREATE
pipelineSize: 3
minBytesRcvd: 0
maxBytesRcvd: 0
latestGenerationStamp: 0
requestedChecksum {
  type: CHECKSUM_CRC32C
  bytesPerChecksum: 512
}
cachingStrategy {
}
storageType: DISK
allowLazyPersist: false
pinning: false
storageId: "DS-98c5da98-47d1-4ec8-8c42-db45703eedeb"

2020-12-03 07:21:52,781 [DataXceiver for client DFSClient_NONMAPREDUCE_-391545094_1 at /127.0.0.1:38466 [Receiving block BP-112083932-172.17.0.7-1606980105622:blk_1073741828_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-112083932-172.17.0.7-1606980105622:blk_1073741828_1004 src: /127.0.0.1:38466 dest: /127.0.0.1:40228
2020-12-03 07:21:52,829 [PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741828_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38466, dest: /127.0.0.1:40228, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-391545094_1, offset: 0, srvID: 4531fc3a-8c15-42c0-ad49-f6505a50dcea, blockid: BP-112083932-172.17.0.7-1606980105622:blk_1073741828_1004, duration(ns): 44286586
2020-12-03 07:21:52,831 [PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741828_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741828_1004, type=LAST_IN_PIPELINE terminating
2020-12-03 07:21:52,833 [PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40228]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56376, dest: /127.0.0.1:32936, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-391545094_1, offset: 0, srvID: fc258908-e76f-48a7-8279-3420f46782bd, blockid: BP-112083932-172.17.0.7-1606980105622:blk_1073741828_1004, duration(ns): 47624840
2020-12-03 07:21:52,833 [PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40228]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40228] terminating
2020-12-03 07:21:52,837 [PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:32936, 127.0.0.1:40228]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58294, dest: /127.0.0.1:46191, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-391545094_1, offset: 0, srvID: 7b793216-748f-4be6-a144-367935ffbafb, blockid: BP-112083932-172.17.0.7-1606980105622:blk_1073741828_1004, duration(ns): 52317078
2020-12-03 07:21:52,838 [PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:32936, 127.0.0.1:40228]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:32936, 127.0.0.1:40228] terminating
2020-12-03 07:21:52,840 [IPC Server handler 9 on default port 44902] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /hot/file0 is closed by DFSClient_NONMAPREDUCE_-391545094_1
2020-12-03 07:21:52,843 [IPC Server handler 4 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/hot	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:21:52,846 [IPC Server handler 3 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/hot/file1	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:21:52,852 [IPC Server handler 6 on default port 44902] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(427)) - storageTypes={DISK=3}
2020-12-03 07:21:52,852 [IPC Server handler 6 on default port 44902] DEBUG blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseRemoteRack(719)) - Failed to choose remote rack (location = ~/default-rack), fallback to local rack
org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy$NotEnoughReplicasException: 
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRandom(BlockPlacementPolicyDefault.java:852)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRemoteRack(BlockPlacementPolicyDefault.java:714)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTargetInOrder(BlockPlacementPolicyDefault.java:519)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:437)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:309)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:149)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:174)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2211)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2789)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:892)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:574)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
2020-12-03 07:21:52,853 [IPC Server handler 6 on default port 44902] DEBUG blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseRemoteRack(719)) - Failed to choose remote rack (location = ~/default-rack), fallback to local rack
org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy$NotEnoughReplicasException: 
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRandom(BlockPlacementPolicyDefault.java:852)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRemoteRack(BlockPlacementPolicyDefault.java:714)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTargetInOrder(BlockPlacementPolicyDefault.java:528)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:437)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:309)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:149)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:174)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2211)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2789)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:892)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:574)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
2020-12-03 07:21:52,854 [IPC Server handler 6 on default port 44902] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741829_1005, replicas=127.0.0.1:40228, 127.0.0.1:46191, 127.0.0.1:32936 for /hot/file1
2020-12-03 07:21:52,857 [Thread-284] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:52,859 [Thread-284] TRACE datatransfer.DataTransferProtocol (Sender.java:send(79)) - Sending DataTransferOp OpWriteBlockProto: header {
  baseHeader {
    block {
      poolId: "BP-112083932-172.17.0.7-1606980105622"
      blockId: 1073741829
      generationStamp: 1005
      numBytes: 1024
    }
    token {
      identifier: ""
      password: ""
      kind: ""
      service: ""
    }
  }
  clientName: "DFSClient_NONMAPREDUCE_-391545094_1"
}
targets {
  id {
    ipAddr: "127.0.0.1"
    hostName: "127.0.0.1"
    datanodeUuid: "7b793216-748f-4be6-a144-367935ffbafb"
    xferPort: 46191
    infoPort: 38566
    ipcPort: 41609
    infoSecurePort: 0
  }
  capacity: 1922244395008
  dfsUsed: 49675
  remaining: 1198464253952
  blockPoolUsed: 49675
  lastUpdate: 1606980112280
  xceiverCount: 1
  location: "/default-rack"
  nonDfsUsed: 626088386037
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 141101203
  lastBlockReportTime: 1606980111349
  lastBlockReportMonotonic: 141100272
  numBlocks: 0
}
targets {
  id {
    ipAddr: "127.0.0.1"
    hostName: "127.0.0.1"
    datanodeUuid: "fc258908-e76f-48a7-8279-3420f46782bd"
    xferPort: 32936
    infoPort: 46144
    ipcPort: 43123
    infoSecurePort: 0
  }
  capacity: 1922244395008
  dfsUsed: 49152
  remaining: 1198464253952
  blockPoolUsed: 49152
  lastUpdate: 1606980112278
  xceiverCount: 1
  location: "/default-rack"
  nonDfsUsed: 626088386560
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 141101200
  lastBlockReportTime: 1606980111349
  lastBlockReportMonotonic: 141100272
  numBlocks: 0
}
stage: PIPELINE_SETUP_CREATE
pipelineSize: 3
minBytesRcvd: 0
maxBytesRcvd: 0
latestGenerationStamp: 0
requestedChecksum {
  type: CHECKSUM_CRC32C
  bytesPerChecksum: 512
}
cachingStrategy {
}
storageType: DISK
targetStorageTypes: DISK
targetStorageTypes: DISK
allowLazyPersist: false
pinning: false
targetPinnings: false
storageId: "DS-98c5da98-47d1-4ec8-8c42-db45703eedeb"
targetStorageIds: "DS-dfbdbbaa-c98a-4ba8-8504-1c726531280a"
targetStorageIds: "DS-c5bce671-868b-4fa8-afa7-49e9ec5526a2"

2020-12-03 07:21:52,860 [DataXceiver for client DFSClient_NONMAPREDUCE_-391545094_1 at /127.0.0.1:38470 [Receiving block BP-112083932-172.17.0.7-1606980105622:blk_1073741829_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-112083932-172.17.0.7-1606980105622:blk_1073741829_1005 src: /127.0.0.1:38470 dest: /127.0.0.1:40228
2020-12-03 07:21:52,861 [DataXceiver for client DFSClient_NONMAPREDUCE_-391545094_1 at /127.0.0.1:38470 [Receiving block BP-112083932-172.17.0.7-1606980105622:blk_1073741829_1005]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:52,863 [DataXceiver for client DFSClient_NONMAPREDUCE_-391545094_1 at /127.0.0.1:38470 [Receiving block BP-112083932-172.17.0.7-1606980105622:blk_1073741829_1005]] TRACE datatransfer.DataTransferProtocol (Sender.java:send(79)) - Sending DataTransferOp OpWriteBlockProto: header {
  baseHeader {
    block {
      poolId: "BP-112083932-172.17.0.7-1606980105622"
      blockId: 1073741829
      generationStamp: 1005
      numBytes: 1024
    }
    token {
      identifier: ""
      password: ""
      kind: ""
      service: ""
    }
  }
  clientName: "DFSClient_NONMAPREDUCE_-391545094_1"
}
targets {
  id {
    ipAddr: "127.0.0.1"
    hostName: "127.0.0.1"
    datanodeUuid: "fc258908-e76f-48a7-8279-3420f46782bd"
    xferPort: 32936
    infoPort: 46144
    ipcPort: 43123
    infoSecurePort: 0
  }
  capacity: 1922244395008
  dfsUsed: 49152
  remaining: 1198464253952
  blockPoolUsed: 49152
  lastUpdate: 1606980112278
  xceiverCount: 1
  location: "/default-rack"
  nonDfsUsed: 626088386560
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 141101200
  lastBlockReportTime: 1606980111349
  lastBlockReportMonotonic: 141100272
  numBlocks: 0
}
source {
  id {
    ipAddr: ""
    hostName: ""
    datanodeUuid: ""
    xferPort: 0
    infoPort: 0
    ipcPort: 0
    infoSecurePort: 0
  }
  capacity: 0
  dfsUsed: 0
  remaining: 0
  blockPoolUsed: 0
  lastUpdate: 0
  xceiverCount: 0
  nonDfsUsed: 0
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 0
  lastBlockReportTime: 0
  lastBlockReportMonotonic: 0
  numBlocks: 0
}
stage: PIPELINE_SETUP_CREATE
pipelineSize: 3
minBytesRcvd: 0
maxBytesRcvd: 0
latestGenerationStamp: 0
requestedChecksum {
  type: CHECKSUM_CRC32C
  bytesPerChecksum: 512
}
cachingStrategy {
}
storageType: DISK
targetStorageTypes: DISK
allowLazyPersist: false
pinning: false
storageId: "DS-dfbdbbaa-c98a-4ba8-8504-1c726531280a"
targetStorageIds: "DS-c5bce671-868b-4fa8-afa7-49e9ec5526a2"

2020-12-03 07:21:52,864 [DataXceiver for client DFSClient_NONMAPREDUCE_-391545094_1 at /127.0.0.1:58304 [Receiving block BP-112083932-172.17.0.7-1606980105622:blk_1073741829_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-112083932-172.17.0.7-1606980105622:blk_1073741829_1005 src: /127.0.0.1:58304 dest: /127.0.0.1:46191
2020-12-03 07:21:52,866 [DataXceiver for client DFSClient_NONMAPREDUCE_-391545094_1 at /127.0.0.1:58304 [Receiving block BP-112083932-172.17.0.7-1606980105622:blk_1073741829_1005]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:52,868 [DataXceiver for client DFSClient_NONMAPREDUCE_-391545094_1 at /127.0.0.1:58304 [Receiving block BP-112083932-172.17.0.7-1606980105622:blk_1073741829_1005]] TRACE datatransfer.DataTransferProtocol (Sender.java:send(79)) - Sending DataTransferOp OpWriteBlockProto: header {
  baseHeader {
    block {
      poolId: "BP-112083932-172.17.0.7-1606980105622"
      blockId: 1073741829
      generationStamp: 1005
      numBytes: 1024
    }
    token {
      identifier: ""
      password: ""
      kind: ""
      service: ""
    }
  }
  clientName: "DFSClient_NONMAPREDUCE_-391545094_1"
}
source {
  id {
    ipAddr: ""
    hostName: ""
    datanodeUuid: ""
    xferPort: 0
    infoPort: 0
    ipcPort: 0
    infoSecurePort: 0
  }
  capacity: 0
  dfsUsed: 0
  remaining: 0
  blockPoolUsed: 0
  lastUpdate: 0
  xceiverCount: 0
  nonDfsUsed: 0
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 0
  lastBlockReportTime: 0
  lastBlockReportMonotonic: 0
  numBlocks: 0
}
stage: PIPELINE_SETUP_CREATE
pipelineSize: 3
minBytesRcvd: 0
maxBytesRcvd: 0
latestGenerationStamp: 0
requestedChecksum {
  type: CHECKSUM_CRC32C
  bytesPerChecksum: 512
}
cachingStrategy {
}
storageType: DISK
allowLazyPersist: false
pinning: false
storageId: "DS-c5bce671-868b-4fa8-afa7-49e9ec5526a2"

2020-12-03 07:21:52,871 [DataXceiver for client DFSClient_NONMAPREDUCE_-391545094_1 at /127.0.0.1:56386 [Receiving block BP-112083932-172.17.0.7-1606980105622:blk_1073741829_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-112083932-172.17.0.7-1606980105622:blk_1073741829_1005 src: /127.0.0.1:56386 dest: /127.0.0.1:32936
2020-12-03 07:21:52,887 [PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741829_1005, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56386, dest: /127.0.0.1:32936, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-391545094_1, offset: 0, srvID: fc258908-e76f-48a7-8279-3420f46782bd, blockid: BP-112083932-172.17.0.7-1606980105622:blk_1073741829_1005, duration(ns): 12770916
2020-12-03 07:21:52,888 [PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741829_1005, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741829_1005, type=LAST_IN_PIPELINE terminating
2020-12-03 07:21:52,890 [PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:32936]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58304, dest: /127.0.0.1:46191, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-391545094_1, offset: 0, srvID: 7b793216-748f-4be6-a144-367935ffbafb, blockid: BP-112083932-172.17.0.7-1606980105622:blk_1073741829_1005, duration(ns): 14333751
2020-12-03 07:21:52,890 [PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:32936]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:32936] terminating
2020-12-03 07:21:52,893 [PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46191, 127.0.0.1:32936]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38470, dest: /127.0.0.1:40228, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-391545094_1, offset: 0, srvID: 4531fc3a-8c15-42c0-ad49-f6505a50dcea, blockid: BP-112083932-172.17.0.7-1606980105622:blk_1073741829_1005, duration(ns): 16733412
2020-12-03 07:21:52,893 [PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46191, 127.0.0.1:32936]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46191, 127.0.0.1:32936] terminating
2020-12-03 07:21:52,896 [IPC Server handler 2 on default port 44902] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /hot/file1 is closed by DFSClient_NONMAPREDUCE_-391545094_1
2020-12-03 07:21:52,902 [IPC Server handler 0 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/hot	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:21:52,905 [IPC Server handler 8 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/hot/file2	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:21:52,917 [IPC Server handler 9 on default port 44902] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(427)) - storageTypes={DISK=3}
2020-12-03 07:21:52,918 [IPC Server handler 9 on default port 44902] DEBUG blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseRemoteRack(719)) - Failed to choose remote rack (location = ~/default-rack), fallback to local rack
org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy$NotEnoughReplicasException: 
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRandom(BlockPlacementPolicyDefault.java:852)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRemoteRack(BlockPlacementPolicyDefault.java:714)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTargetInOrder(BlockPlacementPolicyDefault.java:519)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:437)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:309)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:149)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:174)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2211)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2789)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:892)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:574)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
2020-12-03 07:21:52,919 [IPC Server handler 9 on default port 44902] DEBUG blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseRemoteRack(719)) - Failed to choose remote rack (location = ~/default-rack), fallback to local rack
org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy$NotEnoughReplicasException: 
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRandom(BlockPlacementPolicyDefault.java:852)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRemoteRack(BlockPlacementPolicyDefault.java:714)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTargetInOrder(BlockPlacementPolicyDefault.java:528)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:437)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:309)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:149)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:174)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2211)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2789)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:892)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:574)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
2020-12-03 07:21:52,922 [IPC Server handler 9 on default port 44902] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741830_1006, replicas=127.0.0.1:32811, 127.0.0.1:40228, 127.0.0.1:33330 for /hot/file2
2020-12-03 07:21:52,925 [Thread-292] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:52,950 [Thread-292] TRACE datatransfer.DataTransferProtocol (Sender.java:send(79)) - Sending DataTransferOp OpWriteBlockProto: header {
  baseHeader {
    block {
      poolId: "BP-112083932-172.17.0.7-1606980105622"
      blockId: 1073741830
      generationStamp: 1006
      numBytes: 1024
    }
    token {
      identifier: ""
      password: ""
      kind: ""
      service: ""
    }
  }
  clientName: "DFSClient_NONMAPREDUCE_-391545094_1"
}
targets {
  id {
    ipAddr: "127.0.0.1"
    hostName: "127.0.0.1"
    datanodeUuid: "4531fc3a-8c15-42c0-ad49-f6505a50dcea"
    xferPort: 40228
    infoPort: 35466
    ipcPort: 41630
    infoSecurePort: 0
  }
  capacity: 1922244395008
  dfsUsed: 49675
  remaining: 1198464253952
  blockPoolUsed: 49675
  lastUpdate: 1606980112285
  xceiverCount: 1
  location: "/default-rack"
  nonDfsUsed: 626088386037
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 141101208
  lastBlockReportTime: 1606980111349
  lastBlockReportMonotonic: 141100272
  numBlocks: 0
}
targets {
  id {
    ipAddr: "127.0.0.1"
    hostName: "127.0.0.1"
    datanodeUuid: "0237cc88-214f-4ecc-9fca-2ef3974ab7eb"
    xferPort: 33330
    infoPort: 37559
    ipcPort: 33221
    infoSecurePort: 0
  }
  capacity: 1922244395008
  dfsUsed: 49152
  remaining: 1198464253952
  blockPoolUsed: 49152
  lastUpdate: 1606980112283
  xceiverCount: 1
  location: "/default-rack"
  nonDfsUsed: 626088386560
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 141101206
  lastBlockReportTime: 1606980111349
  lastBlockReportMonotonic: 141100272
  numBlocks: 0
}
stage: PIPELINE_SETUP_CREATE
pipelineSize: 3
minBytesRcvd: 0
maxBytesRcvd: 0
latestGenerationStamp: 0
requestedChecksum {
  type: CHECKSUM_CRC32C
  bytesPerChecksum: 512
}
cachingStrategy {
}
storageType: DISK
targetStorageTypes: DISK
targetStorageTypes: DISK
allowLazyPersist: false
pinning: false
targetPinnings: false
storageId: "DS-1bb59e4f-55f8-43b4-92c0-6f9216074971"
targetStorageIds: "DS-98c5da98-47d1-4ec8-8c42-db45703eedeb"
targetStorageIds: "DS-d75ea7b4-2fee-44a5-844d-faa34ba6681d"

2020-12-03 07:21:52,952 [DataXceiver for client DFSClient_NONMAPREDUCE_-391545094_1 at /127.0.0.1:58302 [Receiving block BP-112083932-172.17.0.7-1606980105622:blk_1073741830_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-112083932-172.17.0.7-1606980105622:blk_1073741830_1006 src: /127.0.0.1:58302 dest: /127.0.0.1:32811
2020-12-03 07:21:52,953 [DataXceiver for client DFSClient_NONMAPREDUCE_-391545094_1 at /127.0.0.1:58302 [Receiving block BP-112083932-172.17.0.7-1606980105622:blk_1073741830_1006]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:52,957 [DataXceiver for client DFSClient_NONMAPREDUCE_-391545094_1 at /127.0.0.1:58302 [Receiving block BP-112083932-172.17.0.7-1606980105622:blk_1073741830_1006]] TRACE datatransfer.DataTransferProtocol (Sender.java:send(79)) - Sending DataTransferOp OpWriteBlockProto: header {
  baseHeader {
    block {
      poolId: "BP-112083932-172.17.0.7-1606980105622"
      blockId: 1073741830
      generationStamp: 1006
      numBytes: 1024
    }
    token {
      identifier: ""
      password: ""
      kind: ""
      service: ""
    }
  }
  clientName: "DFSClient_NONMAPREDUCE_-391545094_1"
}
targets {
  id {
    ipAddr: "127.0.0.1"
    hostName: "127.0.0.1"
    datanodeUuid: "0237cc88-214f-4ecc-9fca-2ef3974ab7eb"
    xferPort: 33330
    infoPort: 37559
    ipcPort: 33221
    infoSecurePort: 0
  }
  capacity: 1922244395008
  dfsUsed: 49152
  remaining: 1198464253952
  blockPoolUsed: 49152
  lastUpdate: 1606980112283
  xceiverCount: 1
  location: "/default-rack"
  nonDfsUsed: 626088386560
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 141101206
  lastBlockReportTime: 1606980111349
  lastBlockReportMonotonic: 141100272
  numBlocks: 0
}
source {
  id {
    ipAddr: ""
    hostName: ""
    datanodeUuid: ""
    xferPort: 0
    infoPort: 0
    ipcPort: 0
    infoSecurePort: 0
  }
  capacity: 0
  dfsUsed: 0
  remaining: 0
  blockPoolUsed: 0
  lastUpdate: 0
  xceiverCount: 0
  nonDfsUsed: 0
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 0
  lastBlockReportTime: 0
  lastBlockReportMonotonic: 0
  numBlocks: 0
}
stage: PIPELINE_SETUP_CREATE
pipelineSize: 3
minBytesRcvd: 0
maxBytesRcvd: 0
latestGenerationStamp: 0
requestedChecksum {
  type: CHECKSUM_CRC32C
  bytesPerChecksum: 512
}
cachingStrategy {
}
storageType: DISK
targetStorageTypes: DISK
allowLazyPersist: false
pinning: false
storageId: "DS-98c5da98-47d1-4ec8-8c42-db45703eedeb"
targetStorageIds: "DS-d75ea7b4-2fee-44a5-844d-faa34ba6681d"

2020-12-03 07:21:52,959 [DataXceiver for client DFSClient_NONMAPREDUCE_-391545094_1 at /127.0.0.1:38478 [Receiving block BP-112083932-172.17.0.7-1606980105622:blk_1073741830_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-112083932-172.17.0.7-1606980105622:blk_1073741830_1006 src: /127.0.0.1:38478 dest: /127.0.0.1:40228
2020-12-03 07:21:52,962 [DataXceiver for client DFSClient_NONMAPREDUCE_-391545094_1 at /127.0.0.1:38478 [Receiving block BP-112083932-172.17.0.7-1606980105622:blk_1073741830_1006]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:52,963 [DataXceiver for client DFSClient_NONMAPREDUCE_-391545094_1 at /127.0.0.1:38478 [Receiving block BP-112083932-172.17.0.7-1606980105622:blk_1073741830_1006]] TRACE datatransfer.DataTransferProtocol (Sender.java:send(79)) - Sending DataTransferOp OpWriteBlockProto: header {
  baseHeader {
    block {
      poolId: "BP-112083932-172.17.0.7-1606980105622"
      blockId: 1073741830
      generationStamp: 1006
      numBytes: 1024
    }
    token {
      identifier: ""
      password: ""
      kind: ""
      service: ""
    }
  }
  clientName: "DFSClient_NONMAPREDUCE_-391545094_1"
}
source {
  id {
    ipAddr: ""
    hostName: ""
    datanodeUuid: ""
    xferPort: 0
    infoPort: 0
    ipcPort: 0
    infoSecurePort: 0
  }
  capacity: 0
  dfsUsed: 0
  remaining: 0
  blockPoolUsed: 0
  lastUpdate: 0
  xceiverCount: 0
  nonDfsUsed: 0
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 0
  lastBlockReportTime: 0
  lastBlockReportMonotonic: 0
  numBlocks: 0
}
stage: PIPELINE_SETUP_CREATE
pipelineSize: 3
minBytesRcvd: 0
maxBytesRcvd: 0
latestGenerationStamp: 0
requestedChecksum {
  type: CHECKSUM_CRC32C
  bytesPerChecksum: 512
}
cachingStrategy {
}
storageType: DISK
allowLazyPersist: false
pinning: false
storageId: "DS-d75ea7b4-2fee-44a5-844d-faa34ba6681d"

2020-12-03 07:21:52,965 [DataXceiver for client DFSClient_NONMAPREDUCE_-391545094_1 at /127.0.0.1:40840 [Receiving block BP-112083932-172.17.0.7-1606980105622:blk_1073741830_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-112083932-172.17.0.7-1606980105622:blk_1073741830_1006 src: /127.0.0.1:40840 dest: /127.0.0.1:33330
2020-12-03 07:21:52,990 [PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741830_1006, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40840, dest: /127.0.0.1:33330, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-391545094_1, offset: 0, srvID: 0237cc88-214f-4ecc-9fca-2ef3974ab7eb, blockid: BP-112083932-172.17.0.7-1606980105622:blk_1073741830_1006, duration(ns): 19407763
2020-12-03 07:21:52,991 [PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741830_1006, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741830_1006, type=LAST_IN_PIPELINE terminating
2020-12-03 07:21:52,994 [PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:33330]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38478, dest: /127.0.0.1:40228, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-391545094_1, offset: 0, srvID: 4531fc3a-8c15-42c0-ad49-f6505a50dcea, blockid: BP-112083932-172.17.0.7-1606980105622:blk_1073741830_1006, duration(ns): 23333182
2020-12-03 07:21:52,995 [PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:33330]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:33330] terminating
2020-12-03 07:21:52,998 [PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:40228, 127.0.0.1:33330]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58302, dest: /127.0.0.1:32811, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-391545094_1, offset: 0, srvID: d756da44-2378-4af0-be27-9028065cb33e, blockid: BP-112083932-172.17.0.7-1606980105622:blk_1073741830_1006, duration(ns): 24491930
2020-12-03 07:21:52,998 [PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:40228, 127.0.0.1:33330]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:40228, 127.0.0.1:33330] terminating
2020-12-03 07:21:53,005 [IPC Server handler 5 on default port 44902] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /hot/file2 is closed by DFSClient_NONMAPREDUCE_-391545094_1
2020-12-03 07:21:53,010 [IPC Server handler 1 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/warm	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:21:53,012 [IPC Server handler 7 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/warm/file0	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:21:53,020 [IPC Server handler 2 on default port 44902] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(427)) - storageTypes={DISK=3}
2020-12-03 07:21:53,020 [IPC Server handler 2 on default port 44902] DEBUG blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseRemoteRack(719)) - Failed to choose remote rack (location = ~/default-rack), fallback to local rack
org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy$NotEnoughReplicasException: 
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRandom(BlockPlacementPolicyDefault.java:852)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRemoteRack(BlockPlacementPolicyDefault.java:714)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTargetInOrder(BlockPlacementPolicyDefault.java:519)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:437)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:309)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:149)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:174)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2211)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2789)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:892)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:574)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
2020-12-03 07:21:53,021 [IPC Server handler 2 on default port 44902] DEBUG blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseRemoteRack(719)) - Failed to choose remote rack (location = ~/default-rack), fallback to local rack
org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy$NotEnoughReplicasException: 
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRandom(BlockPlacementPolicyDefault.java:852)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRemoteRack(BlockPlacementPolicyDefault.java:714)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTargetInOrder(BlockPlacementPolicyDefault.java:528)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:437)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:309)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:149)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:174)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2211)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2789)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:892)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:574)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
2020-12-03 07:21:53,022 [IPC Server handler 2 on default port 44902] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741831_1007, replicas=127.0.0.1:46191, 127.0.0.1:32936, 127.0.0.1:40228 for /warm/file0
2020-12-03 07:21:53,024 [Thread-300] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:53,026 [Thread-300] TRACE datatransfer.DataTransferProtocol (Sender.java:send(79)) - Sending DataTransferOp OpWriteBlockProto: header {
  baseHeader {
    block {
      poolId: "BP-112083932-172.17.0.7-1606980105622"
      blockId: 1073741831
      generationStamp: 1007
      numBytes: 1024
    }
    token {
      identifier: ""
      password: ""
      kind: ""
      service: ""
    }
  }
  clientName: "DFSClient_NONMAPREDUCE_-391545094_1"
}
targets {
  id {
    ipAddr: "127.0.0.1"
    hostName: "127.0.0.1"
    datanodeUuid: "fc258908-e76f-48a7-8279-3420f46782bd"
    xferPort: 32936
    infoPort: 46144
    ipcPort: 43123
    infoSecurePort: 0
  }
  capacity: 1922244395008
  dfsUsed: 49152
  remaining: 1198464253952
  blockPoolUsed: 49152
  lastUpdate: 1606980112278
  xceiverCount: 1
  location: "/default-rack"
  nonDfsUsed: 626088386560
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 141101200
  lastBlockReportTime: 1606980111349
  lastBlockReportMonotonic: 141100272
  numBlocks: 0
}
targets {
  id {
    ipAddr: "127.0.0.1"
    hostName: "127.0.0.1"
    datanodeUuid: "4531fc3a-8c15-42c0-ad49-f6505a50dcea"
    xferPort: 40228
    infoPort: 35466
    ipcPort: 41630
    infoSecurePort: 0
  }
  capacity: 1922244395008
  dfsUsed: 49675
  remaining: 1198464253952
  blockPoolUsed: 49675
  lastUpdate: 1606980112285
  xceiverCount: 1
  location: "/default-rack"
  nonDfsUsed: 626088386037
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 141101208
  lastBlockReportTime: 1606980111349
  lastBlockReportMonotonic: 141100272
  numBlocks: 0
}
stage: PIPELINE_SETUP_CREATE
pipelineSize: 3
minBytesRcvd: 0
maxBytesRcvd: 0
latestGenerationStamp: 0
requestedChecksum {
  type: CHECKSUM_CRC32C
  bytesPerChecksum: 512
}
cachingStrategy {
}
storageType: DISK
targetStorageTypes: DISK
targetStorageTypes: DISK
allowLazyPersist: false
pinning: false
targetPinnings: false
storageId: "DS-dfbdbbaa-c98a-4ba8-8504-1c726531280a"
targetStorageIds: "DS-c5bce671-868b-4fa8-afa7-49e9ec5526a2"
targetStorageIds: "DS-98c5da98-47d1-4ec8-8c42-db45703eedeb"

2020-12-03 07:21:53,026 [DataXceiver for client DFSClient_NONMAPREDUCE_-391545094_1 at /127.0.0.1:58314 [Receiving block BP-112083932-172.17.0.7-1606980105622:blk_1073741831_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-112083932-172.17.0.7-1606980105622:blk_1073741831_1007 src: /127.0.0.1:58314 dest: /127.0.0.1:46191
2020-12-03 07:21:53,027 [DataXceiver for client DFSClient_NONMAPREDUCE_-391545094_1 at /127.0.0.1:58314 [Receiving block BP-112083932-172.17.0.7-1606980105622:blk_1073741831_1007]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:53,028 [DataXceiver for client DFSClient_NONMAPREDUCE_-391545094_1 at /127.0.0.1:58314 [Receiving block BP-112083932-172.17.0.7-1606980105622:blk_1073741831_1007]] TRACE datatransfer.DataTransferProtocol (Sender.java:send(79)) - Sending DataTransferOp OpWriteBlockProto: header {
  baseHeader {
    block {
      poolId: "BP-112083932-172.17.0.7-1606980105622"
      blockId: 1073741831
      generationStamp: 1007
      numBytes: 1024
    }
    token {
      identifier: ""
      password: ""
      kind: ""
      service: ""
    }
  }
  clientName: "DFSClient_NONMAPREDUCE_-391545094_1"
}
targets {
  id {
    ipAddr: "127.0.0.1"
    hostName: "127.0.0.1"
    datanodeUuid: "4531fc3a-8c15-42c0-ad49-f6505a50dcea"
    xferPort: 40228
    infoPort: 35466
    ipcPort: 41630
    infoSecurePort: 0
  }
  capacity: 1922244395008
  dfsUsed: 49675
  remaining: 1198464253952
  blockPoolUsed: 49675
  lastUpdate: 1606980112285
  xceiverCount: 1
  location: "/default-rack"
  nonDfsUsed: 626088386037
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 141101208
  lastBlockReportTime: 1606980111349
  lastBlockReportMonotonic: 141100272
  numBlocks: 0
}
source {
  id {
    ipAddr: ""
    hostName: ""
    datanodeUuid: ""
    xferPort: 0
    infoPort: 0
    ipcPort: 0
    infoSecurePort: 0
  }
  capacity: 0
  dfsUsed: 0
  remaining: 0
  blockPoolUsed: 0
  lastUpdate: 0
  xceiverCount: 0
  nonDfsUsed: 0
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 0
  lastBlockReportTime: 0
  lastBlockReportMonotonic: 0
  numBlocks: 0
}
stage: PIPELINE_SETUP_CREATE
pipelineSize: 3
minBytesRcvd: 0
maxBytesRcvd: 0
latestGenerationStamp: 0
requestedChecksum {
  type: CHECKSUM_CRC32C
  bytesPerChecksum: 512
}
cachingStrategy {
}
storageType: DISK
targetStorageTypes: DISK
allowLazyPersist: false
pinning: false
storageId: "DS-c5bce671-868b-4fa8-afa7-49e9ec5526a2"
targetStorageIds: "DS-98c5da98-47d1-4ec8-8c42-db45703eedeb"

2020-12-03 07:21:53,029 [DataXceiver for client DFSClient_NONMAPREDUCE_-391545094_1 at /127.0.0.1:56396 [Receiving block BP-112083932-172.17.0.7-1606980105622:blk_1073741831_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-112083932-172.17.0.7-1606980105622:blk_1073741831_1007 src: /127.0.0.1:56396 dest: /127.0.0.1:32936
2020-12-03 07:21:53,031 [DataXceiver for client DFSClient_NONMAPREDUCE_-391545094_1 at /127.0.0.1:56396 [Receiving block BP-112083932-172.17.0.7-1606980105622:blk_1073741831_1007]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:53,032 [DataXceiver for client DFSClient_NONMAPREDUCE_-391545094_1 at /127.0.0.1:56396 [Receiving block BP-112083932-172.17.0.7-1606980105622:blk_1073741831_1007]] TRACE datatransfer.DataTransferProtocol (Sender.java:send(79)) - Sending DataTransferOp OpWriteBlockProto: header {
  baseHeader {
    block {
      poolId: "BP-112083932-172.17.0.7-1606980105622"
      blockId: 1073741831
      generationStamp: 1007
      numBytes: 1024
    }
    token {
      identifier: ""
      password: ""
      kind: ""
      service: ""
    }
  }
  clientName: "DFSClient_NONMAPREDUCE_-391545094_1"
}
source {
  id {
    ipAddr: ""
    hostName: ""
    datanodeUuid: ""
    xferPort: 0
    infoPort: 0
    ipcPort: 0
    infoSecurePort: 0
  }
  capacity: 0
  dfsUsed: 0
  remaining: 0
  blockPoolUsed: 0
  lastUpdate: 0
  xceiverCount: 0
  nonDfsUsed: 0
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 0
  lastBlockReportTime: 0
  lastBlockReportMonotonic: 0
  numBlocks: 0
}
stage: PIPELINE_SETUP_CREATE
pipelineSize: 3
minBytesRcvd: 0
maxBytesRcvd: 0
latestGenerationStamp: 0
requestedChecksum {
  type: CHECKSUM_CRC32C
  bytesPerChecksum: 512
}
cachingStrategy {
}
storageType: DISK
allowLazyPersist: false
pinning: false
storageId: "DS-98c5da98-47d1-4ec8-8c42-db45703eedeb"

2020-12-03 07:21:53,033 [DataXceiver for client DFSClient_NONMAPREDUCE_-391545094_1 at /127.0.0.1:38486 [Receiving block BP-112083932-172.17.0.7-1606980105622:blk_1073741831_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-112083932-172.17.0.7-1606980105622:blk_1073741831_1007 src: /127.0.0.1:38486 dest: /127.0.0.1:40228
2020-12-03 07:21:53,051 [PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741831_1007, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38486, dest: /127.0.0.1:40228, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-391545094_1, offset: 0, srvID: 4531fc3a-8c15-42c0-ad49-f6505a50dcea, blockid: BP-112083932-172.17.0.7-1606980105622:blk_1073741831_1007, duration(ns): 12719551
2020-12-03 07:21:53,052 [PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741831_1007, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741831_1007, type=LAST_IN_PIPELINE terminating
2020-12-03 07:21:53,055 [PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741831_1007, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40228]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56396, dest: /127.0.0.1:32936, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-391545094_1, offset: 0, srvID: fc258908-e76f-48a7-8279-3420f46782bd, blockid: BP-112083932-172.17.0.7-1606980105622:blk_1073741831_1007, duration(ns): 17322031
2020-12-03 07:21:53,056 [PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741831_1007, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40228]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741831_1007, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40228] terminating
2020-12-03 07:21:53,057 [PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741831_1007, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:32936, 127.0.0.1:40228]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58314, dest: /127.0.0.1:46191, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-391545094_1, offset: 0, srvID: 7b793216-748f-4be6-a144-367935ffbafb, blockid: BP-112083932-172.17.0.7-1606980105622:blk_1073741831_1007, duration(ns): 20691623
2020-12-03 07:21:53,057 [PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741831_1007, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:32936, 127.0.0.1:40228]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741831_1007, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:32936, 127.0.0.1:40228] terminating
2020-12-03 07:21:53,059 [IPC Server handler 4 on default port 44902] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /warm/file0 is closed by DFSClient_NONMAPREDUCE_-391545094_1
2020-12-03 07:21:53,062 [IPC Server handler 3 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/warm	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:21:53,064 [IPC Server handler 6 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/warm/file1	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:21:53,067 [IPC Server handler 5 on default port 44902] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(427)) - storageTypes={DISK=3}
2020-12-03 07:21:53,068 [IPC Server handler 5 on default port 44902] DEBUG blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseRemoteRack(719)) - Failed to choose remote rack (location = ~/default-rack), fallback to local rack
org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy$NotEnoughReplicasException: 
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRandom(BlockPlacementPolicyDefault.java:852)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRemoteRack(BlockPlacementPolicyDefault.java:714)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTargetInOrder(BlockPlacementPolicyDefault.java:519)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:437)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:309)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:149)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:174)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2211)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2789)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:892)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:574)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
2020-12-03 07:21:53,068 [IPC Server handler 5 on default port 44902] DEBUG blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseRemoteRack(719)) - Failed to choose remote rack (location = ~/default-rack), fallback to local rack
org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy$NotEnoughReplicasException: 
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRandom(BlockPlacementPolicyDefault.java:852)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRemoteRack(BlockPlacementPolicyDefault.java:714)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTargetInOrder(BlockPlacementPolicyDefault.java:528)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:437)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:309)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:149)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:174)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2211)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2789)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:892)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:574)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
2020-12-03 07:21:53,069 [IPC Server handler 5 on default port 44902] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741832_1008, replicas=127.0.0.1:46191, 127.0.0.1:40228, 127.0.0.1:32811 for /warm/file1
2020-12-03 07:21:53,071 [Thread-308] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:53,073 [Thread-308] TRACE datatransfer.DataTransferProtocol (Sender.java:send(79)) - Sending DataTransferOp OpWriteBlockProto: header {
  baseHeader {
    block {
      poolId: "BP-112083932-172.17.0.7-1606980105622"
      blockId: 1073741832
      generationStamp: 1008
      numBytes: 1024
    }
    token {
      identifier: ""
      password: ""
      kind: ""
      service: ""
    }
  }
  clientName: "DFSClient_NONMAPREDUCE_-391545094_1"
}
targets {
  id {
    ipAddr: "127.0.0.1"
    hostName: "127.0.0.1"
    datanodeUuid: "4531fc3a-8c15-42c0-ad49-f6505a50dcea"
    xferPort: 40228
    infoPort: 35466
    ipcPort: 41630
    infoSecurePort: 0
  }
  capacity: 1922244395008
  dfsUsed: 49675
  remaining: 1198464253952
  blockPoolUsed: 49675
  lastUpdate: 1606980112285
  xceiverCount: 1
  location: "/default-rack"
  nonDfsUsed: 626088386037
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 141101208
  lastBlockReportTime: 1606980111349
  lastBlockReportMonotonic: 141100272
  numBlocks: 0
}
targets {
  id {
    ipAddr: "127.0.0.1"
    hostName: "127.0.0.1"
    datanodeUuid: "d756da44-2378-4af0-be27-9028065cb33e"
    xferPort: 32811
    infoPort: 38406
    ipcPort: 37726
    infoSecurePort: 0
  }
  capacity: 1922244395008
  dfsUsed: 49152
  remaining: 1198464253952
  blockPoolUsed: 49152
  lastUpdate: 1606980112278
  xceiverCount: 1
  location: "/default-rack"
  nonDfsUsed: 626088386560
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 141101201
  lastBlockReportTime: 1606980111349
  lastBlockReportMonotonic: 141100272
  numBlocks: 0
}
stage: PIPELINE_SETUP_CREATE
pipelineSize: 3
minBytesRcvd: 0
maxBytesRcvd: 0
latestGenerationStamp: 0
requestedChecksum {
  type: CHECKSUM_CRC32C
  bytesPerChecksum: 512
}
cachingStrategy {
}
storageType: DISK
targetStorageTypes: DISK
targetStorageTypes: DISK
allowLazyPersist: false
pinning: false
targetPinnings: false
storageId: "DS-dfbdbbaa-c98a-4ba8-8504-1c726531280a"
targetStorageIds: "DS-98c5da98-47d1-4ec8-8c42-db45703eedeb"
targetStorageIds: "DS-1bb59e4f-55f8-43b4-92c0-6f9216074971"

2020-12-03 07:21:53,074 [DataXceiver for client DFSClient_NONMAPREDUCE_-391545094_1 at /127.0.0.1:58320 [Receiving block BP-112083932-172.17.0.7-1606980105622:blk_1073741832_1008]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-112083932-172.17.0.7-1606980105622:blk_1073741832_1008 src: /127.0.0.1:58320 dest: /127.0.0.1:46191
2020-12-03 07:21:53,075 [DataXceiver for client DFSClient_NONMAPREDUCE_-391545094_1 at /127.0.0.1:58320 [Receiving block BP-112083932-172.17.0.7-1606980105622:blk_1073741832_1008]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:53,076 [DataXceiver for client DFSClient_NONMAPREDUCE_-391545094_1 at /127.0.0.1:58320 [Receiving block BP-112083932-172.17.0.7-1606980105622:blk_1073741832_1008]] TRACE datatransfer.DataTransferProtocol (Sender.java:send(79)) - Sending DataTransferOp OpWriteBlockProto: header {
  baseHeader {
    block {
      poolId: "BP-112083932-172.17.0.7-1606980105622"
      blockId: 1073741832
      generationStamp: 1008
      numBytes: 1024
    }
    token {
      identifier: ""
      password: ""
      kind: ""
      service: ""
    }
  }
  clientName: "DFSClient_NONMAPREDUCE_-391545094_1"
}
targets {
  id {
    ipAddr: "127.0.0.1"
    hostName: "127.0.0.1"
    datanodeUuid: "d756da44-2378-4af0-be27-9028065cb33e"
    xferPort: 32811
    infoPort: 38406
    ipcPort: 37726
    infoSecurePort: 0
  }
  capacity: 1922244395008
  dfsUsed: 49152
  remaining: 1198464253952
  blockPoolUsed: 49152
  lastUpdate: 1606980112278
  xceiverCount: 1
  location: "/default-rack"
  nonDfsUsed: 626088386560
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 141101201
  lastBlockReportTime: 1606980111349
  lastBlockReportMonotonic: 141100272
  numBlocks: 0
}
source {
  id {
    ipAddr: ""
    hostName: ""
    datanodeUuid: ""
    xferPort: 0
    infoPort: 0
    ipcPort: 0
    infoSecurePort: 0
  }
  capacity: 0
  dfsUsed: 0
  remaining: 0
  blockPoolUsed: 0
  lastUpdate: 0
  xceiverCount: 0
  nonDfsUsed: 0
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 0
  lastBlockReportTime: 0
  lastBlockReportMonotonic: 0
  numBlocks: 0
}
stage: PIPELINE_SETUP_CREATE
pipelineSize: 3
minBytesRcvd: 0
maxBytesRcvd: 0
latestGenerationStamp: 0
requestedChecksum {
  type: CHECKSUM_CRC32C
  bytesPerChecksum: 512
}
cachingStrategy {
}
storageType: DISK
targetStorageTypes: DISK
allowLazyPersist: false
pinning: false
storageId: "DS-98c5da98-47d1-4ec8-8c42-db45703eedeb"
targetStorageIds: "DS-1bb59e4f-55f8-43b4-92c0-6f9216074971"

2020-12-03 07:21:53,077 [DataXceiver for client DFSClient_NONMAPREDUCE_-391545094_1 at /127.0.0.1:38490 [Receiving block BP-112083932-172.17.0.7-1606980105622:blk_1073741832_1008]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-112083932-172.17.0.7-1606980105622:blk_1073741832_1008 src: /127.0.0.1:38490 dest: /127.0.0.1:40228
2020-12-03 07:21:53,079 [DataXceiver for client DFSClient_NONMAPREDUCE_-391545094_1 at /127.0.0.1:38490 [Receiving block BP-112083932-172.17.0.7-1606980105622:blk_1073741832_1008]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:53,081 [DataXceiver for client DFSClient_NONMAPREDUCE_-391545094_1 at /127.0.0.1:38490 [Receiving block BP-112083932-172.17.0.7-1606980105622:blk_1073741832_1008]] TRACE datatransfer.DataTransferProtocol (Sender.java:send(79)) - Sending DataTransferOp OpWriteBlockProto: header {
  baseHeader {
    block {
      poolId: "BP-112083932-172.17.0.7-1606980105622"
      blockId: 1073741832
      generationStamp: 1008
      numBytes: 1024
    }
    token {
      identifier: ""
      password: ""
      kind: ""
      service: ""
    }
  }
  clientName: "DFSClient_NONMAPREDUCE_-391545094_1"
}
source {
  id {
    ipAddr: ""
    hostName: ""
    datanodeUuid: ""
    xferPort: 0
    infoPort: 0
    ipcPort: 0
    infoSecurePort: 0
  }
  capacity: 0
  dfsUsed: 0
  remaining: 0
  blockPoolUsed: 0
  lastUpdate: 0
  xceiverCount: 0
  nonDfsUsed: 0
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 0
  lastBlockReportTime: 0
  lastBlockReportMonotonic: 0
  numBlocks: 0
}
stage: PIPELINE_SETUP_CREATE
pipelineSize: 3
minBytesRcvd: 0
maxBytesRcvd: 0
latestGenerationStamp: 0
requestedChecksum {
  type: CHECKSUM_CRC32C
  bytesPerChecksum: 512
}
cachingStrategy {
}
storageType: DISK
allowLazyPersist: false
pinning: false
storageId: "DS-1bb59e4f-55f8-43b4-92c0-6f9216074971"

2020-12-03 07:21:53,082 [DataXceiver for client DFSClient_NONMAPREDUCE_-391545094_1 at /127.0.0.1:58318 [Receiving block BP-112083932-172.17.0.7-1606980105622:blk_1073741832_1008]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-112083932-172.17.0.7-1606980105622:blk_1073741832_1008 src: /127.0.0.1:58318 dest: /127.0.0.1:32811
2020-12-03 07:21:53,094 [PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741832_1008, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58318, dest: /127.0.0.1:32811, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-391545094_1, offset: 0, srvID: d756da44-2378-4af0-be27-9028065cb33e, blockid: BP-112083932-172.17.0.7-1606980105622:blk_1073741832_1008, duration(ns): 8991900
2020-12-03 07:21:53,094 [PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741832_1008, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741832_1008, type=LAST_IN_PIPELINE terminating
2020-12-03 07:21:53,096 [PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741832_1008, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:32811]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38490, dest: /127.0.0.1:40228, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-391545094_1, offset: 0, srvID: 4531fc3a-8c15-42c0-ad49-f6505a50dcea, blockid: BP-112083932-172.17.0.7-1606980105622:blk_1073741832_1008, duration(ns): 11051366
2020-12-03 07:21:53,097 [PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741832_1008, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:32811]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741832_1008, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:32811] terminating
2020-12-03 07:21:53,098 [PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741832_1008, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:40228, 127.0.0.1:32811]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58320, dest: /127.0.0.1:46191, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-391545094_1, offset: 0, srvID: 7b793216-748f-4be6-a144-367935ffbafb, blockid: BP-112083932-172.17.0.7-1606980105622:blk_1073741832_1008, duration(ns): 12663258
2020-12-03 07:21:53,099 [PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741832_1008, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:40228, 127.0.0.1:32811]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741832_1008, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:40228, 127.0.0.1:32811] terminating
2020-12-03 07:21:53,101 [IPC Server handler 0 on default port 44902] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /warm/file1 is closed by DFSClient_NONMAPREDUCE_-391545094_1
2020-12-03 07:21:53,105 [IPC Server handler 8 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/warm	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:21:53,107 [IPC Server handler 9 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/warm/file2	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:21:53,110 [IPC Server handler 4 on default port 44902] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(427)) - storageTypes={DISK=3}
2020-12-03 07:21:53,111 [IPC Server handler 4 on default port 44902] DEBUG blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseRemoteRack(719)) - Failed to choose remote rack (location = ~/default-rack), fallback to local rack
org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy$NotEnoughReplicasException: 
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRandom(BlockPlacementPolicyDefault.java:852)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRemoteRack(BlockPlacementPolicyDefault.java:714)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTargetInOrder(BlockPlacementPolicyDefault.java:519)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:437)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:309)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:149)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:174)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2211)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2789)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:892)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:574)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
2020-12-03 07:21:53,111 [IPC Server handler 4 on default port 44902] DEBUG blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseRemoteRack(719)) - Failed to choose remote rack (location = ~/default-rack), fallback to local rack
org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy$NotEnoughReplicasException: 
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRandom(BlockPlacementPolicyDefault.java:852)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRemoteRack(BlockPlacementPolicyDefault.java:714)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTargetInOrder(BlockPlacementPolicyDefault.java:528)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:437)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:309)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:149)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:174)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2211)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2789)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:892)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:574)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
2020-12-03 07:21:53,112 [IPC Server handler 4 on default port 44902] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741833_1009, replicas=127.0.0.1:32811, 127.0.0.1:33330, 127.0.0.1:40228 for /warm/file2
2020-12-03 07:21:53,115 [Thread-316] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:53,116 [Thread-316] TRACE datatransfer.DataTransferProtocol (Sender.java:send(79)) - Sending DataTransferOp OpWriteBlockProto: header {
  baseHeader {
    block {
      poolId: "BP-112083932-172.17.0.7-1606980105622"
      blockId: 1073741833
      generationStamp: 1009
      numBytes: 1024
    }
    token {
      identifier: ""
      password: ""
      kind: ""
      service: ""
    }
  }
  clientName: "DFSClient_NONMAPREDUCE_-391545094_1"
}
targets {
  id {
    ipAddr: "127.0.0.1"
    hostName: "127.0.0.1"
    datanodeUuid: "0237cc88-214f-4ecc-9fca-2ef3974ab7eb"
    xferPort: 33330
    infoPort: 37559
    ipcPort: 33221
    infoSecurePort: 0
  }
  capacity: 1922244395008
  dfsUsed: 49152
  remaining: 1198464253952
  blockPoolUsed: 49152
  lastUpdate: 1606980112283
  xceiverCount: 1
  location: "/default-rack"
  nonDfsUsed: 626088386560
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 141101206
  lastBlockReportTime: 1606980111349
  lastBlockReportMonotonic: 141100272
  numBlocks: 0
}
targets {
  id {
    ipAddr: "127.0.0.1"
    hostName: "127.0.0.1"
    datanodeUuid: "4531fc3a-8c15-42c0-ad49-f6505a50dcea"
    xferPort: 40228
    infoPort: 35466
    ipcPort: 41630
    infoSecurePort: 0
  }
  capacity: 1922244395008
  dfsUsed: 49675
  remaining: 1198464253952
  blockPoolUsed: 49675
  lastUpdate: 1606980112285
  xceiverCount: 1
  location: "/default-rack"
  nonDfsUsed: 626088386037
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 141101208
  lastBlockReportTime: 1606980111349
  lastBlockReportMonotonic: 141100272
  numBlocks: 0
}
stage: PIPELINE_SETUP_CREATE
pipelineSize: 3
minBytesRcvd: 0
maxBytesRcvd: 0
latestGenerationStamp: 0
requestedChecksum {
  type: CHECKSUM_CRC32C
  bytesPerChecksum: 512
}
cachingStrategy {
}
storageType: DISK
targetStorageTypes: DISK
targetStorageTypes: DISK
allowLazyPersist: false
pinning: false
targetPinnings: false
storageId: "DS-1bb59e4f-55f8-43b4-92c0-6f9216074971"
targetStorageIds: "DS-d75ea7b4-2fee-44a5-844d-faa34ba6681d"
targetStorageIds: "DS-98c5da98-47d1-4ec8-8c42-db45703eedeb"

2020-12-03 07:21:53,118 [DataXceiver for client DFSClient_NONMAPREDUCE_-391545094_1 at /127.0.0.1:58322 [Receiving block BP-112083932-172.17.0.7-1606980105622:blk_1073741833_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-112083932-172.17.0.7-1606980105622:blk_1073741833_1009 src: /127.0.0.1:58322 dest: /127.0.0.1:32811
2020-12-03 07:21:53,119 [DataXceiver for client DFSClient_NONMAPREDUCE_-391545094_1 at /127.0.0.1:58322 [Receiving block BP-112083932-172.17.0.7-1606980105622:blk_1073741833_1009]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:53,120 [DataXceiver for client DFSClient_NONMAPREDUCE_-391545094_1 at /127.0.0.1:58322 [Receiving block BP-112083932-172.17.0.7-1606980105622:blk_1073741833_1009]] TRACE datatransfer.DataTransferProtocol (Sender.java:send(79)) - Sending DataTransferOp OpWriteBlockProto: header {
  baseHeader {
    block {
      poolId: "BP-112083932-172.17.0.7-1606980105622"
      blockId: 1073741833
      generationStamp: 1009
      numBytes: 1024
    }
    token {
      identifier: ""
      password: ""
      kind: ""
      service: ""
    }
  }
  clientName: "DFSClient_NONMAPREDUCE_-391545094_1"
}
targets {
  id {
    ipAddr: "127.0.0.1"
    hostName: "127.0.0.1"
    datanodeUuid: "4531fc3a-8c15-42c0-ad49-f6505a50dcea"
    xferPort: 40228
    infoPort: 35466
    ipcPort: 41630
    infoSecurePort: 0
  }
  capacity: 1922244395008
  dfsUsed: 49675
  remaining: 1198464253952
  blockPoolUsed: 49675
  lastUpdate: 1606980112285
  xceiverCount: 1
  location: "/default-rack"
  nonDfsUsed: 626088386037
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 141101208
  lastBlockReportTime: 1606980111349
  lastBlockReportMonotonic: 141100272
  numBlocks: 0
}
source {
  id {
    ipAddr: ""
    hostName: ""
    datanodeUuid: ""
    xferPort: 0
    infoPort: 0
    ipcPort: 0
    infoSecurePort: 0
  }
  capacity: 0
  dfsUsed: 0
  remaining: 0
  blockPoolUsed: 0
  lastUpdate: 0
  xceiverCount: 0
  nonDfsUsed: 0
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 0
  lastBlockReportTime: 0
  lastBlockReportMonotonic: 0
  numBlocks: 0
}
stage: PIPELINE_SETUP_CREATE
pipelineSize: 3
minBytesRcvd: 0
maxBytesRcvd: 0
latestGenerationStamp: 0
requestedChecksum {
  type: CHECKSUM_CRC32C
  bytesPerChecksum: 512
}
cachingStrategy {
}
storageType: DISK
targetStorageTypes: DISK
allowLazyPersist: false
pinning: false
storageId: "DS-d75ea7b4-2fee-44a5-844d-faa34ba6681d"
targetStorageIds: "DS-98c5da98-47d1-4ec8-8c42-db45703eedeb"

2020-12-03 07:21:53,121 [DataXceiver for client DFSClient_NONMAPREDUCE_-391545094_1 at /127.0.0.1:40858 [Receiving block BP-112083932-172.17.0.7-1606980105622:blk_1073741833_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-112083932-172.17.0.7-1606980105622:blk_1073741833_1009 src: /127.0.0.1:40858 dest: /127.0.0.1:33330
2020-12-03 07:21:53,124 [DataXceiver for client DFSClient_NONMAPREDUCE_-391545094_1 at /127.0.0.1:40858 [Receiving block BP-112083932-172.17.0.7-1606980105622:blk_1073741833_1009]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:53,125 [DataXceiver for client DFSClient_NONMAPREDUCE_-391545094_1 at /127.0.0.1:40858 [Receiving block BP-112083932-172.17.0.7-1606980105622:blk_1073741833_1009]] TRACE datatransfer.DataTransferProtocol (Sender.java:send(79)) - Sending DataTransferOp OpWriteBlockProto: header {
  baseHeader {
    block {
      poolId: "BP-112083932-172.17.0.7-1606980105622"
      blockId: 1073741833
      generationStamp: 1009
      numBytes: 1024
    }
    token {
      identifier: ""
      password: ""
      kind: ""
      service: ""
    }
  }
  clientName: "DFSClient_NONMAPREDUCE_-391545094_1"
}
source {
  id {
    ipAddr: ""
    hostName: ""
    datanodeUuid: ""
    xferPort: 0
    infoPort: 0
    ipcPort: 0
    infoSecurePort: 0
  }
  capacity: 0
  dfsUsed: 0
  remaining: 0
  blockPoolUsed: 0
  lastUpdate: 0
  xceiverCount: 0
  nonDfsUsed: 0
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 0
  lastBlockReportTime: 0
  lastBlockReportMonotonic: 0
  numBlocks: 0
}
stage: PIPELINE_SETUP_CREATE
pipelineSize: 3
minBytesRcvd: 0
maxBytesRcvd: 0
latestGenerationStamp: 0
requestedChecksum {
  type: CHECKSUM_CRC32C
  bytesPerChecksum: 512
}
cachingStrategy {
}
storageType: DISK
allowLazyPersist: false
pinning: false
storageId: "DS-98c5da98-47d1-4ec8-8c42-db45703eedeb"

2020-12-03 07:21:53,125 [DataXceiver for client DFSClient_NONMAPREDUCE_-391545094_1 at /127.0.0.1:38500 [Receiving block BP-112083932-172.17.0.7-1606980105622:blk_1073741833_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-112083932-172.17.0.7-1606980105622:blk_1073741833_1009 src: /127.0.0.1:38500 dest: /127.0.0.1:40228
2020-12-03 07:21:53,142 [PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741833_1009, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38500, dest: /127.0.0.1:40228, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-391545094_1, offset: 0, srvID: 4531fc3a-8c15-42c0-ad49-f6505a50dcea, blockid: BP-112083932-172.17.0.7-1606980105622:blk_1073741833_1009, duration(ns): 13389593
2020-12-03 07:21:53,144 [PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741833_1009, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741833_1009, type=LAST_IN_PIPELINE terminating
2020-12-03 07:21:53,151 [PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741833_1009, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40228]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40858, dest: /127.0.0.1:33330, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-391545094_1, offset: 0, srvID: 0237cc88-214f-4ecc-9fca-2ef3974ab7eb, blockid: BP-112083932-172.17.0.7-1606980105622:blk_1073741833_1009, duration(ns): 16026537
2020-12-03 07:21:53,151 [PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741833_1009, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40228]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741833_1009, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40228] terminating
2020-12-03 07:21:53,158 [PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741833_1009, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:33330, 127.0.0.1:40228]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58322, dest: /127.0.0.1:32811, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-391545094_1, offset: 0, srvID: d756da44-2378-4af0-be27-9028065cb33e, blockid: BP-112083932-172.17.0.7-1606980105622:blk_1073741833_1009, duration(ns): 25122790
2020-12-03 07:21:53,158 [PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741833_1009, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:33330, 127.0.0.1:40228]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-112083932-172.17.0.7-1606980105622:blk_1073741833_1009, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:33330, 127.0.0.1:40228] terminating
2020-12-03 07:21:53,161 [IPC Server handler 5 on default port 44902] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /warm/file2 is closed by DFSClient_NONMAPREDUCE_-391545094_1
2020-12-03 07:21:53,169 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:44902
2020-12-03 07:21:53,173 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x34913344e47fcf67: from storage DS-98c5da98-47d1-4ec8-8c42-db45703eedeb node DatanodeRegistration(127.0.0.1:40228, datanodeUuid=4531fc3a-8c15-42c0-ad49-f6505a50dcea, infoPort=35466, infoSecurePort=0, ipcPort=41630, storageInfo=lv=-57;cid=testClusterID;nsid=543616343;c=1606980105622), blocks: 8, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:21:53,173 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x34913344e47fcf67: from storage DS-45d26ee9-5330-4328-a6f5-9d5cae8072d4 node DatanodeRegistration(127.0.0.1:40228, datanodeUuid=4531fc3a-8c15-42c0-ad49-f6505a50dcea, infoPort=35466, infoSecurePort=0, ipcPort=41630, storageInfo=lv=-57;cid=testClusterID;nsid=543616343;c=1606980105622), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:53,174 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x34913344e47fcf67,  containing 2 storage report(s), of which we sent 2. The reports had 8 total blocks and used 1 RPC(s). This took 2 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:21:53,174 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-112083932-172.17.0.7-1606980105622
2020-12-03 07:21:53,271 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:44902
2020-12-03 07:21:53,273 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xfc8314b2c08b8c8d: from storage DS-c5bce671-868b-4fa8-afa7-49e9ec5526a2 node DatanodeRegistration(127.0.0.1:32936, datanodeUuid=fc258908-e76f-48a7-8279-3420f46782bd, infoPort=46144, infoSecurePort=0, ipcPort=43123, storageInfo=lv=-57;cid=testClusterID;nsid=543616343;c=1606980105622), blocks: 5, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:53,274 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xfc8314b2c08b8c8d: from storage DS-d4b106f7-6476-43e5-bebc-4d76f054903f node DatanodeRegistration(127.0.0.1:32936, datanodeUuid=fc258908-e76f-48a7-8279-3420f46782bd, infoPort=46144, infoSecurePort=0, ipcPort=43123, storageInfo=lv=-57;cid=testClusterID;nsid=543616343;c=1606980105622), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:53,274 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xfc8314b2c08b8c8d,  containing 2 storage report(s), of which we sent 2. The reports had 5 total blocks and used 1 RPC(s). This took 1 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:21:53,275 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-112083932-172.17.0.7-1606980105622
2020-12-03 07:21:53,369 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:44902
2020-12-03 07:21:53,371 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xc4cf9a8c92a7c44b: from storage DS-ae119148-187a-42b8-a576-43913a2cea7b node DatanodeRegistration(127.0.0.1:46191, datanodeUuid=7b793216-748f-4be6-a144-367935ffbafb, infoPort=38566, infoSecurePort=0, ipcPort=41609, storageInfo=lv=-57;cid=testClusterID;nsid=543616343;c=1606980105622), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:53,371 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xc4cf9a8c92a7c44b: from storage DS-dfbdbbaa-c98a-4ba8-8504-1c726531280a node DatanodeRegistration(127.0.0.1:46191, datanodeUuid=7b793216-748f-4be6-a144-367935ffbafb, infoPort=38566, infoSecurePort=0, ipcPort=41609, storageInfo=lv=-57;cid=testClusterID;nsid=543616343;c=1606980105622), blocks: 5, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:53,372 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xc4cf9a8c92a7c44b,  containing 2 storage report(s), of which we sent 2. The reports had 5 total blocks and used 1 RPC(s). This took 1 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:21:53,372 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-112083932-172.17.0.7-1606980105622
2020-12-03 07:21:53,469 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:44902
2020-12-03 07:21:53,471 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xf8fb16a3530b4cf4: from storage DS-8e084a11-8a03-4947-83b2-a2598a529f6c node DatanodeRegistration(127.0.0.1:33330, datanodeUuid=0237cc88-214f-4ecc-9fca-2ef3974ab7eb, infoPort=37559, infoSecurePort=0, ipcPort=33221, storageInfo=lv=-57;cid=testClusterID;nsid=543616343;c=1606980105622), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:53,471 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xf8fb16a3530b4cf4: from storage DS-d75ea7b4-2fee-44a5-844d-faa34ba6681d node DatanodeRegistration(127.0.0.1:33330, datanodeUuid=0237cc88-214f-4ecc-9fca-2ef3974ab7eb, infoPort=37559, infoSecurePort=0, ipcPort=33221, storageInfo=lv=-57;cid=testClusterID;nsid=543616343;c=1606980105622), blocks: 3, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:53,472 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xf8fb16a3530b4cf4,  containing 2 storage report(s), of which we sent 2. The reports had 3 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:21:53,472 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-112083932-172.17.0.7-1606980105622
2020-12-03 07:21:53,570 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:44902
2020-12-03 07:21:53,571 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x219f0ed3ff786fa5: from storage DS-0e0d2a62-0a95-4405-ac61-c36d0ad42c39 node DatanodeRegistration(127.0.0.1:41276, datanodeUuid=002461fc-4aa8-4d26-86c3-971092b194a6, infoPort=35624, infoSecurePort=0, ipcPort=36273, storageInfo=lv=-57;cid=testClusterID;nsid=543616343;c=1606980105622), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:53,572 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x219f0ed3ff786fa5: from storage DS-d45ac532-8cf5-4065-bea9-b33e7114dc7d node DatanodeRegistration(127.0.0.1:41276, datanodeUuid=002461fc-4aa8-4d26-86c3-971092b194a6, infoPort=35624, infoSecurePort=0, ipcPort=36273, storageInfo=lv=-57;cid=testClusterID;nsid=543616343;c=1606980105622), blocks: 1, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:21:53,572 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x219f0ed3ff786fa5,  containing 2 storage report(s), of which we sent 2. The reports had 1 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:21:53,572 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-112083932-172.17.0.7-1606980105622
2020-12-03 07:21:53,670 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:44902
2020-12-03 07:21:53,672 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x2af71878c25e8976: from storage DS-7ba7554c-5ca9-4cc9-a977-6f21fc38dd76 node DatanodeRegistration(127.0.0.1:32811, datanodeUuid=d756da44-2378-4af0-be27-9028065cb33e, infoPort=38406, infoSecurePort=0, ipcPort=37726, storageInfo=lv=-57;cid=testClusterID;nsid=543616343;c=1606980105622), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:53,672 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x2af71878c25e8976: from storage DS-1bb59e4f-55f8-43b4-92c0-6f9216074971 node DatanodeRegistration(127.0.0.1:32811, datanodeUuid=d756da44-2378-4af0-be27-9028065cb33e, infoPort=38406, infoSecurePort=0, ipcPort=37726, storageInfo=lv=-57;cid=testClusterID;nsid=543616343;c=1606980105622), blocks: 5, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:53,673 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x2af71878c25e8976,  containing 2 storage report(s), of which we sent 2. The reports had 5 total blocks and used 1 RPC(s). This took 1 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:21:53,673 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-112083932-172.17.0.7-1606980105622
2020-12-03 07:21:53,772 [IPC Server handler 3 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/	dst=null	perm=null	proto=rpc
2020-12-03 07:21:53,777 [IPC Server handler 6 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/	dst=null	perm=null	proto=rpc
2020-12-03 07:21:53,784 [IPC Server handler 1 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/cold	dst=null	perm=null	proto=rpc
2020-12-03 07:21:53,800 [IPC Server handler 5 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/hot	dst=null	perm=null	proto=rpc
2020-12-03 07:21:53,807 [IPC Server handler 7 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/warm	dst=null	perm=null	proto=rpc
2020-12-03 07:21:53,821 [IPC Server handler 2 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setStoragePolicy	src=/cold	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:21:53,823 [IPC Server handler 0 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setStoragePolicy	src=/hot	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:21:53,825 [IPC Server handler 8 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setStoragePolicy	src=/warm	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:21:53,827 [Listener at localhost/37726] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:53,828 [Listener at localhost/37726] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.redundancy.interval.seconds(2) assuming SECONDS
2020-12-03 07:21:53,828 [Listener at localhost/37726] INFO  mover.Mover (Mover.java:run(642)) - namenodes = {hdfs://localhost:44902=null}
2020-12-03 07:21:53,884 [IPC Server handler 3 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/system/mover.id	dst=null	perm=null	proto=rpc
2020-12-03 07:21:53,888 [IPC Server handler 6 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/system/mover.id	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:21:53,890 [IPC Server handler 1 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/system/mover.id	dst=null	perm=null	proto=rpc
2020-12-03 07:21:53,895 [Listener at localhost/37726] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:53,895 [Listener at localhost/37726] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:53,910 [IPC Server handler 7 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getDatanodeStorageReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:53,919 [Listener at localhost/37726] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41276
2020-12-03 07:21:53,920 [Listener at localhost/37726] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:46191
2020-12-03 07:21:53,920 [Listener at localhost/37726] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:33330
2020-12-03 07:21:53,920 [Listener at localhost/37726] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:32936
2020-12-03 07:21:53,920 [Listener at localhost/37726] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:32811
2020-12-03 07:21:53,920 [Listener at localhost/37726] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:40228
2020-12-03 07:21:53,926 [IPC Server handler 2 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listSnapshottableDirectory	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:53,928 [IPC Server handler 0 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/	dst=null	perm=null	proto=rpc
2020-12-03 07:21:53,931 [IPC Server handler 8 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/cold/	dst=null	perm=null	proto=rpc
2020-12-03 07:21:53,936 [Listener at localhost/37726] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741825_1001 with size=512 from 127.0.0.1:41276:DISK to 127.0.0.1:41276:ARCHIVE through 127.0.0.1:41276
2020-12-03 07:21:53,937 [Listener at localhost/37726] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741826_1002 with size=512 from 127.0.0.1:32811:DISK to 127.0.0.1:32811:ARCHIVE through 127.0.0.1:32811
2020-12-03 07:21:53,937 [pool-83-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741825_1001 with size=512 from 127.0.0.1:41276:DISK to 127.0.0.1:41276:ARCHIVE through 127.0.0.1:41276
2020-12-03 07:21:53,937 [Listener at localhost/37726] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741827_1003 with size=512 from 127.0.0.1:32811:DISK to 127.0.0.1:32811:ARCHIVE through 127.0.0.1:32811
2020-12-03 07:21:53,937 [pool-84-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741826_1002 with size=512 from 127.0.0.1:32811:DISK to 127.0.0.1:32811:ARCHIVE through 127.0.0.1:32811
2020-12-03 07:21:53,939 [IPC Server handler 4 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/hot/	dst=null	perm=null	proto=rpc
2020-12-03 07:21:53,945 [IPC Server handler 9 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/system/	dst=null	perm=null	proto=rpc
2020-12-03 07:21:53,945 [pool-84-thread-1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:53,945 [pool-83-thread-1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:53,948 [IPC Server handler 3 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/warm/	dst=null	perm=null	proto=rpc
2020-12-03 07:21:53,951 [pool-83-thread-1] TRACE datatransfer.DataTransferProtocol (Sender.java:send(79)) - Sending DataTransferOp OpReplaceBlockProto: header {
  block {
    poolId: "BP-112083932-172.17.0.7-1606980105622"
    blockId: 1073741825
    generationStamp: 1001
    numBytes: 512
  }
  token {
    identifier: ""
    password: ""
    kind: ""
    service: ""
  }
}
delHint: "002461fc-4aa8-4d26-86c3-971092b194a6"
source {
  id {
    ipAddr: "127.0.0.1"
    hostName: "127.0.0.1"
    datanodeUuid: "002461fc-4aa8-4d26-86c3-971092b194a6"
    xferPort: 41276
    infoPort: 35624
    ipcPort: 36273
    infoSecurePort: 0
  }
  capacity: 1922244395008
  dfsUsed: 49675
  remaining: 1198461272064
  blockPoolUsed: 49675
  lastUpdate: 1606980113569
  xceiverCount: 1
  location: "/default-rack"
  nonDfsUsed: 626091367925
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 141102492
  lastBlockReportTime: 1606980113572
  lastBlockReportMonotonic: 141102495
  numBlocks: 0
}
storageType: ARCHIVE

2020-12-03 07:21:53,952 [pool-84-thread-1] TRACE datatransfer.DataTransferProtocol (Sender.java:send(79)) - Sending DataTransferOp OpReplaceBlockProto: header {
  block {
    poolId: "BP-112083932-172.17.0.7-1606980105622"
    blockId: 1073741826
    generationStamp: 1002
    numBytes: 512
  }
  token {
    identifier: ""
    password: ""
    kind: ""
    service: ""
  }
}
delHint: "d756da44-2378-4af0-be27-9028065cb33e"
source {
  id {
    ipAddr: "127.0.0.1"
    hostName: "127.0.0.1"
    datanodeUuid: "d756da44-2378-4af0-be27-9028065cb33e"
    xferPort: 32811
    infoPort: 38406
    ipcPort: 37726
    infoSecurePort: 0
  }
  capacity: 1922244395008
  dfsUsed: 51767
  remaining: 1198461239296
  blockPoolUsed: 51767
  lastUpdate: 1606980113670
  xceiverCount: 1
  location: "/default-rack"
  nonDfsUsed: 626091398601
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 141102593
  lastBlockReportTime: 1606980113672
  lastBlockReportMonotonic: 141102595
  numBlocks: 0
}
storageType: ARCHIVE

2020-12-03 07:21:53,955 [Listener at localhost/37726] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741831_1007 with size=512 from 127.0.0.1:46191:DISK to 127.0.0.1:46191:ARCHIVE through 127.0.0.1:46191
2020-12-03 07:21:53,956 [Listener at localhost/37726] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741832_1008 with size=512 from 127.0.0.1:32811:DISK to 127.0.0.1:32811:ARCHIVE through 127.0.0.1:32811
2020-12-03 07:21:53,956 [pool-85-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741831_1007 with size=512 from 127.0.0.1:46191:DISK to 127.0.0.1:46191:ARCHIVE through 127.0.0.1:46191
2020-12-03 07:21:53,957 [Listener at localhost/37726] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741833_1009 with size=512 from 127.0.0.1:40228:DISK to 127.0.0.1:40228:ARCHIVE through 127.0.0.1:40228
2020-12-03 07:21:53,957 [pool-85-thread-1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:53,957 [pool-86-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741833_1009 with size=512 from 127.0.0.1:40228:DISK to 127.0.0.1:40228:ARCHIVE through 127.0.0.1:40228
2020-12-03 07:21:53,958 [pool-86-thread-1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:53,958 [pool-85-thread-1] TRACE datatransfer.DataTransferProtocol (Sender.java:send(79)) - Sending DataTransferOp OpReplaceBlockProto: header {
  block {
    poolId: "BP-112083932-172.17.0.7-1606980105622"
    blockId: 1073741831
    generationStamp: 1007
    numBytes: 512
  }
  token {
    identifier: ""
    password: ""
    kind: ""
    service: ""
  }
}
delHint: "7b793216-748f-4be6-a144-367935ffbafb"
source {
  id {
    ipAddr: "127.0.0.1"
    hostName: "127.0.0.1"
    datanodeUuid: "7b793216-748f-4be6-a144-367935ffbafb"
    xferPort: 46191
    infoPort: 38566
    ipcPort: 41609
    infoSecurePort: 0
  }
  capacity: 1922244395008
  dfsUsed: 51767
  remaining: 1198461796352
  blockPoolUsed: 51767
  lastUpdate: 1606980113369
  xceiverCount: 1
  location: "/default-rack"
  nonDfsUsed: 626090841545
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 141102292
  lastBlockReportTime: 1606980113372
  lastBlockReportMonotonic: 141102294
  numBlocks: 0
}
storageType: ARCHIVE

2020-12-03 07:21:53,958 [pool-86-thread-1] TRACE datatransfer.DataTransferProtocol (Sender.java:send(79)) - Sending DataTransferOp OpReplaceBlockProto: header {
  block {
    poolId: "BP-112083932-172.17.0.7-1606980105622"
    blockId: 1073741833
    generationStamp: 1009
    numBytes: 512
  }
  token {
    identifier: ""
    password: ""
    kind: ""
    service: ""
  }
}
delHint: "4531fc3a-8c15-42c0-ad49-f6505a50dcea"
source {
  id {
    ipAddr: "127.0.0.1"
    hostName: "127.0.0.1"
    datanodeUuid: "4531fc3a-8c15-42c0-ad49-f6505a50dcea"
    xferPort: 40228
    infoPort: 35466
    ipcPort: 41630
    infoSecurePort: 0
  }
  capacity: 1922244395008
  dfsUsed: 53336
  remaining: 1198462296064
  blockPoolUsed: 53336
  lastUpdate: 1606980113169
  xceiverCount: 1
  location: "/default-rack"
  nonDfsUsed: 626090340264
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 141102092
  lastBlockReportTime: 1606980113174
  lastBlockReportMonotonic: 141102096
  numBlocks: 0
}
storageType: ARCHIVE

2020-12-03 07:21:53,959 [DataXceiver for client /127.0.0.1:58350 [Replacing block BP-112083932-172.17.0.7-1606980105622:blk_1073741826_1002 from d756da44-2378-4af0-be27-9028065cb33e]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1186)) - Moved BP-112083932-172.17.0.7-1606980105622:blk_1073741826_1002 from StorageType DISK to ARCHIVE
2020-12-03 07:21:53,959 [DataXceiver for client /127.0.0.1:37194 [Replacing block BP-112083932-172.17.0.7-1606980105622:blk_1073741825_1001 from 002461fc-4aa8-4d26-86c3-971092b194a6]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1186)) - Moved BP-112083932-172.17.0.7-1606980105622:blk_1073741825_1001 from StorageType DISK to ARCHIVE
2020-12-03 07:21:53,961 [pool-84-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741826_1002 with size=512 from 127.0.0.1:32811:DISK to 127.0.0.1:32811:ARCHIVE through 127.0.0.1:32811
2020-12-03 07:21:53,961 [pool-83-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741825_1001 with size=512 from 127.0.0.1:41276:DISK to 127.0.0.1:41276:ARCHIVE through 127.0.0.1:41276
2020-12-03 07:21:53,962 [pool-84-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741827_1003 with size=512 from 127.0.0.1:32811:DISK to 127.0.0.1:32811:ARCHIVE through 127.0.0.1:32811
2020-12-03 07:21:53,962 [Block report processor] WARN  BlockStateChange (BlockManager.java:addStoredBlock(3356)) - BLOCK* addStoredBlock: block blk_1073741826_1002 moved to storageType ARCHIVE on node 127.0.0.1:32811
2020-12-03 07:21:53,962 [pool-84-thread-1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:53,963 [Block report processor] WARN  BlockStateChange (BlockManager.java:addStoredBlock(3356)) - BLOCK* addStoredBlock: block blk_1073741825_1001 moved to storageType ARCHIVE on node 127.0.0.1:41276
2020-12-03 07:21:53,963 [pool-84-thread-1] TRACE datatransfer.DataTransferProtocol (Sender.java:send(79)) - Sending DataTransferOp OpReplaceBlockProto: header {
  block {
    poolId: "BP-112083932-172.17.0.7-1606980105622"
    blockId: 1073741827
    generationStamp: 1003
    numBytes: 512
  }
  token {
    identifier: ""
    password: ""
    kind: ""
    service: ""
  }
}
delHint: "d756da44-2378-4af0-be27-9028065cb33e"
source {
  id {
    ipAddr: "127.0.0.1"
    hostName: "127.0.0.1"
    datanodeUuid: "d756da44-2378-4af0-be27-9028065cb33e"
    xferPort: 32811
    infoPort: 38406
    ipcPort: 37726
    infoSecurePort: 0
  }
  capacity: 1922244395008
  dfsUsed: 51767
  remaining: 1198461239296
  blockPoolUsed: 51767
  lastUpdate: 1606980113670
  xceiverCount: 1
  location: "/default-rack"
  nonDfsUsed: 626091398601
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 141102593
  lastBlockReportTime: 1606980113672
  lastBlockReportMonotonic: 141102595
  numBlocks: 0
}
storageType: ARCHIVE

2020-12-03 07:21:53,966 [DataXceiver for client /127.0.0.1:58360 [Replacing block BP-112083932-172.17.0.7-1606980105622:blk_1073741827_1003 from d756da44-2378-4af0-be27-9028065cb33e]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1186)) - Moved BP-112083932-172.17.0.7-1606980105622:blk_1073741827_1003 from StorageType DISK to ARCHIVE
2020-12-03 07:21:53,966 [DataXceiver for client /127.0.0.1:58360 [Replacing block BP-112083932-172.17.0.7-1606980105622:blk_1073741831_1007 from 7b793216-748f-4be6-a144-367935ffbafb]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1186)) - Moved BP-112083932-172.17.0.7-1606980105622:blk_1073741831_1007 from StorageType DISK to ARCHIVE
2020-12-03 07:21:53,966 [pool-84-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741827_1003 with size=512 from 127.0.0.1:32811:DISK to 127.0.0.1:32811:ARCHIVE through 127.0.0.1:32811
2020-12-03 07:21:53,966 [pool-85-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741831_1007 with size=512 from 127.0.0.1:46191:DISK to 127.0.0.1:46191:ARCHIVE through 127.0.0.1:46191
2020-12-03 07:21:53,966 [pool-84-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741832_1008 with size=512 from 127.0.0.1:32811:DISK to 127.0.0.1:32811:ARCHIVE through 127.0.0.1:32811
2020-12-03 07:21:53,966 [DataXceiver for client /127.0.0.1:38530 [Replacing block BP-112083932-172.17.0.7-1606980105622:blk_1073741833_1009 from 4531fc3a-8c15-42c0-ad49-f6505a50dcea]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1186)) - Moved BP-112083932-172.17.0.7-1606980105622:blk_1073741833_1009 from StorageType DISK to ARCHIVE
2020-12-03 07:21:53,967 [pool-86-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741833_1009 with size=512 from 127.0.0.1:40228:DISK to 127.0.0.1:40228:ARCHIVE through 127.0.0.1:40228
2020-12-03 07:21:53,967 [pool-84-thread-1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:53,969 [Block report processor] WARN  BlockStateChange (BlockManager.java:addStoredBlock(3356)) - BLOCK* addStoredBlock: block blk_1073741827_1003 moved to storageType ARCHIVE on node 127.0.0.1:32811
2020-12-03 07:21:53,969 [Block report processor] WARN  BlockStateChange (BlockManager.java:addStoredBlock(3356)) - BLOCK* addStoredBlock: block blk_1073741831_1007 moved to storageType ARCHIVE on node 127.0.0.1:46191
2020-12-03 07:21:53,969 [Block report processor] WARN  BlockStateChange (BlockManager.java:addStoredBlock(3356)) - BLOCK* addStoredBlock: block blk_1073741833_1009 moved to storageType ARCHIVE on node 127.0.0.1:40228
2020-12-03 07:21:53,970 [pool-84-thread-1] TRACE datatransfer.DataTransferProtocol (Sender.java:send(79)) - Sending DataTransferOp OpReplaceBlockProto: header {
  block {
    poolId: "BP-112083932-172.17.0.7-1606980105622"
    blockId: 1073741832
    generationStamp: 1008
    numBytes: 512
  }
  token {
    identifier: ""
    password: ""
    kind: ""
    service: ""
  }
}
delHint: "d756da44-2378-4af0-be27-9028065cb33e"
source {
  id {
    ipAddr: "127.0.0.1"
    hostName: "127.0.0.1"
    datanodeUuid: "d756da44-2378-4af0-be27-9028065cb33e"
    xferPort: 32811
    infoPort: 38406
    ipcPort: 37726
    infoSecurePort: 0
  }
  capacity: 1922244395008
  dfsUsed: 51767
  remaining: 1198461239296
  blockPoolUsed: 51767
  lastUpdate: 1606980113670
  xceiverCount: 1
  location: "/default-rack"
  nonDfsUsed: 626091398601
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 141102593
  lastBlockReportTime: 1606980113672
  lastBlockReportMonotonic: 141102595
  numBlocks: 0
}
storageType: ARCHIVE

2020-12-03 07:21:53,974 [DataXceiver for client /127.0.0.1:58362 [Replacing block BP-112083932-172.17.0.7-1606980105622:blk_1073741832_1008 from d756da44-2378-4af0-be27-9028065cb33e]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1186)) - Moved BP-112083932-172.17.0.7-1606980105622:blk_1073741832_1008 from StorageType DISK to ARCHIVE
2020-12-03 07:21:53,974 [pool-84-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741832_1008 with size=512 from 127.0.0.1:32811:DISK to 127.0.0.1:32811:ARCHIVE through 127.0.0.1:32811
2020-12-03 07:21:53,975 [Block report processor] WARN  BlockStateChange (BlockManager.java:addStoredBlock(3356)) - BLOCK* addStoredBlock: block blk_1073741832_1008 moved to storageType ARCHIVE on node 127.0.0.1:32811
2020-12-03 07:21:58,958 [Listener at localhost/37726] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:58,959 [Listener at localhost/37726] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:58,962 [IPC Server handler 2 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getDatanodeStorageReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:58,963 [Listener at localhost/37726] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:40228
2020-12-03 07:21:58,963 [Listener at localhost/37726] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:46191
2020-12-03 07:21:58,963 [Listener at localhost/37726] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41276
2020-12-03 07:21:58,963 [Listener at localhost/37726] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:32936
2020-12-03 07:21:58,964 [Listener at localhost/37726] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:33330
2020-12-03 07:21:58,964 [Listener at localhost/37726] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:32811
2020-12-03 07:21:58,965 [IPC Server handler 0 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listSnapshottableDirectory	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:58,966 [IPC Server handler 8 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/	dst=null	perm=null	proto=rpc
2020-12-03 07:21:58,968 [IPC Server handler 4 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/cold/	dst=null	perm=null	proto=rpc
2020-12-03 07:21:58,971 [Listener at localhost/37726] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741825_1001 with size=512 from 127.0.0.1:40228:DISK to 127.0.0.1:40228:ARCHIVE through 127.0.0.1:40228
2020-12-03 07:21:58,985 [pool-87-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741825_1001 with size=512 from 127.0.0.1:40228:DISK to 127.0.0.1:40228:ARCHIVE through 127.0.0.1:40228
2020-12-03 07:21:58,985 [Listener at localhost/37726] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741826_1002 with size=512 from 127.0.0.1:32936:DISK to 127.0.0.1:32936:ARCHIVE through 127.0.0.1:32936
2020-12-03 07:21:58,986 [pool-87-thread-1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:58,986 [Listener at localhost/37726] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741827_1003 with size=512 from 127.0.0.1:40228:DISK to 127.0.0.1:40228:ARCHIVE through 127.0.0.1:40228
2020-12-03 07:21:58,986 [pool-88-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741826_1002 with size=512 from 127.0.0.1:32936:DISK to 127.0.0.1:32936:ARCHIVE through 127.0.0.1:32936
2020-12-03 07:21:58,986 [pool-88-thread-1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:58,986 [pool-87-thread-1] TRACE datatransfer.DataTransferProtocol (Sender.java:send(79)) - Sending DataTransferOp OpReplaceBlockProto: header {
  block {
    poolId: "BP-112083932-172.17.0.7-1606980105622"
    blockId: 1073741825
    generationStamp: 1001
    numBytes: 512
  }
  token {
    identifier: ""
    password: ""
    kind: ""
    service: ""
  }
}
delHint: "4531fc3a-8c15-42c0-ad49-f6505a50dcea"
source {
  id {
    ipAddr: "127.0.0.1"
    hostName: "127.0.0.1"
    datanodeUuid: "4531fc3a-8c15-42c0-ad49-f6505a50dcea"
    xferPort: 40228
    infoPort: 35466
    ipcPort: 41630
    infoSecurePort: 0
  }
  capacity: 1922244395008
  dfsUsed: 53347
  remaining: 1198432526336
  blockPoolUsed: 53347
  lastUpdate: 1606980118169
  xceiverCount: 1
  location: "/default-rack"
  nonDfsUsed: 626120109981
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 141107092
  lastBlockReportTime: 1606980113174
  lastBlockReportMonotonic: 141102096
  numBlocks: 0
}
storageType: ARCHIVE

2020-12-03 07:21:58,987 [pool-88-thread-1] TRACE datatransfer.DataTransferProtocol (Sender.java:send(79)) - Sending DataTransferOp OpReplaceBlockProto: header {
  block {
    poolId: "BP-112083932-172.17.0.7-1606980105622"
    blockId: 1073741826
    generationStamp: 1002
    numBytes: 512
  }
  token {
    identifier: ""
    password: ""
    kind: ""
    service: ""
  }
}
delHint: "fc258908-e76f-48a7-8279-3420f46782bd"
source {
  id {
    ipAddr: "127.0.0.1"
    hostName: "127.0.0.1"
    datanodeUuid: "fc258908-e76f-48a7-8279-3420f46782bd"
    xferPort: 32936
    infoPort: 46144
    ipcPort: 43123
    infoSecurePort: 0
  }
  capacity: 1922244395008
  dfsUsed: 51767
  remaining: 1198432526336
  blockPoolUsed: 51767
  lastUpdate: 1606980118270
  xceiverCount: 1
  location: "/default-rack"
  nonDfsUsed: 626120111561
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 141107193
  lastBlockReportTime: 1606980113274
  lastBlockReportMonotonic: 141102197
  numBlocks: 0
}
storageType: ARCHIVE

2020-12-03 07:21:58,988 [IPC Server handler 9 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/hot/	dst=null	perm=null	proto=rpc
2020-12-03 07:21:58,991 [DataXceiver for client /127.0.0.1:38778 [Replacing block BP-112083932-172.17.0.7-1606980105622:blk_1073741825_1001 from 4531fc3a-8c15-42c0-ad49-f6505a50dcea]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1186)) - Moved BP-112083932-172.17.0.7-1606980105622:blk_1073741825_1001 from StorageType DISK to ARCHIVE
2020-12-03 07:21:58,991 [pool-87-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741825_1001 with size=512 from 127.0.0.1:40228:DISK to 127.0.0.1:40228:ARCHIVE through 127.0.0.1:40228
2020-12-03 07:21:58,993 [pool-87-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741827_1003 with size=512 from 127.0.0.1:40228:DISK to 127.0.0.1:40228:ARCHIVE through 127.0.0.1:40228
2020-12-03 07:21:58,993 [DataXceiver for client /127.0.0.1:56692 [Replacing block BP-112083932-172.17.0.7-1606980105622:blk_1073741826_1002 from fc258908-e76f-48a7-8279-3420f46782bd]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1186)) - Moved BP-112083932-172.17.0.7-1606980105622:blk_1073741826_1002 from StorageType DISK to ARCHIVE
2020-12-03 07:21:58,993 [pool-88-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741826_1002 with size=512 from 127.0.0.1:32936:DISK to 127.0.0.1:32936:ARCHIVE through 127.0.0.1:32936
2020-12-03 07:21:58,993 [pool-87-thread-1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:58,993 [Block report processor] WARN  BlockStateChange (BlockManager.java:addStoredBlock(3356)) - BLOCK* addStoredBlock: block blk_1073741825_1001 moved to storageType ARCHIVE on node 127.0.0.1:40228
2020-12-03 07:21:58,994 [Block report processor] WARN  BlockStateChange (BlockManager.java:addStoredBlock(3356)) - BLOCK* addStoredBlock: block blk_1073741826_1002 moved to storageType ARCHIVE on node 127.0.0.1:32936
2020-12-03 07:21:58,995 [pool-87-thread-1] TRACE datatransfer.DataTransferProtocol (Sender.java:send(79)) - Sending DataTransferOp OpReplaceBlockProto: header {
  block {
    poolId: "BP-112083932-172.17.0.7-1606980105622"
    blockId: 1073741827
    generationStamp: 1003
    numBytes: 512
  }
  token {
    identifier: ""
    password: ""
    kind: ""
    service: ""
  }
}
delHint: "4531fc3a-8c15-42c0-ad49-f6505a50dcea"
source {
  id {
    ipAddr: "127.0.0.1"
    hostName: "127.0.0.1"
    datanodeUuid: "4531fc3a-8c15-42c0-ad49-f6505a50dcea"
    xferPort: 40228
    infoPort: 35466
    ipcPort: 41630
    infoSecurePort: 0
  }
  capacity: 1922244395008
  dfsUsed: 53347
  remaining: 1198432526336
  blockPoolUsed: 53347
  lastUpdate: 1606980118169
  xceiverCount: 1
  location: "/default-rack"
  nonDfsUsed: 626120109981
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 141107092
  lastBlockReportTime: 1606980113174
  lastBlockReportMonotonic: 141102096
  numBlocks: 0
}
storageType: ARCHIVE

2020-12-03 07:21:58,995 [IPC Server handler 6 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/system/	dst=null	perm=null	proto=rpc
2020-12-03 07:21:58,997 [IPC Server handler 7 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/warm/	dst=null	perm=null	proto=rpc
2020-12-03 07:21:58,999 [DataXceiver for client /127.0.0.1:38782 [Replacing block BP-112083932-172.17.0.7-1606980105622:blk_1073741827_1003 from 4531fc3a-8c15-42c0-ad49-f6505a50dcea]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1186)) - Moved BP-112083932-172.17.0.7-1606980105622:blk_1073741827_1003 from StorageType DISK to ARCHIVE
2020-12-03 07:21:59,000 [pool-87-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741827_1003 with size=512 from 127.0.0.1:40228:DISK to 127.0.0.1:40228:ARCHIVE through 127.0.0.1:40228
2020-12-03 07:21:59,000 [Block report processor] WARN  BlockStateChange (BlockManager.java:addStoredBlock(3356)) - BLOCK* addStoredBlock: block blk_1073741827_1003 moved to storageType ARCHIVE on node 127.0.0.1:40228
2020-12-03 07:21:59,001 [Listener at localhost/37726] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741831_1007 with size=512 from 127.0.0.1:40228:DISK to 127.0.0.1:40228:ARCHIVE through 127.0.0.1:40228
2020-12-03 07:21:59,002 [pool-87-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741831_1007 with size=512 from 127.0.0.1:40228:DISK to 127.0.0.1:40228:ARCHIVE through 127.0.0.1:40228
2020-12-03 07:21:59,002 [Listener at localhost/37726] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741832_1008 with size=512 from 127.0.0.1:40228:DISK to 127.0.0.1:40228:ARCHIVE through 127.0.0.1:40228
2020-12-03 07:21:59,002 [pool-87-thread-1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:59,002 [Listener at localhost/37726] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741833_1009 with size=512 from 127.0.0.1:32811:DISK to 127.0.0.1:32811:ARCHIVE through 127.0.0.1:32811
2020-12-03 07:21:59,003 [pool-89-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741833_1009 with size=512 from 127.0.0.1:32811:DISK to 127.0.0.1:32811:ARCHIVE through 127.0.0.1:32811
2020-12-03 07:21:59,003 [pool-89-thread-1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:59,004 [pool-87-thread-1] TRACE datatransfer.DataTransferProtocol (Sender.java:send(79)) - Sending DataTransferOp OpReplaceBlockProto: header {
  block {
    poolId: "BP-112083932-172.17.0.7-1606980105622"
    blockId: 1073741831
    generationStamp: 1007
    numBytes: 512
  }
  token {
    identifier: ""
    password: ""
    kind: ""
    service: ""
  }
}
delHint: "4531fc3a-8c15-42c0-ad49-f6505a50dcea"
source {
  id {
    ipAddr: "127.0.0.1"
    hostName: "127.0.0.1"
    datanodeUuid: "4531fc3a-8c15-42c0-ad49-f6505a50dcea"
    xferPort: 40228
    infoPort: 35466
    ipcPort: 41630
    infoSecurePort: 0
  }
  capacity: 1922244395008
  dfsUsed: 53347
  remaining: 1198432526336
  blockPoolUsed: 53347
  lastUpdate: 1606980118169
  xceiverCount: 1
  location: "/default-rack"
  nonDfsUsed: 626120109981
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 141107092
  lastBlockReportTime: 1606980113174
  lastBlockReportMonotonic: 141102096
  numBlocks: 0
}
storageType: ARCHIVE

2020-12-03 07:21:59,004 [pool-89-thread-1] TRACE datatransfer.DataTransferProtocol (Sender.java:send(79)) - Sending DataTransferOp OpReplaceBlockProto: header {
  block {
    poolId: "BP-112083932-172.17.0.7-1606980105622"
    blockId: 1073741833
    generationStamp: 1009
    numBytes: 512
  }
  token {
    identifier: ""
    password: ""
    kind: ""
    service: ""
  }
}
delHint: "d756da44-2378-4af0-be27-9028065cb33e"
source {
  id {
    ipAddr: "127.0.0.1"
    hostName: "127.0.0.1"
    datanodeUuid: "d756da44-2378-4af0-be27-9028065cb33e"
    xferPort: 32811
    infoPort: 38406
    ipcPort: 37726
    infoSecurePort: 0
  }
  capacity: 1922244395008
  dfsUsed: 51800
  remaining: 1198432477184
  blockPoolUsed: 51800
  lastUpdate: 1606980118669
  xceiverCount: 1
  location: "/default-rack"
  nonDfsUsed: 626120160680
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 141107592
  lastBlockReportTime: 1606980113672
  lastBlockReportMonotonic: 141102595
  numBlocks: 0
}
storageType: ARCHIVE

2020-12-03 07:21:59,008 [DataXceiver for client /127.0.0.1:38784 [Replacing block BP-112083932-172.17.0.7-1606980105622:blk_1073741831_1007 from 4531fc3a-8c15-42c0-ad49-f6505a50dcea]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1186)) - Moved BP-112083932-172.17.0.7-1606980105622:blk_1073741831_1007 from StorageType DISK to ARCHIVE
2020-12-03 07:21:59,008 [DataXceiver for client /127.0.0.1:58612 [Replacing block BP-112083932-172.17.0.7-1606980105622:blk_1073741833_1009 from d756da44-2378-4af0-be27-9028065cb33e]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1186)) - Moved BP-112083932-172.17.0.7-1606980105622:blk_1073741833_1009 from StorageType DISK to ARCHIVE
2020-12-03 07:21:59,008 [pool-87-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741831_1007 with size=512 from 127.0.0.1:40228:DISK to 127.0.0.1:40228:ARCHIVE through 127.0.0.1:40228
2020-12-03 07:21:59,009 [pool-87-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741832_1008 with size=512 from 127.0.0.1:40228:DISK to 127.0.0.1:40228:ARCHIVE through 127.0.0.1:40228
2020-12-03 07:21:59,009 [pool-89-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741833_1009 with size=512 from 127.0.0.1:32811:DISK to 127.0.0.1:32811:ARCHIVE through 127.0.0.1:32811
2020-12-03 07:21:59,010 [Block report processor] WARN  BlockStateChange (BlockManager.java:addStoredBlock(3356)) - BLOCK* addStoredBlock: block blk_1073741831_1007 moved to storageType ARCHIVE on node 127.0.0.1:40228
2020-12-03 07:21:59,010 [pool-87-thread-1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:59,010 [Block report processor] WARN  BlockStateChange (BlockManager.java:addStoredBlock(3356)) - BLOCK* addStoredBlock: block blk_1073741833_1009 moved to storageType ARCHIVE on node 127.0.0.1:32811
2020-12-03 07:21:59,011 [pool-87-thread-1] TRACE datatransfer.DataTransferProtocol (Sender.java:send(79)) - Sending DataTransferOp OpReplaceBlockProto: header {
  block {
    poolId: "BP-112083932-172.17.0.7-1606980105622"
    blockId: 1073741832
    generationStamp: 1008
    numBytes: 512
  }
  token {
    identifier: ""
    password: ""
    kind: ""
    service: ""
  }
}
delHint: "4531fc3a-8c15-42c0-ad49-f6505a50dcea"
source {
  id {
    ipAddr: "127.0.0.1"
    hostName: "127.0.0.1"
    datanodeUuid: "4531fc3a-8c15-42c0-ad49-f6505a50dcea"
    xferPort: 40228
    infoPort: 35466
    ipcPort: 41630
    infoSecurePort: 0
  }
  capacity: 1922244395008
  dfsUsed: 53347
  remaining: 1198432526336
  blockPoolUsed: 53347
  lastUpdate: 1606980118169
  xceiverCount: 1
  location: "/default-rack"
  nonDfsUsed: 626120109981
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 141107092
  lastBlockReportTime: 1606980113174
  lastBlockReportMonotonic: 141102096
  numBlocks: 0
}
storageType: ARCHIVE

2020-12-03 07:21:59,013 [DataXceiver for client /127.0.0.1:38788 [Replacing block BP-112083932-172.17.0.7-1606980105622:blk_1073741832_1008 from 4531fc3a-8c15-42c0-ad49-f6505a50dcea]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1186)) - Moved BP-112083932-172.17.0.7-1606980105622:blk_1073741832_1008 from StorageType DISK to ARCHIVE
2020-12-03 07:21:59,014 [pool-87-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741832_1008 with size=512 from 127.0.0.1:40228:DISK to 127.0.0.1:40228:ARCHIVE through 127.0.0.1:40228
2020-12-03 07:21:59,014 [Block report processor] WARN  BlockStateChange (BlockManager.java:addStoredBlock(3356)) - BLOCK* addStoredBlock: block blk_1073741832_1008 moved to storageType ARCHIVE on node 127.0.0.1:40228
2020-12-03 07:22:04,003 [Listener at localhost/37726] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:04,004 [Listener at localhost/37726] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:04,007 [IPC Server handler 0 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getDatanodeStorageReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:04,008 [Listener at localhost/37726] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:40228
2020-12-03 07:22:04,009 [Listener at localhost/37726] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:32811
2020-12-03 07:22:04,009 [Listener at localhost/37726] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:33330
2020-12-03 07:22:04,009 [Listener at localhost/37726] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41276
2020-12-03 07:22:04,009 [Listener at localhost/37726] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:32936
2020-12-03 07:22:04,009 [Listener at localhost/37726] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:46191
2020-12-03 07:22:04,010 [IPC Server handler 8 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listSnapshottableDirectory	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:04,012 [IPC Server handler 4 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/	dst=null	perm=null	proto=rpc
2020-12-03 07:22:04,014 [IPC Server handler 9 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/cold/	dst=null	perm=null	proto=rpc
2020-12-03 07:22:04,017 [Listener at localhost/37726] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741825_1001 with size=512 from 127.0.0.1:46191:DISK to 127.0.0.1:46191:ARCHIVE through 127.0.0.1:46191
2020-12-03 07:22:04,017 [Listener at localhost/37726] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741826_1002 with size=512 from 127.0.0.1:33330:DISK to 127.0.0.1:33330:ARCHIVE through 127.0.0.1:33330
2020-12-03 07:22:04,017 [pool-90-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741825_1001 with size=512 from 127.0.0.1:46191:DISK to 127.0.0.1:46191:ARCHIVE through 127.0.0.1:46191
2020-12-03 07:22:04,018 [Listener at localhost/37726] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741827_1003 with size=512 from 127.0.0.1:32936:DISK to 127.0.0.1:32936:ARCHIVE through 127.0.0.1:32936
2020-12-03 07:22:04,018 [pool-91-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741826_1002 with size=512 from 127.0.0.1:33330:DISK to 127.0.0.1:33330:ARCHIVE through 127.0.0.1:33330
2020-12-03 07:22:04,018 [pool-90-thread-1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:04,018 [pool-92-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741827_1003 with size=512 from 127.0.0.1:32936:DISK to 127.0.0.1:32936:ARCHIVE through 127.0.0.1:32936
2020-12-03 07:22:04,018 [pool-91-thread-1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:04,019 [pool-92-thread-1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:04,019 [pool-90-thread-1] TRACE datatransfer.DataTransferProtocol (Sender.java:send(79)) - Sending DataTransferOp OpReplaceBlockProto: header {
  block {
    poolId: "BP-112083932-172.17.0.7-1606980105622"
    blockId: 1073741825
    generationStamp: 1001
    numBytes: 512
  }
  token {
    identifier: ""
    password: ""
    kind: ""
    service: ""
  }
}
delHint: "7b793216-748f-4be6-a144-367935ffbafb"
source {
  id {
    ipAddr: "127.0.0.1"
    hostName: "127.0.0.1"
    datanodeUuid: "7b793216-748f-4be6-a144-367935ffbafb"
    xferPort: 46191
    infoPort: 38566
    ipcPort: 41609
    infoSecurePort: 0
  }
  capacity: 1922244395008
  dfsUsed: 51778
  remaining: 1198447616000
  blockPoolUsed: 51778
  lastUpdate: 1606980123368
  xceiverCount: 1
  location: "/default-rack"
  nonDfsUsed: 626105021886
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 141112291
  lastBlockReportTime: 1606980113372
  lastBlockReportMonotonic: 141102294
  numBlocks: 0
}
storageType: ARCHIVE

2020-12-03 07:22:04,019 [pool-91-thread-1] TRACE datatransfer.DataTransferProtocol (Sender.java:send(79)) - Sending DataTransferOp OpReplaceBlockProto: header {
  block {
    poolId: "BP-112083932-172.17.0.7-1606980105622"
    blockId: 1073741826
    generationStamp: 1002
    numBytes: 512
  }
  token {
    identifier: ""
    password: ""
    kind: ""
    service: ""
  }
}
delHint: "0237cc88-214f-4ecc-9fca-2ef3974ab7eb"
source {
  id {
    ipAddr: "127.0.0.1"
    hostName: "127.0.0.1"
    datanodeUuid: "0237cc88-214f-4ecc-9fca-2ef3974ab7eb"
    xferPort: 33330
    infoPort: 37559
    ipcPort: 33221
    infoSecurePort: 0
  }
  capacity: 1922244395008
  dfsUsed: 50721
  remaining: 1198447583232
  blockPoolUsed: 50721
  lastUpdate: 1606980123470
  xceiverCount: 1
  location: "/default-rack"
  nonDfsUsed: 626105055711
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 141112393
  lastBlockReportTime: 1606980113471
  lastBlockReportMonotonic: 141102394
  numBlocks: 0
}
storageType: ARCHIVE

2020-12-03 07:22:04,019 [pool-92-thread-1] TRACE datatransfer.DataTransferProtocol (Sender.java:send(79)) - Sending DataTransferOp OpReplaceBlockProto: header {
  block {
    poolId: "BP-112083932-172.17.0.7-1606980105622"
    blockId: 1073741827
    generationStamp: 1003
    numBytes: 512
  }
  token {
    identifier: ""
    password: ""
    kind: ""
    service: ""
  }
}
delHint: "fc258908-e76f-48a7-8279-3420f46782bd"
source {
  id {
    ipAddr: "127.0.0.1"
    hostName: "127.0.0.1"
    datanodeUuid: "fc258908-e76f-48a7-8279-3420f46782bd"
    xferPort: 32936
    infoPort: 46144
    ipcPort: 43123
    infoSecurePort: 0
  }
  capacity: 1922244395008
  dfsUsed: 51778
  remaining: 1198447681536
  blockPoolUsed: 51778
  lastUpdate: 1606980123269
  xceiverCount: 1
  location: "/default-rack"
  nonDfsUsed: 626104956350
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 141112192
  lastBlockReportTime: 1606980113274
  lastBlockReportMonotonic: 141102197
  numBlocks: 0
}
storageType: ARCHIVE

2020-12-03 07:22:04,021 [IPC Server handler 3 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/hot/	dst=null	perm=null	proto=rpc
2020-12-03 07:22:04,023 [DataXceiver for client /127.0.0.1:56782 [Replacing block BP-112083932-172.17.0.7-1606980105622:blk_1073741827_1003 from fc258908-e76f-48a7-8279-3420f46782bd]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1186)) - Moved BP-112083932-172.17.0.7-1606980105622:blk_1073741827_1003 from StorageType DISK to ARCHIVE
2020-12-03 07:22:04,026 [pool-92-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741827_1003 with size=512 from 127.0.0.1:32936:DISK to 127.0.0.1:32936:ARCHIVE through 127.0.0.1:32936
2020-12-03 07:22:04,026 [DataXceiver for client /127.0.0.1:41228 [Replacing block BP-112083932-172.17.0.7-1606980105622:blk_1073741826_1002 from 0237cc88-214f-4ecc-9fca-2ef3974ab7eb]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1186)) - Moved BP-112083932-172.17.0.7-1606980105622:blk_1073741826_1002 from StorageType DISK to ARCHIVE
2020-12-03 07:22:04,026 [DataXceiver for client /127.0.0.1:58698 [Replacing block BP-112083932-172.17.0.7-1606980105622:blk_1073741825_1001 from 7b793216-748f-4be6-a144-367935ffbafb]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1186)) - Moved BP-112083932-172.17.0.7-1606980105622:blk_1073741825_1001 from StorageType DISK to ARCHIVE
2020-12-03 07:22:04,027 [pool-91-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741826_1002 with size=512 from 127.0.0.1:33330:DISK to 127.0.0.1:33330:ARCHIVE through 127.0.0.1:33330
2020-12-03 07:22:04,028 [pool-90-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741825_1001 with size=512 from 127.0.0.1:46191:DISK to 127.0.0.1:46191:ARCHIVE through 127.0.0.1:46191
2020-12-03 07:22:04,030 [Block report processor] WARN  BlockStateChange (BlockManager.java:addStoredBlock(3356)) - BLOCK* addStoredBlock: block blk_1073741827_1003 moved to storageType ARCHIVE on node 127.0.0.1:32936
2020-12-03 07:22:04,030 [Block report processor] WARN  BlockStateChange (BlockManager.java:addStoredBlock(3356)) - BLOCK* addStoredBlock: block blk_1073741825_1001 moved to storageType ARCHIVE on node 127.0.0.1:46191
2020-12-03 07:22:04,030 [Block report processor] WARN  BlockStateChange (BlockManager.java:addStoredBlock(3356)) - BLOCK* addStoredBlock: block blk_1073741826_1002 moved to storageType ARCHIVE on node 127.0.0.1:33330
2020-12-03 07:22:04,031 [IPC Server handler 5 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/system/	dst=null	perm=null	proto=rpc
2020-12-03 07:22:04,032 [IPC Server handler 2 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/warm/	dst=null	perm=null	proto=rpc
2020-12-03 07:22:04,036 [IPC Server handler 0 on default port 44902] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /system/mover.id is closed by DFSClient_NONMAPREDUCE_-391545094_1
2020-12-03 07:22:04,047 [IPC Server handler 8 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/system/mover.id	dst=null	perm=null	proto=rpc
Mover Successful: all blocks satisfy the specified storage policy. Exiting...
2020-12-03 07:22:13,053 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:44902
2020-12-03 07:22:13,055 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x34913344e47fcf68: from storage DS-98c5da98-47d1-4ec8-8c42-db45703eedeb node DatanodeRegistration(127.0.0.1:40228, datanodeUuid=4531fc3a-8c15-42c0-ad49-f6505a50dcea, infoPort=35466, infoSecurePort=0, ipcPort=41630, storageInfo=lv=-57;cid=testClusterID;nsid=543616343;c=1606980105622), blocks: 3, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:13,056 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x34913344e47fcf68: from storage DS-45d26ee9-5330-4328-a6f5-9d5cae8072d4 node DatanodeRegistration(127.0.0.1:40228, datanodeUuid=4531fc3a-8c15-42c0-ad49-f6505a50dcea, infoPort=35466, infoSecurePort=0, ipcPort=41630, storageInfo=lv=-57;cid=testClusterID;nsid=543616343;c=1606980105622), blocks: 5, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:22:13,056 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x34913344e47fcf68,  containing 2 storage report(s), of which we sent 2. The reports had 8 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:13,056 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-112083932-172.17.0.7-1606980105622
2020-12-03 07:22:13,154 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:44902
2020-12-03 07:22:13,155 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xfc8314b2c08b8c8e: from storage DS-c5bce671-868b-4fa8-afa7-49e9ec5526a2 node DatanodeRegistration(127.0.0.1:32936, datanodeUuid=fc258908-e76f-48a7-8279-3420f46782bd, infoPort=46144, infoSecurePort=0, ipcPort=43123, storageInfo=lv=-57;cid=testClusterID;nsid=543616343;c=1606980105622), blocks: 3, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:13,156 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xfc8314b2c08b8c8e: from storage DS-d4b106f7-6476-43e5-bebc-4d76f054903f node DatanodeRegistration(127.0.0.1:32936, datanodeUuid=fc258908-e76f-48a7-8279-3420f46782bd, infoPort=46144, infoSecurePort=0, ipcPort=43123, storageInfo=lv=-57;cid=testClusterID;nsid=543616343;c=1606980105622), blocks: 2, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:22:13,156 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xfc8314b2c08b8c8e,  containing 2 storage report(s), of which we sent 2. The reports had 5 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:13,156 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-112083932-172.17.0.7-1606980105622
2020-12-03 07:22:13,254 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:44902
2020-12-03 07:22:13,255 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xc4cf9a8c92a7c44c: from storage DS-ae119148-187a-42b8-a576-43913a2cea7b node DatanodeRegistration(127.0.0.1:46191, datanodeUuid=7b793216-748f-4be6-a144-367935ffbafb, infoPort=38566, infoSecurePort=0, ipcPort=41609, storageInfo=lv=-57;cid=testClusterID;nsid=543616343;c=1606980105622), blocks: 2, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:13,255 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xc4cf9a8c92a7c44c: from storage DS-dfbdbbaa-c98a-4ba8-8504-1c726531280a node DatanodeRegistration(127.0.0.1:46191, datanodeUuid=7b793216-748f-4be6-a144-367935ffbafb, infoPort=38566, infoSecurePort=0, ipcPort=41609, storageInfo=lv=-57;cid=testClusterID;nsid=543616343;c=1606980105622), blocks: 3, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:13,256 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xc4cf9a8c92a7c44c,  containing 2 storage report(s), of which we sent 2. The reports had 5 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:13,256 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-112083932-172.17.0.7-1606980105622
2020-12-03 07:22:13,354 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:44902
2020-12-03 07:22:13,355 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xf8fb16a3530b4cf5: from storage DS-8e084a11-8a03-4947-83b2-a2598a529f6c node DatanodeRegistration(127.0.0.1:33330, datanodeUuid=0237cc88-214f-4ecc-9fca-2ef3974ab7eb, infoPort=37559, infoSecurePort=0, ipcPort=33221, storageInfo=lv=-57;cid=testClusterID;nsid=543616343;c=1606980105622), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:13,356 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xf8fb16a3530b4cf5: from storage DS-d75ea7b4-2fee-44a5-844d-faa34ba6681d node DatanodeRegistration(127.0.0.1:33330, datanodeUuid=0237cc88-214f-4ecc-9fca-2ef3974ab7eb, infoPort=37559, infoSecurePort=0, ipcPort=33221, storageInfo=lv=-57;cid=testClusterID;nsid=543616343;c=1606980105622), blocks: 2, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:22:13,356 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xf8fb16a3530b4cf5,  containing 2 storage report(s), of which we sent 2. The reports had 3 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:13,356 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-112083932-172.17.0.7-1606980105622
2020-12-03 07:22:13,454 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:44902
2020-12-03 07:22:13,455 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x219f0ed3ff786fa6: from storage DS-0e0d2a62-0a95-4405-ac61-c36d0ad42c39 node DatanodeRegistration(127.0.0.1:41276, datanodeUuid=002461fc-4aa8-4d26-86c3-971092b194a6, infoPort=35624, infoSecurePort=0, ipcPort=36273, storageInfo=lv=-57;cid=testClusterID;nsid=543616343;c=1606980105622), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:13,456 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x219f0ed3ff786fa6: from storage DS-d45ac532-8cf5-4065-bea9-b33e7114dc7d node DatanodeRegistration(127.0.0.1:41276, datanodeUuid=002461fc-4aa8-4d26-86c3-971092b194a6, infoPort=35624, infoSecurePort=0, ipcPort=36273, storageInfo=lv=-57;cid=testClusterID;nsid=543616343;c=1606980105622), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:22:13,456 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x219f0ed3ff786fa6,  containing 2 storage report(s), of which we sent 2. The reports had 1 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:13,456 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-112083932-172.17.0.7-1606980105622
2020-12-03 07:22:13,554 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:44902
2020-12-03 07:22:13,556 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x2af71878c25e8977: from storage DS-7ba7554c-5ca9-4cc9-a977-6f21fc38dd76 node DatanodeRegistration(127.0.0.1:32811, datanodeUuid=d756da44-2378-4af0-be27-9028065cb33e, infoPort=38406, infoSecurePort=0, ipcPort=37726, storageInfo=lv=-57;cid=testClusterID;nsid=543616343;c=1606980105622), blocks: 4, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:22:13,556 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x2af71878c25e8977: from storage DS-1bb59e4f-55f8-43b4-92c0-6f9216074971 node DatanodeRegistration(127.0.0.1:32811, datanodeUuid=d756da44-2378-4af0-be27-9028065cb33e, infoPort=38406, infoSecurePort=0, ipcPort=37726, storageInfo=lv=-57;cid=testClusterID;nsid=543616343;c=1606980105622), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:13,557 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x2af71878c25e8977,  containing 2 storage report(s), of which we sent 2. The reports had 5 total blocks and used 1 RPC(s). This took 1 msec to generate and 1 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:13,557 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-112083932-172.17.0.7-1606980105622
2020-12-03 07:22:13,654 [IPC Server handler 3 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/	dst=null	perm=null	proto=rpc
2020-12-03 07:22:13,655 [IPC Server handler 1 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/	dst=null	perm=null	proto=rpc
2020-12-03 07:22:13,657 [IPC Server handler 6 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/cold	dst=null	perm=null	proto=rpc
2020-12-03 07:22:13,663 [IPC Server handler 7 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/hot	dst=null	perm=null	proto=rpc
2020-12-03 07:22:13,666 [IPC Server handler 5 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/system	dst=null	perm=null	proto=rpc
2020-12-03 07:22:13,667 [IPC Server handler 0 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/warm	dst=null	perm=null	proto=rpc
2020-12-03 07:22:13,670 [Listener at localhost/37726] INFO  mover.TestStorageMover (TestStorageMover.java:moveAround(463)) - rename /cold/file0 to /hot/cold2hot
2020-12-03 07:22:13,678 [IPC Server handler 2 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=rename	src=/cold/file0	dst=/hot/cold2hot	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:22:13,681 [Listener at localhost/37726] INFO  mover.TestStorageMover (TestStorageMover.java:moveAround(463)) - rename /cold/file1 to /warm/cold2warm
2020-12-03 07:22:13,682 [IPC Server handler 8 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=rename	src=/cold/file1	dst=/warm/cold2warm	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:22:13,683 [Listener at localhost/37726] INFO  mover.TestStorageMover (TestStorageMover.java:moveAround(463)) - rename /hot/file0 to /cold/hot2cold
2020-12-03 07:22:13,684 [IPC Server handler 4 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=rename	src=/hot/file0	dst=/cold/hot2cold	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:22:13,684 [Listener at localhost/37726] INFO  mover.TestStorageMover (TestStorageMover.java:moveAround(463)) - rename /hot/file1 to /warm/hot2warm
2020-12-03 07:22:13,686 [IPC Server handler 9 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=rename	src=/hot/file1	dst=/warm/hot2warm	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:22:13,686 [Listener at localhost/37726] INFO  mover.TestStorageMover (TestStorageMover.java:moveAround(463)) - rename /warm/file0 to /cold/warm2cold
2020-12-03 07:22:13,687 [IPC Server handler 3 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=rename	src=/warm/file0	dst=/cold/warm2cold	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:22:13,688 [Listener at localhost/37726] INFO  mover.TestStorageMover (TestStorageMover.java:moveAround(463)) - rename /warm/file1 to /hot/warm2hot
2020-12-03 07:22:13,689 [IPC Server handler 1 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=rename	src=/warm/file1	dst=/hot/warm2hot	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:22:13,690 [Listener at localhost/37726] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:13,690 [Listener at localhost/37726] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.redundancy.interval.seconds(2) assuming SECONDS
2020-12-03 07:22:13,690 [Listener at localhost/37726] INFO  mover.Mover (Mover.java:run(642)) - namenodes = {hdfs://localhost:44902=null}
2020-12-03 07:22:13,695 [IPC Server handler 5 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/system/mover.id	dst=null	perm=null	proto=rpc
2020-12-03 07:22:13,697 [IPC Server handler 0 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/system/mover.id	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:22:13,699 [IPC Server handler 2 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/system/mover.id	dst=null	perm=null	proto=rpc
2020-12-03 07:22:13,699 [Listener at localhost/37726] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:13,700 [Listener at localhost/37726] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:13,701 [IPC Server handler 4 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getDatanodeStorageReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:13,702 [Listener at localhost/37726] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:40228
2020-12-03 07:22:13,702 [Listener at localhost/37726] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:33330
2020-12-03 07:22:13,703 [Listener at localhost/37726] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:46191
2020-12-03 07:22:13,703 [Listener at localhost/37726] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:32936
2020-12-03 07:22:13,703 [Listener at localhost/37726] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41276
2020-12-03 07:22:13,703 [Listener at localhost/37726] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:32811
2020-12-03 07:22:13,704 [IPC Server handler 9 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listSnapshottableDirectory	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:13,705 [IPC Server handler 3 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/	dst=null	perm=null	proto=rpc
2020-12-03 07:22:13,707 [IPC Server handler 1 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/cold/	dst=null	perm=null	proto=rpc
2020-12-03 07:22:13,709 [Listener at localhost/37726] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741828_1004 with size=512 from 127.0.0.1:46191:DISK to 127.0.0.1:46191:ARCHIVE through 127.0.0.1:46191
2020-12-03 07:22:13,709 [pool-93-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741828_1004 with size=512 from 127.0.0.1:46191:DISK to 127.0.0.1:46191:ARCHIVE through 127.0.0.1:46191
2020-12-03 07:22:13,709 [Listener at localhost/37726] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741831_1007 with size=512 from 127.0.0.1:32936:DISK to 127.0.0.1:32936:ARCHIVE through 127.0.0.1:32936
2020-12-03 07:22:13,710 [pool-93-thread-1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:13,710 [pool-94-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741831_1007 with size=512 from 127.0.0.1:32936:DISK to 127.0.0.1:32936:ARCHIVE through 127.0.0.1:32936
2020-12-03 07:22:13,710 [pool-94-thread-1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:13,711 [IPC Server handler 6 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/hot/	dst=null	perm=null	proto=rpc
2020-12-03 07:22:13,713 [pool-94-thread-1] TRACE datatransfer.DataTransferProtocol (Sender.java:send(79)) - Sending DataTransferOp OpReplaceBlockProto: header {
  block {
    poolId: "BP-112083932-172.17.0.7-1606980105622"
    blockId: 1073741831
    generationStamp: 1007
    numBytes: 512
  }
  token {
    identifier: ""
    password: ""
    kind: ""
    service: ""
  }
}
delHint: "fc258908-e76f-48a7-8279-3420f46782bd"
source {
  id {
    ipAddr: "127.0.0.1"
    hostName: "127.0.0.1"
    datanodeUuid: "fc258908-e76f-48a7-8279-3420f46782bd"
    xferPort: 32936
    infoPort: 46144
    ipcPort: 43123
    infoSecurePort: 0
  }
  capacity: 1922244395008
  dfsUsed: 51789
  remaining: 1198477090816
  blockPoolUsed: 51789
  lastUpdate: 1606980133153
  xceiverCount: 1
  location: "/default-rack"
  nonDfsUsed: 626075547059
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 141122076
  lastBlockReportTime: 1606980133156
  lastBlockReportMonotonic: 141122079
  numBlocks: 0
}
storageType: ARCHIVE

2020-12-03 07:22:13,713 [Listener at localhost/37726] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741825_1001 with size=512 from 127.0.0.1:41276:ARCHIVE to 127.0.0.1:41276:DISK through 127.0.0.1:41276
2020-12-03 07:22:13,713 [pool-93-thread-1] TRACE datatransfer.DataTransferProtocol (Sender.java:send(79)) - Sending DataTransferOp OpReplaceBlockProto: header {
  block {
    poolId: "BP-112083932-172.17.0.7-1606980105622"
    blockId: 1073741828
    generationStamp: 1004
    numBytes: 512
  }
  token {
    identifier: ""
    password: ""
    kind: ""
    service: ""
  }
}
delHint: "7b793216-748f-4be6-a144-367935ffbafb"
source {
  id {
    ipAddr: "127.0.0.1"
    hostName: "127.0.0.1"
    datanodeUuid: "7b793216-748f-4be6-a144-367935ffbafb"
    xferPort: 46191
    infoPort: 38566
    ipcPort: 41609
    infoSecurePort: 0
  }
  capacity: 1922244395008
  dfsUsed: 51789
  remaining: 1198477058048
  blockPoolUsed: 51789
  lastUpdate: 1606980133253
  xceiverCount: 1
  location: "/default-rack"
  nonDfsUsed: 626075579827
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 141122176
  lastBlockReportTime: 1606980133255
  lastBlockReportMonotonic: 141122178
  numBlocks: 0
}
storageType: ARCHIVE

2020-12-03 07:22:13,713 [Listener at localhost/37726] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741832_1008 with size=512 from 127.0.0.1:32811:ARCHIVE to 127.0.0.1:32811:DISK through 127.0.0.1:32811
2020-12-03 07:22:13,714 [pool-95-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741825_1001 with size=512 from 127.0.0.1:41276:ARCHIVE to 127.0.0.1:41276:DISK through 127.0.0.1:41276
2020-12-03 07:22:13,714 [pool-96-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741832_1008 with size=512 from 127.0.0.1:32811:ARCHIVE to 127.0.0.1:32811:DISK through 127.0.0.1:32811
2020-12-03 07:22:13,714 [pool-95-thread-1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:13,714 [pool-96-thread-1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:13,715 [IPC Server handler 7 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/system/	dst=null	perm=null	proto=rpc
2020-12-03 07:22:13,715 [pool-96-thread-1] TRACE datatransfer.DataTransferProtocol (Sender.java:send(79)) - Sending DataTransferOp OpReplaceBlockProto: header {
  block {
    poolId: "BP-112083932-172.17.0.7-1606980105622"
    blockId: 1073741832
    generationStamp: 1008
    numBytes: 512
  }
  token {
    identifier: ""
    password: ""
    kind: ""
    service: ""
  }
}
delHint: "d756da44-2378-4af0-be27-9028065cb33e"
source {
  id {
    ipAddr: "127.0.0.1"
    hostName: "127.0.0.1"
    datanodeUuid: "d756da44-2378-4af0-be27-9028065cb33e"
    xferPort: 32811
    infoPort: 38406
    ipcPort: 37726
    infoSecurePort: 0
  }
  capacity: 1922244395008
  dfsUsed: 51811
  remaining: 1198476951552
  blockPoolUsed: 51811
  lastUpdate: 1606980133554
  xceiverCount: 1
  location: "/default-rack"
  nonDfsUsed: 626075686301
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 141122477
  lastBlockReportTime: 1606980133556
  lastBlockReportMonotonic: 141122479
  numBlocks: 0
}
storageType: DISK

2020-12-03 07:22:13,715 [pool-95-thread-1] TRACE datatransfer.DataTransferProtocol (Sender.java:send(79)) - Sending DataTransferOp OpReplaceBlockProto: header {
  block {
    poolId: "BP-112083932-172.17.0.7-1606980105622"
    blockId: 1073741825
    generationStamp: 1001
    numBytes: 512
  }
  token {
    identifier: ""
    password: ""
    kind: ""
    service: ""
  }
}
delHint: "002461fc-4aa8-4d26-86c3-971092b194a6"
source {
  id {
    ipAddr: "127.0.0.1"
    hostName: "127.0.0.1"
    datanodeUuid: "002461fc-4aa8-4d26-86c3-971092b194a6"
    xferPort: 41276
    infoPort: 35624
    ipcPort: 36273
    infoSecurePort: 0
  }
  capacity: 1922244395008
  dfsUsed: 49686
  remaining: 1198476918784
  blockPoolUsed: 49686
  lastUpdate: 1606980133454
  xceiverCount: 1
  location: "/default-rack"
  nonDfsUsed: 626075721194
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 141122377
  lastBlockReportTime: 1606980133456
  lastBlockReportMonotonic: 141122379
  numBlocks: 0
}
storageType: DISK

2020-12-03 07:22:13,716 [DataXceiver for client /127.0.0.1:58746 [Replacing block BP-112083932-172.17.0.7-1606980105622:blk_1073741828_1004 from 7b793216-748f-4be6-a144-367935ffbafb]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1186)) - Moved BP-112083932-172.17.0.7-1606980105622:blk_1073741828_1004 from StorageType DISK to ARCHIVE
2020-12-03 07:22:13,716 [IPC Server handler 5 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/warm/	dst=null	perm=null	proto=rpc
2020-12-03 07:22:13,719 [pool-93-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741828_1004 with size=512 from 127.0.0.1:46191:DISK to 127.0.0.1:46191:ARCHIVE through 127.0.0.1:46191
2020-12-03 07:22:13,719 [DataXceiver for client /127.0.0.1:56828 [Replacing block BP-112083932-172.17.0.7-1606980105622:blk_1073741831_1007 from fc258908-e76f-48a7-8279-3420f46782bd]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1186)) - Moved BP-112083932-172.17.0.7-1606980105622:blk_1073741831_1007 from StorageType DISK to ARCHIVE
2020-12-03 07:22:13,720 [Block report processor] WARN  BlockStateChange (BlockManager.java:addStoredBlock(3356)) - BLOCK* addStoredBlock: block blk_1073741828_1004 moved to storageType ARCHIVE on node 127.0.0.1:46191
2020-12-03 07:22:13,720 [pool-94-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741831_1007 with size=512 from 127.0.0.1:32936:DISK to 127.0.0.1:32936:ARCHIVE through 127.0.0.1:32936
2020-12-03 07:22:13,721 [Block report processor] WARN  BlockStateChange (BlockManager.java:addStoredBlock(3356)) - BLOCK* addStoredBlock: block blk_1073741831_1007 moved to storageType ARCHIVE on node 127.0.0.1:32936
2020-12-03 07:22:13,723 [Listener at localhost/37726] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741826_1002 with size=512 from 127.0.0.1:32811:ARCHIVE to 127.0.0.1:32811:DISK through 127.0.0.1:32811
2020-12-03 07:22:13,723 [Listener at localhost/37726] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741829_1005 with size=512 from 127.0.0.1:40228:DISK to 127.0.0.1:40228:ARCHIVE through 127.0.0.1:40228
2020-12-03 07:22:13,723 [DataXceiver for client /127.0.0.1:58746 [Replacing block BP-112083932-172.17.0.7-1606980105622:blk_1073741832_1008 from d756da44-2378-4af0-be27-9028065cb33e]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1186)) - Moved BP-112083932-172.17.0.7-1606980105622:blk_1073741832_1008 from StorageType ARCHIVE to DISK
2020-12-03 07:22:13,724 [pool-97-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741829_1005 with size=512 from 127.0.0.1:40228:DISK to 127.0.0.1:40228:ARCHIVE through 127.0.0.1:40228
2020-12-03 07:22:13,724 [DataXceiver for client /127.0.0.1:37588 [Replacing block BP-112083932-172.17.0.7-1606980105622:blk_1073741825_1001 from 002461fc-4aa8-4d26-86c3-971092b194a6]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1186)) - Moved BP-112083932-172.17.0.7-1606980105622:blk_1073741825_1001 from StorageType ARCHIVE to DISK
2020-12-03 07:22:13,724 [pool-96-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741832_1008 with size=512 from 127.0.0.1:32811:ARCHIVE to 127.0.0.1:32811:DISK through 127.0.0.1:32811
2020-12-03 07:22:13,724 [pool-95-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741825_1001 with size=512 from 127.0.0.1:41276:ARCHIVE to 127.0.0.1:41276:DISK through 127.0.0.1:41276
2020-12-03 07:22:13,727 [pool-97-thread-1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:13,727 [Block report processor] WARN  BlockStateChange (BlockManager.java:addStoredBlock(3356)) - BLOCK* addStoredBlock: block blk_1073741825_1001 moved to storageType DISK on node 127.0.0.1:41276
2020-12-03 07:22:13,728 [pool-96-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741826_1002 with size=512 from 127.0.0.1:32811:ARCHIVE to 127.0.0.1:32811:DISK through 127.0.0.1:32811
2020-12-03 07:22:13,728 [Block report processor] WARN  BlockStateChange (BlockManager.java:addStoredBlock(3356)) - BLOCK* addStoredBlock: block blk_1073741832_1008 moved to storageType DISK on node 127.0.0.1:32811
2020-12-03 07:22:13,728 [pool-97-thread-1] TRACE datatransfer.DataTransferProtocol (Sender.java:send(79)) - Sending DataTransferOp OpReplaceBlockProto: header {
  block {
    poolId: "BP-112083932-172.17.0.7-1606980105622"
    blockId: 1073741829
    generationStamp: 1005
    numBytes: 512
  }
  token {
    identifier: ""
    password: ""
    kind: ""
    service: ""
  }
}
delHint: "4531fc3a-8c15-42c0-ad49-f6505a50dcea"
source {
  id {
    ipAddr: "127.0.0.1"
    hostName: "127.0.0.1"
    datanodeUuid: "4531fc3a-8c15-42c0-ad49-f6505a50dcea"
    xferPort: 40228
    infoPort: 35466
    ipcPort: 41630
    infoSecurePort: 0
  }
  capacity: 1922244395008
  dfsUsed: 53391
  remaining: 1198477025280
  blockPoolUsed: 53391
  lastUpdate: 1606980133053
  xceiverCount: 1
  location: "/default-rack"
  nonDfsUsed: 626075610993
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 141121976
  lastBlockReportTime: 1606980133056
  lastBlockReportMonotonic: 141121979
  numBlocks: 0
}
storageType: ARCHIVE

2020-12-03 07:22:13,728 [pool-96-thread-1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:13,729 [pool-96-thread-1] TRACE datatransfer.DataTransferProtocol (Sender.java:send(79)) - Sending DataTransferOp OpReplaceBlockProto: header {
  block {
    poolId: "BP-112083932-172.17.0.7-1606980105622"
    blockId: 1073741826
    generationStamp: 1002
    numBytes: 512
  }
  token {
    identifier: ""
    password: ""
    kind: ""
    service: ""
  }
}
delHint: "d756da44-2378-4af0-be27-9028065cb33e"
source {
  id {
    ipAddr: "127.0.0.1"
    hostName: "127.0.0.1"
    datanodeUuid: "d756da44-2378-4af0-be27-9028065cb33e"
    xferPort: 32811
    infoPort: 38406
    ipcPort: 37726
    infoSecurePort: 0
  }
  capacity: 1922244395008
  dfsUsed: 51811
  remaining: 1198476951552
  blockPoolUsed: 51811
  lastUpdate: 1606980133554
  xceiverCount: 1
  location: "/default-rack"
  nonDfsUsed: 626075686301
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 141122477
  lastBlockReportTime: 1606980133556
  lastBlockReportMonotonic: 141122479
  numBlocks: 0
}
storageType: DISK

2020-12-03 07:22:13,731 [DataXceiver for client /127.0.0.1:38922 [Replacing block BP-112083932-172.17.0.7-1606980105622:blk_1073741829_1005 from 4531fc3a-8c15-42c0-ad49-f6505a50dcea]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1186)) - Moved BP-112083932-172.17.0.7-1606980105622:blk_1073741829_1005 from StorageType DISK to ARCHIVE
2020-12-03 07:22:13,731 [DataXceiver for client /127.0.0.1:58750 [Replacing block BP-112083932-172.17.0.7-1606980105622:blk_1073741826_1002 from d756da44-2378-4af0-be27-9028065cb33e]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1186)) - Moved BP-112083932-172.17.0.7-1606980105622:blk_1073741826_1002 from StorageType ARCHIVE to DISK
2020-12-03 07:22:13,731 [pool-97-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741829_1005 with size=512 from 127.0.0.1:40228:DISK to 127.0.0.1:40228:ARCHIVE through 127.0.0.1:40228
2020-12-03 07:22:13,732 [pool-96-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741826_1002 with size=512 from 127.0.0.1:32811:ARCHIVE to 127.0.0.1:32811:DISK through 127.0.0.1:32811
2020-12-03 07:22:13,732 [Block report processor] WARN  BlockStateChange (BlockManager.java:addStoredBlock(3356)) - BLOCK* addStoredBlock: block blk_1073741829_1005 moved to storageType ARCHIVE on node 127.0.0.1:40228
2020-12-03 07:22:13,733 [Block report processor] WARN  BlockStateChange (BlockManager.java:addStoredBlock(3356)) - BLOCK* addStoredBlock: block blk_1073741826_1002 moved to storageType DISK on node 127.0.0.1:32811
2020-12-03 07:22:18,724 [Listener at localhost/37726] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:18,724 [Listener at localhost/37726] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:18,727 [IPC Server handler 8 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getDatanodeStorageReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:18,729 [Listener at localhost/37726] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:32936
2020-12-03 07:22:18,729 [Listener at localhost/37726] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:33330
2020-12-03 07:22:18,729 [Listener at localhost/37726] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:46191
2020-12-03 07:22:18,730 [Listener at localhost/37726] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41276
2020-12-03 07:22:18,730 [Listener at localhost/37726] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:40228
2020-12-03 07:22:18,730 [Listener at localhost/37726] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:32811
2020-12-03 07:22:18,732 [IPC Server handler 9 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listSnapshottableDirectory	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:18,733 [IPC Server handler 3 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/	dst=null	perm=null	proto=rpc
2020-12-03 07:22:18,737 [IPC Server handler 1 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/cold/	dst=null	perm=null	proto=rpc
2020-12-03 07:22:18,747 [Listener at localhost/37726] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741828_1004 with size=512 from 127.0.0.1:40228:DISK to 127.0.0.1:40228:ARCHIVE through 127.0.0.1:40228
2020-12-03 07:22:18,748 [pool-98-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741828_1004 with size=512 from 127.0.0.1:40228:DISK to 127.0.0.1:40228:ARCHIVE through 127.0.0.1:40228
2020-12-03 07:22:18,748 [pool-98-thread-1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:18,749 [pool-98-thread-1] TRACE datatransfer.DataTransferProtocol (Sender.java:send(79)) - Sending DataTransferOp OpReplaceBlockProto: header {
  block {
    poolId: "BP-112083932-172.17.0.7-1606980105622"
    blockId: 1073741828
    generationStamp: 1004
    numBytes: 512
  }
  token {
    identifier: ""
    password: ""
    kind: ""
    service: ""
  }
}
delHint: "4531fc3a-8c15-42c0-ad49-f6505a50dcea"
source {
  id {
    ipAddr: "127.0.0.1"
    hostName: "127.0.0.1"
    datanodeUuid: "4531fc3a-8c15-42c0-ad49-f6505a50dcea"
    xferPort: 40228
    infoPort: 35466
    ipcPort: 41630
    infoSecurePort: 0
  }
  capacity: 1922244395008
  dfsUsed: 53402
  remaining: 1198481252352
  blockPoolUsed: 53402
  lastUpdate: 1606980138053
  xceiverCount: 1
  location: "/default-rack"
  nonDfsUsed: 626071383910
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 141126976
  lastBlockReportTime: 1606980133056
  lastBlockReportMonotonic: 141121979
  numBlocks: 0
}
storageType: ARCHIVE

2020-12-03 07:22:18,750 [IPC Server handler 6 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/hot/	dst=null	perm=null	proto=rpc
2020-12-03 07:22:18,753 [DataXceiver for client /127.0.0.1:38932 [Replacing block BP-112083932-172.17.0.7-1606980105622:blk_1073741828_1004 from 4531fc3a-8c15-42c0-ad49-f6505a50dcea]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1186)) - Moved BP-112083932-172.17.0.7-1606980105622:blk_1073741828_1004 from StorageType DISK to ARCHIVE
2020-12-03 07:22:18,754 [pool-98-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741828_1004 with size=512 from 127.0.0.1:40228:DISK to 127.0.0.1:40228:ARCHIVE through 127.0.0.1:40228
2020-12-03 07:22:18,754 [Listener at localhost/37726] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741825_1001 with size=512 from 127.0.0.1:40228:ARCHIVE to 127.0.0.1:40228:DISK through 127.0.0.1:40228
2020-12-03 07:22:18,754 [Listener at localhost/37726] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741832_1008 with size=512 from 127.0.0.1:40228:ARCHIVE to 127.0.0.1:40228:DISK through 127.0.0.1:40228
2020-12-03 07:22:18,755 [Block report processor] WARN  BlockStateChange (BlockManager.java:addStoredBlock(3356)) - BLOCK* addStoredBlock: block blk_1073741828_1004 moved to storageType ARCHIVE on node 127.0.0.1:40228
2020-12-03 07:22:18,760 [pool-98-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741825_1001 with size=512 from 127.0.0.1:40228:ARCHIVE to 127.0.0.1:40228:DISK through 127.0.0.1:40228
2020-12-03 07:22:18,761 [pool-98-thread-1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:18,762 [IPC Server handler 0 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/system/	dst=null	perm=null	proto=rpc
2020-12-03 07:22:18,762 [pool-98-thread-1] TRACE datatransfer.DataTransferProtocol (Sender.java:send(79)) - Sending DataTransferOp OpReplaceBlockProto: header {
  block {
    poolId: "BP-112083932-172.17.0.7-1606980105622"
    blockId: 1073741825
    generationStamp: 1001
    numBytes: 512
  }
  token {
    identifier: ""
    password: ""
    kind: ""
    service: ""
  }
}
delHint: "4531fc3a-8c15-42c0-ad49-f6505a50dcea"
source {
  id {
    ipAddr: "127.0.0.1"
    hostName: "127.0.0.1"
    datanodeUuid: "4531fc3a-8c15-42c0-ad49-f6505a50dcea"
    xferPort: 40228
    infoPort: 35466
    ipcPort: 41630
    infoSecurePort: 0
  }
  capacity: 1922244395008
  dfsUsed: 53402
  remaining: 1198481252352
  blockPoolUsed: 53402
  lastUpdate: 1606980138053
  xceiverCount: 1
  location: "/default-rack"
  nonDfsUsed: 626071383910
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 141126976
  lastBlockReportTime: 1606980133056
  lastBlockReportMonotonic: 141121979
  numBlocks: 0
}
storageType: DISK

2020-12-03 07:22:18,765 [IPC Server handler 5 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/warm/	dst=null	perm=null	proto=rpc
2020-12-03 07:22:18,766 [DataXceiver for client /127.0.0.1:38934 [Replacing block BP-112083932-172.17.0.7-1606980105622:blk_1073741825_1001 from 4531fc3a-8c15-42c0-ad49-f6505a50dcea]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1186)) - Moved BP-112083932-172.17.0.7-1606980105622:blk_1073741825_1001 from StorageType ARCHIVE to DISK
2020-12-03 07:22:18,767 [pool-98-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741825_1001 with size=512 from 127.0.0.1:40228:ARCHIVE to 127.0.0.1:40228:DISK through 127.0.0.1:40228
2020-12-03 07:22:18,767 [pool-98-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741832_1008 with size=512 from 127.0.0.1:40228:ARCHIVE to 127.0.0.1:40228:DISK through 127.0.0.1:40228
2020-12-03 07:22:18,768 [pool-98-thread-1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:18,768 [Listener at localhost/37726] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741829_1005 with size=512 from 127.0.0.1:46191:DISK to 127.0.0.1:46191:ARCHIVE through 127.0.0.1:46191
2020-12-03 07:22:18,768 [Block report processor] WARN  BlockStateChange (BlockManager.java:addStoredBlock(3356)) - BLOCK* addStoredBlock: block blk_1073741825_1001 moved to storageType DISK on node 127.0.0.1:40228
2020-12-03 07:22:18,769 [pool-99-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741829_1005 with size=512 from 127.0.0.1:46191:DISK to 127.0.0.1:46191:ARCHIVE through 127.0.0.1:46191
2020-12-03 07:22:18,769 [pool-98-thread-1] TRACE datatransfer.DataTransferProtocol (Sender.java:send(79)) - Sending DataTransferOp OpReplaceBlockProto: header {
  block {
    poolId: "BP-112083932-172.17.0.7-1606980105622"
    blockId: 1073741832
    generationStamp: 1008
    numBytes: 512
  }
  token {
    identifier: ""
    password: ""
    kind: ""
    service: ""
  }
}
delHint: "4531fc3a-8c15-42c0-ad49-f6505a50dcea"
source {
  id {
    ipAddr: "127.0.0.1"
    hostName: "127.0.0.1"
    datanodeUuid: "4531fc3a-8c15-42c0-ad49-f6505a50dcea"
    xferPort: 40228
    infoPort: 35466
    ipcPort: 41630
    infoSecurePort: 0
  }
  capacity: 1922244395008
  dfsUsed: 53402
  remaining: 1198481252352
  blockPoolUsed: 53402
  lastUpdate: 1606980138053
  xceiverCount: 1
  location: "/default-rack"
  nonDfsUsed: 626071383910
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 141126976
  lastBlockReportTime: 1606980133056
  lastBlockReportMonotonic: 141121979
  numBlocks: 0
}
storageType: DISK

2020-12-03 07:22:18,769 [pool-99-thread-1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:18,770 [pool-99-thread-1] TRACE datatransfer.DataTransferProtocol (Sender.java:send(79)) - Sending DataTransferOp OpReplaceBlockProto: header {
  block {
    poolId: "BP-112083932-172.17.0.7-1606980105622"
    blockId: 1073741829
    generationStamp: 1005
    numBytes: 512
  }
  token {
    identifier: ""
    password: ""
    kind: ""
    service: ""
  }
}
delHint: "7b793216-748f-4be6-a144-367935ffbafb"
source {
  id {
    ipAddr: "127.0.0.1"
    hostName: "127.0.0.1"
    datanodeUuid: "7b793216-748f-4be6-a144-367935ffbafb"
    xferPort: 46191
    infoPort: 38566
    ipcPort: 41609
    infoSecurePort: 0
  }
  capacity: 1922244395008
  dfsUsed: 51800
  remaining: 1198481072128
  blockPoolUsed: 51800
  lastUpdate: 1606980138254
  xceiverCount: 1
  location: "/default-rack"
  nonDfsUsed: 626071565736
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 141127177
  lastBlockReportTime: 1606980133255
  lastBlockReportMonotonic: 141122178
  numBlocks: 0
}
storageType: ARCHIVE

2020-12-03 07:22:18,771 [DataXceiver for client /127.0.0.1:38936 [Replacing block BP-112083932-172.17.0.7-1606980105622:blk_1073741832_1008 from 4531fc3a-8c15-42c0-ad49-f6505a50dcea]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1186)) - Moved BP-112083932-172.17.0.7-1606980105622:blk_1073741832_1008 from StorageType ARCHIVE to DISK
2020-12-03 07:22:18,772 [pool-98-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741832_1008 with size=512 from 127.0.0.1:40228:ARCHIVE to 127.0.0.1:40228:DISK through 127.0.0.1:40228
2020-12-03 07:22:18,774 [DataXceiver for client /127.0.0.1:58770 [Replacing block BP-112083932-172.17.0.7-1606980105622:blk_1073741829_1005 from 7b793216-748f-4be6-a144-367935ffbafb]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1186)) - Moved BP-112083932-172.17.0.7-1606980105622:blk_1073741829_1005 from StorageType DISK to ARCHIVE
2020-12-03 07:22:18,775 [pool-99-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741829_1005 with size=512 from 127.0.0.1:46191:DISK to 127.0.0.1:46191:ARCHIVE through 127.0.0.1:46191
2020-12-03 07:22:18,781 [Block report processor] WARN  BlockStateChange (BlockManager.java:addStoredBlock(3356)) - BLOCK* addStoredBlock: block blk_1073741829_1005 moved to storageType ARCHIVE on node 127.0.0.1:46191
2020-12-03 07:22:18,783 [Block report processor] WARN  BlockStateChange (BlockManager.java:addStoredBlock(3356)) - BLOCK* addStoredBlock: block blk_1073741832_1008 moved to storageType DISK on node 127.0.0.1:40228
2020-12-03 07:22:23,769 [Listener at localhost/37726] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:23,769 [Listener at localhost/37726] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:23,772 [IPC Server handler 8 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getDatanodeStorageReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:23,773 [Listener at localhost/37726] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41276
2020-12-03 07:22:23,773 [Listener at localhost/37726] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:46191
2020-12-03 07:22:23,773 [Listener at localhost/37726] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:32936
2020-12-03 07:22:23,773 [Listener at localhost/37726] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:40228
2020-12-03 07:22:23,774 [Listener at localhost/37726] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:33330
2020-12-03 07:22:23,774 [Listener at localhost/37726] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:32811
2020-12-03 07:22:23,775 [IPC Server handler 9 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listSnapshottableDirectory	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:23,776 [IPC Server handler 3 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/	dst=null	perm=null	proto=rpc
2020-12-03 07:22:23,777 [IPC Server handler 1 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/cold/	dst=null	perm=null	proto=rpc
2020-12-03 07:22:23,779 [Listener at localhost/37726] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741828_1004 with size=512 from 127.0.0.1:32936:DISK to 127.0.0.1:32936:ARCHIVE through 127.0.0.1:32936
2020-12-03 07:22:23,780 [pool-100-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741828_1004 with size=512 from 127.0.0.1:32936:DISK to 127.0.0.1:32936:ARCHIVE through 127.0.0.1:32936
2020-12-03 07:22:23,781 [pool-100-thread-1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:23,781 [IPC Server handler 6 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/hot/	dst=null	perm=null	proto=rpc
2020-12-03 07:22:23,782 [pool-100-thread-1] TRACE datatransfer.DataTransferProtocol (Sender.java:send(79)) - Sending DataTransferOp OpReplaceBlockProto: header {
  block {
    poolId: "BP-112083932-172.17.0.7-1606980105622"
    blockId: 1073741828
    generationStamp: 1004
    numBytes: 512
  }
  token {
    identifier: ""
    password: ""
    kind: ""
    service: ""
  }
}
delHint: "fc258908-e76f-48a7-8279-3420f46782bd"
source {
  id {
    ipAddr: "127.0.0.1"
    hostName: "127.0.0.1"
    datanodeUuid: "fc258908-e76f-48a7-8279-3420f46782bd"
    xferPort: 32936
    infoPort: 46144
    ipcPort: 43123
    infoSecurePort: 0
  }
  capacity: 1922244395008
  dfsUsed: 51800
  remaining: 1198477025280
  blockPoolUsed: 51800
  lastUpdate: 1606980143154
  xceiverCount: 1
  location: "/default-rack"
  nonDfsUsed: 626075612584
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 141132077
  lastBlockReportTime: 1606980133156
  lastBlockReportMonotonic: 141122079
  numBlocks: 0
}
storageType: ARCHIVE

2020-12-03 07:22:23,784 [Listener at localhost/37726] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741825_1001 with size=512 from 127.0.0.1:46191:ARCHIVE to 127.0.0.1:46191:DISK through 127.0.0.1:46191
2020-12-03 07:22:23,784 [pool-101-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741825_1001 with size=512 from 127.0.0.1:46191:ARCHIVE to 127.0.0.1:46191:DISK through 127.0.0.1:46191
2020-12-03 07:22:23,785 [pool-101-thread-1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:23,785 [IPC Server handler 7 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/system/	dst=null	perm=null	proto=rpc
2020-12-03 07:22:23,786 [pool-101-thread-1] TRACE datatransfer.DataTransferProtocol (Sender.java:send(79)) - Sending DataTransferOp OpReplaceBlockProto: header {
  block {
    poolId: "BP-112083932-172.17.0.7-1606980105622"
    blockId: 1073741825
    generationStamp: 1001
    numBytes: 512
  }
  token {
    identifier: ""
    password: ""
    kind: ""
    service: ""
  }
}
delHint: "7b793216-748f-4be6-a144-367935ffbafb"
source {
  id {
    ipAddr: "127.0.0.1"
    hostName: "127.0.0.1"
    datanodeUuid: "7b793216-748f-4be6-a144-367935ffbafb"
    xferPort: 46191
    infoPort: 38566
    ipcPort: 41609
    infoSecurePort: 0
  }
  capacity: 1922244395008
  dfsUsed: 51811
  remaining: 1198476918784
  blockPoolUsed: 51811
  lastUpdate: 1606980143255
  xceiverCount: 1
  location: "/default-rack"
  nonDfsUsed: 626075719069
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 141132178
  lastBlockReportTime: 1606980133255
  lastBlockReportMonotonic: 141122178
  numBlocks: 0
}
storageType: DISK

2020-12-03 07:22:23,786 [DataXceiver for client /127.0.0.1:56958 [Replacing block BP-112083932-172.17.0.7-1606980105622:blk_1073741828_1004 from fc258908-e76f-48a7-8279-3420f46782bd]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1186)) - Moved BP-112083932-172.17.0.7-1606980105622:blk_1073741828_1004 from StorageType DISK to ARCHIVE
2020-12-03 07:22:23,786 [pool-100-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741828_1004 with size=512 from 127.0.0.1:32936:DISK to 127.0.0.1:32936:ARCHIVE through 127.0.0.1:32936
2020-12-03 07:22:23,790 [IPC Server handler 0 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/warm/	dst=null	perm=null	proto=rpc
2020-12-03 07:22:23,791 [Block report processor] WARN  BlockStateChange (BlockManager.java:addStoredBlock(3356)) - BLOCK* addStoredBlock: block blk_1073741828_1004 moved to storageType ARCHIVE on node 127.0.0.1:32936
2020-12-03 07:22:23,792 [DataXceiver for client /127.0.0.1:58880 [Replacing block BP-112083932-172.17.0.7-1606980105622:blk_1073741825_1001 from 7b793216-748f-4be6-a144-367935ffbafb]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1186)) - Moved BP-112083932-172.17.0.7-1606980105622:blk_1073741825_1001 from StorageType ARCHIVE to DISK
2020-12-03 07:22:23,794 [pool-101-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741825_1001 with size=512 from 127.0.0.1:46191:ARCHIVE to 127.0.0.1:46191:DISK through 127.0.0.1:46191
2020-12-03 07:22:23,795 [Block report processor] WARN  BlockStateChange (BlockManager.java:addStoredBlock(3356)) - BLOCK* addStoredBlock: block blk_1073741825_1001 moved to storageType DISK on node 127.0.0.1:46191
2020-12-03 07:22:24,796 [IPC Server handler 4 on default port 44902] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /system/mover.id is closed by DFSClient_NONMAPREDUCE_-391545094_1
2020-12-03 07:22:24,798 [IPC Server handler 8 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/system/mover.id	dst=null	perm=null	proto=rpc
Mover Successful: all blocks satisfy the specified storage policy. Exiting...
2020-12-03 07:22:33,802 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:44902
2020-12-03 07:22:33,804 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x34913344e47fcf69: from storage DS-98c5da98-47d1-4ec8-8c42-db45703eedeb node DatanodeRegistration(127.0.0.1:40228, datanodeUuid=4531fc3a-8c15-42c0-ad49-f6505a50dcea, infoPort=35466, infoSecurePort=0, ipcPort=41630, storageInfo=lv=-57;cid=testClusterID;nsid=543616343;c=1606980105622), blocks: 3, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:33,804 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x34913344e47fcf69: from storage DS-45d26ee9-5330-4328-a6f5-9d5cae8072d4 node DatanodeRegistration(127.0.0.1:40228, datanodeUuid=4531fc3a-8c15-42c0-ad49-f6505a50dcea, infoPort=35466, infoSecurePort=0, ipcPort=41630, storageInfo=lv=-57;cid=testClusterID;nsid=543616343;c=1606980105622), blocks: 5, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:33,805 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x34913344e47fcf69,  containing 2 storage report(s), of which we sent 2. The reports had 8 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:33,805 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-112083932-172.17.0.7-1606980105622
2020-12-03 07:22:33,901 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:44902
2020-12-03 07:22:33,903 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xfc8314b2c08b8c8f: from storage DS-c5bce671-868b-4fa8-afa7-49e9ec5526a2 node DatanodeRegistration(127.0.0.1:32936, datanodeUuid=fc258908-e76f-48a7-8279-3420f46782bd, infoPort=46144, infoSecurePort=0, ipcPort=43123, storageInfo=lv=-57;cid=testClusterID;nsid=543616343;c=1606980105622), blocks: 1, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:22:33,903 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xfc8314b2c08b8c8f: from storage DS-d4b106f7-6476-43e5-bebc-4d76f054903f node DatanodeRegistration(127.0.0.1:32936, datanodeUuid=fc258908-e76f-48a7-8279-3420f46782bd, infoPort=46144, infoSecurePort=0, ipcPort=43123, storageInfo=lv=-57;cid=testClusterID;nsid=543616343;c=1606980105622), blocks: 4, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:33,904 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xfc8314b2c08b8c8f,  containing 2 storage report(s), of which we sent 2. The reports had 5 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:33,904 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-112083932-172.17.0.7-1606980105622
2020-12-03 07:22:34,001 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:44902
2020-12-03 07:22:34,003 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xc4cf9a8c92a7c44d: from storage DS-ae119148-187a-42b8-a576-43913a2cea7b node DatanodeRegistration(127.0.0.1:46191, datanodeUuid=7b793216-748f-4be6-a144-367935ffbafb, infoPort=38566, infoSecurePort=0, ipcPort=41609, storageInfo=lv=-57;cid=testClusterID;nsid=543616343;c=1606980105622), blocks: 3, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:34,003 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xc4cf9a8c92a7c44d: from storage DS-dfbdbbaa-c98a-4ba8-8504-1c726531280a node DatanodeRegistration(127.0.0.1:46191, datanodeUuid=7b793216-748f-4be6-a144-367935ffbafb, infoPort=38566, infoSecurePort=0, ipcPort=41609, storageInfo=lv=-57;cid=testClusterID;nsid=543616343;c=1606980105622), blocks: 2, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:34,004 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xc4cf9a8c92a7c44d,  containing 2 storage report(s), of which we sent 2. The reports had 5 total blocks and used 1 RPC(s). This took 1 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:34,004 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-112083932-172.17.0.7-1606980105622
2020-12-03 07:22:34,101 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:44902
2020-12-03 07:22:34,103 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xf8fb16a3530b4cf6: from storage DS-8e084a11-8a03-4947-83b2-a2598a529f6c node DatanodeRegistration(127.0.0.1:33330, datanodeUuid=0237cc88-214f-4ecc-9fca-2ef3974ab7eb, infoPort=37559, infoSecurePort=0, ipcPort=33221, storageInfo=lv=-57;cid=testClusterID;nsid=543616343;c=1606980105622), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:34,104 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xf8fb16a3530b4cf6: from storage DS-d75ea7b4-2fee-44a5-844d-faa34ba6681d node DatanodeRegistration(127.0.0.1:33330, datanodeUuid=0237cc88-214f-4ecc-9fca-2ef3974ab7eb, infoPort=37559, infoSecurePort=0, ipcPort=33221, storageInfo=lv=-57;cid=testClusterID;nsid=543616343;c=1606980105622), blocks: 2, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:34,104 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xf8fb16a3530b4cf6,  containing 2 storage report(s), of which we sent 2. The reports had 3 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:34,104 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-112083932-172.17.0.7-1606980105622
2020-12-03 07:22:34,201 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:44902
2020-12-03 07:22:34,203 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x219f0ed3ff786fa7: from storage DS-0e0d2a62-0a95-4405-ac61-c36d0ad42c39 node DatanodeRegistration(127.0.0.1:41276, datanodeUuid=002461fc-4aa8-4d26-86c3-971092b194a6, infoPort=35624, infoSecurePort=0, ipcPort=36273, storageInfo=lv=-57;cid=testClusterID;nsid=543616343;c=1606980105622), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:34,203 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x219f0ed3ff786fa7: from storage DS-d45ac532-8cf5-4065-bea9-b33e7114dc7d node DatanodeRegistration(127.0.0.1:41276, datanodeUuid=002461fc-4aa8-4d26-86c3-971092b194a6, infoPort=35624, infoSecurePort=0, ipcPort=36273, storageInfo=lv=-57;cid=testClusterID;nsid=543616343;c=1606980105622), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:34,204 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x219f0ed3ff786fa7,  containing 2 storage report(s), of which we sent 2. The reports had 1 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:34,204 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-112083932-172.17.0.7-1606980105622
2020-12-03 07:22:34,304 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:44902
2020-12-03 07:22:34,306 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x2af71878c25e8978: from storage DS-7ba7554c-5ca9-4cc9-a977-6f21fc38dd76 node DatanodeRegistration(127.0.0.1:32811, datanodeUuid=d756da44-2378-4af0-be27-9028065cb33e, infoPort=38406, infoSecurePort=0, ipcPort=37726, storageInfo=lv=-57;cid=testClusterID;nsid=543616343;c=1606980105622), blocks: 2, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:34,307 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x2af71878c25e8978: from storage DS-1bb59e4f-55f8-43b4-92c0-6f9216074971 node DatanodeRegistration(127.0.0.1:32811, datanodeUuid=d756da44-2378-4af0-be27-9028065cb33e, infoPort=38406, infoSecurePort=0, ipcPort=37726, storageInfo=lv=-57;cid=testClusterID;nsid=543616343;c=1606980105622), blocks: 3, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:34,307 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x2af71878c25e8978,  containing 2 storage report(s), of which we sent 2. The reports had 5 total blocks and used 1 RPC(s). This took 1 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:34,308 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-112083932-172.17.0.7-1606980105622
2020-12-03 07:22:34,401 [IPC Server handler 3 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/	dst=null	perm=null	proto=rpc
2020-12-03 07:22:34,403 [IPC Server handler 1 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/	dst=null	perm=null	proto=rpc
2020-12-03 07:22:34,406 [IPC Server handler 6 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/cold	dst=null	perm=null	proto=rpc
2020-12-03 07:22:34,410 [IPC Server handler 7 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/hot	dst=null	perm=null	proto=rpc
2020-12-03 07:22:34,414 [IPC Server handler 5 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/system	dst=null	perm=null	proto=rpc
2020-12-03 07:22:34,415 [IPC Server handler 0 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/warm	dst=null	perm=null	proto=rpc
2020-12-03 07:22:34,420 [IPC Server handler 8 on default port 44902] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/system/mover.id	dst=null	perm=null	proto=rpc
2020-12-03 07:22:34,420 [Listener at localhost/37726] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:22:34,421 [Listener at localhost/37726] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 5
2020-12-03 07:22:34,423 [Listener at localhost/37726] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:22:34,423 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@12f3afb5] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:22:34,424 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-1bb59e4f-55f8-43b4-92c0-6f9216074971) exiting.
2020-12-03 07:22:34,424 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-7ba7554c-5ca9-4cc9-a977-6f21fc38dd76) exiting.
2020-12-03 07:22:34,731 [Listener at localhost/37726] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@a23a01d{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:22:34,753 [Listener at localhost/37726] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4acf72b6{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:34,754 [Listener at localhost/37726] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3aaf4f07{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:34,754 [Listener at localhost/37726] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@27dc79f7{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:34,761 [Listener at localhost/37726] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 37726
2020-12-03 07:22:34,772 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:34,772 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:34,773 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:34,773 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-112083932-172.17.0.7-1606980105622 (Datanode Uuid d756da44-2378-4af0-be27-9028065cb33e) service to localhost/127.0.0.1:44902
2020-12-03 07:22:34,773 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-112083932-172.17.0.7-1606980105622 (Datanode Uuid d756da44-2378-4af0-be27-9028065cb33e)
2020-12-03 07:22:34,773 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-112083932-172.17.0.7-1606980105622
2020-12-03 07:22:34,775 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-112083932-172.17.0.7-1606980105622] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:34,781 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-112083932-172.17.0.7-1606980105622] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:34,788 [Listener at localhost/37726] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:22:34,789 [Listener at localhost/37726] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:22:34,791 [Listener at localhost/37726] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:22:34,791 [Listener at localhost/37726] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:22:34,803 [Listener at localhost/37726] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:22:34,803 [Listener at localhost/37726] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 4
2020-12-03 07:22:34,803 [Listener at localhost/37726] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:22:34,817 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@5949eba8] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:22:34,825 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-d45ac532-8cf5-4065-bea9-b33e7114dc7d) exiting.
2020-12-03 07:22:34,825 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-0e0d2a62-0a95-4405-ac61-c36d0ad42c39) exiting.
2020-12-03 07:22:34,931 [Listener at localhost/37726] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1bc53649{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:22:34,932 [Listener at localhost/37726] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@88d6f9b{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:34,932 [Listener at localhost/37726] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5167268{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:34,938 [Listener at localhost/37726] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7728643a{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:34,940 [Listener at localhost/37726] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 36273
2020-12-03 07:22:34,962 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:34,965 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:34,965 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:34,967 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-112083932-172.17.0.7-1606980105622 (Datanode Uuid 002461fc-4aa8-4d26-86c3-971092b194a6) service to localhost/127.0.0.1:44902
2020-12-03 07:22:34,967 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-112083932-172.17.0.7-1606980105622 (Datanode Uuid 002461fc-4aa8-4d26-86c3-971092b194a6)
2020-12-03 07:22:34,968 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-112083932-172.17.0.7-1606980105622
2020-12-03 07:22:34,968 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-112083932-172.17.0.7-1606980105622] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:34,971 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-112083932-172.17.0.7-1606980105622] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:34,981 [Listener at localhost/37726] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:22:34,981 [Listener at localhost/37726] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:22:34,982 [Listener at localhost/37726] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:22:34,982 [Listener at localhost/37726] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:22:34,987 [Listener at localhost/37726] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:22:34,988 [Listener at localhost/37726] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 3
2020-12-03 07:22:34,988 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@29539e36] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:22:34,988 [Listener at localhost/37726] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:22:34,991 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-8e084a11-8a03-4947-83b2-a2598a529f6c) exiting.
2020-12-03 07:22:34,991 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-d75ea7b4-2fee-44a5-844d-faa34ba6681d) exiting.
2020-12-03 07:22:35,072 [Listener at localhost/37726] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@37d3d232{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:22:35,073 [Listener at localhost/37726] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@30c0ccff{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:35,073 [Listener at localhost/37726] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@66d23e4a{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:35,074 [Listener at localhost/37726] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@49a64d82{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:35,078 [Listener at localhost/37726] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 33221
2020-12-03 07:22:35,080 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:35,083 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:35,084 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:35,084 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-112083932-172.17.0.7-1606980105622 (Datanode Uuid 0237cc88-214f-4ecc-9fca-2ef3974ab7eb) service to localhost/127.0.0.1:44902
2020-12-03 07:22:35,084 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-112083932-172.17.0.7-1606980105622 (Datanode Uuid 0237cc88-214f-4ecc-9fca-2ef3974ab7eb)
2020-12-03 07:22:35,084 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-112083932-172.17.0.7-1606980105622
2020-12-03 07:22:35,085 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-112083932-172.17.0.7-1606980105622] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:35,086 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-112083932-172.17.0.7-1606980105622] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:35,103 [Listener at localhost/37726] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:22:35,104 [Listener at localhost/37726] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:22:35,111 [Listener at localhost/37726] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:22:35,121 [Listener at localhost/37726] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:22:35,130 [Listener at localhost/37726] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:22:35,131 [Listener at localhost/37726] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 2
2020-12-03 07:22:35,131 [Listener at localhost/37726] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:22:35,131 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@1c25b8a7] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:22:35,134 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-ae119148-187a-42b8-a576-43913a2cea7b) exiting.
2020-12-03 07:22:35,135 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-dfbdbbaa-c98a-4ba8-8504-1c726531280a) exiting.
2020-12-03 07:22:35,188 [Listener at localhost/37726] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@3d4d3fe7{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:22:35,191 [Listener at localhost/37726] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@65f87a2c{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:35,192 [Listener at localhost/37726] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@70e0accd{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:35,192 [Listener at localhost/37726] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1e11bc55{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:35,195 [Listener at localhost/37726] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 41609
2020-12-03 07:22:35,201 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:35,201 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:35,201 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:35,201 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-112083932-172.17.0.7-1606980105622 (Datanode Uuid 7b793216-748f-4be6-a144-367935ffbafb) service to localhost/127.0.0.1:44902
2020-12-03 07:22:35,202 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-112083932-172.17.0.7-1606980105622 (Datanode Uuid 7b793216-748f-4be6-a144-367935ffbafb)
2020-12-03 07:22:35,202 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-112083932-172.17.0.7-1606980105622
2020-12-03 07:22:35,207 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-112083932-172.17.0.7-1606980105622] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:35,208 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-112083932-172.17.0.7-1606980105622] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:35,217 [Listener at localhost/37726] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:22:35,217 [Listener at localhost/37726] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:22:35,220 [Listener at localhost/37726] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:22:35,220 [Listener at localhost/37726] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:22:35,227 [Listener at localhost/37726] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:22:35,227 [Listener at localhost/37726] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 1
2020-12-03 07:22:35,228 [Listener at localhost/37726] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:22:35,231 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-c5bce671-868b-4fa8-afa7-49e9ec5526a2) exiting.
2020-12-03 07:22:35,232 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-d4b106f7-6476-43e5-bebc-4d76f054903f) exiting.
2020-12-03 07:22:35,237 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@41200e0c] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:22:35,258 [Listener at localhost/37726] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@29ad44e3{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:22:35,259 [Listener at localhost/37726] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@15bcf458{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:35,259 [Listener at localhost/37726] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@aec50a1{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:35,260 [Listener at localhost/37726] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@24be2d9c{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:35,269 [Listener at localhost/37726] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 43123
2020-12-03 07:22:35,276 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:35,277 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:35,277 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-112083932-172.17.0.7-1606980105622 (Datanode Uuid fc258908-e76f-48a7-8279-3420f46782bd) service to localhost/127.0.0.1:44902
2020-12-03 07:22:35,277 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-112083932-172.17.0.7-1606980105622 (Datanode Uuid fc258908-e76f-48a7-8279-3420f46782bd)
2020-12-03 07:22:35,277 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-112083932-172.17.0.7-1606980105622
2020-12-03 07:22:35,286 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:35,288 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-112083932-172.17.0.7-1606980105622] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:35,288 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-112083932-172.17.0.7-1606980105622] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:35,313 [Listener at localhost/37726] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:22:35,314 [Listener at localhost/37726] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:22:35,317 [Listener at localhost/37726] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:22:35,318 [Listener at localhost/37726] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:22:35,325 [Listener at localhost/37726] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:22:35,325 [Listener at localhost/37726] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:22:35,326 [Listener at localhost/37726] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:22:35,326 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@4c6daf0] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:22:35,330 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-45d26ee9-5330-4328-a6f5-9d5cae8072d4) exiting.
2020-12-03 07:22:35,332 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-98c5da98-47d1-4ec8-8c42-db45703eedeb) exiting.
2020-12-03 07:22:35,384 [Listener at localhost/37726] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@61526469{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:22:35,386 [Listener at localhost/37726] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@274872f8{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:35,387 [Listener at localhost/37726] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@62e70ea3{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:35,387 [Listener at localhost/37726] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7a7471ce{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:35,389 [Listener at localhost/37726] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 41630
2020-12-03 07:22:35,401 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:35,401 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:35,402 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:35,402 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-112083932-172.17.0.7-1606980105622 (Datanode Uuid 4531fc3a-8c15-42c0-ad49-f6505a50dcea) service to localhost/127.0.0.1:44902
2020-12-03 07:22:35,402 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-112083932-172.17.0.7-1606980105622 (Datanode Uuid 4531fc3a-8c15-42c0-ad49-f6505a50dcea)
2020-12-03 07:22:35,402 [BP-112083932-172.17.0.7-1606980105622 heartbeating to localhost/127.0.0.1:44902] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-112083932-172.17.0.7-1606980105622
2020-12-03 07:22:35,403 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-112083932-172.17.0.7-1606980105622] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:35,415 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-112083932-172.17.0.7-1606980105622] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:35,434 [Listener at localhost/37726] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:22:35,435 [Listener at localhost/37726] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:22:35,440 [Listener at localhost/37726] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:22:35,440 [Listener at localhost/37726] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:22:35,451 [Listener at localhost/37726] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:22:35,451 [Listener at localhost/37726] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:22:35,452 [Listener at localhost/37726] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:22:35,458 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@1b065145] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:22:35,462 [Listener at localhost/37726] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 1, 65
2020-12-03 07:22:35,462 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@45cff11c] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:22:35,463 [Listener at localhost/37726] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 66 Total time for transactions(ms): 38 Number of transactions batched in Syncs: 10 Number of syncs: 57 SyncTimes(ms): 5 3 
2020-12-03 07:22:35,465 [Listener at localhost/37726] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000066
2020-12-03 07:22:35,466 [Listener at localhost/37726] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000066
2020-12-03 07:22:35,467 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:22:35,467 [CacheReplicationMonitor(954627498)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:22:35,468 [Listener at localhost/37726] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 44902
2020-12-03 07:22:35,475 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:35,475 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:35,481 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:22:35,481 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:22:35,547 [Listener at localhost/37726] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:22:35,548 [Listener at localhost/37726] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:22:35,551 [Listener at localhost/37726] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@7a3793c7{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:22:35,555 [Listener at localhost/37726] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7189bcba{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:35,556 [Listener at localhost/37726] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@71687585{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:35,556 [Listener at localhost/37726] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5c7bfdc1{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:35,566 [Listener at localhost/37726] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-12-03 07:22:35,598 [Listener at localhost/37726] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-12-03 07:22:35,599 [Listener at localhost/37726] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
msx-rc 0
