2020-12-03 07:22:34,233 [main] INFO  blockmanagement.TestReconstructStripedBlocksWithRackAwareness (TestReconstructStripedBlocksWithRackAwareness.java:testReconstructForNotEnoughRacks(146)) - cluster hosts: [host1, host2, host3, host4, host5, host6, host7, host8, host9, host10], racks: [/r1, /r1, /r2, /r2, /r3, /r3, /r4, /r4, /r5, /r6]
2020-12-03 07:22:34,297 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=10
Formatting using clusterid: testClusterID
2020-12-03 07:22:35,034 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:22:35,049 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:22:35,051 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:22:35,052 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:22:35,062 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:22:35,062 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:22:35,063 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:22:35,064 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:22:35,107 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:35,112 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2020-12-03 07:22:35,113 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:22:35,113 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:22:35,118 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:22:35,118 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:22:35
2020-12-03 07:22:35,122 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:22:35,122 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:35,124 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-12-03 07:22:35,124 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:22:35,145 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:22:35,145 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:22:35,148 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.redundancy.interval.seconds(1) assuming SECONDS
2020-12-03 07:22:35,154 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:22:35,154 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:22:35,154 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:22:35,155 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:22:35,156 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:22:35,156 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:22:35,156 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:22:35,157 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:22:35,157 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 1000ms
2020-12-03 07:22:35,157 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:22:35,157 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:22:35,197 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GLOBAL serial map: bits=29 maxEntries=536870911
2020-12-03 07:22:35,198 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - USER serial map: bits=24 maxEntries=16777215
2020-12-03 07:22:35,198 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GROUP serial map: bits=24 maxEntries=16777215
2020-12-03 07:22:35,198 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - XATTR serial map: bits=24 maxEntries=16777215
2020-12-03 07:22:35,223 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:22:35,224 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:35,225 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-12-03 07:22:35,225 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:22:35,232 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:22:35,232 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:22:35,232 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:22:35,233 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:22:35,239 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:22:35,242 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:22:35,249 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:22:35,249 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:35,250 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-12-03 07:22:35,250 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:22:35,259 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:22:35,260 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:22:35,260 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:22:35,266 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:22:35,267 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:22:35,270 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:22:35,271 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:35,271 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-12-03 07:22:35,272 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:22:35,324 [main] INFO  namenode.FSImage (FSImage.java:format(185)) - Allocated new BlockPoolId: BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:35,466 [main] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-12-03 07:22:35,623 [main] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-12-03 07:22:35,658 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:22:35,658 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:22:35,799 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:22:35,799 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:22:35,871 [main] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-12-03 07:22:35,875 [main] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:22:35,991 [main] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:22:36,354 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:22:36,354 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:22:36,396 [main] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-12-03 07:22:36,441 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2ed2d9cb] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:36,460 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:22:36,466 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:36,483 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @3352ms
2020-12-03 07:22:36,608 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:36,612 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:22:36,612 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:36,622 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:36,626 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:22:36,626 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:36,626 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:36,668 [main] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:22:36,668 [main] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:22:36,682 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 38047
2020-12-03 07:22:36,684 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:36,735 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@28cda624{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:36,736 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7eecb5b8{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:36,781 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3e44f2a5{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:22:36,791 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@589da3f3{HTTP/1.1,[http/1.1]}{localhost:38047}
2020-12-03 07:22:36,791 [main] INFO  server.Server (Server.java:doStart(419)) - Started @3660ms
2020-12-03 07:22:36,802 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:22:36,802 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:22:36,802 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:22:36,803 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:22:36,803 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:22:36,803 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:22:36,803 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:22:36,804 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:22:36,805 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:36,805 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:22:36,805 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:22:36,806 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:22:36,806 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:22:36
2020-12-03 07:22:36,807 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:22:36,807 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:36,807 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:22:36,807 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:22:36,813 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:22:36,813 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:22:36,813 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.redundancy.interval.seconds(1) assuming SECONDS
2020-12-03 07:22:36,814 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:22:36,814 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:22:36,814 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:22:36,815 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:22:36,815 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:22:36,815 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:22:36,815 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:22:36,815 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:22:36,816 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 1000ms
2020-12-03 07:22:36,816 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:22:36,816 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:22:36,817 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:22:36,817 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:36,818 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:22:36,818 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:22:36,820 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:22:36,821 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:22:36,821 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:22:36,821 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:22:36,821 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:22:36,822 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:22:36,822 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:22:36,822 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:36,822 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:22:36,822 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:22:36,823 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:22:36,824 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:22:36,824 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:22:36,824 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:22:36,824 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:22:36,824 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:22:36,824 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:36,825 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:22:36,825 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:22:36,915 [main] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 5051@533329efb28f
2020-12-03 07:22:37,029 [main] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 5051@533329efb28f
2020-12-03 07:22:37,033 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-12-03 07:22:37,033 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-12-03 07:22:37,034 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:22:37,034 [main] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:22:37,064 [main] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:22:37,071 [main] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:22:37,071 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-12-03 07:22:37,076 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:22:37,076 [main] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 1
2020-12-03 07:22:37,293 [main] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:22:37,293 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 466 msecs
2020-12-03 07:22:37,492 [main] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:22:37,537 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:37,551 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:37,807 [Listener at localhost/36012] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:36012 to access this namenode/service.
2020-12-03 07:22:37,811 [Listener at localhost/36012] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:22:37,826 [Listener at localhost/36012] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:22:37,828 [org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor@47db5fa5] DEBUG blockmanagement.BlockManager (PendingReconstructionBlocks.java:pendingReconstructionCheck(261)) - PendingReconstructionMonitor checking Q
2020-12-03 07:22:37,838 [Listener at localhost/36012] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:22:37,838 [Listener at localhost/36012] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:22:37,839 [Listener at localhost/36012] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:22:37,839 [Listener at localhost/36012] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:22:37,844 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 0
2020-12-03 07:22:37,844 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:22:37,844 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:22:37,845 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:22:37,845 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:22:37,845 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 6 msec
2020-12-03 07:22:37,881 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:37,881 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:37,885 [Listener at localhost/36012] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:36012
2020-12-03 07:22:37,890 [Listener at localhost/36012] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:22:37,890 [Listener at localhost/36012] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:22:37,898 [Listener at localhost/36012] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 8 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:22:37,903 [CacheReplicationMonitor(597548231)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:22:37,907 [Listener at localhost/36012] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:22:37,908 [Listener at localhost/36012] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1664)) - Starting DataNode 0 with hostname set to: host1
2020-12-03 07:22:37,908 [Listener at localhost/36012] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1669)) - Adding node with hostname : host1 to rack /r1
2020-12-03 07:22:37,986 [Listener at localhost/36012] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:22:38,003 [Listener at localhost/36012] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:22:38,023 [Listener at localhost/36012] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:22:38,028 [Listener at localhost/36012] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:38,031 [Listener at localhost/36012] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:22:38,035 [Listener at localhost/36012] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is host1
2020-12-03 07:22:38,037 [Listener at localhost/36012] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:38,041 [Listener at localhost/36012] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:22:38,048 [Listener at localhost/36012] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:46157
2020-12-03 07:22:38,051 [Listener at localhost/36012] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:22:38,051 [Listener at localhost/36012] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:22:38,070 [Listener at localhost/36012] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:38,073 [Listener at localhost/36012] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:38,074 [Listener at localhost/36012] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:22:38,074 [Listener at localhost/36012] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:38,078 [Listener at localhost/36012] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:38,079 [Listener at localhost/36012] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:22:38,079 [Listener at localhost/36012] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:38,079 [Listener at localhost/36012] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:38,083 [Listener at localhost/36012] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 40323
2020-12-03 07:22:38,084 [Listener at localhost/36012] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:38,085 [Listener at localhost/36012] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@482d776b{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:38,087 [Listener at localhost/36012] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@132ddbab{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:38,094 [Listener at localhost/36012] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@32f0fba8{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:22:38,098 [Listener at localhost/36012] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@545de5a4{HTTP/1.1,[http/1.1]}{localhost:40323}
2020-12-03 07:22:38,098 [Listener at localhost/36012] INFO  server.Server (Server.java:doStart(419)) - Started @4967ms
2020-12-03 07:22:38,426 [Listener at localhost/36012] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:42565
2020-12-03 07:22:38,427 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5ef8df1e] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:38,428 [Listener at localhost/36012] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:22:38,429 [Listener at localhost/36012] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:22:38,660 [Listener at localhost/36012] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:38,661 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:38,673 [Listener at localhost/34197] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:34197
2020-12-03 07:22:38,698 [Listener at localhost/34197] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:22:38,701 [Listener at localhost/34197] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:22:38,717 [Thread-59] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36012 starting to offer service
2020-12-03 07:22:38,723 [Listener at localhost/34197] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1724)) - Adding node with service : 127.0.0.1:46157 to rack /r1
2020-12-03 07:22:38,724 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:38,724 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:38,729 [Listener at localhost/34197] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:22:38,729 [Listener at localhost/34197] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1664)) - Starting DataNode 1 with hostname set to: host2
2020-12-03 07:22:38,729 [Listener at localhost/34197] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1669)) - Adding node with hostname : host2 to rack /r1
2020-12-03 07:22:38,731 [Listener at localhost/34197] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:22:38,731 [Listener at localhost/34197] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:22:38,734 [Listener at localhost/34197] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:22:38,734 [Listener at localhost/34197] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:38,734 [Listener at localhost/34197] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:22:38,735 [Listener at localhost/34197] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is host2
2020-12-03 07:22:38,735 [Listener at localhost/34197] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:38,736 [Listener at localhost/34197] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:22:38,737 [Listener at localhost/34197] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:39491
2020-12-03 07:22:38,737 [Listener at localhost/34197] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:22:38,737 [Listener at localhost/34197] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:22:38,738 [Listener at localhost/34197] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:38,740 [Listener at localhost/34197] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:38,741 [Listener at localhost/34197] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:22:38,741 [Listener at localhost/34197] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:38,743 [Listener at localhost/34197] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:38,744 [Listener at localhost/34197] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:22:38,744 [Listener at localhost/34197] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:38,744 [Listener at localhost/34197] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:38,745 [Listener at localhost/34197] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 39166
2020-12-03 07:22:38,745 [Listener at localhost/34197] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:38,749 [Listener at localhost/34197] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@72efb5c1{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:38,750 [Listener at localhost/34197] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@41200e0c{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:38,756 [Listener at localhost/34197] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@42a9a63e{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:22:38,758 [Listener at localhost/34197] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@62da83ed{HTTP/1.1,[http/1.1]}{localhost:39166}
2020-12-03 07:22:38,758 [Listener at localhost/34197] INFO  server.Server (Server.java:doStart(419)) - Started @5627ms
2020-12-03 07:22:38,834 [Listener at localhost/34197] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:34327
2020-12-03 07:22:38,835 [Listener at localhost/34197] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:22:38,835 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@37d80fe7] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:38,835 [Listener at localhost/34197] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:22:38,835 [Listener at localhost/34197] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:38,836 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:38,836 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1998)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-12-03 07:22:38,841 [Listener at localhost/46347] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:46347
2020-12-03 07:22:38,846 [Listener at localhost/46347] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:22:38,846 [Listener at localhost/46347] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:22:38,847 [Thread-83] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36012 starting to offer service
2020-12-03 07:22:38,849 [Listener at localhost/46347] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1724)) - Adding node with service : 127.0.0.1:39491 to rack /r1
2020-12-03 07:22:38,850 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:38,850 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:38,855 [Listener at localhost/46347] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:22:38,855 [Listener at localhost/46347] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1664)) - Starting DataNode 2 with hostname set to: host3
2020-12-03 07:22:38,855 [Listener at localhost/46347] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1669)) - Adding node with hostname : host3 to rack /r2
2020-12-03 07:22:38,857 [Listener at localhost/46347] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:22:38,858 [Listener at localhost/46347] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:22:38,860 [Listener at localhost/46347] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:22:38,860 [Listener at localhost/46347] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:38,861 [Listener at localhost/46347] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:22:38,861 [Listener at localhost/46347] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is host3
2020-12-03 07:22:38,861 [Listener at localhost/46347] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:38,862 [Listener at localhost/46347] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:22:38,862 [Listener at localhost/46347] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:42147
2020-12-03 07:22:38,863 [Listener at localhost/46347] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:22:38,863 [Listener at localhost/46347] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:22:38,865 [Listener at localhost/46347] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:38,867 [Listener at localhost/46347] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:38,868 [Listener at localhost/46347] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:22:38,868 [Listener at localhost/46347] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:38,871 [Listener at localhost/46347] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:38,872 [Listener at localhost/46347] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:22:38,872 [Listener at localhost/46347] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:38,873 [Listener at localhost/46347] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:38,874 [Listener at localhost/46347] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 34827
2020-12-03 07:22:38,874 [Listener at localhost/46347] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:38,876 [Listener at localhost/46347] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7249dadf{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:38,877 [Listener at localhost/46347] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@66238be2{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:38,887 [Listener at localhost/46347] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1734f68{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:22:38,888 [Listener at localhost/46347] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@77b7ffa4{HTTP/1.1,[http/1.1]}{localhost:34827}
2020-12-03 07:22:38,889 [Listener at localhost/46347] INFO  server.Server (Server.java:doStart(419)) - Started @5758ms
2020-12-03 07:22:38,925 [Listener at localhost/46347] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:38259
2020-12-03 07:22:38,926 [Listener at localhost/46347] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:22:38,926 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@402f80f5] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:38,926 [Listener at localhost/46347] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:22:38,927 [Listener at localhost/46347] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:38,928 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:38,933 [Listener at localhost/36393] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:36393
2020-12-03 07:22:38,940 [Listener at localhost/36393] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:22:38,941 [Listener at localhost/36393] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:22:38,955 [Thread-106] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36012 starting to offer service
2020-12-03 07:22:38,964 [Listener at localhost/36393] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1724)) - Adding node with service : 127.0.0.1:42147 to rack /r2
2020-12-03 07:22:38,972 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:38,972 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:38,986 [Listener at localhost/36393] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 3 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:22:38,986 [Listener at localhost/36393] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1664)) - Starting DataNode 3 with hostname set to: host4
2020-12-03 07:22:38,986 [Listener at localhost/36393] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1669)) - Adding node with hostname : host4 to rack /r2
2020-12-03 07:22:38,988 [Listener at localhost/36393] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:22:38,988 [Listener at localhost/36393] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:22:38,990 [Listener at localhost/36393] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:22:38,991 [Listener at localhost/36393] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:38,991 [Listener at localhost/36393] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:22:38,991 [Listener at localhost/36393] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is host4
2020-12-03 07:22:38,992 [Listener at localhost/36393] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:38,992 [Listener at localhost/36393] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:22:38,993 [Listener at localhost/36393] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:38964
2020-12-03 07:22:38,993 [Listener at localhost/36393] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:22:38,993 [Listener at localhost/36393] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:22:38,995 [Listener at localhost/36393] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:38,996 [Listener at localhost/36393] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:38,997 [Listener at localhost/36393] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:22:38,998 [Listener at localhost/36393] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:39,001 [Listener at localhost/36393] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:39,002 [Listener at localhost/36393] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:22:39,002 [Listener at localhost/36393] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:39,002 [Listener at localhost/36393] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:39,003 [Listener at localhost/36393] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 42447
2020-12-03 07:22:39,003 [Listener at localhost/36393] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:39,006 [Listener at localhost/36393] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@cc62a3b{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:39,007 [Listener at localhost/36393] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@29539e36{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:39,013 [Listener at localhost/36393] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@72bca894{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:22:39,015 [Listener at localhost/36393] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@433ffad1{HTTP/1.1,[http/1.1]}{localhost:42447}
2020-12-03 07:22:39,015 [Listener at localhost/36393] INFO  server.Server (Server.java:doStart(419)) - Started @5884ms
2020-12-03 07:22:39,065 [Listener at localhost/36393] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:46799
2020-12-03 07:22:39,066 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2575f671] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:39,066 [Listener at localhost/36393] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:22:39,066 [Listener at localhost/36393] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:22:39,067 [Listener at localhost/36393] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:39,068 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:39,072 [Listener at localhost/40410] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:40410
2020-12-03 07:22:39,076 [Listener at localhost/40410] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:22:39,077 [Listener at localhost/40410] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:22:39,078 [Thread-128] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36012 starting to offer service
2020-12-03 07:22:39,079 [Listener at localhost/40410] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1724)) - Adding node with service : 127.0.0.1:38964 to rack /r2
2020-12-03 07:22:39,080 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:39,080 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:39,083 [Listener at localhost/40410] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 4 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:22:39,084 [Listener at localhost/40410] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1664)) - Starting DataNode 4 with hostname set to: host5
2020-12-03 07:22:39,084 [Listener at localhost/40410] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1669)) - Adding node with hostname : host5 to rack /r3
2020-12-03 07:22:39,086 [Listener at localhost/40410] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:22:39,086 [Listener at localhost/40410] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:22:39,087 [Listener at localhost/40410] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:22:39,088 [Listener at localhost/40410] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:39,089 [Listener at localhost/40410] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:22:39,089 [Listener at localhost/40410] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is host5
2020-12-03 07:22:39,090 [Listener at localhost/40410] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:39,090 [Listener at localhost/40410] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:22:39,092 [Listener at localhost/40410] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:41586
2020-12-03 07:22:39,092 [Listener at localhost/40410] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:22:39,092 [Listener at localhost/40410] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:22:39,093 [Listener at localhost/40410] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:39,095 [Listener at localhost/40410] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:39,096 [Listener at localhost/40410] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:22:39,096 [Listener at localhost/40410] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:39,098 [Listener at localhost/40410] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:39,099 [Listener at localhost/40410] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:22:39,099 [Listener at localhost/40410] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:39,099 [Listener at localhost/40410] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:39,100 [Listener at localhost/40410] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 43860
2020-12-03 07:22:39,101 [Listener at localhost/40410] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:39,176 [Listener at localhost/40410] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@c074c0c{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:39,177 [Listener at localhost/40410] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5949eba8{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:39,178 [Thread-128] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36012
2020-12-03 07:22:39,178 [Thread-83] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36012
2020-12-03 07:22:39,178 [Thread-59] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36012
2020-12-03 07:22:39,178 [Thread-106] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36012
2020-12-03 07:22:39,181 [Thread-59] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:39,181 [Thread-106] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:39,181 [Thread-128] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:39,181 [Thread-83] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:39,187 [Listener at localhost/40410] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@51c929ae{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:22:39,188 [Listener at localhost/40410] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3c8bdd5b{HTTP/1.1,[http/1.1]}{localhost:43860}
2020-12-03 07:22:39,188 [Listener at localhost/40410] INFO  server.Server (Server.java:doStart(419)) - Started @6057ms
2020-12-03 07:22:39,203 [Listener at localhost/40410] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:34293
2020-12-03 07:22:39,204 [Listener at localhost/40410] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:22:39,204 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@40e4ea87] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:39,204 [Listener at localhost/40410] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:22:39,205 [Listener at localhost/40410] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:39,206 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:39,210 [Listener at localhost/40964] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:40964
2020-12-03 07:22:39,215 [Listener at localhost/40964] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:22:39,216 [Listener at localhost/40964] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:22:39,217 [Thread-150] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36012 starting to offer service
2020-12-03 07:22:39,218 [Thread-83] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 5051@533329efb28f
2020-12-03 07:22:39,218 [Listener at localhost/40964] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1724)) - Adding node with service : 127.0.0.1:41586 to rack /r3
2020-12-03 07:22:39,218 [Thread-106] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 5051@533329efb28f
2020-12-03 07:22:39,218 [Thread-59] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 5051@533329efb28f
2020-12-03 07:22:39,218 [Thread-128] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/in_use.lock acquired by nodename 5051@533329efb28f
2020-12-03 07:22:39,219 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:39,224 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:39,224 [Thread-59] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 872050423. Formatting...
2020-12-03 07:22:39,224 [Thread-106] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 is not formatted for namespace 872050423. Formatting...
2020-12-03 07:22:39,224 [Thread-128] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 is not formatted for namespace 872050423. Formatting...
2020-12-03 07:22:39,224 [Thread-83] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 is not formatted for namespace 872050423. Formatting...
2020-12-03 07:22:39,227 [Thread-59] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-4738ef7e-bb4a-4c3f-bc80-47b226c6d2de for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-12-03 07:22:39,227 [Thread-83] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-ddcf86b6-f4e7-4e7e-b776-8c3ecf9168cb for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 
2020-12-03 07:22:39,227 [Thread-128] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-92e8fd76-ed61-46b0-972b-2eb1bdaeedb2 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 
2020-12-03 07:22:39,227 [Thread-106] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-05ad14d3-6743-431b-89ed-3742b183502a for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 
2020-12-03 07:22:39,227 [Thread-150] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36012
2020-12-03 07:22:39,228 [Thread-150] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:39,228 [Listener at localhost/40964] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 5 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:22:39,228 [Listener at localhost/40964] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1664)) - Starting DataNode 5 with hostname set to: host6
2020-12-03 07:22:39,228 [Listener at localhost/40964] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1669)) - Adding node with hostname : host6 to rack /r3
2020-12-03 07:22:39,230 [Listener at localhost/40964] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:22:39,230 [Listener at localhost/40964] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:22:39,231 [Listener at localhost/40964] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:22:39,232 [Listener at localhost/40964] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:39,232 [Listener at localhost/40964] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:22:39,232 [Listener at localhost/40964] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is host6
2020-12-03 07:22:39,233 [Listener at localhost/40964] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:39,233 [Listener at localhost/40964] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:22:39,234 [Listener at localhost/40964] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:45386
2020-12-03 07:22:39,234 [Listener at localhost/40964] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:22:39,234 [Listener at localhost/40964] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:22:39,235 [Listener at localhost/40964] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:39,236 [Listener at localhost/40964] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:39,237 [Listener at localhost/40964] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:22:39,237 [Listener at localhost/40964] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:39,239 [Listener at localhost/40964] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:39,240 [Listener at localhost/40964] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:22:39,240 [Listener at localhost/40964] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:39,240 [Listener at localhost/40964] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:39,241 [Listener at localhost/40964] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 41160
2020-12-03 07:22:39,241 [Listener at localhost/40964] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:39,243 [Listener at localhost/40964] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3fabf088{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:39,243 [Listener at localhost/40964] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@12f3afb5{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:39,250 [Listener at localhost/40964] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@79f227a9{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:22:39,251 [Listener at localhost/40964] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6ca320ab{HTTP/1.1,[http/1.1]}{localhost:41160}
2020-12-03 07:22:39,251 [Listener at localhost/40964] INFO  server.Server (Server.java:doStart(419)) - Started @6120ms
2020-12-03 07:22:39,266 [Listener at localhost/40964] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:42525
2020-12-03 07:22:39,266 [Listener at localhost/40964] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:22:39,266 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1e53135d] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:39,266 [Listener at localhost/40964] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:22:39,267 [Listener at localhost/40964] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:39,268 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:39,271 [Listener at localhost/33906] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:33906
2020-12-03 07:22:39,275 [Listener at localhost/33906] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:22:39,276 [Listener at localhost/33906] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:22:39,276 [Thread-172] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36012 starting to offer service
2020-12-03 07:22:39,277 [Listener at localhost/33906] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1724)) - Adding node with service : 127.0.0.1:45386 to rack /r3
2020-12-03 07:22:39,279 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:39,279 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:39,282 [Thread-172] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36012
2020-12-03 07:22:39,282 [Thread-172] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:39,282 [Listener at localhost/33906] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 6 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:22:39,282 [Listener at localhost/33906] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1664)) - Starting DataNode 6 with hostname set to: host7
2020-12-03 07:22:39,283 [Listener at localhost/33906] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1669)) - Adding node with hostname : host7 to rack /r4
2020-12-03 07:22:39,284 [Listener at localhost/33906] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:22:39,285 [Listener at localhost/33906] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:22:39,286 [Listener at localhost/33906] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:22:39,287 [Listener at localhost/33906] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:39,288 [Listener at localhost/33906] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:22:39,288 [Listener at localhost/33906] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is host7
2020-12-03 07:22:39,288 [Listener at localhost/33906] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:39,289 [Listener at localhost/33906] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:22:39,289 [Listener at localhost/33906] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:40234
2020-12-03 07:22:39,289 [Listener at localhost/33906] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:22:39,290 [Listener at localhost/33906] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:22:39,291 [Listener at localhost/33906] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:39,292 [Listener at localhost/33906] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:39,293 [Listener at localhost/33906] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:22:39,293 [Listener at localhost/33906] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:39,295 [Listener at localhost/33906] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:39,296 [Listener at localhost/33906] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:22:39,296 [Listener at localhost/33906] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:39,296 [Listener at localhost/33906] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:39,297 [Listener at localhost/33906] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 34291
2020-12-03 07:22:39,298 [Listener at localhost/33906] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:39,300 [Listener at localhost/33906] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@53bc1328{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:39,300 [Listener at localhost/33906] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3c1e3314{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:39,307 [Listener at localhost/33906] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3a71c100{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:22:39,309 [Listener at localhost/33906] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@5b69fd74{HTTP/1.1,[http/1.1]}{localhost:34291}
2020-12-03 07:22:39,309 [Listener at localhost/33906] INFO  server.Server (Server.java:doStart(419)) - Started @6178ms
2020-12-03 07:22:39,325 [Listener at localhost/33906] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:41354
2020-12-03 07:22:39,326 [Listener at localhost/33906] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:22:39,326 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@437e951d] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:39,326 [Listener at localhost/33906] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:22:39,326 [Listener at localhost/33906] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:39,329 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:39,333 [Listener at localhost/36043] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:36043
2020-12-03 07:22:39,337 [Thread-150] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/in_use.lock acquired by nodename 5051@533329efb28f
2020-12-03 07:22:39,337 [Thread-172] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/in_use.lock acquired by nodename 5051@533329efb28f
2020-12-03 07:22:39,337 [Thread-150] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 is not formatted for namespace 872050423. Formatting...
2020-12-03 07:22:39,338 [Thread-172] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 is not formatted for namespace 872050423. Formatting...
2020-12-03 07:22:39,338 [Listener at localhost/36043] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:22:39,338 [Thread-172] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-f37d1a87-7be4-40de-ad34-60a5fad513e2 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 
2020-12-03 07:22:39,338 [Thread-150] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-8e39d766-2507-4fa6-bfa3-f30fcbfb6361 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 
2020-12-03 07:22:39,338 [Listener at localhost/36043] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:22:39,339 [Thread-194] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36012 starting to offer service
2020-12-03 07:22:39,340 [Listener at localhost/36043] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1724)) - Adding node with service : 127.0.0.1:40234 to rack /r4
2020-12-03 07:22:39,341 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:39,342 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:39,344 [Thread-194] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36012
2020-12-03 07:22:39,345 [Thread-194] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:39,346 [Listener at localhost/36043] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 7 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:22:39,346 [Listener at localhost/36043] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1664)) - Starting DataNode 7 with hostname set to: host8
2020-12-03 07:22:39,346 [Listener at localhost/36043] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1669)) - Adding node with hostname : host8 to rack /r4
2020-12-03 07:22:39,348 [Listener at localhost/36043] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:22:39,348 [Listener at localhost/36043] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:22:39,350 [Listener at localhost/36043] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:22:39,350 [Listener at localhost/36043] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:39,350 [Listener at localhost/36043] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:22:39,351 [Listener at localhost/36043] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is host8
2020-12-03 07:22:39,351 [Listener at localhost/36043] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:39,351 [Listener at localhost/36043] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:22:39,352 [Listener at localhost/36043] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:39617
2020-12-03 07:22:39,352 [Listener at localhost/36043] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:22:39,352 [Listener at localhost/36043] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:22:39,353 [Listener at localhost/36043] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:39,355 [Listener at localhost/36043] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:39,356 [Listener at localhost/36043] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:22:39,356 [Listener at localhost/36043] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:39,358 [Listener at localhost/36043] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:39,358 [Listener at localhost/36043] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:22:39,358 [Listener at localhost/36043] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:39,358 [Listener at localhost/36043] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:39,359 [Listener at localhost/36043] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 39775
2020-12-03 07:22:39,359 [Listener at localhost/36043] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:39,361 [Listener at localhost/36043] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@85ec632{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:39,362 [Listener at localhost/36043] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@65ef722a{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:39,368 [Listener at localhost/36043] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@60b85ba1{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:22:39,370 [Listener at localhost/36043] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@492fc69e{HTTP/1.1,[http/1.1]}{localhost:39775}
2020-12-03 07:22:39,370 [Listener at localhost/36043] INFO  server.Server (Server.java:doStart(419)) - Started @6239ms
2020-12-03 07:22:39,441 [Thread-194] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/in_use.lock acquired by nodename 5051@533329efb28f
2020-12-03 07:22:39,441 [Thread-194] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 is not formatted for namespace 872050423. Formatting...
2020-12-03 07:22:39,442 [Thread-194] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-f0f0e850-b5f4-4644-b56c-a705ab62e451 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 
2020-12-03 07:22:39,469 [Listener at localhost/36043] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:46795
2020-12-03 07:22:39,470 [Listener at localhost/36043] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:22:39,470 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2fb68ec6] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:39,470 [Listener at localhost/36043] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:22:39,472 [Listener at localhost/36043] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:39,473 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:39,478 [Listener at localhost/35265] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:35265
2020-12-03 07:22:39,483 [Listener at localhost/35265] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:22:39,484 [Listener at localhost/35265] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:22:39,485 [Thread-216] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36012 starting to offer service
2020-12-03 07:22:39,485 [Listener at localhost/35265] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1724)) - Adding node with service : 127.0.0.1:39617 to rack /r4
2020-12-03 07:22:39,487 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:39,488 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:39,497 [Listener at localhost/35265] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 8 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:22:39,497 [Listener at localhost/35265] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1664)) - Starting DataNode 8 with hostname set to: host9
2020-12-03 07:22:39,497 [Listener at localhost/35265] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1669)) - Adding node with hostname : host9 to rack /r5
2020-12-03 07:22:39,500 [Listener at localhost/35265] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:22:39,501 [Listener at localhost/35265] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:22:39,505 [Thread-216] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36012
2020-12-03 07:22:39,506 [Thread-216] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:39,512 [Listener at localhost/35265] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:22:39,514 [Listener at localhost/35265] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:39,514 [Listener at localhost/35265] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:22:39,515 [Listener at localhost/35265] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is host9
2020-12-03 07:22:39,515 [Listener at localhost/35265] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:39,515 [Listener at localhost/35265] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:22:39,516 [Listener at localhost/35265] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:45017
2020-12-03 07:22:39,517 [Listener at localhost/35265] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:22:39,517 [Listener at localhost/35265] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:22:39,518 [Listener at localhost/35265] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:39,520 [Listener at localhost/35265] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:39,521 [Listener at localhost/35265] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:22:39,521 [Listener at localhost/35265] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:39,523 [Listener at localhost/35265] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:39,523 [Listener at localhost/35265] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:22:39,524 [Listener at localhost/35265] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:39,524 [Listener at localhost/35265] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:39,525 [Listener at localhost/35265] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 44868
2020-12-03 07:22:39,525 [Listener at localhost/35265] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:39,528 [Listener at localhost/35265] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@530a8454{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:39,529 [Listener at localhost/35265] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5215cd9a{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:39,538 [Listener at localhost/35265] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5a6d5a8f{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:22:39,539 [Listener at localhost/35265] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4a67318f{HTTP/1.1,[http/1.1]}{localhost:44868}
2020-12-03 07:22:39,539 [Listener at localhost/35265] INFO  server.Server (Server.java:doStart(419)) - Started @6408ms
2020-12-03 07:22:39,542 [Thread-128] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/in_use.lock acquired by nodename 5051@533329efb28f
2020-12-03 07:22:39,542 [Thread-128] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 is not formatted for namespace 872050423. Formatting...
2020-12-03 07:22:39,542 [Thread-83] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 5051@533329efb28f
2020-12-03 07:22:39,543 [Thread-83] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 is not formatted for namespace 872050423. Formatting...
2020-12-03 07:22:39,543 [Thread-128] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-1a983e4d-ddf3-46b2-91ca-90f4a6e1615f for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 
2020-12-03 07:22:39,543 [Thread-83] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-681ff351-b360-4f5e-bd2c-c799b895a27a for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 
2020-12-03 07:22:39,570 [Listener at localhost/35265] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:41292
2020-12-03 07:22:39,570 [Listener at localhost/35265] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:22:39,570 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@17f9344b] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:39,570 [Listener at localhost/35265] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:22:39,571 [Listener at localhost/35265] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:39,572 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:39,577 [Listener at localhost/40844] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:40844
2020-12-03 07:22:39,583 [Thread-216] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/in_use.lock acquired by nodename 5051@533329efb28f
2020-12-03 07:22:39,583 [Thread-106] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 5051@533329efb28f
2020-12-03 07:22:39,583 [Thread-59] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 5051@533329efb28f
2020-12-03 07:22:39,583 [Thread-216] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 is not formatted for namespace 872050423. Formatting...
2020-12-03 07:22:39,583 [Thread-106] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 is not formatted for namespace 872050423. Formatting...
2020-12-03 07:22:39,584 [Thread-59] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 872050423. Formatting...
2020-12-03 07:22:39,585 [Thread-59] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-c1d413d2-7376-49c7-8b31-3f158353ef17 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-12-03 07:22:39,586 [Listener at localhost/40844] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:22:39,586 [Listener at localhost/40844] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:22:39,587 [Thread-238] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36012 starting to offer service
2020-12-03 07:22:39,597 [Listener at localhost/40844] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1724)) - Adding node with service : 127.0.0.1:45017 to rack /r5
2020-12-03 07:22:39,598 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:39,598 [Thread-106] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-a7a22227-223b-4d81-b014-9eb36b463dbe for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 
2020-12-03 07:22:39,599 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:39,599 [Thread-216] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-21b99e88-4822-4e4b-a603-4dfda1d22bf8 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 
2020-12-03 07:22:39,605 [Thread-238] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36012
2020-12-03 07:22:39,625 [Thread-238] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:39,625 [Listener at localhost/40844] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 9 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20
2020-12-03 07:22:39,626 [Listener at localhost/40844] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1664)) - Starting DataNode 9 with hostname set to: host10
2020-12-03 07:22:39,626 [Listener at localhost/40844] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1669)) - Adding node with hostname : host10 to rack /r6
2020-12-03 07:22:39,627 [Listener at localhost/40844] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19
2020-12-03 07:22:39,628 [Listener at localhost/40844] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20
2020-12-03 07:22:39,629 [Listener at localhost/40844] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:22:39,630 [Listener at localhost/40844] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:39,631 [Listener at localhost/40844] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:22:39,631 [Listener at localhost/40844] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is host10
2020-12-03 07:22:39,631 [Listener at localhost/40844] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:39,632 [Listener at localhost/40844] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:22:39,633 [Listener at localhost/40844] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:40901
2020-12-03 07:22:39,633 [Listener at localhost/40844] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:22:39,633 [Listener at localhost/40844] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:22:39,634 [Listener at localhost/40844] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:39,637 [Listener at localhost/40844] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:39,637 [Listener at localhost/40844] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:22:39,638 [Listener at localhost/40844] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:39,638 [Thread-150] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/in_use.lock acquired by nodename 5051@533329efb28f
2020-12-03 07:22:39,638 [Thread-172] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/in_use.lock acquired by nodename 5051@533329efb28f
2020-12-03 07:22:39,639 [Thread-150] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 is not formatted for namespace 872050423. Formatting...
2020-12-03 07:22:39,639 [Thread-172] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 is not formatted for namespace 872050423. Formatting...
2020-12-03 07:22:39,640 [Thread-172] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-1ab59b68-5e90-426a-a8e7-4de5c23f0a5c for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 
2020-12-03 07:22:39,640 [Listener at localhost/40844] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:39,641 [Listener at localhost/40844] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:22:39,641 [Listener at localhost/40844] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:39,642 [Listener at localhost/40844] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:39,641 [Thread-150] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-ed5b1af2-4d6a-44cc-8f44-ea6a996fecca for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 
2020-12-03 07:22:39,643 [Listener at localhost/40844] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 45475
2020-12-03 07:22:39,643 [Listener at localhost/40844] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:39,648 [Listener at localhost/40844] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@b273a59{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:39,650 [Listener at localhost/40844] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@251ebf23{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:39,661 [Listener at localhost/40844] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3773862a{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:22:39,662 [Listener at localhost/40844] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2472c7d8{HTTP/1.1,[http/1.1]}{localhost:45475}
2020-12-03 07:22:39,663 [Listener at localhost/40844] INFO  server.Server (Server.java:doStart(419)) - Started @6532ms
2020-12-03 07:22:39,685 [Listener at localhost/40844] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:44954
2020-12-03 07:22:39,686 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@22175d4f] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:39,686 [Listener at localhost/40844] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:22:39,687 [Listener at localhost/40844] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:22:39,687 [Listener at localhost/40844] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:39,689 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:39,694 [Listener at localhost/38093] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:38093
2020-12-03 07:22:39,701 [Thread-238] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/in_use.lock acquired by nodename 5051@533329efb28f
2020-12-03 07:22:39,701 [Thread-238] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 is not formatted for namespace 872050423. Formatting...
2020-12-03 07:22:39,703 [Listener at localhost/38093] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:22:39,703 [Thread-238] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-8003d045-1e99-412a-8cb9-6c5a540f201c for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 
2020-12-03 07:22:39,705 [Listener at localhost/38093] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:22:39,706 [Thread-260] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36012 starting to offer service
2020-12-03 07:22:39,717 [Listener at localhost/38093] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1724)) - Adding node with service : 127.0.0.1:40901 to rack /r6
2020-12-03 07:22:39,718 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:39,718 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:39,739 [Thread-260] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36012
2020-12-03 07:22:39,739 [Thread-260] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:39,777 [Thread-194] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/in_use.lock acquired by nodename 5051@533329efb28f
2020-12-03 07:22:39,777 [Thread-194] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 is not formatted for namespace 872050423. Formatting...
2020-12-03 07:22:39,792 [Thread-194] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-56d51eb8-96f6-40a8-96a0-dc3a49d00c78 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 
2020-12-03 07:22:39,807 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:39,807 [Thread-128] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:39,807 [Thread-83] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:39,808 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 and block pool id BP-1542479078-172.17.0.8-1606980155306 is not formatted. Formatting ...
2020-12-03 07:22:39,809 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1542479078-172.17.0.8-1606980155306 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1542479078-172.17.0.8-1606980155306/current
2020-12-03 07:22:39,808 [Thread-128] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:39,812 [Thread-128] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 and block pool id BP-1542479078-172.17.0.8-1606980155306 is not formatted. Formatting ...
2020-12-03 07:22:39,812 [Thread-128] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1542479078-172.17.0.8-1606980155306 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1542479078-172.17.0.8-1606980155306/current
2020-12-03 07:22:39,828 [Thread-260] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19/in_use.lock acquired by nodename 5051@533329efb28f
2020-12-03 07:22:39,829 [Thread-260] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19 is not formatted for namespace 872050423. Formatting...
2020-12-03 07:22:39,830 [Thread-260] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-a1467a89-1c19-458e-aaea-444c4edcbb62 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19 
2020-12-03 07:22:39,838 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1998)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-12-03 07:22:39,838 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:39,839 [Thread-59] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:39,839 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-1542479078-172.17.0.8-1606980155306 is not formatted. Formatting ...
2020-12-03 07:22:39,839 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1542479078-172.17.0.8-1606980155306 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1542479078-172.17.0.8-1606980155306/current
2020-12-03 07:22:39,839 [Thread-106] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:39,840 [Thread-106] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:39,840 [Thread-106] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 and block pool id BP-1542479078-172.17.0.8-1606980155306 is not formatted. Formatting ...
2020-12-03 07:22:39,840 [Thread-106] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1542479078-172.17.0.8-1606980155306 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1542479078-172.17.0.8-1606980155306/current
2020-12-03 07:22:39,907 [Thread-150] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:39,907 [Thread-150] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:39,907 [Thread-150] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 and block pool id BP-1542479078-172.17.0.8-1606980155306 is not formatted. Formatting ...
2020-12-03 07:22:39,907 [Thread-150] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1542479078-172.17.0.8-1606980155306 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1542479078-172.17.0.8-1606980155306/current
2020-12-03 07:22:39,908 [Thread-172] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:39,908 [Thread-172] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:39,908 [Thread-172] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 and block pool id BP-1542479078-172.17.0.8-1606980155306 is not formatted. Formatting ...
2020-12-03 07:22:39,908 [Thread-172] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1542479078-172.17.0.8-1606980155306 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1542479078-172.17.0.8-1606980155306/current
2020-12-03 07:22:39,960 [Thread-216] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/in_use.lock acquired by nodename 5051@533329efb28f
2020-12-03 07:22:39,960 [Thread-216] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 is not formatted for namespace 872050423. Formatting...
2020-12-03 07:22:39,961 [Thread-216] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-46a01a31-aa4b-45dc-ad39-15882c9ae2df for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 
2020-12-03 07:22:40,032 [Thread-194] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:40,032 [Thread-194] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:40,033 [Thread-194] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 and block pool id BP-1542479078-172.17.0.8-1606980155306 is not formatted. Formatting ...
2020-12-03 07:22:40,033 [Thread-194] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1542479078-172.17.0.8-1606980155306 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1542479078-172.17.0.8-1606980155306/current
2020-12-03 07:22:40,035 [Thread-128] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:40,035 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:40,035 [Thread-128] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:40,035 [Thread-83] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:40,035 [Thread-128] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 and block pool id BP-1542479078-172.17.0.8-1606980155306 is not formatted. Formatting ...
2020-12-03 07:22:40,035 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 and block pool id BP-1542479078-172.17.0.8-1606980155306 is not formatted. Formatting ...
2020-12-03 07:22:40,036 [Thread-128] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1542479078-172.17.0.8-1606980155306 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1542479078-172.17.0.8-1606980155306/current
2020-12-03 07:22:40,036 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1542479078-172.17.0.8-1606980155306 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1542479078-172.17.0.8-1606980155306/current
2020-12-03 07:22:40,081 [Thread-238] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/in_use.lock acquired by nodename 5051@533329efb28f
2020-12-03 07:22:40,081 [Thread-238] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 is not formatted for namespace 872050423. Formatting...
2020-12-03 07:22:40,083 [Thread-238] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-2de1543c-c1ec-4bd6-91e0-70fe2d9c1268 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 
2020-12-03 07:22:40,090 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:40,091 [Thread-59] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:40,091 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-1542479078-172.17.0.8-1606980155306 is not formatted. Formatting ...
2020-12-03 07:22:40,091 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1542479078-172.17.0.8-1606980155306 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1542479078-172.17.0.8-1606980155306/current
2020-12-03 07:22:40,094 [Thread-106] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:40,095 [Thread-106] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:40,095 [Thread-106] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 and block pool id BP-1542479078-172.17.0.8-1606980155306 is not formatted. Formatting ...
2020-12-03 07:22:40,095 [Thread-106] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1542479078-172.17.0.8-1606980155306 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1542479078-172.17.0.8-1606980155306/current
2020-12-03 07:22:40,162 [Thread-150] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:40,162 [Thread-172] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:40,163 [Thread-150] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:40,163 [Thread-150] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 and block pool id BP-1542479078-172.17.0.8-1606980155306 is not formatted. Formatting ...
2020-12-03 07:22:40,163 [Thread-172] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:40,163 [Thread-150] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1542479078-172.17.0.8-1606980155306 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1542479078-172.17.0.8-1606980155306/current
2020-12-03 07:22:40,163 [Thread-172] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 and block pool id BP-1542479078-172.17.0.8-1606980155306 is not formatted. Formatting ...
2020-12-03 07:22:40,163 [Thread-172] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1542479078-172.17.0.8-1606980155306 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1542479078-172.17.0.8-1606980155306/current
2020-12-03 07:22:40,224 [Thread-260] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20/in_use.lock acquired by nodename 5051@533329efb28f
2020-12-03 07:22:40,225 [Thread-260] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20 is not formatted for namespace 872050423. Formatting...
2020-12-03 07:22:40,226 [Thread-260] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-d2c1ad45-6699-44ec-91c4-683f480b3a5c for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20 
2020-12-03 07:22:40,235 [Thread-216] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:40,236 [Thread-216] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:40,236 [Thread-216] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 and block pool id BP-1542479078-172.17.0.8-1606980155306 is not formatted. Formatting ...
2020-12-03 07:22:40,236 [Thread-216] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1542479078-172.17.0.8-1606980155306 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1542479078-172.17.0.8-1606980155306/current
2020-12-03 07:22:40,272 [IPC Server handler 4 on default port 36012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:40,282 [Listener at localhost/38093] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:40,282 [Listener at localhost/38093] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:40,298 [Thread-128] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=872050423;bpid=BP-1542479078-172.17.0.8-1606980155306;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=872050423;c=1606980155306;bpid=BP-1542479078-172.17.0.8-1606980155306;dnuuid=null
2020-12-03 07:22:40,298 [Thread-83] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=872050423;bpid=BP-1542479078-172.17.0.8-1606980155306;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=872050423;c=1606980155306;bpid=BP-1542479078-172.17.0.8-1606980155306;dnuuid=null
2020-12-03 07:22:40,315 [Thread-194] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:40,316 [Thread-194] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:40,316 [Thread-194] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 and block pool id BP-1542479078-172.17.0.8-1606980155306 is not formatted. Formatting ...
2020-12-03 07:22:40,316 [Thread-194] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1542479078-172.17.0.8-1606980155306 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1542479078-172.17.0.8-1606980155306/current
2020-12-03 07:22:40,365 [Thread-59] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=872050423;bpid=BP-1542479078-172.17.0.8-1606980155306;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=872050423;c=1606980155306;bpid=BP-1542479078-172.17.0.8-1606980155306;dnuuid=null
2020-12-03 07:22:40,365 [Thread-106] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=872050423;bpid=BP-1542479078-172.17.0.8-1606980155306;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=872050423;c=1606980155306;bpid=BP-1542479078-172.17.0.8-1606980155306;dnuuid=null
2020-12-03 07:22:40,375 [Thread-238] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:40,375 [Thread-238] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:40,375 [Thread-238] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 and block pool id BP-1542479078-172.17.0.8-1606980155306 is not formatted. Formatting ...
2020-12-03 07:22:40,376 [Thread-238] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1542479078-172.17.0.8-1606980155306 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1542479078-172.17.0.8-1606980155306/current
2020-12-03 07:22:40,386 [IPC Server handler 7 on default port 36012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:40,387 [Listener at localhost/38093] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:40,387 [Listener at localhost/38093] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:40,443 [Thread-150] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=872050423;bpid=BP-1542479078-172.17.0.8-1606980155306;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=872050423;c=1606980155306;bpid=BP-1542479078-172.17.0.8-1606980155306;dnuuid=null
2020-12-03 07:22:40,444 [Thread-172] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=872050423;bpid=BP-1542479078-172.17.0.8-1606980155306;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=872050423;c=1606980155306;bpid=BP-1542479078-172.17.0.8-1606980155306;dnuuid=null
2020-12-03 07:22:40,490 [IPC Server handler 8 on default port 36012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:40,491 [Listener at localhost/38093] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:40,491 [Listener at localhost/38093] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:40,535 [Thread-216] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:40,536 [Thread-216] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:40,536 [Thread-216] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 and block pool id BP-1542479078-172.17.0.8-1606980155306 is not formatted. Formatting ...
2020-12-03 07:22:40,536 [Thread-216] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1542479078-172.17.0.8-1606980155306 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1542479078-172.17.0.8-1606980155306/current
2020-12-03 07:22:40,537 [Thread-260] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:40,538 [Thread-260] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19/current/BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:40,538 [Thread-260] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19 and block pool id BP-1542479078-172.17.0.8-1606980155306 is not formatted. Formatting ...
2020-12-03 07:22:40,538 [Thread-260] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1542479078-172.17.0.8-1606980155306 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19/current/BP-1542479078-172.17.0.8-1606980155306/current
2020-12-03 07:22:40,594 [IPC Server handler 9 on default port 36012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:40,594 [Listener at localhost/38093] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:40,595 [Listener at localhost/38093] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:40,612 [Thread-128] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID ebfaef1c-4294-466a-956a-c88ace7fd121
2020-12-03 07:22:40,613 [Thread-194] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=872050423;bpid=BP-1542479078-172.17.0.8-1606980155306;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=872050423;c=1606980155306;bpid=BP-1542479078-172.17.0.8-1606980155306;dnuuid=null
2020-12-03 07:22:40,613 [Thread-83] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 34ff7519-927c-4ea8-9154-f544635bdcd4
2020-12-03 07:22:40,685 [Thread-106] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 8c91dbe3-abfe-4c89-9b41-cb13db08eba0
2020-12-03 07:22:40,685 [Thread-59] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID c3e1f354-2020-42cf-ad8e-7a6090792910
2020-12-03 07:22:40,694 [Thread-238] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:40,694 [Thread-238] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:40,695 [Thread-238] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 and block pool id BP-1542479078-172.17.0.8-1606980155306 is not formatted. Formatting ...
2020-12-03 07:22:40,695 [Thread-238] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1542479078-172.17.0.8-1606980155306 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1542479078-172.17.0.8-1606980155306/current
2020-12-03 07:22:40,697 [IPC Server handler 0 on default port 36012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:40,698 [Listener at localhost/38093] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:40,698 [Listener at localhost/38093] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:40,742 [Thread-106] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-05ad14d3-6743-431b-89ed-3742b183502a
2020-12-03 07:22:40,742 [Thread-106] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, StorageType: DISK
2020-12-03 07:22:40,742 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-4738ef7e-bb4a-4c3f-bc80-47b226c6d2de
2020-12-03 07:22:40,742 [Thread-128] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-92e8fd76-ed61-46b0-972b-2eb1bdaeedb2
2020-12-03 07:22:40,742 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-ddcf86b6-f4e7-4e7e-b776-8c3ecf9168cb
2020-12-03 07:22:40,744 [Thread-128] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, StorageType: DISK
2020-12-03 07:22:40,744 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-12-03 07:22:40,745 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: DISK
2020-12-03 07:22:40,746 [Thread-106] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-a7a22227-223b-4d81-b014-9eb36b463dbe
2020-12-03 07:22:40,746 [Thread-106] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, StorageType: DISK
2020-12-03 07:22:40,748 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-c1d413d2-7376-49c7-8b31-3f158353ef17
2020-12-03 07:22:40,749 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-12-03 07:22:40,751 [Thread-128] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-1a983e4d-ddf3-46b2-91ca-90f4a6e1615f
2020-12-03 07:22:40,751 [Thread-128] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, StorageType: DISK
2020-12-03 07:22:40,752 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:22:40,752 [Thread-106] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:22:40,752 [Thread-128] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:22:40,754 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-681ff351-b360-4f5e-bd2c-c799b895a27a
2020-12-03 07:22:40,754 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: DISK
2020-12-03 07:22:40,755 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:22:40,760 [Thread-128] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:22:40,761 [Thread-106] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:22:40,762 [Thread-59] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:22:40,764 [Thread-150] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 8204a70a-e37a-4db4-a3af-000c4ffdf4f3
2020-12-03 07:22:40,764 [Thread-172] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID f11e5127-b51f-4a84-b875-807607aa34a6
2020-12-03 07:22:40,764 [Thread-83] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:22:40,766 [Thread-150] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-8e39d766-2507-4fa6-bfa3-f30fcbfb6361
2020-12-03 07:22:40,766 [Thread-150] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, StorageType: DISK
2020-12-03 07:22:40,770 [Thread-172] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-f37d1a87-7be4-40de-ad34-60a5fad513e2
2020-12-03 07:22:40,771 [Thread-172] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, StorageType: DISK
2020-12-03 07:22:40,772 [Thread-59] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:22:40,772 [Thread-150] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-ed5b1af2-4d6a-44cc-8f44-ea6a996fecca
2020-12-03 07:22:40,773 [Thread-106] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:22:40,772 [Thread-128] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:22:40,772 [Thread-83] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:22:40,773 [Thread-150] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, StorageType: DISK
2020-12-03 07:22:40,774 [Thread-150] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:22:40,774 [Thread-106] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:22:40,774 [Thread-106] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:22:40,774 [Thread-59] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:22:40,774 [Thread-83] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:22:40,775 [Thread-59] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:22:40,775 [Thread-106] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:40,774 [Thread-128] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:22:40,777 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:40,776 [Thread-83] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:22:40,778 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:40,777 [Thread-172] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-1ab59b68-5e90-426a-a8e7-4de5c23f0a5c
2020-12-03 07:22:40,778 [Thread-172] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, StorageType: DISK
2020-12-03 07:22:40,779 [Thread-172] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:22:40,777 [Thread-128] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:22:40,778 [Thread-286] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:22:40,779 [Thread-128] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:40,779 [Thread-150] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:22:40,780 [Thread-288] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:22:40,780 [Thread-290] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-12-03 07:22:40,780 [Thread-287] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:22:40,782 [Thread-289] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:22:40,782 [Thread-291] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-12-03 07:22:40,782 [Thread-293] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:22:40,782 [Thread-292] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:22:40,782 [Thread-150] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:22:40,782 [Thread-150] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:22:40,782 [Thread-172] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:22:40,783 [Thread-150] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:22:40,784 [Thread-150] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:40,784 [Thread-172] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:22:40,784 [Thread-172] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:22:40,785 [Thread-294] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-12-03 07:22:40,785 [Thread-172] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:22:40,785 [Thread-295] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-12-03 07:22:40,785 [Thread-172] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:40,785 [Thread-296] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11...
2020-12-03 07:22:40,786 [Thread-297] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12...
2020-12-03 07:22:40,801 [IPC Server handler 1 on default port 36012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:40,802 [Thread-216] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=872050423;bpid=BP-1542479078-172.17.0.8-1606980155306;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=872050423;c=1606980155306;bpid=BP-1542479078-172.17.0.8-1606980155306;dnuuid=null
2020-12-03 07:22:40,803 [Listener at localhost/38093] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:40,803 [Listener at localhost/38093] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:40,816 [Thread-260] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:40,817 [Thread-260] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20/current/BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:40,817 [Thread-260] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20 and block pool id BP-1542479078-172.17.0.8-1606980155306 is not formatted. Formatting ...
2020-12-03 07:22:40,817 [Thread-260] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1542479078-172.17.0.8-1606980155306 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20/current/BP-1542479078-172.17.0.8-1606980155306/current
2020-12-03 07:22:40,842 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1998)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-12-03 07:22:40,873 [Thread-194] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 001b4761-f836-4ea2-9f52-478db0422ff2
2020-12-03 07:22:40,877 [Thread-194] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-f0f0e850-b5f4-4644-b56c-a705ab62e451
2020-12-03 07:22:40,877 [Thread-194] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, StorageType: DISK
2020-12-03 07:22:40,878 [Thread-294] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1542479078-172.17.0.8-1606980155306 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 93ms
2020-12-03 07:22:40,879 [Thread-194] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-56d51eb8-96f6-40a8-96a0-dc3a49d00c78
2020-12-03 07:22:40,880 [Thread-194] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, StorageType: DISK
2020-12-03 07:22:40,887 [Thread-194] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:22:40,888 [Thread-286] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1542479078-172.17.0.8-1606980155306 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 109ms
2020-12-03 07:22:40,889 [Thread-194] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:22:40,890 [Thread-289] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1542479078-172.17.0.8-1606980155306 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 108ms
2020-12-03 07:22:40,890 [Thread-290] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1542479078-172.17.0.8-1606980155306 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 110ms
2020-12-03 07:22:40,890 [Thread-194] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:22:40,892 [Thread-194] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:22:40,893 [Thread-293] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1542479078-172.17.0.8-1606980155306 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 111ms
2020-12-03 07:22:40,893 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1542479078-172.17.0.8-1606980155306: 115ms
2020-12-03 07:22:40,900 [Thread-194] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:22:40,900 [Thread-291] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1542479078-172.17.0.8-1606980155306 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 119ms
2020-12-03 07:22:40,901 [Thread-194] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:40,900 [Thread-287] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1542479078-172.17.0.8-1606980155306 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 118ms
2020-12-03 07:22:40,901 [Thread-128] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1542479078-172.17.0.8-1606980155306: 122ms
2020-12-03 07:22:40,902 [Thread-312] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13...
2020-12-03 07:22:40,902 [Thread-295] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1542479078-172.17.0.8-1606980155306 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 117ms
2020-12-03 07:22:40,902 [Thread-292] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1542479078-172.17.0.8-1606980155306 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 120ms
2020-12-03 07:22:40,902 [Thread-313] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14...
2020-12-03 07:22:40,902 [Thread-150] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1542479078-172.17.0.8-1606980155306: 118ms
2020-12-03 07:22:40,902 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1542479078-172.17.0.8-1606980155306: 125ms
2020-12-03 07:22:40,903 [Thread-314] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-12-03 07:22:40,903 [Thread-317] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:22:40,903 [Thread-314] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1542479078-172.17.0.8-1606980155306/current/replicas doesn't exist 
2020-12-03 07:22:40,903 [Thread-288] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1542479078-172.17.0.8-1606980155306 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 123ms
2020-12-03 07:22:40,904 [Thread-316] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-12-03 07:22:40,903 [Thread-317] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1542479078-172.17.0.8-1606980155306/current/replicas doesn't exist 
2020-12-03 07:22:40,904 [Thread-106] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1542479078-172.17.0.8-1606980155306: 127ms
2020-12-03 07:22:40,907 [Thread-316] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1542479078-172.17.0.8-1606980155306/current/replicas doesn't exist 
2020-12-03 07:22:40,907 [Thread-321] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:22:40,907 [Thread-297] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1542479078-172.17.0.8-1606980155306 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12: 121ms
2020-12-03 07:22:40,907 [Thread-315] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:22:40,910 [Thread-322] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:22:40,914 [Thread-315] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1542479078-172.17.0.8-1606980155306/current/replicas doesn't exist 
2020-12-03 07:22:40,910 [Thread-318] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-12-03 07:22:40,916 [Thread-316] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 9ms
2020-12-03 07:22:40,908 [Thread-321] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1542479078-172.17.0.8-1606980155306/current/replicas doesn't exist 
2020-12-03 07:22:40,910 [Thread-319] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:22:40,907 [Thread-296] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1542479078-172.17.0.8-1606980155306 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11: 121ms
2020-12-03 07:22:40,916 [Thread-321] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 8ms
2020-12-03 07:22:40,907 [Thread-320] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-12-03 07:22:40,916 [Thread-172] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1542479078-172.17.0.8-1606980155306: 132ms
2020-12-03 07:22:40,916 [Thread-319] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1542479078-172.17.0.8-1606980155306/current/replicas doesn't exist 
2020-12-03 07:22:40,916 [Thread-318] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1542479078-172.17.0.8-1606980155306/current/replicas doesn't exist 
2020-12-03 07:22:40,915 [Thread-315] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 2ms
2020-12-03 07:22:40,915 [IPC Server handler 2 on default port 36012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:40,915 [Thread-317] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 12ms
2020-12-03 07:22:40,915 [Thread-314] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 12ms
2020-12-03 07:22:40,914 [Thread-322] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1542479078-172.17.0.8-1606980155306/current/replicas doesn't exist 
2020-12-03 07:22:40,914 [Thread-323] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:22:40,923 [Thread-318] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 8ms
2020-12-03 07:22:40,924 [Thread-322] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 10ms
2020-12-03 07:22:40,923 [Thread-327] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12...
2020-12-03 07:22:40,923 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1542479078-172.17.0.8-1606980155306: 20ms
2020-12-03 07:22:40,923 [Thread-319] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 7ms
2020-12-03 07:22:40,923 [Thread-326] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11...
2020-12-03 07:22:40,918 [Thread-320] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1542479078-172.17.0.8-1606980155306/current/replicas doesn't exist 
2020-12-03 07:22:40,926 [Thread-238] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=872050423;bpid=BP-1542479078-172.17.0.8-1606980155306;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=872050423;c=1606980155306;bpid=BP-1542479078-172.17.0.8-1606980155306;dnuuid=null
2020-12-03 07:22:40,924 [Thread-327] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1542479078-172.17.0.8-1606980155306/current/replicas doesn't exist 
2020-12-03 07:22:40,924 [Listener at localhost/38093] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:40,929 [Listener at localhost/38093] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:40,924 [Thread-150] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1542479078-172.17.0.8-1606980155306: 21ms
2020-12-03 07:22:40,924 [Thread-323] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1542479078-172.17.0.8-1606980155306/current/replicas doesn't exist 
2020-12-03 07:22:40,929 [Thread-320] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 11ms
2020-12-03 07:22:40,928 [Thread-326] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1542479078-172.17.0.8-1606980155306/current/replicas doesn't exist 
2020-12-03 07:22:40,929 [Thread-128] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1542479078-172.17.0.8-1606980155306: 27ms
2020-12-03 07:22:40,930 [Thread-323] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 6ms
2020-12-03 07:22:40,929 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:22:40,930 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:22:40,930 [Thread-106] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1542479078-172.17.0.8-1606980155306: 23ms
2020-12-03 07:22:40,930 [Thread-326] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11: 2ms
2020-12-03 07:22:40,930 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1542479078-172.17.0.8-1606980155306: 27ms
2020-12-03 07:22:40,937 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:22:40,937 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:22:40,937 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:22:40,937 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:22:40,931 [Thread-327] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12: 7ms
2020-12-03 07:22:40,930 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:22:40,939 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-681ff351-b360-4f5e-bd2c-c799b895a27a): finished scanning block pool BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:40,939 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:22:40,940 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-1a983e4d-ddf3-46b2-91ca-90f4a6e1615f): finished scanning block pool BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:40,938 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:22:40,938 [Thread-172] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1542479078-172.17.0.8-1606980155306: 15ms
2020-12-03 07:22:40,938 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-c1d413d2-7376-49c7-8b31-3f158353ef17): finished scanning block pool BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:40,937 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:22:40,940 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:22:40,940 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-ddcf86b6-f4e7-4e7e-b776-8c3ecf9168cb): finished scanning block pool BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:40,941 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-a7a22227-223b-4d81-b014-9eb36b463dbe): finished scanning block pool BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:40,940 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-92e8fd76-ed61-46b0-972b-2eb1bdaeedb2): finished scanning block pool BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:40,940 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-8e39d766-2507-4fa6-bfa3-f30fcbfb6361): finished scanning block pool BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:40,940 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-4738ef7e-bb4a-4c3f-bc80-47b226c6d2de): finished scanning block pool BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:40,940 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-05ad14d3-6743-431b-89ed-3742b183502a): finished scanning block pool BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:40,939 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-ed5b1af2-4d6a-44cc-8f44-ea6a996fecca): finished scanning block pool BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:40,941 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-1ab59b68-5e90-426a-a8e7-4de5c23f0a5c): finished scanning block pool BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:40,940 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:22:40,946 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-f37d1a87-7be4-40de-ad34-60a5fad513e2): finished scanning block pool BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:40,953 [Thread-313] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1542479078-172.17.0.8-1606980155306 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14: 51ms
2020-12-03 07:22:40,967 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-05ad14d3-6743-431b-89ed-3742b183502a): no suitable block pools found to scan.  Waiting 1814399971 ms.
2020-12-03 07:22:40,967 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-8e39d766-2507-4fa6-bfa3-f30fcbfb6361): no suitable block pools found to scan.  Waiting 1814399963 ms.
2020-12-03 07:22:40,967 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-f37d1a87-7be4-40de-ad34-60a5fad513e2): no suitable block pools found to scan.  Waiting 1814399973 ms.
2020-12-03 07:22:40,967 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-1ab59b68-5e90-426a-a8e7-4de5c23f0a5c): no suitable block pools found to scan.  Waiting 1814399973 ms.
2020-12-03 07:22:40,967 [Thread-106] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 10:21 AM with interval of 21600000ms
2020-12-03 07:22:40,967 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-681ff351-b360-4f5e-bd2c-c799b895a27a): no suitable block pools found to scan.  Waiting 1814399970 ms.
2020-12-03 07:22:40,967 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-c1d413d2-7376-49c7-8b31-3f158353ef17): no suitable block pools found to scan.  Waiting 1814399962 ms.
2020-12-03 07:22:40,968 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-92e8fd76-ed61-46b0-972b-2eb1bdaeedb2): no suitable block pools found to scan.  Waiting 1814399968 ms.
2020-12-03 07:22:40,967 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-a7a22227-223b-4d81-b014-9eb36b463dbe): no suitable block pools found to scan.  Waiting 1814399970 ms.
2020-12-03 07:22:40,967 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-1a983e4d-ddf3-46b2-91ca-90f4a6e1615f): no suitable block pools found to scan.  Waiting 1814399963 ms.
2020-12-03 07:22:40,968 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-ddcf86b6-f4e7-4e7e-b776-8c3ecf9168cb): no suitable block pools found to scan.  Waiting 1814399969 ms.
2020-12-03 07:22:40,968 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-4738ef7e-bb4a-4c3f-bc80-47b226c6d2de): no suitable block pools found to scan.  Waiting 1814399961 ms.
2020-12-03 07:22:40,968 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-ed5b1af2-4d6a-44cc-8f44-ea6a996fecca): no suitable block pools found to scan.  Waiting 1814399969 ms.
2020-12-03 07:22:40,967 [Thread-59] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:43 AM with interval of 21600000ms
2020-12-03 07:22:40,968 [Thread-83] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 9:38 AM with interval of 21600000ms
2020-12-03 07:22:40,968 [Thread-128] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:39 AM with interval of 21600000ms
2020-12-03 07:22:40,968 [Thread-150] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:32 AM with interval of 21600000ms
2020-12-03 07:22:40,980 [Thread-172] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 8:47 AM with interval of 21600000ms
2020-12-03 07:22:40,987 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1542479078-172.17.0.8-1606980155306 (Datanode Uuid c3e1f354-2020-42cf-ad8e-7a6090792910) service to localhost/127.0.0.1:36012 beginning handshake with NN
2020-12-03 07:22:40,987 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1542479078-172.17.0.8-1606980155306 (Datanode Uuid ebfaef1c-4294-466a-956a-c88ace7fd121) service to localhost/127.0.0.1:36012 beginning handshake with NN
2020-12-03 07:22:40,987 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1542479078-172.17.0.8-1606980155306 (Datanode Uuid 8c91dbe3-abfe-4c89-9b41-cb13db08eba0) service to localhost/127.0.0.1:36012 beginning handshake with NN
2020-12-03 07:22:40,987 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1542479078-172.17.0.8-1606980155306 (Datanode Uuid f11e5127-b51f-4a84-b875-807607aa34a6) service to localhost/127.0.0.1:36012 beginning handshake with NN
2020-12-03 07:22:40,987 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1542479078-172.17.0.8-1606980155306 (Datanode Uuid 34ff7519-927c-4ea8-9154-f544635bdcd4) service to localhost/127.0.0.1:36012 beginning handshake with NN
2020-12-03 07:22:40,987 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1542479078-172.17.0.8-1606980155306 (Datanode Uuid 8204a70a-e37a-4db4-a3af-000c4ffdf4f3) service to localhost/127.0.0.1:36012 beginning handshake with NN
2020-12-03 07:22:40,991 [Thread-312] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1542479078-172.17.0.8-1606980155306 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13: 89ms
2020-12-03 07:22:40,991 [Thread-194] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1542479078-172.17.0.8-1606980155306: 90ms
2020-12-03 07:22:40,992 [Thread-346] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13...
2020-12-03 07:22:40,992 [Thread-347] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14...
2020-12-03 07:22:40,992 [Thread-346] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1542479078-172.17.0.8-1606980155306/current/replicas doesn't exist 
2020-12-03 07:22:40,992 [Thread-347] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1542479078-172.17.0.8-1606980155306/current/replicas doesn't exist 
2020-12-03 07:22:40,996 [Thread-347] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14: 4ms
2020-12-03 07:22:40,996 [Thread-346] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13: 4ms
2020-12-03 07:22:40,997 [Thread-194] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1542479078-172.17.0.8-1606980155306: 5ms
2020-12-03 07:22:40,997 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:22:40,997 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:22:40,997 [Thread-194] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 9:40 AM with interval of 21600000ms
2020-12-03 07:22:40,997 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-f0f0e850-b5f4-4644-b56c-a705ab62e451): finished scanning block pool BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:40,997 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-56d51eb8-96f6-40a8-96a0-dc3a49d00c78): finished scanning block pool BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:40,999 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1542479078-172.17.0.8-1606980155306 (Datanode Uuid 001b4761-f836-4ea2-9f52-478db0422ff2) service to localhost/127.0.0.1:36012 beginning handshake with NN
2020-12-03 07:22:41,000 [Thread-216] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID d5b3f975-4d17-4d98-968c-975d03e85a9a
2020-12-03 07:22:41,000 [Thread-260] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=872050423;bpid=BP-1542479078-172.17.0.8-1606980155306;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=872050423;c=1606980155306;bpid=BP-1542479078-172.17.0.8-1606980155306;dnuuid=null
2020-12-03 07:22:41,000 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-56d51eb8-96f6-40a8-96a0-dc3a49d00c78): no suitable block pools found to scan.  Waiting 1814399997 ms.
2020-12-03 07:22:41,000 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-f0f0e850-b5f4-4644-b56c-a705ab62e451): no suitable block pools found to scan.  Waiting 1814399997 ms.
2020-12-03 07:22:41,008 [IPC Server handler 3 on default port 36012] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:40234, datanodeUuid=001b4761-f836-4ea2-9f52-478db0422ff2, infoPort=41354, infoSecurePort=0, ipcPort=36043, storageInfo=lv=-57;cid=testClusterID;nsid=872050423;c=1606980155306) storage 001b4761-f836-4ea2-9f52-478db0422ff2
2020-12-03 07:22:41,008 [Thread-216] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-21b99e88-4822-4e4b-a603-4dfda1d22bf8
2020-12-03 07:22:41,009 [Thread-216] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, StorageType: DISK
2020-12-03 07:22:41,010 [Thread-216] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-46a01a31-aa4b-45dc-ad39-15882c9ae2df
2020-12-03 07:22:41,010 [Thread-216] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, StorageType: DISK
2020-12-03 07:22:41,011 [IPC Server handler 3 on default port 36012] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /r4/127.0.0.1:40234
2020-12-03 07:22:41,012 [IPC Server handler 3 on default port 36012] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 001b4761-f836-4ea2-9f52-478db0422ff2 (127.0.0.1:40234).
2020-12-03 07:22:41,012 [Thread-216] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:22:41,013 [Thread-216] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:22:41,014 [IPC Server handler 4 on default port 36012] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:45386, datanodeUuid=f11e5127-b51f-4a84-b875-807607aa34a6, infoPort=42525, infoSecurePort=0, ipcPort=33906, storageInfo=lv=-57;cid=testClusterID;nsid=872050423;c=1606980155306) storage f11e5127-b51f-4a84-b875-807607aa34a6
2020-12-03 07:22:41,014 [Thread-216] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:22:41,014 [IPC Server handler 4 on default port 36012] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /r3/127.0.0.1:45386
2020-12-03 07:22:41,014 [Thread-216] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:22:41,014 [IPC Server handler 4 on default port 36012] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:checkIfClusterIsNowMultiRack(1387)) - DN 127.0.0.1:45386 joining cluster has expanded a formerly single-rack cluster to be multi-rack. Re-checking all blocks for replication, since they should now be replicated cross-rack
2020-12-03 07:22:41,014 [Thread-216] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:22:41,014 [Thread-216] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:41,015 [Thread-354] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15...
2020-12-03 07:22:41,016 [Thread-355] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16...
2020-12-03 07:22:41,016 [IPC Server handler 4 on default port 36012] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN f11e5127-b51f-4a84-b875-807607aa34a6 (127.0.0.1:45386).
2020-12-03 07:22:41,017 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1542479078-172.17.0.8-1606980155306 (Datanode Uuid 001b4761-f836-4ea2-9f52-478db0422ff2) service to localhost/127.0.0.1:36012 successfully registered with NN
2020-12-03 07:22:41,017 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:36012 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:22:41,018 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1542479078-172.17.0.8-1606980155306 (Datanode Uuid f11e5127-b51f-4a84-b875-807607aa34a6) service to localhost/127.0.0.1:36012 successfully registered with NN
2020-12-03 07:22:41,018 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:36012 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:22:41,018 [IPC Server handler 5 on default port 36012] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:38964, datanodeUuid=ebfaef1c-4294-466a-956a-c88ace7fd121, infoPort=46799, infoSecurePort=0, ipcPort=40410, storageInfo=lv=-57;cid=testClusterID;nsid=872050423;c=1606980155306) storage ebfaef1c-4294-466a-956a-c88ace7fd121
2020-12-03 07:22:41,018 [IPC Server handler 5 on default port 36012] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /r2/127.0.0.1:38964
2020-12-03 07:22:41,019 [IPC Server handler 5 on default port 36012] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN ebfaef1c-4294-466a-956a-c88ace7fd121 (127.0.0.1:38964).
2020-12-03 07:22:41,019 [IPC Server handler 6 on default port 36012] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:39491, datanodeUuid=34ff7519-927c-4ea8-9154-f544635bdcd4, infoPort=34327, infoSecurePort=0, ipcPort=46347, storageInfo=lv=-57;cid=testClusterID;nsid=872050423;c=1606980155306) storage 34ff7519-927c-4ea8-9154-f544635bdcd4
2020-12-03 07:22:41,019 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1542479078-172.17.0.8-1606980155306 (Datanode Uuid ebfaef1c-4294-466a-956a-c88ace7fd121) service to localhost/127.0.0.1:36012 successfully registered with NN
2020-12-03 07:22:41,020 [IPC Server handler 6 on default port 36012] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /r1/127.0.0.1:39491
2020-12-03 07:22:41,020 [IPC Server handler 6 on default port 36012] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 34ff7519-927c-4ea8-9154-f544635bdcd4 (127.0.0.1:39491).
2020-12-03 07:22:41,020 [IPC Server handler 7 on default port 36012] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:41586, datanodeUuid=8204a70a-e37a-4db4-a3af-000c4ffdf4f3, infoPort=34293, infoSecurePort=0, ipcPort=40964, storageInfo=lv=-57;cid=testClusterID;nsid=872050423;c=1606980155306) storage 8204a70a-e37a-4db4-a3af-000c4ffdf4f3
2020-12-03 07:22:41,020 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:36012 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:22:41,020 [IPC Server handler 7 on default port 36012] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /r3/127.0.0.1:41586
2020-12-03 07:22:41,021 [IPC Server handler 7 on default port 36012] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 8204a70a-e37a-4db4-a3af-000c4ffdf4f3 (127.0.0.1:41586).
2020-12-03 07:22:41,025 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1542479078-172.17.0.8-1606980155306 (Datanode Uuid 34ff7519-927c-4ea8-9154-f544635bdcd4) service to localhost/127.0.0.1:36012 successfully registered with NN
2020-12-03 07:22:41,025 [IPC Server handler 8 on default port 36012] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:46157, datanodeUuid=c3e1f354-2020-42cf-ad8e-7a6090792910, infoPort=42565, infoSecurePort=0, ipcPort=34197, storageInfo=lv=-57;cid=testClusterID;nsid=872050423;c=1606980155306) storage c3e1f354-2020-42cf-ad8e-7a6090792910
2020-12-03 07:22:41,025 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:36012 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:22:41,025 [IPC Server handler 8 on default port 36012] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /r1/127.0.0.1:46157
2020-12-03 07:22:41,026 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1542479078-172.17.0.8-1606980155306 (Datanode Uuid 8204a70a-e37a-4db4-a3af-000c4ffdf4f3) service to localhost/127.0.0.1:36012 successfully registered with NN
2020-12-03 07:22:41,026 [IPC Server handler 8 on default port 36012] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN c3e1f354-2020-42cf-ad8e-7a6090792910 (127.0.0.1:46157).
2020-12-03 07:22:41,027 [IPC Server handler 9 on default port 36012] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:42147, datanodeUuid=8c91dbe3-abfe-4c89-9b41-cb13db08eba0, infoPort=38259, infoSecurePort=0, ipcPort=36393, storageInfo=lv=-57;cid=testClusterID;nsid=872050423;c=1606980155306) storage 8c91dbe3-abfe-4c89-9b41-cb13db08eba0
2020-12-03 07:22:41,027 [IPC Server handler 9 on default port 36012] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /r2/127.0.0.1:42147
2020-12-03 07:22:41,026 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:36012 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:22:41,027 [IPC Server handler 9 on default port 36012] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 8c91dbe3-abfe-4c89-9b41-cb13db08eba0 (127.0.0.1:42147).
2020-12-03 07:22:41,029 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 0
2020-12-03 07:22:41,029 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1542479078-172.17.0.8-1606980155306 (Datanode Uuid c3e1f354-2020-42cf-ad8e-7a6090792910) service to localhost/127.0.0.1:36012 successfully registered with NN
2020-12-03 07:22:41,029 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:22:41,029 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:36012 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:22:41,029 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1542479078-172.17.0.8-1606980155306 (Datanode Uuid 8c91dbe3-abfe-4c89-9b41-cb13db08eba0) service to localhost/127.0.0.1:36012 successfully registered with NN
2020-12-03 07:22:41,029 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:22:41,029 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:36012 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:22:41,029 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:22:41,030 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:22:41,031 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 14 msec
2020-12-03 07:22:41,044 [IPC Server handler 0 on default port 36012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:41,053 [Listener at localhost/38093] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:41,055 [Listener at localhost/38093] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:41,056 [Thread-355] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1542479078-172.17.0.8-1606980155306 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16: 39ms
2020-12-03 07:22:41,059 [IPC Server handler 1 on default port 36012] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-05ad14d3-6743-431b-89ed-3742b183502a for DN 127.0.0.1:42147
2020-12-03 07:22:41,060 [IPC Server handler 1 on default port 36012] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-a7a22227-223b-4d81-b014-9eb36b463dbe for DN 127.0.0.1:42147
2020-12-03 07:22:41,060 [IPC Server handler 7 on default port 36012] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-92e8fd76-ed61-46b0-972b-2eb1bdaeedb2 for DN 127.0.0.1:38964
2020-12-03 07:22:41,062 [IPC Server handler 7 on default port 36012] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-1a983e4d-ddf3-46b2-91ca-90f4a6e1615f for DN 127.0.0.1:38964
2020-12-03 07:22:41,062 [IPC Server handler 6 on default port 36012] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-f0f0e850-b5f4-4644-b56c-a705ab62e451 for DN 127.0.0.1:40234
2020-12-03 07:22:41,062 [IPC Server handler 6 on default port 36012] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-56d51eb8-96f6-40a8-96a0-dc3a49d00c78 for DN 127.0.0.1:40234
2020-12-03 07:22:41,063 [IPC Server handler 5 on default port 36012] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-8e39d766-2507-4fa6-bfa3-f30fcbfb6361 for DN 127.0.0.1:41586
2020-12-03 07:22:41,063 [Thread-354] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1542479078-172.17.0.8-1606980155306 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15: 48ms
2020-12-03 07:22:41,063 [IPC Server handler 5 on default port 36012] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-ed5b1af2-4d6a-44cc-8f44-ea6a996fecca for DN 127.0.0.1:41586
2020-12-03 07:22:41,063 [Thread-216] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1542479078-172.17.0.8-1606980155306: 48ms
2020-12-03 07:22:41,063 [IPC Server handler 4 on default port 36012] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-4738ef7e-bb4a-4c3f-bc80-47b226c6d2de for DN 127.0.0.1:46157
2020-12-03 07:22:41,063 [IPC Server handler 4 on default port 36012] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c1d413d2-7376-49c7-8b31-3f158353ef17 for DN 127.0.0.1:46157
2020-12-03 07:22:41,064 [IPC Server handler 3 on default port 36012] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-f37d1a87-7be4-40de-ad34-60a5fad513e2 for DN 127.0.0.1:45386
2020-12-03 07:22:41,064 [Thread-359] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16...
2020-12-03 07:22:41,064 [Thread-358] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15...
2020-12-03 07:22:41,064 [IPC Server handler 3 on default port 36012] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-1ab59b68-5e90-426a-a8e7-4de5c23f0a5c for DN 127.0.0.1:45386
2020-12-03 07:22:41,065 [Thread-359] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1542479078-172.17.0.8-1606980155306/current/replicas doesn't exist 
2020-12-03 07:22:41,065 [Thread-358] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1542479078-172.17.0.8-1606980155306/current/replicas doesn't exist 
2020-12-03 07:22:41,065 [IPC Server handler 2 on default port 36012] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-ddcf86b6-f4e7-4e7e-b776-8c3ecf9168cb for DN 127.0.0.1:39491
2020-12-03 07:22:41,065 [Thread-359] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16: 0ms
2020-12-03 07:22:41,066 [Thread-358] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15: 1ms
2020-12-03 07:22:41,066 [IPC Server handler 2 on default port 36012] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-681ff351-b360-4f5e-bd2c-c799b895a27a for DN 127.0.0.1:39491
2020-12-03 07:22:41,067 [Thread-216] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1542479078-172.17.0.8-1606980155306: 4ms
2020-12-03 07:22:41,067 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:22:41,067 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:22:41,068 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-46a01a31-aa4b-45dc-ad39-15882c9ae2df): finished scanning block pool BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:41,068 [Thread-216] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 1:12 PM with interval of 21600000ms
2020-12-03 07:22:41,068 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-21b99e88-4822-4e4b-a603-4dfda1d22bf8): finished scanning block pool BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:41,069 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-46a01a31-aa4b-45dc-ad39-15882c9ae2df): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-12-03 07:22:41,069 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-21b99e88-4822-4e4b-a603-4dfda1d22bf8): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-12-03 07:22:41,069 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1542479078-172.17.0.8-1606980155306 (Datanode Uuid d5b3f975-4d17-4d98-968c-975d03e85a9a) service to localhost/127.0.0.1:36012 beginning handshake with NN
2020-12-03 07:22:41,072 [IPC Server handler 8 on default port 36012] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:39617, datanodeUuid=d5b3f975-4d17-4d98-968c-975d03e85a9a, infoPort=46795, infoSecurePort=0, ipcPort=35265, storageInfo=lv=-57;cid=testClusterID;nsid=872050423;c=1606980155306) storage d5b3f975-4d17-4d98-968c-975d03e85a9a
2020-12-03 07:22:41,072 [IPC Server handler 8 on default port 36012] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /r4/127.0.0.1:39617
2020-12-03 07:22:41,072 [IPC Server handler 8 on default port 36012] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN d5b3f975-4d17-4d98-968c-975d03e85a9a (127.0.0.1:39617).
2020-12-03 07:22:41,073 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1542479078-172.17.0.8-1606980155306 (Datanode Uuid d5b3f975-4d17-4d98-968c-975d03e85a9a) service to localhost/127.0.0.1:36012 successfully registered with NN
2020-12-03 07:22:41,073 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:36012 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:22:41,077 [IPC Server handler 9 on default port 36012] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-21b99e88-4822-4e4b-a603-4dfda1d22bf8 for DN 127.0.0.1:39617
2020-12-03 07:22:41,078 [IPC Server handler 9 on default port 36012] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-46a01a31-aa4b-45dc-ad39-15882c9ae2df for DN 127.0.0.1:39617
2020-12-03 07:22:41,102 [IPC Server handler 2 on default port 36012] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1566)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:40234, datanodeUuid=001b4761-f836-4ea2-9f52-478db0422ff2, infoPort=41354, infoSecurePort=0, ipcPort=36043, storageInfo=lv=-57;cid=testClusterID;nsid=872050423;c=1606980155306), reports.length=2
2020-12-03 07:22:41,102 [IPC Server handler 8 on default port 36012] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1566)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:42147, datanodeUuid=8c91dbe3-abfe-4c89-9b41-cb13db08eba0, infoPort=38259, infoSecurePort=0, ipcPort=36393, storageInfo=lv=-57;cid=testClusterID;nsid=872050423;c=1606980155306), reports.length=2
2020-12-03 07:22:41,102 [IPC Server handler 0 on default port 36012] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1566)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:38964, datanodeUuid=ebfaef1c-4294-466a-956a-c88ace7fd121, infoPort=46799, infoSecurePort=0, ipcPort=40410, storageInfo=lv=-57;cid=testClusterID;nsid=872050423;c=1606980155306), reports.length=2
2020-12-03 07:22:41,102 [IPC Server handler 5 on default port 36012] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1566)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:41586, datanodeUuid=8204a70a-e37a-4db4-a3af-000c4ffdf4f3, infoPort=34293, infoSecurePort=0, ipcPort=40964, storageInfo=lv=-57;cid=testClusterID;nsid=872050423;c=1606980155306), reports.length=2
2020-12-03 07:22:41,103 [IPC Server handler 4 on default port 36012] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1566)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:46157, datanodeUuid=c3e1f354-2020-42cf-ad8e-7a6090792910, infoPort=42565, infoSecurePort=0, ipcPort=34197, storageInfo=lv=-57;cid=testClusterID;nsid=872050423;c=1606980155306), reports.length=2
2020-12-03 07:22:41,103 [IPC Server handler 3 on default port 36012] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1566)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:45386, datanodeUuid=f11e5127-b51f-4a84-b875-807607aa34a6, infoPort=42525, infoSecurePort=0, ipcPort=33906, storageInfo=lv=-57;cid=testClusterID;nsid=872050423;c=1606980155306), reports.length=2
2020-12-03 07:22:41,108 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xd9834470ce8f5c91: Processing first storage report for DS-c1d413d2-7376-49c7-8b31-3f158353ef17 from datanode c3e1f354-2020-42cf-ad8e-7a6090792910
2020-12-03 07:22:41,110 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xd9834470ce8f5c91: from storage DS-c1d413d2-7376-49c7-8b31-3f158353ef17 node DatanodeRegistration(127.0.0.1:46157, datanodeUuid=c3e1f354-2020-42cf-ad8e-7a6090792910, infoPort=42565, infoSecurePort=0, ipcPort=34197, storageInfo=lv=-57;cid=testClusterID;nsid=872050423;c=1606980155306), blocks: 0, hasStaleStorage: true, processing time: 2 msecs, invalidatedBlocks: 0
2020-12-03 07:22:41,110 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x964cecf35d914534: Processing first storage report for DS-56d51eb8-96f6-40a8-96a0-dc3a49d00c78 from datanode 001b4761-f836-4ea2-9f52-478db0422ff2
2020-12-03 07:22:41,110 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x964cecf35d914534: from storage DS-56d51eb8-96f6-40a8-96a0-dc3a49d00c78 node DatanodeRegistration(127.0.0.1:40234, datanodeUuid=001b4761-f836-4ea2-9f52-478db0422ff2, infoPort=41354, infoSecurePort=0, ipcPort=36043, storageInfo=lv=-57;cid=testClusterID;nsid=872050423;c=1606980155306), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:41,110 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x14bc2b416842452d: Processing first storage report for DS-f37d1a87-7be4-40de-ad34-60a5fad513e2 from datanode f11e5127-b51f-4a84-b875-807607aa34a6
2020-12-03 07:22:41,111 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x14bc2b416842452d: from storage DS-f37d1a87-7be4-40de-ad34-60a5fad513e2 node DatanodeRegistration(127.0.0.1:45386, datanodeUuid=f11e5127-b51f-4a84-b875-807607aa34a6, infoPort=42525, infoSecurePort=0, ipcPort=33906, storageInfo=lv=-57;cid=testClusterID;nsid=872050423;c=1606980155306), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:41,111 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x31710f976957127c: Processing first storage report for DS-05ad14d3-6743-431b-89ed-3742b183502a from datanode 8c91dbe3-abfe-4c89-9b41-cb13db08eba0
2020-12-03 07:22:41,111 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x31710f976957127c: from storage DS-05ad14d3-6743-431b-89ed-3742b183502a node DatanodeRegistration(127.0.0.1:42147, datanodeUuid=8c91dbe3-abfe-4c89-9b41-cb13db08eba0, infoPort=38259, infoSecurePort=0, ipcPort=36393, storageInfo=lv=-57;cid=testClusterID;nsid=872050423;c=1606980155306), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:41,111 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xd10c06aff08e2c94: Processing first storage report for DS-92e8fd76-ed61-46b0-972b-2eb1bdaeedb2 from datanode ebfaef1c-4294-466a-956a-c88ace7fd121
2020-12-03 07:22:41,111 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xd10c06aff08e2c94: from storage DS-92e8fd76-ed61-46b0-972b-2eb1bdaeedb2 node DatanodeRegistration(127.0.0.1:38964, datanodeUuid=ebfaef1c-4294-466a-956a-c88ace7fd121, infoPort=46799, infoSecurePort=0, ipcPort=40410, storageInfo=lv=-57;cid=testClusterID;nsid=872050423;c=1606980155306), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:41,111 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x5e023c43a1024ade: Processing first storage report for DS-8e39d766-2507-4fa6-bfa3-f30fcbfb6361 from datanode 8204a70a-e37a-4db4-a3af-000c4ffdf4f3
2020-12-03 07:22:41,111 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x5e023c43a1024ade: from storage DS-8e39d766-2507-4fa6-bfa3-f30fcbfb6361 node DatanodeRegistration(127.0.0.1:41586, datanodeUuid=8204a70a-e37a-4db4-a3af-000c4ffdf4f3, infoPort=34293, infoSecurePort=0, ipcPort=40964, storageInfo=lv=-57;cid=testClusterID;nsid=872050423;c=1606980155306), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:41,112 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xd9834470ce8f5c91: Processing first storage report for DS-4738ef7e-bb4a-4c3f-bc80-47b226c6d2de from datanode c3e1f354-2020-42cf-ad8e-7a6090792910
2020-12-03 07:22:41,112 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xd9834470ce8f5c91: from storage DS-4738ef7e-bb4a-4c3f-bc80-47b226c6d2de node DatanodeRegistration(127.0.0.1:46157, datanodeUuid=c3e1f354-2020-42cf-ad8e-7a6090792910, infoPort=42565, infoSecurePort=0, ipcPort=34197, storageInfo=lv=-57;cid=testClusterID;nsid=872050423;c=1606980155306), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:41,112 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x964cecf35d914534: Processing first storage report for DS-f0f0e850-b5f4-4644-b56c-a705ab62e451 from datanode 001b4761-f836-4ea2-9f52-478db0422ff2
2020-12-03 07:22:41,112 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x964cecf35d914534: from storage DS-f0f0e850-b5f4-4644-b56c-a705ab62e451 node DatanodeRegistration(127.0.0.1:40234, datanodeUuid=001b4761-f836-4ea2-9f52-478db0422ff2, infoPort=41354, infoSecurePort=0, ipcPort=36043, storageInfo=lv=-57;cid=testClusterID;nsid=872050423;c=1606980155306), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:41,112 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x14bc2b416842452d: Processing first storage report for DS-1ab59b68-5e90-426a-a8e7-4de5c23f0a5c from datanode f11e5127-b51f-4a84-b875-807607aa34a6
2020-12-03 07:22:41,112 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x14bc2b416842452d: from storage DS-1ab59b68-5e90-426a-a8e7-4de5c23f0a5c node DatanodeRegistration(127.0.0.1:45386, datanodeUuid=f11e5127-b51f-4a84-b875-807607aa34a6, infoPort=42525, infoSecurePort=0, ipcPort=33906, storageInfo=lv=-57;cid=testClusterID;nsid=872050423;c=1606980155306), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:41,112 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x31710f976957127c: Processing first storage report for DS-a7a22227-223b-4d81-b014-9eb36b463dbe from datanode 8c91dbe3-abfe-4c89-9b41-cb13db08eba0
2020-12-03 07:22:41,112 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x31710f976957127c: from storage DS-a7a22227-223b-4d81-b014-9eb36b463dbe node DatanodeRegistration(127.0.0.1:42147, datanodeUuid=8c91dbe3-abfe-4c89-9b41-cb13db08eba0, infoPort=38259, infoSecurePort=0, ipcPort=36393, storageInfo=lv=-57;cid=testClusterID;nsid=872050423;c=1606980155306), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:41,113 [IPC Server handler 4 on default port 36012] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2700)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xd9834470ce8f5c91
2020-12-03 07:22:41,113 [IPC Server handler 2 on default port 36012] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2700)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x964cecf35d914534
2020-12-03 07:22:41,113 [IPC Server handler 3 on default port 36012] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2700)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x14bc2b416842452d
2020-12-03 07:22:41,113 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xd10c06aff08e2c94: Processing first storage report for DS-1a983e4d-ddf3-46b2-91ca-90f4a6e1615f from datanode ebfaef1c-4294-466a-956a-c88ace7fd121
2020-12-03 07:22:41,113 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xd10c06aff08e2c94: from storage DS-1a983e4d-ddf3-46b2-91ca-90f4a6e1615f node DatanodeRegistration(127.0.0.1:38964, datanodeUuid=ebfaef1c-4294-466a-956a-c88ace7fd121, infoPort=46799, infoSecurePort=0, ipcPort=40410, storageInfo=lv=-57;cid=testClusterID;nsid=872050423;c=1606980155306), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:41,114 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x5e023c43a1024ade: Processing first storage report for DS-ed5b1af2-4d6a-44cc-8f44-ea6a996fecca from datanode 8204a70a-e37a-4db4-a3af-000c4ffdf4f3
2020-12-03 07:22:41,114 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x5e023c43a1024ade: from storage DS-ed5b1af2-4d6a-44cc-8f44-ea6a996fecca node DatanodeRegistration(127.0.0.1:41586, datanodeUuid=8204a70a-e37a-4db4-a3af-000c4ffdf4f3, infoPort=34293, infoSecurePort=0, ipcPort=40964, storageInfo=lv=-57;cid=testClusterID;nsid=872050423;c=1606980155306), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:41,114 [IPC Server handler 8 on default port 36012] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2700)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x31710f976957127c
2020-12-03 07:22:41,114 [IPC Server handler 0 on default port 36012] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2700)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xd10c06aff08e2c94
2020-12-03 07:22:41,114 [IPC Server handler 5 on default port 36012] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2700)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x5e023c43a1024ade
2020-12-03 07:22:41,135 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x5e023c43a1024ade,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 6 msec to generate and 47 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:41,135 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x31710f976957127c,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 47 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:41,135 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x964cecf35d914534,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 47 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:41,135 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x14bc2b416842452d,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 6 msec to generate and 48 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:41,135 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xd9834470ce8f5c91,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 6 msec to generate and 48 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:41,135 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xd10c06aff08e2c94,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 6 msec to generate and 48 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:41,136 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:41,136 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:41,136 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:41,136 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:41,135 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:41,136 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:41,142 [Thread-238] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID e381e65a-d500-4d88-9fe7-9fef9ef1ca50
2020-12-03 07:22:41,145 [Thread-238] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-8003d045-1e99-412a-8cb9-6c5a540f201c
2020-12-03 07:22:41,146 [Thread-238] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, StorageType: DISK
2020-12-03 07:22:41,147 [Thread-238] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-2de1543c-c1ec-4bd6-91e0-70fe2d9c1268
2020-12-03 07:22:41,148 [Thread-238] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, StorageType: DISK
2020-12-03 07:22:41,148 [Thread-238] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:22:41,149 [Thread-238] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:22:41,150 [Thread-238] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:22:41,150 [Thread-238] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:22:41,150 [Thread-238] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:22:41,151 [Thread-238] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:41,151 [Thread-365] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17...
2020-12-03 07:22:41,151 [Thread-366] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18...
2020-12-03 07:22:41,157 [IPC Server handler 7 on default port 36012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:41,159 [Listener at localhost/38093] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:41,159 [Listener at localhost/38093] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:41,196 [Thread-365] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1542479078-172.17.0.8-1606980155306 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17: 45ms
2020-12-03 07:22:41,196 [Thread-366] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1542479078-172.17.0.8-1606980155306 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18: 45ms
2020-12-03 07:22:41,196 [Thread-238] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1542479078-172.17.0.8-1606980155306: 45ms
2020-12-03 07:22:41,197 [Thread-369] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17...
2020-12-03 07:22:41,197 [Thread-370] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18...
2020-12-03 07:22:41,197 [Thread-369] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1542479078-172.17.0.8-1606980155306/current/replicas doesn't exist 
2020-12-03 07:22:41,197 [Thread-370] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1542479078-172.17.0.8-1606980155306/current/replicas doesn't exist 
2020-12-03 07:22:41,197 [Thread-369] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17: 0ms
2020-12-03 07:22:41,198 [Thread-260] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 2778076c-5f6e-47a7-889f-fd644454ad1c
2020-12-03 07:22:41,198 [Thread-370] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18: 1ms
2020-12-03 07:22:41,198 [Thread-238] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1542479078-172.17.0.8-1606980155306: 3ms
2020-12-03 07:22:41,199 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:22:41,199 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:22:41,199 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-2de1543c-c1ec-4bd6-91e0-70fe2d9c1268): finished scanning block pool BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:41,199 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-8003d045-1e99-412a-8cb9-6c5a540f201c): finished scanning block pool BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:41,199 [Thread-238] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 8:53 AM with interval of 21600000ms
2020-12-03 07:22:41,200 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-2de1543c-c1ec-4bd6-91e0-70fe2d9c1268): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:22:41,200 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-8003d045-1e99-412a-8cb9-6c5a540f201c): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:22:41,201 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1542479078-172.17.0.8-1606980155306 (Datanode Uuid e381e65a-d500-4d88-9fe7-9fef9ef1ca50) service to localhost/127.0.0.1:36012 beginning handshake with NN
2020-12-03 07:22:41,203 [IPC Server handler 9 on default port 36012] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:45017, datanodeUuid=e381e65a-d500-4d88-9fe7-9fef9ef1ca50, infoPort=41292, infoSecurePort=0, ipcPort=40844, storageInfo=lv=-57;cid=testClusterID;nsid=872050423;c=1606980155306) storage e381e65a-d500-4d88-9fe7-9fef9ef1ca50
2020-12-03 07:22:41,203 [Thread-260] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-a1467a89-1c19-458e-aaea-444c4edcbb62
2020-12-03 07:22:41,204 [Thread-260] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19, StorageType: DISK
2020-12-03 07:22:41,204 [IPC Server handler 9 on default port 36012] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /r5/127.0.0.1:45017
2020-12-03 07:22:41,204 [IPC Server handler 9 on default port 36012] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN e381e65a-d500-4d88-9fe7-9fef9ef1ca50 (127.0.0.1:45017).
2020-12-03 07:22:41,205 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1542479078-172.17.0.8-1606980155306 (Datanode Uuid e381e65a-d500-4d88-9fe7-9fef9ef1ca50) service to localhost/127.0.0.1:36012 successfully registered with NN
2020-12-03 07:22:41,205 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:36012 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:22:41,206 [Thread-260] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-d2c1ad45-6699-44ec-91c4-683f480b3a5c
2020-12-03 07:22:41,207 [Thread-260] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20, StorageType: DISK
2020-12-03 07:22:41,211 [Thread-260] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:22:41,212 [IPC Server handler 1 on default port 36012] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-8003d045-1e99-412a-8cb9-6c5a540f201c for DN 127.0.0.1:45017
2020-12-03 07:22:41,212 [IPC Server handler 1 on default port 36012] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-2de1543c-c1ec-4bd6-91e0-70fe2d9c1268 for DN 127.0.0.1:45017
2020-12-03 07:22:41,284 [Thread-260] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19
2020-12-03 07:22:41,285 [Thread-260] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19
2020-12-03 07:22:41,288 [Thread-260] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20
2020-12-03 07:22:41,293 [Thread-260] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20
2020-12-03 07:22:41,295 [IPC Server handler 6 on default port 36012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:41,299 [Thread-260] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:41,300 [Thread-376] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19...
2020-12-03 07:22:41,300 [Thread-377] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20...
2020-12-03 07:22:41,302 [Listener at localhost/38093] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:41,302 [Listener at localhost/38093] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:41,303 [IPC Server handler 2 on default port 36012] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1566)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:45017, datanodeUuid=e381e65a-d500-4d88-9fe7-9fef9ef1ca50, infoPort=41292, infoSecurePort=0, ipcPort=40844, storageInfo=lv=-57;cid=testClusterID;nsid=872050423;c=1606980155306), reports.length=2
2020-12-03 07:22:41,303 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xecf14673b22300b7: Processing first storage report for DS-8003d045-1e99-412a-8cb9-6c5a540f201c from datanode e381e65a-d500-4d88-9fe7-9fef9ef1ca50
2020-12-03 07:22:41,303 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xecf14673b22300b7: from storage DS-8003d045-1e99-412a-8cb9-6c5a540f201c node DatanodeRegistration(127.0.0.1:45017, datanodeUuid=e381e65a-d500-4d88-9fe7-9fef9ef1ca50, infoPort=41292, infoSecurePort=0, ipcPort=40844, storageInfo=lv=-57;cid=testClusterID;nsid=872050423;c=1606980155306), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:41,303 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xecf14673b22300b7: Processing first storage report for DS-2de1543c-c1ec-4bd6-91e0-70fe2d9c1268 from datanode e381e65a-d500-4d88-9fe7-9fef9ef1ca50
2020-12-03 07:22:41,303 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xecf14673b22300b7: from storage DS-2de1543c-c1ec-4bd6-91e0-70fe2d9c1268 node DatanodeRegistration(127.0.0.1:45017, datanodeUuid=e381e65a-d500-4d88-9fe7-9fef9ef1ca50, infoPort=41292, infoSecurePort=0, ipcPort=40844, storageInfo=lv=-57;cid=testClusterID;nsid=872050423;c=1606980155306), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:41,303 [IPC Server handler 2 on default port 36012] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2700)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xecf14673b22300b7
2020-12-03 07:22:41,304 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xecf14673b22300b7,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 4 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:41,304 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:41,333 [Thread-376] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1542479078-172.17.0.8-1606980155306 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19: 33ms
2020-12-03 07:22:41,337 [Thread-377] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1542479078-172.17.0.8-1606980155306 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20: 37ms
2020-12-03 07:22:41,337 [Thread-260] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1542479078-172.17.0.8-1606980155306: 37ms
2020-12-03 07:22:41,338 [Thread-380] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19...
2020-12-03 07:22:41,338 [Thread-380] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19/current/BP-1542479078-172.17.0.8-1606980155306/current/replicas doesn't exist 
2020-12-03 07:22:41,338 [Thread-381] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20...
2020-12-03 07:22:41,339 [Thread-381] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20/current/BP-1542479078-172.17.0.8-1606980155306/current/replicas doesn't exist 
2020-12-03 07:22:41,339 [Thread-381] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20: 0ms
2020-12-03 07:22:41,339 [Thread-380] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19: 1ms
2020-12-03 07:22:41,343 [Thread-260] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1542479078-172.17.0.8-1606980155306: 6ms
2020-12-03 07:22:41,343 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19
2020-12-03 07:22:41,343 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20
2020-12-03 07:22:41,343 [Thread-260] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 8:55 AM with interval of 21600000ms
2020-12-03 07:22:41,343 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19, DS-a1467a89-1c19-458e-aaea-444c4edcbb62): finished scanning block pool BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:41,344 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20, DS-d2c1ad45-6699-44ec-91c4-683f480b3a5c): finished scanning block pool BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:41,345 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1542479078-172.17.0.8-1606980155306 (Datanode Uuid 2778076c-5f6e-47a7-889f-fd644454ad1c) service to localhost/127.0.0.1:36012 beginning handshake with NN
2020-12-03 07:22:41,345 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19, DS-a1467a89-1c19-458e-aaea-444c4edcbb62): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-12-03 07:22:41,345 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20, DS-d2c1ad45-6699-44ec-91c4-683f480b3a5c): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-12-03 07:22:41,346 [IPC Server handler 3 on default port 36012] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:40901, datanodeUuid=2778076c-5f6e-47a7-889f-fd644454ad1c, infoPort=44954, infoSecurePort=0, ipcPort=38093, storageInfo=lv=-57;cid=testClusterID;nsid=872050423;c=1606980155306) storage 2778076c-5f6e-47a7-889f-fd644454ad1c
2020-12-03 07:22:41,346 [IPC Server handler 3 on default port 36012] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /r6/127.0.0.1:40901
2020-12-03 07:22:41,346 [IPC Server handler 3 on default port 36012] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 2778076c-5f6e-47a7-889f-fd644454ad1c (127.0.0.1:40901).
2020-12-03 07:22:41,347 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1542479078-172.17.0.8-1606980155306 (Datanode Uuid 2778076c-5f6e-47a7-889f-fd644454ad1c) service to localhost/127.0.0.1:36012 successfully registered with NN
2020-12-03 07:22:41,348 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:36012 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:22:41,350 [IPC Server handler 5 on default port 36012] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-a1467a89-1c19-458e-aaea-444c4edcbb62 for DN 127.0.0.1:40901
2020-12-03 07:22:41,350 [IPC Server handler 5 on default port 36012] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d2c1ad45-6699-44ec-91c4-683f480b3a5c for DN 127.0.0.1:40901
2020-12-03 07:22:41,351 [IPC Server handler 0 on default port 36012] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1566)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:40901, datanodeUuid=2778076c-5f6e-47a7-889f-fd644454ad1c, infoPort=44954, infoSecurePort=0, ipcPort=38093, storageInfo=lv=-57;cid=testClusterID;nsid=872050423;c=1606980155306), reports.length=2
2020-12-03 07:22:41,352 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x88aff387be6bf6d: Processing first storage report for DS-d2c1ad45-6699-44ec-91c4-683f480b3a5c from datanode 2778076c-5f6e-47a7-889f-fd644454ad1c
2020-12-03 07:22:41,352 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x88aff387be6bf6d: from storage DS-d2c1ad45-6699-44ec-91c4-683f480b3a5c node DatanodeRegistration(127.0.0.1:40901, datanodeUuid=2778076c-5f6e-47a7-889f-fd644454ad1c, infoPort=44954, infoSecurePort=0, ipcPort=38093, storageInfo=lv=-57;cid=testClusterID;nsid=872050423;c=1606980155306), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:41,352 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x88aff387be6bf6d: Processing first storage report for DS-a1467a89-1c19-458e-aaea-444c4edcbb62 from datanode 2778076c-5f6e-47a7-889f-fd644454ad1c
2020-12-03 07:22:41,352 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x88aff387be6bf6d: from storage DS-a1467a89-1c19-458e-aaea-444c4edcbb62 node DatanodeRegistration(127.0.0.1:40901, datanodeUuid=2778076c-5f6e-47a7-889f-fd644454ad1c, infoPort=44954, infoSecurePort=0, ipcPort=38093, storageInfo=lv=-57;cid=testClusterID;nsid=872050423;c=1606980155306), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:41,352 [IPC Server handler 0 on default port 36012] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2700)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x88aff387be6bf6d
2020-12-03 07:22:41,353 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x88aff387be6bf6d,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:41,353 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:41,404 [IPC Server handler 8 on default port 36012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:41,408 [Listener at localhost/38093] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:22:41,415 [IPC Server handler 4 on default port 36012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:41,416 [Listener at localhost/38093] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:22:41,426 [IPC Server handler 7 on default port 36012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=enableErasureCodingPolicy	src=RS-6-3-1024k	dst=null	perm=null	proto=rpc
2020-12-03 07:22:41,454 [IPC Server handler 9 on default port 36012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setErasureCodingPolicy	src=/	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:22:41,460 [Listener at localhost/38093] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopDataNode(2331)) - MiniDFSCluster Stopping DataNode host10:40901 from a total of 10 datanodes.
2020-12-03 07:22:41,460 [Listener at localhost/38093] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:22:41,460 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@199e4c2b] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:22:41,462 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19, DS-a1467a89-1c19-458e-aaea-444c4edcbb62) exiting.
2020-12-03 07:22:41,462 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20, DS-d2c1ad45-6699-44ec-91c4-683f480b3a5c) exiting.
2020-12-03 07:22:41,485 [Listener at localhost/38093] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@3773862a{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:22:41,490 [Listener at localhost/38093] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2472c7d8{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:41,490 [Listener at localhost/38093] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@251ebf23{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:41,490 [Listener at localhost/38093] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@b273a59{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:41,493 [Listener at localhost/38093] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 38093
2020-12-03 07:22:41,498 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:41,500 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:41,501 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:41,501 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1542479078-172.17.0.8-1606980155306 (Datanode Uuid 2778076c-5f6e-47a7-889f-fd644454ad1c) service to localhost/127.0.0.1:36012
2020-12-03 07:22:41,502 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1542479078-172.17.0.8-1606980155306 (Datanode Uuid 2778076c-5f6e-47a7-889f-fd644454ad1c)
2020-12-03 07:22:41,502 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:41,502 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19/current/BP-1542479078-172.17.0.8-1606980155306] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:41,502 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20/current/BP-1542479078-172.17.0.8-1606980155306] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:41,506 [Listener at localhost/38093] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:22:41,506 [Listener at localhost/38093] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:22:41,507 [Listener at localhost/38093] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:22:41,507 [Listener at localhost/38093] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:22:41,513 [Listener at localhost/38093] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:22:41,515 [Listener at localhost/38093] INFO  hdfs.StateChange (DatanodeManager.java:removeDeadDatanode(754)) - BLOCK* removeDeadDatanode: lost heartbeat from 127.0.0.1:40901, removeBlocksFromBlockMap true
2020-12-03 07:22:41,516 [Listener at localhost/38093] INFO  net.NetworkTopology (NetworkTopology.java:remove(219)) - Removing a node: /r6/127.0.0.1:40901
2020-12-03 07:22:41,517 [Listener at localhost/38093] INFO  blockmanagement.TestReconstructStripedBlocksWithRackAwareness (TestReconstructStripedBlocksWithRackAwareness.java:stopDataNode(120)) - stop datanode host10
2020-12-03 07:22:41,523 [IPC Server handler 1 on default port 36012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:22:41,560 [IPC Server handler 6 on default port 36012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/foo	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:22:41,620 [IPC Server handler 2 on default port 36012] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(427)) - storageTypes={DISK=9}
2020-12-03 07:22:41,622 [IPC Server handler 2 on default port 36012] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyRackFaultTolerant.java:chooseTargetInOrder(135)) - Chosen nodes: [[DISK]DS-8003d045-1e99-412a-8cb9-6c5a540f201c:NORMAL:127.0.0.1:45017, [DISK]DS-f37d1a87-7be4-40de-ad34-60a5fad513e2:NORMAL:127.0.0.1:45386, [DISK]DS-92e8fd76-ed61-46b0-972b-2eb1bdaeedb2:NORMAL:127.0.0.1:38964, [DISK]DS-ddcf86b6-f4e7-4e7e-b776-8c3ecf9168cb:NORMAL:127.0.0.1:39491, [DISK]DS-56d51eb8-96f6-40a8-96a0-dc3a49d00c78:NORMAL:127.0.0.1:40234]
2020-12-03 07:22:41,622 [IPC Server handler 2 on default port 36012] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyRackFaultTolerant.java:chooseTargetInOrder(136)) - Excluded nodes: [127.0.0.1:40234, 127.0.0.1:45017, 127.0.0.1:38964, 127.0.0.1:45386, 127.0.0.1:39491]
2020-12-03 07:22:41,623 [IPC Server handler 2 on default port 36012] DEBUG blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseLocalRack(655)) - Failed to choose from local rack (location = /r5), retry with the rack of the next replica (location = /r3)
org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy$NotEnoughReplicasException: 
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRandom(BlockPlacementPolicyDefault.java:852)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRandom(BlockPlacementPolicyDefault.java:740)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseLocalRack(BlockPlacementPolicyDefault.java:647)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseLocalStorage(BlockPlacementPolicyDefault.java:607)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyRackFaultTolerant.chooseOnce(BlockPlacementPolicyRackFaultTolerant.java:218)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyRackFaultTolerant.chooseTargetInOrder(BlockPlacementPolicyRackFaultTolerant.java:139)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:437)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:309)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:149)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:174)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2211)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2789)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:892)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:574)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
2020-12-03 07:22:41,629 [IPC Server handler 2 on default port 36012] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_-9223372036854775792_1001, replicas=127.0.0.1:45017, 127.0.0.1:45386, 127.0.0.1:41586, 127.0.0.1:39491, 127.0.0.1:46157, 127.0.0.1:38964, 127.0.0.1:42147, 127.0.0.1:39617, 127.0.0.1:40234 for /foo
2020-12-03 07:22:41,676 [Thread-385] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:41,702 [Thread-386] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:41,716 [Thread-387] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:41,731 [Thread-388] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:41,749 [Thread-389] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:41,761 [Thread-390] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:41,781 [DataXceiver for client DFSClient_NONMAPREDUCE_2109196941_1 at /127.0.0.1:38118 [Receiving block BP-1542479078-172.17.0.8-1606980155306:blk_-9223372036854775789_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1542479078-172.17.0.8-1606980155306:blk_-9223372036854775789_1001 src: /127.0.0.1:38118 dest: /127.0.0.1:39491
2020-12-03 07:22:41,782 [DataXceiver for client DFSClient_NONMAPREDUCE_2109196941_1 at /127.0.0.1:44402 [Receiving block BP-1542479078-172.17.0.8-1606980155306:blk_-9223372036854775790_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1542479078-172.17.0.8-1606980155306:blk_-9223372036854775790_1001 src: /127.0.0.1:44402 dest: /127.0.0.1:41586
2020-12-03 07:22:41,782 [DataXceiver for client DFSClient_NONMAPREDUCE_2109196941_1 at /127.0.0.1:60558 [Receiving block BP-1542479078-172.17.0.8-1606980155306:blk_-9223372036854775788_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1542479078-172.17.0.8-1606980155306:blk_-9223372036854775788_1001 src: /127.0.0.1:60558 dest: /127.0.0.1:46157
2020-12-03 07:22:41,784 [DataXceiver for client DFSClient_NONMAPREDUCE_2109196941_1 at /127.0.0.1:34822 [Receiving block BP-1542479078-172.17.0.8-1606980155306:blk_-9223372036854775791_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1542479078-172.17.0.8-1606980155306:blk_-9223372036854775791_1001 src: /127.0.0.1:34822 dest: /127.0.0.1:45386
2020-12-03 07:22:41,785 [DataXceiver for client DFSClient_NONMAPREDUCE_2109196941_1 at /127.0.0.1:47892 [Receiving block BP-1542479078-172.17.0.8-1606980155306:blk_-9223372036854775792_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1542479078-172.17.0.8-1606980155306:blk_-9223372036854775792_1001 src: /127.0.0.1:47892 dest: /127.0.0.1:45017
2020-12-03 07:22:41,785 [DataXceiver for client DFSClient_NONMAPREDUCE_2109196941_1 at /127.0.0.1:46730 [Receiving block BP-1542479078-172.17.0.8-1606980155306:blk_-9223372036854775787_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1542479078-172.17.0.8-1606980155306:blk_-9223372036854775787_1001 src: /127.0.0.1:46730 dest: /127.0.0.1:38964
2020-12-03 07:22:41,797 [Thread-391] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:41,799 [DataXceiver for client DFSClient_NONMAPREDUCE_2109196941_1 at /127.0.0.1:59198 [Receiving block BP-1542479078-172.17.0.8-1606980155306:blk_-9223372036854775786_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1542479078-172.17.0.8-1606980155306:blk_-9223372036854775786_1001 src: /127.0.0.1:59198 dest: /127.0.0.1:42147
2020-12-03 07:22:41,827 [Thread-392] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:41,830 [DataXceiver for client DFSClient_NONMAPREDUCE_2109196941_1 at /127.0.0.1:40374 [Receiving block BP-1542479078-172.17.0.8-1606980155306:blk_-9223372036854775785_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1542479078-172.17.0.8-1606980155306:blk_-9223372036854775785_1001 src: /127.0.0.1:40374 dest: /127.0.0.1:39617
2020-12-03 07:22:41,836 [Thread-393] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:41,840 [DataXceiver for client DFSClient_NONMAPREDUCE_2109196941_1 at /127.0.0.1:43660 [Receiving block BP-1542479078-172.17.0.8-1606980155306:blk_-9223372036854775784_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1542479078-172.17.0.8-1606980155306:blk_-9223372036854775784_1001 src: /127.0.0.1:43660 dest: /127.0.0.1:40234
2020-12-03 07:22:41,848 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1998)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-12-03 07:22:42,071 [PacketResponder: BP-1542479078-172.17.0.8-1606980155306:blk_-9223372036854775792_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:47892, dest: /127.0.0.1:45017, bytes: 2097152, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2109196941_1, offset: 0, srvID: e381e65a-d500-4d88-9fe7-9fef9ef1ca50, blockid: BP-1542479078-172.17.0.8-1606980155306:blk_-9223372036854775792_1001, duration(ns): 220891485
2020-12-03 07:22:42,072 [PacketResponder: BP-1542479078-172.17.0.8-1606980155306:blk_-9223372036854775792_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1542479078-172.17.0.8-1606980155306:blk_-9223372036854775792_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:22:42,078 [PacketResponder: BP-1542479078-172.17.0.8-1606980155306:blk_-9223372036854775791_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:34822, dest: /127.0.0.1:45386, bytes: 2097152, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2109196941_1, offset: 0, srvID: f11e5127-b51f-4a84-b875-807607aa34a6, blockid: BP-1542479078-172.17.0.8-1606980155306:blk_-9223372036854775791_1001, duration(ns): 236445198
2020-12-03 07:22:42,079 [PacketResponder: BP-1542479078-172.17.0.8-1606980155306:blk_-9223372036854775791_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1542479078-172.17.0.8-1606980155306:blk_-9223372036854775791_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:22:42,085 [PacketResponder: BP-1542479078-172.17.0.8-1606980155306:blk_-9223372036854775790_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:44402, dest: /127.0.0.1:41586, bytes: 2097152, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2109196941_1, offset: 0, srvID: 8204a70a-e37a-4db4-a3af-000c4ffdf4f3, blockid: BP-1542479078-172.17.0.8-1606980155306:blk_-9223372036854775790_1001, duration(ns): 244243870
2020-12-03 07:22:42,086 [PacketResponder: BP-1542479078-172.17.0.8-1606980155306:blk_-9223372036854775790_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1542479078-172.17.0.8-1606980155306:blk_-9223372036854775790_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:22:42,092 [PacketResponder: BP-1542479078-172.17.0.8-1606980155306:blk_-9223372036854775789_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38118, dest: /127.0.0.1:39491, bytes: 2097152, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2109196941_1, offset: 0, srvID: 34ff7519-927c-4ea8-9154-f544635bdcd4, blockid: BP-1542479078-172.17.0.8-1606980155306:blk_-9223372036854775789_1001, duration(ns): 245125968
2020-12-03 07:22:42,092 [PacketResponder: BP-1542479078-172.17.0.8-1606980155306:blk_-9223372036854775789_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1542479078-172.17.0.8-1606980155306:blk_-9223372036854775789_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:22:42,099 [PacketResponder: BP-1542479078-172.17.0.8-1606980155306:blk_-9223372036854775788_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60558, dest: /127.0.0.1:46157, bytes: 2097152, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2109196941_1, offset: 0, srvID: c3e1f354-2020-42cf-ad8e-7a6090792910, blockid: BP-1542479078-172.17.0.8-1606980155306:blk_-9223372036854775788_1001, duration(ns): 256813968
2020-12-03 07:22:42,099 [PacketResponder: BP-1542479078-172.17.0.8-1606980155306:blk_-9223372036854775788_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1542479078-172.17.0.8-1606980155306:blk_-9223372036854775788_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:22:42,107 [PacketResponder: BP-1542479078-172.17.0.8-1606980155306:blk_-9223372036854775787_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:46730, dest: /127.0.0.1:38964, bytes: 2097152, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2109196941_1, offset: 0, srvID: ebfaef1c-4294-466a-956a-c88ace7fd121, blockid: BP-1542479078-172.17.0.8-1606980155306:blk_-9223372036854775787_1001, duration(ns): 264659216
2020-12-03 07:22:42,107 [PacketResponder: BP-1542479078-172.17.0.8-1606980155306:blk_-9223372036854775787_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1542479078-172.17.0.8-1606980155306:blk_-9223372036854775787_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:22:42,115 [IPC Server handler 8 on default port 36012] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1627)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:39491, datanodeUuid=34ff7519-927c-4ea8-9154-f544635bdcd4, infoPort=34327, infoSecurePort=0, ipcPort=46347, storageInfo=lv=-57;cid=testClusterID;nsid=872050423;c=1606980155306) 1 blocks.
2020-12-03 07:22:42,115 [IPC Server handler 7 on default port 36012] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1627)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:46157, datanodeUuid=c3e1f354-2020-42cf-ad8e-7a6090792910, infoPort=42565, infoSecurePort=0, ipcPort=34197, storageInfo=lv=-57;cid=testClusterID;nsid=872050423;c=1606980155306) 1 blocks.
2020-12-03 07:22:42,115 [IPC Server handler 5 on default port 36012] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1627)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:45386, datanodeUuid=f11e5127-b51f-4a84-b875-807607aa34a6, infoPort=42525, infoSecurePort=0, ipcPort=33906, storageInfo=lv=-57;cid=testClusterID;nsid=872050423;c=1606980155306) 1 blocks.
2020-12-03 07:22:42,115 [IPC Server handler 0 on default port 36012] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1627)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:38964, datanodeUuid=ebfaef1c-4294-466a-956a-c88ace7fd121, infoPort=46799, infoSecurePort=0, ipcPort=40410, storageInfo=lv=-57;cid=testClusterID;nsid=872050423;c=1606980155306) 1 blocks.
2020-12-03 07:22:42,115 [IPC Server handler 4 on default port 36012] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1627)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:45017, datanodeUuid=e381e65a-d500-4d88-9fe7-9fef9ef1ca50, infoPort=41292, infoSecurePort=0, ipcPort=40844, storageInfo=lv=-57;cid=testClusterID;nsid=872050423;c=1606980155306) 1 blocks.
2020-12-03 07:22:42,115 [IPC Server handler 9 on default port 36012] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1627)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:41586, datanodeUuid=8204a70a-e37a-4db4-a3af-000c4ffdf4f3, infoPort=34293, infoSecurePort=0, ipcPort=40964, storageInfo=lv=-57;cid=testClusterID;nsid=872050423;c=1606980155306) 1 blocks.
2020-12-03 07:22:42,116 [PacketResponder: BP-1542479078-172.17.0.8-1606980155306:blk_-9223372036854775786_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59198, dest: /127.0.0.1:42147, bytes: 2097152, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2109196941_1, offset: 0, srvID: 8c91dbe3-abfe-4c89-9b41-cb13db08eba0, blockid: BP-1542479078-172.17.0.8-1606980155306:blk_-9223372036854775786_1001, duration(ns): 274300728
2020-12-03 07:22:42,117 [PacketResponder: BP-1542479078-172.17.0.8-1606980155306:blk_-9223372036854775786_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1542479078-172.17.0.8-1606980155306:blk_-9223372036854775786_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:22:42,119 [IPC Server handler 1 on default port 36012] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1627)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:42147, datanodeUuid=8c91dbe3-abfe-4c89-9b41-cb13db08eba0, infoPort=38259, infoSecurePort=0, ipcPort=36393, storageInfo=lv=-57;cid=testClusterID;nsid=872050423;c=1606980155306) 1 blocks.
2020-12-03 07:22:42,120 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4021)) - Reported block blk_-9223372036854775791_1001 on 127.0.0.1:45386 size 2097152 replicaState = FINALIZED
2020-12-03 07:22:42,121 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4044)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-12-03 07:22:42,121 [PacketResponder: BP-1542479078-172.17.0.8-1606980155306:blk_-9223372036854775785_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40374, dest: /127.0.0.1:39617, bytes: 2097152, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2109196941_1, offset: 0, srvID: d5b3f975-4d17-4d98-968c-975d03e85a9a, blockid: BP-1542479078-172.17.0.8-1606980155306:blk_-9223372036854775785_1001, duration(ns): 271193782
2020-12-03 07:22:42,121 [PacketResponder: BP-1542479078-172.17.0.8-1606980155306:blk_-9223372036854775785_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1542479078-172.17.0.8-1606980155306:blk_-9223372036854775785_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:22:42,126 [IPC Server handler 6 on default port 36012] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1627)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:39617, datanodeUuid=d5b3f975-4d17-4d98-968c-975d03e85a9a, infoPort=46795, infoSecurePort=0, ipcPort=35265, storageInfo=lv=-57;cid=testClusterID;nsid=872050423;c=1606980155306) 1 blocks.
2020-12-03 07:22:42,131 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3351)) - BLOCK* addStoredBlock: 127.0.0.1:45386 is added to blk_-9223372036854775792_1001 (size=0)
2020-12-03 07:22:42,133 [PacketResponder: BP-1542479078-172.17.0.8-1606980155306:blk_-9223372036854775784_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:43660, dest: /127.0.0.1:40234, bytes: 2097152, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2109196941_1, offset: 0, srvID: 001b4761-f836-4ea2-9f52-478db0422ff2, blockid: BP-1542479078-172.17.0.8-1606980155306:blk_-9223372036854775784_1001, duration(ns): 283122237
2020-12-03 07:22:42,133 [PacketResponder: BP-1542479078-172.17.0.8-1606980155306:blk_-9223372036854775784_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1542479078-172.17.0.8-1606980155306:blk_-9223372036854775784_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:22:42,134 [IPC Server handler 2 on default port 36012] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1627)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:40234, datanodeUuid=001b4761-f836-4ea2-9f52-478db0422ff2, infoPort=41354, infoSecurePort=0, ipcPort=36043, storageInfo=lv=-57;cid=testClusterID;nsid=872050423;c=1606980155306) 1 blocks.
2020-12-03 07:22:42,134 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4154)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775791_1001 is received from 127.0.0.1:45386
2020-12-03 07:22:42,134 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4157)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:45386 receiving: 0, received: 1, deleted: 0
2020-12-03 07:22:42,135 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4021)) - Reported block blk_-9223372036854775790_1001 on 127.0.0.1:41586 size 2097152 replicaState = FINALIZED
2020-12-03 07:22:42,135 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4044)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-12-03 07:22:42,135 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3351)) - BLOCK* addStoredBlock: 127.0.0.1:41586 is added to blk_-9223372036854775792_1001 (size=0)
2020-12-03 07:22:42,135 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4154)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775790_1001 is received from 127.0.0.1:41586
2020-12-03 07:22:42,135 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4157)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:41586 receiving: 0, received: 1, deleted: 0
2020-12-03 07:22:42,135 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4021)) - Reported block blk_-9223372036854775787_1001 on 127.0.0.1:38964 size 2097152 replicaState = FINALIZED
2020-12-03 07:22:42,135 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4044)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-12-03 07:22:42,136 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3351)) - BLOCK* addStoredBlock: 127.0.0.1:38964 is added to blk_-9223372036854775792_1001 (size=0)
2020-12-03 07:22:42,136 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4154)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775787_1001 is received from 127.0.0.1:38964
2020-12-03 07:22:42,136 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4157)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:38964 receiving: 0, received: 1, deleted: 0
2020-12-03 07:22:42,136 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4021)) - Reported block blk_-9223372036854775788_1001 on 127.0.0.1:46157 size 2097152 replicaState = FINALIZED
2020-12-03 07:22:42,136 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4044)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-12-03 07:22:42,136 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3351)) - BLOCK* addStoredBlock: 127.0.0.1:46157 is added to blk_-9223372036854775792_1001 (size=0)
2020-12-03 07:22:42,137 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4154)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775788_1001 is received from 127.0.0.1:46157
2020-12-03 07:22:42,137 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4157)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:46157 receiving: 0, received: 1, deleted: 0
2020-12-03 07:22:42,137 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4021)) - Reported block blk_-9223372036854775792_1001 on 127.0.0.1:45017 size 2097152 replicaState = FINALIZED
2020-12-03 07:22:42,137 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4044)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-12-03 07:22:42,137 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3351)) - BLOCK* addStoredBlock: 127.0.0.1:45017 is added to blk_-9223372036854775792_1001 (size=0)
2020-12-03 07:22:42,137 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4154)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775792_1001 is received from 127.0.0.1:45017
2020-12-03 07:22:42,137 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4157)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:45017 receiving: 0, received: 1, deleted: 0
2020-12-03 07:22:42,138 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4021)) - Reported block blk_-9223372036854775789_1001 on 127.0.0.1:39491 size 2097152 replicaState = FINALIZED
2020-12-03 07:22:42,138 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4044)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-12-03 07:22:42,138 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3351)) - BLOCK* addStoredBlock: 127.0.0.1:39491 is added to blk_-9223372036854775792_1001 (size=0)
2020-12-03 07:22:42,138 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4154)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775789_1001 is received from 127.0.0.1:39491
2020-12-03 07:22:42,138 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4157)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:39491 receiving: 0, received: 1, deleted: 0
2020-12-03 07:22:42,138 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4021)) - Reported block blk_-9223372036854775786_1001 on 127.0.0.1:42147 size 2097152 replicaState = FINALIZED
2020-12-03 07:22:42,138 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4044)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-12-03 07:22:42,139 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3351)) - BLOCK* addStoredBlock: 127.0.0.1:42147 is added to blk_-9223372036854775792_1001 (size=0)
2020-12-03 07:22:42,139 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4154)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775786_1001 is received from 127.0.0.1:42147
2020-12-03 07:22:42,139 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4157)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:42147 receiving: 0, received: 1, deleted: 0
2020-12-03 07:22:42,139 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4021)) - Reported block blk_-9223372036854775785_1001 on 127.0.0.1:39617 size 2097152 replicaState = FINALIZED
2020-12-03 07:22:42,139 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4044)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-12-03 07:22:42,139 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3351)) - BLOCK* addStoredBlock: 127.0.0.1:39617 is added to blk_-9223372036854775792_1001 (size=0)
2020-12-03 07:22:42,139 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4154)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775785_1001 is received from 127.0.0.1:39617
2020-12-03 07:22:42,139 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4157)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:39617 receiving: 0, received: 1, deleted: 0
2020-12-03 07:22:42,141 [IPC Server handler 3 on default port 36012] DEBUG BlockStateChange (LowRedundancyBlocks.java:add(293)) - BLOCK* NameSystem.LowRedundancyBlock.add: blk_-9223372036854775792_1001 has only 8 replicas and need 9 replicas so is added to neededReconstructions at priority level 2
2020-12-03 07:22:42,141 [IPC Server handler 3 on default port 36012] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /foo is closed by DFSClient_NONMAPREDUCE_2109196941_1
2020-12-03 07:22:42,141 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4021)) - Reported block blk_-9223372036854775784_1001 on 127.0.0.1:40234 size 2097152 replicaState = FINALIZED
2020-12-03 07:22:42,141 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4044)) - In memory blockUCState = COMPLETE
2020-12-03 07:22:42,142 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3351)) - BLOCK* addStoredBlock: 127.0.0.1:40234 is added to blk_-9223372036854775792_1001 (size=12582912)
2020-12-03 07:22:42,143 [Block report processor] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775792_1001 from priority queue 2
2020-12-03 07:22:42,143 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4154)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775784_1001 is received from 127.0.0.1:40234
2020-12-03 07:22:42,143 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4157)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:40234 receiving: 0, received: 1, deleted: 0
2020-12-03 07:22:42,150 [Listener at localhost/38093] INFO  blockmanagement.TestReconstructStripedBlocksWithRackAwareness (TestReconstructStripedBlocksWithRackAwareness.java:testReconstructForNotEnoughRacks(167)) - Created file /foo
2020-12-03 07:22:42,153 [Listener at localhost/38093] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19
2020-12-03 07:22:42,153 [Listener at localhost/38093] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20
2020-12-03 07:22:42,154 [Listener at localhost/38093] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:22:42,160 [Listener at localhost/38093] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:42,160 [Listener at localhost/38093] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:22:42,161 [Listener at localhost/38093] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is host10
2020-12-03 07:22:42,161 [Listener at localhost/38093] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:42,162 [Listener at localhost/38093] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:22:42,163 [Listener at localhost/38093] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:34862
2020-12-03 07:22:42,163 [Listener at localhost/38093] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:22:42,163 [Listener at localhost/38093] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:22:42,165 [Listener at localhost/38093] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:42,167 [Listener at localhost/38093] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:42,168 [Listener at localhost/38093] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:22:42,169 [Listener at localhost/38093] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:42,171 [Listener at localhost/38093] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:42,172 [Listener at localhost/38093] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:22:42,172 [Listener at localhost/38093] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:42,172 [Listener at localhost/38093] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:42,173 [Listener at localhost/38093] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 44149
2020-12-03 07:22:42,174 [Listener at localhost/38093] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:42,176 [Listener at localhost/38093] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@656d10a4{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:42,177 [Listener at localhost/38093] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3104351d{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:42,182 [Listener at localhost/38093] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@4ae263bf{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:22:42,184 [Listener at localhost/38093] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7103ab0{HTTP/1.1,[http/1.1]}{localhost:44149}
2020-12-03 07:22:42,184 [Listener at localhost/38093] INFO  server.Server (Server.java:doStart(419)) - Started @9053ms
2020-12-03 07:22:42,200 [Listener at localhost/38093] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:41027
2020-12-03 07:22:42,200 [Listener at localhost/38093] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:22:42,200 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@769d513] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:42,200 [Listener at localhost/38093] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:22:42,201 [Listener at localhost/38093] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:42,202 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:42,205 [Listener at localhost/43963] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:43963
2020-12-03 07:22:42,215 [Listener at localhost/43963] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:22:42,216 [Listener at localhost/43963] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:22:42,216 [Thread-433] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36012 starting to offer service
2020-12-03 07:22:42,220 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:42,220 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:42,223 [Thread-433] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36012
2020-12-03 07:22:42,224 [Thread-433] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:42,225 [IPC Server handler 4 on default port 36012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:42,226 [Listener at localhost/43963] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:42,227 [Listener at localhost/43963] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:42,328 [IPC Server handler 7 on default port 36012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:42,330 [Listener at localhost/43963] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:42,330 [Listener at localhost/43963] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:42,357 [Thread-433] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19/in_use.lock acquired by nodename 5051@533329efb28f
2020-12-03 07:22:42,431 [IPC Server handler 9 on default port 36012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:42,433 [Listener at localhost/43963] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:42,433 [Listener at localhost/43963] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:42,536 [IPC Server handler 0 on default port 36012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:42,538 [Listener at localhost/43963] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:42,538 [Listener at localhost/43963] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:42,621 [Thread-433] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20/in_use.lock acquired by nodename 5051@533329efb28f
2020-12-03 07:22:42,640 [IPC Server handler 8 on default port 36012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:42,641 [Listener at localhost/43963] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:42,642 [Listener at localhost/43963] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:42,739 [Thread-433] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:42,739 [Thread-433] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19/current/BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:42,743 [IPC Server handler 1 on default port 36012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:42,746 [Listener at localhost/43963] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:42,746 [Listener at localhost/43963] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:42,847 [IPC Server handler 6 on default port 36012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:42,849 [Listener at localhost/43963] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:42,849 [Listener at localhost/43963] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:42,850 [Thread-433] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:42,850 [Thread-433] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20/current/BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:42,854 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1998)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-12-03 07:22:42,943 [Thread-433] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=872050423;bpid=BP-1542479078-172.17.0.8-1606980155306;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=872050423;c=1606980155306;bpid=BP-1542479078-172.17.0.8-1606980155306;dnuuid=2778076c-5f6e-47a7-889f-fd644454ad1c
2020-12-03 07:22:42,952 [Thread-433] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-a1467a89-1c19-458e-aaea-444c4edcbb62
2020-12-03 07:22:42,954 [Thread-433] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19, StorageType: DISK
2020-12-03 07:22:42,955 [IPC Server handler 2 on default port 36012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:42,956 [Thread-433] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-d2c1ad45-6699-44ec-91c4-683f480b3a5c
2020-12-03 07:22:42,956 [Thread-433] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20, StorageType: DISK
2020-12-03 07:22:42,956 [Thread-433] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:22:42,957 [Listener at localhost/43963] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:42,957 [Listener at localhost/43963] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:42,958 [Thread-433] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19
2020-12-03 07:22:42,960 [Thread-433] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19
2020-12-03 07:22:42,960 [Thread-433] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20
2020-12-03 07:22:42,960 [Thread-433] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20
2020-12-03 07:22:42,961 [Thread-433] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:42,961 [Thread-446] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19...
2020-12-03 07:22:42,961 [Thread-447] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20...
2020-12-03 07:22:42,964 [Thread-447] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20/current/BP-1542479078-172.17.0.8-1606980155306/current: 24576
2020-12-03 07:22:42,964 [Thread-446] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19/current/BP-1542479078-172.17.0.8-1606980155306/current: 24576
2020-12-03 07:22:42,973 [Thread-446] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1542479078-172.17.0.8-1606980155306 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19: 12ms
2020-12-03 07:22:42,973 [Thread-447] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1542479078-172.17.0.8-1606980155306 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20: 12ms
2020-12-03 07:22:42,973 [Thread-433] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1542479078-172.17.0.8-1606980155306: 12ms
2020-12-03 07:22:42,973 [Thread-448] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19...
2020-12-03 07:22:42,973 [Thread-448] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19/current/BP-1542479078-172.17.0.8-1606980155306/current/replicas doesn't exist 
2020-12-03 07:22:42,973 [Thread-449] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20...
2020-12-03 07:22:42,974 [Thread-449] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20/current/BP-1542479078-172.17.0.8-1606980155306/current/replicas doesn't exist 
2020-12-03 07:22:42,974 [Thread-448] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19: 1ms
2020-12-03 07:22:42,974 [Thread-449] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1542479078-172.17.0.8-1606980155306 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20: 0ms
2020-12-03 07:22:42,974 [Thread-433] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1542479078-172.17.0.8-1606980155306: 2ms
2020-12-03 07:22:42,990 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19, DS-a1467a89-1c19-458e-aaea-444c4edcbb62): no suitable block pools found to scan.  Waiting 1814398354 ms.
2020-12-03 07:22:42,990 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20, DS-d2c1ad45-6699-44ec-91c4-683f480b3a5c): no suitable block pools found to scan.  Waiting 1814398353 ms.
2020-12-03 07:22:42,990 [Thread-433] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:32 AM with interval of 21600000ms
2020-12-03 07:22:42,993 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1542479078-172.17.0.8-1606980155306 (Datanode Uuid 2778076c-5f6e-47a7-889f-fd644454ad1c) service to localhost/127.0.0.1:36012 beginning handshake with NN
2020-12-03 07:22:42,994 [IPC Server handler 3 on default port 36012] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34862, datanodeUuid=2778076c-5f6e-47a7-889f-fd644454ad1c, infoPort=41027, infoSecurePort=0, ipcPort=43963, storageInfo=lv=-57;cid=testClusterID;nsid=872050423;c=1606980155306) storage 2778076c-5f6e-47a7-889f-fd644454ad1c
2020-12-03 07:22:42,994 [IPC Server handler 3 on default port 36012] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1078)) - BLOCK* registerDatanode: 127.0.0.1:40901 is replaced by DatanodeRegistration(127.0.0.1:34862, datanodeUuid=2778076c-5f6e-47a7-889f-fd644454ad1c, infoPort=41027, infoSecurePort=0, ipcPort=43963, storageInfo=lv=-57;cid=testClusterID;nsid=872050423;c=1606980155306) with the same storageID 2778076c-5f6e-47a7-889f-fd644454ad1c
2020-12-03 07:22:42,994 [IPC Server handler 3 on default port 36012] INFO  net.NetworkTopology (NetworkTopology.java:remove(219)) - Removing a node: /r6/127.0.0.1:40901
2020-12-03 07:22:42,995 [IPC Server handler 3 on default port 36012] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /r6/127.0.0.1:34862
2020-12-03 07:22:42,995 [IPC Server handler 3 on default port 36012] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateFailedStorage(562)) - [DISK]DS-d2c1ad45-6699-44ec-91c4-683f480b3a5c:NORMAL:127.0.0.1:34862 failed.
2020-12-03 07:22:42,995 [IPC Server handler 3 on default port 36012] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateFailedStorage(562)) - [DISK]DS-a1467a89-1c19-458e-aaea-444c4edcbb62:NORMAL:127.0.0.1:34862 failed.
2020-12-03 07:22:42,995 [IPC Server handler 3 on default port 36012] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:pruneStorageMap(548)) - Removed storage [DISK]DS-d2c1ad45-6699-44ec-91c4-683f480b3a5c:FAILED:127.0.0.1:34862 from DataNode 127.0.0.1:34862
2020-12-03 07:22:42,995 [IPC Server handler 3 on default port 36012] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:pruneStorageMap(548)) - Removed storage [DISK]DS-a1467a89-1c19-458e-aaea-444c4edcbb62:FAILED:127.0.0.1:34862 from DataNode 127.0.0.1:34862
2020-12-03 07:22:42,996 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1542479078-172.17.0.8-1606980155306 (Datanode Uuid 2778076c-5f6e-47a7-889f-fd644454ad1c) service to localhost/127.0.0.1:36012 successfully registered with NN
2020-12-03 07:22:42,996 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:36012 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:22:43,000 [IPC Server handler 5 on default port 36012] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-a1467a89-1c19-458e-aaea-444c4edcbb62 for DN 127.0.0.1:34862
2020-12-03 07:22:43,001 [IPC Server handler 5 on default port 36012] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d2c1ad45-6699-44ec-91c4-683f480b3a5c for DN 127.0.0.1:34862
2020-12-03 07:22:43,002 [IPC Server handler 5 on default port 36012] WARN  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:requestLease(230)) - DN 2778076c-5f6e-47a7-889f-fd644454ad1c (127.0.0.1:34862) requested a lease even though it wasn't yet registered.  Registering now.
2020-12-03 07:22:43,002 [IPC Server handler 5 on default port 36012] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 2778076c-5f6e-47a7-889f-fd644454ad1c (127.0.0.1:34862).
2020-12-03 07:22:43,005 [IPC Server handler 4 on default port 36012] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1566)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:34862, datanodeUuid=2778076c-5f6e-47a7-889f-fd644454ad1c, infoPort=41027, infoSecurePort=0, ipcPort=43963, storageInfo=lv=-57;cid=testClusterID;nsid=872050423;c=1606980155306), reports.length=2
2020-12-03 07:22:43,005 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xdccc3444bd8745e1: Processing first storage report for DS-d2c1ad45-6699-44ec-91c4-683f480b3a5c from datanode 2778076c-5f6e-47a7-889f-fd644454ad1c
2020-12-03 07:22:43,005 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xdccc3444bd8745e1: from storage DS-d2c1ad45-6699-44ec-91c4-683f480b3a5c node DatanodeRegistration(127.0.0.1:34862, datanodeUuid=2778076c-5f6e-47a7-889f-fd644454ad1c, infoPort=41027, infoSecurePort=0, ipcPort=43963, storageInfo=lv=-57;cid=testClusterID;nsid=872050423;c=1606980155306), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:43,005 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xdccc3444bd8745e1: Processing first storage report for DS-a1467a89-1c19-458e-aaea-444c4edcbb62 from datanode 2778076c-5f6e-47a7-889f-fd644454ad1c
2020-12-03 07:22:43,006 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xdccc3444bd8745e1: from storage DS-a1467a89-1c19-458e-aaea-444c4edcbb62 node DatanodeRegistration(127.0.0.1:34862, datanodeUuid=2778076c-5f6e-47a7-889f-fd644454ad1c, infoPort=41027, infoSecurePort=0, ipcPort=43963, storageInfo=lv=-57;cid=testClusterID;nsid=872050423;c=1606980155306), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:43,006 [IPC Server handler 4 on default port 36012] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2700)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xdccc3444bd8745e1
2020-12-03 07:22:43,008 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xdccc3444bd8745e1,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:43,008 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:43,059 [IPC Server handler 7 on default port 36012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:43,061 [Listener at localhost/43963] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:22:43,061 [Listener at localhost/43963] INFO  blockmanagement.TestReconstructStripedBlocksWithRackAwareness (TestReconstructStripedBlocksWithRackAwareness.java:testReconstructForNotEnoughRacks(187)) - topology is: Number of racks: 6
Expected number of leaves:10
/r4/127.0.0.1:40234
/r4/127.0.0.1:39617
/r3/127.0.0.1:45386
/r3/127.0.0.1:41586
/r2/127.0.0.1:38964
/r2/127.0.0.1:42147
/r1/127.0.0.1:39491
/r1/127.0.0.1:46157
/r5/127.0.0.1:45017
/r6/127.0.0.1:34862

2020-12-03 07:22:43,072 [Reconstruction Queue Initializer] DEBUG BlockStateChange (LowRedundancyBlocks.java:add(293)) - BLOCK* NameSystem.LowRedundancyBlock.add: blk_-9223372036854775792_1001 has only 9 replicas and need 9 replicas so is added to neededReconstructions at priority level 3
2020-12-03 07:22:43,072 [Reconstruction Queue Initializer] TRACE blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3551)) - under replicated block blk_-9223372036854775792_1001: UNDER_REPLICATED
2020-12-03 07:22:43,080 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 1
2020-12-03 07:22:43,084 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:22:43,088 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 1
2020-12-03 07:22:43,088 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:22:43,088 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:22:43,088 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 24 msec
2020-12-03 07:22:43,856 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (ErasureCodingWork.java:<init>(47)) - Creating an ErasureCodingWork to blk_-9223372036854775792_1001 reconstruct 
2020-12-03 07:22:43,857 [RedundancyMonitor] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(427)) - storageTypes={DISK=1}
2020-12-03 07:22:43,857 [RedundancyMonitor] DEBUG blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseLocalRack(655)) - Failed to choose from local rack (location = /r5), retry with the rack of the next replica (location = /r3)
org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy$NotEnoughReplicasException: 
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRandom(BlockPlacementPolicyDefault.java:852)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRandom(BlockPlacementPolicyDefault.java:740)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseLocalRack(BlockPlacementPolicyDefault.java:647)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseLocalStorage(BlockPlacementPolicyDefault.java:607)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyRackFaultTolerant.chooseOnce(BlockPlacementPolicyRackFaultTolerant.java:218)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyRackFaultTolerant.chooseTargetInOrder(BlockPlacementPolicyRackFaultTolerant.java:126)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:437)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:309)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:149)
	at org.apache.hadoop.hdfs.server.blockmanagement.ErasureCodingWork.chooseTargets(ErasureCodingWork.java:60)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.computeReconstructionWorkForBlocks(BlockManager.java:1960)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.computeBlockReconstructionWork(BlockManager.java:1912)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.computeDatanodeWork(BlockManager.java:4813)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$RedundancyMonitor.run(BlockManager.java:4680)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:22:43,858 [RedundancyMonitor] DEBUG blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseFromNextRack(687)) - Failed to choose from the next rack (location = /r3), retry choosing randomly
org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy$NotEnoughReplicasException: 
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRandom(BlockPlacementPolicyDefault.java:852)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRandom(BlockPlacementPolicyDefault.java:740)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseFromNextRack(BlockPlacementPolicyDefault.java:683)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseLocalRack(BlockPlacementPolicyDefault.java:659)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseLocalStorage(BlockPlacementPolicyDefault.java:607)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyRackFaultTolerant.chooseOnce(BlockPlacementPolicyRackFaultTolerant.java:218)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyRackFaultTolerant.chooseTargetInOrder(BlockPlacementPolicyRackFaultTolerant.java:126)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:437)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:309)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:149)
	at org.apache.hadoop.hdfs.server.blockmanagement.ErasureCodingWork.chooseTargets(ErasureCodingWork.java:60)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.computeReconstructionWorkForBlocks(BlockManager.java:1960)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.computeBlockReconstructionWork(BlockManager.java:1912)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.computeDatanodeWork(BlockManager.java:4813)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$RedundancyMonitor.run(BlockManager.java:4680)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:22:43,859 [RedundancyMonitor] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyRackFaultTolerant.java:chooseTargetInOrder(135)) - Chosen nodes: [[DISK]DS-8003d045-1e99-412a-8cb9-6c5a540f201c:NORMAL:127.0.0.1:45017, [DISK]DS-f37d1a87-7be4-40de-ad34-60a5fad513e2:NORMAL:127.0.0.1:45386, [DISK]DS-8e39d766-2507-4fa6-bfa3-f30fcbfb6361:NORMAL:127.0.0.1:41586, [DISK]DS-ddcf86b6-f4e7-4e7e-b776-8c3ecf9168cb:NORMAL:127.0.0.1:39491, [DISK]DS-4738ef7e-bb4a-4c3f-bc80-47b226c6d2de:NORMAL:127.0.0.1:46157, [DISK]DS-92e8fd76-ed61-46b0-972b-2eb1bdaeedb2:NORMAL:127.0.0.1:38964, [DISK]DS-05ad14d3-6743-431b-89ed-3742b183502a:NORMAL:127.0.0.1:42147, [DISK]DS-21b99e88-4822-4e4b-a603-4dfda1d22bf8:NORMAL:127.0.0.1:39617, [DISK]DS-f0f0e850-b5f4-4644-b56c-a705ab62e451:NORMAL:127.0.0.1:40234, [DISK]DS-d2c1ad45-6699-44ec-91c4-683f480b3a5c:NORMAL:127.0.0.1:34862]
2020-12-03 07:22:43,859 [RedundancyMonitor] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyRackFaultTolerant.java:chooseTargetInOrder(136)) - Excluded nodes: [127.0.0.1:39617, 127.0.0.1:40234, 127.0.0.1:45017, 127.0.0.1:41586, 127.0.0.1:38964, 127.0.0.1:42147, 127.0.0.1:45386, 127.0.0.1:46157, 127.0.0.1:34862, 127.0.0.1:39491]
2020-12-03 07:22:43,859 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:isInNewRack(2095)) - check if target 127.0.0.1:34862 increases racks, srcs=[127.0.0.1:45017, 127.0.0.1:45386, 127.0.0.1:41586, 127.0.0.1:39491, 127.0.0.1:46157, 127.0.0.1:38964, 127.0.0.1:42147, 127.0.0.1:39617, 127.0.0.1:40234]
2020-12-03 07:22:43,860 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (ErasureCodingWork.java:createReplicationWork(161)) - Add replication task from source 127.0.0.1:45386 to target [DISK]DS-d2c1ad45-6699-44ec-91c4-683f480b3a5c:NORMAL:127.0.0.1:34862 for EC block blk_-9223372036854775791_1001
2020-12-03 07:22:43,860 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:validateReconstructionWork(2152)) - BLOCK* block blk_-9223372036854775792_1001 is moved from neededReconstruction to pendingReconstruction
2020-12-03 07:22:43,861 [RedundancyMonitor] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(376)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775792_1001 from priority queue 3
2020-12-03 07:22:43,861 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1993)) - BLOCK* ask [127.0.0.1:45017, 127.0.0.1:45386, 127.0.0.1:41586, 127.0.0.1:39491, 127.0.0.1:46157, 127.0.0.1:38964, 127.0.0.1:42147, 127.0.0.1:39617, 127.0.0.1:40234] to replicate blk_-9223372036854775792_1001 to datanode(s) 127.0.0.1:34862
2020-12-03 07:22:43,861 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1998)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 1
2020-12-03 07:22:44,088 [Listener at localhost/43963] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:22:44,090 [Listener at localhost/43963] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 9
2020-12-03 07:22:44,090 [Listener at localhost/43963] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:22:44,090 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@15cea7b0] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:22:44,110 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19, DS-a1467a89-1c19-458e-aaea-444c4edcbb62) exiting.
2020-12-03 07:22:44,110 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20, DS-d2c1ad45-6699-44ec-91c4-683f480b3a5c) exiting.
2020-12-03 07:22:44,207 [Listener at localhost/43963] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@4ae263bf{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:22:44,210 [Listener at localhost/43963] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7103ab0{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:44,211 [Listener at localhost/43963] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3104351d{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:44,212 [Listener at localhost/43963] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@656d10a4{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:44,214 [Listener at localhost/43963] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 43963
2020-12-03 07:22:44,221 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:44,221 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:44,221 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:44,224 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1542479078-172.17.0.8-1606980155306 (Datanode Uuid 2778076c-5f6e-47a7-889f-fd644454ad1c) service to localhost/127.0.0.1:36012
2020-12-03 07:22:44,225 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1542479078-172.17.0.8-1606980155306 (Datanode Uuid 2778076c-5f6e-47a7-889f-fd644454ad1c)
2020-12-03 07:22:44,225 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:44,231 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19/current/BP-1542479078-172.17.0.8-1606980155306] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:44,231 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20/current/BP-1542479078-172.17.0.8-1606980155306] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:44,264 [Listener at localhost/43963] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:22:44,264 [Listener at localhost/43963] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:22:44,265 [Listener at localhost/43963] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:22:44,265 [Listener at localhost/43963] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:22:44,267 [Listener at localhost/43963] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:22:44,267 [Listener at localhost/43963] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 8
2020-12-03 07:22:44,268 [Listener at localhost/43963] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:22:44,268 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1542479078-172.17.0.8-1606980155306 (Datanode Uuid e381e65a-d500-4d88-9fe7-9fef9ef1ca50) service to localhost/127.0.0.1:36012
2020-12-03 07:22:44,269 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-8003d045-1e99-412a-8cb9-6c5a540f201c) exiting.
2020-12-03 07:22:44,269 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-2de1543c-c1ec-4bd6-91e0-70fe2d9c1268) exiting.
2020-12-03 07:22:44,268 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@7ee55e70] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:22:44,284 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1542479078-172.17.0.8-1606980155306 (Datanode Uuid e381e65a-d500-4d88-9fe7-9fef9ef1ca50)
2020-12-03 07:22:44,285 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:44,286 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1542479078-172.17.0.8-1606980155306] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:44,287 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1542479078-172.17.0.8-1606980155306] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:44,306 [Listener at localhost/43963] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5a6d5a8f{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:22:44,306 [Listener at localhost/43963] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4a67318f{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:44,307 [Listener at localhost/43963] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5215cd9a{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:44,307 [Listener at localhost/43963] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@530a8454{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:44,309 [Listener at localhost/43963] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 40844
2020-12-03 07:22:44,313 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:44,313 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:44,324 [Listener at localhost/43963] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:22:44,324 [Listener at localhost/43963] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:22:44,326 [Listener at localhost/43963] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:22:44,326 [Listener at localhost/43963] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:22:44,330 [Listener at localhost/43963] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:22:44,330 [Listener at localhost/43963] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 7
2020-12-03 07:22:44,330 [Listener at localhost/43963] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:22:44,330 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1542479078-172.17.0.8-1606980155306 (Datanode Uuid d5b3f975-4d17-4d98-968c-975d03e85a9a) service to localhost/127.0.0.1:36012
2020-12-03 07:22:44,330 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@7a34b7b8] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:22:44,332 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-21b99e88-4822-4e4b-a603-4dfda1d22bf8) exiting.
2020-12-03 07:22:44,332 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-46a01a31-aa4b-45dc-ad39-15882c9ae2df) exiting.
2020-12-03 07:22:44,334 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1542479078-172.17.0.8-1606980155306 (Datanode Uuid d5b3f975-4d17-4d98-968c-975d03e85a9a)
2020-12-03 07:22:44,334 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:44,341 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1542479078-172.17.0.8-1606980155306] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:44,348 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1542479078-172.17.0.8-1606980155306] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:44,415 [Listener at localhost/43963] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@60b85ba1{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:22:44,421 [Listener at localhost/43963] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@492fc69e{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:44,421 [Listener at localhost/43963] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@65ef722a{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:44,422 [Listener at localhost/43963] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@85ec632{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:44,451 [Listener at localhost/43963] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 35265
2020-12-03 07:22:44,458 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:44,472 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:44,482 [Listener at localhost/43963] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:22:44,483 [Listener at localhost/43963] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:22:44,484 [Listener at localhost/43963] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:22:44,484 [Listener at localhost/43963] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:22:44,495 [Listener at localhost/43963] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:22:44,496 [Listener at localhost/43963] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 6
2020-12-03 07:22:44,496 [Listener at localhost/43963] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:22:44,496 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1542479078-172.17.0.8-1606980155306 (Datanode Uuid 001b4761-f836-4ea2-9f52-478db0422ff2) service to localhost/127.0.0.1:36012
2020-12-03 07:22:44,496 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@26d10f2e] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:22:44,496 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1542479078-172.17.0.8-1606980155306 (Datanode Uuid 001b4761-f836-4ea2-9f52-478db0422ff2)
2020-12-03 07:22:44,497 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:44,499 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-56d51eb8-96f6-40a8-96a0-dc3a49d00c78) exiting.
2020-12-03 07:22:44,499 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-f0f0e850-b5f4-4644-b56c-a705ab62e451) exiting.
2020-12-03 07:22:44,500 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1542479078-172.17.0.8-1606980155306] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:44,500 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1542479078-172.17.0.8-1606980155306] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:44,531 [Listener at localhost/43963] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@3a71c100{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:22:44,532 [Listener at localhost/43963] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@5b69fd74{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:44,533 [Listener at localhost/43963] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3c1e3314{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:44,534 [Listener at localhost/43963] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@53bc1328{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:44,535 [Listener at localhost/43963] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 36043
2020-12-03 07:22:44,538 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:44,555 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:44,582 [Listener at localhost/43963] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:22:44,582 [Listener at localhost/43963] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:22:44,584 [Listener at localhost/43963] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:22:44,585 [Listener at localhost/43963] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:22:44,590 [Listener at localhost/43963] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:22:44,590 [Listener at localhost/43963] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 5
2020-12-03 07:22:44,590 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1542479078-172.17.0.8-1606980155306 (Datanode Uuid f11e5127-b51f-4a84-b875-807607aa34a6) service to localhost/127.0.0.1:36012
2020-12-03 07:22:44,591 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1542479078-172.17.0.8-1606980155306 (Datanode Uuid f11e5127-b51f-4a84-b875-807607aa34a6)
2020-12-03 07:22:44,591 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:44,592 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1542479078-172.17.0.8-1606980155306] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:44,593 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1542479078-172.17.0.8-1606980155306] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:44,596 [Listener at localhost/43963] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:22:44,596 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@1dfd5f51] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:22:44,600 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-f37d1a87-7be4-40de-ad34-60a5fad513e2) exiting.
2020-12-03 07:22:44,600 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-1ab59b68-5e90-426a-a8e7-4de5c23f0a5c) exiting.
2020-12-03 07:22:44,662 [Listener at localhost/43963] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@79f227a9{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:22:44,664 [Listener at localhost/43963] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6ca320ab{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:44,664 [Listener at localhost/43963] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@12f3afb5{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:44,664 [Listener at localhost/43963] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3fabf088{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:44,666 [Listener at localhost/43963] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 33906
2020-12-03 07:22:44,674 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:44,674 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:44,680 [Listener at localhost/43963] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:22:44,682 [Listener at localhost/43963] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:22:44,685 [Listener at localhost/43963] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:22:44,685 [Listener at localhost/43963] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:22:44,690 [Listener at localhost/43963] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:22:44,690 [Listener at localhost/43963] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 4
2020-12-03 07:22:44,690 [Listener at localhost/43963] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:22:44,690 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1542479078-172.17.0.8-1606980155306 (Datanode Uuid 8204a70a-e37a-4db4-a3af-000c4ffdf4f3) service to localhost/127.0.0.1:36012
2020-12-03 07:22:44,690 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@21680803] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:22:44,690 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1542479078-172.17.0.8-1606980155306 (Datanode Uuid 8204a70a-e37a-4db4-a3af-000c4ffdf4f3)
2020-12-03 07:22:44,691 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:44,694 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-ed5b1af2-4d6a-44cc-8f44-ea6a996fecca) exiting.
2020-12-03 07:22:44,694 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-8e39d766-2507-4fa6-bfa3-f30fcbfb6361) exiting.
2020-12-03 07:22:44,695 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1542479078-172.17.0.8-1606980155306] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:44,695 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1542479078-172.17.0.8-1606980155306] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:44,731 [Listener at localhost/43963] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@51c929ae{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:22:44,732 [Listener at localhost/43963] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@3c8bdd5b{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:44,732 [Listener at localhost/43963] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5949eba8{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:44,732 [Listener at localhost/43963] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@c074c0c{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:44,736 [Listener at localhost/43963] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 40964
2020-12-03 07:22:44,740 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:44,740 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:44,746 [Listener at localhost/43963] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:22:44,749 [Listener at localhost/43963] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:22:44,751 [Listener at localhost/43963] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:22:44,751 [Listener at localhost/43963] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:22:44,755 [Listener at localhost/43963] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:22:44,756 [Listener at localhost/43963] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 3
2020-12-03 07:22:44,756 [Listener at localhost/43963] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:22:44,756 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@54ec8cc9] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:22:44,756 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1542479078-172.17.0.8-1606980155306 (Datanode Uuid ebfaef1c-4294-466a-956a-c88ace7fd121) service to localhost/127.0.0.1:36012
2020-12-03 07:22:44,758 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-92e8fd76-ed61-46b0-972b-2eb1bdaeedb2) exiting.
2020-12-03 07:22:44,758 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-1a983e4d-ddf3-46b2-91ca-90f4a6e1615f) exiting.
2020-12-03 07:22:44,758 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1542479078-172.17.0.8-1606980155306 (Datanode Uuid ebfaef1c-4294-466a-956a-c88ace7fd121)
2020-12-03 07:22:44,759 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:44,760 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1542479078-172.17.0.8-1606980155306] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:44,760 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1542479078-172.17.0.8-1606980155306] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:44,854 [Listener at localhost/43963] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@72bca894{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:22:44,855 [Listener at localhost/43963] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@433ffad1{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:44,855 [Listener at localhost/43963] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@29539e36{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:44,855 [Listener at localhost/43963] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@cc62a3b{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:44,856 [Listener at localhost/43963] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 40410
2020-12-03 07:22:44,861 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1998)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 1
2020-12-03 07:22:44,861 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:44,861 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:44,873 [Listener at localhost/43963] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:22:44,877 [Listener at localhost/43963] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:22:44,880 [Listener at localhost/43963] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:22:44,881 [Listener at localhost/43963] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:22:44,886 [Listener at localhost/43963] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:22:44,886 [Listener at localhost/43963] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 2
2020-12-03 07:22:44,886 [Listener at localhost/43963] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:22:44,887 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@2db2cd5] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:22:44,887 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1542479078-172.17.0.8-1606980155306 (Datanode Uuid 8c91dbe3-abfe-4c89-9b41-cb13db08eba0) service to localhost/127.0.0.1:36012
2020-12-03 07:22:44,887 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1542479078-172.17.0.8-1606980155306 (Datanode Uuid 8c91dbe3-abfe-4c89-9b41-cb13db08eba0)
2020-12-03 07:22:44,890 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-05ad14d3-6743-431b-89ed-3742b183502a) exiting.
2020-12-03 07:22:44,890 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-a7a22227-223b-4d81-b014-9eb36b463dbe) exiting.
2020-12-03 07:22:44,891 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:44,893 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1542479078-172.17.0.8-1606980155306] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:44,893 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1542479078-172.17.0.8-1606980155306] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:44,916 [Listener at localhost/43963] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1734f68{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:22:44,917 [Listener at localhost/43963] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@77b7ffa4{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:44,918 [Listener at localhost/43963] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@66238be2{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:44,918 [Listener at localhost/43963] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7249dadf{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:44,919 [Listener at localhost/43963] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 36393
2020-12-03 07:22:44,920 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:44,926 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:44,938 [Listener at localhost/43963] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:22:44,938 [Listener at localhost/43963] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:22:44,941 [Listener at localhost/43963] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:22:44,941 [Listener at localhost/43963] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:22:44,946 [Listener at localhost/43963] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:22:44,947 [Listener at localhost/43963] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 1
2020-12-03 07:22:44,947 [Listener at localhost/43963] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:22:44,947 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1542479078-172.17.0.8-1606980155306 (Datanode Uuid 34ff7519-927c-4ea8-9154-f544635bdcd4) service to localhost/127.0.0.1:36012
2020-12-03 07:22:44,947 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@5707c1cb] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:22:44,947 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1542479078-172.17.0.8-1606980155306 (Datanode Uuid 34ff7519-927c-4ea8-9154-f544635bdcd4)
2020-12-03 07:22:44,950 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-ddcf86b6-f4e7-4e7e-b776-8c3ecf9168cb) exiting.
2020-12-03 07:22:44,950 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-681ff351-b360-4f5e-bd2c-c799b895a27a) exiting.
2020-12-03 07:22:44,952 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:44,953 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1542479078-172.17.0.8-1606980155306] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:44,954 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1542479078-172.17.0.8-1606980155306] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:44,989 [Listener at localhost/43963] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@42a9a63e{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:22:44,990 [Listener at localhost/43963] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@62da83ed{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:44,990 [Listener at localhost/43963] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@41200e0c{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:44,991 [Listener at localhost/43963] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@72efb5c1{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:44,992 [Listener at localhost/43963] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 46347
2020-12-03 07:22:44,999 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:45,010 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:45,050 [Listener at localhost/43963] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:22:45,051 [Listener at localhost/43963] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:22:45,055 [Listener at localhost/43963] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:22:45,056 [Listener at localhost/43963] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:22:45,094 [Listener at localhost/43963] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:22:45,094 [Listener at localhost/43963] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:22:45,094 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1542479078-172.17.0.8-1606980155306 (Datanode Uuid c3e1f354-2020-42cf-ad8e-7a6090792910) service to localhost/127.0.0.1:36012
2020-12-03 07:22:45,096 [Listener at localhost/43963] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:22:45,096 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@39dcf4b0] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:22:45,104 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-4738ef7e-bb4a-4c3f-bc80-47b226c6d2de) exiting.
2020-12-03 07:22:45,104 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-c1d413d2-7376-49c7-8b31-3f158353ef17) exiting.
2020-12-03 07:22:45,133 [Listener at localhost/43963] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@32f0fba8{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:22:45,134 [Listener at localhost/43963] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@545de5a4{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:45,135 [Listener at localhost/43963] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@132ddbab{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:45,135 [Listener at localhost/43963] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@482d776b{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:45,137 [Listener at localhost/43963] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 34197
2020-12-03 07:22:45,151 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:45,158 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:45,159 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1542479078-172.17.0.8-1606980155306 (Datanode Uuid c3e1f354-2020-42cf-ad8e-7a6090792910)
2020-12-03 07:22:45,159 [BP-1542479078-172.17.0.8-1606980155306 heartbeating to localhost/127.0.0.1:36012] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1542479078-172.17.0.8-1606980155306
2020-12-03 07:22:45,160 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1542479078-172.17.0.8-1606980155306] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:45,160 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1542479078-172.17.0.8-1606980155306] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:45,167 [Listener at localhost/43963] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:22:45,168 [Listener at localhost/43963] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:22:45,174 [Listener at localhost/43963] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:22:45,175 [Listener at localhost/43963] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:22:45,175 [Listener at localhost/43963] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:22:45,176 [Listener at localhost/43963] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:22:45,176 [Listener at localhost/43963] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:22:45,176 [Listener at localhost/43963] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 1, 8
2020-12-03 07:22:45,177 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@242aa8d9] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:22:45,177 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@7be58f16] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:22:45,178 [Listener at localhost/43963] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 9 Total time for transactions(ms): 18 Number of transactions batched in Syncs: 0 Number of syncs: 10 SyncTimes(ms): 1 1 
2020-12-03 07:22:45,179 [Listener at localhost/43963] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000009
2020-12-03 07:22:45,180 [Listener at localhost/43963] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000009
2020-12-03 07:22:45,181 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:22:45,181 [CacheReplicationMonitor(597548231)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:22:45,263 [Listener at localhost/43963] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 36012
2020-12-03 07:22:45,270 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:45,277 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:45,277 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:22:45,277 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:22:45,287 [org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor@47db5fa5] DEBUG blockmanagement.BlockManager (PendingReconstructionBlocks.java:run(248)) - PendingReconstructionMonitor thread is interrupted.
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor.run(PendingReconstructionBlocks.java:246)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:22:45,327 [Listener at localhost/43963] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:22:45,328 [Listener at localhost/43963] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:22:45,330 [Listener at localhost/43963] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@3e44f2a5{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:22:45,331 [Listener at localhost/43963] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@589da3f3{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:45,332 [Listener at localhost/43963] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7eecb5b8{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:45,332 [Listener at localhost/43963] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@28cda624{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:45,333 [Listener at localhost/43963] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-12-03 07:22:45,336 [Listener at localhost/43963] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-12-03 07:22:45,337 [Listener at localhost/43963] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
msx-rc 0
