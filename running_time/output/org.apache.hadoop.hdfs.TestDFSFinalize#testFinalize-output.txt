2020-12-03 07:22:42,442 [main] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/namenodeMaster in configuration.
2020-12-03 07:22:42,447 [main] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/namenodeMaster in configuration.
Formatting using clusterid: testClusterID
2020-12-03 07:22:42,490 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:22:42,512 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:22:42,513 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:22:42,516 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:22:42,525 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:22:42,525 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:22:42,525 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:22:42,526 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:22:42,580 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:42,601 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:22:42,602 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:22:42,608 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:22:42,608 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:22:42
2020-12-03 07:22:42,611 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:22:42,612 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:42,615 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-12-03 07:22:42,615 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:22:42,635 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:22:42,636 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:22:42,644 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS
2020-12-03 07:22:42,644 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:22:42,645 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:22:42,645 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 30000
2020-12-03 07:22:42,646 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:22:42,646 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:22:42,647 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:22:42,647 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:22:42,647 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:22:42,647 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:22:42,648 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:22:42,682 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GLOBAL serial map: bits=29 maxEntries=536870911
2020-12-03 07:22:42,683 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - USER serial map: bits=24 maxEntries=16777215
2020-12-03 07:22:42,683 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GROUP serial map: bits=24 maxEntries=16777215
2020-12-03 07:22:42,683 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - XATTR serial map: bits=24 maxEntries=16777215
2020-12-03 07:22:42,699 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:22:42,699 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:42,700 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-12-03 07:22:42,700 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:22:42,707 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:22:42,707 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:22:42,707 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:22:42,708 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:22:42,718 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:22:42,721 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:22:42,727 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:22:42,727 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:42,728 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-12-03 07:22:42,728 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:22:42,739 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:22:42,740 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:22:42,740 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:22:42,746 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:22:42,746 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:22:42,750 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:22:42,751 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:42,752 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-12-03 07:22:42,752 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:22:42,802 [main] INFO  namenode.FSImage (FSImage.java:format(185)) - Allocated new BlockPoolId: BP-1584977637-172.17.0.10-1606980162785
2020-12-03 07:22:42,899 [main] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/namenodeMaster has been successfully formatted.
2020-12-03 07:22:42,940 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/namenodeMaster of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/namenodeMaster/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:22:43,077 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/namenodeMaster of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/namenodeMaster/current/fsimage.ckpt_0000000000000000000 of size 396 bytes saved in 0 seconds .
2020-12-03 07:22:43,138 [main] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-12-03 07:22:43,147 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=1
2020-12-03 07:22:43,300 [main] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/namenodeMaster in configuration.
2020-12-03 07:22:43,302 [main] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:22:43,415 [main] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:22:43,825 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:22:43,825 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:22:43,880 [main] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-12-03 07:22:43,954 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1de76cc7] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:43,980 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:22:43,987 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:44,005 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @3196ms
2020-12-03 07:22:44,141 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:44,145 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:22:44,145 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:44,157 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:44,159 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:22:44,160 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:44,160 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:44,192 [main] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:22:44,193 [main] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:22:44,204 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 39526
2020-12-03 07:22:44,206 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:44,258 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5c7bfdc1{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:44,259 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@71687585{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:44,304 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7a3793c7{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:22:44,316 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4c012563{HTTP/1.1,[http/1.1]}{localhost:39526}
2020-12-03 07:22:44,317 [main] INFO  server.Server (Server.java:doStart(419)) - Started @3507ms
2020-12-03 07:22:44,317 [main] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/namenodeMaster in configuration.
2020-12-03 07:22:44,318 [main] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/namenodeMaster in configuration.
2020-12-03 07:22:44,319 [main] WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(686)) - Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2020-12-03 07:22:44,319 [main] WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(691)) - Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2020-12-03 07:22:44,319 [main] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/namenodeMaster in configuration.
2020-12-03 07:22:44,320 [main] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/namenodeMaster in configuration.
2020-12-03 07:22:44,329 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:22:44,330 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:22:44,330 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:22:44,330 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:22:44,331 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:22:44,331 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:22:44,331 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:22:44,332 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:22:44,332 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:44,333 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2020-12-03 07:22:44,334 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:22:44,334 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:22:44,334 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:22:44,335 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:22:44
2020-12-03 07:22:44,335 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:22:44,335 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:44,336 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:22:44,336 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:22:44,344 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:22:44,344 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:22:44,345 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:22:44,345 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:22:44,345 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:22:44,346 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:22:44,346 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 1
2020-12-03 07:22:44,346 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:22:44,347 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:22:44,347 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:22:44,347 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:22:44,348 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:22:44,348 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:22:44,349 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:22:44,349 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:44,350 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:22:44,350 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:22:44,361 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:22:44,361 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:22:44,361 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:22:44,362 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:22:44,362 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:22:44,362 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:22:44,363 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:22:44,363 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:44,364 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:22:44,364 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:22:44,365 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:22:44,366 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:22:44,366 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:22:44,366 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:22:44,367 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:22:44,367 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:22:44,367 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:44,368 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:22:44,368 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:22:44,415 [main] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/namenodeMaster/in_use.lock acquired by nodename 5752@f8f6fab70ed3
2020-12-03 07:22:44,420 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/namenodeMaster/current
2020-12-03 07:22:44,420 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:22:44,421 [main] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/namenodeMaster/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:22:44,452 [main] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:22:44,459 [main] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:22:44,460 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/namenodeMaster/current/fsimage_0000000000000000000
2020-12-03 07:22:44,465 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:22:44,465 [main] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 1
2020-12-03 07:22:44,597 [main] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:22:44,597 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 225 msecs
2020-12-03 07:22:44,802 [main] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:22:44,856 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:44,873 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:45,171 [Listener at localhost/45114] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:45114 to access this namenode/service.
2020-12-03 07:22:45,176 [Listener at localhost/45114] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:22:45,177 [Listener at localhost/45114] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/namenodeMaster in configuration.
2020-12-03 07:22:45,205 [Listener at localhost/45114] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:22:45,222 [Listener at localhost/45114] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:22:45,223 [Listener at localhost/45114] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:22:45,228 [Listener at localhost/45114] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:22:45,241 [Listener at localhost/45114] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:22:45,248 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 0
2020-12-03 07:22:45,251 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:22:45,252 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:22:45,252 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:22:45,252 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:22:45,252 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 20 msec
2020-12-03 07:22:45,305 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:45,318 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:45,320 [Listener at localhost/45114] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:45114
2020-12-03 07:22:45,323 [Listener at localhost/45114] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:22:45,324 [Listener at localhost/45114] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:22:45,336 [Listener at localhost/45114] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 12 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:22:45,346 [CacheReplicationMonitor(2034055039)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:22:45,355 [Listener at localhost/45114] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/datanodeMaster
2020-12-03 07:22:45,456 [Listener at localhost/45114] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/datanodeMaster
2020-12-03 07:22:45,503 [Listener at localhost/45114] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:22:45,508 [Listener at localhost/45114] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:45,512 [Listener at localhost/45114] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:22:45,517 [Listener at localhost/45114] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:22:45,518 [Listener at localhost/45114] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:45,523 [Listener at localhost/45114] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:22:45,532 [Listener at localhost/45114] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:39276
2020-12-03 07:22:45,535 [Listener at localhost/45114] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:22:45,535 [Listener at localhost/45114] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:22:45,559 [Listener at localhost/45114] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:45,562 [Listener at localhost/45114] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:45,562 [Listener at localhost/45114] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:22:45,563 [Listener at localhost/45114] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:45,566 [Listener at localhost/45114] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:45,568 [Listener at localhost/45114] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:22:45,568 [Listener at localhost/45114] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:45,569 [Listener at localhost/45114] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:45,573 [Listener at localhost/45114] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 46507
2020-12-03 07:22:45,573 [Listener at localhost/45114] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:45,575 [Listener at localhost/45114] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2a3591c5{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:45,576 [Listener at localhost/45114] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@346a361{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:45,584 [Listener at localhost/45114] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5b58ed3c{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:22:45,585 [Listener at localhost/45114] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@24faea88{HTTP/1.1,[http/1.1]}{localhost:46507}
2020-12-03 07:22:45,585 [Listener at localhost/45114] INFO  server.Server (Server.java:doStart(419)) - Started @4776ms
2020-12-03 07:22:45,957 [Listener at localhost/45114] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:44605
2020-12-03 07:22:45,958 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@71f67a79] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:45,960 [Listener at localhost/45114] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:22:45,960 [Listener at localhost/45114] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:22:45,977 [Listener at localhost/45114] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:45,979 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:45,986 [Listener at localhost/37597] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:37597
2020-12-03 07:22:46,219 [Listener at localhost/37597] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:22:46,222 [Listener at localhost/37597] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:22:46,233 [Thread-58] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45114 starting to offer service
2020-12-03 07:22:46,240 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:46,240 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:46,575 [Thread-58] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45114
2020-12-03 07:22:46,578 [Thread-58] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2020-12-03 07:22:46,613 [Thread-58] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/datanodeMaster/in_use.lock acquired by nodename 5752@f8f6fab70ed3
2020-12-03 07:22:46,614 [Thread-58] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/datanodeMaster is not formatted for namespace 60730268. Formatting...
2020-12-03 07:22:46,615 [Thread-58] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-01c1f918-528d-470c-ad21-c7fd22eca90a for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/datanodeMaster 
2020-12-03 07:22:46,697 [Thread-58] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1584977637-172.17.0.10-1606980162785
2020-12-03 07:22:46,698 [Thread-58] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/datanodeMaster/current/BP-1584977637-172.17.0.10-1606980162785
2020-12-03 07:22:46,699 [Thread-58] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/datanodeMaster and block pool id BP-1584977637-172.17.0.10-1606980162785 is not formatted. Formatting ...
2020-12-03 07:22:46,699 [Thread-58] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1584977637-172.17.0.10-1606980162785 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/datanodeMaster/current/BP-1584977637-172.17.0.10-1606980162785/current
2020-12-03 07:22:46,791 [Thread-58] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=60730268;bpid=BP-1584977637-172.17.0.10-1606980162785;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=60730268;c=1606980162785;bpid=BP-1584977637-172.17.0.10-1606980162785;dnuuid=null
2020-12-03 07:22:46,831 [IPC Server handler 2 on default port 45114] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:46,839 [Listener at localhost/37597] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:46,840 [Listener at localhost/37597] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:46,841 [Thread-58] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID f1d8177d-b4c6-4841-8546-addcebbb1ab1
2020-12-03 07:22:46,943 [IPC Server handler 1 on default port 45114] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:46,944 [Listener at localhost/37597] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:46,944 [Listener at localhost/37597] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:46,975 [Thread-58] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-01c1f918-528d-470c-ad21-c7fd22eca90a
2020-12-03 07:22:46,975 [Thread-58] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/datanodeMaster, StorageType: DISK
2020-12-03 07:22:46,986 [Thread-58] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:22:46,996 [Thread-58] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/datanodeMaster
2020-12-03 07:22:47,004 [Thread-58] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/datanodeMaster
2020-12-03 07:22:47,006 [Thread-58] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1584977637-172.17.0.10-1606980162785
2020-12-03 07:22:47,007 [Thread-75] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1584977637-172.17.0.10-1606980162785 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/datanodeMaster...
2020-12-03 07:22:47,039 [Thread-75] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1584977637-172.17.0.10-1606980162785 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/datanodeMaster: 32ms
2020-12-03 07:22:47,040 [Thread-58] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1584977637-172.17.0.10-1606980162785: 33ms
2020-12-03 07:22:47,042 [Thread-77] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1584977637-172.17.0.10-1606980162785 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/datanodeMaster...
2020-12-03 07:22:47,042 [Thread-77] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/datanodeMaster/current/BP-1584977637-172.17.0.10-1606980162785/current/replicas doesn't exist 
2020-12-03 07:22:47,044 [Thread-77] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1584977637-172.17.0.10-1606980162785 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/datanodeMaster: 1ms
2020-12-03 07:22:47,044 [Thread-58] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1584977637-172.17.0.10-1606980162785: 3ms
2020-12-03 07:22:47,047 [IPC Server handler 3 on default port 45114] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:47,047 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/datanodeMaster)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1584977637-172.17.0.10-1606980162785 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/datanodeMaster
2020-12-03 07:22:47,047 [Listener at localhost/37597] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:47,048 [Listener at localhost/37597] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:47,049 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/datanodeMaster)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/datanodeMaster, DS-01c1f918-528d-470c-ad21-c7fd22eca90a): finished scanning block pool BP-1584977637-172.17.0.10-1606980162785
2020-12-03 07:22:47,069 [Thread-58] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 8:54 AM with interval of 21600000ms
2020-12-03 07:22:47,076 [BP-1584977637-172.17.0.10-1606980162785 heartbeating to localhost/127.0.0.1:45114] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1584977637-172.17.0.10-1606980162785 (Datanode Uuid f1d8177d-b4c6-4841-8546-addcebbb1ab1) service to localhost/127.0.0.1:45114 beginning handshake with NN
2020-12-03 07:22:47,087 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/datanodeMaster)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/datanodeMaster, DS-01c1f918-528d-470c-ad21-c7fd22eca90a): no suitable block pools found to scan.  Waiting 1814399960 ms.
2020-12-03 07:22:47,091 [IPC Server handler 4 on default port 45114] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:39276, datanodeUuid=f1d8177d-b4c6-4841-8546-addcebbb1ab1, infoPort=44605, infoSecurePort=0, ipcPort=37597, storageInfo=lv=-57;cid=testClusterID;nsid=60730268;c=1606980162785) storage f1d8177d-b4c6-4841-8546-addcebbb1ab1
2020-12-03 07:22:47,094 [IPC Server handler 4 on default port 45114] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:39276
2020-12-03 07:22:47,094 [IPC Server handler 4 on default port 45114] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN f1d8177d-b4c6-4841-8546-addcebbb1ab1 (127.0.0.1:39276).
2020-12-03 07:22:47,100 [BP-1584977637-172.17.0.10-1606980162785 heartbeating to localhost/127.0.0.1:45114] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1584977637-172.17.0.10-1606980162785 (Datanode Uuid f1d8177d-b4c6-4841-8546-addcebbb1ab1) service to localhost/127.0.0.1:45114 successfully registered with NN
2020-12-03 07:22:47,101 [BP-1584977637-172.17.0.10-1606980162785 heartbeating to localhost/127.0.0.1:45114] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:45114 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:22:47,122 [IPC Server handler 5 on default port 45114] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-01c1f918-528d-470c-ad21-c7fd22eca90a for DN 127.0.0.1:39276
2020-12-03 07:22:47,154 [IPC Server handler 6 on default port 45114] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:47,157 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x9c575c53649f763c: Processing first storage report for DS-01c1f918-528d-470c-ad21-c7fd22eca90a from datanode f1d8177d-b4c6-4841-8546-addcebbb1ab1
2020-12-03 07:22:47,159 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x9c575c53649f763c: from storage DS-01c1f918-528d-470c-ad21-c7fd22eca90a node DatanodeRegistration(127.0.0.1:39276, datanodeUuid=f1d8177d-b4c6-4841-8546-addcebbb1ab1, infoPort=44605, infoSecurePort=0, ipcPort=37597, storageInfo=lv=-57;cid=testClusterID;nsid=60730268;c=1606980162785), blocks: 0, hasStaleStorage: false, processing time: 2 msecs, invalidatedBlocks: 0
2020-12-03 07:22:47,164 [Listener at localhost/37597] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:22:47,182 [BP-1584977637-172.17.0.10-1606980162785 heartbeating to localhost/127.0.0.1:45114] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x9c575c53649f763c,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 39 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:47,182 [BP-1584977637-172.17.0.10-1606980162785 heartbeating to localhost/127.0.0.1:45114] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1584977637-172.17.0.10-1606980162785
2020-12-03 07:22:47,197 [IPC Server handler 9 on default port 45114] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/TestUpgrade	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:22:47,262 [IPC Server handler 8 on default port 45114] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/TestUpgrade/file1	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:22:47,309 [IPC Server handler 0 on default port 45114] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:39276 for /TestUpgrade/file1
2020-12-03 07:22:47,326 [Thread-81] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:47,386 [DataXceiver for client DFSClient_NONMAPREDUCE_459844888_1 at /127.0.0.1:37408 [Receiving block BP-1584977637-172.17.0.10-1606980162785:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1584977637-172.17.0.10-1606980162785:blk_1073741825_1001 src: /127.0.0.1:37408 dest: /127.0.0.1:39276
2020-12-03 07:22:47,441 [PacketResponder: BP-1584977637-172.17.0.10-1606980162785:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37408, dest: /127.0.0.1:39276, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_459844888_1, offset: 0, srvID: f1d8177d-b4c6-4841-8546-addcebbb1ab1, blockid: BP-1584977637-172.17.0.10-1606980162785:blk_1073741825_1001, duration(ns): 13583548
2020-12-03 07:22:47,441 [PacketResponder: BP-1584977637-172.17.0.10-1606980162785:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1584977637-172.17.0.10-1606980162785:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:22:47,448 [IPC Server handler 1 on default port 45114] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741826_1002, replicas=127.0.0.1:39276 for /TestUpgrade/file1
2020-12-03 07:22:47,450 [DataStreamer for file /TestUpgrade/file1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:47,455 [DataXceiver for client DFSClient_NONMAPREDUCE_459844888_1 at /127.0.0.1:37410 [Receiving block BP-1584977637-172.17.0.10-1606980162785:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1584977637-172.17.0.10-1606980162785:blk_1073741826_1002 src: /127.0.0.1:37410 dest: /127.0.0.1:39276
2020-12-03 07:22:47,469 [PacketResponder: BP-1584977637-172.17.0.10-1606980162785:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37410, dest: /127.0.0.1:39276, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_459844888_1, offset: 0, srvID: f1d8177d-b4c6-4841-8546-addcebbb1ab1, blockid: BP-1584977637-172.17.0.10-1606980162785:blk_1073741826_1002, duration(ns): 11855065
2020-12-03 07:22:47,470 [PacketResponder: BP-1584977637-172.17.0.10-1606980162785:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1584977637-172.17.0.10-1606980162785:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2020-12-03 07:22:47,473 [IPC Server handler 6 on default port 45114] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741827_1003, replicas=127.0.0.1:39276 for /TestUpgrade/file1
2020-12-03 07:22:47,475 [DataStreamer for file /TestUpgrade/file1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:47,476 [DataXceiver for client DFSClient_NONMAPREDUCE_459844888_1 at /127.0.0.1:37412 [Receiving block BP-1584977637-172.17.0.10-1606980162785:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1584977637-172.17.0.10-1606980162785:blk_1073741827_1003 src: /127.0.0.1:37412 dest: /127.0.0.1:39276
2020-12-03 07:22:47,482 [PacketResponder: BP-1584977637-172.17.0.10-1606980162785:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37412, dest: /127.0.0.1:39276, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_459844888_1, offset: 0, srvID: f1d8177d-b4c6-4841-8546-addcebbb1ab1, blockid: BP-1584977637-172.17.0.10-1606980162785:blk_1073741827_1003, duration(ns): 3437073
2020-12-03 07:22:47,482 [PacketResponder: BP-1584977637-172.17.0.10-1606980162785:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1584977637-172.17.0.10-1606980162785:blk_1073741827_1003, type=LAST_IN_PIPELINE terminating
2020-12-03 07:22:47,485 [IPC Server handler 9 on default port 45114] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741828_1004, replicas=127.0.0.1:39276 for /TestUpgrade/file1
2020-12-03 07:22:47,487 [DataStreamer for file /TestUpgrade/file1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:47,489 [DataXceiver for client DFSClient_NONMAPREDUCE_459844888_1 at /127.0.0.1:37414 [Receiving block BP-1584977637-172.17.0.10-1606980162785:blk_1073741828_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1584977637-172.17.0.10-1606980162785:blk_1073741828_1004 src: /127.0.0.1:37414 dest: /127.0.0.1:39276
2020-12-03 07:22:47,495 [PacketResponder: BP-1584977637-172.17.0.10-1606980162785:blk_1073741828_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37414, dest: /127.0.0.1:39276, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_459844888_1, offset: 0, srvID: f1d8177d-b4c6-4841-8546-addcebbb1ab1, blockid: BP-1584977637-172.17.0.10-1606980162785:blk_1073741828_1004, duration(ns): 4277845
2020-12-03 07:22:47,496 [PacketResponder: BP-1584977637-172.17.0.10-1606980162785:blk_1073741828_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1584977637-172.17.0.10-1606980162785:blk_1073741828_1004, type=LAST_IN_PIPELINE terminating
2020-12-03 07:22:47,501 [IPC Server handler 0 on default port 45114] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /TestUpgrade/file1 is closed by DFSClient_NONMAPREDUCE_459844888_1
2020-12-03 07:22:47,507 [IPC Server handler 2 on default port 45114] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/TestUpgrade/file2	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:22:47,510 [IPC Server handler 1 on default port 45114] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741829_1005, replicas=127.0.0.1:39276 for /TestUpgrade/file2
2020-12-03 07:22:47,512 [Thread-95] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:47,513 [DataXceiver for client DFSClient_NONMAPREDUCE_459844888_1 at /127.0.0.1:37416 [Receiving block BP-1584977637-172.17.0.10-1606980162785:blk_1073741829_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1584977637-172.17.0.10-1606980162785:blk_1073741829_1005 src: /127.0.0.1:37416 dest: /127.0.0.1:39276
2020-12-03 07:22:47,520 [PacketResponder: BP-1584977637-172.17.0.10-1606980162785:blk_1073741829_1005, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37416, dest: /127.0.0.1:39276, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_459844888_1, offset: 0, srvID: f1d8177d-b4c6-4841-8546-addcebbb1ab1, blockid: BP-1584977637-172.17.0.10-1606980162785:blk_1073741829_1005, duration(ns): 4263412
2020-12-03 07:22:47,520 [PacketResponder: BP-1584977637-172.17.0.10-1606980162785:blk_1073741829_1005, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1584977637-172.17.0.10-1606980162785:blk_1073741829_1005, type=LAST_IN_PIPELINE terminating
2020-12-03 07:22:47,523 [IPC Server handler 4 on default port 45114] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741830_1006, replicas=127.0.0.1:39276 for /TestUpgrade/file2
2020-12-03 07:22:47,525 [DataStreamer for file /TestUpgrade/file2] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:47,526 [DataXceiver for client DFSClient_NONMAPREDUCE_459844888_1 at /127.0.0.1:37418 [Receiving block BP-1584977637-172.17.0.10-1606980162785:blk_1073741830_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1584977637-172.17.0.10-1606980162785:blk_1073741830_1006 src: /127.0.0.1:37418 dest: /127.0.0.1:39276
2020-12-03 07:22:47,531 [PacketResponder: BP-1584977637-172.17.0.10-1606980162785:blk_1073741830_1006, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37418, dest: /127.0.0.1:39276, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_459844888_1, offset: 0, srvID: f1d8177d-b4c6-4841-8546-addcebbb1ab1, blockid: BP-1584977637-172.17.0.10-1606980162785:blk_1073741830_1006, duration(ns): 2741507
2020-12-03 07:22:47,532 [PacketResponder: BP-1584977637-172.17.0.10-1606980162785:blk_1073741830_1006, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1584977637-172.17.0.10-1606980162785:blk_1073741830_1006, type=LAST_IN_PIPELINE terminating
2020-12-03 07:22:47,534 [IPC Server handler 6 on default port 45114] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741831_1007, replicas=127.0.0.1:39276 for /TestUpgrade/file2
2020-12-03 07:22:47,535 [DataStreamer for file /TestUpgrade/file2] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:47,537 [DataXceiver for client DFSClient_NONMAPREDUCE_459844888_1 at /127.0.0.1:37420 [Receiving block BP-1584977637-172.17.0.10-1606980162785:blk_1073741831_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1584977637-172.17.0.10-1606980162785:blk_1073741831_1007 src: /127.0.0.1:37420 dest: /127.0.0.1:39276
2020-12-03 07:22:47,542 [PacketResponder: BP-1584977637-172.17.0.10-1606980162785:blk_1073741831_1007, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37420, dest: /127.0.0.1:39276, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_459844888_1, offset: 0, srvID: f1d8177d-b4c6-4841-8546-addcebbb1ab1, blockid: BP-1584977637-172.17.0.10-1606980162785:blk_1073741831_1007, duration(ns): 2800408
2020-12-03 07:22:47,542 [PacketResponder: BP-1584977637-172.17.0.10-1606980162785:blk_1073741831_1007, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1584977637-172.17.0.10-1606980162785:blk_1073741831_1007, type=LAST_IN_PIPELINE terminating
2020-12-03 07:22:47,545 [IPC Server handler 7 on default port 45114] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741832_1008, replicas=127.0.0.1:39276 for /TestUpgrade/file2
2020-12-03 07:22:47,546 [DataStreamer for file /TestUpgrade/file2] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:47,547 [DataXceiver for client DFSClient_NONMAPREDUCE_459844888_1 at /127.0.0.1:37424 [Receiving block BP-1584977637-172.17.0.10-1606980162785:blk_1073741832_1008]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1584977637-172.17.0.10-1606980162785:blk_1073741832_1008 src: /127.0.0.1:37424 dest: /127.0.0.1:39276
2020-12-03 07:22:47,555 [PacketResponder: BP-1584977637-172.17.0.10-1606980162785:blk_1073741832_1008, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37424, dest: /127.0.0.1:39276, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_459844888_1, offset: 0, srvID: f1d8177d-b4c6-4841-8546-addcebbb1ab1, blockid: BP-1584977637-172.17.0.10-1606980162785:blk_1073741832_1008, duration(ns): 5205200
2020-12-03 07:22:47,556 [PacketResponder: BP-1584977637-172.17.0.10-1606980162785:blk_1073741832_1008, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1584977637-172.17.0.10-1606980162785:blk_1073741832_1008, type=LAST_IN_PIPELINE terminating
2020-12-03 07:22:47,558 [IPC Server handler 0 on default port 45114] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /TestUpgrade/file2 is closed by DFSClient_NONMAPREDUCE_459844888_1
2020-12-03 07:22:47,560 [Listener at localhost/37597] INFO  hdfs.StateChange (FSNamesystem.java:enterSafeMode(4674)) - STATE* Safe mode is ON.
It was turned on manually. Use "hdfs dfsadmin -safemode leave" to turn safe mode off.
2020-12-03 07:22:47,560 [Listener at localhost/37597] INFO  namenode.FSImage (FSImage.java:saveNamespace(1147)) - Save namespace ...
2020-12-03 07:22:47,560 [Listener at localhost/37597] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 1, 30
2020-12-03 07:22:47,561 [Listener at localhost/37597] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 31 Total time for transactions(ms): 18 Number of transactions batched in Syncs: 7 Number of syncs: 25 SyncTimes(ms): 3 
2020-12-03 07:22:47,563 [Listener at localhost/37597] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/namenodeMaster/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/namenodeMaster/current/edits_0000000000000000001-0000000000000000031
2020-12-03 07:22:47,573 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/namenodeMaster of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/namenodeMaster/current/fsimage.ckpt_0000000000000000031 using no compression
2020-12-03 07:22:47,584 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/namenodeMaster of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/namenodeMaster/current/fsimage.ckpt_0000000000000000031 of size 716 bytes saved in 0 seconds .
2020-12-03 07:22:47,629 [Listener at localhost/37597] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 2 images with txid >= 0
2020-12-03 07:22:47,661 [Listener at localhost/37597] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 32
2020-12-03 07:22:47,697 [Listener at localhost/37597] INFO  namenode.FSNamesystem (FSNamesystem.java:saveNamespace(4500)) - New namespace image has been created
2020-12-03 07:22:47,697 [Listener at localhost/37597] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 2 secs
2020-12-03 07:22:47,697 [Listener at localhost/37597] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 1 racks and 1 datanodes
2020-12-03 07:22:47,698 [Listener at localhost/37597] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:22:47,704 [IPC Server handler 2 on default port 45114] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/TestUpgrade/file3	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:22:47,712 [IPC Server handler 1 on default port 45114] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741833_1009, replicas=127.0.0.1:39276 for /TestUpgrade/file3
2020-12-03 07:22:47,715 [Thread-108] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:47,717 [DataXceiver for client DFSClient_NONMAPREDUCE_459844888_1 at /127.0.0.1:37426 [Receiving block BP-1584977637-172.17.0.10-1606980162785:blk_1073741833_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1584977637-172.17.0.10-1606980162785:blk_1073741833_1009 src: /127.0.0.1:37426 dest: /127.0.0.1:39276
2020-12-03 07:22:47,730 [PacketResponder: BP-1584977637-172.17.0.10-1606980162785:blk_1073741833_1009, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37426, dest: /127.0.0.1:39276, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_459844888_1, offset: 0, srvID: f1d8177d-b4c6-4841-8546-addcebbb1ab1, blockid: BP-1584977637-172.17.0.10-1606980162785:blk_1073741833_1009, duration(ns): 9704511
2020-12-03 07:22:47,731 [PacketResponder: BP-1584977637-172.17.0.10-1606980162785:blk_1073741833_1009, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1584977637-172.17.0.10-1606980162785:blk_1073741833_1009, type=LAST_IN_PIPELINE terminating
2020-12-03 07:22:47,737 [IPC Server handler 4 on default port 45114] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741834_1010, replicas=127.0.0.1:39276 for /TestUpgrade/file3
2020-12-03 07:22:47,738 [DataStreamer for file /TestUpgrade/file3] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:47,740 [DataXceiver for client DFSClient_NONMAPREDUCE_459844888_1 at /127.0.0.1:37428 [Receiving block BP-1584977637-172.17.0.10-1606980162785:blk_1073741834_1010]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1584977637-172.17.0.10-1606980162785:blk_1073741834_1010 src: /127.0.0.1:37428 dest: /127.0.0.1:39276
2020-12-03 07:22:47,753 [PacketResponder: BP-1584977637-172.17.0.10-1606980162785:blk_1073741834_1010, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37428, dest: /127.0.0.1:39276, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_459844888_1, offset: 0, srvID: f1d8177d-b4c6-4841-8546-addcebbb1ab1, blockid: BP-1584977637-172.17.0.10-1606980162785:blk_1073741834_1010, duration(ns): 5045792
2020-12-03 07:22:47,753 [PacketResponder: BP-1584977637-172.17.0.10-1606980162785:blk_1073741834_1010, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1584977637-172.17.0.10-1606980162785:blk_1073741834_1010, type=LAST_IN_PIPELINE terminating
2020-12-03 07:22:47,759 [IPC Server handler 9 on default port 45114] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741835_1011, replicas=127.0.0.1:39276 for /TestUpgrade/file3
2020-12-03 07:22:47,761 [DataStreamer for file /TestUpgrade/file3] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:47,762 [DataXceiver for client DFSClient_NONMAPREDUCE_459844888_1 at /127.0.0.1:37430 [Receiving block BP-1584977637-172.17.0.10-1606980162785:blk_1073741835_1011]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1584977637-172.17.0.10-1606980162785:blk_1073741835_1011 src: /127.0.0.1:37430 dest: /127.0.0.1:39276
2020-12-03 07:22:47,767 [PacketResponder: BP-1584977637-172.17.0.10-1606980162785:blk_1073741835_1011, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37430, dest: /127.0.0.1:39276, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_459844888_1, offset: 0, srvID: f1d8177d-b4c6-4841-8546-addcebbb1ab1, blockid: BP-1584977637-172.17.0.10-1606980162785:blk_1073741835_1011, duration(ns): 3387938
2020-12-03 07:22:47,768 [PacketResponder: BP-1584977637-172.17.0.10-1606980162785:blk_1073741835_1011, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1584977637-172.17.0.10-1606980162785:blk_1073741835_1011, type=LAST_IN_PIPELINE terminating
2020-12-03 07:22:47,772 [IPC Server handler 0 on default port 45114] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741836_1012, replicas=127.0.0.1:39276 for /TestUpgrade/file3
2020-12-03 07:22:47,774 [DataStreamer for file /TestUpgrade/file3] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:47,775 [DataXceiver for client DFSClient_NONMAPREDUCE_459844888_1 at /127.0.0.1:37432 [Receiving block BP-1584977637-172.17.0.10-1606980162785:blk_1073741836_1012]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1584977637-172.17.0.10-1606980162785:blk_1073741836_1012 src: /127.0.0.1:37432 dest: /127.0.0.1:39276
2020-12-03 07:22:47,781 [PacketResponder: BP-1584977637-172.17.0.10-1606980162785:blk_1073741836_1012, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37432, dest: /127.0.0.1:39276, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_459844888_1, offset: 0, srvID: f1d8177d-b4c6-4841-8546-addcebbb1ab1, blockid: BP-1584977637-172.17.0.10-1606980162785:blk_1073741836_1012, duration(ns): 3879606
2020-12-03 07:22:47,782 [PacketResponder: BP-1584977637-172.17.0.10-1606980162785:blk_1073741836_1012, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1584977637-172.17.0.10-1606980162785:blk_1073741836_1012, type=LAST_IN_PIPELINE terminating
2020-12-03 07:22:47,784 [IPC Server handler 2 on default port 45114] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /TestUpgrade/file3 is closed by DFSClient_NONMAPREDUCE_459844888_1
2020-12-03 07:22:47,786 [IPC Server handler 3 on default port 45114] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/TestUpgrade/file4	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:22:47,790 [IPC Server handler 4 on default port 45114] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741837_1013, replicas=127.0.0.1:39276 for /TestUpgrade/file4
2020-12-03 07:22:47,793 [Thread-121] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:47,794 [DataXceiver for client DFSClient_NONMAPREDUCE_459844888_1 at /127.0.0.1:37434 [Receiving block BP-1584977637-172.17.0.10-1606980162785:blk_1073741837_1013]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1584977637-172.17.0.10-1606980162785:blk_1073741837_1013 src: /127.0.0.1:37434 dest: /127.0.0.1:39276
2020-12-03 07:22:47,801 [PacketResponder: BP-1584977637-172.17.0.10-1606980162785:blk_1073741837_1013, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37434, dest: /127.0.0.1:39276, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_459844888_1, offset: 0, srvID: f1d8177d-b4c6-4841-8546-addcebbb1ab1, blockid: BP-1584977637-172.17.0.10-1606980162785:blk_1073741837_1013, duration(ns): 3679581
2020-12-03 07:22:47,801 [PacketResponder: BP-1584977637-172.17.0.10-1606980162785:blk_1073741837_1013, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1584977637-172.17.0.10-1606980162785:blk_1073741837_1013, type=LAST_IN_PIPELINE terminating
2020-12-03 07:22:47,803 [IPC Server handler 6 on default port 45114] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741838_1014, replicas=127.0.0.1:39276 for /TestUpgrade/file4
2020-12-03 07:22:47,805 [DataStreamer for file /TestUpgrade/file4] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:47,806 [DataXceiver for client DFSClient_NONMAPREDUCE_459844888_1 at /127.0.0.1:37440 [Receiving block BP-1584977637-172.17.0.10-1606980162785:blk_1073741838_1014]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1584977637-172.17.0.10-1606980162785:blk_1073741838_1014 src: /127.0.0.1:37440 dest: /127.0.0.1:39276
2020-12-03 07:22:47,813 [PacketResponder: BP-1584977637-172.17.0.10-1606980162785:blk_1073741838_1014, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37440, dest: /127.0.0.1:39276, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_459844888_1, offset: 0, srvID: f1d8177d-b4c6-4841-8546-addcebbb1ab1, blockid: BP-1584977637-172.17.0.10-1606980162785:blk_1073741838_1014, duration(ns): 3912743
2020-12-03 07:22:47,813 [PacketResponder: BP-1584977637-172.17.0.10-1606980162785:blk_1073741838_1014, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1584977637-172.17.0.10-1606980162785:blk_1073741838_1014, type=LAST_IN_PIPELINE terminating
2020-12-03 07:22:47,816 [IPC Server handler 7 on default port 45114] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741839_1015, replicas=127.0.0.1:39276 for /TestUpgrade/file4
2020-12-03 07:22:47,819 [DataStreamer for file /TestUpgrade/file4] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:47,820 [DataXceiver for client DFSClient_NONMAPREDUCE_459844888_1 at /127.0.0.1:37442 [Receiving block BP-1584977637-172.17.0.10-1606980162785:blk_1073741839_1015]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1584977637-172.17.0.10-1606980162785:blk_1073741839_1015 src: /127.0.0.1:37442 dest: /127.0.0.1:39276
2020-12-03 07:22:47,826 [PacketResponder: BP-1584977637-172.17.0.10-1606980162785:blk_1073741839_1015, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37442, dest: /127.0.0.1:39276, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_459844888_1, offset: 0, srvID: f1d8177d-b4c6-4841-8546-addcebbb1ab1, blockid: BP-1584977637-172.17.0.10-1606980162785:blk_1073741839_1015, duration(ns): 4372204
2020-12-03 07:22:47,827 [PacketResponder: BP-1584977637-172.17.0.10-1606980162785:blk_1073741839_1015, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1584977637-172.17.0.10-1606980162785:blk_1073741839_1015, type=LAST_IN_PIPELINE terminating
2020-12-03 07:22:47,832 [IPC Server handler 0 on default port 45114] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741840_1016, replicas=127.0.0.1:39276 for /TestUpgrade/file4
2020-12-03 07:22:47,835 [DataStreamer for file /TestUpgrade/file4] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:47,836 [DataXceiver for client DFSClient_NONMAPREDUCE_459844888_1 at /127.0.0.1:37444 [Receiving block BP-1584977637-172.17.0.10-1606980162785:blk_1073741840_1016]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1584977637-172.17.0.10-1606980162785:blk_1073741840_1016 src: /127.0.0.1:37444 dest: /127.0.0.1:39276
2020-12-03 07:22:47,840 [PacketResponder: BP-1584977637-172.17.0.10-1606980162785:blk_1073741840_1016, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37444, dest: /127.0.0.1:39276, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_459844888_1, offset: 0, srvID: f1d8177d-b4c6-4841-8546-addcebbb1ab1, blockid: BP-1584977637-172.17.0.10-1606980162785:blk_1073741840_1016, duration(ns): 2364790
2020-12-03 07:22:47,841 [PacketResponder: BP-1584977637-172.17.0.10-1606980162785:blk_1073741840_1016, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1584977637-172.17.0.10-1606980162785:blk_1073741840_1016, type=LAST_IN_PIPELINE terminating
2020-12-03 07:22:47,842 [IPC Server handler 1 on default port 45114] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /TestUpgrade/file4 is closed by DFSClient_NONMAPREDUCE_459844888_1
2020-12-03 07:22:47,843 [Listener at localhost/37597] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:22:47,843 [Listener at localhost/37597] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:22:47,844 [Listener at localhost/37597] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:22:47,844 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@1ce61929] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:22:47,845 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/datanodeMaster)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/datanodeMaster, DS-01c1f918-528d-470c-ad21-c7fd22eca90a) exiting.
2020-12-03 07:22:47,877 [Listener at localhost/37597] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5b58ed3c{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:22:47,881 [Listener at localhost/37597] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@24faea88{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:47,882 [Listener at localhost/37597] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@346a361{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:47,883 [Listener at localhost/37597] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2a3591c5{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:47,890 [Listener at localhost/37597] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 37597
2020-12-03 07:22:47,894 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:47,894 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:47,896 [BP-1584977637-172.17.0.10-1606980162785 heartbeating to localhost/127.0.0.1:45114] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:47,896 [BP-1584977637-172.17.0.10-1606980162785 heartbeating to localhost/127.0.0.1:45114] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1584977637-172.17.0.10-1606980162785 (Datanode Uuid f1d8177d-b4c6-4841-8546-addcebbb1ab1) service to localhost/127.0.0.1:45114
2020-12-03 07:22:47,897 [BP-1584977637-172.17.0.10-1606980162785 heartbeating to localhost/127.0.0.1:45114] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1584977637-172.17.0.10-1606980162785 (Datanode Uuid f1d8177d-b4c6-4841-8546-addcebbb1ab1)
2020-12-03 07:22:47,897 [BP-1584977637-172.17.0.10-1606980162785 heartbeating to localhost/127.0.0.1:45114] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1584977637-172.17.0.10-1606980162785
2020-12-03 07:22:47,899 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/datanodeMaster/current/BP-1584977637-172.17.0.10-1606980162785] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:47,901 [Listener at localhost/37597] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:22:47,901 [Listener at localhost/37597] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:22:47,902 [Listener at localhost/37597] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:22:47,902 [Listener at localhost/37597] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:22:47,908 [Listener at localhost/37597] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:22:47,908 [Listener at localhost/37597] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:22:47,908 [Listener at localhost/37597] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:22:47,909 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@2ece4966] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:22:47,909 [Listener at localhost/37597] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 32, 60
2020-12-03 07:22:47,909 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@47605f2f] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:22:47,910 [Listener at localhost/37597] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 30 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 9 Number of syncs: 22 SyncTimes(ms): 5 
2020-12-03 07:22:47,910 [Listener at localhost/37597] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/namenodeMaster/current/edits_inprogress_0000000000000000032 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/namenodeMaster/current/edits_0000000000000000032-0000000000000000061
2020-12-03 07:22:47,911 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:22:47,911 [CacheReplicationMonitor(2034055039)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:22:47,913 [Listener at localhost/37597] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 45114
2020-12-03 07:22:47,917 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:47,918 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:47,918 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:22:47,918 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:22:47,965 [Listener at localhost/37597] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:22:47,965 [Listener at localhost/37597] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:22:47,966 [Listener at localhost/37597] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@7a3793c7{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:22:47,969 [Listener at localhost/37597] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4c012563{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:47,970 [Listener at localhost/37597] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@71687585{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:47,970 [Listener at localhost/37597] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5c7bfdc1{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:47,971 [Listener at localhost/37597] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-12-03 07:22:47,973 [Listener at localhost/37597] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-12-03 07:22:47,974 [Listener at localhost/37597] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-12-03 07:22:48,001 [Listener at localhost/37597] INFO  hdfs.TestDFSFinalize (TestDFSFinalize.java:log(56)) - ============================================================
2020-12-03 07:22:48,002 [Listener at localhost/37597] INFO  hdfs.TestDFSFinalize (TestDFSFinalize.java:log(57)) - ***TEST 0*** Finalize NN & DN with existing previous dir: numDirs=1
2020-12-03 07:22:48,625 [Listener at localhost/37597] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=1
2020-12-03 07:22:48,625 [Listener at localhost/37597] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:22:48,627 [Listener at localhost/37597] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:22:48,631 [Listener at localhost/37597] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:22:48,633 [Listener at localhost/37597] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:22:48,633 [Listener at localhost/37597] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:22:48,634 [Listener at localhost/37597] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-12-03 07:22:48,642 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5b78fdb1] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:48,642 [Listener at localhost/37597] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:22:48,642 [Listener at localhost/37597] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:48,644 [Listener at localhost/37597] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:48,645 [Listener at localhost/37597] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:22:48,645 [Listener at localhost/37597] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:48,648 [Listener at localhost/37597] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:48,649 [Listener at localhost/37597] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:22:48,649 [Listener at localhost/37597] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:48,649 [Listener at localhost/37597] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:48,651 [Listener at localhost/37597] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:22:48,651 [Listener at localhost/37597] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:22:48,652 [Listener at localhost/37597] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 41248
2020-12-03 07:22:48,652 [Listener at localhost/37597] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:48,658 [Listener at localhost/37597] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@16fe9c29{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:48,658 [Listener at localhost/37597] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4525d1d3{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:48,666 [Listener at localhost/37597] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@34cf5a97{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:22:48,668 [Listener at localhost/37597] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@5b3f3ba0{HTTP/1.1,[http/1.1]}{localhost:41248}
2020-12-03 07:22:48,668 [Listener at localhost/37597] INFO  server.Server (Server.java:doStart(419)) - Started @7859ms
2020-12-03 07:22:48,669 [Listener at localhost/37597] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:22:48,669 [Listener at localhost/37597] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:22:48,669 [Listener at localhost/37597] WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(686)) - Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2020-12-03 07:22:48,670 [Listener at localhost/37597] WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(691)) - Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2020-12-03 07:22:48,670 [Listener at localhost/37597] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:22:48,670 [Listener at localhost/37597] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:22:48,673 [Listener at localhost/37597] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:22:48,673 [Listener at localhost/37597] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:22:48,673 [Listener at localhost/37597] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:22:48,674 [Listener at localhost/37597] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:22:48,674 [Listener at localhost/37597] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:22:48,674 [Listener at localhost/37597] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:22:48,674 [Listener at localhost/37597] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:22:48,675 [Listener at localhost/37597] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:22:48,675 [Listener at localhost/37597] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:48,676 [Listener at localhost/37597] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:22:48,676 [Listener at localhost/37597] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:22:48,676 [Listener at localhost/37597] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:22:48,677 [Listener at localhost/37597] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:22:48
2020-12-03 07:22:48,677 [Listener at localhost/37597] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:22:48,677 [Listener at localhost/37597] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:48,677 [Listener at localhost/37597] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-12-03 07:22:48,678 [Listener at localhost/37597] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:22:48,691 [Listener at localhost/37597] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:22:48,691 [Listener at localhost/37597] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:22:48,692 [Listener at localhost/37597] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:22:48,692 [Listener at localhost/37597] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:22:48,692 [Listener at localhost/37597] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:22:48,692 [Listener at localhost/37597] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:22:48,692 [Listener at localhost/37597] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 1
2020-12-03 07:22:48,693 [Listener at localhost/37597] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:22:48,693 [Listener at localhost/37597] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:22:48,693 [Listener at localhost/37597] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:22:48,693 [Listener at localhost/37597] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:22:48,693 [Listener at localhost/37597] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:22:48,693 [Listener at localhost/37597] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:22:48,694 [Listener at localhost/37597] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:22:48,694 [Listener at localhost/37597] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:48,694 [Listener at localhost/37597] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-12-03 07:22:48,694 [Listener at localhost/37597] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:22:48,700 [Listener at localhost/37597] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:22:48,701 [Listener at localhost/37597] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:22:48,701 [Listener at localhost/37597] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:22:48,701 [Listener at localhost/37597] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:22:48,701 [Listener at localhost/37597] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:22:48,701 [Listener at localhost/37597] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:22:48,701 [Listener at localhost/37597] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:22:48,702 [Listener at localhost/37597] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:48,702 [Listener at localhost/37597] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-12-03 07:22:48,702 [Listener at localhost/37597] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:22:48,704 [Listener at localhost/37597] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:22:48,704 [Listener at localhost/37597] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:22:48,704 [Listener at localhost/37597] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:22:48,705 [Listener at localhost/37597] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:22:48,706 [Listener at localhost/37597] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:22:48,706 [Listener at localhost/37597] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:22:48,706 [Listener at localhost/37597] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:48,706 [Listener at localhost/37597] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-12-03 07:22:48,706 [Listener at localhost/37597] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:22:48,777 [Listener at localhost/37597] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/in_use.lock acquired by nodename 5752@f8f6fab70ed3
2020-12-03 07:22:48,779 [Listener at localhost/37597] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current
2020-12-03 07:22:48,780 [Listener at localhost/37597] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031, cpktTxId=0000000000000000031)
2020-12-03 07:22:48,785 [Listener at localhost/37597] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 4 INodes.
2020-12-03 07:22:48,789 [Listener at localhost/37597] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:22:48,789 [Listener at localhost/37597] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 31 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031
2020-12-03 07:22:48,793 [Listener at localhost/37597] INFO  namenode.FSImage (FSImage.java:loadEdits(910)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@40021799 expecting start txid #32
2020-12-03 07:22:48,793 [Listener at localhost/37597] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061 maxTxnsToRead = 9223372036854775807
2020-12-03 07:22:48,795 [Listener at localhost/37597] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061' to transaction ID 32
2020-12-03 07:22:48,854 [Listener at localhost/37597] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(188)) - Loaded 1 edits file(s) (the last named /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061) of total size 1692.0, total edits 30.0, total load time 26.0 ms
2020-12-03 07:22:48,855 [Listener at localhost/37597] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:22:48,856 [Listener at localhost/37597] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 62
2020-12-03 07:22:48,921 [Listener at localhost/37597] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:22:48,921 [Listener at localhost/37597] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 214 msecs
2020-12-03 07:22:48,922 [Listener at localhost/37597] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:22:48,923 [Listener at localhost/37597] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:48,924 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:48,929 [Listener at localhost/46481] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:46481 to access this namenode/service.
2020-12-03 07:22:48,930 [Listener at localhost/46481] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:22:48,931 [Listener at localhost/46481] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:22:48,939 [Listener at localhost/46481] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:22:48,941 [Listener at localhost/46481] INFO  hdfs.StateChange (BlockManagerSafeMode.java:reportStatus(617)) - STATE* Safe mode ON. 
The reported blocks 0 needs additional 15 blocks to reach the threshold 0.9990 of total blocks 16.
The minimum number of live datanodes is not required. Safe mode will be turned off automatically once the thresholds have been reached.
2020-12-03 07:22:48,948 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:48,948 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:48,966 [Listener at localhost/46481] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:46481
2020-12-03 07:22:48,967 [Listener at localhost/46481] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:22:48,967 [Listener at localhost/46481] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:22:48,969 [Listener at localhost/46481] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 2 milliseconds
name space=6
storage space=16384
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:22:48,971 [Listener at localhost/46481] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:22:48,979 [CacheReplicationMonitor(170781695)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:22:48,981 [Listener at localhost/46481] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:22:48,983 [Listener at localhost/46481] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:22:48,983 [Listener at localhost/46481] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:48,983 [Listener at localhost/46481] INFO  datanode.BlockScanner (BlockScanner.java:<init>(187)) - Disabled block scanner.
2020-12-03 07:22:48,984 [Listener at localhost/46481] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:22:48,984 [Listener at localhost/46481] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:48,985 [Listener at localhost/46481] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:22:48,985 [Listener at localhost/46481] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:32928
2020-12-03 07:22:48,986 [Listener at localhost/46481] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:22:48,986 [Listener at localhost/46481] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:22:48,987 [Listener at localhost/46481] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:48,989 [Listener at localhost/46481] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:48,991 [Listener at localhost/46481] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:22:48,991 [Listener at localhost/46481] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:48,993 [Listener at localhost/46481] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:48,994 [Listener at localhost/46481] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:22:48,994 [Listener at localhost/46481] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:48,995 [Listener at localhost/46481] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:48,996 [Listener at localhost/46481] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 39355
2020-12-03 07:22:48,996 [Listener at localhost/46481] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:48,998 [Listener at localhost/46481] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@9a7a808{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:48,999 [Listener at localhost/46481] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2687f956{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:49,008 [Listener at localhost/46481] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@48ea2003{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:22:49,009 [Listener at localhost/46481] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6b1e7ad3{HTTP/1.1,[http/1.1]}{localhost:39355}
2020-12-03 07:22:49,009 [Listener at localhost/46481] INFO  server.Server (Server.java:doStart(419)) - Started @8200ms
2020-12-03 07:22:49,162 [Listener at localhost/46481] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:34371
2020-12-03 07:22:49,163 [Listener at localhost/46481] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:22:49,163 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@13a37e2a] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:49,163 [Listener at localhost/46481] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:22:49,164 [Listener at localhost/46481] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:49,164 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:49,169 [Listener at localhost/42403] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:42403
2020-12-03 07:22:49,174 [Listener at localhost/42403] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:22:49,175 [Listener at localhost/42403] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:22:49,176 [Thread-182] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46481 starting to offer service
2020-12-03 07:22:49,178 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:49,178 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:49,187 [Thread-182] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46481
2020-12-03 07:22:49,192 [Thread-182] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2020-12-03 07:22:49,197 [IPC Server handler 3 on default port 46481] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:49,198 [Listener at localhost/42403] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:49,198 [Listener at localhost/42403] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:49,235 [Thread-182] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/in_use.lock acquired by nodename 5752@f8f6fab70ed3
2020-12-03 07:22:49,303 [IPC Server handler 4 on default port 46481] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:49,306 [Listener at localhost/42403] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:49,307 [Listener at localhost/42403] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:49,320 [Thread-182] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1584977637-172.17.0.10-1606980162785
2020-12-03 07:22:49,320 [Thread-182] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-1584977637-172.17.0.10-1606980162785
2020-12-03 07:22:49,373 [Thread-182] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=60730268;bpid=BP-1584977637-172.17.0.10-1606980162785;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=60730268;c=1606980162785;bpid=BP-1584977637-172.17.0.10-1606980162785;dnuuid=f1d8177d-b4c6-4841-8546-addcebbb1ab1
2020-12-03 07:22:49,375 [Thread-182] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-01c1f918-528d-470c-ad21-c7fd22eca90a
2020-12-03 07:22:49,375 [Thread-182] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1, StorageType: DISK
2020-12-03 07:22:49,376 [Thread-182] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:22:49,377 [Thread-182] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:22:49,378 [Thread-182] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:22:49,379 [Thread-182] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1584977637-172.17.0.10-1606980162785
2020-12-03 07:22:49,379 [Thread-195] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1584977637-172.17.0.10-1606980162785 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1...
2020-12-03 07:22:49,389 [Thread-195] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-1584977637-172.17.0.10-1606980162785/current: 41200
2020-12-03 07:22:49,399 [Thread-195] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1584977637-172.17.0.10-1606980162785 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1: 19ms
2020-12-03 07:22:49,399 [Thread-182] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1584977637-172.17.0.10-1606980162785: 21ms
2020-12-03 07:22:49,400 [Thread-196] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1584977637-172.17.0.10-1606980162785 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1...
2020-12-03 07:22:49,404 [Thread-196] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(925)) - Successfully read replica from cache file : /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-1584977637-172.17.0.10-1606980162785/current/replicas
2020-12-03 07:22:49,405 [Thread-196] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1584977637-172.17.0.10-1606980162785 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1: 5ms
2020-12-03 07:22:49,405 [Thread-182] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1584977637-172.17.0.10-1606980162785: 5ms
2020-12-03 07:22:49,406 [Thread-182] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 8:17 AM with interval of 21600000ms
2020-12-03 07:22:49,408 [BP-1584977637-172.17.0.10-1606980162785 heartbeating to localhost/127.0.0.1:46481] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1584977637-172.17.0.10-1606980162785 (Datanode Uuid f1d8177d-b4c6-4841-8546-addcebbb1ab1) service to localhost/127.0.0.1:46481 beginning handshake with NN
2020-12-03 07:22:49,409 [IPC Server handler 5 on default port 46481] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:49,410 [Listener at localhost/42403] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:49,410 [Listener at localhost/42403] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:49,410 [IPC Server handler 6 on default port 46481] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:32928, datanodeUuid=f1d8177d-b4c6-4841-8546-addcebbb1ab1, infoPort=34371, infoSecurePort=0, ipcPort=42403, storageInfo=lv=-57;cid=testClusterID;nsid=60730268;c=1606980162785) storage f1d8177d-b4c6-4841-8546-addcebbb1ab1
2020-12-03 07:22:49,410 [IPC Server handler 6 on default port 46481] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:32928
2020-12-03 07:22:49,410 [IPC Server handler 6 on default port 46481] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN f1d8177d-b4c6-4841-8546-addcebbb1ab1 (127.0.0.1:32928).
2020-12-03 07:22:49,413 [BP-1584977637-172.17.0.10-1606980162785 heartbeating to localhost/127.0.0.1:46481] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1584977637-172.17.0.10-1606980162785 (Datanode Uuid f1d8177d-b4c6-4841-8546-addcebbb1ab1) service to localhost/127.0.0.1:46481 successfully registered with NN
2020-12-03 07:22:49,413 [BP-1584977637-172.17.0.10-1606980162785 heartbeating to localhost/127.0.0.1:46481] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:46481 using BLOCKREPORT_INTERVAL of 10000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:22:49,416 [IPC Server handler 7 on default port 46481] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-01c1f918-528d-470c-ad21-c7fd22eca90a for DN 127.0.0.1:32928
2020-12-03 07:22:49,420 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x5f7b9a1d1bb349de: Processing first storage report for DS-01c1f918-528d-470c-ad21-c7fd22eca90a from datanode f1d8177d-b4c6-4841-8546-addcebbb1ab1
2020-12-03 07:22:49,421 [Block report processor] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:22:49,422 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(395)) - STATE* Safe mode is OFF
2020-12-03 07:22:49,422 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:22:49,423 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 1 racks and 1 datanodes
2020-12-03 07:22:49,423 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:22:49,425 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x5f7b9a1d1bb349de: from storage DS-01c1f918-528d-470c-ad21-c7fd22eca90a node DatanodeRegistration(127.0.0.1:32928, datanodeUuid=f1d8177d-b4c6-4841-8546-addcebbb1ab1, infoPort=34371, infoSecurePort=0, ipcPort=42403, storageInfo=lv=-57;cid=testClusterID;nsid=60730268;c=1606980162785), blocks: 16, hasStaleStorage: false, processing time: 5 msecs, invalidatedBlocks: 0
2020-12-03 07:22:49,432 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 16
2020-12-03 07:22:49,432 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:22:49,432 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:22:49,432 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:22:49,433 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:22:49,433 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 10 msec
2020-12-03 07:22:49,434 [BP-1584977637-172.17.0.10-1606980162785 heartbeating to localhost/127.0.0.1:46481] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x5f7b9a1d1bb349de,  containing 1 storage report(s), of which we sent 1. The reports had 16 total blocks and used 1 RPC(s). This took 0 msec to generate and 15 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:22:49,511 [IPC Server handler 9 on default port 46481] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:49,513 [Listener at localhost/42403] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:22:49,538 [IPC Server handler 1 on default port 46481] INFO  namenode.FSImage (FSImage.java:finalizeUpgrade(614)) - Finalizing upgrade for local dirs. 
   cur LV = -65; cur CTime = 1606980162785
2020-12-03 07:22:49,539 [IPC Server handler 1 on default port 46481] INFO  namenode.NNUpgradeUtil (NNUpgradeUtil.java:doFinalize(95)) - Finalizing upgrade of storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1
2020-12-03 07:22:49,541 [IPC Server handler 1 on default port 46481] INFO  namenode.NNUpgradeUtil (NNUpgradeUtil.java:doFinalize(102)) - Finalize upgrade for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 is complete.
2020-12-03 07:22:49,541 [IPC Server handler 1 on default port 46481] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=finalizeUpgrade	src=null	dst=null	perm=null	proto=rpc
Finalize upgrade successful
2020-12-03 07:22:49,545 [BP-1584977637-172.17.0.10-1606980162785 heartbeating to localhost/127.0.0.1:46481] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:46481
2020-12-03 07:22:49,548 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x5f7b9a1d1bb349df: from storage DS-01c1f918-528d-470c-ad21-c7fd22eca90a node DatanodeRegistration(127.0.0.1:32928, datanodeUuid=f1d8177d-b4c6-4841-8546-addcebbb1ab1, infoPort=34371, infoSecurePort=0, ipcPort=42403, storageInfo=lv=-57;cid=testClusterID;nsid=60730268;c=1606980162785), blocks: 16, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:49,549 [BP-1584977637-172.17.0.10-1606980162785 heartbeating to localhost/127.0.0.1:46481] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x5f7b9a1d1bb349df,  containing 1 storage report(s), of which we sent 1. The reports had 16 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:49,549 [BP-1584977637-172.17.0.10-1606980162785 heartbeating to localhost/127.0.0.1:46481] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1584977637-172.17.0.10-1606980162785
2020-12-03 07:22:49,549 [BP-1584977637-172.17.0.10-1606980162785 heartbeating to localhost/127.0.0.1:46481] INFO  common.Storage (DataStorage.java:doFinalize(970)) - Finalizing upgrade for storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1.
   cur LV = -57; cur CTime = 0
2020-12-03 07:22:49,557 [Finalize /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1] INFO  common.Storage (DataStorage.java:run(993)) - Finalize upgrade for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1 is complete
2020-12-03 07:22:50,851 [Listener at localhost/42403] INFO  hdfs.TestDFSFinalize (TestDFSFinalize.java:log(56)) - ============================================================
2020-12-03 07:22:50,851 [Listener at localhost/42403] INFO  hdfs.TestDFSFinalize (TestDFSFinalize.java:log(57)) - ***TEST 1*** Finalize NN & DN without existing previous dir: numDirs=1
2020-12-03 07:22:50,853 [IPC Server handler 3 on default port 46481] INFO  namenode.FSImage (FSImage.java:finalizeUpgrade(614)) - Finalizing upgrade for local dirs. 
   cur LV = -65; cur CTime = 1606980162785
2020-12-03 07:22:50,853 [IPC Server handler 3 on default port 46481] INFO  namenode.NNUpgradeUtil (NNUpgradeUtil.java:doFinalize(91)) - Directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/previous does not exist.
2020-12-03 07:22:50,854 [IPC Server handler 3 on default port 46481] INFO  namenode.NNUpgradeUtil (NNUpgradeUtil.java:doFinalize(92)) - Finalize upgrade for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 is not required.
2020-12-03 07:22:50,854 [IPC Server handler 3 on default port 46481] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=finalizeUpgrade	src=null	dst=null	perm=null	proto=rpc
Finalize upgrade successful
2020-12-03 07:22:50,860 [BP-1584977637-172.17.0.10-1606980162785 heartbeating to localhost/127.0.0.1:46481] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:46481
2020-12-03 07:22:50,863 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x5f7b9a1d1bb349e0: from storage DS-01c1f918-528d-470c-ad21-c7fd22eca90a node DatanodeRegistration(127.0.0.1:32928, datanodeUuid=f1d8177d-b4c6-4841-8546-addcebbb1ab1, infoPort=34371, infoSecurePort=0, ipcPort=42403, storageInfo=lv=-57;cid=testClusterID;nsid=60730268;c=1606980162785), blocks: 16, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:50,864 [BP-1584977637-172.17.0.10-1606980162785 heartbeating to localhost/127.0.0.1:46481] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x5f7b9a1d1bb349e0,  containing 1 storage report(s), of which we sent 1. The reports had 16 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:50,864 [BP-1584977637-172.17.0.10-1606980162785 heartbeating to localhost/127.0.0.1:46481] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1584977637-172.17.0.10-1606980162785
2020-12-03 07:22:51,961 [Listener at localhost/42403] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:22:51,961 [Listener at localhost/42403] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:22:51,962 [Listener at localhost/42403] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:22:51,962 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@2b97cc1f] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:22:52,236 [Listener at localhost/42403] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@48ea2003{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:22:52,237 [Listener at localhost/42403] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6b1e7ad3{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:52,239 [Listener at localhost/42403] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2687f956{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:52,239 [Listener at localhost/42403] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@9a7a808{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:52,246 [Listener at localhost/42403] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 42403
2020-12-03 07:22:52,251 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:52,252 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:52,253 [BP-1584977637-172.17.0.10-1606980162785 heartbeating to localhost/127.0.0.1:46481] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:52,253 [BP-1584977637-172.17.0.10-1606980162785 heartbeating to localhost/127.0.0.1:46481] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1584977637-172.17.0.10-1606980162785 (Datanode Uuid f1d8177d-b4c6-4841-8546-addcebbb1ab1) service to localhost/127.0.0.1:46481
2020-12-03 07:22:52,253 [BP-1584977637-172.17.0.10-1606980162785 heartbeating to localhost/127.0.0.1:46481] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1584977637-172.17.0.10-1606980162785 (Datanode Uuid f1d8177d-b4c6-4841-8546-addcebbb1ab1)
2020-12-03 07:22:52,253 [BP-1584977637-172.17.0.10-1606980162785 heartbeating to localhost/127.0.0.1:46481] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1584977637-172.17.0.10-1606980162785
2020-12-03 07:22:52,254 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-1584977637-172.17.0.10-1606980162785] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:52,259 [Listener at localhost/42403] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:22:52,259 [Listener at localhost/42403] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:22:52,260 [Listener at localhost/42403] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:22:52,260 [Listener at localhost/42403] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:22:52,262 [Listener at localhost/42403] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:22:52,262 [Listener at localhost/42403] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:22:52,262 [Listener at localhost/42403] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:22:52,263 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@703feacd] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:22:52,264 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@68809cc7] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:22:52,281 [Listener at localhost/42403] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 62, 62
2020-12-03 07:22:52,284 [Listener at localhost/42403] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 2 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 61 Number of syncs: 3 SyncTimes(ms): 3 
2020-12-03 07:22:52,286 [Listener at localhost/42403] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_inprogress_0000000000000000062 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000062-0000000000000000063
2020-12-03 07:22:52,286 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:22:52,287 [CacheReplicationMonitor(170781695)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:22:52,287 [Listener at localhost/42403] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 46481
2020-12-03 07:22:52,301 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:52,302 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:22:52,302 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:22:52,304 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:52,313 [Listener at localhost/42403] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:22:52,314 [Listener at localhost/42403] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:22:52,318 [Listener at localhost/42403] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@34cf5a97{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:22:52,320 [Listener at localhost/42403] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@5b3f3ba0{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:52,320 [Listener at localhost/42403] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4525d1d3{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:52,321 [Listener at localhost/42403] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@16fe9c29{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:52,334 [Listener at localhost/42403] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-12-03 07:22:52,336 [Listener at localhost/42403] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-12-03 07:22:52,337 [Listener at localhost/42403] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-12-03 07:22:52,352 [Listener at localhost/42403] INFO  hdfs.TestDFSFinalize (TestDFSFinalize.java:log(56)) - ============================================================
2020-12-03 07:22:52,352 [Listener at localhost/42403] INFO  hdfs.TestDFSFinalize (TestDFSFinalize.java:log(57)) - ***TEST 2*** Finalize NN & BP with existing previous dir: numDirs=1
2020-12-03 07:22:52,726 [Listener at localhost/42403] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=1
2020-12-03 07:22:52,727 [Listener at localhost/42403] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:22:52,728 [Listener at localhost/42403] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:22:52,731 [Listener at localhost/42403] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:22:52,734 [Listener at localhost/42403] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:22:52,734 [Listener at localhost/42403] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:22:52,735 [Listener at localhost/42403] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-12-03 07:22:52,741 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@66ec9390] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:52,742 [Listener at localhost/42403] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:22:52,742 [Listener at localhost/42403] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:52,747 [Listener at localhost/42403] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:52,748 [Listener at localhost/42403] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:22:52,748 [Listener at localhost/42403] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:52,751 [Listener at localhost/42403] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:52,751 [Listener at localhost/42403] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:22:52,752 [Listener at localhost/42403] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:52,752 [Listener at localhost/42403] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:52,754 [Listener at localhost/42403] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:22:52,755 [Listener at localhost/42403] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:22:52,755 [Listener at localhost/42403] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 44225
2020-12-03 07:22:52,756 [Listener at localhost/42403] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:52,759 [Listener at localhost/42403] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5b12012e{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:52,760 [Listener at localhost/42403] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4a3be6a5{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:52,778 [Listener at localhost/42403] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@64aad6db{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:22:52,785 [Listener at localhost/42403] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@ae7950d{HTTP/1.1,[http/1.1]}{localhost:44225}
2020-12-03 07:22:52,786 [Listener at localhost/42403] INFO  server.Server (Server.java:doStart(419)) - Started @11976ms
2020-12-03 07:22:52,786 [Listener at localhost/42403] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:22:52,787 [Listener at localhost/42403] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:22:52,787 [Listener at localhost/42403] WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(686)) - Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2020-12-03 07:22:52,787 [Listener at localhost/42403] WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(691)) - Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2020-12-03 07:22:52,787 [Listener at localhost/42403] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:22:52,788 [Listener at localhost/42403] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:22:52,790 [Listener at localhost/42403] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:22:52,790 [Listener at localhost/42403] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:22:52,791 [Listener at localhost/42403] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:22:52,791 [Listener at localhost/42403] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:22:52,791 [Listener at localhost/42403] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:22:52,791 [Listener at localhost/42403] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:22:52,792 [Listener at localhost/42403] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:22:52,792 [Listener at localhost/42403] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:22:52,803 [Listener at localhost/42403] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:52,804 [Listener at localhost/42403] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:22:52,804 [Listener at localhost/42403] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:22:52,804 [Listener at localhost/42403] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:22:52,805 [Listener at localhost/42403] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:22:52
2020-12-03 07:22:52,805 [Listener at localhost/42403] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:22:52,805 [Listener at localhost/42403] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:52,806 [Listener at localhost/42403] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-12-03 07:22:52,806 [Listener at localhost/42403] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:22:52,810 [Listener at localhost/42403] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:22:52,811 [Listener at localhost/42403] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:22:52,811 [Listener at localhost/42403] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:22:52,812 [Listener at localhost/42403] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:22:52,812 [Listener at localhost/42403] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:22:52,812 [Listener at localhost/42403] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:22:52,812 [Listener at localhost/42403] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 1
2020-12-03 07:22:52,812 [Listener at localhost/42403] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:22:52,813 [Listener at localhost/42403] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:22:52,813 [Listener at localhost/42403] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:22:52,813 [Listener at localhost/42403] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:22:52,813 [Listener at localhost/42403] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:22:52,813 [Listener at localhost/42403] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:22:52,814 [Listener at localhost/42403] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:22:52,814 [Listener at localhost/42403] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:52,815 [Listener at localhost/42403] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-12-03 07:22:52,815 [Listener at localhost/42403] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:22:52,818 [Listener at localhost/42403] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:22:52,818 [Listener at localhost/42403] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:22:52,819 [Listener at localhost/42403] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:22:52,819 [Listener at localhost/42403] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:22:52,819 [Listener at localhost/42403] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:22:52,819 [Listener at localhost/42403] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:22:52,820 [Listener at localhost/42403] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:22:52,820 [Listener at localhost/42403] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:52,820 [Listener at localhost/42403] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-12-03 07:22:52,821 [Listener at localhost/42403] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:22:52,822 [Listener at localhost/42403] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:22:52,822 [Listener at localhost/42403] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:22:52,822 [Listener at localhost/42403] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:22:52,824 [Listener at localhost/42403] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:22:52,824 [Listener at localhost/42403] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:22:52,824 [Listener at localhost/42403] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:22:52,824 [Listener at localhost/42403] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:52,825 [Listener at localhost/42403] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-12-03 07:22:52,825 [Listener at localhost/42403] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:22:52,858 [Listener at localhost/42403] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/in_use.lock acquired by nodename 5752@f8f6fab70ed3
2020-12-03 07:22:52,859 [Listener at localhost/42403] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current
2020-12-03 07:22:52,860 [Listener at localhost/42403] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031, cpktTxId=0000000000000000031)
2020-12-03 07:22:52,863 [Listener at localhost/42403] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 4 INodes.
2020-12-03 07:22:52,864 [Listener at localhost/42403] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:22:52,865 [Listener at localhost/42403] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 31 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031
2020-12-03 07:22:52,865 [Listener at localhost/42403] INFO  namenode.FSImage (FSImage.java:loadEdits(910)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@2822c6ff expecting start txid #32
2020-12-03 07:22:52,865 [Listener at localhost/42403] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061 maxTxnsToRead = 9223372036854775807
2020-12-03 07:22:52,866 [Listener at localhost/42403] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061' to transaction ID 32
2020-12-03 07:22:52,871 [Listener at localhost/42403] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(188)) - Loaded 1 edits file(s) (the last named /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061) of total size 1692.0, total edits 30.0, total load time 5.0 ms
2020-12-03 07:22:52,871 [Listener at localhost/42403] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:22:52,872 [Listener at localhost/42403] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 62
2020-12-03 07:22:52,935 [Listener at localhost/42403] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:22:52,935 [Listener at localhost/42403] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 108 msecs
2020-12-03 07:22:52,935 [Listener at localhost/42403] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:22:52,936 [Listener at localhost/42403] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:52,937 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:52,941 [Listener at localhost/40000] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:40000 to access this namenode/service.
2020-12-03 07:22:52,942 [Listener at localhost/40000] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:22:52,942 [Listener at localhost/40000] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:22:52,951 [Listener at localhost/40000] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:22:52,952 [Listener at localhost/40000] INFO  hdfs.StateChange (BlockManagerSafeMode.java:reportStatus(617)) - STATE* Safe mode ON. 
The reported blocks 0 needs additional 15 blocks to reach the threshold 0.9990 of total blocks 16.
The minimum number of live datanodes is not required. Safe mode will be turned off automatically once the thresholds have been reached.
2020-12-03 07:22:52,956 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:52,956 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:52,959 [Listener at localhost/40000] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:40000
2020-12-03 07:22:52,960 [Listener at localhost/40000] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:22:52,960 [Listener at localhost/40000] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:22:52,961 [Listener at localhost/40000] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 1 milliseconds
name space=6
storage space=16384
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:22:52,964 [CacheReplicationMonitor(104918161)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:22:52,965 [Listener at localhost/40000] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:22:52,967 [Listener at localhost/40000] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:22:52,968 [Listener at localhost/40000] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:22:52,968 [Listener at localhost/40000] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:52,968 [Listener at localhost/40000] INFO  datanode.BlockScanner (BlockScanner.java:<init>(187)) - Disabled block scanner.
2020-12-03 07:22:52,969 [Listener at localhost/40000] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:22:52,969 [Listener at localhost/40000] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:52,970 [Listener at localhost/40000] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:22:52,970 [Listener at localhost/40000] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:39687
2020-12-03 07:22:52,971 [Listener at localhost/40000] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:22:52,971 [Listener at localhost/40000] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:22:52,972 [Listener at localhost/40000] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:52,974 [Listener at localhost/40000] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:52,975 [Listener at localhost/40000] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:22:52,975 [Listener at localhost/40000] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:52,978 [Listener at localhost/40000] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:52,979 [Listener at localhost/40000] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:22:52,979 [Listener at localhost/40000] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:52,979 [Listener at localhost/40000] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:52,980 [Listener at localhost/40000] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 36351
2020-12-03 07:22:52,980 [Listener at localhost/40000] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:52,982 [Listener at localhost/40000] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@719843e5{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:52,987 [Listener at localhost/40000] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@58112bc4{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:52,997 [Listener at localhost/40000] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@17271176{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:22:52,999 [Listener at localhost/40000] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2e3cdec2{HTTP/1.1,[http/1.1]}{localhost:36351}
2020-12-03 07:22:52,999 [Listener at localhost/40000] INFO  server.Server (Server.java:doStart(419)) - Started @12190ms
2020-12-03 07:22:53,028 [Listener at localhost/40000] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:41116
2020-12-03 07:22:53,029 [Listener at localhost/40000] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:22:53,029 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3051e0b2] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:53,029 [Listener at localhost/40000] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:22:53,030 [Listener at localhost/40000] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:53,031 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:53,036 [Listener at localhost/39151] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:39151
2020-12-03 07:22:53,042 [Listener at localhost/39151] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:22:53,043 [Listener at localhost/39151] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:22:53,044 [Thread-250] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40000 starting to offer service
2020-12-03 07:22:53,048 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:53,048 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:53,059 [Thread-250] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40000
2020-12-03 07:22:53,074 [Thread-250] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2020-12-03 07:22:53,076 [IPC Server handler 1 on default port 40000] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:53,079 [Listener at localhost/39151] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:53,079 [Listener at localhost/39151] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:53,182 [IPC Server handler 2 on default port 40000] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:53,184 [Listener at localhost/39151] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:53,184 [Listener at localhost/39151] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:53,286 [IPC Server handler 3 on default port 40000] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:53,287 [Listener at localhost/39151] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:53,287 [Listener at localhost/39151] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:53,388 [IPC Server handler 4 on default port 40000] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:53,389 [Listener at localhost/39151] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:53,389 [Listener at localhost/39151] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:53,465 [Thread-250] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/in_use.lock acquired by nodename 5752@f8f6fab70ed3
2020-12-03 07:22:53,491 [IPC Server handler 5 on default port 40000] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:53,492 [Listener at localhost/39151] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:53,492 [Listener at localhost/39151] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:53,513 [Thread-250] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1584977637-172.17.0.10-1606980162785
2020-12-03 07:22:53,514 [Thread-250] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-1584977637-172.17.0.10-1606980162785
2020-12-03 07:22:53,594 [IPC Server handler 6 on default port 40000] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:53,595 [Listener at localhost/39151] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:53,595 [Listener at localhost/39151] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:53,594 [Thread-250] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=60730268;bpid=BP-1584977637-172.17.0.10-1606980162785;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=60730268;c=1606980162785;bpid=BP-1584977637-172.17.0.10-1606980162785;dnuuid=f1d8177d-b4c6-4841-8546-addcebbb1ab1
2020-12-03 07:22:53,599 [Thread-250] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-41883aee-cd67-4501-bed9-db37172521d6
2020-12-03 07:22:53,599 [Thread-250] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1, StorageType: DISK
2020-12-03 07:22:53,600 [Thread-250] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:22:53,601 [Thread-250] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:22:53,602 [Thread-250] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:22:53,602 [Thread-250] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1584977637-172.17.0.10-1606980162785
2020-12-03 07:22:53,602 [Thread-263] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1584977637-172.17.0.10-1606980162785 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1...
2020-12-03 07:22:53,605 [Thread-263] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-1584977637-172.17.0.10-1606980162785/current: 41200
2020-12-03 07:22:53,614 [Thread-263] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1584977637-172.17.0.10-1606980162785 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1: 11ms
2020-12-03 07:22:53,614 [Thread-250] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1584977637-172.17.0.10-1606980162785: 12ms
2020-12-03 07:22:53,615 [Thread-264] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1584977637-172.17.0.10-1606980162785 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1...
2020-12-03 07:22:53,617 [Thread-264] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(925)) - Successfully read replica from cache file : /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-1584977637-172.17.0.10-1606980162785/current/replicas
2020-12-03 07:22:53,617 [Thread-264] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1584977637-172.17.0.10-1606980162785 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1: 2ms
2020-12-03 07:22:53,617 [Thread-250] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1584977637-172.17.0.10-1606980162785: 2ms
2020-12-03 07:22:53,617 [Thread-250] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 9:17 AM with interval of 21600000ms
2020-12-03 07:22:53,621 [BP-1584977637-172.17.0.10-1606980162785 heartbeating to localhost/127.0.0.1:40000] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1584977637-172.17.0.10-1606980162785 (Datanode Uuid f1d8177d-b4c6-4841-8546-addcebbb1ab1) service to localhost/127.0.0.1:40000 beginning handshake with NN
2020-12-03 07:22:53,622 [IPC Server handler 7 on default port 40000] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:39687, datanodeUuid=f1d8177d-b4c6-4841-8546-addcebbb1ab1, infoPort=41116, infoSecurePort=0, ipcPort=39151, storageInfo=lv=-57;cid=testClusterID;nsid=60730268;c=1606980162785) storage f1d8177d-b4c6-4841-8546-addcebbb1ab1
2020-12-03 07:22:53,623 [IPC Server handler 7 on default port 40000] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:39687
2020-12-03 07:22:53,623 [IPC Server handler 7 on default port 40000] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN f1d8177d-b4c6-4841-8546-addcebbb1ab1 (127.0.0.1:39687).
2020-12-03 07:22:53,626 [BP-1584977637-172.17.0.10-1606980162785 heartbeating to localhost/127.0.0.1:40000] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1584977637-172.17.0.10-1606980162785 (Datanode Uuid f1d8177d-b4c6-4841-8546-addcebbb1ab1) service to localhost/127.0.0.1:40000 successfully registered with NN
2020-12-03 07:22:53,626 [BP-1584977637-172.17.0.10-1606980162785 heartbeating to localhost/127.0.0.1:40000] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:40000 using BLOCKREPORT_INTERVAL of 10000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:22:53,629 [IPC Server handler 8 on default port 40000] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-41883aee-cd67-4501-bed9-db37172521d6 for DN 127.0.0.1:39687
2020-12-03 07:22:53,631 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xf049be06760b295a: Processing first storage report for DS-41883aee-cd67-4501-bed9-db37172521d6 from datanode f1d8177d-b4c6-4841-8546-addcebbb1ab1
2020-12-03 07:22:53,632 [Block report processor] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:22:53,636 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(395)) - STATE* Safe mode is OFF
2020-12-03 07:22:53,636 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:22:53,636 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 1 racks and 1 datanodes
2020-12-03 07:22:53,637 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:22:53,638 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xf049be06760b295a: from storage DS-41883aee-cd67-4501-bed9-db37172521d6 node DatanodeRegistration(127.0.0.1:39687, datanodeUuid=f1d8177d-b4c6-4841-8546-addcebbb1ab1, infoPort=41116, infoSecurePort=0, ipcPort=39151, storageInfo=lv=-57;cid=testClusterID;nsid=60730268;c=1606980162785), blocks: 16, hasStaleStorage: false, processing time: 7 msecs, invalidatedBlocks: 0
2020-12-03 07:22:53,644 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 16
2020-12-03 07:22:53,644 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:22:53,644 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:22:53,645 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:22:53,645 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:22:53,645 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 8 msec
2020-12-03 07:22:53,646 [BP-1584977637-172.17.0.10-1606980162785 heartbeating to localhost/127.0.0.1:40000] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xf049be06760b295a,  containing 1 storage report(s), of which we sent 1. The reports had 16 total blocks and used 1 RPC(s). This took 0 msec to generate and 16 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:22:53,697 [IPC Server handler 0 on default port 40000] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:53,698 [Listener at localhost/39151] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:22:53,703 [IPC Server handler 1 on default port 40000] INFO  namenode.FSImage (FSImage.java:finalizeUpgrade(614)) - Finalizing upgrade for local dirs. 
   cur LV = -65; cur CTime = 1606980162785
2020-12-03 07:22:53,703 [IPC Server handler 1 on default port 40000] INFO  namenode.NNUpgradeUtil (NNUpgradeUtil.java:doFinalize(95)) - Finalizing upgrade of storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1
2020-12-03 07:22:53,704 [IPC Server handler 1 on default port 40000] INFO  namenode.NNUpgradeUtil (NNUpgradeUtil.java:doFinalize(102)) - Finalize upgrade for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 is complete.
2020-12-03 07:22:53,704 [IPC Server handler 1 on default port 40000] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=finalizeUpgrade	src=null	dst=null	perm=null	proto=rpc
Finalize upgrade successful
2020-12-03 07:22:53,708 [BP-1584977637-172.17.0.10-1606980162785 heartbeating to localhost/127.0.0.1:40000] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:40000
2020-12-03 07:22:53,709 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xf049be06760b295b: from storage DS-41883aee-cd67-4501-bed9-db37172521d6 node DatanodeRegistration(127.0.0.1:39687, datanodeUuid=f1d8177d-b4c6-4841-8546-addcebbb1ab1, infoPort=41116, infoSecurePort=0, ipcPort=39151, storageInfo=lv=-57;cid=testClusterID;nsid=60730268;c=1606980162785), blocks: 16, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:22:53,710 [BP-1584977637-172.17.0.10-1606980162785 heartbeating to localhost/127.0.0.1:40000] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xf049be06760b295b,  containing 1 storage report(s), of which we sent 1. The reports had 16 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:53,710 [BP-1584977637-172.17.0.10-1606980162785 heartbeating to localhost/127.0.0.1:40000] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1584977637-172.17.0.10-1606980162785
2020-12-03 07:22:53,711 [BP-1584977637-172.17.0.10-1606980162785 heartbeating to localhost/127.0.0.1:40000] INFO  common.Storage (BlockPoolSliceStorage.java:doFinalize(652)) - Finalizing upgrade for storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-1584977637-172.17.0.10-1606980162785.
   cur LV = -57; cur CTime = 1606980162785
2020-12-03 07:22:53,714 [Finalize /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-1584977637-172.17.0.10-1606980162785] INFO  common.Storage (BlockPoolSliceStorage.java:run(670)) - Finalize upgrade for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-1584977637-172.17.0.10-1606980162785 is complete.
2020-12-03 07:22:54,814 [Listener at localhost/39151] INFO  hdfs.TestDFSFinalize (TestDFSFinalize.java:log(56)) - ============================================================
2020-12-03 07:22:54,814 [Listener at localhost/39151] INFO  hdfs.TestDFSFinalize (TestDFSFinalize.java:log(57)) - ***TEST 3*** Finalize NN & BP without existing previous dir: numDirs=1
2020-12-03 07:22:54,816 [IPC Server handler 4 on default port 40000] INFO  namenode.FSImage (FSImage.java:finalizeUpgrade(614)) - Finalizing upgrade for local dirs. 
   cur LV = -65; cur CTime = 1606980162785
2020-12-03 07:22:54,816 [IPC Server handler 4 on default port 40000] INFO  namenode.NNUpgradeUtil (NNUpgradeUtil.java:doFinalize(91)) - Directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/previous does not exist.
2020-12-03 07:22:54,816 [IPC Server handler 4 on default port 40000] INFO  namenode.NNUpgradeUtil (NNUpgradeUtil.java:doFinalize(92)) - Finalize upgrade for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 is not required.
2020-12-03 07:22:54,817 [IPC Server handler 4 on default port 40000] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=finalizeUpgrade	src=null	dst=null	perm=null	proto=rpc
Finalize upgrade successful
2020-12-03 07:22:54,826 [BP-1584977637-172.17.0.10-1606980162785 heartbeating to localhost/127.0.0.1:40000] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:40000
2020-12-03 07:22:54,829 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xf049be06760b295c: from storage DS-41883aee-cd67-4501-bed9-db37172521d6 node DatanodeRegistration(127.0.0.1:39687, datanodeUuid=f1d8177d-b4c6-4841-8546-addcebbb1ab1, infoPort=41116, infoSecurePort=0, ipcPort=39151, storageInfo=lv=-57;cid=testClusterID;nsid=60730268;c=1606980162785), blocks: 16, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:22:54,829 [BP-1584977637-172.17.0.10-1606980162785 heartbeating to localhost/127.0.0.1:40000] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xf049be06760b295c,  containing 1 storage report(s), of which we sent 1. The reports had 16 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:54,829 [BP-1584977637-172.17.0.10-1606980162785 heartbeating to localhost/127.0.0.1:40000] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1584977637-172.17.0.10-1606980162785
2020-12-03 07:22:55,927 [Listener at localhost/39151] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:22:55,927 [Listener at localhost/39151] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:22:55,928 [Listener at localhost/39151] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:22:55,928 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@15bc339] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:22:55,948 [Listener at localhost/39151] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@17271176{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:22:55,949 [Listener at localhost/39151] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2e3cdec2{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:55,949 [Listener at localhost/39151] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@58112bc4{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:55,950 [Listener at localhost/39151] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@719843e5{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:55,951 [Listener at localhost/39151] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 39151
2020-12-03 07:22:55,952 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:55,952 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:55,952 [BP-1584977637-172.17.0.10-1606980162785 heartbeating to localhost/127.0.0.1:40000] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:55,953 [BP-1584977637-172.17.0.10-1606980162785 heartbeating to localhost/127.0.0.1:40000] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1584977637-172.17.0.10-1606980162785 (Datanode Uuid f1d8177d-b4c6-4841-8546-addcebbb1ab1) service to localhost/127.0.0.1:40000
2020-12-03 07:22:55,954 [BP-1584977637-172.17.0.10-1606980162785 heartbeating to localhost/127.0.0.1:40000] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1584977637-172.17.0.10-1606980162785 (Datanode Uuid f1d8177d-b4c6-4841-8546-addcebbb1ab1)
2020-12-03 07:22:55,954 [BP-1584977637-172.17.0.10-1606980162785 heartbeating to localhost/127.0.0.1:40000] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1584977637-172.17.0.10-1606980162785
2020-12-03 07:22:55,955 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-1584977637-172.17.0.10-1606980162785] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:55,956 [Listener at localhost/39151] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:22:55,956 [Listener at localhost/39151] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:22:55,957 [Listener at localhost/39151] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:22:55,957 [Listener at localhost/39151] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:22:55,958 [Listener at localhost/39151] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:22:55,958 [Listener at localhost/39151] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:22:55,958 [Listener at localhost/39151] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:22:55,958 [Listener at localhost/39151] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 62, 62
2020-12-03 07:22:55,958 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@6e106680] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:22:55,958 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@576c5536] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:22:55,964 [Listener at localhost/39151] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 2 Total time for transactions(ms): 6 Number of transactions batched in Syncs: 61 Number of syncs: 3 SyncTimes(ms): 3 
2020-12-03 07:22:55,965 [Listener at localhost/39151] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_inprogress_0000000000000000062 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000062-0000000000000000063
2020-12-03 07:22:55,965 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:22:55,965 [CacheReplicationMonitor(104918161)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:22:55,966 [Listener at localhost/39151] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 40000
2020-12-03 07:22:55,968 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:55,969 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:55,969 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:22:55,969 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:22:55,986 [Listener at localhost/39151] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:22:55,987 [Listener at localhost/39151] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:22:55,989 [Listener at localhost/39151] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@64aad6db{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:22:55,990 [Listener at localhost/39151] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@ae7950d{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:55,991 [Listener at localhost/39151] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4a3be6a5{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:55,991 [Listener at localhost/39151] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5b12012e{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:55,995 [Listener at localhost/39151] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-12-03 07:22:55,997 [Listener at localhost/39151] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-12-03 07:22:55,998 [Listener at localhost/39151] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-12-03 07:22:56,030 [Listener at localhost/39151] INFO  hdfs.TestDFSFinalize (TestDFSFinalize.java:log(56)) - ============================================================
2020-12-03 07:22:56,030 [Listener at localhost/39151] INFO  hdfs.TestDFSFinalize (TestDFSFinalize.java:log(57)) - ***TEST 4*** Finalize NN & DN with existing previous dir: numDirs=2
2020-12-03 07:22:56,661 [Listener at localhost/39151] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=1
2020-12-03 07:22:56,661 [Listener at localhost/39151] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:22:56,662 [Listener at localhost/39151] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:22:56,662 [Listener at localhost/39151] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:22:56,666 [Listener at localhost/39151] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:22:56,668 [Listener at localhost/39151] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:22:56,668 [Listener at localhost/39151] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:22:56,669 [Listener at localhost/39151] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-12-03 07:22:56,675 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@67e28be3] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:56,675 [Listener at localhost/39151] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:22:56,675 [Listener at localhost/39151] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:56,677 [Listener at localhost/39151] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:56,678 [Listener at localhost/39151] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:22:56,678 [Listener at localhost/39151] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:56,680 [Listener at localhost/39151] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:56,681 [Listener at localhost/39151] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:22:56,681 [Listener at localhost/39151] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:56,681 [Listener at localhost/39151] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:56,683 [Listener at localhost/39151] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:22:56,683 [Listener at localhost/39151] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:22:56,683 [Listener at localhost/39151] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 38783
2020-12-03 07:22:56,683 [Listener at localhost/39151] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:56,685 [Listener at localhost/39151] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4e904fd5{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:56,686 [Listener at localhost/39151] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4cbf4f53{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:56,692 [Listener at localhost/39151] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1dc2de84{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:22:56,696 [Listener at localhost/39151] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6a0659ac{HTTP/1.1,[http/1.1]}{localhost:38783}
2020-12-03 07:22:56,697 [Listener at localhost/39151] INFO  server.Server (Server.java:doStart(419)) - Started @15887ms
2020-12-03 07:22:56,697 [Listener at localhost/39151] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:22:56,697 [Listener at localhost/39151] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:22:56,697 [Listener at localhost/39151] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:22:56,698 [Listener at localhost/39151] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:22:56,698 [Listener at localhost/39151] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:22:56,698 [Listener at localhost/39151] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:22:56,698 [Listener at localhost/39151] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:22:56,698 [Listener at localhost/39151] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:22:56,701 [Listener at localhost/39151] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:22:56,701 [Listener at localhost/39151] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:22:56,701 [Listener at localhost/39151] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:22:56,701 [Listener at localhost/39151] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:22:56,702 [Listener at localhost/39151] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:22:56,702 [Listener at localhost/39151] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:22:56,702 [Listener at localhost/39151] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:22:56,702 [Listener at localhost/39151] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:22:56,703 [Listener at localhost/39151] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:56,703 [Listener at localhost/39151] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:22:56,703 [Listener at localhost/39151] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:22:56,704 [Listener at localhost/39151] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:22:56,704 [Listener at localhost/39151] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:22:56
2020-12-03 07:22:56,704 [Listener at localhost/39151] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:22:56,704 [Listener at localhost/39151] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:56,705 [Listener at localhost/39151] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-12-03 07:22:56,705 [Listener at localhost/39151] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:22:56,716 [Listener at localhost/39151] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:22:56,716 [Listener at localhost/39151] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:22:56,717 [Listener at localhost/39151] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:22:56,717 [Listener at localhost/39151] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:22:56,717 [Listener at localhost/39151] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:22:56,717 [Listener at localhost/39151] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:22:56,717 [Listener at localhost/39151] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 1
2020-12-03 07:22:56,718 [Listener at localhost/39151] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:22:56,718 [Listener at localhost/39151] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:22:56,718 [Listener at localhost/39151] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:22:56,718 [Listener at localhost/39151] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:22:56,718 [Listener at localhost/39151] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:22:56,718 [Listener at localhost/39151] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:22:56,719 [Listener at localhost/39151] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:22:56,719 [Listener at localhost/39151] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:56,719 [Listener at localhost/39151] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-12-03 07:22:56,720 [Listener at localhost/39151] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:22:56,722 [Listener at localhost/39151] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:22:56,722 [Listener at localhost/39151] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:22:56,722 [Listener at localhost/39151] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:22:56,722 [Listener at localhost/39151] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:22:56,723 [Listener at localhost/39151] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:22:56,723 [Listener at localhost/39151] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:22:56,723 [Listener at localhost/39151] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:22:56,723 [Listener at localhost/39151] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:56,724 [Listener at localhost/39151] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-12-03 07:22:56,724 [Listener at localhost/39151] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:22:56,726 [Listener at localhost/39151] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:22:56,726 [Listener at localhost/39151] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:22:56,726 [Listener at localhost/39151] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:22:56,727 [Listener at localhost/39151] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:22:56,727 [Listener at localhost/39151] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:22:56,728 [Listener at localhost/39151] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:22:56,728 [Listener at localhost/39151] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:56,728 [Listener at localhost/39151] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-12-03 07:22:56,728 [Listener at localhost/39151] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:22:56,761 [Listener at localhost/39151] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/in_use.lock acquired by nodename 5752@f8f6fab70ed3
2020-12-03 07:22:56,787 [Listener at localhost/39151] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/in_use.lock acquired by nodename 5752@f8f6fab70ed3
2020-12-03 07:22:56,789 [Listener at localhost/39151] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current
2020-12-03 07:22:56,790 [Listener at localhost/39151] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current
2020-12-03 07:22:56,793 [Listener at localhost/39151] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031, cpktTxId=0000000000000000031)
2020-12-03 07:22:56,795 [Listener at localhost/39151] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 4 INodes.
2020-12-03 07:22:56,797 [Listener at localhost/39151] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:22:56,797 [Listener at localhost/39151] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 31 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031
2020-12-03 07:22:56,798 [Listener at localhost/39151] INFO  namenode.FSImage (FSImage.java:loadEdits(910)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@68dcfd52 expecting start txid #32
2020-12-03 07:22:56,798 [Listener at localhost/39151] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_0000000000000000032-0000000000000000061 maxTxnsToRead = 9223372036854775807
2020-12-03 07:22:56,798 [Listener at localhost/39151] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061' to transaction ID 32
2020-12-03 07:22:56,805 [Listener at localhost/39151] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(188)) - Loaded 1 edits file(s) (the last named /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_0000000000000000032-0000000000000000061) of total size 1692.0, total edits 30.0, total load time 6.0 ms
2020-12-03 07:22:56,805 [Listener at localhost/39151] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:22:56,809 [Listener at localhost/39151] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 62
2020-12-03 07:22:56,896 [Listener at localhost/39151] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:22:56,897 [Listener at localhost/39151] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 167 msecs
2020-12-03 07:22:56,897 [Listener at localhost/39151] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:22:56,898 [Listener at localhost/39151] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:56,899 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:56,904 [Listener at localhost/43145] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:43145 to access this namenode/service.
2020-12-03 07:22:56,905 [Listener at localhost/43145] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:22:56,905 [Listener at localhost/43145] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:22:56,905 [Listener at localhost/43145] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:22:56,933 [Listener at localhost/43145] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:22:56,935 [Listener at localhost/43145] INFO  hdfs.StateChange (BlockManagerSafeMode.java:reportStatus(617)) - STATE* Safe mode ON. 
The reported blocks 0 needs additional 15 blocks to reach the threshold 0.9990 of total blocks 16.
The minimum number of live datanodes is not required. Safe mode will be turned off automatically once the thresholds have been reached.
2020-12-03 07:22:56,943 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:56,943 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:56,949 [Listener at localhost/43145] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:43145
2020-12-03 07:22:56,950 [Listener at localhost/43145] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:22:56,950 [Listener at localhost/43145] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:22:56,958 [Listener at localhost/43145] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 0 milliseconds
name space=6
storage space=16384
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:22:56,962 [CacheReplicationMonitor(1295074466)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:22:56,977 [Listener at localhost/43145] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1,/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2
2020-12-03 07:22:56,978 [Listener at localhost/43145] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:22:56,979 [Listener at localhost/43145] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2
2020-12-03 07:22:56,979 [Listener at localhost/43145] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:22:56,981 [Listener at localhost/43145] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:56,981 [Listener at localhost/43145] INFO  datanode.BlockScanner (BlockScanner.java:<init>(187)) - Disabled block scanner.
2020-12-03 07:22:56,982 [Listener at localhost/43145] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:22:56,982 [Listener at localhost/43145] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:56,982 [Listener at localhost/43145] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:22:56,983 [Listener at localhost/43145] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:43270
2020-12-03 07:22:56,984 [Listener at localhost/43145] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:22:56,984 [Listener at localhost/43145] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:22:56,985 [Listener at localhost/43145] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:56,987 [Listener at localhost/43145] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:56,988 [Listener at localhost/43145] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:22:56,988 [Listener at localhost/43145] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:56,991 [Listener at localhost/43145] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:56,991 [Listener at localhost/43145] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:22:56,991 [Listener at localhost/43145] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:56,992 [Listener at localhost/43145] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:56,992 [Listener at localhost/43145] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 38084
2020-12-03 07:22:56,996 [Listener at localhost/43145] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:56,998 [Listener at localhost/43145] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6e57b5e9{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:56,999 [Listener at localhost/43145] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6a0ac48e{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:57,008 [Listener at localhost/43145] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@66bacdbc{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:22:57,009 [Listener at localhost/43145] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2c6ee758{HTTP/1.1,[http/1.1]}{localhost:38084}
2020-12-03 07:22:57,011 [Listener at localhost/43145] INFO  server.Server (Server.java:doStart(419)) - Started @16201ms
2020-12-03 07:22:57,040 [Listener at localhost/43145] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:42034
2020-12-03 07:22:57,041 [Listener at localhost/43145] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:22:57,041 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4b54af3d] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:57,041 [Listener at localhost/43145] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:22:57,042 [Listener at localhost/43145] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:57,043 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:57,060 [Listener at localhost/35267] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:35267
2020-12-03 07:22:57,066 [Listener at localhost/35267] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:22:57,067 [Listener at localhost/35267] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:22:57,068 [Thread-319] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43145 starting to offer service
2020-12-03 07:22:57,076 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:57,076 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:57,083 [Thread-319] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43145
2020-12-03 07:22:57,084 [Thread-319] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:57,090 [IPC Server handler 1 on default port 43145] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:57,091 [Listener at localhost/35267] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:57,092 [Listener at localhost/35267] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:57,123 [Thread-319] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/in_use.lock acquired by nodename 5752@f8f6fab70ed3
2020-12-03 07:22:57,194 [IPC Server handler 2 on default port 43145] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:57,196 [Listener at localhost/35267] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:57,196 [Listener at localhost/35267] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:57,265 [Thread-319] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/in_use.lock acquired by nodename 5752@f8f6fab70ed3
2020-12-03 07:22:57,297 [IPC Server handler 5 on default port 43145] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:57,298 [Listener at localhost/35267] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:57,298 [Listener at localhost/35267] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:57,344 [Thread-319] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1584977637-172.17.0.10-1606980162785
2020-12-03 07:22:57,345 [Thread-319] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-1584977637-172.17.0.10-1606980162785
2020-12-03 07:22:57,400 [IPC Server handler 4 on default port 43145] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:57,401 [Listener at localhost/35267] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:57,401 [Listener at localhost/35267] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:57,427 [Thread-319] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1584977637-172.17.0.10-1606980162785
2020-12-03 07:22:57,427 [Thread-319] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/current/BP-1584977637-172.17.0.10-1606980162785
2020-12-03 07:22:57,463 [Thread-319] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=60730268;bpid=BP-1584977637-172.17.0.10-1606980162785;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=60730268;c=1606980162785;bpid=BP-1584977637-172.17.0.10-1606980162785;dnuuid=f1d8177d-b4c6-4841-8546-addcebbb1ab1
2020-12-03 07:22:57,465 [Thread-319] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-359c699b-55fc-4fa8-9dd1-6c1b6932a2df
2020-12-03 07:22:57,466 [Thread-319] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1, StorageType: DISK
2020-12-03 07:22:57,467 [Thread-319] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-a6c87294-a0f0-48be-a912-f46226ca0975
2020-12-03 07:22:57,467 [Thread-319] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2, StorageType: DISK
2020-12-03 07:22:57,468 [Thread-319] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:22:57,469 [Thread-319] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:22:57,472 [Thread-319] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:22:57,472 [Thread-319] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2
2020-12-03 07:22:57,472 [Thread-319] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2
2020-12-03 07:22:57,473 [Thread-319] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1584977637-172.17.0.10-1606980162785
2020-12-03 07:22:57,473 [Thread-332] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1584977637-172.17.0.10-1606980162785 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1...
2020-12-03 07:22:57,473 [Thread-333] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1584977637-172.17.0.10-1606980162785 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2...
2020-12-03 07:22:57,475 [Thread-332] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-1584977637-172.17.0.10-1606980162785/current: 41200
2020-12-03 07:22:57,475 [Thread-333] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/current/BP-1584977637-172.17.0.10-1606980162785/current: 41200
2020-12-03 07:22:57,485 [Thread-332] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1584977637-172.17.0.10-1606980162785 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1: 12ms
2020-12-03 07:22:57,486 [Thread-333] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1584977637-172.17.0.10-1606980162785 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2: 12ms
2020-12-03 07:22:57,486 [Thread-319] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1584977637-172.17.0.10-1606980162785: 14ms
2020-12-03 07:22:57,487 [Thread-334] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1584977637-172.17.0.10-1606980162785 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1...
2020-12-03 07:22:57,487 [Thread-335] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1584977637-172.17.0.10-1606980162785 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2...
2020-12-03 07:22:57,489 [Thread-334] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(925)) - Successfully read replica from cache file : /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-1584977637-172.17.0.10-1606980162785/current/replicas
2020-12-03 07:22:57,489 [Thread-334] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1584977637-172.17.0.10-1606980162785 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1: 3ms
2020-12-03 07:22:57,489 [Thread-335] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(925)) - Successfully read replica from cache file : /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/current/BP-1584977637-172.17.0.10-1606980162785/current/replicas
2020-12-03 07:22:57,489 [Thread-335] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1584977637-172.17.0.10-1606980162785 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2: 2ms
2020-12-03 07:22:57,490 [Thread-319] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1584977637-172.17.0.10-1606980162785: 3ms
2020-12-03 07:22:57,490 [Thread-319] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:23 AM with interval of 21600000ms
2020-12-03 07:22:57,491 [BP-1584977637-172.17.0.10-1606980162785 heartbeating to localhost/127.0.0.1:43145] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1584977637-172.17.0.10-1606980162785 (Datanode Uuid f1d8177d-b4c6-4841-8546-addcebbb1ab1) service to localhost/127.0.0.1:43145 beginning handshake with NN
2020-12-03 07:22:57,493 [IPC Server handler 6 on default port 43145] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:43270, datanodeUuid=f1d8177d-b4c6-4841-8546-addcebbb1ab1, infoPort=42034, infoSecurePort=0, ipcPort=35267, storageInfo=lv=-57;cid=testClusterID;nsid=60730268;c=1606980162785) storage f1d8177d-b4c6-4841-8546-addcebbb1ab1
2020-12-03 07:22:57,493 [IPC Server handler 6 on default port 43145] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:43270
2020-12-03 07:22:57,494 [IPC Server handler 6 on default port 43145] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN f1d8177d-b4c6-4841-8546-addcebbb1ab1 (127.0.0.1:43270).
2020-12-03 07:22:57,496 [BP-1584977637-172.17.0.10-1606980162785 heartbeating to localhost/127.0.0.1:43145] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1584977637-172.17.0.10-1606980162785 (Datanode Uuid f1d8177d-b4c6-4841-8546-addcebbb1ab1) service to localhost/127.0.0.1:43145 successfully registered with NN
2020-12-03 07:22:57,496 [BP-1584977637-172.17.0.10-1606980162785 heartbeating to localhost/127.0.0.1:43145] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:43145 using BLOCKREPORT_INTERVAL of 10000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:22:57,499 [IPC Server handler 7 on default port 43145] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-359c699b-55fc-4fa8-9dd1-6c1b6932a2df for DN 127.0.0.1:43270
2020-12-03 07:22:57,499 [IPC Server handler 7 on default port 43145] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-a6c87294-a0f0-48be-a912-f46226ca0975 for DN 127.0.0.1:43270
2020-12-03 07:22:57,502 [IPC Server handler 8 on default port 43145] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:57,503 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xe9fbda45a4a0be4a: Processing first storage report for DS-359c699b-55fc-4fa8-9dd1-6c1b6932a2df from datanode f1d8177d-b4c6-4841-8546-addcebbb1ab1
2020-12-03 07:22:57,503 [Listener at localhost/35267] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:22:57,504 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xe9fbda45a4a0be4a: from storage DS-359c699b-55fc-4fa8-9dd1-6c1b6932a2df node DatanodeRegistration(127.0.0.1:43270, datanodeUuid=f1d8177d-b4c6-4841-8546-addcebbb1ab1, infoPort=42034, infoSecurePort=0, ipcPort=35267, storageInfo=lv=-57;cid=testClusterID;nsid=60730268;c=1606980162785), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:57,505 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xe9fbda45a4a0be4a: Processing first storage report for DS-a6c87294-a0f0-48be-a912-f46226ca0975 from datanode f1d8177d-b4c6-4841-8546-addcebbb1ab1
2020-12-03 07:22:57,505 [Listener at localhost/35267] WARN  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitClusterUp(1436)) - Waiting for the Mini HDFS Cluster to start...
2020-12-03 07:22:57,506 [Block report processor] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:22:57,507 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(395)) - STATE* Safe mode is OFF
2020-12-03 07:22:57,507 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:22:57,507 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 1 racks and 1 datanodes
2020-12-03 07:22:57,507 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:22:57,509 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xe9fbda45a4a0be4a: from storage DS-a6c87294-a0f0-48be-a912-f46226ca0975 node DatanodeRegistration(127.0.0.1:43270, datanodeUuid=f1d8177d-b4c6-4841-8546-addcebbb1ab1, infoPort=42034, infoSecurePort=0, ipcPort=35267, storageInfo=lv=-57;cid=testClusterID;nsid=60730268;c=1606980162785), blocks: 16, hasStaleStorage: false, processing time: 4 msecs, invalidatedBlocks: 0
2020-12-03 07:22:57,519 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 16
2020-12-03 07:22:57,519 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:22:57,520 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:22:57,520 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:22:57,520 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:22:57,520 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 13 msec
2020-12-03 07:22:57,523 [BP-1584977637-172.17.0.10-1606980162785 heartbeating to localhost/127.0.0.1:43145] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xe9fbda45a4a0be4a,  containing 2 storage report(s), of which we sent 2. The reports had 16 total blocks and used 1 RPC(s). This took 1 msec to generate and 21 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:22:58,510 [IPC Server handler 9 on default port 43145] INFO  namenode.FSImage (FSImage.java:finalizeUpgrade(614)) - Finalizing upgrade for local dirs. 
   cur LV = -65; cur CTime = 1606980162785
2020-12-03 07:22:58,510 [IPC Server handler 9 on default port 43145] INFO  namenode.NNUpgradeUtil (NNUpgradeUtil.java:doFinalize(95)) - Finalizing upgrade of storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1
2020-12-03 07:22:58,511 [IPC Server handler 9 on default port 43145] INFO  namenode.NNUpgradeUtil (NNUpgradeUtil.java:doFinalize(102)) - Finalize upgrade for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 is complete.
2020-12-03 07:22:58,511 [IPC Server handler 9 on default port 43145] INFO  namenode.NNUpgradeUtil (NNUpgradeUtil.java:doFinalize(95)) - Finalizing upgrade of storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2
2020-12-03 07:22:58,512 [IPC Server handler 9 on default port 43145] INFO  namenode.NNUpgradeUtil (NNUpgradeUtil.java:doFinalize(102)) - Finalize upgrade for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 is complete.
2020-12-03 07:22:58,512 [IPC Server handler 9 on default port 43145] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=finalizeUpgrade	src=null	dst=null	perm=null	proto=rpc
Finalize upgrade successful
2020-12-03 07:22:58,515 [BP-1584977637-172.17.0.10-1606980162785 heartbeating to localhost/127.0.0.1:43145] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:43145
2020-12-03 07:22:58,516 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xe9fbda45a4a0be4b: from storage DS-359c699b-55fc-4fa8-9dd1-6c1b6932a2df node DatanodeRegistration(127.0.0.1:43270, datanodeUuid=f1d8177d-b4c6-4841-8546-addcebbb1ab1, infoPort=42034, infoSecurePort=0, ipcPort=35267, storageInfo=lv=-57;cid=testClusterID;nsid=60730268;c=1606980162785), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:58,517 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xe9fbda45a4a0be4b: from storage DS-a6c87294-a0f0-48be-a912-f46226ca0975 node DatanodeRegistration(127.0.0.1:43270, datanodeUuid=f1d8177d-b4c6-4841-8546-addcebbb1ab1, infoPort=42034, infoSecurePort=0, ipcPort=35267, storageInfo=lv=-57;cid=testClusterID;nsid=60730268;c=1606980162785), blocks: 16, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:58,517 [BP-1584977637-172.17.0.10-1606980162785 heartbeating to localhost/127.0.0.1:43145] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xe9fbda45a4a0be4b,  containing 2 storage report(s), of which we sent 2. The reports had 16 total blocks and used 1 RPC(s). This took 1 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:58,517 [BP-1584977637-172.17.0.10-1606980162785 heartbeating to localhost/127.0.0.1:43145] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1584977637-172.17.0.10-1606980162785
2020-12-03 07:22:58,518 [BP-1584977637-172.17.0.10-1606980162785 heartbeating to localhost/127.0.0.1:43145] INFO  common.Storage (DataStorage.java:doFinalize(970)) - Finalizing upgrade for storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1.
   cur LV = -57; cur CTime = 0
2020-12-03 07:22:58,518 [BP-1584977637-172.17.0.10-1606980162785 heartbeating to localhost/127.0.0.1:43145] INFO  common.Storage (DataStorage.java:doFinalize(970)) - Finalizing upgrade for storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2.
   cur LV = -57; cur CTime = 0
2020-12-03 07:22:58,521 [Finalize /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1] INFO  common.Storage (DataStorage.java:run(993)) - Finalize upgrade for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1 is complete
2020-12-03 07:22:58,521 [Finalize /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2] INFO  common.Storage (DataStorage.java:run(993)) - Finalize upgrade for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2 is complete
2020-12-03 07:22:59,662 [Listener at localhost/35267] INFO  hdfs.TestDFSFinalize (TestDFSFinalize.java:log(56)) - ============================================================
2020-12-03 07:22:59,662 [Listener at localhost/35267] INFO  hdfs.TestDFSFinalize (TestDFSFinalize.java:log(57)) - ***TEST 5*** Finalize NN & DN without existing previous dir: numDirs=2
2020-12-03 07:22:59,667 [IPC Server handler 1 on default port 43145] INFO  namenode.FSImage (FSImage.java:finalizeUpgrade(614)) - Finalizing upgrade for local dirs. 
   cur LV = -65; cur CTime = 1606980162785
2020-12-03 07:22:59,667 [IPC Server handler 1 on default port 43145] INFO  namenode.NNUpgradeUtil (NNUpgradeUtil.java:doFinalize(91)) - Directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/previous does not exist.
2020-12-03 07:22:59,667 [IPC Server handler 1 on default port 43145] INFO  namenode.NNUpgradeUtil (NNUpgradeUtil.java:doFinalize(92)) - Finalize upgrade for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 is not required.
2020-12-03 07:22:59,668 [IPC Server handler 1 on default port 43145] INFO  namenode.NNUpgradeUtil (NNUpgradeUtil.java:doFinalize(91)) - Directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/previous does not exist.
2020-12-03 07:22:59,668 [IPC Server handler 1 on default port 43145] INFO  namenode.NNUpgradeUtil (NNUpgradeUtil.java:doFinalize(92)) - Finalize upgrade for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 is not required.
2020-12-03 07:22:59,668 [IPC Server handler 1 on default port 43145] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=finalizeUpgrade	src=null	dst=null	perm=null	proto=rpc
Finalize upgrade successful
2020-12-03 07:22:59,674 [BP-1584977637-172.17.0.10-1606980162785 heartbeating to localhost/127.0.0.1:43145] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:43145
2020-12-03 07:22:59,676 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xe9fbda45a4a0be4c: from storage DS-359c699b-55fc-4fa8-9dd1-6c1b6932a2df node DatanodeRegistration(127.0.0.1:43270, datanodeUuid=f1d8177d-b4c6-4841-8546-addcebbb1ab1, infoPort=42034, infoSecurePort=0, ipcPort=35267, storageInfo=lv=-57;cid=testClusterID;nsid=60730268;c=1606980162785), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:59,677 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xe9fbda45a4a0be4c: from storage DS-a6c87294-a0f0-48be-a912-f46226ca0975 node DatanodeRegistration(127.0.0.1:43270, datanodeUuid=f1d8177d-b4c6-4841-8546-addcebbb1ab1, infoPort=42034, infoSecurePort=0, ipcPort=35267, storageInfo=lv=-57;cid=testClusterID;nsid=60730268;c=1606980162785), blocks: 16, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:59,678 [BP-1584977637-172.17.0.10-1606980162785 heartbeating to localhost/127.0.0.1:43145] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xe9fbda45a4a0be4c,  containing 2 storage report(s), of which we sent 2. The reports had 16 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:59,678 [BP-1584977637-172.17.0.10-1606980162785 heartbeating to localhost/127.0.0.1:43145] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1584977637-172.17.0.10-1606980162785
2020-12-03 07:23:00,800 [Listener at localhost/35267] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:23:00,801 [Listener at localhost/35267] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:23:00,802 [Listener at localhost/35267] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:23:00,804 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@4a68135e] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:00,830 [Listener at localhost/35267] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@66bacdbc{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:00,832 [Listener at localhost/35267] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2c6ee758{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:00,839 [Listener at localhost/35267] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6a0ac48e{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:00,848 [Listener at localhost/35267] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6e57b5e9{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:00,851 [Listener at localhost/35267] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 35267
2020-12-03 07:23:00,854 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:00,854 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:00,855 [BP-1584977637-172.17.0.10-1606980162785 heartbeating to localhost/127.0.0.1:43145] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:00,869 [BP-1584977637-172.17.0.10-1606980162785 heartbeating to localhost/127.0.0.1:43145] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1584977637-172.17.0.10-1606980162785 (Datanode Uuid f1d8177d-b4c6-4841-8546-addcebbb1ab1) service to localhost/127.0.0.1:43145
2020-12-03 07:23:00,869 [BP-1584977637-172.17.0.10-1606980162785 heartbeating to localhost/127.0.0.1:43145] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1584977637-172.17.0.10-1606980162785 (Datanode Uuid f1d8177d-b4c6-4841-8546-addcebbb1ab1)
2020-12-03 07:23:00,870 [BP-1584977637-172.17.0.10-1606980162785 heartbeating to localhost/127.0.0.1:43145] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1584977637-172.17.0.10-1606980162785
2020-12-03 07:23:00,871 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-1584977637-172.17.0.10-1606980162785] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:00,872 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/current/BP-1584977637-172.17.0.10-1606980162785] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:00,874 [Listener at localhost/35267] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:23:00,874 [Listener at localhost/35267] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:23:00,875 [Listener at localhost/35267] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:23:00,875 [Listener at localhost/35267] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:23:00,877 [Listener at localhost/35267] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:00,877 [Listener at localhost/35267] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:23:00,877 [Listener at localhost/35267] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:00,880 [Listener at localhost/35267] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 62, 62
2020-12-03 07:23:00,880 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@3a2b2322] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:23:00,880 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@5e1218b4] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:23:00,882 [Listener at localhost/35267] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 2 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 61 Number of syncs: 3 SyncTimes(ms): 1 7 
2020-12-03 07:23:00,883 [Listener at localhost/35267] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_inprogress_0000000000000000062 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000062-0000000000000000063
2020-12-03 07:23:00,883 [Listener at localhost/35267] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_inprogress_0000000000000000062 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_0000000000000000062-0000000000000000063
2020-12-03 07:23:00,884 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:23:00,884 [CacheReplicationMonitor(1295074466)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:23:00,885 [Listener at localhost/35267] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 43145
2020-12-03 07:23:00,905 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:00,910 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:00,914 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:23:00,914 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:23:00,960 [Listener at localhost/35267] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:00,960 [Listener at localhost/35267] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:23:00,962 [Listener at localhost/35267] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1dc2de84{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:23:00,964 [Listener at localhost/35267] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6a0659ac{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:00,964 [Listener at localhost/35267] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4cbf4f53{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:00,964 [Listener at localhost/35267] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4e904fd5{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:00,966 [Listener at localhost/35267] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-12-03 07:23:00,968 [Listener at localhost/35267] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-12-03 07:23:00,969 [Listener at localhost/35267] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-12-03 07:23:00,990 [Listener at localhost/35267] INFO  hdfs.TestDFSFinalize (TestDFSFinalize.java:log(56)) - ============================================================
2020-12-03 07:23:00,991 [Listener at localhost/35267] INFO  hdfs.TestDFSFinalize (TestDFSFinalize.java:log(57)) - ***TEST 6*** Finalize NN & BP with existing previous dir: numDirs=2
2020-12-03 07:23:01,675 [Listener at localhost/35267] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=1
2020-12-03 07:23:01,676 [Listener at localhost/35267] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:01,676 [Listener at localhost/35267] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:23:01,677 [Listener at localhost/35267] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:23:01,680 [Listener at localhost/35267] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:23:01,682 [Listener at localhost/35267] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:23:01,683 [Listener at localhost/35267] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:23:01,684 [Listener at localhost/35267] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-12-03 07:23:01,688 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@787f32b7] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:01,689 [Listener at localhost/35267] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:23:01,689 [Listener at localhost/35267] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:01,691 [Listener at localhost/35267] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:01,691 [Listener at localhost/35267] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:23:01,692 [Listener at localhost/35267] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:01,694 [Listener at localhost/35267] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:01,694 [Listener at localhost/35267] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:23:01,695 [Listener at localhost/35267] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:01,695 [Listener at localhost/35267] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:01,696 [Listener at localhost/35267] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:23:01,697 [Listener at localhost/35267] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:23:01,697 [Listener at localhost/35267] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 38136
2020-12-03 07:23:01,697 [Listener at localhost/35267] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:01,700 [Listener at localhost/35267] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@45d6ef73{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:01,700 [Listener at localhost/35267] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1f6d27cc{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:01,707 [Listener at localhost/35267] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6fd77352{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:23:01,709 [Listener at localhost/35267] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@5109e8cf{HTTP/1.1,[http/1.1]}{localhost:38136}
2020-12-03 07:23:01,709 [Listener at localhost/35267] INFO  server.Server (Server.java:doStart(419)) - Started @20900ms
2020-12-03 07:23:01,710 [Listener at localhost/35267] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:01,710 [Listener at localhost/35267] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:23:01,710 [Listener at localhost/35267] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:01,710 [Listener at localhost/35267] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:23:01,711 [Listener at localhost/35267] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:01,711 [Listener at localhost/35267] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:23:01,711 [Listener at localhost/35267] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:01,711 [Listener at localhost/35267] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:23:01,713 [Listener at localhost/35267] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:23:01,714 [Listener at localhost/35267] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:23:01,714 [Listener at localhost/35267] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:23:01,714 [Listener at localhost/35267] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:23:01,714 [Listener at localhost/35267] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:23:01,715 [Listener at localhost/35267] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:23:01,715 [Listener at localhost/35267] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:23:01,715 [Listener at localhost/35267] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:23:01,716 [Listener at localhost/35267] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:01,716 [Listener at localhost/35267] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:23:01,716 [Listener at localhost/35267] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:23:01,716 [Listener at localhost/35267] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:23:01,717 [Listener at localhost/35267] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:23:01
2020-12-03 07:23:01,717 [Listener at localhost/35267] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:23:01,717 [Listener at localhost/35267] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:01,718 [Listener at localhost/35267] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-12-03 07:23:01,718 [Listener at localhost/35267] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:23:01,729 [Listener at localhost/35267] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:23:01,729 [Listener at localhost/35267] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:23:01,730 [Listener at localhost/35267] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:23:01,730 [Listener at localhost/35267] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:23:01,730 [Listener at localhost/35267] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:23:01,730 [Listener at localhost/35267] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:23:01,730 [Listener at localhost/35267] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 1
2020-12-03 07:23:01,730 [Listener at localhost/35267] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:23:01,731 [Listener at localhost/35267] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:23:01,731 [Listener at localhost/35267] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:23:01,731 [Listener at localhost/35267] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:23:01,731 [Listener at localhost/35267] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:23:01,731 [Listener at localhost/35267] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:23:01,732 [Listener at localhost/35267] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:23:01,732 [Listener at localhost/35267] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:01,732 [Listener at localhost/35267] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-12-03 07:23:01,732 [Listener at localhost/35267] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:23:01,738 [Listener at localhost/35267] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:23:01,739 [Listener at localhost/35267] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:23:01,739 [Listener at localhost/35267] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:23:01,739 [Listener at localhost/35267] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:23:01,739 [Listener at localhost/35267] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:23:01,739 [Listener at localhost/35267] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:23:01,740 [Listener at localhost/35267] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:23:01,740 [Listener at localhost/35267] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:01,740 [Listener at localhost/35267] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-12-03 07:23:01,740 [Listener at localhost/35267] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:23:01,742 [Listener at localhost/35267] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:23:01,742 [Listener at localhost/35267] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:23:01,743 [Listener at localhost/35267] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:23:01,743 [Listener at localhost/35267] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:23:01,744 [Listener at localhost/35267] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:23:01,744 [Listener at localhost/35267] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:23:01,744 [Listener at localhost/35267] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:01,744 [Listener at localhost/35267] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-12-03 07:23:01,745 [Listener at localhost/35267] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:23:01,792 [Listener at localhost/35267] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/in_use.lock acquired by nodename 5752@f8f6fab70ed3
2020-12-03 07:23:01,907 [Listener at localhost/35267] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/in_use.lock acquired by nodename 5752@f8f6fab70ed3
2020-12-03 07:23:01,909 [Listener at localhost/35267] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current
2020-12-03 07:23:01,909 [Listener at localhost/35267] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current
2020-12-03 07:23:01,910 [Listener at localhost/35267] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031, cpktTxId=0000000000000000031)
2020-12-03 07:23:01,913 [Listener at localhost/35267] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 4 INodes.
2020-12-03 07:23:01,915 [Listener at localhost/35267] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:23:01,915 [Listener at localhost/35267] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 31 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/fsimage_0000000000000000031
2020-12-03 07:23:01,915 [Listener at localhost/35267] INFO  namenode.FSImage (FSImage.java:loadEdits(910)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@2d000e80 expecting start txid #32
2020-12-03 07:23:01,916 [Listener at localhost/35267] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_0000000000000000032-0000000000000000061 maxTxnsToRead = 9223372036854775807
2020-12-03 07:23:01,916 [Listener at localhost/35267] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061' to transaction ID 32
2020-12-03 07:23:01,920 [Listener at localhost/35267] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(188)) - Loaded 1 edits file(s) (the last named /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000032-0000000000000000061, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_0000000000000000032-0000000000000000061) of total size 1692.0, total edits 30.0, total load time 4.0 ms
2020-12-03 07:23:01,920 [Listener at localhost/35267] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:23:01,921 [Listener at localhost/35267] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 62
2020-12-03 07:23:02,101 [Listener at localhost/35267] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:23:02,101 [Listener at localhost/35267] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 356 msecs
2020-12-03 07:23:02,102 [Listener at localhost/35267] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:23:02,103 [Listener at localhost/35267] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:02,104 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:02,109 [Listener at localhost/42252] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:42252 to access this namenode/service.
2020-12-03 07:23:02,109 [Listener at localhost/42252] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:23:02,110 [Listener at localhost/42252] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 in configuration.
2020-12-03 07:23:02,110 [Listener at localhost/42252] INFO  common.Util (Util.java:stringAsURI(100)) - Assuming 'file' scheme for path /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 in configuration.
2020-12-03 07:23:02,127 [Listener at localhost/42252] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:23:02,129 [Listener at localhost/42252] INFO  hdfs.StateChange (BlockManagerSafeMode.java:reportStatus(617)) - STATE* Safe mode ON. 
The reported blocks 0 needs additional 15 blocks to reach the threshold 0.9990 of total blocks 16.
The minimum number of live datanodes is not required. Safe mode will be turned off automatically once the thresholds have been reached.
2020-12-03 07:23:02,133 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:02,135 [Listener at localhost/42252] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:42252
2020-12-03 07:23:02,135 [Listener at localhost/42252] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:23:02,135 [Listener at localhost/42252] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:23:02,136 [Listener at localhost/42252] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 1 milliseconds
name space=6
storage space=16384
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:23:02,144 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:02,148 [CacheReplicationMonitor(1693976077)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:23:02,149 [Listener at localhost/42252] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1,/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2
2020-12-03 07:23:02,150 [Listener at localhost/42252] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:23:02,151 [Listener at localhost/42252] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2
2020-12-03 07:23:02,152 [Listener at localhost/42252] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:23:02,153 [Listener at localhost/42252] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:02,153 [Listener at localhost/42252] INFO  datanode.BlockScanner (BlockScanner.java:<init>(187)) - Disabled block scanner.
2020-12-03 07:23:02,153 [Listener at localhost/42252] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:23:02,153 [Listener at localhost/42252] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:02,154 [Listener at localhost/42252] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:23:02,154 [Listener at localhost/42252] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:34393
2020-12-03 07:23:02,155 [Listener at localhost/42252] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:23:02,155 [Listener at localhost/42252] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:23:02,156 [Listener at localhost/42252] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:02,158 [Listener at localhost/42252] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:02,159 [Listener at localhost/42252] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:23:02,160 [Listener at localhost/42252] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:02,162 [Listener at localhost/42252] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:02,163 [Listener at localhost/42252] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:23:02,163 [Listener at localhost/42252] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:02,164 [Listener at localhost/42252] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:02,165 [Listener at localhost/42252] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 37323
2020-12-03 07:23:02,165 [Listener at localhost/42252] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:02,167 [Listener at localhost/42252] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3d98d138{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:23:02,168 [Listener at localhost/42252] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@f2ce6b{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:02,176 [Listener at localhost/42252] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6f38a289{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:23:02,177 [Listener at localhost/42252] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@61e3cf4d{HTTP/1.1,[http/1.1]}{localhost:37323}
2020-12-03 07:23:02,178 [Listener at localhost/42252] INFO  server.Server (Server.java:doStart(419)) - Started @21368ms
2020-12-03 07:23:02,197 [Listener at localhost/42252] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:39752
2020-12-03 07:23:02,198 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@64b70919] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:02,198 [Listener at localhost/42252] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:23:02,198 [Listener at localhost/42252] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:23:02,198 [Listener at localhost/42252] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:02,199 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:02,204 [Listener at localhost/36987] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:36987
2020-12-03 07:23:02,209 [Listener at localhost/36987] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:23:02,210 [Listener at localhost/36987] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:23:02,210 [Thread-391] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42252 starting to offer service
2020-12-03 07:23:02,219 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:02,230 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:02,244 [Thread-391] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42252
2020-12-03 07:23:02,245 [Thread-391] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:23:02,249 [IPC Server handler 1 on default port 42252] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:02,250 [Listener at localhost/36987] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:02,251 [Listener at localhost/36987] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:02,300 [Thread-391] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/in_use.lock acquired by nodename 5752@f8f6fab70ed3
2020-12-03 07:23:02,353 [IPC Server handler 2 on default port 42252] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:02,356 [Listener at localhost/36987] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:02,356 [Listener at localhost/36987] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:02,417 [Thread-391] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/in_use.lock acquired by nodename 5752@f8f6fab70ed3
2020-12-03 07:23:02,458 [IPC Server handler 3 on default port 42252] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:02,459 [Listener at localhost/36987] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:02,459 [Listener at localhost/36987] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:02,460 [Thread-391] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1584977637-172.17.0.10-1606980162785
2020-12-03 07:23:02,460 [Thread-391] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-1584977637-172.17.0.10-1606980162785
2020-12-03 07:23:02,512 [Thread-391] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1584977637-172.17.0.10-1606980162785
2020-12-03 07:23:02,512 [Thread-391] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/current/BP-1584977637-172.17.0.10-1606980162785
2020-12-03 07:23:02,545 [Thread-391] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=60730268;bpid=BP-1584977637-172.17.0.10-1606980162785;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=60730268;c=1606980162785;bpid=BP-1584977637-172.17.0.10-1606980162785;dnuuid=f1d8177d-b4c6-4841-8546-addcebbb1ab1
2020-12-03 07:23:02,547 [Thread-391] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-f2b90e12-0401-46d5-a804-098b4e1c4fc6
2020-12-03 07:23:02,548 [Thread-391] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1, StorageType: DISK
2020-12-03 07:23:02,549 [Thread-391] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-b06fa154-9af2-4db9-92d8-164709b740ec
2020-12-03 07:23:02,549 [Thread-391] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2, StorageType: DISK
2020-12-03 07:23:02,550 [Thread-391] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:23:02,551 [Thread-391] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:23:02,553 [Thread-391] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1
2020-12-03 07:23:02,553 [Thread-391] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2
2020-12-03 07:23:02,553 [Thread-391] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2
2020-12-03 07:23:02,555 [Thread-391] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1584977637-172.17.0.10-1606980162785
2020-12-03 07:23:02,555 [Thread-404] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1584977637-172.17.0.10-1606980162785 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1...
2020-12-03 07:23:02,556 [Thread-405] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1584977637-172.17.0.10-1606980162785 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2...
2020-12-03 07:23:02,557 [Thread-405] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/current/BP-1584977637-172.17.0.10-1606980162785/current: 41200
2020-12-03 07:23:02,557 [Thread-404] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-1584977637-172.17.0.10-1606980162785/current: 41200
2020-12-03 07:23:02,560 [IPC Server handler 4 on default port 42252] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:02,561 [Listener at localhost/36987] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:02,561 [Listener at localhost/36987] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:02,568 [Thread-405] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1584977637-172.17.0.10-1606980162785 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2: 12ms
2020-12-03 07:23:02,570 [Thread-404] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1584977637-172.17.0.10-1606980162785 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1: 14ms
2020-12-03 07:23:02,570 [Thread-391] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1584977637-172.17.0.10-1606980162785: 14ms
2020-12-03 07:23:02,570 [Thread-406] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1584977637-172.17.0.10-1606980162785 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1...
2020-12-03 07:23:02,572 [Thread-407] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1584977637-172.17.0.10-1606980162785 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2...
2020-12-03 07:23:02,573 [Thread-407] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(925)) - Successfully read replica from cache file : /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/current/BP-1584977637-172.17.0.10-1606980162785/current/replicas
2020-12-03 07:23:02,574 [Thread-407] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1584977637-172.17.0.10-1606980162785 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2: 2ms
2020-12-03 07:23:02,576 [Thread-406] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(925)) - Successfully read replica from cache file : /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-1584977637-172.17.0.10-1606980162785/current/replicas
2020-12-03 07:23:02,576 [Thread-406] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1584977637-172.17.0.10-1606980162785 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1: 6ms
2020-12-03 07:23:02,577 [Thread-391] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1584977637-172.17.0.10-1606980162785: 7ms
2020-12-03 07:23:02,577 [Thread-391] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 12:39 PM with interval of 21600000ms
2020-12-03 07:23:02,578 [BP-1584977637-172.17.0.10-1606980162785 heartbeating to localhost/127.0.0.1:42252] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1584977637-172.17.0.10-1606980162785 (Datanode Uuid f1d8177d-b4c6-4841-8546-addcebbb1ab1) service to localhost/127.0.0.1:42252 beginning handshake with NN
2020-12-03 07:23:02,580 [IPC Server handler 5 on default port 42252] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34393, datanodeUuid=f1d8177d-b4c6-4841-8546-addcebbb1ab1, infoPort=39752, infoSecurePort=0, ipcPort=36987, storageInfo=lv=-57;cid=testClusterID;nsid=60730268;c=1606980162785) storage f1d8177d-b4c6-4841-8546-addcebbb1ab1
2020-12-03 07:23:02,581 [IPC Server handler 5 on default port 42252] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:34393
2020-12-03 07:23:02,581 [IPC Server handler 5 on default port 42252] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN f1d8177d-b4c6-4841-8546-addcebbb1ab1 (127.0.0.1:34393).
2020-12-03 07:23:02,585 [BP-1584977637-172.17.0.10-1606980162785 heartbeating to localhost/127.0.0.1:42252] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1584977637-172.17.0.10-1606980162785 (Datanode Uuid f1d8177d-b4c6-4841-8546-addcebbb1ab1) service to localhost/127.0.0.1:42252 successfully registered with NN
2020-12-03 07:23:02,585 [BP-1584977637-172.17.0.10-1606980162785 heartbeating to localhost/127.0.0.1:42252] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:42252 using BLOCKREPORT_INTERVAL of 10000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:02,588 [IPC Server handler 6 on default port 42252] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-f2b90e12-0401-46d5-a804-098b4e1c4fc6 for DN 127.0.0.1:34393
2020-12-03 07:23:02,589 [IPC Server handler 6 on default port 42252] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-b06fa154-9af2-4db9-92d8-164709b740ec for DN 127.0.0.1:34393
2020-12-03 07:23:02,597 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x15e557dcdfdfd351: Processing first storage report for DS-f2b90e12-0401-46d5-a804-098b4e1c4fc6 from datanode f1d8177d-b4c6-4841-8546-addcebbb1ab1
2020-12-03 07:23:02,597 [Block report processor] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:23:02,599 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(395)) - STATE* Safe mode is OFF
2020-12-03 07:23:02,599 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:23:02,599 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 1 racks and 1 datanodes
2020-12-03 07:23:02,599 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:23:02,601 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x15e557dcdfdfd351: from storage DS-f2b90e12-0401-46d5-a804-098b4e1c4fc6 node DatanodeRegistration(127.0.0.1:34393, datanodeUuid=f1d8177d-b4c6-4841-8546-addcebbb1ab1, infoPort=39752, infoSecurePort=0, ipcPort=36987, storageInfo=lv=-57;cid=testClusterID;nsid=60730268;c=1606980162785), blocks: 16, hasStaleStorage: true, processing time: 4 msecs, invalidatedBlocks: 0
2020-12-03 07:23:02,607 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 16
2020-12-03 07:23:02,607 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:23:02,607 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:23:02,607 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:23:02,607 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:23:02,607 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 9 msec
2020-12-03 07:23:02,608 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x15e557dcdfdfd351: Processing first storage report for DS-b06fa154-9af2-4db9-92d8-164709b740ec from datanode f1d8177d-b4c6-4841-8546-addcebbb1ab1
2020-12-03 07:23:02,608 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x15e557dcdfdfd351: from storage DS-b06fa154-9af2-4db9-92d8-164709b740ec node DatanodeRegistration(127.0.0.1:34393, datanodeUuid=f1d8177d-b4c6-4841-8546-addcebbb1ab1, infoPort=39752, infoSecurePort=0, ipcPort=36987, storageInfo=lv=-57;cid=testClusterID;nsid=60730268;c=1606980162785), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:02,609 [BP-1584977637-172.17.0.10-1606980162785 heartbeating to localhost/127.0.0.1:42252] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x15e557dcdfdfd351,  containing 2 storage report(s), of which we sent 2. The reports had 16 total blocks and used 1 RPC(s). This took 0 msec to generate and 14 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:23:02,663 [IPC Server handler 8 on default port 42252] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:02,664 [Listener at localhost/36987] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:23:02,669 [IPC Server handler 9 on default port 42252] INFO  namenode.FSImage (FSImage.java:finalizeUpgrade(614)) - Finalizing upgrade for local dirs. 
   cur LV = -65; cur CTime = 1606980162785
2020-12-03 07:23:02,669 [IPC Server handler 9 on default port 42252] INFO  namenode.NNUpgradeUtil (NNUpgradeUtil.java:doFinalize(95)) - Finalizing upgrade of storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1
2020-12-03 07:23:02,670 [IPC Server handler 9 on default port 42252] INFO  namenode.NNUpgradeUtil (NNUpgradeUtil.java:doFinalize(102)) - Finalize upgrade for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 is complete.
2020-12-03 07:23:02,670 [IPC Server handler 9 on default port 42252] INFO  namenode.NNUpgradeUtil (NNUpgradeUtil.java:doFinalize(95)) - Finalizing upgrade of storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2
2020-12-03 07:23:02,670 [IPC Server handler 9 on default port 42252] INFO  namenode.NNUpgradeUtil (NNUpgradeUtil.java:doFinalize(102)) - Finalize upgrade for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 is complete.
2020-12-03 07:23:02,671 [IPC Server handler 9 on default port 42252] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=finalizeUpgrade	src=null	dst=null	perm=null	proto=rpc
Finalize upgrade successful
2020-12-03 07:23:02,673 [BP-1584977637-172.17.0.10-1606980162785 heartbeating to localhost/127.0.0.1:42252] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:42252
2020-12-03 07:23:02,676 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x15e557dcdfdfd352: from storage DS-f2b90e12-0401-46d5-a804-098b4e1c4fc6 node DatanodeRegistration(127.0.0.1:34393, datanodeUuid=f1d8177d-b4c6-4841-8546-addcebbb1ab1, infoPort=39752, infoSecurePort=0, ipcPort=36987, storageInfo=lv=-57;cid=testClusterID;nsid=60730268;c=1606980162785), blocks: 16, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:02,676 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x15e557dcdfdfd352: from storage DS-b06fa154-9af2-4db9-92d8-164709b740ec node DatanodeRegistration(127.0.0.1:34393, datanodeUuid=f1d8177d-b4c6-4841-8546-addcebbb1ab1, infoPort=39752, infoSecurePort=0, ipcPort=36987, storageInfo=lv=-57;cid=testClusterID;nsid=60730268;c=1606980162785), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:02,677 [BP-1584977637-172.17.0.10-1606980162785 heartbeating to localhost/127.0.0.1:42252] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x15e557dcdfdfd352,  containing 2 storage report(s), of which we sent 2. The reports had 16 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:23:02,677 [BP-1584977637-172.17.0.10-1606980162785 heartbeating to localhost/127.0.0.1:42252] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1584977637-172.17.0.10-1606980162785
2020-12-03 07:23:02,677 [BP-1584977637-172.17.0.10-1606980162785 heartbeating to localhost/127.0.0.1:42252] INFO  common.Storage (BlockPoolSliceStorage.java:doFinalize(652)) - Finalizing upgrade for storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-1584977637-172.17.0.10-1606980162785.
   cur LV = -57; cur CTime = 1606980162785
2020-12-03 07:23:02,678 [BP-1584977637-172.17.0.10-1606980162785 heartbeating to localhost/127.0.0.1:42252] INFO  common.Storage (BlockPoolSliceStorage.java:doFinalize(652)) - Finalizing upgrade for storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/current/BP-1584977637-172.17.0.10-1606980162785.
   cur LV = -57; cur CTime = 1606980162785
2020-12-03 07:23:02,680 [Finalize /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-1584977637-172.17.0.10-1606980162785] INFO  common.Storage (BlockPoolSliceStorage.java:run(670)) - Finalize upgrade for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-1584977637-172.17.0.10-1606980162785 is complete.
2020-12-03 07:23:02,680 [Finalize /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/current/BP-1584977637-172.17.0.10-1606980162785] INFO  common.Storage (BlockPoolSliceStorage.java:run(670)) - Finalize upgrade for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/current/BP-1584977637-172.17.0.10-1606980162785 is complete.
2020-12-03 07:23:03,800 [Listener at localhost/36987] INFO  hdfs.TestDFSFinalize (TestDFSFinalize.java:log(56)) - ============================================================
2020-12-03 07:23:03,801 [Listener at localhost/36987] INFO  hdfs.TestDFSFinalize (TestDFSFinalize.java:log(57)) - ***TEST 7*** Finalize NN & BP without existing previous dir: numDirs=2
2020-12-03 07:23:03,802 [IPC Server handler 2 on default port 42252] INFO  namenode.FSImage (FSImage.java:finalizeUpgrade(614)) - Finalizing upgrade for local dirs. 
   cur LV = -65; cur CTime = 1606980162785
2020-12-03 07:23:03,803 [IPC Server handler 2 on default port 42252] INFO  namenode.NNUpgradeUtil (NNUpgradeUtil.java:doFinalize(91)) - Directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/previous does not exist.
2020-12-03 07:23:03,803 [IPC Server handler 2 on default port 42252] INFO  namenode.NNUpgradeUtil (NNUpgradeUtil.java:doFinalize(92)) - Finalize upgrade for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1 is not required.
2020-12-03 07:23:03,803 [IPC Server handler 2 on default port 42252] INFO  namenode.NNUpgradeUtil (NNUpgradeUtil.java:doFinalize(91)) - Directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/previous does not exist.
2020-12-03 07:23:03,803 [IPC Server handler 2 on default port 42252] INFO  namenode.NNUpgradeUtil (NNUpgradeUtil.java:doFinalize(92)) - Finalize upgrade for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2 is not required.
2020-12-03 07:23:03,803 [IPC Server handler 2 on default port 42252] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=finalizeUpgrade	src=null	dst=null	perm=null	proto=rpc
Finalize upgrade successful
2020-12-03 07:23:03,807 [BP-1584977637-172.17.0.10-1606980162785 heartbeating to localhost/127.0.0.1:42252] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:42252
2020-12-03 07:23:03,809 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x15e557dcdfdfd353: from storage DS-f2b90e12-0401-46d5-a804-098b4e1c4fc6 node DatanodeRegistration(127.0.0.1:34393, datanodeUuid=f1d8177d-b4c6-4841-8546-addcebbb1ab1, infoPort=39752, infoSecurePort=0, ipcPort=36987, storageInfo=lv=-57;cid=testClusterID;nsid=60730268;c=1606980162785), blocks: 16, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:03,809 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x15e557dcdfdfd353: from storage DS-b06fa154-9af2-4db9-92d8-164709b740ec node DatanodeRegistration(127.0.0.1:34393, datanodeUuid=f1d8177d-b4c6-4841-8546-addcebbb1ab1, infoPort=39752, infoSecurePort=0, ipcPort=36987, storageInfo=lv=-57;cid=testClusterID;nsid=60730268;c=1606980162785), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:03,810 [BP-1584977637-172.17.0.10-1606980162785 heartbeating to localhost/127.0.0.1:42252] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x15e557dcdfdfd353,  containing 2 storage report(s), of which we sent 2. The reports had 16 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:23:03,810 [BP-1584977637-172.17.0.10-1606980162785 heartbeating to localhost/127.0.0.1:42252] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1584977637-172.17.0.10-1606980162785
2020-12-03 07:23:04,930 [Listener at localhost/36987] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:23:04,930 [Listener at localhost/36987] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:23:04,930 [Listener at localhost/36987] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:23:04,930 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@f4c0e4e] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:05,126 [Listener at localhost/36987] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6f38a289{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:05,127 [Listener at localhost/36987] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@61e3cf4d{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:05,128 [Listener at localhost/36987] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@f2ce6b{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:05,128 [Listener at localhost/36987] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3d98d138{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:05,131 [Listener at localhost/36987] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 36987
2020-12-03 07:23:05,133 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:05,133 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:05,134 [BP-1584977637-172.17.0.10-1606980162785 heartbeating to localhost/127.0.0.1:42252] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:05,134 [BP-1584977637-172.17.0.10-1606980162785 heartbeating to localhost/127.0.0.1:42252] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1584977637-172.17.0.10-1606980162785 (Datanode Uuid f1d8177d-b4c6-4841-8546-addcebbb1ab1) service to localhost/127.0.0.1:42252
2020-12-03 07:23:05,134 [BP-1584977637-172.17.0.10-1606980162785 heartbeating to localhost/127.0.0.1:42252] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1584977637-172.17.0.10-1606980162785 (Datanode Uuid f1d8177d-b4c6-4841-8546-addcebbb1ab1)
2020-12-03 07:23:05,134 [BP-1584977637-172.17.0.10-1606980162785 heartbeating to localhost/127.0.0.1:42252] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1584977637-172.17.0.10-1606980162785
2020-12-03 07:23:05,137 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data1/current/BP-1584977637-172.17.0.10-1606980162785] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:05,137 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data2/current/BP-1584977637-172.17.0.10-1606980162785] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:05,140 [Listener at localhost/36987] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:23:05,140 [Listener at localhost/36987] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:23:05,141 [Listener at localhost/36987] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:23:05,141 [Listener at localhost/36987] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:23:05,142 [Listener at localhost/36987] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:05,143 [Listener at localhost/36987] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:23:05,143 [Listener at localhost/36987] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:05,143 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@6d9fb2d1] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:23:05,143 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@4682eba5] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:23:05,143 [Listener at localhost/36987] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 62, 62
2020-12-03 07:23:05,145 [Listener at localhost/36987] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 2 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 61 Number of syncs: 3 SyncTimes(ms): 1 1 
2020-12-03 07:23:05,145 [Listener at localhost/36987] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_inprogress_0000000000000000062 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name1/current/edits_0000000000000000062-0000000000000000063
2020-12-03 07:23:05,146 [Listener at localhost/36987] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_inprogress_0000000000000000062 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name2/current/edits_0000000000000000062-0000000000000000063
2020-12-03 07:23:05,147 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:23:05,147 [CacheReplicationMonitor(1693976077)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:23:05,147 [Listener at localhost/36987] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 42252
2020-12-03 07:23:05,150 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:05,150 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:05,151 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:23:05,151 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:23:05,162 [Listener at localhost/36987] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:05,163 [Listener at localhost/36987] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:23:05,165 [Listener at localhost/36987] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6fd77352{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:23:05,170 [Listener at localhost/36987] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@5109e8cf{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:05,171 [Listener at localhost/36987] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1f6d27cc{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:05,171 [Listener at localhost/36987] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@45d6ef73{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:23:05,173 [Listener at localhost/36987] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-12-03 07:23:05,175 [Listener at localhost/36987] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-12-03 07:23:05,175 [Listener at localhost/36987] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-12-03 07:23:05,196 [Listener at localhost/36987] INFO  hdfs.TestDFSFinalize (TestDFSFinalize.java:tearDown(190)) - Shutting down MiniDFSCluster
2020-12-03 07:23:05,198 [Listener at localhost/36987] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:23:05,198 [Listener at localhost/36987] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
msx-rc 0
