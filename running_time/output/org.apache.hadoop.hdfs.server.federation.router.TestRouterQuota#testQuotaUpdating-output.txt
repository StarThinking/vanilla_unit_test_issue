2020-12-03 07:20:10,774 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=2, numDataNodes=4
Formatting using clusterid: testClusterID
2020-12-03 07:20:11,528 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:20:11,545 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:20:11,547 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:20:11,547 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:20:11,556 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:20:11,556 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:20:11,557 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:20:11,558 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns0
2020-12-03 07:20:11,558 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:20:11,621 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:11,626 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2020-12-03 07:20:11,627 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:20:11,627 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:20:11,634 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:20:11,635 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:20:11
2020-12-03 07:20:11,639 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:20:11,639 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:11,642 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-12-03 07:20:11,642 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:20:11,663 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:20:11,663 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:20:11,672 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:20:11,673 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:20:11,673 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:20:11,674 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:20:11,675 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 1
2020-12-03 07:20:11,675 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:20:11,675 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:20:11,675 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:20:11,676 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:20:11,676 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:20:11,676 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:20:11,716 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GLOBAL serial map: bits=29 maxEntries=536870911
2020-12-03 07:20:11,717 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - USER serial map: bits=24 maxEntries=16777215
2020-12-03 07:20:11,717 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GROUP serial map: bits=24 maxEntries=16777215
2020-12-03 07:20:11,717 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - XATTR serial map: bits=24 maxEntries=16777215
2020-12-03 07:20:11,738 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:20:11,738 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:11,739 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-12-03 07:20:11,739 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:20:11,745 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:20:11,746 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:20:11,746 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:20:11,746 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:20:11,753 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:20:11,757 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:20:11,762 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:20:11,763 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:11,763 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-12-03 07:20:11,763 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:20:11,775 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:20:11,776 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:20:11,776 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:20:11,781 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:20:11,781 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:20:11,784 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:20:11,785 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:11,785 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-12-03 07:20:11,785 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:20:11,823 [main] INFO  namenode.FSImage (FSImage.java:format(185)) - Allocated new BlockPoolId: BP-442495584-172.17.0.8-1606980011809
2020-12-03 07:20:11,972 [main] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-12-03 07:20:12,072 [main] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-12-03 07:20:12,110 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:20:12,110 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:20:12,258 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:20:12,258 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:20:12,361 [main] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-12-03 07:20:12,365 [main] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:20:12,437 [main] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-namenode.properties,hadoop-metrics2.properties
2020-12-03 07:20:12,811 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2020-12-03 07:20:12,812 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:20:12,843 [main] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://ns0
2020-12-03 07:20:12,896 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7d9f158f] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:12,914 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:20:12,942 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @3142ms
2020-12-03 07:20:13,072 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:13,077 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:20:13,090 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:13,092 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:20:13,093 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:13,093 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:13,127 [main] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:20:13,128 [main] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:20:13,140 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 45485
2020-12-03 07:20:13,143 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:13,192 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@20f5281c{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:20:13,193 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@341814d3{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:20:13,472 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1b955cac{/,file:///tmp/jetty-localhost-45485-hdfs-_-any-7018387645082930758.dir/webapp/,AVAILABLE}{/hdfs}
2020-12-03 07:20:13,480 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1f010bf0{HTTP/1.1,[http/1.1]}{localhost:45485}
2020-12-03 07:20:13,481 [main] INFO  server.Server (Server.java:doStart(419)) - Started @3681ms
2020-12-03 07:20:13,491 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:20:13,492 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:20:13,493 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:20:13,493 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:20:13,494 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:20:13,494 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:20:13,494 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:20:13,495 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns0
2020-12-03 07:20:13,495 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:20:13,510 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:13,511 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:20:13,511 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:20:13,511 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:20:13,512 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:20:13
2020-12-03 07:20:13,512 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:20:13,512 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:13,513 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:20:13,513 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:20:13,518 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:20:13,518 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:20:13,519 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:20:13,519 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:20:13,519 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:20:13,519 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:20:13,520 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 1
2020-12-03 07:20:13,520 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:20:13,520 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:20:13,520 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:20:13,520 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:20:13,521 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:20:13,521 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:20:13,521 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:20:13,521 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:13,522 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:20:13,522 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:20:13,525 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:20:13,525 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:20:13,525 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:20:13,526 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:20:13,526 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:20:13,526 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:20:13,526 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:20:13,527 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:13,527 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:20:13,527 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:20:13,528 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:20:13,529 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:20:13,529 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:20:13,529 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:20:13,529 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:20:13,529 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:20:13,530 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:13,530 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:20:13,530 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:20:13,623 [main] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 945@b120fe239ee9
2020-12-03 07:20:13,720 [main] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 945@b120fe239ee9
2020-12-03 07:20:13,724 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current
2020-12-03 07:20:13,724 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/current
2020-12-03 07:20:13,725 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:20:13,725 [main] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:20:13,761 [main] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:20:13,769 [main] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:20:13,770 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-12-03 07:20:13,775 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:20:13,776 [main] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 1
2020-12-03 07:20:14,022 [main] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:20:14,023 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 491 msecs
2020-12-03 07:20:14,243 [main] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to 0.0.0.0:0
2020-12-03 07:20:14,291 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:14,305 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:14,591 [Listener at 0.0.0.0/38725] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:38725 to access this namenode/service.
2020-12-03 07:20:14,594 [Listener at 0.0.0.0/38725] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:20:14,612 [Listener at 0.0.0.0/38725] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:20:14,625 [Listener at 0.0.0.0/38725] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:20:14,625 [Listener at 0.0.0.0/38725] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:20:14,626 [Listener at 0.0.0.0/38725] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:20:14,626 [Listener at 0.0.0.0/38725] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:20:14,629 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 0
2020-12-03 07:20:14,629 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:20:14,630 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:20:14,630 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:20:14,630 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:20:14,630 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 5 msec
2020-12-03 07:20:14,661 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:14,661 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:14,665 [Listener at 0.0.0.0/38725] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:38725
2020-12-03 07:20:14,667 [Listener at 0.0.0.0/38725] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:20:14,667 [Listener at 0.0.0.0/38725] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:20:14,675 [Listener at 0.0.0.0/38725] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 8 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:20:14,681 [CacheReplicationMonitor(212274427)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
Formatting using clusterid: testClusterID
2020-12-03 07:20:14,685 [Listener at 0.0.0.0/38725] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:20:14,685 [Listener at 0.0.0.0/38725] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:20:14,686 [Listener at 0.0.0.0/38725] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:20:14,686 [Listener at 0.0.0.0/38725] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:20:14,686 [Listener at 0.0.0.0/38725] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:20:14,686 [Listener at 0.0.0.0/38725] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:20:14,686 [Listener at 0.0.0.0/38725] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:20:14,687 [Listener at 0.0.0.0/38725] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns1
2020-12-03 07:20:14,687 [Listener at 0.0.0.0/38725] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:20:14,687 [Listener at 0.0.0.0/38725] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:14,688 [Listener at 0.0.0.0/38725] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:20:14,688 [Listener at 0.0.0.0/38725] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:20:14,688 [Listener at 0.0.0.0/38725] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:20:14,689 [Listener at 0.0.0.0/38725] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:20:14
2020-12-03 07:20:14,689 [Listener at 0.0.0.0/38725] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:20:14,689 [Listener at 0.0.0.0/38725] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:14,690 [Listener at 0.0.0.0/38725] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:20:14,690 [Listener at 0.0.0.0/38725] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:20:14,702 [Listener at 0.0.0.0/38725] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:20:14,702 [Listener at 0.0.0.0/38725] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:20:14,703 [Listener at 0.0.0.0/38725] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:20:14,703 [Listener at 0.0.0.0/38725] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:20:14,703 [Listener at 0.0.0.0/38725] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:20:14,703 [Listener at 0.0.0.0/38725] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:20:14,703 [Listener at 0.0.0.0/38725] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 1
2020-12-03 07:20:14,704 [Listener at 0.0.0.0/38725] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:20:14,704 [Listener at 0.0.0.0/38725] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:20:14,704 [Listener at 0.0.0.0/38725] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:20:14,704 [Listener at 0.0.0.0/38725] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:20:14,704 [Listener at 0.0.0.0/38725] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:20:14,704 [Listener at 0.0.0.0/38725] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:20:14,705 [Listener at 0.0.0.0/38725] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:20:14,705 [Listener at 0.0.0.0/38725] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:14,707 [Listener at 0.0.0.0/38725] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:20:14,707 [Listener at 0.0.0.0/38725] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:20:14,713 [Listener at 0.0.0.0/38725] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:20:14,713 [Listener at 0.0.0.0/38725] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:20:14,714 [Listener at 0.0.0.0/38725] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:20:14,714 [Listener at 0.0.0.0/38725] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:20:14,714 [Listener at 0.0.0.0/38725] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:20:14,714 [Listener at 0.0.0.0/38725] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:20:14,714 [Listener at 0.0.0.0/38725] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:20:14,714 [Listener at 0.0.0.0/38725] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:14,715 [Listener at 0.0.0.0/38725] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:20:14,715 [Listener at 0.0.0.0/38725] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:20:14,717 [Listener at 0.0.0.0/38725] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:20:14,717 [Listener at 0.0.0.0/38725] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:20:14,717 [Listener at 0.0.0.0/38725] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:20:14,717 [Listener at 0.0.0.0/38725] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:20:14,718 [Listener at 0.0.0.0/38725] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:20:14,718 [Listener at 0.0.0.0/38725] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:20:14,718 [Listener at 0.0.0.0/38725] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:14,719 [Listener at 0.0.0.0/38725] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:20:14,719 [Listener at 0.0.0.0/38725] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:20:14,721 [Listener at 0.0.0.0/38725] INFO  namenode.FSImage (FSImage.java:format(185)) - Allocated new BlockPoolId: BP-1196056580-172.17.0.8-1606980014721
2020-12-03 07:20:14,997 [Listener at 0.0.0.0/38725] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-3 has been successfully formatted.
2020-12-03 07:20:15,355 [Listener at 0.0.0.0/38725] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-4 has been successfully formatted.
2020-12-03 07:20:15,368 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-3 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-3/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:20:15,368 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-4 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-4/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:20:15,373 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-4 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-4/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:20:15,374 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-3 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-3/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:20:15,559 [Listener at 0.0.0.0/38725] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-12-03 07:20:15,562 [Listener at 0.0.0.0/38725] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:20:15,562 [Listener at 0.0.0.0/38725] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-12-03 07:20:15,563 [Listener at 0.0.0.0/38725] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://ns0
2020-12-03 07:20:15,571 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@8ab78bc] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:15,571 [Listener at 0.0.0.0/38725] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:20:15,573 [Listener at 0.0.0.0/38725] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:15,574 [Listener at 0.0.0.0/38725] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:20:15,576 [Listener at 0.0.0.0/38725] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:15,577 [Listener at 0.0.0.0/38725] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:20:15,577 [Listener at 0.0.0.0/38725] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:15,577 [Listener at 0.0.0.0/38725] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:15,580 [Listener at 0.0.0.0/38725] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:20:15,580 [Listener at 0.0.0.0/38725] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:20:15,581 [Listener at 0.0.0.0/38725] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 39049
2020-12-03 07:20:15,581 [Listener at 0.0.0.0/38725] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:15,584 [Listener at 0.0.0.0/38725] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@486be205{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:20:15,585 [Listener at 0.0.0.0/38725] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@74f7d1d2{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:20:15,772 [Listener at 0.0.0.0/38725] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@2e8ab815{/,file:///tmp/jetty-localhost-39049-hdfs-_-any-9016128233234926312.dir/webapp/,AVAILABLE}{/hdfs}
2020-12-03 07:20:15,773 [Listener at 0.0.0.0/38725] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@67af833b{HTTP/1.1,[http/1.1]}{localhost:39049}
2020-12-03 07:20:15,774 [Listener at 0.0.0.0/38725] INFO  server.Server (Server.java:doStart(419)) - Started @5975ms
2020-12-03 07:20:15,778 [Listener at 0.0.0.0/38725] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:20:15,778 [Listener at 0.0.0.0/38725] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:20:15,779 [Listener at 0.0.0.0/38725] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:20:15,779 [Listener at 0.0.0.0/38725] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:20:15,779 [Listener at 0.0.0.0/38725] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:20:15,779 [Listener at 0.0.0.0/38725] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:20:15,779 [Listener at 0.0.0.0/38725] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:20:15,780 [Listener at 0.0.0.0/38725] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns1
2020-12-03 07:20:15,780 [Listener at 0.0.0.0/38725] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:20:15,780 [Listener at 0.0.0.0/38725] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:15,781 [Listener at 0.0.0.0/38725] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:20:15,781 [Listener at 0.0.0.0/38725] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:20:15,781 [Listener at 0.0.0.0/38725] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:20:15,782 [Listener at 0.0.0.0/38725] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:20:15
2020-12-03 07:20:15,782 [Listener at 0.0.0.0/38725] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:20:15,782 [Listener at 0.0.0.0/38725] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:15,783 [Listener at 0.0.0.0/38725] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:20:15,783 [Listener at 0.0.0.0/38725] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:20:15,795 [Listener at 0.0.0.0/38725] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:20:15,795 [Listener at 0.0.0.0/38725] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:20:15,795 [Listener at 0.0.0.0/38725] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:20:15,796 [Listener at 0.0.0.0/38725] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:20:15,796 [Listener at 0.0.0.0/38725] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:20:15,796 [Listener at 0.0.0.0/38725] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:20:15,796 [Listener at 0.0.0.0/38725] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 1
2020-12-03 07:20:15,796 [Listener at 0.0.0.0/38725] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:20:15,796 [Listener at 0.0.0.0/38725] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:20:15,797 [Listener at 0.0.0.0/38725] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:20:15,797 [Listener at 0.0.0.0/38725] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:20:15,797 [Listener at 0.0.0.0/38725] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:20:15,797 [Listener at 0.0.0.0/38725] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:20:15,798 [Listener at 0.0.0.0/38725] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:20:15,798 [Listener at 0.0.0.0/38725] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:15,798 [Listener at 0.0.0.0/38725] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:20:15,798 [Listener at 0.0.0.0/38725] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:20:15,804 [Listener at 0.0.0.0/38725] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:20:15,804 [Listener at 0.0.0.0/38725] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:20:15,805 [Listener at 0.0.0.0/38725] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:20:15,805 [Listener at 0.0.0.0/38725] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:20:15,805 [Listener at 0.0.0.0/38725] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:20:15,805 [Listener at 0.0.0.0/38725] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:20:15,805 [Listener at 0.0.0.0/38725] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:20:15,806 [Listener at 0.0.0.0/38725] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:15,806 [Listener at 0.0.0.0/38725] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:20:15,806 [Listener at 0.0.0.0/38725] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:20:15,808 [Listener at 0.0.0.0/38725] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:20:15,808 [Listener at 0.0.0.0/38725] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:20:15,808 [Listener at 0.0.0.0/38725] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:20:15,808 [Listener at 0.0.0.0/38725] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:20:15,809 [Listener at 0.0.0.0/38725] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:20:15,809 [Listener at 0.0.0.0/38725] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:20:15,809 [Listener at 0.0.0.0/38725] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:15,809 [Listener at 0.0.0.0/38725] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:20:15,809 [Listener at 0.0.0.0/38725] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:20:15,914 [Listener at 0.0.0.0/38725] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-3/in_use.lock acquired by nodename 945@b120fe239ee9
2020-12-03 07:20:16,042 [Listener at 0.0.0.0/38725] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-4/in_use.lock acquired by nodename 945@b120fe239ee9
2020-12-03 07:20:16,045 [Listener at 0.0.0.0/38725] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-3/current
2020-12-03 07:20:16,045 [Listener at 0.0.0.0/38725] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-4/current
2020-12-03 07:20:16,046 [Listener at 0.0.0.0/38725] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:20:16,046 [Listener at 0.0.0.0/38725] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-3/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:20:16,048 [Listener at 0.0.0.0/38725] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:20:16,049 [Listener at 0.0.0.0/38725] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:20:16,049 [Listener at 0.0.0.0/38725] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-3/current/fsimage_0000000000000000000
2020-12-03 07:20:16,050 [Listener at 0.0.0.0/38725] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:20:16,050 [Listener at 0.0.0.0/38725] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 1
2020-12-03 07:20:16,261 [Listener at 0.0.0.0/38725] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:20:16,262 [Listener at 0.0.0.0/38725] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 451 msecs
2020-12-03 07:20:16,263 [Listener at 0.0.0.0/38725] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to 0.0.0.0:0
2020-12-03 07:20:16,264 [Listener at 0.0.0.0/38725] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:16,265 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:16,278 [Listener at 0.0.0.0/46765] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:46765 to access this namenode/service.
2020-12-03 07:20:16,280 [Listener at 0.0.0.0/46765] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:20:16,328 [Listener at 0.0.0.0/46765] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:20:16,330 [Listener at 0.0.0.0/46765] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:20:16,330 [Listener at 0.0.0.0/46765] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:20:16,330 [Listener at 0.0.0.0/46765] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:20:16,330 [Listener at 0.0.0.0/46765] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:20:16,334 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 0
2020-12-03 07:20:16,334 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:20:16,334 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:20:16,334 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:20:16,334 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:20:16,334 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 4 msec
2020-12-03 07:20:16,340 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:16,340 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:16,344 [Listener at 0.0.0.0/46765] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:46765
2020-12-03 07:20:16,344 [Listener at 0.0.0.0/46765] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:20:16,344 [Listener at 0.0.0.0/46765] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:20:16,346 [Listener at 0.0.0.0/46765] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 0 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:20:16,348 [CacheReplicationMonitor(11880)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:20:16,359 [Listener at 0.0.0.0/46765] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-12-03 07:20:16,430 [Listener at 0.0.0.0/46765] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-12-03 07:20:16,444 [Listener at 0.0.0.0/46765] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-12-03 07:20:16,465 [Listener at 0.0.0.0/46765] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:16,470 [Listener at 0.0.0.0/46765] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:16,474 [Listener at 0.0.0.0/46765] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:16,478 [Listener at 0.0.0.0/46765] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:16,479 [Listener at 0.0.0.0/46765] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:16,483 [Listener at 0.0.0.0/46765] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:16,490 [Listener at 0.0.0.0/46765] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:38963
2020-12-03 07:20:16,492 [Listener at 0.0.0.0/46765] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:16,493 [Listener at 0.0.0.0/46765] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:16,512 [Listener at 0.0.0.0/46765] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:16,513 [Listener at 0.0.0.0/46765] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:16,515 [Listener at 0.0.0.0/46765] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:16,516 [Listener at 0.0.0.0/46765] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:16,516 [Listener at 0.0.0.0/46765] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:16,517 [Listener at 0.0.0.0/46765] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:16,520 [Listener at 0.0.0.0/46765] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 40061
2020-12-03 07:20:16,520 [Listener at 0.0.0.0/46765] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:16,522 [Listener at 0.0.0.0/46765] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@74a9c4b0{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:20:16,523 [Listener at 0.0.0.0/46765] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1c05a54d{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:20:16,710 [Listener at 0.0.0.0/46765] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3add81c4{/,file:///tmp/jetty-localhost-40061-datanode-_-any-1456476231779121471.dir/webapp/,AVAILABLE}{/datanode}
2020-12-03 07:20:16,712 [Listener at 0.0.0.0/46765] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1a1d3c1a{HTTP/1.1,[http/1.1]}{localhost:40061}
2020-12-03 07:20:16,714 [Listener at 0.0.0.0/46765] INFO  server.Server (Server.java:doStart(419)) - Started @6914ms
2020-12-03 07:20:17,246 [Listener at 0.0.0.0/46765] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:33651
2020-12-03 07:20:17,247 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@412c995d] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:17,248 [Listener at 0.0.0.0/46765] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:17,248 [Listener at 0.0.0.0/46765] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:17,266 [Listener at 0.0.0.0/46765] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:17,267 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:17,274 [Listener at localhost/44444] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:44444
2020-12-03 07:20:17,295 [Listener at localhost/44444] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns0,ns1
2020-12-03 07:20:17,297 [Listener at localhost/44444] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns0,ns1
2020-12-03 07:20:17,310 [Thread-101] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46765 starting to offer service
2020-12-03 07:20:17,310 [Thread-100] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38725 starting to offer service
2020-12-03 07:20:17,319 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:17,319 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:17,323 [Listener at localhost/44444] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-12-03 07:20:17,325 [Listener at localhost/44444] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-12-03 07:20:17,326 [Listener at localhost/44444] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-12-03 07:20:17,328 [Listener at localhost/44444] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:17,328 [Listener at localhost/44444] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:17,329 [Listener at localhost/44444] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:17,329 [Listener at localhost/44444] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:17,329 [Listener at localhost/44444] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:17,330 [Listener at localhost/44444] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:17,331 [Listener at localhost/44444] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:44357
2020-12-03 07:20:17,331 [Listener at localhost/44444] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:17,331 [Listener at localhost/44444] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:17,334 [Listener at localhost/44444] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:17,335 [Listener at localhost/44444] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:17,337 [Listener at localhost/44444] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:17,338 [Listener at localhost/44444] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:17,338 [Listener at localhost/44444] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:17,338 [Listener at localhost/44444] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:17,339 [Listener at localhost/44444] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 33444
2020-12-03 07:20:17,339 [Listener at localhost/44444] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:17,342 [Listener at localhost/44444] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1d3e6d34{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:20:17,342 [Listener at localhost/44444] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@26a94fa5{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:20:17,520 [Listener at localhost/44444] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5eccd3b9{/,file:///tmp/jetty-localhost-33444-datanode-_-any-5115383260402704723.dir/webapp/,AVAILABLE}{/datanode}
2020-12-03 07:20:17,522 [Listener at localhost/44444] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4d6f197e{HTTP/1.1,[http/1.1]}{localhost:33444}
2020-12-03 07:20:17,522 [Listener at localhost/44444] INFO  server.Server (Server.java:doStart(419)) - Started @7723ms
2020-12-03 07:20:17,563 [Thread-101] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46765
2020-12-03 07:20:17,563 [Thread-100] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38725
2020-12-03 07:20:17,565 [Thread-101] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:17,611 [Listener at localhost/44444] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:34551
2020-12-03 07:20:17,612 [Listener at localhost/44444] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:17,612 [Listener at localhost/44444] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:17,612 [Listener at localhost/44444] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:17,612 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@64e1dd11] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:17,614 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:17,618 [Listener at localhost/41249] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:41249
2020-12-03 07:20:17,624 [Listener at localhost/41249] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns0,ns1
2020-12-03 07:20:17,625 [Listener at localhost/41249] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns0,ns1
2020-12-03 07:20:17,625 [Thread-125] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38725 starting to offer service
2020-12-03 07:20:17,626 [Thread-126] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46765 starting to offer service
2020-12-03 07:20:17,633 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:17,643 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:17,655 [Thread-101] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 945@b120fe239ee9
2020-12-03 07:20:17,666 [Listener at localhost/41249] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-12-03 07:20:17,668 [Listener at localhost/41249] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-12-03 07:20:17,669 [Listener at localhost/41249] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-12-03 07:20:17,670 [Listener at localhost/41249] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:17,671 [Listener at localhost/41249] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:17,671 [Listener at localhost/41249] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:17,672 [Listener at localhost/41249] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:17,672 [Listener at localhost/41249] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:17,672 [Listener at localhost/41249] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:17,673 [Listener at localhost/41249] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:38408
2020-12-03 07:20:17,673 [Listener at localhost/41249] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:17,673 [Listener at localhost/41249] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:17,677 [Listener at localhost/41249] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:17,679 [Thread-101] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1 is not formatted for namespace 1484114581. Formatting...
2020-12-03 07:20:17,680 [Thread-125] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38725
2020-12-03 07:20:17,681 [Thread-125] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:17,681 [Listener at localhost/41249] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:17,682 [Thread-126] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46765
2020-12-03 07:20:17,682 [Thread-101] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-e52a9cea-fdc2-430f-b809-6ea6c5790b20 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1 
2020-12-03 07:20:17,684 [Listener at localhost/41249] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:17,685 [Listener at localhost/41249] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:17,685 [Listener at localhost/41249] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:17,686 [Listener at localhost/41249] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:17,686 [Listener at localhost/41249] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 41962
2020-12-03 07:20:17,687 [Listener at localhost/41249] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:17,689 [Listener at localhost/41249] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4d8539de{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:20:17,689 [Listener at localhost/41249] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@272a179c{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:20:17,767 [Thread-125] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 945@b120fe239ee9
2020-12-03 07:20:17,767 [Thread-125] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3 is not formatted for namespace 1294197665. Formatting...
2020-12-03 07:20:17,767 [Thread-125] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-10b59786-dd4a-42b3-8172-914cf700b081 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3 
2020-12-03 07:20:17,864 [Listener at localhost/41249] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5f462e3b{/,file:///tmp/jetty-localhost-41962-datanode-_-any-4359429309055389068.dir/webapp/,AVAILABLE}{/datanode}
2020-12-03 07:20:17,865 [Listener at localhost/41249] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3d7fa3ae{HTTP/1.1,[http/1.1]}{localhost:41962}
2020-12-03 07:20:17,866 [Listener at localhost/41249] INFO  server.Server (Server.java:doStart(419)) - Started @8066ms
2020-12-03 07:20:17,890 [Listener at localhost/41249] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:46144
2020-12-03 07:20:17,890 [Listener at localhost/41249] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:17,890 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3605c4d3] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:17,890 [Listener at localhost/41249] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:17,891 [Listener at localhost/41249] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:17,892 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:17,895 [Listener at localhost/46440] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:46440
2020-12-03 07:20:17,900 [Listener at localhost/46440] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns0,ns1
2020-12-03 07:20:17,900 [Listener at localhost/46440] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns0,ns1
2020-12-03 07:20:17,901 [Thread-148] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38725 starting to offer service
2020-12-03 07:20:17,901 [Thread-149] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46765 starting to offer service
2020-12-03 07:20:17,903 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:17,903 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:17,905 [Thread-149] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46765
2020-12-03 07:20:17,905 [Thread-148] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38725
2020-12-03 07:20:17,906 [Thread-149] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:17,906 [Listener at localhost/46440] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 3 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-12-03 07:20:17,908 [Listener at localhost/46440] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7
2020-12-03 07:20:17,908 [Listener at localhost/46440] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-12-03 07:20:17,909 [Listener at localhost/46440] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:17,910 [Listener at localhost/46440] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:17,910 [Listener at localhost/46440] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:17,911 [Listener at localhost/46440] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:17,911 [Listener at localhost/46440] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:17,911 [Listener at localhost/46440] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:17,912 [Listener at localhost/46440] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:33835
2020-12-03 07:20:17,912 [Listener at localhost/46440] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:17,912 [Listener at localhost/46440] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:17,915 [Listener at localhost/46440] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:17,915 [Listener at localhost/46440] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:17,917 [Listener at localhost/46440] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:17,918 [Listener at localhost/46440] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:17,918 [Listener at localhost/46440] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:17,918 [Listener at localhost/46440] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:17,919 [Listener at localhost/46440] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 42660
2020-12-03 07:20:17,919 [Listener at localhost/46440] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:17,921 [Listener at localhost/46440] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@599f571f{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:20:17,922 [Listener at localhost/46440] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3fbfa96{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:20:18,011 [Thread-101] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 945@b120fe239ee9
2020-12-03 07:20:18,014 [Thread-101] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2 is not formatted for namespace 1484114581. Formatting...
2020-12-03 07:20:18,014 [Thread-101] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-d8458332-36c9-46f8-afdf-c2195c0ebf3a for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2 
2020-12-03 07:20:18,015 [Thread-149] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 945@b120fe239ee9
2020-12-03 07:20:18,016 [Thread-149] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5 is not formatted for namespace 1484114581. Formatting...
2020-12-03 07:20:18,016 [Thread-149] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-83fd7724-742b-40a1-bf8e-dcb9168386f8 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5 
2020-12-03 07:20:18,099 [Thread-125] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 945@b120fe239ee9
2020-12-03 07:20:18,099 [Thread-125] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4 is not formatted for namespace 1294197665. Formatting...
2020-12-03 07:20:18,102 [Thread-125] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-5fa6371f-9ba8-4a41-b4aa-d539ceb7700f for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4 
2020-12-03 07:20:18,108 [Listener at localhost/46440] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7b44b63d{/,file:///tmp/jetty-localhost-42660-datanode-_-any-2156456173955758397.dir/webapp/,AVAILABLE}{/datanode}
2020-12-03 07:20:18,112 [Listener at localhost/46440] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4a699efa{HTTP/1.1,[http/1.1]}{localhost:42660}
2020-12-03 07:20:18,113 [Listener at localhost/46440] INFO  server.Server (Server.java:doStart(419)) - Started @8313ms
2020-12-03 07:20:18,188 [Listener at localhost/46440] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:39227
2020-12-03 07:20:18,189 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4905c46b] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:18,189 [Listener at localhost/46440] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:18,189 [Listener at localhost/46440] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:18,190 [Listener at localhost/46440] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:18,191 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:18,198 [Listener at localhost/45254] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:45254
2020-12-03 07:20:18,205 [Listener at localhost/45254] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns0,ns1
2020-12-03 07:20:18,206 [Listener at localhost/45254] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns0,ns1
2020-12-03 07:20:18,207 [Thread-171] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38725 starting to offer service
2020-12-03 07:20:18,208 [Thread-172] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46765 starting to offer service
2020-12-03 07:20:18,210 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:18,210 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:18,213 [Thread-172] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46765
2020-12-03 07:20:18,213 [Thread-171] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38725
2020-12-03 07:20:18,213 [Thread-172] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:18,233 [Thread-101] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1196056580-172.17.0.8-1606980014721
2020-12-03 07:20:18,234 [Thread-101] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-1196056580-172.17.0.8-1606980014721
2020-12-03 07:20:18,234 [Thread-101] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1 and block pool id BP-1196056580-172.17.0.8-1606980014721 is not formatted. Formatting ...
2020-12-03 07:20:18,235 [Thread-101] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1196056580-172.17.0.8-1606980014721 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-1196056580-172.17.0.8-1606980014721/current
2020-12-03 07:20:18,378 [Thread-172] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/in_use.lock acquired by nodename 945@b120fe239ee9
2020-12-03 07:20:18,378 [Thread-149] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 945@b120fe239ee9
2020-12-03 07:20:18,379 [Thread-172] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7 is not formatted for namespace 1484114581. Formatting...
2020-12-03 07:20:18,379 [Thread-149] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6 is not formatted for namespace 1484114581. Formatting...
2020-12-03 07:20:18,379 [Thread-172] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-5b55ee66-15b3-4cba-8c37-e81745468554 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7 
2020-12-03 07:20:18,379 [Thread-149] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-80699e0e-37c6-48a4-8564-b17c23a6c31a for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6 
2020-12-03 07:20:18,461 [Thread-125] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-442495584-172.17.0.8-1606980011809
2020-12-03 07:20:18,461 [Thread-125] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-442495584-172.17.0.8-1606980011809
2020-12-03 07:20:18,461 [Thread-125] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3 and block pool id BP-442495584-172.17.0.8-1606980011809 is not formatted. Formatting ...
2020-12-03 07:20:18,461 [Thread-125] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-442495584-172.17.0.8-1606980011809 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-442495584-172.17.0.8-1606980011809/current
2020-12-03 07:20:18,528 [Thread-101] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1196056580-172.17.0.8-1606980014721
2020-12-03 07:20:18,528 [Thread-101] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-1196056580-172.17.0.8-1606980014721
2020-12-03 07:20:18,528 [Thread-101] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2 and block pool id BP-1196056580-172.17.0.8-1606980014721 is not formatted. Formatting ...
2020-12-03 07:20:18,529 [Thread-101] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1196056580-172.17.0.8-1606980014721 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-1196056580-172.17.0.8-1606980014721/current
2020-12-03 07:20:18,683 [IPC Server handler 4 on default port 38725] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:18,691 [Listener at localhost/45254] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:18,691 [Listener at localhost/45254] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:18,710 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1196056580-172.17.0.8-1606980014721
2020-12-03 07:20:18,710 [Thread-149] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-1196056580-172.17.0.8-1606980014721
2020-12-03 07:20:18,711 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5 and block pool id BP-1196056580-172.17.0.8-1606980014721 is not formatted. Formatting ...
2020-12-03 07:20:18,711 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1196056580-172.17.0.8-1606980014721 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-1196056580-172.17.0.8-1606980014721/current
2020-12-03 07:20:18,769 [Thread-125] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-442495584-172.17.0.8-1606980011809
2020-12-03 07:20:18,769 [Thread-125] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-442495584-172.17.0.8-1606980011809
2020-12-03 07:20:18,769 [Thread-125] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4 and block pool id BP-442495584-172.17.0.8-1606980011809 is not formatted. Formatting ...
2020-12-03 07:20:18,770 [Thread-125] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-442495584-172.17.0.8-1606980011809 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-442495584-172.17.0.8-1606980011809/current
2020-12-03 07:20:18,794 [IPC Server handler 2 on default port 38725] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:18,795 [Listener at localhost/45254] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:18,796 [Listener at localhost/45254] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:18,844 [Thread-172] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/in_use.lock acquired by nodename 945@b120fe239ee9
2020-12-03 07:20:18,844 [Thread-172] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8 is not formatted for namespace 1484114581. Formatting...
2020-12-03 07:20:18,846 [Thread-172] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-34ccfd88-9e87-4fea-8957-f24bb641b43a for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8 
2020-12-03 07:20:18,847 [Thread-100] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:18,847 [Thread-101] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1484114581;bpid=BP-1196056580-172.17.0.8-1606980014721;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1484114581;c=1606980014721;bpid=BP-1196056580-172.17.0.8-1606980014721;dnuuid=null
2020-12-03 07:20:18,847 [Thread-100] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1 has already been used.
2020-12-03 07:20:18,847 [Thread-100] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2 has already been used.
2020-12-03 07:20:18,858 [Thread-100] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-442495584-172.17.0.8-1606980011809
2020-12-03 07:20:18,858 [Thread-100] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-442495584-172.17.0.8-1606980011809
2020-12-03 07:20:18,858 [Thread-100] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1 and block pool id BP-442495584-172.17.0.8-1606980011809 is not formatted. Formatting ...
2020-12-03 07:20:18,858 [Thread-100] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-442495584-172.17.0.8-1606980011809 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-442495584-172.17.0.8-1606980011809/current
2020-12-03 07:20:18,898 [IPC Server handler 1 on default port 38725] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:18,898 [Listener at localhost/45254] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:18,899 [Listener at localhost/45254] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:19,001 [IPC Server handler 3 on default port 38725] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:19,002 [Listener at localhost/45254] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:19,002 [Listener at localhost/45254] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:19,053 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1196056580-172.17.0.8-1606980014721
2020-12-03 07:20:19,053 [Thread-149] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-1196056580-172.17.0.8-1606980014721
2020-12-03 07:20:19,054 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6 and block pool id BP-1196056580-172.17.0.8-1606980014721 is not formatted. Formatting ...
2020-12-03 07:20:19,054 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1196056580-172.17.0.8-1606980014721 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-1196056580-172.17.0.8-1606980014721/current
2020-12-03 07:20:19,104 [IPC Server handler 5 on default port 38725] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:19,105 [Listener at localhost/45254] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:19,105 [Listener at localhost/45254] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:19,145 [Thread-125] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1294197665;bpid=BP-442495584-172.17.0.8-1606980011809;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1294197665;c=1606980011809;bpid=BP-442495584-172.17.0.8-1606980011809;dnuuid=null
2020-12-03 07:20:19,146 [Thread-126] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:19,146 [Thread-126] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3 has already been used.
2020-12-03 07:20:19,146 [Thread-126] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4 has already been used.
2020-12-03 07:20:19,156 [Thread-126] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1196056580-172.17.0.8-1606980014721
2020-12-03 07:20:19,156 [Thread-126] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-1196056580-172.17.0.8-1606980014721
2020-12-03 07:20:19,157 [Thread-126] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3 and block pool id BP-1196056580-172.17.0.8-1606980014721 is not formatted. Formatting ...
2020-12-03 07:20:19,157 [Thread-126] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1196056580-172.17.0.8-1606980014721 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-1196056580-172.17.0.8-1606980014721/current
2020-12-03 07:20:19,207 [IPC Server handler 0 on default port 38725] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:19,208 [Listener at localhost/45254] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:19,208 [Listener at localhost/45254] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:19,227 [Thread-172] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1196056580-172.17.0.8-1606980014721
2020-12-03 07:20:19,227 [Thread-100] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-442495584-172.17.0.8-1606980011809
2020-12-03 07:20:19,228 [Thread-172] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-1196056580-172.17.0.8-1606980014721
2020-12-03 07:20:19,228 [Thread-100] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-442495584-172.17.0.8-1606980011809
2020-12-03 07:20:19,228 [Thread-172] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7 and block pool id BP-1196056580-172.17.0.8-1606980014721 is not formatted. Formatting ...
2020-12-03 07:20:19,228 [Thread-100] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2 and block pool id BP-442495584-172.17.0.8-1606980011809 is not formatted. Formatting ...
2020-12-03 07:20:19,228 [Thread-172] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1196056580-172.17.0.8-1606980014721 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-1196056580-172.17.0.8-1606980014721/current
2020-12-03 07:20:19,228 [Thread-100] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-442495584-172.17.0.8-1606980011809 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-442495584-172.17.0.8-1606980011809/current
2020-12-03 07:20:19,310 [IPC Server handler 6 on default port 38725] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:19,311 [Listener at localhost/45254] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:19,311 [Listener at localhost/45254] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:19,414 [IPC Server handler 7 on default port 38725] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:19,414 [Listener at localhost/45254] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:19,415 [Listener at localhost/45254] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:19,441 [Thread-148] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:19,441 [Thread-149] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1484114581;bpid=BP-1196056580-172.17.0.8-1606980014721;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1484114581;c=1606980014721;bpid=BP-1196056580-172.17.0.8-1606980014721;dnuuid=null
2020-12-03 07:20:19,441 [Thread-148] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5 has already been used.
2020-12-03 07:20:19,441 [Thread-148] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6 has already been used.
2020-12-03 07:20:19,451 [Thread-148] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-442495584-172.17.0.8-1606980011809
2020-12-03 07:20:19,452 [Thread-148] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-442495584-172.17.0.8-1606980011809
2020-12-03 07:20:19,452 [Thread-148] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5 and block pool id BP-442495584-172.17.0.8-1606980011809 is not formatted. Formatting ...
2020-12-03 07:20:19,452 [Thread-148] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-442495584-172.17.0.8-1606980011809 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-442495584-172.17.0.8-1606980011809/current
2020-12-03 07:20:19,517 [IPC Server handler 8 on default port 38725] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:19,518 [Listener at localhost/45254] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:19,519 [Listener at localhost/45254] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:19,535 [Thread-126] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1196056580-172.17.0.8-1606980014721
2020-12-03 07:20:19,536 [Thread-126] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-1196056580-172.17.0.8-1606980014721
2020-12-03 07:20:19,536 [Thread-126] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4 and block pool id BP-1196056580-172.17.0.8-1606980014721 is not formatted. Formatting ...
2020-12-03 07:20:19,536 [Thread-126] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1196056580-172.17.0.8-1606980014721 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-1196056580-172.17.0.8-1606980014721/current
2020-12-03 07:20:19,594 [Thread-100] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1294197665;bpid=BP-442495584-172.17.0.8-1606980011809;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1294197665;c=1606980011809;bpid=BP-442495584-172.17.0.8-1606980011809;dnuuid=null
2020-12-03 07:20:19,606 [Thread-172] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1196056580-172.17.0.8-1606980014721
2020-12-03 07:20:19,606 [Thread-172] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-1196056580-172.17.0.8-1606980014721
2020-12-03 07:20:19,606 [Thread-172] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8 and block pool id BP-1196056580-172.17.0.8-1606980014721 is not formatted. Formatting ...
2020-12-03 07:20:19,606 [Thread-172] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1196056580-172.17.0.8-1606980014721 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-1196056580-172.17.0.8-1606980014721/current
2020-12-03 07:20:19,620 [IPC Server handler 9 on default port 38725] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:19,621 [Listener at localhost/45254] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:19,621 [Listener at localhost/45254] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:19,723 [IPC Server handler 2 on default port 38725] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:19,724 [Listener at localhost/45254] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:19,724 [Listener at localhost/45254] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:19,746 [Thread-148] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-442495584-172.17.0.8-1606980011809
2020-12-03 07:20:19,747 [Thread-148] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-442495584-172.17.0.8-1606980011809
2020-12-03 07:20:19,747 [Thread-148] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6 and block pool id BP-442495584-172.17.0.8-1606980011809 is not formatted. Formatting ...
2020-12-03 07:20:19,747 [Thread-148] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-442495584-172.17.0.8-1606980011809 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-442495584-172.17.0.8-1606980011809/current
2020-12-03 07:20:19,786 [Thread-126] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1484114581;bpid=BP-1196056580-172.17.0.8-1606980014721;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1484114581;c=1606980014721;bpid=BP-1196056580-172.17.0.8-1606980014721;dnuuid=null
2020-12-03 07:20:19,828 [IPC Server handler 1 on default port 38725] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:19,829 [Listener at localhost/45254] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:19,829 [Listener at localhost/45254] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:19,893 [Thread-101] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID c9a70406-f6ea-4f06-bdaa-9c25e33ee15a
2020-12-03 07:20:19,893 [Thread-172] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1484114581;bpid=BP-1196056580-172.17.0.8-1606980014721;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1484114581;c=1606980014721;bpid=BP-1196056580-172.17.0.8-1606980014721;dnuuid=null
2020-12-03 07:20:19,894 [Thread-171] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:19,895 [Thread-171] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7 has already been used.
2020-12-03 07:20:19,895 [Thread-171] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8 has already been used.
2020-12-03 07:20:19,906 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-442495584-172.17.0.8-1606980011809
2020-12-03 07:20:19,906 [Thread-171] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-442495584-172.17.0.8-1606980011809
2020-12-03 07:20:19,906 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7 and block pool id BP-442495584-172.17.0.8-1606980011809 is not formatted. Formatting ...
2020-12-03 07:20:19,906 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-442495584-172.17.0.8-1606980011809 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-442495584-172.17.0.8-1606980011809/current
2020-12-03 07:20:19,931 [IPC Server handler 3 on default port 38725] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:19,932 [Listener at localhost/45254] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:19,932 [Listener at localhost/45254] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:20,021 [Thread-101] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-e52a9cea-fdc2-430f-b809-6ea6c5790b20
2020-12-03 07:20:20,022 [Thread-101] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, StorageType: DISK
2020-12-03 07:20:20,024 [Thread-101] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-d8458332-36c9-46f8-afdf-c2195c0ebf3a
2020-12-03 07:20:20,024 [Thread-101] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, StorageType: DISK
2020-12-03 07:20:20,029 [Thread-101] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:20,033 [IPC Server handler 5 on default port 38725] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:20,034 [Listener at localhost/45254] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:20,034 [Listener at localhost/45254] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:20,036 [Thread-100] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-12-03 07:20:20,036 [Thread-101] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-12-03 07:20:20,046 [Thread-101] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-12-03 07:20:20,046 [Thread-100] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-12-03 07:20:20,048 [Thread-100] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-12-03 07:20:20,048 [Thread-101] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-12-03 07:20:20,049 [Thread-100] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-12-03 07:20:20,049 [Thread-101] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-12-03 07:20:20,049 [Thread-101] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1196056580-172.17.0.8-1606980014721
2020-12-03 07:20:20,049 [Thread-100] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-442495584-172.17.0.8-1606980011809
2020-12-03 07:20:20,050 [Thread-188] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1196056580-172.17.0.8-1606980014721 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1...
2020-12-03 07:20:20,050 [Thread-189] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1196056580-172.17.0.8-1606980014721 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2...
2020-12-03 07:20:20,071 [Thread-148] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1294197665;bpid=BP-442495584-172.17.0.8-1606980011809;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1294197665;c=1606980011809;bpid=BP-442495584-172.17.0.8-1606980011809;dnuuid=null
2020-12-03 07:20:20,080 [Thread-188] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1196056580-172.17.0.8-1606980014721 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1: 30ms
2020-12-03 07:20:20,080 [Thread-189] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1196056580-172.17.0.8-1606980014721 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2: 30ms
2020-12-03 07:20:20,081 [Thread-101] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1196056580-172.17.0.8-1606980014721: 32ms
2020-12-03 07:20:20,082 [Thread-192] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-442495584-172.17.0.8-1606980011809 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1...
2020-12-03 07:20:20,083 [Thread-193] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1196056580-172.17.0.8-1606980014721 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1...
2020-12-03 07:20:20,084 [Thread-194] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-442495584-172.17.0.8-1606980011809 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2...
2020-12-03 07:20:20,084 [Thread-195] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1196056580-172.17.0.8-1606980014721 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2...
2020-12-03 07:20:20,084 [Thread-193] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-1196056580-172.17.0.8-1606980014721/current/replicas doesn't exist 
2020-12-03 07:20:20,084 [Thread-195] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-1196056580-172.17.0.8-1606980014721/current/replicas doesn't exist 
2020-12-03 07:20:20,085 [Thread-193] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1196056580-172.17.0.8-1606980014721 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1: 2ms
2020-12-03 07:20:20,085 [Thread-195] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1196056580-172.17.0.8-1606980014721 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2: 1ms
2020-12-03 07:20:20,086 [Thread-101] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1196056580-172.17.0.8-1606980014721: 4ms
2020-12-03 07:20:20,088 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1196056580-172.17.0.8-1606980014721 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-12-03 07:20:20,089 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1196056580-172.17.0.8-1606980014721 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-12-03 07:20:20,090 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, DS-e52a9cea-fdc2-430f-b809-6ea6c5790b20): finished scanning block pool BP-1196056580-172.17.0.8-1606980014721
2020-12-03 07:20:20,090 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, DS-d8458332-36c9-46f8-afdf-c2195c0ebf3a): finished scanning block pool BP-1196056580-172.17.0.8-1606980014721
2020-12-03 07:20:20,104 [Thread-192] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-442495584-172.17.0.8-1606980011809 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1: 22ms
2020-12-03 07:20:20,104 [Thread-194] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-442495584-172.17.0.8-1606980011809 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2: 20ms
2020-12-03 07:20:20,104 [Thread-100] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-442495584-172.17.0.8-1606980011809: 22ms
2020-12-03 07:20:20,105 [Thread-200] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-442495584-172.17.0.8-1606980011809 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1...
2020-12-03 07:20:20,105 [Thread-200] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-442495584-172.17.0.8-1606980011809/current/replicas doesn't exist 
2020-12-03 07:20:20,105 [Thread-201] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-442495584-172.17.0.8-1606980011809 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2...
2020-12-03 07:20:20,105 [Thread-200] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-442495584-172.17.0.8-1606980011809 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1: 0ms
2020-12-03 07:20:20,105 [Thread-201] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-442495584-172.17.0.8-1606980011809/current/replicas doesn't exist 
2020-12-03 07:20:20,106 [Thread-201] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-442495584-172.17.0.8-1606980011809 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2: 1ms
2020-12-03 07:20:20,106 [Thread-100] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-442495584-172.17.0.8-1606980011809: 2ms
2020-12-03 07:20:20,113 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-442495584-172.17.0.8-1606980011809 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-12-03 07:20:20,113 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-442495584-172.17.0.8-1606980011809 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-12-03 07:20:20,113 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, DS-d8458332-36c9-46f8-afdf-c2195c0ebf3a): finished scanning block pool BP-442495584-172.17.0.8-1606980011809
2020-12-03 07:20:20,114 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, DS-e52a9cea-fdc2-430f-b809-6ea6c5790b20): finished scanning block pool BP-442495584-172.17.0.8-1606980011809
2020-12-03 07:20:20,114 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, DS-d8458332-36c9-46f8-afdf-c2195c0ebf3a): no suitable block pools found to scan.  Waiting 1814399974 ms.
2020-12-03 07:20:20,114 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, DS-e52a9cea-fdc2-430f-b809-6ea6c5790b20): no suitable block pools found to scan.  Waiting 1814399974 ms.
2020-12-03 07:20:20,114 [Thread-101] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 10:51 AM with interval of 21600000ms
2020-12-03 07:20:20,121 [BP-1196056580-172.17.0.8-1606980014721 heartbeating to localhost/127.0.0.1:46765] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1196056580-172.17.0.8-1606980014721 (Datanode Uuid c9a70406-f6ea-4f06-bdaa-9c25e33ee15a) service to localhost/127.0.0.1:46765 beginning handshake with NN
2020-12-03 07:20:20,121 [BP-442495584-172.17.0.8-1606980011809 heartbeating to localhost/127.0.0.1:38725] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-442495584-172.17.0.8-1606980011809 (Datanode Uuid c9a70406-f6ea-4f06-bdaa-9c25e33ee15a) service to localhost/127.0.0.1:38725 beginning handshake with NN
2020-12-03 07:20:20,131 [IPC Server handler 3 on default port 46765] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:38963, datanodeUuid=c9a70406-f6ea-4f06-bdaa-9c25e33ee15a, infoPort=33651, infoSecurePort=0, ipcPort=44444, storageInfo=lv=-57;cid=testClusterID;nsid=1484114581;c=1606980014721) storage c9a70406-f6ea-4f06-bdaa-9c25e33ee15a
2020-12-03 07:20:20,131 [IPC Server handler 0 on default port 38725] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:38963, datanodeUuid=c9a70406-f6ea-4f06-bdaa-9c25e33ee15a, infoPort=33651, infoSecurePort=0, ipcPort=44444, storageInfo=lv=-57;cid=testClusterID;nsid=1294197665;c=1606980011809) storage c9a70406-f6ea-4f06-bdaa-9c25e33ee15a
2020-12-03 07:20:20,133 [IPC Server handler 3 on default port 46765] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38963
2020-12-03 07:20:20,133 [IPC Server handler 0 on default port 38725] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38963
2020-12-03 07:20:20,133 [IPC Server handler 3 on default port 46765] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN c9a70406-f6ea-4f06-bdaa-9c25e33ee15a (127.0.0.1:38963).
2020-12-03 07:20:20,133 [IPC Server handler 0 on default port 38725] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN c9a70406-f6ea-4f06-bdaa-9c25e33ee15a (127.0.0.1:38963).
2020-12-03 07:20:20,138 [IPC Server handler 6 on default port 38725] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:20,139 [BP-442495584-172.17.0.8-1606980011809 heartbeating to localhost/127.0.0.1:38725] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-442495584-172.17.0.8-1606980011809 (Datanode Uuid c9a70406-f6ea-4f06-bdaa-9c25e33ee15a) service to localhost/127.0.0.1:38725 successfully registered with NN
2020-12-03 07:20:20,139 [BP-1196056580-172.17.0.8-1606980014721 heartbeating to localhost/127.0.0.1:46765] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1196056580-172.17.0.8-1606980014721 (Datanode Uuid c9a70406-f6ea-4f06-bdaa-9c25e33ee15a) service to localhost/127.0.0.1:46765 successfully registered with NN
2020-12-03 07:20:20,139 [BP-442495584-172.17.0.8-1606980011809 heartbeating to localhost/127.0.0.1:38725] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:38725 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:20,140 [BP-1196056580-172.17.0.8-1606980014721 heartbeating to localhost/127.0.0.1:46765] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:46765 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:20,142 [Thread-125] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 5d254eed-d31f-4b68-8ed2-0637095141a0
2020-12-03 07:20:20,144 [Listener at localhost/45254] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:20,144 [Listener at localhost/45254] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:20,144 [Thread-125] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-10b59786-dd4a-42b3-8172-914cf700b081
2020-12-03 07:20:20,145 [Thread-125] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, StorageType: DISK
2020-12-03 07:20:20,146 [Thread-125] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-5fa6371f-9ba8-4a41-b4aa-d539ceb7700f
2020-12-03 07:20:20,147 [Thread-125] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, StorageType: DISK
2020-12-03 07:20:20,147 [Thread-125] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:20,149 [Thread-125] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-12-03 07:20:20,149 [Thread-126] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1196056580-172.17.0.8-1606980014721
2020-12-03 07:20:20,150 [Thread-205] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1196056580-172.17.0.8-1606980014721 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3...
2020-12-03 07:20:20,150 [Thread-206] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1196056580-172.17.0.8-1606980014721 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4...
2020-12-03 07:20:20,151 [Thread-125] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-12-03 07:20:20,151 [Thread-125] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-12-03 07:20:20,151 [Thread-125] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-12-03 07:20:20,152 [Thread-125] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-442495584-172.17.0.8-1606980011809
2020-12-03 07:20:20,164 [IPC Server handler 4 on default port 46765] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-e52a9cea-fdc2-430f-b809-6ea6c5790b20 for DN 127.0.0.1:38963
2020-12-03 07:20:20,164 [IPC Server handler 7 on default port 38725] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-e52a9cea-fdc2-430f-b809-6ea6c5790b20 for DN 127.0.0.1:38963
2020-12-03 07:20:20,165 [IPC Server handler 7 on default port 38725] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d8458332-36c9-46f8-afdf-c2195c0ebf3a for DN 127.0.0.1:38963
2020-12-03 07:20:20,165 [IPC Server handler 4 on default port 46765] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d8458332-36c9-46f8-afdf-c2195c0ebf3a for DN 127.0.0.1:38963
2020-12-03 07:20:20,173 [Thread-205] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1196056580-172.17.0.8-1606980014721 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3: 23ms
2020-12-03 07:20:20,173 [Thread-206] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1196056580-172.17.0.8-1606980014721 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4: 23ms
2020-12-03 07:20:20,173 [Thread-126] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1196056580-172.17.0.8-1606980014721: 24ms
2020-12-03 07:20:20,173 [Thread-209] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1196056580-172.17.0.8-1606980014721 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3...
2020-12-03 07:20:20,174 [Thread-209] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-1196056580-172.17.0.8-1606980014721/current/replicas doesn't exist 
2020-12-03 07:20:20,174 [Thread-210] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-442495584-172.17.0.8-1606980011809 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3...
2020-12-03 07:20:20,174 [Thread-211] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1196056580-172.17.0.8-1606980014721 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4...
2020-12-03 07:20:20,174 [Thread-212] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-442495584-172.17.0.8-1606980011809 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4...
2020-12-03 07:20:20,174 [Thread-211] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-1196056580-172.17.0.8-1606980014721/current/replicas doesn't exist 
2020-12-03 07:20:20,174 [Thread-209] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1196056580-172.17.0.8-1606980014721 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3: 0ms
2020-12-03 07:20:20,174 [Thread-211] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1196056580-172.17.0.8-1606980014721 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4: 0ms
2020-12-03 07:20:20,174 [Thread-126] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1196056580-172.17.0.8-1606980014721: 1ms
2020-12-03 07:20:20,175 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1196056580-172.17.0.8-1606980014721 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-12-03 07:20:20,175 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1196056580-172.17.0.8-1606980014721 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-12-03 07:20:20,175 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, DS-10b59786-dd4a-42b3-8172-914cf700b081): finished scanning block pool BP-1196056580-172.17.0.8-1606980014721
2020-12-03 07:20:20,176 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, DS-5fa6371f-9ba8-4a41-b4aa-d539ceb7700f): finished scanning block pool BP-1196056580-172.17.0.8-1606980014721
2020-12-03 07:20:20,176 [Thread-126] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:58 AM with interval of 21600000ms
2020-12-03 07:20:20,176 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, DS-10b59786-dd4a-42b3-8172-914cf700b081): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:20:20,177 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, DS-5fa6371f-9ba8-4a41-b4aa-d539ceb7700f): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:20:20,178 [BP-1196056580-172.17.0.8-1606980014721 heartbeating to localhost/127.0.0.1:46765] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1196056580-172.17.0.8-1606980014721 (Datanode Uuid 5d254eed-d31f-4b68-8ed2-0637095141a0) service to localhost/127.0.0.1:46765 beginning handshake with NN
2020-12-03 07:20:20,179 [IPC Server handler 5 on default port 46765] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:44357, datanodeUuid=5d254eed-d31f-4b68-8ed2-0637095141a0, infoPort=34551, infoSecurePort=0, ipcPort=41249, storageInfo=lv=-57;cid=testClusterID;nsid=1484114581;c=1606980014721) storage 5d254eed-d31f-4b68-8ed2-0637095141a0
2020-12-03 07:20:20,181 [IPC Server handler 5 on default port 46765] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:44357
2020-12-03 07:20:20,181 [IPC Server handler 5 on default port 46765] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 5d254eed-d31f-4b68-8ed2-0637095141a0 (127.0.0.1:44357).
2020-12-03 07:20:20,182 [BP-1196056580-172.17.0.8-1606980014721 heartbeating to localhost/127.0.0.1:46765] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1196056580-172.17.0.8-1606980014721 (Datanode Uuid 5d254eed-d31f-4b68-8ed2-0637095141a0) service to localhost/127.0.0.1:46765 successfully registered with NN
2020-12-03 07:20:20,183 [BP-1196056580-172.17.0.8-1606980014721 heartbeating to localhost/127.0.0.1:46765] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:46765 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:20,188 [IPC Server handler 7 on default port 46765] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-10b59786-dd4a-42b3-8172-914cf700b081 for DN 127.0.0.1:44357
2020-12-03 07:20:20,190 [IPC Server handler 7 on default port 46765] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-5fa6371f-9ba8-4a41-b4aa-d539ceb7700f for DN 127.0.0.1:44357
2020-12-03 07:20:20,197 [Thread-212] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-442495584-172.17.0.8-1606980011809 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4: 23ms
2020-12-03 07:20:20,197 [Thread-210] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-442495584-172.17.0.8-1606980011809 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3: 23ms
2020-12-03 07:20:20,198 [Thread-125] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-442495584-172.17.0.8-1606980011809: 25ms
2020-12-03 07:20:20,198 [Thread-218] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-442495584-172.17.0.8-1606980011809 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3...
2020-12-03 07:20:20,198 [Thread-218] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-442495584-172.17.0.8-1606980011809/current/replicas doesn't exist 
2020-12-03 07:20:20,199 [Thread-218] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-442495584-172.17.0.8-1606980011809 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3: 1ms
2020-12-03 07:20:20,199 [Thread-219] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-442495584-172.17.0.8-1606980011809 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4...
2020-12-03 07:20:20,199 [Thread-219] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-442495584-172.17.0.8-1606980011809/current/replicas doesn't exist 
2020-12-03 07:20:20,199 [Thread-219] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-442495584-172.17.0.8-1606980011809 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4: 0ms
2020-12-03 07:20:20,199 [Thread-125] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-442495584-172.17.0.8-1606980011809: 1ms
2020-12-03 07:20:20,200 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-442495584-172.17.0.8-1606980011809 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-12-03 07:20:20,200 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-442495584-172.17.0.8-1606980011809 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-12-03 07:20:20,200 [BP-442495584-172.17.0.8-1606980011809 heartbeating to localhost/127.0.0.1:38725] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-442495584-172.17.0.8-1606980011809 (Datanode Uuid 5d254eed-d31f-4b68-8ed2-0637095141a0) service to localhost/127.0.0.1:38725 beginning handshake with NN
2020-12-03 07:20:20,201 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, DS-10b59786-dd4a-42b3-8172-914cf700b081): finished scanning block pool BP-442495584-172.17.0.8-1606980011809
2020-12-03 07:20:20,202 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, DS-5fa6371f-9ba8-4a41-b4aa-d539ceb7700f): finished scanning block pool BP-442495584-172.17.0.8-1606980011809
2020-12-03 07:20:20,202 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, DS-10b59786-dd4a-42b3-8172-914cf700b081): no suitable block pools found to scan.  Waiting 1814399973 ms.
2020-12-03 07:20:20,203 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, DS-5fa6371f-9ba8-4a41-b4aa-d539ceb7700f): no suitable block pools found to scan.  Waiting 1814399972 ms.
2020-12-03 07:20:20,203 [IPC Server handler 9 on default port 38725] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:44357, datanodeUuid=5d254eed-d31f-4b68-8ed2-0637095141a0, infoPort=34551, infoSecurePort=0, ipcPort=41249, storageInfo=lv=-57;cid=testClusterID;nsid=1294197665;c=1606980011809) storage 5d254eed-d31f-4b68-8ed2-0637095141a0
2020-12-03 07:20:20,204 [IPC Server handler 9 on default port 38725] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:44357
2020-12-03 07:20:20,204 [IPC Server handler 9 on default port 38725] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 5d254eed-d31f-4b68-8ed2-0637095141a0 (127.0.0.1:44357).
2020-12-03 07:20:20,205 [BP-442495584-172.17.0.8-1606980011809 heartbeating to localhost/127.0.0.1:38725] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-442495584-172.17.0.8-1606980011809 (Datanode Uuid 5d254eed-d31f-4b68-8ed2-0637095141a0) service to localhost/127.0.0.1:38725 successfully registered with NN
2020-12-03 07:20:20,205 [BP-442495584-172.17.0.8-1606980011809 heartbeating to localhost/127.0.0.1:38725] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:38725 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:20,206 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x9c2941950cdb65c3: Processing first storage report for DS-e52a9cea-fdc2-430f-b809-6ea6c5790b20 from datanode c9a70406-f6ea-4f06-bdaa-9c25e33ee15a
2020-12-03 07:20:20,206 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x89f337cb79585bef: Processing first storage report for DS-e52a9cea-fdc2-430f-b809-6ea6c5790b20 from datanode c9a70406-f6ea-4f06-bdaa-9c25e33ee15a
2020-12-03 07:20:20,209 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x89f337cb79585bef: from storage DS-e52a9cea-fdc2-430f-b809-6ea6c5790b20 node DatanodeRegistration(127.0.0.1:38963, datanodeUuid=c9a70406-f6ea-4f06-bdaa-9c25e33ee15a, infoPort=33651, infoSecurePort=0, ipcPort=44444, storageInfo=lv=-57;cid=testClusterID;nsid=1484114581;c=1606980014721), blocks: 0, hasStaleStorage: true, processing time: 2 msecs, invalidatedBlocks: 0
2020-12-03 07:20:20,209 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x9c2941950cdb65c3: from storage DS-e52a9cea-fdc2-430f-b809-6ea6c5790b20 node DatanodeRegistration(127.0.0.1:38963, datanodeUuid=c9a70406-f6ea-4f06-bdaa-9c25e33ee15a, infoPort=33651, infoSecurePort=0, ipcPort=44444, storageInfo=lv=-57;cid=testClusterID;nsid=1294197665;c=1606980011809), blocks: 0, hasStaleStorage: true, processing time: 2 msecs, invalidatedBlocks: 0
2020-12-03 07:20:20,209 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x81ff19ceb58159b5: Processing first storage report for DS-5fa6371f-9ba8-4a41-b4aa-d539ceb7700f from datanode 5d254eed-d31f-4b68-8ed2-0637095141a0
2020-12-03 07:20:20,210 [IPC Server handler 4 on default port 38725] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-10b59786-dd4a-42b3-8172-914cf700b081 for DN 127.0.0.1:44357
2020-12-03 07:20:20,210 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x81ff19ceb58159b5: from storage DS-5fa6371f-9ba8-4a41-b4aa-d539ceb7700f node DatanodeRegistration(127.0.0.1:44357, datanodeUuid=5d254eed-d31f-4b68-8ed2-0637095141a0, infoPort=34551, infoSecurePort=0, ipcPort=41249, storageInfo=lv=-57;cid=testClusterID;nsid=1484114581;c=1606980014721), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:20,210 [IPC Server handler 4 on default port 38725] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-5fa6371f-9ba8-4a41-b4aa-d539ceb7700f for DN 127.0.0.1:44357
2020-12-03 07:20:20,210 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x89f337cb79585bef: Processing first storage report for DS-d8458332-36c9-46f8-afdf-c2195c0ebf3a from datanode c9a70406-f6ea-4f06-bdaa-9c25e33ee15a
2020-12-03 07:20:20,211 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x89f337cb79585bef: from storage DS-d8458332-36c9-46f8-afdf-c2195c0ebf3a node DatanodeRegistration(127.0.0.1:38963, datanodeUuid=c9a70406-f6ea-4f06-bdaa-9c25e33ee15a, infoPort=33651, infoSecurePort=0, ipcPort=44444, storageInfo=lv=-57;cid=testClusterID;nsid=1484114581;c=1606980014721), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:20,211 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x9c2941950cdb65c3: Processing first storage report for DS-d8458332-36c9-46f8-afdf-c2195c0ebf3a from datanode c9a70406-f6ea-4f06-bdaa-9c25e33ee15a
2020-12-03 07:20:20,211 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x81ff19ceb58159b5: Processing first storage report for DS-10b59786-dd4a-42b3-8172-914cf700b081 from datanode 5d254eed-d31f-4b68-8ed2-0637095141a0
2020-12-03 07:20:20,211 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x9c2941950cdb65c3: from storage DS-d8458332-36c9-46f8-afdf-c2195c0ebf3a node DatanodeRegistration(127.0.0.1:38963, datanodeUuid=c9a70406-f6ea-4f06-bdaa-9c25e33ee15a, infoPort=33651, infoSecurePort=0, ipcPort=44444, storageInfo=lv=-57;cid=testClusterID;nsid=1294197665;c=1606980011809), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:20:20,211 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x81ff19ceb58159b5: from storage DS-10b59786-dd4a-42b3-8172-914cf700b081 node DatanodeRegistration(127.0.0.1:44357, datanodeUuid=5d254eed-d31f-4b68-8ed2-0637095141a0, infoPort=34551, infoSecurePort=0, ipcPort=41249, storageInfo=lv=-57;cid=testClusterID;nsid=1484114581;c=1606980014721), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:20,212 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x891220008fbad400: Processing first storage report for DS-5fa6371f-9ba8-4a41-b4aa-d539ceb7700f from datanode 5d254eed-d31f-4b68-8ed2-0637095141a0
2020-12-03 07:20:20,213 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x891220008fbad400: from storage DS-5fa6371f-9ba8-4a41-b4aa-d539ceb7700f node DatanodeRegistration(127.0.0.1:44357, datanodeUuid=5d254eed-d31f-4b68-8ed2-0637095141a0, infoPort=34551, infoSecurePort=0, ipcPort=41249, storageInfo=lv=-57;cid=testClusterID;nsid=1294197665;c=1606980011809), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:20,213 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x891220008fbad400: Processing first storage report for DS-10b59786-dd4a-42b3-8172-914cf700b081 from datanode 5d254eed-d31f-4b68-8ed2-0637095141a0
2020-12-03 07:20:20,213 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x891220008fbad400: from storage DS-10b59786-dd4a-42b3-8172-914cf700b081 node DatanodeRegistration(127.0.0.1:44357, datanodeUuid=5d254eed-d31f-4b68-8ed2-0637095141a0, infoPort=34551, infoSecurePort=0, ipcPort=41249, storageInfo=lv=-57;cid=testClusterID;nsid=1294197665;c=1606980011809), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:20,234 [BP-442495584-172.17.0.8-1606980011809 heartbeating to localhost/127.0.0.1:38725] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x891220008fbad400,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 23 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:20,234 [BP-1196056580-172.17.0.8-1606980014721 heartbeating to localhost/127.0.0.1:46765] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x89f337cb79585bef,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 10 msec to generate and 44 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:20,234 [BP-442495584-172.17.0.8-1606980011809 heartbeating to localhost/127.0.0.1:38725] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x9c2941950cdb65c3,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 9 msec to generate and 44 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:20,234 [BP-1196056580-172.17.0.8-1606980014721 heartbeating to localhost/127.0.0.1:46765] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x81ff19ceb58159b5,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 7 msec to generate and 36 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:20,235 [BP-442495584-172.17.0.8-1606980011809 heartbeating to localhost/127.0.0.1:38725] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-442495584-172.17.0.8-1606980011809
2020-12-03 07:20:20,235 [BP-1196056580-172.17.0.8-1606980014721 heartbeating to localhost/127.0.0.1:46765] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1196056580-172.17.0.8-1606980014721
2020-12-03 07:20:20,235 [BP-442495584-172.17.0.8-1606980011809 heartbeating to localhost/127.0.0.1:38725] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-442495584-172.17.0.8-1606980011809
2020-12-03 07:20:20,235 [BP-1196056580-172.17.0.8-1606980014721 heartbeating to localhost/127.0.0.1:46765] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1196056580-172.17.0.8-1606980014721
2020-12-03 07:20:20,246 [IPC Server handler 1 on default port 38725] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:20,247 [Listener at localhost/45254] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:20,247 [Listener at localhost/45254] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:20,248 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-442495584-172.17.0.8-1606980011809
2020-12-03 07:20:20,248 [Thread-171] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-442495584-172.17.0.8-1606980011809
2020-12-03 07:20:20,249 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8 and block pool id BP-442495584-172.17.0.8-1606980011809 is not formatted. Formatting ...
2020-12-03 07:20:20,249 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-442495584-172.17.0.8-1606980011809 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-442495584-172.17.0.8-1606980011809/current
2020-12-03 07:20:20,348 [IPC Server handler 3 on default port 38725] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:20,349 [Listener at localhost/45254] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:20,349 [Listener at localhost/45254] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:20,439 [Thread-149] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID bf73dede-45ff-42c6-af89-d263bc2c1a45
2020-12-03 07:20:20,442 [Thread-149] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-83fd7724-742b-40a1-bf8e-dcb9168386f8
2020-12-03 07:20:20,443 [Thread-149] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, StorageType: DISK
2020-12-03 07:20:20,444 [Thread-149] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-80699e0e-37c6-48a4-8564-b17c23a6c31a
2020-12-03 07:20:20,444 [Thread-149] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, StorageType: DISK
2020-12-03 07:20:20,445 [Thread-149] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:20,447 [Thread-149] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-12-03 07:20:20,447 [Thread-148] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-442495584-172.17.0.8-1606980011809
2020-12-03 07:20:20,447 [Thread-222] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-442495584-172.17.0.8-1606980011809 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5...
2020-12-03 07:20:20,447 [Thread-223] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-442495584-172.17.0.8-1606980011809 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6...
2020-12-03 07:20:20,448 [Thread-149] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-12-03 07:20:20,448 [Thread-149] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-12-03 07:20:20,448 [Thread-149] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-12-03 07:20:20,448 [Thread-149] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1196056580-172.17.0.8-1606980014721
2020-12-03 07:20:20,451 [IPC Server handler 5 on default port 38725] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:20,452 [Listener at localhost/45254] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:20,452 [Listener at localhost/45254] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:20,466 [Thread-223] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-442495584-172.17.0.8-1606980011809 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6: 19ms
2020-12-03 07:20:20,467 [Thread-222] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-442495584-172.17.0.8-1606980011809 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5: 20ms
2020-12-03 07:20:20,467 [Thread-148] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-442495584-172.17.0.8-1606980011809: 20ms
2020-12-03 07:20:20,468 [Thread-226] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-442495584-172.17.0.8-1606980011809 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5...
2020-12-03 07:20:20,468 [Thread-226] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-442495584-172.17.0.8-1606980011809/current/replicas doesn't exist 
2020-12-03 07:20:20,468 [Thread-227] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1196056580-172.17.0.8-1606980014721 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5...
2020-12-03 07:20:20,468 [Thread-228] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-442495584-172.17.0.8-1606980011809 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6...
2020-12-03 07:20:20,468 [Thread-226] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-442495584-172.17.0.8-1606980011809 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5: 0ms
2020-12-03 07:20:20,468 [Thread-229] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1196056580-172.17.0.8-1606980014721 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6...
2020-12-03 07:20:20,468 [Thread-228] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-442495584-172.17.0.8-1606980011809/current/replicas doesn't exist 
2020-12-03 07:20:20,469 [Thread-228] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-442495584-172.17.0.8-1606980011809 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6: 1ms
2020-12-03 07:20:20,469 [Thread-148] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-442495584-172.17.0.8-1606980011809: 2ms
2020-12-03 07:20:20,469 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-442495584-172.17.0.8-1606980011809 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-12-03 07:20:20,470 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-442495584-172.17.0.8-1606980011809 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-12-03 07:20:20,470 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, DS-80699e0e-37c6-48a4-8564-b17c23a6c31a): finished scanning block pool BP-442495584-172.17.0.8-1606980011809
2020-12-03 07:20:20,470 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, DS-83fd7724-742b-40a1-bf8e-dcb9168386f8): finished scanning block pool BP-442495584-172.17.0.8-1606980011809
2020-12-03 07:20:20,470 [Thread-148] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 8:36 AM with interval of 21600000ms
2020-12-03 07:20:20,470 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, DS-80699e0e-37c6-48a4-8564-b17c23a6c31a): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:20:20,471 [BP-442495584-172.17.0.8-1606980011809 heartbeating to localhost/127.0.0.1:38725] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-442495584-172.17.0.8-1606980011809 (Datanode Uuid bf73dede-45ff-42c6-af89-d263bc2c1a45) service to localhost/127.0.0.1:38725 beginning handshake with NN
2020-12-03 07:20:20,471 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, DS-83fd7724-742b-40a1-bf8e-dcb9168386f8): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:20:20,473 [IPC Server handler 0 on default port 38725] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:38408, datanodeUuid=bf73dede-45ff-42c6-af89-d263bc2c1a45, infoPort=46144, infoSecurePort=0, ipcPort=46440, storageInfo=lv=-57;cid=testClusterID;nsid=1294197665;c=1606980011809) storage bf73dede-45ff-42c6-af89-d263bc2c1a45
2020-12-03 07:20:20,473 [IPC Server handler 0 on default port 38725] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38408
2020-12-03 07:20:20,473 [IPC Server handler 0 on default port 38725] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN bf73dede-45ff-42c6-af89-d263bc2c1a45 (127.0.0.1:38408).
2020-12-03 07:20:20,474 [BP-442495584-172.17.0.8-1606980011809 heartbeating to localhost/127.0.0.1:38725] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-442495584-172.17.0.8-1606980011809 (Datanode Uuid bf73dede-45ff-42c6-af89-d263bc2c1a45) service to localhost/127.0.0.1:38725 successfully registered with NN
2020-12-03 07:20:20,474 [BP-442495584-172.17.0.8-1606980011809 heartbeating to localhost/127.0.0.1:38725] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:38725 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:20,482 [IPC Server handler 6 on default port 38725] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-83fd7724-742b-40a1-bf8e-dcb9168386f8 for DN 127.0.0.1:38408
2020-12-03 07:20:20,483 [IPC Server handler 6 on default port 38725] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-80699e0e-37c6-48a4-8564-b17c23a6c31a for DN 127.0.0.1:38408
2020-12-03 07:20:20,489 [Thread-227] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1196056580-172.17.0.8-1606980014721 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5: 21ms
2020-12-03 07:20:20,490 [Thread-229] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1196056580-172.17.0.8-1606980014721 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6: 22ms
2020-12-03 07:20:20,490 [Thread-149] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1196056580-172.17.0.8-1606980014721: 23ms
2020-12-03 07:20:20,490 [Thread-235] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1196056580-172.17.0.8-1606980014721 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5...
2020-12-03 07:20:20,490 [Thread-236] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1196056580-172.17.0.8-1606980014721 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6...
2020-12-03 07:20:20,490 [Thread-235] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-1196056580-172.17.0.8-1606980014721/current/replicas doesn't exist 
2020-12-03 07:20:20,490 [Thread-236] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-1196056580-172.17.0.8-1606980014721/current/replicas doesn't exist 
2020-12-03 07:20:20,491 [Thread-235] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1196056580-172.17.0.8-1606980014721 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5: 1ms
2020-12-03 07:20:20,491 [Thread-236] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1196056580-172.17.0.8-1606980014721 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6: 1ms
2020-12-03 07:20:20,491 [Thread-149] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1196056580-172.17.0.8-1606980014721: 1ms
2020-12-03 07:20:20,491 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1196056580-172.17.0.8-1606980014721 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-12-03 07:20:20,492 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1196056580-172.17.0.8-1606980014721 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-12-03 07:20:20,492 [BP-1196056580-172.17.0.8-1606980014721 heartbeating to localhost/127.0.0.1:46765] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1196056580-172.17.0.8-1606980014721 (Datanode Uuid bf73dede-45ff-42c6-af89-d263bc2c1a45) service to localhost/127.0.0.1:46765 beginning handshake with NN
2020-12-03 07:20:20,492 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, DS-80699e0e-37c6-48a4-8564-b17c23a6c31a): finished scanning block pool BP-1196056580-172.17.0.8-1606980014721
2020-12-03 07:20:20,492 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x420ca64943cbc511: Processing first storage report for DS-83fd7724-742b-40a1-bf8e-dcb9168386f8 from datanode bf73dede-45ff-42c6-af89-d263bc2c1a45
2020-12-03 07:20:20,492 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, DS-83fd7724-742b-40a1-bf8e-dcb9168386f8): finished scanning block pool BP-1196056580-172.17.0.8-1606980014721
2020-12-03 07:20:20,492 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x420ca64943cbc511: from storage DS-83fd7724-742b-40a1-bf8e-dcb9168386f8 node DatanodeRegistration(127.0.0.1:38408, datanodeUuid=bf73dede-45ff-42c6-af89-d263bc2c1a45, infoPort=46144, infoSecurePort=0, ipcPort=46440, storageInfo=lv=-57;cid=testClusterID;nsid=1294197665;c=1606980011809), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:20:20,492 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x420ca64943cbc511: Processing first storage report for DS-80699e0e-37c6-48a4-8564-b17c23a6c31a from datanode bf73dede-45ff-42c6-af89-d263bc2c1a45
2020-12-03 07:20:20,492 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, DS-80699e0e-37c6-48a4-8564-b17c23a6c31a): no suitable block pools found to scan.  Waiting 1814399977 ms.
2020-12-03 07:20:20,492 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x420ca64943cbc511: from storage DS-80699e0e-37c6-48a4-8564-b17c23a6c31a node DatanodeRegistration(127.0.0.1:38408, datanodeUuid=bf73dede-45ff-42c6-af89-d263bc2c1a45, infoPort=46144, infoSecurePort=0, ipcPort=46440, storageInfo=lv=-57;cid=testClusterID;nsid=1294197665;c=1606980011809), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:20,492 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, DS-83fd7724-742b-40a1-bf8e-dcb9168386f8): no suitable block pools found to scan.  Waiting 1814399977 ms.
2020-12-03 07:20:20,493 [IPC Server handler 0 on default port 46765] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:38408, datanodeUuid=bf73dede-45ff-42c6-af89-d263bc2c1a45, infoPort=46144, infoSecurePort=0, ipcPort=46440, storageInfo=lv=-57;cid=testClusterID;nsid=1484114581;c=1606980014721) storage bf73dede-45ff-42c6-af89-d263bc2c1a45
2020-12-03 07:20:20,493 [IPC Server handler 0 on default port 46765] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38408
2020-12-03 07:20:20,493 [IPC Server handler 0 on default port 46765] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN bf73dede-45ff-42c6-af89-d263bc2c1a45 (127.0.0.1:38408).
2020-12-03 07:20:20,493 [BP-442495584-172.17.0.8-1606980011809 heartbeating to localhost/127.0.0.1:38725] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x420ca64943cbc511,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 7 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:20,494 [BP-442495584-172.17.0.8-1606980011809 heartbeating to localhost/127.0.0.1:38725] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-442495584-172.17.0.8-1606980011809
2020-12-03 07:20:20,494 [BP-1196056580-172.17.0.8-1606980014721 heartbeating to localhost/127.0.0.1:46765] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1196056580-172.17.0.8-1606980014721 (Datanode Uuid bf73dede-45ff-42c6-af89-d263bc2c1a45) service to localhost/127.0.0.1:46765 successfully registered with NN
2020-12-03 07:20:20,494 [BP-1196056580-172.17.0.8-1606980014721 heartbeating to localhost/127.0.0.1:46765] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:46765 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:20,496 [IPC Server handler 1 on default port 46765] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-83fd7724-742b-40a1-bf8e-dcb9168386f8 for DN 127.0.0.1:38408
2020-12-03 07:20:20,496 [IPC Server handler 1 on default port 46765] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-80699e0e-37c6-48a4-8564-b17c23a6c31a for DN 127.0.0.1:38408
2020-12-03 07:20:20,498 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xaa69cacfe3ef6692: Processing first storage report for DS-83fd7724-742b-40a1-bf8e-dcb9168386f8 from datanode bf73dede-45ff-42c6-af89-d263bc2c1a45
2020-12-03 07:20:20,499 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xaa69cacfe3ef6692: from storage DS-83fd7724-742b-40a1-bf8e-dcb9168386f8 node DatanodeRegistration(127.0.0.1:38408, datanodeUuid=bf73dede-45ff-42c6-af89-d263bc2c1a45, infoPort=46144, infoSecurePort=0, ipcPort=46440, storageInfo=lv=-57;cid=testClusterID;nsid=1484114581;c=1606980014721), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:20,499 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xaa69cacfe3ef6692: Processing first storage report for DS-80699e0e-37c6-48a4-8564-b17c23a6c31a from datanode bf73dede-45ff-42c6-af89-d263bc2c1a45
2020-12-03 07:20:20,499 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xaa69cacfe3ef6692: from storage DS-80699e0e-37c6-48a4-8564-b17c23a6c31a node DatanodeRegistration(127.0.0.1:38408, datanodeUuid=bf73dede-45ff-42c6-af89-d263bc2c1a45, infoPort=46144, infoSecurePort=0, ipcPort=46440, storageInfo=lv=-57;cid=testClusterID;nsid=1484114581;c=1606980014721), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:20,500 [BP-1196056580-172.17.0.8-1606980014721 heartbeating to localhost/127.0.0.1:46765] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xaa69cacfe3ef6692,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:20,500 [BP-1196056580-172.17.0.8-1606980014721 heartbeating to localhost/127.0.0.1:46765] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1196056580-172.17.0.8-1606980014721
2020-12-03 07:20:20,553 [IPC Server handler 9 on default port 38725] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:20,554 [Listener at localhost/45254] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:20,554 [Listener at localhost/45254] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:20,594 [Thread-171] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1294197665;bpid=BP-442495584-172.17.0.8-1606980011809;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1294197665;c=1606980011809;bpid=BP-442495584-172.17.0.8-1606980011809;dnuuid=null
2020-12-03 07:20:20,655 [IPC Server handler 4 on default port 38725] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:20,656 [Listener at localhost/45254] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:20,656 [Listener at localhost/45254] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:20,757 [IPC Server handler 2 on default port 38725] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:20,758 [Listener at localhost/45254] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:20,758 [Listener at localhost/45254] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:20,859 [IPC Server handler 8 on default port 38725] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:20,860 [Listener at localhost/45254] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:20,860 [Listener at localhost/45254] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:20,937 [Thread-172] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 449fc13d-a0df-4d01-b5b4-55c170b0904b
2020-12-03 07:20:20,939 [Thread-172] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-5b55ee66-15b3-4cba-8c37-e81745468554
2020-12-03 07:20:20,940 [Thread-172] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, StorageType: DISK
2020-12-03 07:20:20,942 [Thread-172] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-34ccfd88-9e87-4fea-8957-f24bb641b43a
2020-12-03 07:20:20,942 [Thread-172] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, StorageType: DISK
2020-12-03 07:20:20,943 [Thread-172] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:20,944 [Thread-172] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7
2020-12-03 07:20:20,944 [Thread-171] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-442495584-172.17.0.8-1606980011809
2020-12-03 07:20:20,945 [Thread-239] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-442495584-172.17.0.8-1606980011809 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7...
2020-12-03 07:20:20,945 [Thread-172] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7
2020-12-03 07:20:20,945 [Thread-172] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-12-03 07:20:20,945 [Thread-240] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-442495584-172.17.0.8-1606980011809 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8...
2020-12-03 07:20:20,945 [Thread-172] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-12-03 07:20:20,946 [Thread-172] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1196056580-172.17.0.8-1606980014721
2020-12-03 07:20:20,961 [IPC Server handler 1 on default port 38725] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:20,962 [Listener at localhost/45254] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:20,962 [Listener at localhost/45254] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:20,967 [Thread-239] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-442495584-172.17.0.8-1606980011809 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7: 22ms
2020-12-03 07:20:20,969 [Thread-240] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-442495584-172.17.0.8-1606980011809 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8: 24ms
2020-12-03 07:20:20,969 [Thread-171] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-442495584-172.17.0.8-1606980011809: 25ms
2020-12-03 07:20:20,970 [Thread-243] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-442495584-172.17.0.8-1606980011809 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7...
2020-12-03 07:20:20,970 [Thread-244] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1196056580-172.17.0.8-1606980014721 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7...
2020-12-03 07:20:20,970 [Thread-243] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-442495584-172.17.0.8-1606980011809/current/replicas doesn't exist 
2020-12-03 07:20:20,970 [Thread-245] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-442495584-172.17.0.8-1606980011809 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8...
2020-12-03 07:20:20,970 [Thread-246] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1196056580-172.17.0.8-1606980014721 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8...
2020-12-03 07:20:20,970 [Thread-245] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-442495584-172.17.0.8-1606980011809/current/replicas doesn't exist 
2020-12-03 07:20:20,970 [Thread-243] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-442495584-172.17.0.8-1606980011809 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7: 0ms
2020-12-03 07:20:20,970 [Thread-245] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-442495584-172.17.0.8-1606980011809 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8: 0ms
2020-12-03 07:20:20,970 [Thread-171] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-442495584-172.17.0.8-1606980011809: 1ms
2020-12-03 07:20:20,971 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-442495584-172.17.0.8-1606980011809 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-12-03 07:20:20,971 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-442495584-172.17.0.8-1606980011809 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7
2020-12-03 07:20:20,971 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, DS-34ccfd88-9e87-4fea-8957-f24bb641b43a): finished scanning block pool BP-442495584-172.17.0.8-1606980011809
2020-12-03 07:20:20,972 [Thread-171] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 12:14 PM with interval of 21600000ms
2020-12-03 07:20:20,972 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, DS-5b55ee66-15b3-4cba-8c37-e81745468554): finished scanning block pool BP-442495584-172.17.0.8-1606980011809
2020-12-03 07:20:20,973 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, DS-34ccfd88-9e87-4fea-8957-f24bb641b43a): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-12-03 07:20:20,973 [BP-442495584-172.17.0.8-1606980011809 heartbeating to localhost/127.0.0.1:38725] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-442495584-172.17.0.8-1606980011809 (Datanode Uuid 449fc13d-a0df-4d01-b5b4-55c170b0904b) service to localhost/127.0.0.1:38725 beginning handshake with NN
2020-12-03 07:20:20,973 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, DS-5b55ee66-15b3-4cba-8c37-e81745468554): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-12-03 07:20:20,974 [IPC Server handler 3 on default port 38725] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:33835, datanodeUuid=449fc13d-a0df-4d01-b5b4-55c170b0904b, infoPort=39227, infoSecurePort=0, ipcPort=45254, storageInfo=lv=-57;cid=testClusterID;nsid=1294197665;c=1606980011809) storage 449fc13d-a0df-4d01-b5b4-55c170b0904b
2020-12-03 07:20:20,974 [IPC Server handler 3 on default port 38725] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:33835
2020-12-03 07:20:20,974 [IPC Server handler 3 on default port 38725] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 449fc13d-a0df-4d01-b5b4-55c170b0904b (127.0.0.1:33835).
2020-12-03 07:20:20,975 [BP-442495584-172.17.0.8-1606980011809 heartbeating to localhost/127.0.0.1:38725] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-442495584-172.17.0.8-1606980011809 (Datanode Uuid 449fc13d-a0df-4d01-b5b4-55c170b0904b) service to localhost/127.0.0.1:38725 successfully registered with NN
2020-12-03 07:20:20,975 [BP-442495584-172.17.0.8-1606980011809 heartbeating to localhost/127.0.0.1:38725] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:38725 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:20,979 [IPC Server handler 5 on default port 38725] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-5b55ee66-15b3-4cba-8c37-e81745468554 for DN 127.0.0.1:33835
2020-12-03 07:20:20,979 [IPC Server handler 5 on default port 38725] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-34ccfd88-9e87-4fea-8957-f24bb641b43a for DN 127.0.0.1:33835
2020-12-03 07:20:20,989 [Thread-246] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1196056580-172.17.0.8-1606980014721 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8: 19ms
2020-12-03 07:20:20,989 [Thread-244] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1196056580-172.17.0.8-1606980014721 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7: 19ms
2020-12-03 07:20:20,990 [Thread-172] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1196056580-172.17.0.8-1606980014721: 20ms
2020-12-03 07:20:20,990 [Thread-252] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1196056580-172.17.0.8-1606980014721 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7...
2020-12-03 07:20:20,990 [Thread-252] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-1196056580-172.17.0.8-1606980014721/current/replicas doesn't exist 
2020-12-03 07:20:20,990 [Thread-253] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1196056580-172.17.0.8-1606980014721 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8...
2020-12-03 07:20:20,991 [Thread-253] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-1196056580-172.17.0.8-1606980014721/current/replicas doesn't exist 
2020-12-03 07:20:20,991 [Thread-252] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1196056580-172.17.0.8-1606980014721 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7: 0ms
2020-12-03 07:20:20,991 [Thread-253] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1196056580-172.17.0.8-1606980014721 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8: 1ms
2020-12-03 07:20:20,991 [Thread-172] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1196056580-172.17.0.8-1606980014721: 1ms
2020-12-03 07:20:20,991 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x7efc5e66d7d59a63: Processing first storage report for DS-5b55ee66-15b3-4cba-8c37-e81745468554 from datanode 449fc13d-a0df-4d01-b5b4-55c170b0904b
2020-12-03 07:20:20,991 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x7efc5e66d7d59a63: from storage DS-5b55ee66-15b3-4cba-8c37-e81745468554 node DatanodeRegistration(127.0.0.1:33835, datanodeUuid=449fc13d-a0df-4d01-b5b4-55c170b0904b, infoPort=39227, infoSecurePort=0, ipcPort=45254, storageInfo=lv=-57;cid=testClusterID;nsid=1294197665;c=1606980011809), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:20,991 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1196056580-172.17.0.8-1606980014721 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-12-03 07:20:20,991 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1196056580-172.17.0.8-1606980014721 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7
2020-12-03 07:20:20,992 [BP-1196056580-172.17.0.8-1606980014721 heartbeating to localhost/127.0.0.1:46765] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1196056580-172.17.0.8-1606980014721 (Datanode Uuid 449fc13d-a0df-4d01-b5b4-55c170b0904b) service to localhost/127.0.0.1:46765 beginning handshake with NN
2020-12-03 07:20:20,992 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x7efc5e66d7d59a63: Processing first storage report for DS-34ccfd88-9e87-4fea-8957-f24bb641b43a from datanode 449fc13d-a0df-4d01-b5b4-55c170b0904b
2020-12-03 07:20:20,992 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, DS-5b55ee66-15b3-4cba-8c37-e81745468554): finished scanning block pool BP-1196056580-172.17.0.8-1606980014721
2020-12-03 07:20:20,992 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, DS-34ccfd88-9e87-4fea-8957-f24bb641b43a): finished scanning block pool BP-1196056580-172.17.0.8-1606980014721
2020-12-03 07:20:20,992 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x7efc5e66d7d59a63: from storage DS-34ccfd88-9e87-4fea-8957-f24bb641b43a node DatanodeRegistration(127.0.0.1:33835, datanodeUuid=449fc13d-a0df-4d01-b5b4-55c170b0904b, infoPort=39227, infoSecurePort=0, ipcPort=45254, storageInfo=lv=-57;cid=testClusterID;nsid=1294197665;c=1606980011809), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:20,993 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, DS-5b55ee66-15b3-4cba-8c37-e81745468554): no suitable block pools found to scan.  Waiting 1814399978 ms.
2020-12-03 07:20:20,993 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, DS-34ccfd88-9e87-4fea-8957-f24bb641b43a): no suitable block pools found to scan.  Waiting 1814399978 ms.
2020-12-03 07:20:20,993 [IPC Server handler 3 on default port 46765] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:33835, datanodeUuid=449fc13d-a0df-4d01-b5b4-55c170b0904b, infoPort=39227, infoSecurePort=0, ipcPort=45254, storageInfo=lv=-57;cid=testClusterID;nsid=1484114581;c=1606980014721) storage 449fc13d-a0df-4d01-b5b4-55c170b0904b
2020-12-03 07:20:20,993 [BP-442495584-172.17.0.8-1606980011809 heartbeating to localhost/127.0.0.1:38725] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x7efc5e66d7d59a63,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 11 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:20,993 [BP-442495584-172.17.0.8-1606980011809 heartbeating to localhost/127.0.0.1:38725] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-442495584-172.17.0.8-1606980011809
2020-12-03 07:20:20,993 [IPC Server handler 3 on default port 46765] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:33835
2020-12-03 07:20:20,993 [IPC Server handler 3 on default port 46765] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 449fc13d-a0df-4d01-b5b4-55c170b0904b (127.0.0.1:33835).
2020-12-03 07:20:20,994 [BP-1196056580-172.17.0.8-1606980014721 heartbeating to localhost/127.0.0.1:46765] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1196056580-172.17.0.8-1606980014721 (Datanode Uuid 449fc13d-a0df-4d01-b5b4-55c170b0904b) service to localhost/127.0.0.1:46765 successfully registered with NN
2020-12-03 07:20:20,994 [BP-1196056580-172.17.0.8-1606980014721 heartbeating to localhost/127.0.0.1:46765] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:46765 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:20,996 [IPC Server handler 4 on default port 46765] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-5b55ee66-15b3-4cba-8c37-e81745468554 for DN 127.0.0.1:33835
2020-12-03 07:20:20,996 [IPC Server handler 4 on default port 46765] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-34ccfd88-9e87-4fea-8957-f24bb641b43a for DN 127.0.0.1:33835
2020-12-03 07:20:20,998 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xf78fd322cf0f7262: Processing first storage report for DS-5b55ee66-15b3-4cba-8c37-e81745468554 from datanode 449fc13d-a0df-4d01-b5b4-55c170b0904b
2020-12-03 07:20:20,998 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xf78fd322cf0f7262: from storage DS-5b55ee66-15b3-4cba-8c37-e81745468554 node DatanodeRegistration(127.0.0.1:33835, datanodeUuid=449fc13d-a0df-4d01-b5b4-55c170b0904b, infoPort=39227, infoSecurePort=0, ipcPort=45254, storageInfo=lv=-57;cid=testClusterID;nsid=1484114581;c=1606980014721), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:20,998 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xf78fd322cf0f7262: Processing first storage report for DS-34ccfd88-9e87-4fea-8957-f24bb641b43a from datanode 449fc13d-a0df-4d01-b5b4-55c170b0904b
2020-12-03 07:20:20,998 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xf78fd322cf0f7262: from storage DS-34ccfd88-9e87-4fea-8957-f24bb641b43a node DatanodeRegistration(127.0.0.1:33835, datanodeUuid=449fc13d-a0df-4d01-b5b4-55c170b0904b, infoPort=39227, infoSecurePort=0, ipcPort=45254, storageInfo=lv=-57;cid=testClusterID;nsid=1484114581;c=1606980014721), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:20,999 [BP-1196056580-172.17.0.8-1606980014721 heartbeating to localhost/127.0.0.1:46765] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xf78fd322cf0f7262,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:20,999 [BP-1196056580-172.17.0.8-1606980014721 heartbeating to localhost/127.0.0.1:46765] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1196056580-172.17.0.8-1606980014721
2020-12-03 07:20:21,064 [IPC Server handler 6 on default port 38725] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:21,071 [IPC Server handler 7 on default port 46765] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:21,073 [Listener at localhost/45254] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:20:21,079 [IPC Server handler 7 on default port 38725] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:21,082 [IPC Server handler 8 on default port 46765] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:21,084 [Listener at localhost/45254] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:20:21,119 [Listener at localhost/45254] INFO  resolver.MountTableResolver (MountTableResolver.java:initDefaultNameService(191)) - Default name service: ns0, enabled to read or write
2020-12-03 07:20:21,123 [Listener at localhost/45254] INFO  router.RouterRpcServer (RouterRpcServer.java:<init>(251)) - RPC server binding to /0.0.0.0:0 with 10 handlers for Router null
2020-12-03 07:20:21,125 [Listener at localhost/45254] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:21,126 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:21,133 [Listener at 0.0.0.0/43741] INFO  router.ConnectionManager (ConnectionManager.java:<init>(120)) - Cleaning connection pools every 60 seconds
2020-12-03 07:20:21,133 [Listener at 0.0.0.0/43741] INFO  router.ConnectionManager (ConnectionManager.java:<init>(125)) - Cleaning connections every 10 seconds
2020-12-03 07:20:21,134 [Listener at 0.0.0.0/43741] INFO  router.ConnectionManager (ConnectionManager.java:start(139)) - Cleaning every 10 seconds
2020-12-03 07:20:21,150 [Listener at 0.0.0.0/43741] INFO  router.RouterAdminServer (RouterAdminServer.java:<init>(132)) - Admin server binding to 0.0.0.0:0
2020-12-03 07:20:21,151 [Listener at 0.0.0.0/43741] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 100, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:21,152 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:21,168 [Listener at 0.0.0.0/44216] INFO  store.StateStoreService (StateStoreService.java:serviceInit(185)) - Registered StateStoreMBean: Hadoop:service=Router,name=StateStore
2020-12-03 07:20:21,168 [Listener at 0.0.0.0/44216] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.federation.router.cache.ttl(5000) assuming MILLISECONDS
2020-12-03 07:20:21,172 [Listener at 0.0.0.0/44216] INFO  metrics.FederationRPCPerformanceMonitor (FederationRPCPerformanceMonitor.java:init(91)) - Registered FederationRPCMBean: Hadoop:service=Router,name=FederationRPC
2020-12-03 07:20:21,190 [Listener at 0.0.0.0/44216] INFO  resolver.MountTableResolver (MountTableResolver.java:initDefaultNameService(191)) - Default name service: ns0, enabled to read or write
2020-12-03 07:20:21,190 [Listener at 0.0.0.0/44216] INFO  router.RouterRpcServer (RouterRpcServer.java:<init>(251)) - RPC server binding to /0.0.0.0:0 with 10 handlers for Router null
2020-12-03 07:20:21,191 [Listener at 0.0.0.0/44216] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:21,192 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:21,195 [Listener at 0.0.0.0/34676] INFO  router.ConnectionManager (ConnectionManager.java:<init>(120)) - Cleaning connection pools every 60 seconds
2020-12-03 07:20:21,196 [Listener at 0.0.0.0/34676] INFO  router.ConnectionManager (ConnectionManager.java:<init>(125)) - Cleaning connections every 10 seconds
2020-12-03 07:20:21,196 [Listener at 0.0.0.0/34676] INFO  router.ConnectionManager (ConnectionManager.java:start(139)) - Cleaning every 10 seconds
2020-12-03 07:20:21,197 [Listener at 0.0.0.0/34676] INFO  router.RouterAdminServer (RouterAdminServer.java:<init>(132)) - Admin server binding to 0.0.0.0:0
2020-12-03 07:20:21,197 [Listener at 0.0.0.0/34676] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 100, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:21,198 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:21,202 [Listener at 0.0.0.0/36935] INFO  store.StateStoreService (StateStoreService.java:serviceInit(185)) - Registered StateStoreMBean: Hadoop:service=Router,name=StateStore-1
2020-12-03 07:20:21,202 [Listener at 0.0.0.0/36935] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.federation.router.cache.ttl(5000) assuming MILLISECONDS
2020-12-03 07:20:21,203 [Listener at 0.0.0.0/36935] INFO  metrics.FederationRPCPerformanceMonitor (FederationRPCPerformanceMonitor.java:init(91)) - Registered FederationRPCMBean: Hadoop:service=Router,name=FederationRPC-1
2020-12-03 07:20:21,211 [Listener at 0.0.0.0/36935] WARN  impl.StateStoreFileImpl (StateStoreFileImpl.java:getRootDir(93)) - The root directory is not available, using /tmp/1606980021211-0
2020-12-03 07:20:21,212 [Listener at 0.0.0.0/36935] INFO  impl.StateStoreFileBaseImpl (StateStoreFileBaseImpl.java:initRecordStorage(181)) - /tmp/1606980021211-0/RouterState data directory doesn't exist, creating it
2020-12-03 07:20:21,213 [Listener at 0.0.0.0/36935] INFO  impl.StateStoreFileBaseImpl (StateStoreFileBaseImpl.java:initRecordStorage(181)) - /tmp/1606980021211-0/MountTable data directory doesn't exist, creating it
2020-12-03 07:20:21,213 [Listener at 0.0.0.0/36935] INFO  impl.StateStoreFileBaseImpl (StateStoreFileBaseImpl.java:initRecordStorage(181)) - /tmp/1606980021211-0/DisabledNameservice data directory doesn't exist, creating it
2020-12-03 07:20:21,213 [Listener at 0.0.0.0/36935] INFO  impl.StateStoreFileBaseImpl (StateStoreFileBaseImpl.java:initRecordStorage(181)) - /tmp/1606980021211-0/MembershipState data directory doesn't exist, creating it
2020-12-03 07:20:21,214 [Listener at 0.0.0.0/36935] INFO  store.StateStoreService (StateStoreService.java:loadDriver(275)) - Connection to the State Store driver StateStoreFileImpl is open and ready
2020-12-03 07:20:21,239 [Listener at 0.0.0.0/36935] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreConnectionMonitorService
2020-12-03 07:20:21,240 [Listener at 0.0.0.0/36935] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreCacheUpdateService
2020-12-03 07:20:21,241 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:21,242 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:21,245 [Listener at 0.0.0.0/36935] INFO  router.RouterRpcServer (RouterRpcServer.java:serviceStart(322)) - Router RPC up at: /0.0.0.0:43741
2020-12-03 07:20:21,245 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:21,246 [Listener at 0.0.0.0/36935] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service org.apache.hadoop.hdfs.server.federation.router.RouterQuotaUpdateService
2020-12-03 07:20:21,246 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:21,247 [Listener at 0.0.0.0/36935] WARN  impl.StateStoreFileImpl (StateStoreFileImpl.java:getRootDir(93)) - The root directory is not available, using /tmp/1606980021247-0
2020-12-03 07:20:21,247 [Listener at 0.0.0.0/36935] INFO  impl.StateStoreFileBaseImpl (StateStoreFileBaseImpl.java:initRecordStorage(181)) - /tmp/1606980021247-0/RouterState data directory doesn't exist, creating it
2020-12-03 07:20:21,248 [Listener at 0.0.0.0/36935] INFO  impl.StateStoreFileBaseImpl (StateStoreFileBaseImpl.java:initRecordStorage(181)) - /tmp/1606980021247-0/MountTable data directory doesn't exist, creating it
2020-12-03 07:20:21,248 [Listener at 0.0.0.0/36935] INFO  impl.StateStoreFileBaseImpl (StateStoreFileBaseImpl.java:initRecordStorage(181)) - /tmp/1606980021247-0/DisabledNameservice data directory doesn't exist, creating it
2020-12-03 07:20:21,248 [Listener at 0.0.0.0/36935] INFO  impl.StateStoreFileBaseImpl (StateStoreFileBaseImpl.java:initRecordStorage(181)) - /tmp/1606980021247-0/MembershipState data directory doesn't exist, creating it
2020-12-03 07:20:21,248 [Listener at 0.0.0.0/36935] INFO  store.StateStoreService (StateStoreService.java:loadDriver(275)) - Connection to the State Store driver StateStoreFileImpl is open and ready
2020-12-03 07:20:21,249 [Listener at 0.0.0.0/36935] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreConnectionMonitorService
2020-12-03 07:20:21,249 [Listener at 0.0.0.0/36935] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreCacheUpdateService
2020-12-03 07:20:21,251 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:21,251 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:21,253 [Listener at 0.0.0.0/36935] INFO  router.RouterRpcServer (RouterRpcServer.java:serviceStart(322)) - Router RPC up at: /0.0.0.0:34676
2020-12-03 07:20:21,254 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:21,254 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:21,255 [Listener at 0.0.0.0/36935] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service org.apache.hadoop.hdfs.server.federation.router.RouterQuotaUpdateService
2020-12-03 07:20:21,273 [Listener at 0.0.0.0/36935] INFO  impl.MembershipStoreImpl (MembershipStoreImpl.java:namenodeHeartbeat(176)) - Inserting new NN registration: b120fe239ee9:43741->ns0:null:localhost:38725-ACTIVE
2020-12-03 07:20:21,281 [Listener at 0.0.0.0/36935] INFO  impl.MembershipStoreImpl (MembershipStoreImpl.java:namenodeHeartbeat(176)) - Inserting new NN registration: b120fe239ee9:43741->ns1:null:localhost:46765-ACTIVE
2020-12-03 07:20:21,282 [Listener at 0.0.0.0/36935] INFO  impl.MembershipStoreImpl (MembershipStoreImpl.java:namenodeHeartbeat(176)) - Inserting new NN registration: b120fe239ee9:34676->ns0:null:localhost:38725-ACTIVE
2020-12-03 07:20:21,283 [Listener at 0.0.0.0/36935] INFO  impl.MembershipStoreImpl (MembershipStoreImpl.java:namenodeHeartbeat(176)) - Inserting new NN registration: b120fe239ee9:34676->ns1:null:localhost:46765-ACTIVE
2020-12-03 07:20:21,294 [Listener at 0.0.0.0/36935] ERROR resolver.MembershipNamenodeResolver (MembershipNamenodeResolver.java:getNamenodesForNameserviceId(192)) - Cannot locate eligible NNs for ns0
2020-12-03 07:20:22,294 [Listener at 0.0.0.0/36935] ERROR resolver.MembershipNamenodeResolver (MembershipNamenodeResolver.java:getNamenodesForNameserviceId(192)) - Cannot locate eligible NNs for ns0
2020-12-03 07:20:23,295 [Listener at 0.0.0.0/36935] ERROR resolver.MembershipNamenodeResolver (MembershipNamenodeResolver.java:getNamenodesForNameserviceId(192)) - Cannot locate eligible NNs for ns0
2020-12-03 07:20:24,296 [Listener at 0.0.0.0/36935] ERROR resolver.MembershipNamenodeResolver (MembershipNamenodeResolver.java:getNamenodesForNameserviceId(192)) - Cannot locate eligible NNs for ns0
2020-12-03 07:20:25,297 [Listener at 0.0.0.0/36935] ERROR resolver.MembershipNamenodeResolver (MembershipNamenodeResolver.java:getNamenodesForNameserviceId(192)) - Cannot locate eligible NNs for ns0
2020-12-03 07:20:26,320 [IPC Server handler 2 on default port 38725] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/testdir10	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:20:26,359 [Listener at 0.0.0.0/36935] INFO  federation.MiniRouterDFSCluster (MiniRouterDFSCluster.java:getAdminClient(237)) - Connecting to router admin at /0.0.0.0:36935
2020-12-03 07:20:26,407 [Listener at 0.0.0.0/36935] INFO  resolver.MountTableResolver (MountTableResolver.java:refreshEntries(332)) - Added new mount point /updatequota to resolver
2020-12-03 07:20:26,438 [IPC Server handler 8 on default port 38725] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/testdir10	dst=null	perm=null	proto=rpc
2020-12-03 07:20:26,456 [IPC Server handler 1 on default port 38725] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=quotaUsage	src=/testdir10	dst=null	perm=null	proto=rpc
2020-12-03 07:20:26,470 [IPC Server handler 3 on default port 38725] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setSpaceQuota	src=/testdir10	dst=null	perm=null	proto=rpc
2020-12-03 07:20:26,490 [IPC Server handler 0 on default port 38725] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/testdir10/fbc2bd0e-5c50-4a6c-ada4-43061717490e	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:20:26,493 [Listener at 0.0.0.0/36935] INFO  federation.MiniRouterDFSCluster (MiniRouterDFSCluster.java:getClient(249)) - Connecting to router at hdfs://0.0.0.0:34676
2020-12-03 07:20:26,542 [IPC Server handler 6 on default port 38725] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/testdir10/file	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:20:26,582 [IPC Server handler 7 on default port 38725] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /testdir10/file is closed by DFSClient_NONMAPREDUCE_1791751536_1
2020-12-03 07:20:26,597 [IPC Server handler 9 on default port 38725] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=append	src=/testdir10/file	dst=null	perm=null	proto=rpc
2020-12-03 07:20:26,628 [IPC Server handler 4 on default port 38725] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:38408 for /testdir10/file
2020-12-03 07:20:26,652 [Thread-294] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:26,739 [DataXceiver for client DFSClient_NONMAPREDUCE_1791751536_1 at /127.0.0.1:40866 [Receiving block BP-442495584-172.17.0.8-1606980011809:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-442495584-172.17.0.8-1606980011809:blk_1073741825_1001 src: /127.0.0.1:40866 dest: /127.0.0.1:38408
2020-12-03 07:20:26,814 [PacketResponder: BP-442495584-172.17.0.8-1606980011809:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40866, dest: /127.0.0.1:38408, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1791751536_1, offset: 0, srvID: bf73dede-45ff-42c6-af89-d263bc2c1a45, blockid: BP-442495584-172.17.0.8-1606980011809:blk_1073741825_1001, duration(ns): 27765140
2020-12-03 07:20:26,814 [PacketResponder: BP-442495584-172.17.0.8-1606980011809:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-442495584-172.17.0.8-1606980011809:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:20:26,822 [IPC Server handler 8 on default port 38725] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2995)) - BLOCK* blk_1073741825_1001 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /testdir10/file
2020-12-03 07:20:27,227 [IPC Server handler 5 on default port 38725] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /testdir10/file is closed by DFSClient_NONMAPREDUCE_1791751536_1
2020-12-03 07:20:27,230 [IPC Server handler 0 on default port 38725] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/testdir10	dst=null	perm=null	proto=rpc
2020-12-03 07:20:27,232 [IPC Server handler 6 on default port 38725] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=quotaUsage	src=/testdir10	dst=null	perm=null	proto=rpc
2020-12-03 07:20:27,240 [Thread-298] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - org.apache.hadoop.hdfs.server.federation.router.RouterQuotaUpdateService is shutting down
2020-12-03 07:20:27,241 [Thread-298] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service org.apache.hadoop.hdfs.server.federation.router.RouterQuotaUpdateService
2020-12-03 07:20:27,242 [Thread-298] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 36935
2020-12-03 07:20:27,246 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:27,247 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:27,250 [Thread-298] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 34676
2020-12-03 07:20:27,251 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:27,251 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:27,259 [Thread-298] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreCacheUpdateService is shutting down
2020-12-03 07:20:27,259 [Thread-298] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreCacheUpdateService
2020-12-03 07:20:27,261 [Thread-298] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreConnectionMonitorService is shutting down
2020-12-03 07:20:27,261 [Thread-298] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreConnectionMonitorService
2020-12-03 07:20:28,237 [Listener at 0.0.0.0/36935] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:20:28,237 [Listener at 0.0.0.0/36935] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 3
2020-12-03 07:20:28,239 [Listener at 0.0.0.0/36935] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:28,239 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@4fe01803] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:28,240 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, DS-5b55ee66-15b3-4cba-8c37-e81745468554) exiting.
2020-12-03 07:20:28,240 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, DS-34ccfd88-9e87-4fea-8957-f24bb641b43a) exiting.
2020-12-03 07:20:28,289 [Listener at 0.0.0.0/36935] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@7b44b63d{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:28,293 [Listener at 0.0.0.0/36935] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4a699efa{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:28,294 [Listener at 0.0.0.0/36935] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3fbfa96{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:20:28,294 [Listener at 0.0.0.0/36935] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@599f571f{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:20:28,297 [Listener at 0.0.0.0/36935] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 45254
2020-12-03 07:20:28,299 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:28,302 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:28,303 [BP-442495584-172.17.0.8-1606980011809 heartbeating to localhost/127.0.0.1:38725] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:28,303 [BP-442495584-172.17.0.8-1606980011809 heartbeating to localhost/127.0.0.1:38725] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-442495584-172.17.0.8-1606980011809 (Datanode Uuid 449fc13d-a0df-4d01-b5b4-55c170b0904b) service to localhost/127.0.0.1:38725
2020-12-03 07:20:28,303 [BP-442495584-172.17.0.8-1606980011809 heartbeating to localhost/127.0.0.1:38725] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-442495584-172.17.0.8-1606980011809 (Datanode Uuid 449fc13d-a0df-4d01-b5b4-55c170b0904b)
2020-12-03 07:20:28,304 [BP-442495584-172.17.0.8-1606980011809 heartbeating to localhost/127.0.0.1:38725] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-442495584-172.17.0.8-1606980011809
2020-12-03 07:20:28,305 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-442495584-172.17.0.8-1606980011809] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:28,303 [BP-1196056580-172.17.0.8-1606980014721 heartbeating to localhost/127.0.0.1:46765] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:28,305 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-442495584-172.17.0.8-1606980011809] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:28,310 [BP-1196056580-172.17.0.8-1606980014721 heartbeating to localhost/127.0.0.1:46765] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1196056580-172.17.0.8-1606980014721 (Datanode Uuid 449fc13d-a0df-4d01-b5b4-55c170b0904b) service to localhost/127.0.0.1:46765
2020-12-03 07:20:28,311 [BP-1196056580-172.17.0.8-1606980014721 heartbeating to localhost/127.0.0.1:46765] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1196056580-172.17.0.8-1606980014721 (Datanode Uuid 449fc13d-a0df-4d01-b5b4-55c170b0904b)
2020-12-03 07:20:28,311 [BP-1196056580-172.17.0.8-1606980014721 heartbeating to localhost/127.0.0.1:46765] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1196056580-172.17.0.8-1606980014721
2020-12-03 07:20:28,311 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-1196056580-172.17.0.8-1606980014721] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:28,311 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-1196056580-172.17.0.8-1606980014721] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:28,315 [Listener at 0.0.0.0/36935] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:28,316 [Listener at 0.0.0.0/36935] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:28,317 [Listener at 0.0.0.0/36935] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:28,317 [Listener at 0.0.0.0/36935] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:28,326 [Listener at 0.0.0.0/36935] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:28,326 [Listener at 0.0.0.0/36935] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 2
2020-12-03 07:20:28,327 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@2a037324] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:28,327 [Listener at 0.0.0.0/36935] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:28,336 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, DS-80699e0e-37c6-48a4-8564-b17c23a6c31a) exiting.
2020-12-03 07:20:28,366 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, DS-83fd7724-742b-40a1-bf8e-dcb9168386f8) exiting.
2020-12-03 07:20:28,564 [Listener at 0.0.0.0/36935] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5f462e3b{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:28,565 [Listener at 0.0.0.0/36935] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@3d7fa3ae{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:28,565 [Listener at 0.0.0.0/36935] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@272a179c{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:20:28,566 [Listener at 0.0.0.0/36935] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4d8539de{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:20:28,568 [Listener at 0.0.0.0/36935] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 46440
2020-12-03 07:20:28,571 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:28,573 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:28,574 [BP-442495584-172.17.0.8-1606980011809 heartbeating to localhost/127.0.0.1:38725] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:28,574 [BP-442495584-172.17.0.8-1606980011809 heartbeating to localhost/127.0.0.1:38725] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-442495584-172.17.0.8-1606980011809 (Datanode Uuid bf73dede-45ff-42c6-af89-d263bc2c1a45) service to localhost/127.0.0.1:38725
2020-12-03 07:20:28,574 [BP-442495584-172.17.0.8-1606980011809 heartbeating to localhost/127.0.0.1:38725] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-442495584-172.17.0.8-1606980011809 (Datanode Uuid bf73dede-45ff-42c6-af89-d263bc2c1a45)
2020-12-03 07:20:28,574 [BP-442495584-172.17.0.8-1606980011809 heartbeating to localhost/127.0.0.1:38725] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-442495584-172.17.0.8-1606980011809
2020-12-03 07:20:28,575 [BP-1196056580-172.17.0.8-1606980014721 heartbeating to localhost/127.0.0.1:46765] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:28,576 [BP-1196056580-172.17.0.8-1606980014721 heartbeating to localhost/127.0.0.1:46765] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1196056580-172.17.0.8-1606980014721 (Datanode Uuid bf73dede-45ff-42c6-af89-d263bc2c1a45) service to localhost/127.0.0.1:46765
2020-12-03 07:20:28,576 [BP-1196056580-172.17.0.8-1606980014721 heartbeating to localhost/127.0.0.1:46765] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1196056580-172.17.0.8-1606980014721 (Datanode Uuid bf73dede-45ff-42c6-af89-d263bc2c1a45)
2020-12-03 07:20:28,576 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-442495584-172.17.0.8-1606980011809] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:28,577 [BP-1196056580-172.17.0.8-1606980014721 heartbeating to localhost/127.0.0.1:46765] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1196056580-172.17.0.8-1606980014721
2020-12-03 07:20:28,577 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-442495584-172.17.0.8-1606980011809] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:28,577 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-1196056580-172.17.0.8-1606980014721] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:28,581 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-1196056580-172.17.0.8-1606980014721] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:28,583 [Listener at 0.0.0.0/36935] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:28,584 [Listener at 0.0.0.0/36935] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:28,585 [Listener at 0.0.0.0/36935] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:28,585 [Listener at 0.0.0.0/36935] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:28,587 [Listener at 0.0.0.0/36935] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:28,587 [Listener at 0.0.0.0/36935] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 1
2020-12-03 07:20:28,587 [Listener at 0.0.0.0/36935] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:28,587 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@60f2e0bd] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:28,589 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, DS-10b59786-dd4a-42b3-8172-914cf700b081) exiting.
2020-12-03 07:20:28,589 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, DS-5fa6371f-9ba8-4a41-b4aa-d539ceb7700f) exiting.
2020-12-03 07:20:28,612 [Listener at 0.0.0.0/36935] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5eccd3b9{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:28,613 [Listener at 0.0.0.0/36935] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4d6f197e{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:28,614 [Listener at 0.0.0.0/36935] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@26a94fa5{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:20:28,614 [Listener at 0.0.0.0/36935] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1d3e6d34{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:20:28,615 [Listener at 0.0.0.0/36935] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 41249
2020-12-03 07:20:28,618 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:28,618 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:28,620 [BP-1196056580-172.17.0.8-1606980014721 heartbeating to localhost/127.0.0.1:46765] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:28,620 [BP-442495584-172.17.0.8-1606980011809 heartbeating to localhost/127.0.0.1:38725] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:28,620 [BP-1196056580-172.17.0.8-1606980014721 heartbeating to localhost/127.0.0.1:46765] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1196056580-172.17.0.8-1606980014721 (Datanode Uuid 5d254eed-d31f-4b68-8ed2-0637095141a0) service to localhost/127.0.0.1:46765
2020-12-03 07:20:28,620 [BP-442495584-172.17.0.8-1606980011809 heartbeating to localhost/127.0.0.1:38725] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-442495584-172.17.0.8-1606980011809 (Datanode Uuid 5d254eed-d31f-4b68-8ed2-0637095141a0) service to localhost/127.0.0.1:38725
2020-12-03 07:20:28,620 [BP-1196056580-172.17.0.8-1606980014721 heartbeating to localhost/127.0.0.1:46765] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1196056580-172.17.0.8-1606980014721 (Datanode Uuid 5d254eed-d31f-4b68-8ed2-0637095141a0)
2020-12-03 07:20:28,620 [BP-442495584-172.17.0.8-1606980011809 heartbeating to localhost/127.0.0.1:38725] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-442495584-172.17.0.8-1606980011809 (Datanode Uuid 5d254eed-d31f-4b68-8ed2-0637095141a0)
2020-12-03 07:20:28,620 [BP-1196056580-172.17.0.8-1606980014721 heartbeating to localhost/127.0.0.1:46765] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1196056580-172.17.0.8-1606980014721
2020-12-03 07:20:28,621 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-1196056580-172.17.0.8-1606980014721] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:28,621 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-1196056580-172.17.0.8-1606980014721] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:28,621 [BP-442495584-172.17.0.8-1606980011809 heartbeating to localhost/127.0.0.1:38725] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-442495584-172.17.0.8-1606980011809
2020-12-03 07:20:28,621 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-442495584-172.17.0.8-1606980011809] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:28,622 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-442495584-172.17.0.8-1606980011809] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:28,627 [Listener at 0.0.0.0/36935] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:28,627 [Listener at 0.0.0.0/36935] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:28,628 [Listener at 0.0.0.0/36935] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:28,628 [Listener at 0.0.0.0/36935] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:28,631 [Listener at 0.0.0.0/36935] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:28,631 [Listener at 0.0.0.0/36935] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:20:28,631 [Listener at 0.0.0.0/36935] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:28,631 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@c20be82] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:28,632 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, DS-e52a9cea-fdc2-430f-b809-6ea6c5790b20) exiting.
2020-12-03 07:20:28,632 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, DS-d8458332-36c9-46f8-afdf-c2195c0ebf3a) exiting.
2020-12-03 07:20:28,649 [Listener at 0.0.0.0/36935] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@3add81c4{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:28,649 [Listener at 0.0.0.0/36935] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@1a1d3c1a{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:28,650 [Listener at 0.0.0.0/36935] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1c05a54d{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:20:28,650 [Listener at 0.0.0.0/36935] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@74a9c4b0{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:20:28,651 [Listener at 0.0.0.0/36935] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 44444
2020-12-03 07:20:28,654 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:28,654 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:28,656 [BP-442495584-172.17.0.8-1606980011809 heartbeating to localhost/127.0.0.1:38725] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:28,656 [BP-1196056580-172.17.0.8-1606980014721 heartbeating to localhost/127.0.0.1:46765] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:28,657 [BP-442495584-172.17.0.8-1606980011809 heartbeating to localhost/127.0.0.1:38725] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-442495584-172.17.0.8-1606980011809 (Datanode Uuid c9a70406-f6ea-4f06-bdaa-9c25e33ee15a) service to localhost/127.0.0.1:38725
2020-12-03 07:20:28,657 [BP-1196056580-172.17.0.8-1606980014721 heartbeating to localhost/127.0.0.1:46765] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1196056580-172.17.0.8-1606980014721 (Datanode Uuid c9a70406-f6ea-4f06-bdaa-9c25e33ee15a) service to localhost/127.0.0.1:46765
2020-12-03 07:20:28,657 [BP-442495584-172.17.0.8-1606980011809 heartbeating to localhost/127.0.0.1:38725] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-442495584-172.17.0.8-1606980011809 (Datanode Uuid c9a70406-f6ea-4f06-bdaa-9c25e33ee15a)
2020-12-03 07:20:28,657 [BP-1196056580-172.17.0.8-1606980014721 heartbeating to localhost/127.0.0.1:46765] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1196056580-172.17.0.8-1606980014721 (Datanode Uuid c9a70406-f6ea-4f06-bdaa-9c25e33ee15a)
2020-12-03 07:20:28,657 [BP-442495584-172.17.0.8-1606980011809 heartbeating to localhost/127.0.0.1:38725] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-442495584-172.17.0.8-1606980011809
2020-12-03 07:20:28,658 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-442495584-172.17.0.8-1606980011809] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:28,658 [BP-1196056580-172.17.0.8-1606980014721 heartbeating to localhost/127.0.0.1:46765] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1196056580-172.17.0.8-1606980014721
2020-12-03 07:20:28,658 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-442495584-172.17.0.8-1606980011809] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:28,668 [Listener at 0.0.0.0/36935] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:28,668 [Listener at 0.0.0.0/36935] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:28,668 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-1196056580-172.17.0.8-1606980014721] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:28,671 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-1196056580-172.17.0.8-1606980014721] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:28,671 [Listener at 0.0.0.0/36935] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:28,671 [Listener at 0.0.0.0/36935] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:28,675 [Listener at 0.0.0.0/36935] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:28,676 [Listener at 0.0.0.0/36935] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:20:28,676 [Listener at 0.0.0.0/36935] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:20:28,677 [Listener at 0.0.0.0/36935] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 1, 11
2020-12-03 07:20:28,679 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@21ca139c] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:20:28,682 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@4628b1d3] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:20:28,682 [Listener at 0.0.0.0/36935] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 12 Total time for transactions(ms): 27 Number of transactions batched in Syncs: 0 Number of syncs: 13 SyncTimes(ms): 7 1 
2020-12-03 07:20:28,685 [Listener at 0.0.0.0/36935] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000012
2020-12-03 07:20:28,686 [Listener at 0.0.0.0/36935] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000012
2020-12-03 07:20:28,687 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:20:28,687 [CacheReplicationMonitor(212274427)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:20:28,703 [Listener at 0.0.0.0/36935] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 38725
2020-12-03 07:20:28,706 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:28,708 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:28,708 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:20:28,708 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:20:28,748 [Listener at 0.0.0.0/36935] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:20:28,749 [Listener at 0.0.0.0/36935] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:20:28,751 [Listener at 0.0.0.0/36935] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1b955cac{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:20:28,752 [Listener at 0.0.0.0/36935] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@1f010bf0{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:28,753 [Listener at 0.0.0.0/36935] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@341814d3{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:20:28,753 [Listener at 0.0.0.0/36935] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@20f5281c{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:20:28,754 [Listener at 0.0.0.0/36935] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-12-03 07:20:28,764 [Listener at 0.0.0.0/36935] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-12-03 07:20:28,766 [Listener at 0.0.0.0/36935] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-12-03 07:20:28,770 [Listener at 0.0.0.0/36935] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:20:28,771 [Listener at 0.0.0.0/36935] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:20:28,780 [Listener at 0.0.0.0/36935] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 1, 1
2020-12-03 07:20:28,781 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@41200e0c] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:20:28,781 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@40f33492] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:20:28,785 [Listener at 0.0.0.0/36935] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 2 Total time for transactions(ms): 4 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 1 2 
2020-12-03 07:20:28,786 [Listener at 0.0.0.0/36935] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-3/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-3/current/edits_0000000000000000001-0000000000000000002
2020-12-03 07:20:28,786 [Listener at 0.0.0.0/36935] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-4/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-4/current/edits_0000000000000000001-0000000000000000002
2020-12-03 07:20:28,786 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:20:28,787 [CacheReplicationMonitor(11880)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:20:28,790 [Listener at 0.0.0.0/36935] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 46765
2020-12-03 07:20:28,793 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:28,793 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:20:28,796 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:28,798 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:20:28,806 [Listener at 0.0.0.0/36935] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:20:28,807 [Listener at 0.0.0.0/36935] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:20:28,809 [Listener at 0.0.0.0/36935] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@2e8ab815{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:20:28,811 [Listener at 0.0.0.0/36935] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@67af833b{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:28,812 [Listener at 0.0.0.0/36935] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@74f7d1d2{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:20:28,812 [Listener at 0.0.0.0/36935] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@486be205{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:20:28,832 [Thread-299] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - org.apache.hadoop.hdfs.server.federation.router.RouterQuotaUpdateService is shutting down
2020-12-03 07:20:28,832 [Thread-299] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service org.apache.hadoop.hdfs.server.federation.router.RouterQuotaUpdateService
2020-12-03 07:20:28,839 [Thread-299] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 44216
2020-12-03 07:20:28,841 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:28,842 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:28,845 [Thread-299] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 43741
2020-12-03 07:20:28,848 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:28,848 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:28,857 [Thread-299] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreCacheUpdateService is shutting down
2020-12-03 07:20:28,857 [Thread-299] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreCacheUpdateService
2020-12-03 07:20:28,861 [Thread-299] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreConnectionMonitorService is shutting down
2020-12-03 07:20:28,861 [Thread-299] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreConnectionMonitorService
msx-rc 0
