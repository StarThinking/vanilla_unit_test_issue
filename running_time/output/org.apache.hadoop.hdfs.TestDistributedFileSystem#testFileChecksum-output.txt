seed=-4493251828135460977
2020-12-03 07:20:22,338 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=2
Formatting using clusterid: testClusterID
2020-12-03 07:20:23,233 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:20:23,250 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:20:23,252 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:20:23,253 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:20:23,261 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:20:23,261 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:20:23,262 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:20:23,265 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:20:23,322 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:23,329 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2020-12-03 07:20:23,329 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:20:23,330 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:20:23,336 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:20:23,337 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:20:23
2020-12-03 07:20:23,339 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:20:23,341 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:23,343 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-12-03 07:20:23,343 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:20:23,364 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:20:23,364 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:20:23,372 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:20:23,372 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:20:23,372 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:20:23,373 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:20:23,374 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 2
2020-12-03 07:20:23,374 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:20:23,374 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:20:23,375 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:20:23,375 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:20:23,375 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:20:23,376 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:20:23,417 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GLOBAL serial map: bits=29 maxEntries=536870911
2020-12-03 07:20:23,418 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - USER serial map: bits=24 maxEntries=16777215
2020-12-03 07:20:23,418 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GROUP serial map: bits=24 maxEntries=16777215
2020-12-03 07:20:23,418 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - XATTR serial map: bits=24 maxEntries=16777215
2020-12-03 07:20:23,435 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:20:23,435 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:23,436 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-12-03 07:20:23,436 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:20:23,443 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:20:23,443 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:20:23,443 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:20:23,444 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:20:23,451 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:20:23,455 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:20:23,463 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:20:23,464 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:23,464 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-12-03 07:20:23,465 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:20:23,483 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:20:23,484 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:20:23,484 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:20:23,491 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:20:23,492 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:20:23,495 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:20:23,496 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:23,496 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-12-03 07:20:23,497 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:20:23,541 [main] INFO  namenode.FSImage (FSImage.java:format(185)) - Allocated new BlockPoolId: BP-1046523510-172.17.0.9-1606980023524
2020-12-03 07:20:23,693 [main] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-12-03 07:20:23,841 [main] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-12-03 07:20:23,879 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:20:23,879 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:20:24,045 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:20:24,045 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:20:24,123 [main] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-12-03 07:20:24,127 [main] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:20:24,250 [main] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:20:24,561 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:20:24,561 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:20:24,602 [main] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-12-03 07:20:24,655 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4dbb42b7] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:24,676 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:20:24,685 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:24,703 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @3518ms
2020-12-03 07:20:24,853 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:24,858 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:20:24,859 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:24,872 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:24,875 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:20:24,875 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:24,875 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:24,906 [main] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:20:24,906 [main] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:20:24,916 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 34813
2020-12-03 07:20:24,918 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:25,006 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@14bdbc74{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:25,008 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5a7fe64f{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:25,091 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@12299890{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:20:25,102 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@51c693d{HTTP/1.1,[http/1.1]}{localhost:34813}
2020-12-03 07:20:25,102 [main] INFO  server.Server (Server.java:doStart(419)) - Started @3918ms
2020-12-03 07:20:25,113 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:20:25,114 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:20:25,114 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:20:25,114 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:20:25,115 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:20:25,115 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:20:25,115 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:20:25,115 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:20:25,116 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:25,117 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:20:25,117 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:20:25,117 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:20:25,118 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:20:25
2020-12-03 07:20:25,118 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:20:25,118 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:25,119 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:20:25,119 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:20:25,124 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:20:25,124 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:20:25,127 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:20:25,127 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:20:25,127 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:20:25,127 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:20:25,128 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 2
2020-12-03 07:20:25,128 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:20:25,128 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:20:25,129 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:20:25,129 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:20:25,129 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:20:25,130 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:20:25,130 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:20:25,131 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:25,131 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:20:25,132 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:20:25,134 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:20:25,135 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:20:25,135 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:20:25,135 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:20:25,136 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:20:25,136 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:20:25,136 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:20:25,136 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:25,137 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:20:25,137 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:20:25,138 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:20:25,139 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:20:25,139 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:20:25,139 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:20:25,139 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:20:25,140 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:20:25,140 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:25,140 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:20:25,140 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:20:25,181 [main] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 4426@965bc16c2a3e
2020-12-03 07:20:25,207 [main] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 4426@965bc16c2a3e
2020-12-03 07:20:25,212 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-12-03 07:20:25,212 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-12-03 07:20:25,213 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:20:25,214 [main] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:20:25,245 [main] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:20:25,252 [main] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:20:25,252 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-12-03 07:20:25,258 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:20:25,259 [main] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 1
2020-12-03 07:20:25,351 [main] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:20:25,352 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 209 msecs
2020-12-03 07:20:25,583 [main] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:20:25,636 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:25,652 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:25,989 [Listener at localhost/35705] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:35705 to access this namenode/service.
2020-12-03 07:20:25,993 [Listener at localhost/35705] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:20:26,014 [Listener at localhost/35705] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:20:26,030 [Listener at localhost/35705] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:20:26,031 [Listener at localhost/35705] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:20:26,031 [Listener at localhost/35705] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:20:26,031 [Listener at localhost/35705] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:20:26,035 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 0
2020-12-03 07:20:26,035 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:20:26,035 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:20:26,035 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:20:26,035 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:20:26,036 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 5 msec
2020-12-03 07:20:26,072 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:26,072 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:26,076 [Listener at localhost/35705] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:35705
2020-12-03 07:20:26,080 [Listener at localhost/35705] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:20:26,080 [Listener at localhost/35705] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:20:26,088 [Listener at localhost/35705] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 8 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:20:26,094 [CacheReplicationMonitor(1118389469)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:20:26,101 [Listener at localhost/35705] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:20:26,185 [Listener at localhost/35705] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:20:26,215 [Listener at localhost/35705] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:20:26,235 [Listener at localhost/35705] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:26,240 [Listener at localhost/35705] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:26,243 [Listener at localhost/35705] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:26,247 [Listener at localhost/35705] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:26,248 [Listener at localhost/35705] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:26,253 [Listener at localhost/35705] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:26,260 [Listener at localhost/35705] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:37829
2020-12-03 07:20:26,262 [Listener at localhost/35705] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:26,262 [Listener at localhost/35705] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:26,283 [Listener at localhost/35705] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:26,285 [Listener at localhost/35705] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:26,286 [Listener at localhost/35705] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:26,286 [Listener at localhost/35705] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:26,288 [Listener at localhost/35705] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:26,290 [Listener at localhost/35705] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:26,290 [Listener at localhost/35705] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:26,290 [Listener at localhost/35705] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:26,294 [Listener at localhost/35705] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 39333
2020-12-03 07:20:26,294 [Listener at localhost/35705] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:26,296 [Listener at localhost/35705] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@29ef6856{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:26,296 [Listener at localhost/35705] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3faf2e7d{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:26,317 [Listener at localhost/35705] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@4ebea12c{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:20:26,318 [Listener at localhost/35705] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2a1edad4{HTTP/1.1,[http/1.1]}{localhost:39333}
2020-12-03 07:20:26,318 [Listener at localhost/35705] INFO  server.Server (Server.java:doStart(419)) - Started @5134ms
2020-12-03 07:20:26,997 [Listener at localhost/35705] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:35085
2020-12-03 07:20:26,999 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@63f34b70] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:27,000 [Listener at localhost/35705] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:27,000 [Listener at localhost/35705] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:27,024 [Listener at localhost/35705] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:27,027 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:27,038 [Listener at localhost/36565] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:36565
2020-12-03 07:20:27,055 [Listener at localhost/36565] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:20:27,057 [Listener at localhost/36565] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:20:27,073 [Thread-59] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35705 starting to offer service
2020-12-03 07:20:27,083 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:27,084 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:27,096 [Listener at localhost/36565] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:20:27,099 [Listener at localhost/36565] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:20:27,100 [Listener at localhost/36565] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:20:27,106 [Listener at localhost/36565] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:27,108 [Listener at localhost/36565] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:27,108 [Listener at localhost/36565] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:27,109 [Listener at localhost/36565] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:27,109 [Listener at localhost/36565] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:27,109 [Listener at localhost/36565] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:27,110 [Listener at localhost/36565] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:33302
2020-12-03 07:20:27,110 [Listener at localhost/36565] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:27,111 [Listener at localhost/36565] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:27,112 [Listener at localhost/36565] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:27,114 [Listener at localhost/36565] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:27,115 [Listener at localhost/36565] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:27,115 [Listener at localhost/36565] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:27,117 [Listener at localhost/36565] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:27,118 [Listener at localhost/36565] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:27,118 [Listener at localhost/36565] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:27,119 [Listener at localhost/36565] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:27,120 [Listener at localhost/36565] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 37750
2020-12-03 07:20:27,120 [Listener at localhost/36565] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:27,122 [Listener at localhost/36565] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@384fc774{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:27,122 [Listener at localhost/36565] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@71e9a896{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:27,130 [Listener at localhost/36565] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@344344fa{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:20:27,132 [Listener at localhost/36565] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2db2cd5{HTTP/1.1,[http/1.1]}{localhost:37750}
2020-12-03 07:20:27,133 [Listener at localhost/36565] INFO  server.Server (Server.java:doStart(419)) - Started @5948ms
2020-12-03 07:20:27,233 [Listener at localhost/36565] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:33738
2020-12-03 07:20:27,234 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@615f972] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:27,234 [Listener at localhost/36565] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:27,234 [Listener at localhost/36565] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:27,235 [Listener at localhost/36565] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:27,236 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:27,255 [Listener at localhost/37047] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:37047
2020-12-03 07:20:27,263 [Listener at localhost/37047] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:20:27,264 [Listener at localhost/37047] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:20:27,267 [Thread-83] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35705 starting to offer service
2020-12-03 07:20:27,278 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:27,278 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:27,305 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSClient.java:<init>(318)) - Sets dfs.client.block.write.replace-datanode-on-failure.min-replication to 0
2020-12-03 07:20:27,681 [Thread-59] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35705
2020-12-03 07:20:27,695 [Thread-83] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35705
2020-12-03 07:20:27,697 [Thread-59] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:27,717 [Thread-83] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:27,761 [Thread-59] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 4426@965bc16c2a3e
2020-12-03 07:20:27,762 [Thread-59] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 496224982. Formatting...
2020-12-03 07:20:27,763 [Thread-59] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-f3ac1c58-0b14-4986-934c-b8aef5e53f67 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-12-03 07:20:27,797 [Thread-83] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 4426@965bc16c2a3e
2020-12-03 07:20:27,797 [Thread-83] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 is not formatted for namespace 496224982. Formatting...
2020-12-03 07:20:27,798 [Thread-83] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-bcf09409-8126-477f-9cbc-2496fedf29f8 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 
2020-12-03 07:20:27,952 [Thread-59] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 4426@965bc16c2a3e
2020-12-03 07:20:27,953 [Thread-59] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 496224982. Formatting...
2020-12-03 07:20:27,953 [Thread-59] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-45995af8-9d1f-4a12-b9f4-0314f4595926 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-12-03 07:20:27,990 [Thread-83] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 4426@965bc16c2a3e
2020-12-03 07:20:27,991 [Thread-83] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 is not formatted for namespace 496224982. Formatting...
2020-12-03 07:20:27,991 [Thread-83] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-09eb49bc-318f-44d9-9f6f-340bc899821c for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 
2020-12-03 07:20:28,046 [IPC Server handler 4 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:28,055 [Listener at localhost/37047] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:28,055 [Listener at localhost/37047] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:28,124 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1046523510-172.17.0.9-1606980023524
2020-12-03 07:20:28,125 [Thread-59] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1046523510-172.17.0.9-1606980023524
2020-12-03 07:20:28,126 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-1046523510-172.17.0.9-1606980023524 is not formatted. Formatting ...
2020-12-03 07:20:28,126 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1046523510-172.17.0.9-1606980023524 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1046523510-172.17.0.9-1606980023524/current
2020-12-03 07:20:28,139 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1046523510-172.17.0.9-1606980023524
2020-12-03 07:20:28,139 [Thread-83] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1046523510-172.17.0.9-1606980023524
2020-12-03 07:20:28,140 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 and block pool id BP-1046523510-172.17.0.9-1606980023524 is not formatted. Formatting ...
2020-12-03 07:20:28,140 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1046523510-172.17.0.9-1606980023524 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1046523510-172.17.0.9-1606980023524/current
2020-12-03 07:20:28,158 [IPC Server handler 0 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:28,159 [Listener at localhost/37047] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:28,160 [Listener at localhost/37047] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:28,244 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1046523510-172.17.0.9-1606980023524
2020-12-03 07:20:28,244 [Thread-59] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1046523510-172.17.0.9-1606980023524
2020-12-03 07:20:28,245 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-1046523510-172.17.0.9-1606980023524 is not formatted. Formatting ...
2020-12-03 07:20:28,245 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1046523510-172.17.0.9-1606980023524 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1046523510-172.17.0.9-1606980023524/current
2020-12-03 07:20:28,258 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1046523510-172.17.0.9-1606980023524
2020-12-03 07:20:28,259 [Thread-83] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1046523510-172.17.0.9-1606980023524
2020-12-03 07:20:28,259 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 and block pool id BP-1046523510-172.17.0.9-1606980023524 is not formatted. Formatting ...
2020-12-03 07:20:28,259 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1046523510-172.17.0.9-1606980023524 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1046523510-172.17.0.9-1606980023524/current
2020-12-03 07:20:28,262 [IPC Server handler 1 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:28,263 [Listener at localhost/37047] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:28,263 [Listener at localhost/37047] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:28,342 [Thread-59] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=496224982;bpid=BP-1046523510-172.17.0.9-1606980023524;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=496224982;c=1606980023524;bpid=BP-1046523510-172.17.0.9-1606980023524;dnuuid=null
2020-12-03 07:20:28,365 [IPC Server handler 4 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:28,366 [Listener at localhost/37047] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:28,367 [Listener at localhost/37047] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:28,368 [Thread-83] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=496224982;bpid=BP-1046523510-172.17.0.9-1606980023524;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=496224982;c=1606980023524;bpid=BP-1046523510-172.17.0.9-1606980023524;dnuuid=null
2020-12-03 07:20:28,468 [IPC Server handler 5 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:28,469 [Listener at localhost/37047] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:28,470 [Listener at localhost/37047] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:28,480 [Thread-59] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 26ac7c37-c688-4862-acec-193b89c3e758
2020-12-03 07:20:28,504 [Thread-83] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 14d310ca-8fcf-4840-b079-e46f8cc4dc46
2020-12-03 07:20:28,572 [IPC Server handler 6 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:28,573 [Listener at localhost/37047] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:28,573 [Listener at localhost/37047] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:28,616 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-f3ac1c58-0b14-4986-934c-b8aef5e53f67
2020-12-03 07:20:28,616 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-bcf09409-8126-477f-9cbc-2496fedf29f8
2020-12-03 07:20:28,620 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-12-03 07:20:28,621 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: DISK
2020-12-03 07:20:28,623 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-45995af8-9d1f-4a12-b9f4-0314f4595926
2020-12-03 07:20:28,630 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-12-03 07:20:28,631 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-09eb49bc-318f-44d9-9f6f-340bc899821c
2020-12-03 07:20:28,631 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: DISK
2020-12-03 07:20:28,635 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:28,635 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:28,642 [Thread-59] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:20:28,651 [Thread-83] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:20:28,657 [Thread-59] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:20:28,657 [Thread-83] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:20:28,659 [Thread-83] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:20:28,659 [Thread-59] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:20:28,659 [Thread-83] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:20:28,660 [Thread-59] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:20:28,660 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1046523510-172.17.0.9-1606980023524
2020-12-03 07:20:28,660 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1046523510-172.17.0.9-1606980023524
2020-12-03 07:20:28,661 [Thread-102] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1046523510-172.17.0.9-1606980023524 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:20:28,661 [Thread-103] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1046523510-172.17.0.9-1606980023524 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:20:28,661 [Thread-104] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1046523510-172.17.0.9-1606980023524 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:20:28,662 [Thread-105] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1046523510-172.17.0.9-1606980023524 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:20:28,676 [IPC Server handler 7 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:28,692 [Listener at localhost/37047] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:28,694 [Listener at localhost/37047] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:28,709 [Thread-104] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1046523510-172.17.0.9-1606980023524 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 47ms
2020-12-03 07:20:28,710 [Thread-102] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1046523510-172.17.0.9-1606980023524 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 49ms
2020-12-03 07:20:28,709 [Thread-103] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1046523510-172.17.0.9-1606980023524 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 48ms
2020-12-03 07:20:28,712 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1046523510-172.17.0.9-1606980023524: 52ms
2020-12-03 07:20:28,715 [Thread-110] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1046523510-172.17.0.9-1606980023524 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:20:28,716 [Thread-111] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1046523510-172.17.0.9-1606980023524 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:20:28,716 [Thread-111] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1046523510-172.17.0.9-1606980023524/current/replicas doesn't exist 
2020-12-03 07:20:28,718 [Thread-105] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1046523510-172.17.0.9-1606980023524 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 56ms
2020-12-03 07:20:28,716 [Thread-110] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1046523510-172.17.0.9-1606980023524/current/replicas doesn't exist 
2020-12-03 07:20:28,721 [Thread-111] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1046523510-172.17.0.9-1606980023524 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 5ms
2020-12-03 07:20:28,721 [Thread-110] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1046523510-172.17.0.9-1606980023524 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 5ms
2020-12-03 07:20:28,722 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1046523510-172.17.0.9-1606980023524: 8ms
2020-12-03 07:20:28,722 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1046523510-172.17.0.9-1606980023524: 61ms
2020-12-03 07:20:28,723 [Thread-112] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1046523510-172.17.0.9-1606980023524 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:20:28,723 [Thread-112] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1046523510-172.17.0.9-1606980023524/current/replicas doesn't exist 
2020-12-03 07:20:28,723 [Thread-113] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1046523510-172.17.0.9-1606980023524 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:20:28,723 [Thread-113] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1046523510-172.17.0.9-1606980023524/current/replicas doesn't exist 
2020-12-03 07:20:28,724 [Thread-112] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1046523510-172.17.0.9-1606980023524 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 1ms
2020-12-03 07:20:28,724 [Thread-113] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1046523510-172.17.0.9-1606980023524 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 1ms
2020-12-03 07:20:28,724 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1046523510-172.17.0.9-1606980023524: 2ms
2020-12-03 07:20:28,725 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1046523510-172.17.0.9-1606980023524 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:20:28,728 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-f3ac1c58-0b14-4986-934c-b8aef5e53f67): finished scanning block pool BP-1046523510-172.17.0.9-1606980023524
2020-12-03 07:20:28,726 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1046523510-172.17.0.9-1606980023524 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:20:28,729 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1046523510-172.17.0.9-1606980023524 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:20:28,729 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-45995af8-9d1f-4a12-b9f4-0314f4595926): finished scanning block pool BP-1046523510-172.17.0.9-1606980023524
2020-12-03 07:20:28,729 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1046523510-172.17.0.9-1606980023524 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:20:28,732 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-bcf09409-8126-477f-9cbc-2496fedf29f8): finished scanning block pool BP-1046523510-172.17.0.9-1606980023524
2020-12-03 07:20:28,732 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-09eb49bc-318f-44d9-9f6f-340bc899821c): finished scanning block pool BP-1046523510-172.17.0.9-1606980023524
2020-12-03 07:20:28,756 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-f3ac1c58-0b14-4986-934c-b8aef5e53f67): no suitable block pools found to scan.  Waiting 1814399969 ms.
2020-12-03 07:20:28,757 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-09eb49bc-318f-44d9-9f6f-340bc899821c): no suitable block pools found to scan.  Waiting 1814399968 ms.
2020-12-03 07:20:28,757 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-bcf09409-8126-477f-9cbc-2496fedf29f8): no suitable block pools found to scan.  Waiting 1814399968 ms.
2020-12-03 07:20:28,758 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-45995af8-9d1f-4a12-b9f4-0314f4595926): no suitable block pools found to scan.  Waiting 1814399966 ms.
2020-12-03 07:20:28,759 [Thread-59] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 8:15 AM with interval of 21600000ms
2020-12-03 07:20:28,760 [Thread-83] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 9:00 AM with interval of 21600000ms
2020-12-03 07:20:28,769 [BP-1046523510-172.17.0.9-1606980023524 heartbeating to localhost/127.0.0.1:35705] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1046523510-172.17.0.9-1606980023524 (Datanode Uuid 14d310ca-8fcf-4840-b079-e46f8cc4dc46) service to localhost/127.0.0.1:35705 beginning handshake with NN
2020-12-03 07:20:28,770 [BP-1046523510-172.17.0.9-1606980023524 heartbeating to localhost/127.0.0.1:35705] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1046523510-172.17.0.9-1606980023524 (Datanode Uuid 26ac7c37-c688-4862-acec-193b89c3e758) service to localhost/127.0.0.1:35705 beginning handshake with NN
2020-12-03 07:20:28,783 [IPC Server handler 9 on default port 35705] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:33302, datanodeUuid=14d310ca-8fcf-4840-b079-e46f8cc4dc46, infoPort=33738, infoSecurePort=0, ipcPort=37047, storageInfo=lv=-57;cid=testClusterID;nsid=496224982;c=1606980023524) storage 14d310ca-8fcf-4840-b079-e46f8cc4dc46
2020-12-03 07:20:28,786 [IPC Server handler 9 on default port 35705] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:33302
2020-12-03 07:20:28,787 [IPC Server handler 9 on default port 35705] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 14d310ca-8fcf-4840-b079-e46f8cc4dc46 (127.0.0.1:33302).
2020-12-03 07:20:28,790 [IPC Server handler 8 on default port 35705] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:37829, datanodeUuid=26ac7c37-c688-4862-acec-193b89c3e758, infoPort=35085, infoSecurePort=0, ipcPort=36565, storageInfo=lv=-57;cid=testClusterID;nsid=496224982;c=1606980023524) storage 26ac7c37-c688-4862-acec-193b89c3e758
2020-12-03 07:20:28,790 [IPC Server handler 8 on default port 35705] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:37829
2020-12-03 07:20:28,790 [IPC Server handler 8 on default port 35705] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 26ac7c37-c688-4862-acec-193b89c3e758 (127.0.0.1:37829).
2020-12-03 07:20:28,794 [BP-1046523510-172.17.0.9-1606980023524 heartbeating to localhost/127.0.0.1:35705] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1046523510-172.17.0.9-1606980023524 (Datanode Uuid 14d310ca-8fcf-4840-b079-e46f8cc4dc46) service to localhost/127.0.0.1:35705 successfully registered with NN
2020-12-03 07:20:28,794 [BP-1046523510-172.17.0.9-1606980023524 heartbeating to localhost/127.0.0.1:35705] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1046523510-172.17.0.9-1606980023524 (Datanode Uuid 26ac7c37-c688-4862-acec-193b89c3e758) service to localhost/127.0.0.1:35705 successfully registered with NN
2020-12-03 07:20:28,795 [BP-1046523510-172.17.0.9-1606980023524 heartbeating to localhost/127.0.0.1:35705] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:35705 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:28,795 [BP-1046523510-172.17.0.9-1606980023524 heartbeating to localhost/127.0.0.1:35705] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:35705 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:28,798 [IPC Server handler 2 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:28,806 [Listener at localhost/37047] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2798)) - No heartbeat from DataNode: 127.0.0.1:33302
2020-12-03 07:20:28,806 [Listener at localhost/37047] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:28,827 [IPC Server handler 3 on default port 35705] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-f3ac1c58-0b14-4986-934c-b8aef5e53f67 for DN 127.0.0.1:37829
2020-12-03 07:20:28,829 [IPC Server handler 3 on default port 35705] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-45995af8-9d1f-4a12-b9f4-0314f4595926 for DN 127.0.0.1:37829
2020-12-03 07:20:28,830 [IPC Server handler 0 on default port 35705] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-bcf09409-8126-477f-9cbc-2496fedf29f8 for DN 127.0.0.1:33302
2020-12-03 07:20:28,834 [IPC Server handler 0 on default port 35705] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-09eb49bc-318f-44d9-9f6f-340bc899821c for DN 127.0.0.1:33302
2020-12-03 07:20:28,881 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xe3b59d637050294d: Processing first storage report for DS-f3ac1c58-0b14-4986-934c-b8aef5e53f67 from datanode 26ac7c37-c688-4862-acec-193b89c3e758
2020-12-03 07:20:28,885 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xe3b59d637050294d: from storage DS-f3ac1c58-0b14-4986-934c-b8aef5e53f67 node DatanodeRegistration(127.0.0.1:37829, datanodeUuid=26ac7c37-c688-4862-acec-193b89c3e758, infoPort=35085, infoSecurePort=0, ipcPort=36565, storageInfo=lv=-57;cid=testClusterID;nsid=496224982;c=1606980023524), blocks: 0, hasStaleStorage: true, processing time: 3 msecs, invalidatedBlocks: 0
2020-12-03 07:20:28,885 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xa5d500f7fbf8f80f: Processing first storage report for DS-bcf09409-8126-477f-9cbc-2496fedf29f8 from datanode 14d310ca-8fcf-4840-b079-e46f8cc4dc46
2020-12-03 07:20:28,889 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xa5d500f7fbf8f80f: from storage DS-bcf09409-8126-477f-9cbc-2496fedf29f8 node DatanodeRegistration(127.0.0.1:33302, datanodeUuid=14d310ca-8fcf-4840-b079-e46f8cc4dc46, infoPort=33738, infoSecurePort=0, ipcPort=37047, storageInfo=lv=-57;cid=testClusterID;nsid=496224982;c=1606980023524), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:28,889 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xe3b59d637050294d: Processing first storage report for DS-45995af8-9d1f-4a12-b9f4-0314f4595926 from datanode 26ac7c37-c688-4862-acec-193b89c3e758
2020-12-03 07:20:28,890 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xe3b59d637050294d: from storage DS-45995af8-9d1f-4a12-b9f4-0314f4595926 node DatanodeRegistration(127.0.0.1:37829, datanodeUuid=26ac7c37-c688-4862-acec-193b89c3e758, infoPort=35085, infoSecurePort=0, ipcPort=36565, storageInfo=lv=-57;cid=testClusterID;nsid=496224982;c=1606980023524), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:20:28,890 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xa5d500f7fbf8f80f: Processing first storage report for DS-09eb49bc-318f-44d9-9f6f-340bc899821c from datanode 14d310ca-8fcf-4840-b079-e46f8cc4dc46
2020-12-03 07:20:28,890 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xa5d500f7fbf8f80f: from storage DS-09eb49bc-318f-44d9-9f6f-340bc899821c node DatanodeRegistration(127.0.0.1:33302, datanodeUuid=14d310ca-8fcf-4840-b079-e46f8cc4dc46, infoPort=33738, infoSecurePort=0, ipcPort=37047, storageInfo=lv=-57;cid=testClusterID;nsid=496224982;c=1606980023524), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:28,911 [BP-1046523510-172.17.0.9-1606980023524 heartbeating to localhost/127.0.0.1:35705] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xa5d500f7fbf8f80f,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 5 msec to generate and 51 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:28,911 [BP-1046523510-172.17.0.9-1606980023524 heartbeating to localhost/127.0.0.1:35705] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1046523510-172.17.0.9-1606980023524
2020-12-03 07:20:28,912 [IPC Server handler 5 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:28,913 [BP-1046523510-172.17.0.9-1606980023524 heartbeating to localhost/127.0.0.1:35705] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xe3b59d637050294d,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 5 msec to generate and 53 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:28,913 [BP-1046523510-172.17.0.9-1606980023524 heartbeating to localhost/127.0.0.1:35705] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1046523510-172.17.0.9-1606980023524
2020-12-03 07:20:28,916 [Listener at localhost/37047] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:20:28,923 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSClient.java:<init>(318)) - Sets dfs.client.block.write.replace-datanode-on-failure.min-replication to 0
2020-12-03 07:20:28,950 [IPC Server handler 6 on default port 35705] INFO  ipc.Server (Server.java:logException(2969)) - IPC Server handler 6 on default port 35705, call Call#17 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.getBlockLocations from 127.0.0.1:38756: java.io.FileNotFoundException: File does not exist: /test/TestNonExistingFile
2020-12-03 07:20:28,958 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSClient.java:primitiveMkdir(2423)) - /test/TestExistingDir: masked={ masked: rwxr-xr-x, unmasked: rwxrwxrwx }
2020-12-03 07:20:28,969 [IPC Server handler 7 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test/TestExistingDir	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:20:28,994 [IPC Server handler 9 on default port 35705] INFO  ipc.Server (Server.java:logException(2969)) - IPC Server handler 9 on default port 35705, call Call#19 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.getBlockLocations from 127.0.0.1:38756: java.io.FileNotFoundException: Path is not a file: /test/TestExistingDir
webhdfsuri=webhdfs://localhost:34813
data.length=152
2020-12-03 07:20:29,025 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSClient.java:create(1216)) - /filechecksum/foo0: masked={ masked: rw-r--r--, unmasked: rw-rw-rw- }
2020-12-03 07:20:29,058 [IPC Server handler 8 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/filechecksum/foo0	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:20:29,074 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/filechecksum/foo0, chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:20:29,080 [LeaseRenewer:root@localhost:35705] DEBUG impl.LeaseRenewer (LeaseRenewer.java:run(304)) - Lease renewer daemon for [DFSClient_NONMAPREDUCE_1560091101_1] with renew id 1 started
2020-12-03 07:20:29,083 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=0, src=/filechecksum/foo0, packetSize=65016, chunksPerPacket=126, bytesCurBlock=0, DFSOutputStream:block==null
2020-12-03 07:20:29,102 [IPC Server handler 2 on default port 35705] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:33302, 127.0.0.1:37829 for /filechecksum/foo0
2020-12-03 07:20:29,125 [Thread-120] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:29,195 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:40160 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1046523510-172.17.0.9-1606980023524:blk_1073741825_1001 src: /127.0.0.1:40160 dest: /127.0.0.1:33302
2020-12-03 07:20:29,224 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:40160 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741825_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:29,227 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:59896 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1046523510-172.17.0.9-1606980023524:blk_1073741825_1001 src: /127.0.0.1:59896 dest: /127.0.0.1:37829
2020-12-03 07:20:29,280 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59896, dest: /127.0.0.1:37829, bytes: 152, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1560091101_1, offset: 0, srvID: 26ac7c37-c688-4862-acec-193b89c3e758, blockid: BP-1046523510-172.17.0.9-1606980023524:blk_1073741825_1001, duration(ns): 21457816
2020-12-03 07:20:29,281 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:20:29,286 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37829]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40160, dest: /127.0.0.1:33302, bytes: 152, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1560091101_1, offset: 0, srvID: 14d310ca-8fcf-4840-b079-e46f8cc4dc46, blockid: BP-1046523510-172.17.0.9-1606980023524:blk_1073741825_1001, duration(ns): 30042671
2020-12-03 07:20:29,288 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37829]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37829] terminating
2020-12-03 07:20:29,325 [IPC Server handler 0 on default port 35705] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2995)) - BLOCK* blk_1073741825_1001 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /filechecksum/foo0
2020-12-03 07:20:29,734 [IPC Server handler 5 on default port 35705] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /filechecksum/foo0 is closed by DFSClient_NONMAPREDUCE_1560091101_1
2020-12-03 07:20:29,742 [IPC Server handler 6 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/filechecksum/foo0	dst=null	perm=null	proto=rpc
hdfsfoocs=MD5-of-0MD5-of-512CRC32C:5c74e1e373919e8a12c6a438c96d9974
Dec 03, 2020 7:20:29 AM com.sun.jersey.api.core.PackagesResourceConfig init
INFO: Scanning for root resource and provider classes in the packages:
  org.apache.hadoop.hdfs.server.namenode.web.resources
  org.apache.hadoop.hdfs.web.resources
Dec 03, 2020 7:20:30 AM com.sun.jersey.api.core.ScanningResourceConfig logClasses
INFO: Root resource classes found:
  class org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods
Dec 03, 2020 7:20:30 AM com.sun.jersey.api.core.ScanningResourceConfig logClasses
INFO: Provider classes found:
  class org.apache.hadoop.hdfs.web.resources.UserProvider
  class org.apache.hadoop.hdfs.web.resources.ExceptionHandler
Dec 03, 2020 7:20:30 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
Dec 03, 2020 7:20:31 AM com.sun.jersey.spi.inject.Errors processErrorMessages
WARNING: The following warnings have been detected with resource and/or provider classes:
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.putRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.PutOpParam,org.apache.hadoop.hdfs.web.resources.DestinationParam,org.apache.hadoop.hdfs.web.resources.OwnerParam,org.apache.hadoop.hdfs.web.resources.GroupParam,org.apache.hadoop.hdfs.web.resources.PermissionParam,org.apache.hadoop.hdfs.web.resources.UnmaskedPermissionParam,org.apache.hadoop.hdfs.web.resources.OverwriteParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,org.apache.hadoop.hdfs.web.resources.ReplicationParam,org.apache.hadoop.hdfs.web.resources.BlockSizeParam,org.apache.hadoop.hdfs.web.resources.ModificationTimeParam,org.apache.hadoop.hdfs.web.resources.AccessTimeParam,org.apache.hadoop.hdfs.web.resources.RenameOptionSetParam,org.apache.hadoop.hdfs.web.resources.CreateParentParam,org.apache.hadoop.hdfs.web.resources.TokenArgumentParam,org.apache.hadoop.hdfs.web.resources.AclPermissionParam,org.apache.hadoop.hdfs.web.resources.XAttrNameParam,org.apache.hadoop.hdfs.web.resources.XAttrValueParam,org.apache.hadoop.hdfs.web.resources.XAttrSetFlagParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam,org.apache.hadoop.hdfs.web.resources.OldSnapshotNameParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.CreateFlagParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam,org.apache.hadoop.hdfs.web.resources.StoragePolicyParam,org.apache.hadoop.hdfs.web.resources.ECPolicyParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.postRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.PostOpParam,org.apache.hadoop.hdfs.web.resources.ConcatSourcesParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.NewLengthParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.deleteRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.DeleteOpParam,org.apache.hadoop.hdfs.web.resources.RecursiveParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.getRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.GetOpParam,org.apache.hadoop.hdfs.web.resources.OffsetParam,org.apache.hadoop.hdfs.web.resources.LengthParam,org.apache.hadoop.hdfs.web.resources.RenewerParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,java.util.List,org.apache.hadoop.hdfs.web.resources.XAttrEncodingParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.FsActionParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam,org.apache.hadoop.hdfs.web.resources.OldSnapshotNameParam,org.apache.hadoop.hdfs.web.resources.TokenKindParam,org.apache.hadoop.hdfs.web.resources.TokenServiceParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam,org.apache.hadoop.hdfs.web.resources.StartAfterParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
2020-12-03 07:20:31,833 [IPC Server handler 8 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/filechecksum/foo0	dst=null	perm=null	proto=webhdfs
2020-12-03 07:20:31,835 [IPC Server handler 8 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/filechecksum/foo0	dst=null	perm=null	proto=webhdfs
2020-12-03 07:20:31,972 [nioEventLoopGroup-3-1] DEBUG hdfs.DFSClient (DFSClient.java:<init>(318)) - Sets dfs.client.block.write.replace-datanode-on-failure.min-replication to 0
2020-12-03 07:20:31,979 [IPC Server handler 2 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/filechecksum/foo0	dst=null	perm=null	proto=rpc
2020-12-03 07:20:32,015 [nioEventLoopGroup-3-1] INFO  datanode.webhdfs (WebHdfsHandler.java:run(147)) - 127.0.0.1 GET /webhdfs/v1/filechecksum/foo0?op=GETFILECHECKSUM&user.name=rootx&namenoderpcaddress=localhost:35705 200
webhdfsfoocs=MD5-of-0MD5-of-512CRC32C:5c74e1e373919e8a12c6a438c96d9974
2020-12-03 07:20:32,074 [IPC Server handler 4 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/filechecksum/foo0	dst=null	perm=null	proto=webhdfs
2020-12-03 07:20:32,075 [IPC Server handler 4 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/filechecksum/foo0	dst=null	perm=null	proto=webhdfs
2020-12-03 07:20:32,091 [nioEventLoopGroup-5-1] DEBUG hdfs.DFSClient (DFSClient.java:<init>(318)) - Sets dfs.client.block.write.replace-datanode-on-failure.min-replication to 0
2020-12-03 07:20:32,104 [IPC Server handler 1 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/filechecksum/foo0	dst=null	perm=null	proto=rpc
webhdfs_qfoocs=MD5-of-0MD5-of-512CRC32C:5c74e1e373919e8a12c6a438c96d9974
2020-12-03 07:20:32,129 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSClient.java:create(1216)) - /filechecksum/zeroByteFile0: masked={ masked: rw-r--r--, unmasked: rw-rw-rw- }
2020-12-03 07:20:32,127 [nioEventLoopGroup-5-1] INFO  datanode.webhdfs (WebHdfsHandler.java:run(147)) - 127.0.0.1 GET /webhdfs/v1/filechecksum/foo0?op=GETFILECHECKSUM&user.name=rootx&namenoderpcaddress=localhost:35705 200
2020-12-03 07:20:32,134 [IPC Server handler 5 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/filechecksum/zeroByteFile0	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:20:32,136 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/filechecksum/zeroByteFile0, chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:20:32,142 [IPC Server handler 6 on default port 35705] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /filechecksum/zeroByteFile0 is closed by DFSClient_NONMAPREDUCE_1560091101_1
2020-12-03 07:20:32,144 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSClient.java:create(1216)) - /filechecksum/bar0: masked={ masked: rw-r--r--, unmasked: rw-rw-rw- }
2020-12-03 07:20:32,147 [IPC Server handler 9 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/filechecksum/bar0	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:20:32,149 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/filechecksum/bar0, chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:20:32,150 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=0, src=/filechecksum/bar0, packetSize=65016, chunksPerPacket=126, bytesCurBlock=0, DFSOutputStream:block==null
2020-12-03 07:20:32,158 [IPC Server handler 7 on default port 35705] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741826_1002, replicas=127.0.0.1:33302, 127.0.0.1:37829 for /filechecksum/bar0
2020-12-03 07:20:32,169 [Thread-133] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:32,170 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:40180 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1046523510-172.17.0.9-1606980023524:blk_1073741826_1002 src: /127.0.0.1:40180 dest: /127.0.0.1:33302
2020-12-03 07:20:32,172 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:40180 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741826_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:32,176 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:59916 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1046523510-172.17.0.9-1606980023524:blk_1073741826_1002 src: /127.0.0.1:59916 dest: /127.0.0.1:37829
2020-12-03 07:20:32,216 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59916, dest: /127.0.0.1:37829, bytes: 152, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1560091101_1, offset: 0, srvID: 26ac7c37-c688-4862-acec-193b89c3e758, blockid: BP-1046523510-172.17.0.9-1606980023524:blk_1073741826_1002, duration(ns): 36653643
2020-12-03 07:20:32,217 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2020-12-03 07:20:32,220 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37829]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40180, dest: /127.0.0.1:33302, bytes: 152, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1560091101_1, offset: 0, srvID: 14d310ca-8fcf-4840-b079-e46f8cc4dc46, blockid: BP-1046523510-172.17.0.9-1606980023524:blk_1073741826_1002, duration(ns): 40143915
2020-12-03 07:20:32,221 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37829]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37829] terminating
2020-12-03 07:20:32,228 [IPC Server handler 3 on default port 35705] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /filechecksum/bar0 is closed by DFSClient_NONMAPREDUCE_1560091101_1
2020-12-03 07:20:32,231 [IPC Server handler 4 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/filechecksum/zeroByteFile0	dst=null	perm=null	proto=rpc
2020-12-03 07:20:32,235 [IPC Server handler 1 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/filechecksum/bar0	dst=null	perm=null	proto=rpc
2020-12-03 07:20:32,252 [IPC Server handler 0 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/filechecksum	dst=null	perm=root:supergroup:---------	proto=rpc
2020-12-03 07:20:32,263 [IPC Server handler 5 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=false	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/filechecksum/foo0	dst=null	perm=null	proto=webhdfs
2020-12-03 07:20:32,272 [Listener at localhost/37047] INFO  fs.FileSystem (TestDistributedFileSystem.java:testFileChecksum(1183)) - GOOD: getting an exception
org.apache.hadoop.security.AccessControlException: Permission denied: user=rootx, access=EXECUTE, inode="/filechecksum":root:supergroup:d---------
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:121)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:110)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem.toIOException(WebHdfsFileSystem.java:546)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem.access$800(WebHdfsFileSystem.java:135)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.shouldRetry(WebHdfsFileSystem.java:851)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.runWithRetry(WebHdfsFileSystem.java:817)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.access$100(WebHdfsFileSystem.java:616)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner$1.run(WebHdfsFileSystem.java:654)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.run(WebHdfsFileSystem.java:650)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem.getFileChecksum(WebHdfsFileSystem.java:1874)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem.getFileChecksum(WebHdfsFileSystem.java:135)
	at org.apache.hadoop.hdfs.TestDistributedFileSystem.testFileChecksum(TestDistributedFileSystem.java:1180)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.AccessControlException): Permission denied: user=rootx, access=EXECUTE, inode="/filechecksum":root:supergroup:d---------
	at org.apache.hadoop.hdfs.web.JsonUtilClient.toRemoteException(JsonUtilClient.java:89)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem.validateResponse(WebHdfsFileSystem.java:507)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem.access$200(WebHdfsFileSystem.java:135)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.connect(WebHdfsFileSystem.java:697)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.runWithRetry(WebHdfsFileSystem.java:788)
	... 34 more
2020-12-03 07:20:32,276 [IPC Server handler 6 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/filechecksum	dst=null	perm=root:supergroup:rwxrwxrwx	proto=rpc
data.length=1390
2020-12-03 07:20:32,278 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSClient.java:create(1216)) - /filechecksum/foo1: masked={ masked: rw-r--r--, unmasked: rw-rw-rw- }
2020-12-03 07:20:32,282 [IPC Server handler 9 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/filechecksum/foo1	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:20:32,283 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/filechecksum/foo1, chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:20:32,285 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=0, src=/filechecksum/foo1, packetSize=65016, chunksPerPacket=126, bytesCurBlock=0, DFSOutputStream:block==null
2020-12-03 07:20:32,285 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/filechecksum/foo1, chunkSize=516, chunksPerPacket=1, packetSize=516
2020-12-03 07:20:32,286 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=2, src=/filechecksum/foo1, packetSize=516, chunksPerPacket=1, bytesCurBlock=0, DFSOutputStream:block==null
2020-12-03 07:20:32,286 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/filechecksum/foo1, chunkSize=516, chunksPerPacket=1, packetSize=516
2020-12-03 07:20:32,289 [IPC Server handler 7 on default port 35705] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741827_1003, replicas=127.0.0.1:33302, 127.0.0.1:37829 for /filechecksum/foo1
2020-12-03 07:20:32,292 [Thread-140] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:32,309 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:40186 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1046523510-172.17.0.9-1606980023524:blk_1073741827_1003 src: /127.0.0.1:40186 dest: /127.0.0.1:33302
2020-12-03 07:20:32,311 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:40186 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741827_1003]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:32,312 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:59922 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1046523510-172.17.0.9-1606980023524:blk_1073741827_1003 src: /127.0.0.1:59922 dest: /127.0.0.1:37829
2020-12-03 07:20:32,337 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59922, dest: /127.0.0.1:37829, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1560091101_1, offset: 0, srvID: 26ac7c37-c688-4862-acec-193b89c3e758, blockid: BP-1046523510-172.17.0.9-1606980023524:blk_1073741827_1003, duration(ns): 22080938
2020-12-03 07:20:32,338 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741827_1003, type=LAST_IN_PIPELINE terminating
2020-12-03 07:20:32,343 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37829]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40186, dest: /127.0.0.1:33302, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1560091101_1, offset: 0, srvID: 14d310ca-8fcf-4840-b079-e46f8cc4dc46, blockid: BP-1046523510-172.17.0.9-1606980023524:blk_1073741827_1003, duration(ns): 27222618
2020-12-03 07:20:32,344 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37829]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37829] terminating
2020-12-03 07:20:32,346 [IPC Server handler 3 on default port 35705] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741828_1004, replicas=127.0.0.1:37829, 127.0.0.1:33302 for /filechecksum/foo1
2020-12-03 07:20:32,349 [DataStreamer for file /filechecksum/foo1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:32,356 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:59924 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741828_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1046523510-172.17.0.9-1606980023524:blk_1073741828_1004 src: /127.0.0.1:59924 dest: /127.0.0.1:37829
2020-12-03 07:20:32,358 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:59924 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741828_1004]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:32,360 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:40192 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741828_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1046523510-172.17.0.9-1606980023524:blk_1073741828_1004 src: /127.0.0.1:40192 dest: /127.0.0.1:33302
2020-12-03 07:20:32,369 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741828_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40192, dest: /127.0.0.1:33302, bytes: 366, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1560091101_1, offset: 0, srvID: 14d310ca-8fcf-4840-b079-e46f8cc4dc46, blockid: BP-1046523510-172.17.0.9-1606980023524:blk_1073741828_1004, duration(ns): 6789935
2020-12-03 07:20:32,369 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741828_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741828_1004, type=LAST_IN_PIPELINE terminating
2020-12-03 07:20:32,373 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:33302]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59924, dest: /127.0.0.1:37829, bytes: 366, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1560091101_1, offset: 0, srvID: 26ac7c37-c688-4862-acec-193b89c3e758, blockid: BP-1046523510-172.17.0.9-1606980023524:blk_1073741828_1004, duration(ns): 9460403
2020-12-03 07:20:32,373 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:33302]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:33302] terminating
2020-12-03 07:20:32,381 [IPC Server handler 1 on default port 35705] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /filechecksum/foo1 is closed by DFSClient_NONMAPREDUCE_1560091101_1
2020-12-03 07:20:32,388 [IPC Server handler 5 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/filechecksum/foo1	dst=null	perm=null	proto=rpc
hdfsfoocs=MD5-of-2MD5-of-512CRC32C:37c959ca77486bb22e712e2d46ce3e18
2020-12-03 07:20:32,410 [IPC Server handler 6 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/filechecksum/foo1	dst=null	perm=null	proto=webhdfs
2020-12-03 07:20:32,417 [IPC Server handler 6 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/filechecksum/foo1	dst=null	perm=null	proto=webhdfs
2020-12-03 07:20:32,425 [nioEventLoopGroup-3-2] DEBUG hdfs.DFSClient (DFSClient.java:<init>(318)) - Sets dfs.client.block.write.replace-datanode-on-failure.min-replication to 0
2020-12-03 07:20:32,433 [IPC Server handler 9 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/filechecksum/foo1	dst=null	perm=null	proto=rpc
2020-12-03 07:20:32,450 [nioEventLoopGroup-3-2] INFO  datanode.webhdfs (WebHdfsHandler.java:run(147)) - 127.0.0.1 GET /webhdfs/v1/filechecksum/foo1?op=GETFILECHECKSUM&user.name=rootx&namenoderpcaddress=localhost:35705 200
webhdfsfoocs=MD5-of-2MD5-of-512CRC32C:37c959ca77486bb22e712e2d46ce3e18
2020-12-03 07:20:32,457 [IPC Server handler 8 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/filechecksum/foo1	dst=null	perm=null	proto=webhdfs
2020-12-03 07:20:32,458 [IPC Server handler 8 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/filechecksum/foo1	dst=null	perm=null	proto=webhdfs
2020-12-03 07:20:32,467 [nioEventLoopGroup-5-2] DEBUG hdfs.DFSClient (DFSClient.java:<init>(318)) - Sets dfs.client.block.write.replace-datanode-on-failure.min-replication to 0
2020-12-03 07:20:32,471 [IPC Server handler 2 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/filechecksum/foo1	dst=null	perm=null	proto=rpc
webhdfs_qfoocs=MD5-of-2MD5-of-512CRC32C:37c959ca77486bb22e712e2d46ce3e18
2020-12-03 07:20:32,505 [nioEventLoopGroup-5-2] INFO  datanode.webhdfs (WebHdfsHandler.java:run(147)) - 127.0.0.1 GET /webhdfs/v1/filechecksum/foo1?op=GETFILECHECKSUM&user.name=rootx&namenoderpcaddress=localhost:35705 200
2020-12-03 07:20:32,505 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSClient.java:create(1216)) - /filechecksum/zeroByteFile1: masked={ masked: rw-r--r--, unmasked: rw-rw-rw- }
2020-12-03 07:20:32,508 [IPC Server handler 4 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/filechecksum/zeroByteFile1	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:20:32,509 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/filechecksum/zeroByteFile1, chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:20:32,513 [IPC Server handler 1 on default port 35705] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /filechecksum/zeroByteFile1 is closed by DFSClient_NONMAPREDUCE_1560091101_1
2020-12-03 07:20:32,515 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSClient.java:create(1216)) - /filechecksum/bar1: masked={ masked: rw-r--r--, unmasked: rw-rw-rw- }
2020-12-03 07:20:32,517 [IPC Server handler 0 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/filechecksum/bar1	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:20:32,518 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/filechecksum/bar1, chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:20:32,519 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=0, src=/filechecksum/bar1, packetSize=65016, chunksPerPacket=126, bytesCurBlock=0, DFSOutputStream:block==null
2020-12-03 07:20:32,519 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/filechecksum/bar1, chunkSize=516, chunksPerPacket=1, packetSize=516
2020-12-03 07:20:32,520 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=2, src=/filechecksum/bar1, packetSize=516, chunksPerPacket=1, bytesCurBlock=0, DFSOutputStream:block==null
2020-12-03 07:20:32,520 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/filechecksum/bar1, chunkSize=516, chunksPerPacket=1, packetSize=516
2020-12-03 07:20:32,522 [IPC Server handler 5 on default port 35705] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741829_1005, replicas=127.0.0.1:37829, 127.0.0.1:33302 for /filechecksum/bar1
2020-12-03 07:20:32,525 [Thread-158] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:32,529 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:59944 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741829_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1046523510-172.17.0.9-1606980023524:blk_1073741829_1005 src: /127.0.0.1:59944 dest: /127.0.0.1:37829
2020-12-03 07:20:32,531 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:59944 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741829_1005]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:32,532 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:40212 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741829_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1046523510-172.17.0.9-1606980023524:blk_1073741829_1005 src: /127.0.0.1:40212 dest: /127.0.0.1:33302
2020-12-03 07:20:32,542 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741829_1005, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40212, dest: /127.0.0.1:33302, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1560091101_1, offset: 0, srvID: 14d310ca-8fcf-4840-b079-e46f8cc4dc46, blockid: BP-1046523510-172.17.0.9-1606980023524:blk_1073741829_1005, duration(ns): 7007136
2020-12-03 07:20:32,543 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741829_1005, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741829_1005, type=LAST_IN_PIPELINE terminating
2020-12-03 07:20:32,548 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:33302]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59944, dest: /127.0.0.1:37829, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1560091101_1, offset: 0, srvID: 26ac7c37-c688-4862-acec-193b89c3e758, blockid: BP-1046523510-172.17.0.9-1606980023524:blk_1073741829_1005, duration(ns): 13425228
2020-12-03 07:20:32,549 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:33302]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:33302] terminating
2020-12-03 07:20:32,552 [IPC Server handler 7 on default port 35705] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741830_1006, replicas=127.0.0.1:33302, 127.0.0.1:37829 for /filechecksum/bar1
2020-12-03 07:20:32,554 [DataStreamer for file /filechecksum/bar1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:32,561 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:40214 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741830_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1046523510-172.17.0.9-1606980023524:blk_1073741830_1006 src: /127.0.0.1:40214 dest: /127.0.0.1:33302
2020-12-03 07:20:32,562 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:40214 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741830_1006]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:32,564 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:59950 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741830_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1046523510-172.17.0.9-1606980023524:blk_1073741830_1006 src: /127.0.0.1:59950 dest: /127.0.0.1:37829
2020-12-03 07:20:32,586 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741830_1006, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59950, dest: /127.0.0.1:37829, bytes: 366, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1560091101_1, offset: 0, srvID: 26ac7c37-c688-4862-acec-193b89c3e758, blockid: BP-1046523510-172.17.0.9-1606980023524:blk_1073741830_1006, duration(ns): 20145710
2020-12-03 07:20:32,587 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741830_1006, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741830_1006, type=LAST_IN_PIPELINE terminating
2020-12-03 07:20:32,591 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37829]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40214, dest: /127.0.0.1:33302, bytes: 366, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1560091101_1, offset: 0, srvID: 14d310ca-8fcf-4840-b079-e46f8cc4dc46, blockid: BP-1046523510-172.17.0.9-1606980023524:blk_1073741830_1006, duration(ns): 24522258
2020-12-03 07:20:32,591 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37829]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37829] terminating
2020-12-03 07:20:32,598 [IPC Server handler 3 on default port 35705] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /filechecksum/bar1 is closed by DFSClient_NONMAPREDUCE_1560091101_1
2020-12-03 07:20:32,602 [IPC Server handler 4 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/filechecksum/zeroByteFile1	dst=null	perm=null	proto=rpc
2020-12-03 07:20:32,604 [IPC Server handler 1 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/filechecksum/bar1	dst=null	perm=null	proto=rpc
2020-12-03 07:20:32,621 [IPC Server handler 0 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/filechecksum	dst=null	perm=root:supergroup:---------	proto=rpc
2020-12-03 07:20:32,626 [IPC Server handler 5 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=false	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/filechecksum/foo1	dst=null	perm=null	proto=webhdfs
2020-12-03 07:20:32,628 [Listener at localhost/37047] INFO  fs.FileSystem (TestDistributedFileSystem.java:testFileChecksum(1183)) - GOOD: getting an exception
org.apache.hadoop.security.AccessControlException: Permission denied: user=rootx, access=EXECUTE, inode="/filechecksum":root:supergroup:d---------
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:121)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:110)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem.toIOException(WebHdfsFileSystem.java:546)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem.access$800(WebHdfsFileSystem.java:135)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.shouldRetry(WebHdfsFileSystem.java:851)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.runWithRetry(WebHdfsFileSystem.java:817)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.access$100(WebHdfsFileSystem.java:616)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner$1.run(WebHdfsFileSystem.java:654)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.run(WebHdfsFileSystem.java:650)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem.getFileChecksum(WebHdfsFileSystem.java:1874)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem.getFileChecksum(WebHdfsFileSystem.java:135)
	at org.apache.hadoop.hdfs.TestDistributedFileSystem.testFileChecksum(TestDistributedFileSystem.java:1180)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.AccessControlException): Permission denied: user=rootx, access=EXECUTE, inode="/filechecksum":root:supergroup:d---------
	at org.apache.hadoop.hdfs.web.JsonUtilClient.toRemoteException(JsonUtilClient.java:89)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem.validateResponse(WebHdfsFileSystem.java:507)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem.access$200(WebHdfsFileSystem.java:135)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.connect(WebHdfsFileSystem.java:697)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.runWithRetry(WebHdfsFileSystem.java:788)
	... 34 more
2020-12-03 07:20:32,631 [IPC Server handler 6 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/filechecksum	dst=null	perm=root:supergroup:rwxrwxrwx	proto=rpc
data.length=2374
2020-12-03 07:20:32,633 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSClient.java:create(1216)) - /filechecksum/foo2: masked={ masked: rw-r--r--, unmasked: rw-rw-rw- }
2020-12-03 07:20:32,635 [IPC Server handler 9 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/filechecksum/foo2	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:20:32,635 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/filechecksum/foo2, chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:20:32,636 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=0, src=/filechecksum/foo2, packetSize=65016, chunksPerPacket=126, bytesCurBlock=0, DFSOutputStream:block==null
2020-12-03 07:20:32,636 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/filechecksum/foo2, chunkSize=516, chunksPerPacket=1, packetSize=516
2020-12-03 07:20:32,637 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=2, src=/filechecksum/foo2, packetSize=516, chunksPerPacket=1, bytesCurBlock=0, DFSOutputStream:block==null
2020-12-03 07:20:32,638 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/filechecksum/foo2, chunkSize=516, chunksPerPacket=1, packetSize=516
2020-12-03 07:20:32,638 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=3, src=/filechecksum/foo2, packetSize=516, chunksPerPacket=1, bytesCurBlock=512, DFSOutputStream:block==null
2020-12-03 07:20:32,638 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/filechecksum/foo2, chunkSize=516, chunksPerPacket=1, packetSize=516
2020-12-03 07:20:32,638 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=5, src=/filechecksum/foo2, packetSize=516, chunksPerPacket=1, bytesCurBlock=0, DFSOutputStream:block==null
2020-12-03 07:20:32,639 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/filechecksum/foo2, chunkSize=516, chunksPerPacket=1, packetSize=516
2020-12-03 07:20:32,639 [IPC Server handler 7 on default port 35705] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741831_1007, replicas=127.0.0.1:37829, 127.0.0.1:33302 for /filechecksum/foo2
2020-12-03 07:20:32,646 [Thread-171] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:32,655 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:59956 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741831_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1046523510-172.17.0.9-1606980023524:blk_1073741831_1007 src: /127.0.0.1:59956 dest: /127.0.0.1:37829
2020-12-03 07:20:32,656 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:59956 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741831_1007]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:32,659 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:40224 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741831_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1046523510-172.17.0.9-1606980023524:blk_1073741831_1007 src: /127.0.0.1:40224 dest: /127.0.0.1:33302
2020-12-03 07:20:32,679 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741831_1007, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40224, dest: /127.0.0.1:33302, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1560091101_1, offset: 0, srvID: 14d310ca-8fcf-4840-b079-e46f8cc4dc46, blockid: BP-1046523510-172.17.0.9-1606980023524:blk_1073741831_1007, duration(ns): 17067305
2020-12-03 07:20:32,679 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741831_1007, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741831_1007, type=LAST_IN_PIPELINE terminating
2020-12-03 07:20:32,687 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741831_1007, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:33302]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59956, dest: /127.0.0.1:37829, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1560091101_1, offset: 0, srvID: 26ac7c37-c688-4862-acec-193b89c3e758, blockid: BP-1046523510-172.17.0.9-1606980023524:blk_1073741831_1007, duration(ns): 21920455
2020-12-03 07:20:32,687 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741831_1007, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:33302]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741831_1007, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:33302] terminating
2020-12-03 07:20:32,690 [IPC Server handler 3 on default port 35705] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741832_1008, replicas=127.0.0.1:37829, 127.0.0.1:33302 for /filechecksum/foo2
2020-12-03 07:20:32,696 [DataStreamer for file /filechecksum/foo2] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:32,697 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:59960 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741832_1008]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1046523510-172.17.0.9-1606980023524:blk_1073741832_1008 src: /127.0.0.1:59960 dest: /127.0.0.1:37829
2020-12-03 07:20:32,699 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:59960 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741832_1008]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:32,701 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:40228 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741832_1008]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1046523510-172.17.0.9-1606980023524:blk_1073741832_1008 src: /127.0.0.1:40228 dest: /127.0.0.1:33302
2020-12-03 07:20:32,728 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741832_1008, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40228, dest: /127.0.0.1:33302, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1560091101_1, offset: 0, srvID: 14d310ca-8fcf-4840-b079-e46f8cc4dc46, blockid: BP-1046523510-172.17.0.9-1606980023524:blk_1073741832_1008, duration(ns): 24297396
2020-12-03 07:20:32,728 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741832_1008, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741832_1008, type=LAST_IN_PIPELINE terminating
2020-12-03 07:20:32,736 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741832_1008, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:33302]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59960, dest: /127.0.0.1:37829, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1560091101_1, offset: 0, srvID: 26ac7c37-c688-4862-acec-193b89c3e758, blockid: BP-1046523510-172.17.0.9-1606980023524:blk_1073741832_1008, duration(ns): 29687588
2020-12-03 07:20:32,736 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741832_1008, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:33302]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741832_1008, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:33302] terminating
2020-12-03 07:20:32,739 [IPC Server handler 0 on default port 35705] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741833_1009, replicas=127.0.0.1:33302, 127.0.0.1:37829 for /filechecksum/foo2
2020-12-03 07:20:32,745 [DataStreamer for file /filechecksum/foo2] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:32,749 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:40230 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741833_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1046523510-172.17.0.9-1606980023524:blk_1073741833_1009 src: /127.0.0.1:40230 dest: /127.0.0.1:33302
2020-12-03 07:20:32,751 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:40230 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741833_1009]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:32,753 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:59966 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741833_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1046523510-172.17.0.9-1606980023524:blk_1073741833_1009 src: /127.0.0.1:59966 dest: /127.0.0.1:37829
2020-12-03 07:20:32,794 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741833_1009, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59966, dest: /127.0.0.1:37829, bytes: 326, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1560091101_1, offset: 0, srvID: 26ac7c37-c688-4862-acec-193b89c3e758, blockid: BP-1046523510-172.17.0.9-1606980023524:blk_1073741833_1009, duration(ns): 38143940
2020-12-03 07:20:32,795 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741833_1009, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741833_1009, type=LAST_IN_PIPELINE terminating
2020-12-03 07:20:32,796 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741833_1009, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37829]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40230, dest: /127.0.0.1:33302, bytes: 326, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1560091101_1, offset: 0, srvID: 14d310ca-8fcf-4840-b079-e46f8cc4dc46, blockid: BP-1046523510-172.17.0.9-1606980023524:blk_1073741833_1009, duration(ns): 34660006
2020-12-03 07:20:32,797 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741833_1009, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37829]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741833_1009, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37829] terminating
2020-12-03 07:20:32,804 [IPC Server handler 6 on default port 35705] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /filechecksum/foo2 is closed by DFSClient_NONMAPREDUCE_1560091101_1
2020-12-03 07:20:32,807 [IPC Server handler 7 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/filechecksum/foo2	dst=null	perm=null	proto=rpc
hdfsfoocs=MD5-of-2MD5-of-512CRC32C:453907fe743c86e7c4c00de2f9dd529c
2020-12-03 07:20:32,831 [IPC Server handler 8 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/filechecksum/foo2	dst=null	perm=null	proto=webhdfs
2020-12-03 07:20:32,832 [IPC Server handler 8 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/filechecksum/foo2	dst=null	perm=null	proto=webhdfs
2020-12-03 07:20:32,838 [nioEventLoopGroup-5-3] DEBUG hdfs.DFSClient (DFSClient.java:<init>(318)) - Sets dfs.client.block.write.replace-datanode-on-failure.min-replication to 0
2020-12-03 07:20:32,841 [IPC Server handler 2 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/filechecksum/foo2	dst=null	perm=null	proto=rpc
2020-12-03 07:20:32,867 [nioEventLoopGroup-5-3] INFO  datanode.webhdfs (WebHdfsHandler.java:run(147)) - 127.0.0.1 GET /webhdfs/v1/filechecksum/foo2?op=GETFILECHECKSUM&user.name=rootx&namenoderpcaddress=localhost:35705 200
webhdfsfoocs=MD5-of-2MD5-of-512CRC32C:453907fe743c86e7c4c00de2f9dd529c
2020-12-03 07:20:32,882 [IPC Server handler 4 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/filechecksum/foo2	dst=null	perm=null	proto=webhdfs
2020-12-03 07:20:32,883 [IPC Server handler 4 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/filechecksum/foo2	dst=null	perm=null	proto=webhdfs
2020-12-03 07:20:32,889 [nioEventLoopGroup-3-3] DEBUG hdfs.DFSClient (DFSClient.java:<init>(318)) - Sets dfs.client.block.write.replace-datanode-on-failure.min-replication to 0
2020-12-03 07:20:32,892 [IPC Server handler 1 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/filechecksum/foo2	dst=null	perm=null	proto=rpc
2020-12-03 07:20:32,923 [nioEventLoopGroup-3-3] INFO  datanode.webhdfs (WebHdfsHandler.java:run(147)) - 127.0.0.1 GET /webhdfs/v1/filechecksum/foo2?op=GETFILECHECKSUM&user.name=rootx&namenoderpcaddress=localhost:35705 200
webhdfs_qfoocs=MD5-of-2MD5-of-512CRC32C:453907fe743c86e7c4c00de2f9dd529c
2020-12-03 07:20:32,925 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSClient.java:create(1216)) - /filechecksum/zeroByteFile2: masked={ masked: rw-r--r--, unmasked: rw-rw-rw- }
2020-12-03 07:20:32,927 [IPC Server handler 5 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/filechecksum/zeroByteFile2	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:20:32,931 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/filechecksum/zeroByteFile2, chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:20:32,933 [IPC Server handler 9 on default port 35705] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /filechecksum/zeroByteFile2 is closed by DFSClient_NONMAPREDUCE_1560091101_1
2020-12-03 07:20:32,935 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSClient.java:create(1216)) - /filechecksum/bar2: masked={ masked: rw-r--r--, unmasked: rw-rw-rw- }
2020-12-03 07:20:32,937 [IPC Server handler 6 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/filechecksum/bar2	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:20:32,939 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/filechecksum/bar2, chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:20:32,939 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=0, src=/filechecksum/bar2, packetSize=65016, chunksPerPacket=126, bytesCurBlock=0, DFSOutputStream:block==null
2020-12-03 07:20:32,940 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/filechecksum/bar2, chunkSize=516, chunksPerPacket=1, packetSize=516
2020-12-03 07:20:32,940 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=2, src=/filechecksum/bar2, packetSize=516, chunksPerPacket=1, bytesCurBlock=0, DFSOutputStream:block==null
2020-12-03 07:20:32,941 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/filechecksum/bar2, chunkSize=516, chunksPerPacket=1, packetSize=516
2020-12-03 07:20:32,941 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=3, src=/filechecksum/bar2, packetSize=516, chunksPerPacket=1, bytesCurBlock=512, DFSOutputStream:block==null
2020-12-03 07:20:32,941 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/filechecksum/bar2, chunkSize=516, chunksPerPacket=1, packetSize=516
2020-12-03 07:20:32,941 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=5, src=/filechecksum/bar2, packetSize=516, chunksPerPacket=1, bytesCurBlock=0, DFSOutputStream:block==null
2020-12-03 07:20:32,942 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/filechecksum/bar2, chunkSize=516, chunksPerPacket=1, packetSize=516
2020-12-03 07:20:32,942 [IPC Server handler 7 on default port 35705] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741834_1010, replicas=127.0.0.1:33302, 127.0.0.1:37829 for /filechecksum/bar2
2020-12-03 07:20:32,944 [Thread-197] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:32,946 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:40256 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741834_1010]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1046523510-172.17.0.9-1606980023524:blk_1073741834_1010 src: /127.0.0.1:40256 dest: /127.0.0.1:33302
2020-12-03 07:20:32,947 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:40256 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741834_1010]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:32,948 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:59992 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741834_1010]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1046523510-172.17.0.9-1606980023524:blk_1073741834_1010 src: /127.0.0.1:59992 dest: /127.0.0.1:37829
2020-12-03 07:20:32,976 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741834_1010, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59992, dest: /127.0.0.1:37829, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1560091101_1, offset: 0, srvID: 26ac7c37-c688-4862-acec-193b89c3e758, blockid: BP-1046523510-172.17.0.9-1606980023524:blk_1073741834_1010, duration(ns): 24570741
2020-12-03 07:20:32,976 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741834_1010, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741834_1010, type=LAST_IN_PIPELINE terminating
2020-12-03 07:20:32,984 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741834_1010, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37829]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40256, dest: /127.0.0.1:33302, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1560091101_1, offset: 0, srvID: 14d310ca-8fcf-4840-b079-e46f8cc4dc46, blockid: BP-1046523510-172.17.0.9-1606980023524:blk_1073741834_1010, duration(ns): 22585695
2020-12-03 07:20:32,985 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741834_1010, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37829]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741834_1010, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37829] terminating
2020-12-03 07:20:32,993 [IPC Server handler 3 on default port 35705] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741835_1011, replicas=127.0.0.1:33302, 127.0.0.1:37829 for /filechecksum/bar2
2020-12-03 07:20:33,011 [DataStreamer for file /filechecksum/bar2] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:33,015 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:40260 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741835_1011]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1046523510-172.17.0.9-1606980023524:blk_1073741835_1011 src: /127.0.0.1:40260 dest: /127.0.0.1:33302
2020-12-03 07:20:33,016 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:40260 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741835_1011]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:33,017 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:59996 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741835_1011]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1046523510-172.17.0.9-1606980023524:blk_1073741835_1011 src: /127.0.0.1:59996 dest: /127.0.0.1:37829
2020-12-03 07:20:33,029 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741835_1011, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59996, dest: /127.0.0.1:37829, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1560091101_1, offset: 0, srvID: 26ac7c37-c688-4862-acec-193b89c3e758, blockid: BP-1046523510-172.17.0.9-1606980023524:blk_1073741835_1011, duration(ns): 7121480
2020-12-03 07:20:33,030 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741835_1011, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741835_1011, type=LAST_IN_PIPELINE terminating
2020-12-03 07:20:33,033 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741835_1011, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37829]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40260, dest: /127.0.0.1:33302, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1560091101_1, offset: 0, srvID: 14d310ca-8fcf-4840-b079-e46f8cc4dc46, blockid: BP-1046523510-172.17.0.9-1606980023524:blk_1073741835_1011, duration(ns): 11774291
2020-12-03 07:20:33,034 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741835_1011, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37829]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741835_1011, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37829] terminating
2020-12-03 07:20:33,082 [IPC Server handler 0 on default port 35705] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741836_1012, replicas=127.0.0.1:33302, 127.0.0.1:37829 for /filechecksum/bar2
2020-12-03 07:20:33,092 [DataStreamer for file /filechecksum/bar2] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:33,094 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:40264 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741836_1012]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1046523510-172.17.0.9-1606980023524:blk_1073741836_1012 src: /127.0.0.1:40264 dest: /127.0.0.1:33302
2020-12-03 07:20:33,095 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:40264 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741836_1012]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:33,097 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:60000 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741836_1012]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1046523510-172.17.0.9-1606980023524:blk_1073741836_1012 src: /127.0.0.1:60000 dest: /127.0.0.1:37829
2020-12-03 07:20:33,138 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741836_1012, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60000, dest: /127.0.0.1:37829, bytes: 326, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1560091101_1, offset: 0, srvID: 26ac7c37-c688-4862-acec-193b89c3e758, blockid: BP-1046523510-172.17.0.9-1606980023524:blk_1073741836_1012, duration(ns): 34556555
2020-12-03 07:20:33,138 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741836_1012, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741836_1012, type=LAST_IN_PIPELINE terminating
2020-12-03 07:20:33,146 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741836_1012, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37829]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40264, dest: /127.0.0.1:33302, bytes: 326, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1560091101_1, offset: 0, srvID: 14d310ca-8fcf-4840-b079-e46f8cc4dc46, blockid: BP-1046523510-172.17.0.9-1606980023524:blk_1073741836_1012, duration(ns): 38609536
2020-12-03 07:20:33,147 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741836_1012, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37829]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741836_1012, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37829] terminating
2020-12-03 07:20:33,156 [IPC Server handler 6 on default port 35705] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /filechecksum/bar2 is closed by DFSClient_NONMAPREDUCE_1560091101_1
2020-12-03 07:20:33,169 [IPC Server handler 7 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/filechecksum/zeroByteFile2	dst=null	perm=null	proto=rpc
2020-12-03 07:20:33,174 [IPC Server handler 8 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/filechecksum/bar2	dst=null	perm=null	proto=rpc
2020-12-03 07:20:33,198 [IPC Server handler 2 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/filechecksum	dst=null	perm=root:supergroup:---------	proto=rpc
2020-12-03 07:20:33,207 [IPC Server handler 3 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=false	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/filechecksum/foo2	dst=null	perm=null	proto=webhdfs
2020-12-03 07:20:33,212 [Listener at localhost/37047] INFO  fs.FileSystem (TestDistributedFileSystem.java:testFileChecksum(1183)) - GOOD: getting an exception
org.apache.hadoop.security.AccessControlException: Permission denied: user=rootx, access=EXECUTE, inode="/filechecksum":root:supergroup:d---------
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:121)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:110)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem.toIOException(WebHdfsFileSystem.java:546)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem.access$800(WebHdfsFileSystem.java:135)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.shouldRetry(WebHdfsFileSystem.java:851)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.runWithRetry(WebHdfsFileSystem.java:817)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.access$100(WebHdfsFileSystem.java:616)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner$1.run(WebHdfsFileSystem.java:654)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.run(WebHdfsFileSystem.java:650)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem.getFileChecksum(WebHdfsFileSystem.java:1874)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem.getFileChecksum(WebHdfsFileSystem.java:135)
	at org.apache.hadoop.hdfs.TestDistributedFileSystem.testFileChecksum(TestDistributedFileSystem.java:1180)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.AccessControlException): Permission denied: user=rootx, access=EXECUTE, inode="/filechecksum":root:supergroup:d---------
	at org.apache.hadoop.hdfs.web.JsonUtilClient.toRemoteException(JsonUtilClient.java:89)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem.validateResponse(WebHdfsFileSystem.java:507)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem.access$200(WebHdfsFileSystem.java:135)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.connect(WebHdfsFileSystem.java:697)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.runWithRetry(WebHdfsFileSystem.java:788)
	... 34 more
2020-12-03 07:20:33,216 [IPC Server handler 4 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/filechecksum	dst=null	perm=root:supergroup:rwxrwxrwx	proto=rpc
data.length=3278
2020-12-03 07:20:33,218 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSClient.java:create(1216)) - /filechecksum/foo3: masked={ masked: rw-r--r--, unmasked: rw-rw-rw- }
2020-12-03 07:20:33,222 [IPC Server handler 1 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/filechecksum/foo3	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:20:33,224 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/filechecksum/foo3, chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:20:33,225 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=0, src=/filechecksum/foo3, packetSize=65016, chunksPerPacket=126, bytesCurBlock=0, DFSOutputStream:block==null
2020-12-03 07:20:33,225 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/filechecksum/foo3, chunkSize=516, chunksPerPacket=1, packetSize=516
2020-12-03 07:20:33,225 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=2, src=/filechecksum/foo3, packetSize=516, chunksPerPacket=1, bytesCurBlock=0, DFSOutputStream:block==null
2020-12-03 07:20:33,226 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/filechecksum/foo3, chunkSize=516, chunksPerPacket=1, packetSize=516
2020-12-03 07:20:33,226 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=3, src=/filechecksum/foo3, packetSize=516, chunksPerPacket=1, bytesCurBlock=512, DFSOutputStream:block==null
2020-12-03 07:20:33,226 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/filechecksum/foo3, chunkSize=516, chunksPerPacket=1, packetSize=516
2020-12-03 07:20:33,226 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=5, src=/filechecksum/foo3, packetSize=516, chunksPerPacket=1, bytesCurBlock=0, DFSOutputStream:block==null
2020-12-03 07:20:33,226 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/filechecksum/foo3, chunkSize=516, chunksPerPacket=1, packetSize=516
2020-12-03 07:20:33,227 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=6, src=/filechecksum/foo3, packetSize=516, chunksPerPacket=1, bytesCurBlock=512, DFSOutputStream:block==null
2020-12-03 07:20:33,227 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/filechecksum/foo3, chunkSize=516, chunksPerPacket=1, packetSize=516
2020-12-03 07:20:33,227 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=8, src=/filechecksum/foo3, packetSize=516, chunksPerPacket=1, bytesCurBlock=0, DFSOutputStream:block==null
2020-12-03 07:20:33,227 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/filechecksum/foo3, chunkSize=516, chunksPerPacket=1, packetSize=516
2020-12-03 07:20:33,240 [IPC Server handler 0 on default port 35705] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741837_1013, replicas=127.0.0.1:33302, 127.0.0.1:37829 for /filechecksum/foo3
2020-12-03 07:20:33,243 [Thread-216] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:33,245 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:40274 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741837_1013]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1046523510-172.17.0.9-1606980023524:blk_1073741837_1013 src: /127.0.0.1:40274 dest: /127.0.0.1:33302
2020-12-03 07:20:33,246 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:40274 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741837_1013]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:33,248 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:60010 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741837_1013]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1046523510-172.17.0.9-1606980023524:blk_1073741837_1013 src: /127.0.0.1:60010 dest: /127.0.0.1:37829
2020-12-03 07:20:33,270 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741837_1013, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60010, dest: /127.0.0.1:37829, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1560091101_1, offset: 0, srvID: 26ac7c37-c688-4862-acec-193b89c3e758, blockid: BP-1046523510-172.17.0.9-1606980023524:blk_1073741837_1013, duration(ns): 19603630
2020-12-03 07:20:33,271 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741837_1013, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741837_1013, type=LAST_IN_PIPELINE terminating
2020-12-03 07:20:33,277 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741837_1013, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37829]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40274, dest: /127.0.0.1:33302, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1560091101_1, offset: 0, srvID: 14d310ca-8fcf-4840-b079-e46f8cc4dc46, blockid: BP-1046523510-172.17.0.9-1606980023524:blk_1073741837_1013, duration(ns): 21765912
2020-12-03 07:20:33,278 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741837_1013, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37829]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741837_1013, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37829] terminating
2020-12-03 07:20:33,286 [IPC Server handler 9 on default port 35705] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741838_1014, replicas=127.0.0.1:33302, 127.0.0.1:37829 for /filechecksum/foo3
2020-12-03 07:20:33,289 [DataStreamer for file /filechecksum/foo3] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:33,290 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:40278 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741838_1014]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1046523510-172.17.0.9-1606980023524:blk_1073741838_1014 src: /127.0.0.1:40278 dest: /127.0.0.1:33302
2020-12-03 07:20:33,291 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:40278 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741838_1014]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:33,293 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:60014 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741838_1014]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1046523510-172.17.0.9-1606980023524:blk_1073741838_1014 src: /127.0.0.1:60014 dest: /127.0.0.1:37829
2020-12-03 07:20:33,318 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741838_1014, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60014, dest: /127.0.0.1:37829, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1560091101_1, offset: 0, srvID: 26ac7c37-c688-4862-acec-193b89c3e758, blockid: BP-1046523510-172.17.0.9-1606980023524:blk_1073741838_1014, duration(ns): 23198907
2020-12-03 07:20:33,319 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741838_1014, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741838_1014, type=LAST_IN_PIPELINE terminating
2020-12-03 07:20:33,322 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741838_1014, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37829]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40278, dest: /127.0.0.1:33302, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1560091101_1, offset: 0, srvID: 14d310ca-8fcf-4840-b079-e46f8cc4dc46, blockid: BP-1046523510-172.17.0.9-1606980023524:blk_1073741838_1014, duration(ns): 24915604
2020-12-03 07:20:33,322 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741838_1014, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37829]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741838_1014, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37829] terminating
2020-12-03 07:20:33,326 [IPC Server handler 8 on default port 35705] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741839_1015, replicas=127.0.0.1:37829, 127.0.0.1:33302 for /filechecksum/foo3
2020-12-03 07:20:33,329 [DataStreamer for file /filechecksum/foo3] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:33,333 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:60016 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741839_1015]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1046523510-172.17.0.9-1606980023524:blk_1073741839_1015 src: /127.0.0.1:60016 dest: /127.0.0.1:37829
2020-12-03 07:20:33,335 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:60016 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741839_1015]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:33,336 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:40284 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741839_1015]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1046523510-172.17.0.9-1606980023524:blk_1073741839_1015 src: /127.0.0.1:40284 dest: /127.0.0.1:33302
2020-12-03 07:20:33,376 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741839_1015, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40284, dest: /127.0.0.1:33302, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1560091101_1, offset: 0, srvID: 14d310ca-8fcf-4840-b079-e46f8cc4dc46, blockid: BP-1046523510-172.17.0.9-1606980023524:blk_1073741839_1015, duration(ns): 35417003
2020-12-03 07:20:33,376 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741839_1015, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741839_1015, type=LAST_IN_PIPELINE terminating
2020-12-03 07:20:33,389 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741839_1015, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:33302]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60016, dest: /127.0.0.1:37829, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1560091101_1, offset: 0, srvID: 26ac7c37-c688-4862-acec-193b89c3e758, blockid: BP-1046523510-172.17.0.9-1606980023524:blk_1073741839_1015, duration(ns): 38709213
2020-12-03 07:20:33,390 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741839_1015, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:33302]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741839_1015, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:33302] terminating
2020-12-03 07:20:33,399 [IPC Server handler 1 on default port 35705] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741840_1016, replicas=127.0.0.1:33302, 127.0.0.1:37829 for /filechecksum/foo3
2020-12-03 07:20:33,405 [DataStreamer for file /filechecksum/foo3] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:33,407 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:40286 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741840_1016]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1046523510-172.17.0.9-1606980023524:blk_1073741840_1016 src: /127.0.0.1:40286 dest: /127.0.0.1:33302
2020-12-03 07:20:33,408 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:40286 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741840_1016]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:33,409 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:60022 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741840_1016]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1046523510-172.17.0.9-1606980023524:blk_1073741840_1016 src: /127.0.0.1:60022 dest: /127.0.0.1:37829
2020-12-03 07:20:33,416 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741840_1016, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60022, dest: /127.0.0.1:37829, bytes: 206, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1560091101_1, offset: 0, srvID: 26ac7c37-c688-4862-acec-193b89c3e758, blockid: BP-1046523510-172.17.0.9-1606980023524:blk_1073741840_1016, duration(ns): 4615751
2020-12-03 07:20:33,417 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741840_1016, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741840_1016, type=LAST_IN_PIPELINE terminating
2020-12-03 07:20:33,418 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741840_1016, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37829]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40286, dest: /127.0.0.1:33302, bytes: 206, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1560091101_1, offset: 0, srvID: 14d310ca-8fcf-4840-b079-e46f8cc4dc46, blockid: BP-1046523510-172.17.0.9-1606980023524:blk_1073741840_1016, duration(ns): 4305821
2020-12-03 07:20:33,418 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741840_1016, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37829]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741840_1016, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37829] terminating
2020-12-03 07:20:33,420 [IPC Server handler 5 on default port 35705] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /filechecksum/foo3 is closed by DFSClient_NONMAPREDUCE_1560091101_1
2020-12-03 07:20:33,422 [IPC Server handler 7 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/filechecksum/foo3	dst=null	perm=null	proto=rpc
hdfsfoocs=MD5-of-2MD5-of-512CRC32C:ce5e7c19c5680ce0c67a58b194a9446b
2020-12-03 07:20:33,442 [IPC Server handler 2 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/filechecksum/foo3	dst=null	perm=null	proto=webhdfs
2020-12-03 07:20:33,444 [IPC Server handler 2 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/filechecksum/foo3	dst=null	perm=null	proto=webhdfs
2020-12-03 07:20:33,452 [nioEventLoopGroup-3-4] DEBUG hdfs.DFSClient (DFSClient.java:<init>(318)) - Sets dfs.client.block.write.replace-datanode-on-failure.min-replication to 0
2020-12-03 07:20:33,455 [IPC Server handler 8 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/filechecksum/foo3	dst=null	perm=null	proto=rpc
2020-12-03 07:20:33,470 [nioEventLoopGroup-3-4] INFO  datanode.webhdfs (WebHdfsHandler.java:run(147)) - 127.0.0.1 GET /webhdfs/v1/filechecksum/foo3?op=GETFILECHECKSUM&user.name=rootx&namenoderpcaddress=localhost:35705 200
webhdfsfoocs=MD5-of-2MD5-of-512CRC32C:ce5e7c19c5680ce0c67a58b194a9446b
2020-12-03 07:20:33,485 [IPC Server handler 4 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/filechecksum/foo3	dst=null	perm=null	proto=webhdfs
2020-12-03 07:20:33,486 [IPC Server handler 4 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/filechecksum/foo3	dst=null	perm=null	proto=webhdfs
2020-12-03 07:20:33,497 [nioEventLoopGroup-5-4] DEBUG hdfs.DFSClient (DFSClient.java:<init>(318)) - Sets dfs.client.block.write.replace-datanode-on-failure.min-replication to 0
2020-12-03 07:20:33,502 [IPC Server handler 0 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/filechecksum/foo3	dst=null	perm=null	proto=rpc
2020-12-03 07:20:33,531 [nioEventLoopGroup-5-4] INFO  datanode.webhdfs (WebHdfsHandler.java:run(147)) - 127.0.0.1 GET /webhdfs/v1/filechecksum/foo3?op=GETFILECHECKSUM&user.name=rootx&namenoderpcaddress=localhost:35705 200
webhdfs_qfoocs=MD5-of-2MD5-of-512CRC32C:ce5e7c19c5680ce0c67a58b194a9446b
2020-12-03 07:20:33,532 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSClient.java:create(1216)) - /filechecksum/zeroByteFile3: masked={ masked: rw-r--r--, unmasked: rw-rw-rw- }
2020-12-03 07:20:33,535 [IPC Server handler 9 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/filechecksum/zeroByteFile3	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:20:33,537 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/filechecksum/zeroByteFile3, chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:20:33,545 [IPC Server handler 6 on default port 35705] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /filechecksum/zeroByteFile3 is closed by DFSClient_NONMAPREDUCE_1560091101_1
2020-12-03 07:20:33,547 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSClient.java:create(1216)) - /filechecksum/bar3: masked={ masked: rw-r--r--, unmasked: rw-rw-rw- }
2020-12-03 07:20:33,550 [IPC Server handler 5 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/filechecksum/bar3	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:20:33,551 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/filechecksum/bar3, chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:20:33,554 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=0, src=/filechecksum/bar3, packetSize=65016, chunksPerPacket=126, bytesCurBlock=0, DFSOutputStream:block==null
2020-12-03 07:20:33,555 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/filechecksum/bar3, chunkSize=516, chunksPerPacket=1, packetSize=516
2020-12-03 07:20:33,555 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=2, src=/filechecksum/bar3, packetSize=516, chunksPerPacket=1, bytesCurBlock=0, DFSOutputStream:block==null
2020-12-03 07:20:33,555 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/filechecksum/bar3, chunkSize=516, chunksPerPacket=1, packetSize=516
2020-12-03 07:20:33,555 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=3, src=/filechecksum/bar3, packetSize=516, chunksPerPacket=1, bytesCurBlock=512, DFSOutputStream:block==null
2020-12-03 07:20:33,555 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/filechecksum/bar3, chunkSize=516, chunksPerPacket=1, packetSize=516
2020-12-03 07:20:33,555 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=5, src=/filechecksum/bar3, packetSize=516, chunksPerPacket=1, bytesCurBlock=0, DFSOutputStream:block==null
2020-12-03 07:20:33,556 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/filechecksum/bar3, chunkSize=516, chunksPerPacket=1, packetSize=516
2020-12-03 07:20:33,556 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=6, src=/filechecksum/bar3, packetSize=516, chunksPerPacket=1, bytesCurBlock=512, DFSOutputStream:block==null
2020-12-03 07:20:33,556 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/filechecksum/bar3, chunkSize=516, chunksPerPacket=1, packetSize=516
2020-12-03 07:20:33,556 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=8, src=/filechecksum/bar3, packetSize=516, chunksPerPacket=1, bytesCurBlock=0, DFSOutputStream:block==null
2020-12-03 07:20:33,556 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/filechecksum/bar3, chunkSize=516, chunksPerPacket=1, packetSize=516
2020-12-03 07:20:33,566 [IPC Server handler 7 on default port 35705] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741841_1017, replicas=127.0.0.1:37829, 127.0.0.1:33302 for /filechecksum/bar3
2020-12-03 07:20:33,569 [Thread-250] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:33,570 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:60052 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741841_1017]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1046523510-172.17.0.9-1606980023524:blk_1073741841_1017 src: /127.0.0.1:60052 dest: /127.0.0.1:37829
2020-12-03 07:20:33,572 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:60052 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741841_1017]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:33,573 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:40320 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741841_1017]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1046523510-172.17.0.9-1606980023524:blk_1073741841_1017 src: /127.0.0.1:40320 dest: /127.0.0.1:33302
2020-12-03 07:20:33,614 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741841_1017, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40320, dest: /127.0.0.1:33302, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1560091101_1, offset: 0, srvID: 14d310ca-8fcf-4840-b079-e46f8cc4dc46, blockid: BP-1046523510-172.17.0.9-1606980023524:blk_1073741841_1017, duration(ns): 22622038
2020-12-03 07:20:33,614 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741841_1017, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741841_1017, type=LAST_IN_PIPELINE terminating
2020-12-03 07:20:33,616 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741841_1017, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:33302]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60052, dest: /127.0.0.1:37829, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1560091101_1, offset: 0, srvID: 26ac7c37-c688-4862-acec-193b89c3e758, blockid: BP-1046523510-172.17.0.9-1606980023524:blk_1073741841_1017, duration(ns): 39865265
2020-12-03 07:20:33,616 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741841_1017, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:33302]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741841_1017, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:33302] terminating
2020-12-03 07:20:33,623 [IPC Server handler 2 on default port 35705] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741842_1018, replicas=127.0.0.1:37829, 127.0.0.1:33302 for /filechecksum/bar3
2020-12-03 07:20:33,634 [DataStreamer for file /filechecksum/bar3] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:33,635 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:60056 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741842_1018]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1046523510-172.17.0.9-1606980023524:blk_1073741842_1018 src: /127.0.0.1:60056 dest: /127.0.0.1:37829
2020-12-03 07:20:33,636 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:60056 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741842_1018]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:33,639 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:40324 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741842_1018]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1046523510-172.17.0.9-1606980023524:blk_1073741842_1018 src: /127.0.0.1:40324 dest: /127.0.0.1:33302
2020-12-03 07:20:33,648 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741842_1018, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40324, dest: /127.0.0.1:33302, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1560091101_1, offset: 0, srvID: 14d310ca-8fcf-4840-b079-e46f8cc4dc46, blockid: BP-1046523510-172.17.0.9-1606980023524:blk_1073741842_1018, duration(ns): 7315698
2020-12-03 07:20:33,649 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741842_1018, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741842_1018, type=LAST_IN_PIPELINE terminating
2020-12-03 07:20:33,650 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741842_1018, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:33302]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60056, dest: /127.0.0.1:37829, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1560091101_1, offset: 0, srvID: 26ac7c37-c688-4862-acec-193b89c3e758, blockid: BP-1046523510-172.17.0.9-1606980023524:blk_1073741842_1018, duration(ns): 9066716
2020-12-03 07:20:33,651 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741842_1018, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:33302]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741842_1018, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:33302] terminating
2020-12-03 07:20:33,654 [IPC Server handler 1 on default port 35705] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741843_1019, replicas=127.0.0.1:33302, 127.0.0.1:37829 for /filechecksum/bar3
2020-12-03 07:20:33,658 [DataStreamer for file /filechecksum/bar3] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:33,659 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:40326 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741843_1019]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1046523510-172.17.0.9-1606980023524:blk_1073741843_1019 src: /127.0.0.1:40326 dest: /127.0.0.1:33302
2020-12-03 07:20:33,660 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:40326 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741843_1019]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:33,661 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:60062 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741843_1019]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1046523510-172.17.0.9-1606980023524:blk_1073741843_1019 src: /127.0.0.1:60062 dest: /127.0.0.1:37829
2020-12-03 07:20:33,673 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741843_1019, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60062, dest: /127.0.0.1:37829, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1560091101_1, offset: 0, srvID: 26ac7c37-c688-4862-acec-193b89c3e758, blockid: BP-1046523510-172.17.0.9-1606980023524:blk_1073741843_1019, duration(ns): 4940417
2020-12-03 07:20:33,674 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741843_1019, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741843_1019, type=LAST_IN_PIPELINE terminating
2020-12-03 07:20:33,676 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741843_1019, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37829]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40326, dest: /127.0.0.1:33302, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1560091101_1, offset: 0, srvID: 14d310ca-8fcf-4840-b079-e46f8cc4dc46, blockid: BP-1046523510-172.17.0.9-1606980023524:blk_1073741843_1019, duration(ns): 10396253
2020-12-03 07:20:33,677 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741843_1019, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37829]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741843_1019, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37829] terminating
2020-12-03 07:20:33,687 [IPC Server handler 5 on default port 35705] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741844_1020, replicas=127.0.0.1:37829, 127.0.0.1:33302 for /filechecksum/bar3
2020-12-03 07:20:33,689 [DataStreamer for file /filechecksum/bar3] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:33,690 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:60064 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741844_1020]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1046523510-172.17.0.9-1606980023524:blk_1073741844_1020 src: /127.0.0.1:60064 dest: /127.0.0.1:37829
2020-12-03 07:20:33,691 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:60064 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741844_1020]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:33,696 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:40332 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741844_1020]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1046523510-172.17.0.9-1606980023524:blk_1073741844_1020 src: /127.0.0.1:40332 dest: /127.0.0.1:33302
2020-12-03 07:20:33,708 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741844_1020, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40332, dest: /127.0.0.1:33302, bytes: 206, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1560091101_1, offset: 0, srvID: 14d310ca-8fcf-4840-b079-e46f8cc4dc46, blockid: BP-1046523510-172.17.0.9-1606980023524:blk_1073741844_1020, duration(ns): 6969257
2020-12-03 07:20:33,708 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741844_1020, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741844_1020, type=LAST_IN_PIPELINE terminating
2020-12-03 07:20:33,715 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741844_1020, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:33302]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60064, dest: /127.0.0.1:37829, bytes: 206, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1560091101_1, offset: 0, srvID: 26ac7c37-c688-4862-acec-193b89c3e758, blockid: BP-1046523510-172.17.0.9-1606980023524:blk_1073741844_1020, duration(ns): 10253796
2020-12-03 07:20:33,715 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741844_1020, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:33302]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741844_1020, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:33302] terminating
2020-12-03 07:20:33,717 [IPC Server handler 8 on default port 35705] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /filechecksum/bar3 is closed by DFSClient_NONMAPREDUCE_1560091101_1
2020-12-03 07:20:33,719 [IPC Server handler 3 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/filechecksum/zeroByteFile3	dst=null	perm=null	proto=rpc
2020-12-03 07:20:33,721 [IPC Server handler 4 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/filechecksum/bar3	dst=null	perm=null	proto=rpc
2020-12-03 07:20:33,733 [IPC Server handler 0 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/filechecksum	dst=null	perm=root:supergroup:---------	proto=rpc
2020-12-03 07:20:33,741 [IPC Server handler 1 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=false	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/filechecksum/foo3	dst=null	perm=null	proto=webhdfs
2020-12-03 07:20:33,744 [Listener at localhost/37047] INFO  fs.FileSystem (TestDistributedFileSystem.java:testFileChecksum(1183)) - GOOD: getting an exception
org.apache.hadoop.security.AccessControlException: Permission denied: user=rootx, access=EXECUTE, inode="/filechecksum":root:supergroup:d---------
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:121)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:110)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem.toIOException(WebHdfsFileSystem.java:546)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem.access$800(WebHdfsFileSystem.java:135)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.shouldRetry(WebHdfsFileSystem.java:851)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.runWithRetry(WebHdfsFileSystem.java:817)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.access$100(WebHdfsFileSystem.java:616)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner$1.run(WebHdfsFileSystem.java:654)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.run(WebHdfsFileSystem.java:650)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem.getFileChecksum(WebHdfsFileSystem.java:1874)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem.getFileChecksum(WebHdfsFileSystem.java:135)
	at org.apache.hadoop.hdfs.TestDistributedFileSystem.testFileChecksum(TestDistributedFileSystem.java:1180)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.AccessControlException): Permission denied: user=rootx, access=EXECUTE, inode="/filechecksum":root:supergroup:d---------
	at org.apache.hadoop.hdfs.web.JsonUtilClient.toRemoteException(JsonUtilClient.java:89)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem.validateResponse(WebHdfsFileSystem.java:507)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem.access$200(WebHdfsFileSystem.java:135)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.connect(WebHdfsFileSystem.java:697)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.runWithRetry(WebHdfsFileSystem.java:788)
	... 34 more
2020-12-03 07:20:33,747 [IPC Server handler 9 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/filechecksum	dst=null	perm=root:supergroup:rwxrwxrwx	proto=rpc
data.length=4209
2020-12-03 07:20:33,748 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSClient.java:create(1216)) - /filechecksum/foo4: masked={ masked: rw-r--r--, unmasked: rw-rw-rw- }
2020-12-03 07:20:33,750 [IPC Server handler 6 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/filechecksum/foo4	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:20:33,751 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/filechecksum/foo4, chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:20:33,753 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=0, src=/filechecksum/foo4, packetSize=65016, chunksPerPacket=126, bytesCurBlock=0, DFSOutputStream:block==null
2020-12-03 07:20:33,754 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/filechecksum/foo4, chunkSize=516, chunksPerPacket=1, packetSize=516
2020-12-03 07:20:33,754 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=2, src=/filechecksum/foo4, packetSize=516, chunksPerPacket=1, bytesCurBlock=0, DFSOutputStream:block==null
2020-12-03 07:20:33,755 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/filechecksum/foo4, chunkSize=516, chunksPerPacket=1, packetSize=516
2020-12-03 07:20:33,755 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=3, src=/filechecksum/foo4, packetSize=516, chunksPerPacket=1, bytesCurBlock=512, DFSOutputStream:block==null
2020-12-03 07:20:33,755 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/filechecksum/foo4, chunkSize=516, chunksPerPacket=1, packetSize=516
2020-12-03 07:20:33,756 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=5, src=/filechecksum/foo4, packetSize=516, chunksPerPacket=1, bytesCurBlock=0, DFSOutputStream:block==null
2020-12-03 07:20:33,756 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/filechecksum/foo4, chunkSize=516, chunksPerPacket=1, packetSize=516
2020-12-03 07:20:33,756 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=6, src=/filechecksum/foo4, packetSize=516, chunksPerPacket=1, bytesCurBlock=512, DFSOutputStream:block==null
2020-12-03 07:20:33,756 [IPC Server handler 5 on default port 35705] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741845_1021, replicas=127.0.0.1:37829, 127.0.0.1:33302 for /filechecksum/foo4
2020-12-03 07:20:33,756 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/filechecksum/foo4, chunkSize=516, chunksPerPacket=1, packetSize=516
2020-12-03 07:20:33,757 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=8, src=/filechecksum/foo4, packetSize=516, chunksPerPacket=1, bytesCurBlock=0, DFSOutputStream:block==null
2020-12-03 07:20:33,757 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/filechecksum/foo4, chunkSize=516, chunksPerPacket=1, packetSize=516
2020-12-03 07:20:33,757 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=9, src=/filechecksum/foo4, packetSize=516, chunksPerPacket=1, bytesCurBlock=512, DFSOutputStream:block==null
2020-12-03 07:20:33,757 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/filechecksum/foo4, chunkSize=516, chunksPerPacket=1, packetSize=516
2020-12-03 07:20:33,757 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=11, src=/filechecksum/foo4, packetSize=516, chunksPerPacket=1, bytesCurBlock=0, DFSOutputStream:block==null
2020-12-03 07:20:33,757 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/filechecksum/foo4, chunkSize=516, chunksPerPacket=1, packetSize=516
2020-12-03 07:20:33,758 [Thread-275] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:33,759 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:60076 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741845_1021]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1046523510-172.17.0.9-1606980023524:blk_1073741845_1021 src: /127.0.0.1:60076 dest: /127.0.0.1:37829
2020-12-03 07:20:33,760 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:60076 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741845_1021]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:33,761 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:40344 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741845_1021]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1046523510-172.17.0.9-1606980023524:blk_1073741845_1021 src: /127.0.0.1:40344 dest: /127.0.0.1:33302
2020-12-03 07:20:33,769 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741845_1021, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40344, dest: /127.0.0.1:33302, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1560091101_1, offset: 0, srvID: 14d310ca-8fcf-4840-b079-e46f8cc4dc46, blockid: BP-1046523510-172.17.0.9-1606980023524:blk_1073741845_1021, duration(ns): 6518725
2020-12-03 07:20:33,770 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741845_1021, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741845_1021, type=LAST_IN_PIPELINE terminating
2020-12-03 07:20:33,771 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741845_1021, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:33302]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60076, dest: /127.0.0.1:37829, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1560091101_1, offset: 0, srvID: 26ac7c37-c688-4862-acec-193b89c3e758, blockid: BP-1046523510-172.17.0.9-1606980023524:blk_1073741845_1021, duration(ns): 7349953
2020-12-03 07:20:33,771 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741845_1021, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:33302]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741845_1021, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:33302] terminating
2020-12-03 07:20:33,774 [IPC Server handler 7 on default port 35705] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741846_1022, replicas=127.0.0.1:33302, 127.0.0.1:37829 for /filechecksum/foo4
2020-12-03 07:20:33,776 [DataStreamer for file /filechecksum/foo4] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:33,777 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:40346 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741846_1022]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1046523510-172.17.0.9-1606980023524:blk_1073741846_1022 src: /127.0.0.1:40346 dest: /127.0.0.1:33302
2020-12-03 07:20:33,778 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:40346 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741846_1022]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:33,779 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:60082 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741846_1022]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1046523510-172.17.0.9-1606980023524:blk_1073741846_1022 src: /127.0.0.1:60082 dest: /127.0.0.1:37829
2020-12-03 07:20:33,788 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741846_1022, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60082, dest: /127.0.0.1:37829, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1560091101_1, offset: 0, srvID: 26ac7c37-c688-4862-acec-193b89c3e758, blockid: BP-1046523510-172.17.0.9-1606980023524:blk_1073741846_1022, duration(ns): 7587173
2020-12-03 07:20:33,789 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741846_1022, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741846_1022, type=LAST_IN_PIPELINE terminating
2020-12-03 07:20:33,792 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741846_1022, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37829]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40346, dest: /127.0.0.1:33302, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1560091101_1, offset: 0, srvID: 14d310ca-8fcf-4840-b079-e46f8cc4dc46, blockid: BP-1046523510-172.17.0.9-1606980023524:blk_1073741846_1022, duration(ns): 8429509
2020-12-03 07:20:33,792 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741846_1022, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37829]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741846_1022, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37829] terminating
2020-12-03 07:20:33,795 [IPC Server handler 4 on default port 35705] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741847_1023, replicas=127.0.0.1:37829, 127.0.0.1:33302 for /filechecksum/foo4
2020-12-03 07:20:33,797 [DataStreamer for file /filechecksum/foo4] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:33,798 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:60084 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741847_1023]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1046523510-172.17.0.9-1606980023524:blk_1073741847_1023 src: /127.0.0.1:60084 dest: /127.0.0.1:37829
2020-12-03 07:20:33,799 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:60084 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741847_1023]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:33,800 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:40352 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741847_1023]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1046523510-172.17.0.9-1606980023524:blk_1073741847_1023 src: /127.0.0.1:40352 dest: /127.0.0.1:33302
2020-12-03 07:20:33,822 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741847_1023, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40352, dest: /127.0.0.1:33302, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1560091101_1, offset: 0, srvID: 14d310ca-8fcf-4840-b079-e46f8cc4dc46, blockid: BP-1046523510-172.17.0.9-1606980023524:blk_1073741847_1023, duration(ns): 20516926
2020-12-03 07:20:33,822 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741847_1023, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741847_1023, type=LAST_IN_PIPELINE terminating
2020-12-03 07:20:33,823 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741847_1023, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:33302]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60084, dest: /127.0.0.1:37829, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1560091101_1, offset: 0, srvID: 26ac7c37-c688-4862-acec-193b89c3e758, blockid: BP-1046523510-172.17.0.9-1606980023524:blk_1073741847_1023, duration(ns): 18754515
2020-12-03 07:20:33,824 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741847_1023, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:33302]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741847_1023, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:33302] terminating
2020-12-03 07:20:33,826 [IPC Server handler 5 on default port 35705] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741848_1024, replicas=127.0.0.1:33302, 127.0.0.1:37829 for /filechecksum/foo4
2020-12-03 07:20:33,828 [DataStreamer for file /filechecksum/foo4] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:33,833 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:40354 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741848_1024]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1046523510-172.17.0.9-1606980023524:blk_1073741848_1024 src: /127.0.0.1:40354 dest: /127.0.0.1:33302
2020-12-03 07:20:33,835 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:40354 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741848_1024]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:33,839 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:60090 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741848_1024]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1046523510-172.17.0.9-1606980023524:blk_1073741848_1024 src: /127.0.0.1:60090 dest: /127.0.0.1:37829
2020-12-03 07:20:33,843 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741848_1024, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60090, dest: /127.0.0.1:37829, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1560091101_1, offset: 0, srvID: 26ac7c37-c688-4862-acec-193b89c3e758, blockid: BP-1046523510-172.17.0.9-1606980023524:blk_1073741848_1024, duration(ns): 2353468
2020-12-03 07:20:33,843 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741848_1024, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741848_1024, type=LAST_IN_PIPELINE terminating
2020-12-03 07:20:33,844 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741848_1024, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37829]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40354, dest: /127.0.0.1:33302, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1560091101_1, offset: 0, srvID: 14d310ca-8fcf-4840-b079-e46f8cc4dc46, blockid: BP-1046523510-172.17.0.9-1606980023524:blk_1073741848_1024, duration(ns): 3112198
2020-12-03 07:20:33,844 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741848_1024, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37829]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741848_1024, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37829] terminating
2020-12-03 07:20:33,847 [IPC Server handler 7 on default port 35705] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741849_1025, replicas=127.0.0.1:33302, 127.0.0.1:37829 for /filechecksum/foo4
2020-12-03 07:20:33,849 [DataStreamer for file /filechecksum/foo4] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:33,857 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:40358 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741849_1025]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1046523510-172.17.0.9-1606980023524:blk_1073741849_1025 src: /127.0.0.1:40358 dest: /127.0.0.1:33302
2020-12-03 07:20:33,859 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:40358 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741849_1025]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:33,860 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:60094 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741849_1025]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1046523510-172.17.0.9-1606980023524:blk_1073741849_1025 src: /127.0.0.1:60094 dest: /127.0.0.1:37829
2020-12-03 07:20:33,867 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741849_1025, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60094, dest: /127.0.0.1:37829, bytes: 113, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1560091101_1, offset: 0, srvID: 26ac7c37-c688-4862-acec-193b89c3e758, blockid: BP-1046523510-172.17.0.9-1606980023524:blk_1073741849_1025, duration(ns): 5925953
2020-12-03 07:20:33,868 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741849_1025, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741849_1025, type=LAST_IN_PIPELINE terminating
2020-12-03 07:20:33,869 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741849_1025, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37829]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40358, dest: /127.0.0.1:33302, bytes: 113, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1560091101_1, offset: 0, srvID: 14d310ca-8fcf-4840-b079-e46f8cc4dc46, blockid: BP-1046523510-172.17.0.9-1606980023524:blk_1073741849_1025, duration(ns): 6098975
2020-12-03 07:20:33,869 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741849_1025, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37829]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741849_1025, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37829] terminating
2020-12-03 07:20:33,871 [IPC Server handler 4 on default port 35705] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /filechecksum/foo4 is closed by DFSClient_NONMAPREDUCE_1560091101_1
2020-12-03 07:20:33,873 [IPC Server handler 1 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/filechecksum/foo4	dst=null	perm=null	proto=rpc
hdfsfoocs=MD5-of-2MD5-of-512CRC32C:f91f7adefadac937a32944af549393f6
2020-12-03 07:20:33,897 [IPC Server handler 9 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/filechecksum/foo4	dst=null	perm=null	proto=webhdfs
2020-12-03 07:20:33,901 [IPC Server handler 9 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/filechecksum/foo4	dst=null	perm=null	proto=webhdfs
2020-12-03 07:20:33,915 [nioEventLoopGroup-3-5] DEBUG hdfs.DFSClient (DFSClient.java:<init>(318)) - Sets dfs.client.block.write.replace-datanode-on-failure.min-replication to 0
2020-12-03 07:20:33,917 [IPC Server handler 6 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/filechecksum/foo4	dst=null	perm=null	proto=rpc
2020-12-03 07:20:33,959 [nioEventLoopGroup-3-5] INFO  datanode.webhdfs (WebHdfsHandler.java:run(147)) - 127.0.0.1 GET /webhdfs/v1/filechecksum/foo4?op=GETFILECHECKSUM&user.name=rootx&namenoderpcaddress=localhost:35705 200
webhdfsfoocs=MD5-of-2MD5-of-512CRC32C:f91f7adefadac937a32944af549393f6
2020-12-03 07:20:33,968 [IPC Server handler 2 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/filechecksum/foo4	dst=null	perm=null	proto=webhdfs
2020-12-03 07:20:33,969 [IPC Server handler 2 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/filechecksum/foo4	dst=null	perm=null	proto=webhdfs
2020-12-03 07:20:33,976 [nioEventLoopGroup-3-6] DEBUG hdfs.DFSClient (DFSClient.java:<init>(318)) - Sets dfs.client.block.write.replace-datanode-on-failure.min-replication to 0
2020-12-03 07:20:33,982 [IPC Server handler 8 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/filechecksum/foo4	dst=null	perm=null	proto=rpc
2020-12-03 07:20:34,012 [nioEventLoopGroup-3-6] INFO  datanode.webhdfs (WebHdfsHandler.java:run(147)) - 127.0.0.1 GET /webhdfs/v1/filechecksum/foo4?op=GETFILECHECKSUM&user.name=rootx&namenoderpcaddress=localhost:35705 200
webhdfs_qfoocs=MD5-of-2MD5-of-512CRC32C:f91f7adefadac937a32944af549393f6
2020-12-03 07:20:34,014 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSClient.java:create(1216)) - /filechecksum/zeroByteFile4: masked={ masked: rw-r--r--, unmasked: rw-rw-rw- }
2020-12-03 07:20:34,016 [IPC Server handler 3 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/filechecksum/zeroByteFile4	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:20:34,017 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/filechecksum/zeroByteFile4, chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:20:34,019 [IPC Server handler 0 on default port 35705] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /filechecksum/zeroByteFile4 is closed by DFSClient_NONMAPREDUCE_1560091101_1
2020-12-03 07:20:34,020 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSClient.java:create(1216)) - /filechecksum/bar4: masked={ masked: rw-r--r--, unmasked: rw-rw-rw- }
2020-12-03 07:20:34,022 [IPC Server handler 4 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/filechecksum/bar4	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:20:34,023 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/filechecksum/bar4, chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:20:34,024 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=0, src=/filechecksum/bar4, packetSize=65016, chunksPerPacket=126, bytesCurBlock=0, DFSOutputStream:block==null
2020-12-03 07:20:34,024 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/filechecksum/bar4, chunkSize=516, chunksPerPacket=1, packetSize=516
2020-12-03 07:20:34,025 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=2, src=/filechecksum/bar4, packetSize=516, chunksPerPacket=1, bytesCurBlock=0, DFSOutputStream:block==null
2020-12-03 07:20:34,030 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/filechecksum/bar4, chunkSize=516, chunksPerPacket=1, packetSize=516
2020-12-03 07:20:34,030 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=3, src=/filechecksum/bar4, packetSize=516, chunksPerPacket=1, bytesCurBlock=512, DFSOutputStream:block==null
2020-12-03 07:20:34,030 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/filechecksum/bar4, chunkSize=516, chunksPerPacket=1, packetSize=516
2020-12-03 07:20:34,030 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=5, src=/filechecksum/bar4, packetSize=516, chunksPerPacket=1, bytesCurBlock=0, DFSOutputStream:block==null
2020-12-03 07:20:34,031 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/filechecksum/bar4, chunkSize=516, chunksPerPacket=1, packetSize=516
2020-12-03 07:20:34,031 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=6, src=/filechecksum/bar4, packetSize=516, chunksPerPacket=1, bytesCurBlock=512, DFSOutputStream:block==null
2020-12-03 07:20:34,031 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/filechecksum/bar4, chunkSize=516, chunksPerPacket=1, packetSize=516
2020-12-03 07:20:34,031 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=8, src=/filechecksum/bar4, packetSize=516, chunksPerPacket=1, bytesCurBlock=0, DFSOutputStream:block==null
2020-12-03 07:20:34,031 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/filechecksum/bar4, chunkSize=516, chunksPerPacket=1, packetSize=516
2020-12-03 07:20:34,032 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=9, src=/filechecksum/bar4, packetSize=516, chunksPerPacket=1, bytesCurBlock=512, DFSOutputStream:block==null
2020-12-03 07:20:34,032 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/filechecksum/bar4, chunkSize=516, chunksPerPacket=1, packetSize=516
2020-12-03 07:20:34,032 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=11, src=/filechecksum/bar4, packetSize=516, chunksPerPacket=1, bytesCurBlock=0, DFSOutputStream:block==null
2020-12-03 07:20:34,032 [Listener at localhost/37047] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/filechecksum/bar4, chunkSize=516, chunksPerPacket=1, packetSize=516
2020-12-03 07:20:34,038 [IPC Server handler 1 on default port 35705] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741850_1026, replicas=127.0.0.1:37829, 127.0.0.1:33302 for /filechecksum/bar4
2020-12-03 07:20:34,040 [Thread-317] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:34,042 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:60130 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741850_1026]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1046523510-172.17.0.9-1606980023524:blk_1073741850_1026 src: /127.0.0.1:60130 dest: /127.0.0.1:37829
2020-12-03 07:20:34,043 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:60130 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741850_1026]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:34,053 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:40398 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741850_1026]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1046523510-172.17.0.9-1606980023524:blk_1073741850_1026 src: /127.0.0.1:40398 dest: /127.0.0.1:33302
2020-12-03 07:20:34,061 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741850_1026, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40398, dest: /127.0.0.1:33302, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1560091101_1, offset: 0, srvID: 14d310ca-8fcf-4840-b079-e46f8cc4dc46, blockid: BP-1046523510-172.17.0.9-1606980023524:blk_1073741850_1026, duration(ns): 5546417
2020-12-03 07:20:34,061 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741850_1026, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741850_1026, type=LAST_IN_PIPELINE terminating
2020-12-03 07:20:34,062 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741850_1026, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:33302]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60130, dest: /127.0.0.1:37829, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1560091101_1, offset: 0, srvID: 26ac7c37-c688-4862-acec-193b89c3e758, blockid: BP-1046523510-172.17.0.9-1606980023524:blk_1073741850_1026, duration(ns): 5144689
2020-12-03 07:20:34,062 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741850_1026, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:33302]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741850_1026, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:33302] terminating
2020-12-03 07:20:34,064 [IPC Server handler 6 on default port 35705] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741851_1027, replicas=127.0.0.1:33302, 127.0.0.1:37829 for /filechecksum/bar4
2020-12-03 07:20:34,067 [DataStreamer for file /filechecksum/bar4] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:34,068 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:40400 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741851_1027]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1046523510-172.17.0.9-1606980023524:blk_1073741851_1027 src: /127.0.0.1:40400 dest: /127.0.0.1:33302
2020-12-03 07:20:34,069 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:40400 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741851_1027]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:34,070 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:60136 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741851_1027]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1046523510-172.17.0.9-1606980023524:blk_1073741851_1027 src: /127.0.0.1:60136 dest: /127.0.0.1:37829
2020-12-03 07:20:34,082 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741851_1027, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60136, dest: /127.0.0.1:37829, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1560091101_1, offset: 0, srvID: 26ac7c37-c688-4862-acec-193b89c3e758, blockid: BP-1046523510-172.17.0.9-1606980023524:blk_1073741851_1027, duration(ns): 9759158
2020-12-03 07:20:34,082 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741851_1027, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741851_1027, type=LAST_IN_PIPELINE terminating
2020-12-03 07:20:34,083 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741851_1027, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37829]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40400, dest: /127.0.0.1:33302, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1560091101_1, offset: 0, srvID: 14d310ca-8fcf-4840-b079-e46f8cc4dc46, blockid: BP-1046523510-172.17.0.9-1606980023524:blk_1073741851_1027, duration(ns): 11112596
2020-12-03 07:20:34,084 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741851_1027, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37829]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741851_1027, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37829] terminating
2020-12-03 07:20:34,094 [IPC Server handler 7 on default port 35705] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741852_1028, replicas=127.0.0.1:33302, 127.0.0.1:37829 for /filechecksum/bar4
2020-12-03 07:20:34,096 [DataStreamer for file /filechecksum/bar4] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:34,098 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:40404 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741852_1028]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1046523510-172.17.0.9-1606980023524:blk_1073741852_1028 src: /127.0.0.1:40404 dest: /127.0.0.1:33302
2020-12-03 07:20:34,100 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:40404 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741852_1028]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:34,101 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:60140 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741852_1028]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1046523510-172.17.0.9-1606980023524:blk_1073741852_1028 src: /127.0.0.1:60140 dest: /127.0.0.1:37829
2020-12-03 07:20:34,113 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741852_1028, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60140, dest: /127.0.0.1:37829, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1560091101_1, offset: 0, srvID: 26ac7c37-c688-4862-acec-193b89c3e758, blockid: BP-1046523510-172.17.0.9-1606980023524:blk_1073741852_1028, duration(ns): 9968030
2020-12-03 07:20:34,114 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741852_1028, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741852_1028, type=LAST_IN_PIPELINE terminating
2020-12-03 07:20:34,115 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741852_1028, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37829]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40404, dest: /127.0.0.1:33302, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1560091101_1, offset: 0, srvID: 14d310ca-8fcf-4840-b079-e46f8cc4dc46, blockid: BP-1046523510-172.17.0.9-1606980023524:blk_1073741852_1028, duration(ns): 11248425
2020-12-03 07:20:34,116 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741852_1028, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37829]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741852_1028, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37829] terminating
2020-12-03 07:20:34,134 [IPC Server handler 4 on default port 35705] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741853_1029, replicas=127.0.0.1:37829, 127.0.0.1:33302 for /filechecksum/bar4
2020-12-03 07:20:34,137 [DataStreamer for file /filechecksum/bar4] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:34,138 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:60142 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741853_1029]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1046523510-172.17.0.9-1606980023524:blk_1073741853_1029 src: /127.0.0.1:60142 dest: /127.0.0.1:37829
2020-12-03 07:20:34,139 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:60142 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741853_1029]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:34,140 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:40410 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741853_1029]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1046523510-172.17.0.9-1606980023524:blk_1073741853_1029 src: /127.0.0.1:40410 dest: /127.0.0.1:33302
2020-12-03 07:20:34,150 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741853_1029, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40410, dest: /127.0.0.1:33302, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1560091101_1, offset: 0, srvID: 14d310ca-8fcf-4840-b079-e46f8cc4dc46, blockid: BP-1046523510-172.17.0.9-1606980023524:blk_1073741853_1029, duration(ns): 7521257
2020-12-03 07:20:34,150 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741853_1029, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741853_1029, type=LAST_IN_PIPELINE terminating
2020-12-03 07:20:34,152 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741853_1029, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:33302]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60142, dest: /127.0.0.1:37829, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1560091101_1, offset: 0, srvID: 26ac7c37-c688-4862-acec-193b89c3e758, blockid: BP-1046523510-172.17.0.9-1606980023524:blk_1073741853_1029, duration(ns): 10242203
2020-12-03 07:20:34,153 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741853_1029, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:33302]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741853_1029, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:33302] terminating
2020-12-03 07:20:34,156 [IPC Server handler 6 on default port 35705] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741854_1030, replicas=127.0.0.1:37829, 127.0.0.1:33302 for /filechecksum/bar4
2020-12-03 07:20:34,158 [DataStreamer for file /filechecksum/bar4] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:34,160 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:60146 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741854_1030]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1046523510-172.17.0.9-1606980023524:blk_1073741854_1030 src: /127.0.0.1:60146 dest: /127.0.0.1:37829
2020-12-03 07:20:34,162 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:60146 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741854_1030]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:34,164 [DataXceiver for client DFSClient_NONMAPREDUCE_1560091101_1 at /127.0.0.1:40414 [Receiving block BP-1046523510-172.17.0.9-1606980023524:blk_1073741854_1030]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1046523510-172.17.0.9-1606980023524:blk_1073741854_1030 src: /127.0.0.1:40414 dest: /127.0.0.1:33302
2020-12-03 07:20:34,181 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741854_1030, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40414, dest: /127.0.0.1:33302, bytes: 113, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1560091101_1, offset: 0, srvID: 14d310ca-8fcf-4840-b079-e46f8cc4dc46, blockid: BP-1046523510-172.17.0.9-1606980023524:blk_1073741854_1030, duration(ns): 12461650
2020-12-03 07:20:34,181 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741854_1030, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741854_1030, type=LAST_IN_PIPELINE terminating
2020-12-03 07:20:34,186 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741854_1030, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:33302]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60146, dest: /127.0.0.1:37829, bytes: 113, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1560091101_1, offset: 0, srvID: 26ac7c37-c688-4862-acec-193b89c3e758, blockid: BP-1046523510-172.17.0.9-1606980023524:blk_1073741854_1030, duration(ns): 17496166
2020-12-03 07:20:34,186 [PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741854_1030, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:33302]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1046523510-172.17.0.9-1606980023524:blk_1073741854_1030, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:33302] terminating
2020-12-03 07:20:34,190 [IPC Server handler 2 on default port 35705] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /filechecksum/bar4 is closed by DFSClient_NONMAPREDUCE_1560091101_1
2020-12-03 07:20:34,193 [IPC Server handler 7 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/filechecksum/zeroByteFile4	dst=null	perm=null	proto=rpc
2020-12-03 07:20:34,196 [IPC Server handler 3 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/filechecksum/bar4	dst=null	perm=null	proto=rpc
2020-12-03 07:20:34,346 [IPC Server handler 0 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/filechecksum	dst=null	perm=root:supergroup:---------	proto=rpc
2020-12-03 07:20:34,355 [IPC Server handler 4 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=false	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/filechecksum/foo4	dst=null	perm=null	proto=webhdfs
2020-12-03 07:20:34,358 [Listener at localhost/37047] INFO  fs.FileSystem (TestDistributedFileSystem.java:testFileChecksum(1183)) - GOOD: getting an exception
org.apache.hadoop.security.AccessControlException: Permission denied: user=rootx, access=EXECUTE, inode="/filechecksum":root:supergroup:d---------
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:121)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:110)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem.toIOException(WebHdfsFileSystem.java:546)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem.access$800(WebHdfsFileSystem.java:135)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.shouldRetry(WebHdfsFileSystem.java:851)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.runWithRetry(WebHdfsFileSystem.java:817)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.access$100(WebHdfsFileSystem.java:616)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner$1.run(WebHdfsFileSystem.java:654)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.run(WebHdfsFileSystem.java:650)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem.getFileChecksum(WebHdfsFileSystem.java:1874)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem.getFileChecksum(WebHdfsFileSystem.java:135)
	at org.apache.hadoop.hdfs.TestDistributedFileSystem.testFileChecksum(TestDistributedFileSystem.java:1180)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.AccessControlException): Permission denied: user=rootx, access=EXECUTE, inode="/filechecksum":root:supergroup:d---------
	at org.apache.hadoop.hdfs.web.JsonUtilClient.toRemoteException(JsonUtilClient.java:89)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem.validateResponse(WebHdfsFileSystem.java:507)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem.access$200(WebHdfsFileSystem.java:135)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.connect(WebHdfsFileSystem.java:697)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.runWithRetry(WebHdfsFileSystem.java:788)
	... 34 more
2020-12-03 07:20:34,365 [IPC Server handler 1 on default port 35705] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/filechecksum	dst=null	perm=root:supergroup:rwxrwxrwx	proto=rpc
2020-12-03 07:20:34,366 [Listener at localhost/37047] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:20:34,366 [Listener at localhost/37047] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 1
2020-12-03 07:20:34,368 [Listener at localhost/37047] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:34,368 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@5a4bef8] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:34,370 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-09eb49bc-318f-44d9-9f6f-340bc899821c) exiting.
2020-12-03 07:20:34,371 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-bcf09409-8126-477f-9cbc-2496fedf29f8) exiting.
2020-12-03 07:20:34,417 [Listener at localhost/37047] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@344344fa{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:34,425 [Listener at localhost/37047] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2db2cd5{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:34,426 [Listener at localhost/37047] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@71e9a896{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:34,427 [Listener at localhost/37047] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@384fc774{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:34,441 [Listener at localhost/37047] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 37047
2020-12-03 07:20:34,450 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:34,451 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:34,452 [BP-1046523510-172.17.0.9-1606980023524 heartbeating to localhost/127.0.0.1:35705] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:34,452 [BP-1046523510-172.17.0.9-1606980023524 heartbeating to localhost/127.0.0.1:35705] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1046523510-172.17.0.9-1606980023524 (Datanode Uuid 14d310ca-8fcf-4840-b079-e46f8cc4dc46) service to localhost/127.0.0.1:35705
2020-12-03 07:20:34,453 [BP-1046523510-172.17.0.9-1606980023524 heartbeating to localhost/127.0.0.1:35705] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1046523510-172.17.0.9-1606980023524 (Datanode Uuid 14d310ca-8fcf-4840-b079-e46f8cc4dc46)
2020-12-03 07:20:34,454 [BP-1046523510-172.17.0.9-1606980023524 heartbeating to localhost/127.0.0.1:35705] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1046523510-172.17.0.9-1606980023524
2020-12-03 07:20:34,455 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1046523510-172.17.0.9-1606980023524] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:34,456 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1046523510-172.17.0.9-1606980023524] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:34,459 [Listener at localhost/37047] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:34,459 [Listener at localhost/37047] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:34,460 [Listener at localhost/37047] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:34,460 [Listener at localhost/37047] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:34,467 [Listener at localhost/37047] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:34,468 [Listener at localhost/37047] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:20:34,468 [Listener at localhost/37047] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:34,468 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@72a85671] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:34,470 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-45995af8-9d1f-4a12-b9f4-0314f4595926) exiting.
2020-12-03 07:20:34,471 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-f3ac1c58-0b14-4986-934c-b8aef5e53f67) exiting.
2020-12-03 07:20:34,534 [Listener at localhost/37047] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@4ebea12c{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:34,535 [Listener at localhost/37047] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2a1edad4{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:34,535 [Listener at localhost/37047] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3faf2e7d{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:34,536 [Listener at localhost/37047] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@29ef6856{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:34,538 [Listener at localhost/37047] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 36565
2020-12-03 07:20:34,581 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:34,584 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:34,586 [BP-1046523510-172.17.0.9-1606980023524 heartbeating to localhost/127.0.0.1:35705] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:34,589 [BP-1046523510-172.17.0.9-1606980023524 heartbeating to localhost/127.0.0.1:35705] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1046523510-172.17.0.9-1606980023524 (Datanode Uuid 26ac7c37-c688-4862-acec-193b89c3e758) service to localhost/127.0.0.1:35705
2020-12-03 07:20:34,693 [BP-1046523510-172.17.0.9-1606980023524 heartbeating to localhost/127.0.0.1:35705] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1046523510-172.17.0.9-1606980023524 (Datanode Uuid 26ac7c37-c688-4862-acec-193b89c3e758)
2020-12-03 07:20:34,693 [BP-1046523510-172.17.0.9-1606980023524 heartbeating to localhost/127.0.0.1:35705] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1046523510-172.17.0.9-1606980023524
2020-12-03 07:20:34,694 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1046523510-172.17.0.9-1606980023524] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:34,695 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1046523510-172.17.0.9-1606980023524] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:34,705 [Listener at localhost/37047] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:34,706 [Listener at localhost/37047] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:34,707 [Listener at localhost/37047] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:34,707 [Listener at localhost/37047] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:34,713 [Listener at localhost/37047] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:34,713 [Listener at localhost/37047] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:20:34,714 [Listener at localhost/37047] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:20:34,714 [Listener at localhost/37047] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 1, 134
2020-12-03 07:20:34,714 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@73db4768] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:20:34,717 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@4c37b5b] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:20:34,721 [Listener at localhost/37047] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 135 Total time for transactions(ms): 48 Number of transactions batched in Syncs: 41 Number of syncs: 95 SyncTimes(ms): 5 7 
2020-12-03 07:20:34,723 [Listener at localhost/37047] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000135
2020-12-03 07:20:34,724 [Listener at localhost/37047] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000135
2020-12-03 07:20:34,729 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:20:34,729 [CacheReplicationMonitor(1118389469)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:20:34,730 [Listener at localhost/37047] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 35705
2020-12-03 07:20:34,731 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:34,749 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:34,749 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:20:34,758 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:20:34,808 [Listener at localhost/37047] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:20:34,809 [Listener at localhost/37047] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:20:34,823 [Listener at localhost/37047] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@12299890{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:20:34,827 [Listener at localhost/37047] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@51c693d{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:34,828 [Listener at localhost/37047] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5a7fe64f{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:34,828 [Listener at localhost/37047] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@14bdbc74{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:34,830 [Listener at localhost/37047] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-12-03 07:20:34,833 [Listener at localhost/37047] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-12-03 07:20:34,833 [Listener at localhost/37047] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
msx-rc 0
