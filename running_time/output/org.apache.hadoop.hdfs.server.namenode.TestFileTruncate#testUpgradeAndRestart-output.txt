2020-12-03 07:20:56,014 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=3
Formatting using clusterid: testClusterID
2020-12-03 07:20:56,757 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:20:56,774 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:20:56,775 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:20:56,776 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:20:56,784 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:20:56,784 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:20:56,784 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:20:56,786 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:20:56,840 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:56,846 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2020-12-03 07:20:56,846 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:20:56,847 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=20, effected=1000
2020-12-03 07:20:56,847 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:20:56,847 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:20:56,853 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:20:56,855 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:20:56
2020-12-03 07:20:56,858 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:20:56,858 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:56,860 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-12-03 07:20:56,860 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:20:56,877 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:20:56,878 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:20:56,881 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:20:56,882 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:20:56,884 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:20:56,889 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:20:56,890 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:20:56,890 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:20:56,890 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:20:56,891 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:20:56,891 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:20:56,892 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:20:56,892 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:20:56,892 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:20:56,892 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:20:56,893 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:20:56,927 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GLOBAL serial map: bits=29 maxEntries=536870911
2020-12-03 07:20:56,927 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - USER serial map: bits=24 maxEntries=16777215
2020-12-03 07:20:56,928 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GROUP serial map: bits=24 maxEntries=16777215
2020-12-03 07:20:56,928 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - XATTR serial map: bits=24 maxEntries=16777215
2020-12-03 07:20:56,945 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:20:56,945 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:56,945 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-12-03 07:20:56,946 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:20:56,952 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:20:56,952 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:20:56,953 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:20:56,953 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:20:56,959 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:20:56,962 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:20:56,966 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:20:56,967 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:56,967 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-12-03 07:20:56,967 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:20:56,979 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:20:56,980 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:20:56,980 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:20:56,985 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:20:56,985 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:20:56,989 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:20:56,989 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:56,989 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-12-03 07:20:56,990 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:20:57,032 [main] INFO  namenode.FSImage (FSImage.java:format(185)) - Allocated new BlockPoolId: BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:20:57,235 [main] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-12-03 07:20:57,384 [main] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-12-03 07:20:57,417 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:20:57,417 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:20:57,565 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:20:57,565 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:20:57,634 [main] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-12-03 07:20:57,637 [main] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:20:57,748 [main] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:20:57,986 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:20:57,986 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:20:58,024 [main] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-12-03 07:20:58,067 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5d0a1059] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:58,083 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:20:58,089 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:58,104 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @3098ms
2020-12-03 07:20:58,238 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:58,242 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:20:58,242 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:58,251 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:58,253 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:20:58,253 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:58,253 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:58,286 [main] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:20:58,287 [main] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:20:58,297 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 34369
2020-12-03 07:20:58,299 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:58,347 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@475c9c31{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:58,349 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5c7bfdc1{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:58,500 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@895e367{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:20:58,512 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@50313382{HTTP/1.1,[http/1.1]}{localhost:34369}
2020-12-03 07:20:58,513 [main] INFO  server.Server (Server.java:doStart(419)) - Started @3507ms
2020-12-03 07:20:58,525 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:20:58,525 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:20:58,526 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:20:58,526 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:20:58,526 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:20:58,527 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:20:58,527 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:20:58,527 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:20:58,528 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:58,528 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:20:58,528 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=20, effected=1000
2020-12-03 07:20:58,529 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:20:58,529 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:20:58,529 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:20:58,530 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:20:58
2020-12-03 07:20:58,530 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:20:58,530 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:58,531 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:20:58,531 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:20:58,537 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:20:58,538 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:20:58,538 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:20:58,539 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:20:58,539 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:20:58,539 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:20:58,540 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:20:58,540 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:20:58,540 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:20:58,540 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:20:58,540 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:20:58,540 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:20:58,541 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:20:58,541 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:20:58,541 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:20:58,542 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:20:58,542 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:20:58,542 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:58,543 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:20:58,543 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:20:58,545 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:20:58,545 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:20:58,546 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:20:58,546 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:20:58,546 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:20:58,546 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:20:58,546 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:20:58,547 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:58,547 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:20:58,547 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:20:58,548 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:20:58,548 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:20:58,548 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:20:58,548 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:20:58,549 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:20:58,549 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:20:58,549 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:58,549 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:20:58,549 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:20:58,652 [main] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 2630@9bd33dce04e9
2020-12-03 07:20:58,736 [main] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 2630@9bd33dce04e9
2020-12-03 07:20:58,740 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-12-03 07:20:58,740 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-12-03 07:20:58,741 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:20:58,741 [main] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:20:58,769 [main] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:20:58,776 [main] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:20:58,776 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-12-03 07:20:58,776 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:20:58,777 [main] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 1
2020-12-03 07:20:58,916 [main] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:20:58,917 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 365 msecs
2020-12-03 07:20:59,179 [main] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:20:59,231 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:59,248 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:59,595 [Listener at localhost/39159] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:39159 to access this namenode/service.
2020-12-03 07:20:59,598 [Listener at localhost/39159] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:20:59,615 [Listener at localhost/39159] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:20:59,626 [Listener at localhost/39159] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:20:59,626 [Listener at localhost/39159] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:20:59,627 [Listener at localhost/39159] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:20:59,627 [Listener at localhost/39159] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:20:59,630 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 0
2020-12-03 07:20:59,631 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:20:59,631 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:20:59,631 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:20:59,631 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:20:59,631 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 5 msec
2020-12-03 07:20:59,660 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:59,660 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:59,663 [Listener at localhost/39159] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:39159
2020-12-03 07:20:59,666 [Listener at localhost/39159] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:20:59,667 [Listener at localhost/39159] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:20:59,674 [Listener at localhost/39159] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 8 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:20:59,679 [CacheReplicationMonitor(160473686)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:20:59,688 [Listener at localhost/39159] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:20:59,755 [Listener at localhost/39159] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:20:59,771 [Listener at localhost/39159] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:20:59,790 [Listener at localhost/39159] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:59,794 [Listener at localhost/39159] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:59,797 [Listener at localhost/39159] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:59,801 [Listener at localhost/39159] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:59,803 [Listener at localhost/39159] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:59,803 [Listener at localhost/39159] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:20:59,804 [Listener at localhost/39159] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:20:59,809 [Listener at localhost/39159] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:59,815 [Listener at localhost/39159] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:35575
2020-12-03 07:20:59,817 [Listener at localhost/39159] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:59,817 [Listener at localhost/39159] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:59,836 [Listener at localhost/39159] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:59,838 [Listener at localhost/39159] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:59,839 [Listener at localhost/39159] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:59,839 [Listener at localhost/39159] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:59,841 [Listener at localhost/39159] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:59,842 [Listener at localhost/39159] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:59,843 [Listener at localhost/39159] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:59,843 [Listener at localhost/39159] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:59,847 [Listener at localhost/39159] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 46535
2020-12-03 07:20:59,847 [Listener at localhost/39159] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:59,852 [Listener at localhost/39159] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@297ea53a{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:59,853 [Listener at localhost/39159] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5bf22f18{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:59,861 [Listener at localhost/39159] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@ab7a938{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:20:59,862 [Listener at localhost/39159] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3faf2e7d{HTTP/1.1,[http/1.1]}{localhost:46535}
2020-12-03 07:20:59,863 [Listener at localhost/39159] INFO  server.Server (Server.java:doStart(419)) - Started @4858ms
2020-12-03 07:21:00,197 [Listener at localhost/39159] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:37537
2020-12-03 07:21:00,198 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1f130eaf] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:21:00,199 [Listener at localhost/39159] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:21:00,199 [Listener at localhost/39159] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:21:00,373 [Listener at localhost/39159] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:21:00,390 [Listener at localhost/33627] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:33627
2020-12-03 07:21:00,404 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:21:00,421 [Listener at localhost/33627] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:21:00,423 [Listener at localhost/33627] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:21:00,438 [Thread-59] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:39159 starting to offer service
2020-12-03 07:21:00,452 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:21:00,453 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:21:00,456 [Listener at localhost/33627] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:21:00,458 [Listener at localhost/33627] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:21:00,458 [Listener at localhost/33627] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:21:00,459 [Listener at localhost/33627] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:21:00,460 [Listener at localhost/33627] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:00,460 [Listener at localhost/33627] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:21:00,461 [Listener at localhost/33627] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:21:00,461 [Listener at localhost/33627] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:00,461 [Listener at localhost/33627] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:00,461 [Listener at localhost/33627] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:00,462 [Listener at localhost/33627] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:21:00,463 [Listener at localhost/33627] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:38989
2020-12-03 07:21:00,463 [Listener at localhost/33627] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:21:00,463 [Listener at localhost/33627] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:21:00,465 [Listener at localhost/33627] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:00,467 [Listener at localhost/33627] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:21:00,468 [Listener at localhost/33627] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:21:00,468 [Listener at localhost/33627] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:00,471 [Listener at localhost/33627] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:21:00,472 [Listener at localhost/33627] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:21:00,472 [Listener at localhost/33627] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:21:00,472 [Listener at localhost/33627] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:21:00,473 [Listener at localhost/33627] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 40358
2020-12-03 07:21:00,474 [Listener at localhost/33627] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:21:00,476 [Listener at localhost/33627] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2ad3a1bb{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:21:00,476 [Listener at localhost/33627] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@324c64cd{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:21:00,484 [Listener at localhost/33627] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@e3cee7b{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:21:00,486 [Listener at localhost/33627] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@71e9a896{HTTP/1.1,[http/1.1]}{localhost:40358}
2020-12-03 07:21:00,487 [Listener at localhost/33627] INFO  server.Server (Server.java:doStart(419)) - Started @5481ms
2020-12-03 07:21:00,573 [Listener at localhost/33627] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:40143
2020-12-03 07:21:00,574 [Listener at localhost/33627] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:21:00,574 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@408b35bf] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:21:00,575 [Listener at localhost/33627] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:21:00,576 [Listener at localhost/33627] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:21:00,577 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:21:00,586 [Listener at localhost/36239] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:36239
2020-12-03 07:21:00,593 [Listener at localhost/36239] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:21:00,594 [Listener at localhost/36239] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:21:00,595 [Thread-83] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:39159 starting to offer service
2020-12-03 07:21:00,596 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:21:00,597 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:21:00,601 [Listener at localhost/36239] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:21:00,604 [Listener at localhost/36239] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:21:00,605 [Listener at localhost/36239] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:21:00,606 [Listener at localhost/36239] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:21:00,607 [Listener at localhost/36239] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:00,607 [Listener at localhost/36239] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:21:00,608 [Listener at localhost/36239] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:21:00,608 [Listener at localhost/36239] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:00,608 [Listener at localhost/36239] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:00,608 [Listener at localhost/36239] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:00,610 [Listener at localhost/36239] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:21:00,610 [Listener at localhost/36239] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:37521
2020-12-03 07:21:00,611 [Listener at localhost/36239] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:21:00,611 [Listener at localhost/36239] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:21:00,612 [Listener at localhost/36239] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:00,614 [Listener at localhost/36239] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:21:00,615 [Listener at localhost/36239] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:21:00,615 [Listener at localhost/36239] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:00,618 [Listener at localhost/36239] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:21:00,619 [Listener at localhost/36239] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:21:00,619 [Listener at localhost/36239] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:21:00,620 [Listener at localhost/36239] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:21:00,621 [Listener at localhost/36239] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 42713
2020-12-03 07:21:00,621 [Listener at localhost/36239] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:21:00,623 [Listener at localhost/36239] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3e587920{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:21:00,623 [Listener at localhost/36239] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@24f43aa3{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:21:00,629 [Listener at localhost/36239] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7dac3fd8{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:21:00,631 [Listener at localhost/36239] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@425357dd{HTTP/1.1,[http/1.1]}{localhost:42713}
2020-12-03 07:21:00,631 [Listener at localhost/36239] INFO  server.Server (Server.java:doStart(419)) - Started @5626ms
2020-12-03 07:21:00,654 [Listener at localhost/36239] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:46702
2020-12-03 07:21:00,655 [Listener at localhost/36239] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:21:00,655 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@210386e0] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:21:00,655 [Listener at localhost/36239] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:21:00,655 [Listener at localhost/36239] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:21:00,656 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:21:00,660 [Listener at localhost/45155] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:45155
2020-12-03 07:21:00,666 [Listener at localhost/45155] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:21:00,666 [Listener at localhost/45155] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:21:00,668 [Thread-105] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:39159 starting to offer service
2020-12-03 07:21:00,669 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:21:00,669 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:21:00,767 [Thread-83] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:39159
2020-12-03 07:21:00,767 [Thread-105] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:39159
2020-12-03 07:21:00,767 [Thread-59] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:39159
2020-12-03 07:21:00,771 [Thread-83] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:21:00,771 [Thread-105] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:21:00,771 [Thread-59] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:21:00,868 [Thread-59] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 2630@9bd33dce04e9
2020-12-03 07:21:00,868 [Thread-83] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 2630@9bd33dce04e9
2020-12-03 07:21:00,868 [Thread-105] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 2630@9bd33dce04e9
2020-12-03 07:21:00,869 [Thread-59] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 1142161323. Formatting...
2020-12-03 07:21:00,869 [Thread-105] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 is not formatted for namespace 1142161323. Formatting...
2020-12-03 07:21:00,871 [Thread-59] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-e2a4702c-e5d8-49ec-98d9-afcba9a4bf2b for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-12-03 07:21:00,871 [Thread-105] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-c38ad29d-afe4-4ee0-be21-3867655f82fb for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 
2020-12-03 07:21:00,871 [Thread-83] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 is not formatted for namespace 1142161323. Formatting...
2020-12-03 07:21:00,872 [Thread-83] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-9a7d7b8b-ec12-469a-9a7d-60ed5e71167a for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 
2020-12-03 07:21:01,113 [Thread-83] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 2630@9bd33dce04e9
2020-12-03 07:21:01,113 [Thread-105] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 2630@9bd33dce04e9
2020-12-03 07:21:01,113 [Thread-59] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 2630@9bd33dce04e9
2020-12-03 07:21:01,113 [Thread-83] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 is not formatted for namespace 1142161323. Formatting...
2020-12-03 07:21:01,114 [Thread-105] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 is not formatted for namespace 1142161323. Formatting...
2020-12-03 07:21:01,114 [Thread-59] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 1142161323. Formatting...
2020-12-03 07:21:01,114 [Thread-105] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-07458f0c-3587-41d4-abeb-821d73c89765 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 
2020-12-03 07:21:01,115 [Thread-83] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-d40683d6-ae9f-4bbb-bc67-169f6d82dbbb for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 
2020-12-03 07:21:01,114 [Thread-59] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-7f94b3d0-d801-4a3a-80c5-f0a5c86996d0 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-12-03 07:21:01,197 [IPC Server handler 3 on default port 39159] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:01,206 [Listener at localhost/45155] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:01,206 [Listener at localhost/45155] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:01,308 [IPC Server handler 4 on default port 39159] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:01,309 [Listener at localhost/45155] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:01,310 [Listener at localhost/45155] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:01,390 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:01,390 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:01,390 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:01,390 [Thread-59] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:01,390 [Thread-83] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:01,391 [Thread-105] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:01,391 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 and block pool id BP-425068830-172.17.0.8-1606980057018 is not formatted. Formatting ...
2020-12-03 07:21:01,391 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 and block pool id BP-425068830-172.17.0.8-1606980057018 is not formatted. Formatting ...
2020-12-03 07:21:01,391 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-425068830-172.17.0.8-1606980057018 is not formatted. Formatting ...
2020-12-03 07:21:01,391 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-425068830-172.17.0.8-1606980057018 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-425068830-172.17.0.8-1606980057018/current
2020-12-03 07:21:01,391 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-425068830-172.17.0.8-1606980057018 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-425068830-172.17.0.8-1606980057018/current
2020-12-03 07:21:01,391 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-425068830-172.17.0.8-1606980057018 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-425068830-172.17.0.8-1606980057018/current
2020-12-03 07:21:01,412 [IPC Server handler 5 on default port 39159] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:01,413 [Listener at localhost/45155] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:01,414 [Listener at localhost/45155] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:01,516 [IPC Server handler 6 on default port 39159] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:01,517 [Listener at localhost/45155] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:01,517 [Listener at localhost/45155] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:01,619 [IPC Server handler 7 on default port 39159] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:01,620 [Listener at localhost/45155] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:01,620 [Listener at localhost/45155] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:01,636 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:01,636 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:01,636 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:01,636 [Thread-83] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:01,637 [Thread-105] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:01,637 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 and block pool id BP-425068830-172.17.0.8-1606980057018 is not formatted. Formatting ...
2020-12-03 07:21:01,637 [Thread-59] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:01,637 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-425068830-172.17.0.8-1606980057018 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-425068830-172.17.0.8-1606980057018/current
2020-12-03 07:21:01,637 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 and block pool id BP-425068830-172.17.0.8-1606980057018 is not formatted. Formatting ...
2020-12-03 07:21:01,638 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-425068830-172.17.0.8-1606980057018 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-425068830-172.17.0.8-1606980057018/current
2020-12-03 07:21:01,638 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-425068830-172.17.0.8-1606980057018 is not formatted. Formatting ...
2020-12-03 07:21:01,638 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-425068830-172.17.0.8-1606980057018 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-425068830-172.17.0.8-1606980057018/current
2020-12-03 07:21:01,722 [IPC Server handler 0 on default port 39159] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:01,723 [Listener at localhost/45155] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:01,723 [Listener at localhost/45155] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:01,825 [IPC Server handler 3 on default port 39159] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:01,826 [Listener at localhost/45155] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:01,827 [Listener at localhost/45155] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:01,853 [Thread-59] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1142161323;bpid=BP-425068830-172.17.0.8-1606980057018;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1142161323;c=1606980057018;bpid=BP-425068830-172.17.0.8-1606980057018;dnuuid=null
2020-12-03 07:21:01,853 [Thread-105] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1142161323;bpid=BP-425068830-172.17.0.8-1606980057018;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1142161323;c=1606980057018;bpid=BP-425068830-172.17.0.8-1606980057018;dnuuid=null
2020-12-03 07:21:01,854 [Thread-83] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1142161323;bpid=BP-425068830-172.17.0.8-1606980057018;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1142161323;c=1606980057018;bpid=BP-425068830-172.17.0.8-1606980057018;dnuuid=null
2020-12-03 07:21:01,929 [IPC Server handler 4 on default port 39159] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:01,930 [Listener at localhost/45155] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:01,930 [Listener at localhost/45155] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:02,032 [IPC Server handler 5 on default port 39159] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:02,034 [Listener at localhost/45155] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:02,034 [Listener at localhost/45155] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:02,084 [Thread-83] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 0b0f70d2-7565-48f3-b01c-1adf7b4ab560
2020-12-03 07:21:02,084 [Thread-105] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 5326576b-2216-4538-9245-8b0fb17c9d46
2020-12-03 07:21:02,084 [Thread-59] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 81972425-7fba-4dbf-b586-2759576dcb2a
2020-12-03 07:21:02,135 [IPC Server handler 6 on default port 39159] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:02,136 [Listener at localhost/45155] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:02,136 [Listener at localhost/45155] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:02,212 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-9a7d7b8b-ec12-469a-9a7d-60ed5e71167a
2020-12-03 07:21:02,212 [Thread-105] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-c38ad29d-afe4-4ee0-be21-3867655f82fb
2020-12-03 07:21:02,213 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-e2a4702c-e5d8-49ec-98d9-afcba9a4bf2b
2020-12-03 07:21:02,213 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: DISK
2020-12-03 07:21:02,213 [Thread-105] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, StorageType: DISK
2020-12-03 07:21:02,214 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-12-03 07:21:02,215 [Thread-105] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-07458f0c-3587-41d4-abeb-821d73c89765
2020-12-03 07:21:02,216 [Thread-105] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, StorageType: DISK
2020-12-03 07:21:02,217 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-d40683d6-ae9f-4bbb-bc67-169f6d82dbbb
2020-12-03 07:21:02,217 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: DISK
2020-12-03 07:21:02,219 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-7f94b3d0-d801-4a3a-80c5-f0a5c86996d0
2020-12-03 07:21:02,220 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-12-03 07:21:02,221 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:21:02,221 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:21:02,221 [Thread-105] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:21:02,227 [Thread-83] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:21:02,228 [Thread-105] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:21:02,229 [Thread-59] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:21:02,236 [Thread-59] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:21:02,238 [Thread-83] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:21:02,236 [Thread-105] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:21:02,240 [IPC Server handler 7 on default port 39159] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:02,240 [Thread-83] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:21:02,240 [Thread-105] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:21:02,240 [Thread-59] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:21:02,240 [Thread-105] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:21:02,240 [Thread-83] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:21:02,241 [Thread-59] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:21:02,244 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:02,244 [Thread-105] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:02,244 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:02,245 [Listener at localhost/45155] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:02,245 [Listener at localhost/45155] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:02,245 [Thread-125] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:21:02,245 [Thread-126] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:21:02,246 [Thread-127] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:21:02,246 [Thread-130] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:21:02,246 [Thread-128] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:21:02,246 [Thread-129] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:21:02,286 [Thread-130] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-425068830-172.17.0.8-1606980057018 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 39ms
2020-12-03 07:21:02,286 [Thread-128] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-425068830-172.17.0.8-1606980057018 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 39ms
2020-12-03 07:21:02,286 [Thread-127] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-425068830-172.17.0.8-1606980057018 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 41ms
2020-12-03 07:21:02,287 [Thread-125] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-425068830-172.17.0.8-1606980057018 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 41ms
2020-12-03 07:21:02,286 [Thread-129] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-425068830-172.17.0.8-1606980057018 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 40ms
2020-12-03 07:21:02,286 [Thread-126] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-425068830-172.17.0.8-1606980057018 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 40ms
2020-12-03 07:21:02,287 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-425068830-172.17.0.8-1606980057018: 42ms
2020-12-03 07:21:02,287 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-425068830-172.17.0.8-1606980057018: 41ms
2020-12-03 07:21:02,287 [Thread-105] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-425068830-172.17.0.8-1606980057018: 43ms
2020-12-03 07:21:02,289 [Thread-137] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:21:02,290 [Thread-138] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:21:02,290 [Thread-139] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:21:02,290 [Thread-137] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-425068830-172.17.0.8-1606980057018/current/replicas doesn't exist 
2020-12-03 07:21:02,290 [Thread-138] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-425068830-172.17.0.8-1606980057018/current/replicas doesn't exist 
2020-12-03 07:21:02,290 [Thread-140] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:21:02,290 [Thread-142] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:21:02,290 [Thread-141] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:21:02,291 [Thread-142] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-425068830-172.17.0.8-1606980057018/current/replicas doesn't exist 
2020-12-03 07:21:02,291 [Thread-140] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-425068830-172.17.0.8-1606980057018/current/replicas doesn't exist 
2020-12-03 07:21:02,291 [Thread-141] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-425068830-172.17.0.8-1606980057018/current/replicas doesn't exist 
2020-12-03 07:21:02,292 [Thread-137] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 2ms
2020-12-03 07:21:02,293 [Thread-140] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 2ms
2020-12-03 07:21:02,293 [Thread-139] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-425068830-172.17.0.8-1606980057018/current/replicas doesn't exist 
2020-12-03 07:21:02,293 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-425068830-172.17.0.8-1606980057018: 4ms
2020-12-03 07:21:02,294 [Thread-142] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 3ms
2020-12-03 07:21:02,294 [Thread-139] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 4ms
2020-12-03 07:21:02,294 [Thread-141] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 4ms
2020-12-03 07:21:02,294 [Thread-105] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-425068830-172.17.0.8-1606980057018: 6ms
2020-12-03 07:21:02,295 [Thread-138] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 6ms
2020-12-03 07:21:02,295 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-425068830-172.17.0.8-1606980057018: 7ms
2020-12-03 07:21:02,296 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:21:02,296 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:21:02,296 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:21:02,296 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:21:02,296 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:21:02,296 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:21:02,298 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-d40683d6-ae9f-4bbb-bc67-169f6d82dbbb): finished scanning block pool BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:02,298 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-c38ad29d-afe4-4ee0-be21-3867655f82fb): finished scanning block pool BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:02,298 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-7f94b3d0-d801-4a3a-80c5-f0a5c86996d0): finished scanning block pool BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:02,298 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-07458f0c-3587-41d4-abeb-821d73c89765): finished scanning block pool BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:02,298 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-9a7d7b8b-ec12-469a-9a7d-60ed5e71167a): finished scanning block pool BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:02,298 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-e2a4702c-e5d8-49ec-98d9-afcba9a4bf2b): finished scanning block pool BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:02,321 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-9a7d7b8b-ec12-469a-9a7d-60ed5e71167a): no suitable block pools found to scan.  Waiting 1814399975 ms.
2020-12-03 07:21:02,321 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-7f94b3d0-d801-4a3a-80c5-f0a5c86996d0): no suitable block pools found to scan.  Waiting 1814399975 ms.
2020-12-03 07:21:02,321 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-e2a4702c-e5d8-49ec-98d9-afcba9a4bf2b): no suitable block pools found to scan.  Waiting 1814399975 ms.
2020-12-03 07:21:02,322 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-d40683d6-ae9f-4bbb-bc67-169f6d82dbbb): no suitable block pools found to scan.  Waiting 1814399974 ms.
2020-12-03 07:21:02,321 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-07458f0c-3587-41d4-abeb-821d73c89765): no suitable block pools found to scan.  Waiting 1814399975 ms.
2020-12-03 07:21:02,321 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-c38ad29d-afe4-4ee0-be21-3867655f82fb): no suitable block pools found to scan.  Waiting 1814399975 ms.
2020-12-03 07:21:02,322 [Thread-59] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 9:35 AM with interval of 21600000ms
2020-12-03 07:21:02,322 [Thread-83] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 12:44 PM with interval of 21600000ms
2020-12-03 07:21:02,322 [Thread-105] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 10:45 AM with interval of 21600000ms
2020-12-03 07:21:02,330 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:39159] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-425068830-172.17.0.8-1606980057018 (Datanode Uuid 81972425-7fba-4dbf-b586-2759576dcb2a) service to localhost/127.0.0.1:39159 beginning handshake with NN
2020-12-03 07:21:02,330 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:39159] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-425068830-172.17.0.8-1606980057018 (Datanode Uuid 0b0f70d2-7565-48f3-b01c-1adf7b4ab560) service to localhost/127.0.0.1:39159 beginning handshake with NN
2020-12-03 07:21:02,330 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:39159] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-425068830-172.17.0.8-1606980057018 (Datanode Uuid 5326576b-2216-4538-9245-8b0fb17c9d46) service to localhost/127.0.0.1:39159 beginning handshake with NN
2020-12-03 07:21:02,342 [IPC Server handler 8 on default port 39159] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35575, datanodeUuid=81972425-7fba-4dbf-b586-2759576dcb2a, infoPort=37537, infoSecurePort=0, ipcPort=33627, storageInfo=lv=-57;cid=testClusterID;nsid=1142161323;c=1606980057018) storage 81972425-7fba-4dbf-b586-2759576dcb2a
2020-12-03 07:21:02,345 [IPC Server handler 8 on default port 39159] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:35575
2020-12-03 07:21:02,345 [IPC Server handler 8 on default port 39159] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 81972425-7fba-4dbf-b586-2759576dcb2a (127.0.0.1:35575).
2020-12-03 07:21:02,348 [IPC Server handler 9 on default port 39159] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:37521, datanodeUuid=5326576b-2216-4538-9245-8b0fb17c9d46, infoPort=46702, infoSecurePort=0, ipcPort=45155, storageInfo=lv=-57;cid=testClusterID;nsid=1142161323;c=1606980057018) storage 5326576b-2216-4538-9245-8b0fb17c9d46
2020-12-03 07:21:02,348 [IPC Server handler 9 on default port 39159] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:37521
2020-12-03 07:21:02,349 [IPC Server handler 9 on default port 39159] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 5326576b-2216-4538-9245-8b0fb17c9d46 (127.0.0.1:37521).
2020-12-03 07:21:02,349 [IPC Server handler 0 on default port 39159] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:38989, datanodeUuid=0b0f70d2-7565-48f3-b01c-1adf7b4ab560, infoPort=40143, infoSecurePort=0, ipcPort=36239, storageInfo=lv=-57;cid=testClusterID;nsid=1142161323;c=1606980057018) storage 0b0f70d2-7565-48f3-b01c-1adf7b4ab560
2020-12-03 07:21:02,349 [IPC Server handler 0 on default port 39159] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38989
2020-12-03 07:21:02,349 [IPC Server handler 0 on default port 39159] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 0b0f70d2-7565-48f3-b01c-1adf7b4ab560 (127.0.0.1:38989).
2020-12-03 07:21:02,352 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:39159] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-425068830-172.17.0.8-1606980057018 (Datanode Uuid 5326576b-2216-4538-9245-8b0fb17c9d46) service to localhost/127.0.0.1:39159 successfully registered with NN
2020-12-03 07:21:02,353 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:39159] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:39159 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-12-03 07:21:02,353 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:39159] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-425068830-172.17.0.8-1606980057018 (Datanode Uuid 0b0f70d2-7565-48f3-b01c-1adf7b4ab560) service to localhost/127.0.0.1:39159 successfully registered with NN
2020-12-03 07:21:02,353 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:39159] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:39159 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-12-03 07:21:02,353 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:39159] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-425068830-172.17.0.8-1606980057018 (Datanode Uuid 81972425-7fba-4dbf-b586-2759576dcb2a) service to localhost/127.0.0.1:39159 successfully registered with NN
2020-12-03 07:21:02,355 [IPC Server handler 1 on default port 39159] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:02,356 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:39159] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:39159 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-12-03 07:21:02,365 [Listener at localhost/45155] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2798)) - No heartbeat from DataNode: 127.0.0.1:35575
2020-12-03 07:21:02,365 [Listener at localhost/45155] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:02,377 [IPC Server handler 2 on default port 39159] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-9a7d7b8b-ec12-469a-9a7d-60ed5e71167a for DN 127.0.0.1:38989
2020-12-03 07:21:02,378 [IPC Server handler 2 on default port 39159] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d40683d6-ae9f-4bbb-bc67-169f6d82dbbb for DN 127.0.0.1:38989
2020-12-03 07:21:02,379 [IPC Server handler 3 on default port 39159] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c38ad29d-afe4-4ee0-be21-3867655f82fb for DN 127.0.0.1:37521
2020-12-03 07:21:02,380 [IPC Server handler 3 on default port 39159] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-07458f0c-3587-41d4-abeb-821d73c89765 for DN 127.0.0.1:37521
2020-12-03 07:21:02,380 [IPC Server handler 4 on default port 39159] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-e2a4702c-e5d8-49ec-98d9-afcba9a4bf2b for DN 127.0.0.1:35575
2020-12-03 07:21:02,380 [IPC Server handler 4 on default port 39159] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-7f94b3d0-d801-4a3a-80c5-f0a5c86996d0 for DN 127.0.0.1:35575
2020-12-03 07:21:02,416 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x5ca0f0ea80d6b553: Processing first storage report for DS-07458f0c-3587-41d4-abeb-821d73c89765 from datanode 5326576b-2216-4538-9245-8b0fb17c9d46
2020-12-03 07:21:02,419 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x5ca0f0ea80d6b553: from storage DS-07458f0c-3587-41d4-abeb-821d73c89765 node DatanodeRegistration(127.0.0.1:37521, datanodeUuid=5326576b-2216-4538-9245-8b0fb17c9d46, infoPort=46702, infoSecurePort=0, ipcPort=45155, storageInfo=lv=-57;cid=testClusterID;nsid=1142161323;c=1606980057018), blocks: 0, hasStaleStorage: true, processing time: 3 msecs, invalidatedBlocks: 0
2020-12-03 07:21:02,419 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xdefe52c50901eb25: Processing first storage report for DS-e2a4702c-e5d8-49ec-98d9-afcba9a4bf2b from datanode 81972425-7fba-4dbf-b586-2759576dcb2a
2020-12-03 07:21:02,419 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xdefe52c50901eb25: from storage DS-e2a4702c-e5d8-49ec-98d9-afcba9a4bf2b node DatanodeRegistration(127.0.0.1:35575, datanodeUuid=81972425-7fba-4dbf-b586-2759576dcb2a, infoPort=37537, infoSecurePort=0, ipcPort=33627, storageInfo=lv=-57;cid=testClusterID;nsid=1142161323;c=1606980057018), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:02,419 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x42e605587d6c4e1c: Processing first storage report for DS-9a7d7b8b-ec12-469a-9a7d-60ed5e71167a from datanode 0b0f70d2-7565-48f3-b01c-1adf7b4ab560
2020-12-03 07:21:02,420 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x42e605587d6c4e1c: from storage DS-9a7d7b8b-ec12-469a-9a7d-60ed5e71167a node DatanodeRegistration(127.0.0.1:38989, datanodeUuid=0b0f70d2-7565-48f3-b01c-1adf7b4ab560, infoPort=40143, infoSecurePort=0, ipcPort=36239, storageInfo=lv=-57;cid=testClusterID;nsid=1142161323;c=1606980057018), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:02,420 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x5ca0f0ea80d6b553: Processing first storage report for DS-c38ad29d-afe4-4ee0-be21-3867655f82fb from datanode 5326576b-2216-4538-9245-8b0fb17c9d46
2020-12-03 07:21:02,420 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x5ca0f0ea80d6b553: from storage DS-c38ad29d-afe4-4ee0-be21-3867655f82fb node DatanodeRegistration(127.0.0.1:37521, datanodeUuid=5326576b-2216-4538-9245-8b0fb17c9d46, infoPort=46702, infoSecurePort=0, ipcPort=45155, storageInfo=lv=-57;cid=testClusterID;nsid=1142161323;c=1606980057018), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:02,420 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x42e605587d6c4e1c: Processing first storage report for DS-d40683d6-ae9f-4bbb-bc67-169f6d82dbbb from datanode 0b0f70d2-7565-48f3-b01c-1adf7b4ab560
2020-12-03 07:21:02,421 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x42e605587d6c4e1c: from storage DS-d40683d6-ae9f-4bbb-bc67-169f6d82dbbb node DatanodeRegistration(127.0.0.1:38989, datanodeUuid=0b0f70d2-7565-48f3-b01c-1adf7b4ab560, infoPort=40143, infoSecurePort=0, ipcPort=36239, storageInfo=lv=-57;cid=testClusterID;nsid=1142161323;c=1606980057018), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:02,421 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xdefe52c50901eb25: Processing first storage report for DS-7f94b3d0-d801-4a3a-80c5-f0a5c86996d0 from datanode 81972425-7fba-4dbf-b586-2759576dcb2a
2020-12-03 07:21:02,421 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xdefe52c50901eb25: from storage DS-7f94b3d0-d801-4a3a-80c5-f0a5c86996d0 node DatanodeRegistration(127.0.0.1:35575, datanodeUuid=81972425-7fba-4dbf-b586-2759576dcb2a, infoPort=37537, infoSecurePort=0, ipcPort=33627, storageInfo=lv=-57;cid=testClusterID;nsid=1142161323;c=1606980057018), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:02,442 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:39159] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x42e605587d6c4e1c,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 45 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:21:02,442 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:39159] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x5ca0f0ea80d6b553,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 45 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:21:02,442 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:39159] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xdefe52c50901eb25,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 45 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:21:02,443 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:39159] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:02,443 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:39159] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:02,442 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:39159] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:02,467 [IPC Server handler 9 on default port 39159] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:02,471 [Listener at localhost/45155] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:21:02,489 [IPC Server handler 8 on default port 39159] DEBUG hdfs.StateChange (NameNodeRpcServer.java:mkdirs(1139)) - *DIR* NameNode.mkdirs: /test
2020-12-03 07:21:02,491 [IPC Server handler 8 on default port 39159] DEBUG hdfs.StateChange (FSDirMkdirOp.java:mkdirs(46)) - DIR* NameSystem.mkdirs: /test
2020-12-03 07:21:02,503 [IPC Server handler 8 on default port 39159] DEBUG hdfs.StateChange (FSDirMkdirOp.java:createSingleDirectory(182)) - mkdirs: created directory /test
2020-12-03 07:21:02,505 [IPC Server handler 8 on default port 39159] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:21:02,531 [IPC Server handler 0 on default port 39159] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setSpaceQuota	src=/test	dst=null	perm=null	proto=rpc
2020-12-03 07:21:02,539 [IPC Server handler 1 on default port 39159] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=allowSnapshot	src=/test	dst=null	perm=null	proto=rpc
2020-12-03 07:21:02,543 [Listener at localhost/45155] INFO  hdfs.AppendTestUtil (AppendTestUtil.java:<clinit>(53)) - seed=6770525721621450729
2020-12-03 07:21:02,544 [Listener at localhost/45155] INFO  hdfs.AppendTestUtil (AppendTestUtil.java:initialValue(64)) - Listener at localhost/45155: seed=-7251988732108696358
2020-12-03 07:21:02,544 [Listener at localhost/45155] INFO  hdfs.AppendTestUtil (AppendTestUtil.java:randomBytes(79)) - seed=-1634843625, size=8
2020-12-03 07:21:02,561 [IPC Server handler 4 on default port 39159] DEBUG hdfs.StateChange (NameNodeRpcServer.java:create(774)) - *DIR* NameNode.create: file /test/testUpgrade for DFSClient_NONMAPREDUCE_742258692_1 at 127.0.0.1
2020-12-03 07:21:02,562 [IPC Server handler 4 on default port 39159] DEBUG hdfs.StateChange (FSNamesystem.java:startFileInt(2460)) - DIR* NameSystem.startFile: src=/test/testUpgrade, holder=DFSClient_NONMAPREDUCE_742258692_1, clientMachine=127.0.0.1, createParent=true, replication=3, createFlag=[CREATE, OVERWRITE], blockSize=4, supportedVersions=[CryptoProtocolVersion{description='Encryption zones', version=2, unknownValue=null}]
2020-12-03 07:21:02,575 [IPC Server handler 4 on default port 39159] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addFile(579)) - DIR* addFile: testUpgrade is added
2020-12-03 07:21:02,577 [IPC Server handler 4 on default port 39159] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:startFile(415)) - DIR* NameSystem.startFile: added /test/testUpgrade inode 16387 DFSClient_NONMAPREDUCE_742258692_1
2020-12-03 07:21:02,589 [IPC Server handler 4 on default port 39159] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/test/testUpgrade	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:21:02,626 [IPC Server handler 3 on default port 39159] DEBUG hdfs.StateChange (FSNamesystem.java:getAdditionalBlock(2767)) - BLOCK* getAdditionalBlock: /test/testUpgrade  inodeId 16387 for DFSClient_NONMAPREDUCE_742258692_1
2020-12-03 07:21:02,638 [IPC Server handler 3 on default port 39159] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addBlock(524)) - DIR* FSDirectory.addBlock: /test/testUpgrade with blk_1073741825_1001 block is added to the in-memory file system
2020-12-03 07:21:02,639 [IPC Server handler 3 on default port 39159] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:38989, 127.0.0.1:37521, 127.0.0.1:35575 for /test/testUpgrade
2020-12-03 07:21:02,639 [IPC Server handler 3 on default port 39159] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:persistNewBlock(758)) - persistNewBlock: /test/testUpgrade with new block blk_1073741825_1001, current total block count is 1
2020-12-03 07:21:02,656 [Thread-152] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:02,719 [DataXceiver for client DFSClient_NONMAPREDUCE_742258692_1 at /127.0.0.1:59518 [Receiving block BP-425068830-172.17.0.8-1606980057018:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-425068830-172.17.0.8-1606980057018:blk_1073741825_1001 src: /127.0.0.1:59518 dest: /127.0.0.1:38989
2020-12-03 07:21:02,740 [DataXceiver for client DFSClient_NONMAPREDUCE_742258692_1 at /127.0.0.1:59518 [Receiving block BP-425068830-172.17.0.8-1606980057018:blk_1073741825_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:02,742 [DataXceiver for client DFSClient_NONMAPREDUCE_742258692_1 at /127.0.0.1:46786 [Receiving block BP-425068830-172.17.0.8-1606980057018:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-425068830-172.17.0.8-1606980057018:blk_1073741825_1001 src: /127.0.0.1:46786 dest: /127.0.0.1:37521
2020-12-03 07:21:02,743 [DataXceiver for client DFSClient_NONMAPREDUCE_742258692_1 at /127.0.0.1:46786 [Receiving block BP-425068830-172.17.0.8-1606980057018:blk_1073741825_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:02,745 [DataXceiver for client DFSClient_NONMAPREDUCE_742258692_1 at /127.0.0.1:54964 [Receiving block BP-425068830-172.17.0.8-1606980057018:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-425068830-172.17.0.8-1606980057018:blk_1073741825_1001 src: /127.0.0.1:54964 dest: /127.0.0.1:35575
2020-12-03 07:21:02,785 [PacketResponder: BP-425068830-172.17.0.8-1606980057018:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54964, dest: /127.0.0.1:35575, bytes: 4, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_742258692_1, offset: 0, srvID: 81972425-7fba-4dbf-b586-2759576dcb2a, blockid: BP-425068830-172.17.0.8-1606980057018:blk_1073741825_1001, duration(ns): 23285174
2020-12-03 07:21:02,785 [PacketResponder: BP-425068830-172.17.0.8-1606980057018:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-425068830-172.17.0.8-1606980057018:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:21:02,789 [PacketResponder: BP-425068830-172.17.0.8-1606980057018:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:35575]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:46786, dest: /127.0.0.1:37521, bytes: 4, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_742258692_1, offset: 0, srvID: 5326576b-2216-4538-9245-8b0fb17c9d46, blockid: BP-425068830-172.17.0.8-1606980057018:blk_1073741825_1001, duration(ns): 29263381
2020-12-03 07:21:02,790 [PacketResponder: BP-425068830-172.17.0.8-1606980057018:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:35575]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-425068830-172.17.0.8-1606980057018:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:35575] terminating
2020-12-03 07:21:02,794 [PacketResponder: BP-425068830-172.17.0.8-1606980057018:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37521, 127.0.0.1:35575]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59518, dest: /127.0.0.1:38989, bytes: 4, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_742258692_1, offset: 0, srvID: 0b0f70d2-7565-48f3-b01c-1adf7b4ab560, blockid: BP-425068830-172.17.0.8-1606980057018:blk_1073741825_1001, duration(ns): 34245299
2020-12-03 07:21:02,795 [PacketResponder: BP-425068830-172.17.0.8-1606980057018:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37521, 127.0.0.1:35575]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-425068830-172.17.0.8-1606980057018:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37521, 127.0.0.1:35575] terminating
2020-12-03 07:21:02,799 [IPC Server handler 7 on default port 39159] DEBUG hdfs.StateChange (FSNamesystem.java:getAdditionalBlock(2767)) - BLOCK* getAdditionalBlock: /test/testUpgrade  inodeId 16387 for DFSClient_NONMAPREDUCE_742258692_1
2020-12-03 07:21:02,807 [IPC Server handler 7 on default port 39159] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addBlock(524)) - DIR* FSDirectory.addBlock: /test/testUpgrade with blk_1073741826_1002 block is added to the in-memory file system
2020-12-03 07:21:02,807 [IPC Server handler 7 on default port 39159] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741826_1002, replicas=127.0.0.1:37521, 127.0.0.1:38989, 127.0.0.1:35575 for /test/testUpgrade
2020-12-03 07:21:02,807 [IPC Server handler 7 on default port 39159] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:persistNewBlock(758)) - persistNewBlock: /test/testUpgrade with new block blk_1073741826_1002, current total block count is 2
2020-12-03 07:21:02,810 [DataStreamer for file /test/testUpgrade] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:02,814 [DataXceiver for client DFSClient_NONMAPREDUCE_742258692_1 at /127.0.0.1:46792 [Receiving block BP-425068830-172.17.0.8-1606980057018:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-425068830-172.17.0.8-1606980057018:blk_1073741826_1002 src: /127.0.0.1:46792 dest: /127.0.0.1:37521
2020-12-03 07:21:02,815 [DataXceiver for client DFSClient_NONMAPREDUCE_742258692_1 at /127.0.0.1:46792 [Receiving block BP-425068830-172.17.0.8-1606980057018:blk_1073741826_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:02,817 [DataXceiver for client DFSClient_NONMAPREDUCE_742258692_1 at /127.0.0.1:59530 [Receiving block BP-425068830-172.17.0.8-1606980057018:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-425068830-172.17.0.8-1606980057018:blk_1073741826_1002 src: /127.0.0.1:59530 dest: /127.0.0.1:38989
2020-12-03 07:21:02,818 [DataXceiver for client DFSClient_NONMAPREDUCE_742258692_1 at /127.0.0.1:59530 [Receiving block BP-425068830-172.17.0.8-1606980057018:blk_1073741826_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:02,823 [DataXceiver for client DFSClient_NONMAPREDUCE_742258692_1 at /127.0.0.1:54972 [Receiving block BP-425068830-172.17.0.8-1606980057018:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-425068830-172.17.0.8-1606980057018:blk_1073741826_1002 src: /127.0.0.1:54972 dest: /127.0.0.1:35575
2020-12-03 07:21:02,834 [PacketResponder: BP-425068830-172.17.0.8-1606980057018:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54972, dest: /127.0.0.1:35575, bytes: 4, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_742258692_1, offset: 0, srvID: 81972425-7fba-4dbf-b586-2759576dcb2a, blockid: BP-425068830-172.17.0.8-1606980057018:blk_1073741826_1002, duration(ns): 9075422
2020-12-03 07:21:02,835 [PacketResponder: BP-425068830-172.17.0.8-1606980057018:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-425068830-172.17.0.8-1606980057018:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2020-12-03 07:21:02,840 [PacketResponder: BP-425068830-172.17.0.8-1606980057018:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:35575]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59530, dest: /127.0.0.1:38989, bytes: 4, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_742258692_1, offset: 0, srvID: 0b0f70d2-7565-48f3-b01c-1adf7b4ab560, blockid: BP-425068830-172.17.0.8-1606980057018:blk_1073741826_1002, duration(ns): 12390927
2020-12-03 07:21:02,840 [PacketResponder: BP-425068830-172.17.0.8-1606980057018:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:35575]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-425068830-172.17.0.8-1606980057018:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:35575] terminating
2020-12-03 07:21:02,848 [PacketResponder: BP-425068830-172.17.0.8-1606980057018:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:38989, 127.0.0.1:35575]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:46792, dest: /127.0.0.1:37521, bytes: 4, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_742258692_1, offset: 0, srvID: 5326576b-2216-4538-9245-8b0fb17c9d46, blockid: BP-425068830-172.17.0.8-1606980057018:blk_1073741826_1002, duration(ns): 20858910
2020-12-03 07:21:02,849 [PacketResponder: BP-425068830-172.17.0.8-1606980057018:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:38989, 127.0.0.1:35575]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-425068830-172.17.0.8-1606980057018:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:38989, 127.0.0.1:35575] terminating
2020-12-03 07:21:02,854 [IPC Server handler 4 on default port 39159] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:completeFile(674)) - DIR* NameSystem.completeFile: /test/testUpgrade for DFSClient_NONMAPREDUCE_742258692_1
2020-12-03 07:21:02,855 [IPC Server handler 4 on default port 39159] DEBUG hdfs.StateChange (FSNamesystem.java:closeFile(4036)) - closeFile: /test/testUpgrade with 2 blocks is persisted to the file system
2020-12-03 07:21:02,856 [IPC Server handler 4 on default port 39159] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /test/testUpgrade is closed by DFSClient_NONMAPREDUCE_742258692_1
2020-12-03 07:21:02,874 [IPC Server handler 3 on default port 39159] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=createSnapshot	src=/test	dst=/test/.snapshot/ss0	perm=null	proto=rpc
2020-12-03 07:21:02,881 [IPC Server handler 2 on default port 39159] DEBUG hdfs.StateChange (NameNodeRpcServer.java:truncate(1087)) - *DIR* NameNode.truncate: /test/testUpgrade to 7
2020-12-03 07:21:02,882 [IPC Server handler 2 on default port 39159] DEBUG hdfs.StateChange (FSNamesystem.java:truncate(2136)) - DIR* NameSystem.truncate: src=/test/testUpgrade newLength=7
2020-12-03 07:21:02,889 [IPC Server handler 2 on default port 39159] DEBUG hdfs.StateChange (FSDirTruncateOp.java:prepareFileForTruncate(252)) - BLOCK* prepareFileForTruncate: Scheduling copy-on-truncate to new size 3  new block blk_1073741827_1003 old block blk_1073741826_1002
2020-12-03 07:21:02,892 [IPC Server handler 2 on default port 39159] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=truncate	src=/test/testUpgrade	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:21:02,906 [IPC Server handler 6 on default port 39159] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/test/testUpgrade	dst=null	perm=null	proto=rpc
2020-12-03 07:21:03,021 [IPC Server handler 5 on default port 39159] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/test/testUpgrade	dst=null	perm=null	proto=rpc
2020-12-03 07:21:03,126 [IPC Server handler 7 on default port 39159] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/test/testUpgrade	dst=null	perm=null	proto=rpc
2020-12-03 07:21:03,232 [IPC Server handler 9 on default port 39159] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/test/testUpgrade	dst=null	perm=null	proto=rpc
2020-12-03 07:21:03,338 [IPC Server handler 8 on default port 39159] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/test/testUpgrade	dst=null	perm=null	proto=rpc
2020-12-03 07:21:03,371 [org.apache.hadoop.hdfs.server.datanode.BlockRecoveryWorker$1@2e86e986] INFO  datanode.DataNode (BlockRecoveryWorker.java:logRecoverBlock(549)) - BlockRecoveryWorker: NameNode at localhost/127.0.0.1:39159 calls recoverBlock(BP-425068830-172.17.0.8-1606980057018:blk_1073741826_1002, targets=[DatanodeInfoWithStorage[127.0.0.1:35575,null,null], DatanodeInfoWithStorage[127.0.0.1:38989,null,null], DatanodeInfoWithStorage[127.0.0.1:37521,null,null]], newGenerationStamp=1003, newBlock=blk_1073741827_1003, isStriped=false)
2020-12-03 07:21:03,373 [org.apache.hadoop.hdfs.server.datanode.BlockRecoveryWorker$1@2e86e986] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:initReplicaRecoveryImpl(2588)) - initReplicaRecovery: blk_1073741826_1002, recoveryId=1003, replica=FinalizedReplica, blk_1073741826_1002, FINALIZED
  getNumBytes()     = 4
  getBytesOnDisk()  = 4
  getVisibleLength()= 4
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-425068830-172.17.0.8-1606980057018/current/finalized/subdir0/subdir0/blk_1073741826
2020-12-03 07:21:03,374 [org.apache.hadoop.hdfs.server.datanode.BlockRecoveryWorker$1@2e86e986] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:initReplicaRecoveryImpl(2646)) - initReplicaRecovery: changing replica state for blk_1073741826_1002 from FINALIZED to RUR
2020-12-03 07:21:03,391 [IPC Server handler 2 on default port 36239] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:initReplicaRecoveryImpl(2588)) - initReplicaRecovery: blk_1073741826_1002, recoveryId=1003, replica=FinalizedReplica, blk_1073741826_1002, FINALIZED
  getNumBytes()     = 4
  getBytesOnDisk()  = 4
  getVisibleLength()= 4
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-425068830-172.17.0.8-1606980057018/current/finalized/subdir0/subdir0/blk_1073741826
2020-12-03 07:21:03,393 [IPC Server handler 2 on default port 36239] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:initReplicaRecoveryImpl(2646)) - initReplicaRecovery: changing replica state for blk_1073741826_1002 from FINALIZED to RUR
2020-12-03 07:21:03,402 [IPC Server handler 1 on default port 45155] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:initReplicaRecoveryImpl(2588)) - initReplicaRecovery: blk_1073741826_1002, recoveryId=1003, replica=FinalizedReplica, blk_1073741826_1002, FINALIZED
  getNumBytes()     = 4
  getBytesOnDisk()  = 4
  getVisibleLength()= 4
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-425068830-172.17.0.8-1606980057018/current/finalized/subdir0/subdir0/blk_1073741826
2020-12-03 07:21:03,402 [IPC Server handler 1 on default port 45155] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:initReplicaRecoveryImpl(2646)) - initReplicaRecovery: changing replica state for blk_1073741826_1002 from FINALIZED to RUR
2020-12-03 07:21:03,403 [org.apache.hadoop.hdfs.server.datanode.BlockRecoveryWorker$1@2e86e986] INFO  datanode.DataNode (BlockRecoveryWorker.java:syncBlock(200)) - BlockRecoveryWorker: block=BP-425068830-172.17.0.8-1606980057018:blk_1073741826_1002 (length=4), isTruncateRecovery=true, syncList=[block:blk_1073741826_1002[numBytes=4,originalReplicaState=FINALIZED] node:DatanodeInfoWithStorage[127.0.0.1:35575,null,null], block:blk_1073741826_1002[numBytes=4,originalReplicaState=FINALIZED] node:DatanodeInfoWithStorage[127.0.0.1:38989,null,null], block:blk_1073741826_1002[numBytes=4,originalReplicaState=FINALIZED] node:DatanodeInfoWithStorage[127.0.0.1:37521,null,null]]
2020-12-03 07:21:03,404 [org.apache.hadoop.hdfs.server.datanode.BlockRecoveryWorker$1@2e86e986] INFO  datanode.DataNode (BlockRecoveryWorker.java:syncBlock(293)) - BlockRecoveryWorker: block=BP-425068830-172.17.0.8-1606980057018:blk_1073741826_1002 (length=4), bestState=FINALIZED, newBlock=BP-425068830-172.17.0.8-1606980057018:blk_1073741827_1003 (length=3), participatingList=[block:blk_1073741826_1002[numBytes=4,originalReplicaState=FINALIZED] node:DatanodeInfoWithStorage[127.0.0.1:35575,null,null], block:blk_1073741826_1002[numBytes=4,originalReplicaState=FINALIZED] node:DatanodeInfoWithStorage[127.0.0.1:38989,null,null], block:blk_1073741826_1002[numBytes=4,originalReplicaState=FINALIZED] node:DatanodeInfoWithStorage[127.0.0.1:37521,null,null]]
2020-12-03 07:21:03,405 [org.apache.hadoop.hdfs.server.datanode.BlockRecoveryWorker$1@2e86e986] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:updateReplicaUnderRecovery(2667)) - updateReplica: BP-425068830-172.17.0.8-1606980057018:blk_1073741826_1002[numBytes=4,originalReplicaState=FINALIZED], recoveryId=1003, length=3, replica=ReplicaUnderRecovery, blk_1073741826_1002, RUR
  getNumBytes()     = 4
  getBytesOnDisk()  = 4
  getVisibleLength()= 4
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-425068830-172.17.0.8-1606980057018/current/finalized/subdir0/subdir0/blk_1073741826
  recoveryId=1003
  original=FinalizedReplica, blk_1073741826_1002, FINALIZED
  getNumBytes()     = 4
  getBytesOnDisk()  = 4
  getVisibleLength()= 4
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-425068830-172.17.0.8-1606980057018/current/finalized/subdir0/subdir0/blk_1073741826
2020-12-03 07:21:03,441 [org.apache.hadoop.hdfs.server.datanode.BlockRecoveryWorker$1@2e86e986] INFO  datanode.LocalReplica (LocalReplica.java:truncateBlock(473)) - truncateBlock: blockFile=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-425068830-172.17.0.8-1606980057018/tmp/subdir0/subdir0/blk_1073741827, metaFile=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-425068830-172.17.0.8-1606980057018/tmp/subdir0/subdir0/blk_1073741827_1003.meta, oldlen=4, newlen=3
2020-12-03 07:21:03,445 [IPC Server handler 3 on default port 39159] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/test/testUpgrade	dst=null	perm=null	proto=rpc
2020-12-03 07:21:03,462 [IPC Server handler 1 on default port 36239] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:updateReplicaUnderRecovery(2667)) - updateReplica: BP-425068830-172.17.0.8-1606980057018:blk_1073741826_1002, recoveryId=1003, length=3, replica=ReplicaUnderRecovery, blk_1073741826_1002, RUR
  getNumBytes()     = 4
  getBytesOnDisk()  = 4
  getVisibleLength()= 4
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-425068830-172.17.0.8-1606980057018/current/finalized/subdir0/subdir0/blk_1073741826
  recoveryId=1003
  original=FinalizedReplica, blk_1073741826_1002, FINALIZED
  getNumBytes()     = 4
  getBytesOnDisk()  = 4
  getVisibleLength()= 4
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-425068830-172.17.0.8-1606980057018/current/finalized/subdir0/subdir0/blk_1073741826
2020-12-03 07:21:03,485 [IPC Server handler 1 on default port 36239] INFO  datanode.LocalReplica (LocalReplica.java:truncateBlock(473)) - truncateBlock: blockFile=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-425068830-172.17.0.8-1606980057018/tmp/subdir0/subdir0/blk_1073741827, metaFile=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-425068830-172.17.0.8-1606980057018/tmp/subdir0/subdir0/blk_1073741827_1003.meta, oldlen=4, newlen=3
2020-12-03 07:21:03,499 [IPC Server handler 0 on default port 45155] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:updateReplicaUnderRecovery(2667)) - updateReplica: BP-425068830-172.17.0.8-1606980057018:blk_1073741826_1002, recoveryId=1003, length=3, replica=ReplicaUnderRecovery, blk_1073741826_1002, RUR
  getNumBytes()     = 4
  getBytesOnDisk()  = 4
  getVisibleLength()= 4
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-425068830-172.17.0.8-1606980057018/current/finalized/subdir0/subdir0/blk_1073741826
  recoveryId=1003
  original=FinalizedReplica, blk_1073741826_1002, FINALIZED
  getNumBytes()     = 4
  getBytesOnDisk()  = 4
  getVisibleLength()= 4
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-425068830-172.17.0.8-1606980057018/current/finalized/subdir0/subdir0/blk_1073741826
2020-12-03 07:21:03,531 [IPC Server handler 0 on default port 45155] INFO  datanode.LocalReplica (LocalReplica.java:truncateBlock(473)) - truncateBlock: blockFile=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-425068830-172.17.0.8-1606980057018/tmp/subdir0/subdir0/blk_1073741827, metaFile=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-425068830-172.17.0.8-1606980057018/tmp/subdir0/subdir0/blk_1073741827_1003.meta, oldlen=4, newlen=3
2020-12-03 07:21:03,542 [IPC Server handler 7 on default port 39159] INFO  namenode.FSNamesystem (FSNamesystem.java:commitBlockSynchronization(3655)) - commitBlockSynchronization(oldBlock=BP-425068830-172.17.0.8-1606980057018:blk_1073741826_1002, newgenerationstamp=1003, newlength=3, newtargets=[127.0.0.1:35575, 127.0.0.1:38989, 127.0.0.1:37521], closeFile=true, deleteBlock=false)
2020-12-03 07:21:03,544 [IPC Server handler 7 on default port 39159] DEBUG hdfs.StateChange (FSNamesystem.java:closeFile(4036)) - closeFile: /test/testUpgrade with 2 blocks is persisted to the file system
2020-12-03 07:21:03,544 [IPC Server handler 7 on default port 39159] INFO  namenode.FSNamesystem (FSNamesystem.java:commitBlockSynchronization(3805)) - commitBlockSynchronization(oldBlock=BP-425068830-172.17.0.8-1606980057018:blk_1073741826_1002, file=/test/testUpgrade, newBlock=blk_1073741827_1003, newlength=3, newtargets=[127.0.0.1:35575, 127.0.0.1:38989, 127.0.0.1:37521]) successful
2020-12-03 07:21:03,566 [IPC Server handler 9 on default port 39159] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/test/testUpgrade	dst=null	perm=null	proto=rpc
2020-12-03 07:21:03,575 [IPC Server handler 8 on default port 39159] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testUpgrade	dst=null	perm=null	proto=rpc
2020-12-03 07:21:03,580 [IPC Server handler 0 on default port 39159] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/test/testUpgrade	dst=null	perm=null	proto=rpc
2020-12-03 07:21:03,610 [Listener at localhost/45155] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:03,647 [Listener at localhost/45155] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:03,653 [IPC Server handler 4 on default port 39159] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/test/.snapshot/ss0/testUpgrade	dst=null	perm=null	proto=rpc
2020-12-03 07:21:03,666 [Listener at localhost/45155] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:03,668 [Listener at localhost/45155] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:21:03,669 [Listener at localhost/45155] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 2
2020-12-03 07:21:03,669 [Listener at localhost/45155] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:21:03,670 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@48e64352] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:21:03,671 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-07458f0c-3587-41d4-abeb-821d73c89765) exiting.
2020-12-03 07:21:03,671 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-c38ad29d-afe4-4ee0-be21-3867655f82fb) exiting.
2020-12-03 07:21:03,707 [Listener at localhost/45155] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@7dac3fd8{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:21:03,713 [Listener at localhost/45155] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@425357dd{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:21:03,713 [Listener at localhost/45155] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@24f43aa3{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:21:03,715 [Listener at localhost/45155] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3e587920{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:21:03,726 [Listener at localhost/45155] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 45155
2020-12-03 07:21:03,732 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:03,732 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:03,733 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:39159] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:03,734 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:39159] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-425068830-172.17.0.8-1606980057018 (Datanode Uuid 5326576b-2216-4538-9245-8b0fb17c9d46) service to localhost/127.0.0.1:39159
2020-12-03 07:21:03,734 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:39159] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-425068830-172.17.0.8-1606980057018 (Datanode Uuid 5326576b-2216-4538-9245-8b0fb17c9d46)
2020-12-03 07:21:03,734 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:39159] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:03,736 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-425068830-172.17.0.8-1606980057018] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:03,737 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-425068830-172.17.0.8-1606980057018] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:03,740 [Listener at localhost/45155] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:21:03,741 [Listener at localhost/45155] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:21:03,741 [Listener at localhost/45155] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:21:03,742 [Listener at localhost/45155] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:21:03,750 [Listener at localhost/45155] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:21:03,751 [Listener at localhost/45155] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 1
2020-12-03 07:21:03,751 [Listener at localhost/45155] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:21:03,751 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@2970a5bc] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:21:03,756 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-9a7d7b8b-ec12-469a-9a7d-60ed5e71167a) exiting.
2020-12-03 07:21:03,758 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-d40683d6-ae9f-4bbb-bc67-169f6d82dbbb) exiting.
2020-12-03 07:21:03,788 [Listener at localhost/45155] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@e3cee7b{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:21:03,789 [Listener at localhost/45155] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@71e9a896{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:21:03,790 [Listener at localhost/45155] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@324c64cd{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:21:03,790 [Listener at localhost/45155] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2ad3a1bb{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:21:03,792 [Listener at localhost/45155] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 36239
2020-12-03 07:21:03,813 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:03,813 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:03,813 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:39159] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:03,815 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:39159] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-425068830-172.17.0.8-1606980057018 (Datanode Uuid 0b0f70d2-7565-48f3-b01c-1adf7b4ab560) service to localhost/127.0.0.1:39159
2020-12-03 07:21:03,815 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:39159] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-425068830-172.17.0.8-1606980057018 (Datanode Uuid 0b0f70d2-7565-48f3-b01c-1adf7b4ab560)
2020-12-03 07:21:03,815 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:39159] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:03,816 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-425068830-172.17.0.8-1606980057018] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:03,818 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-425068830-172.17.0.8-1606980057018] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:03,821 [Listener at localhost/45155] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:21:03,821 [Listener at localhost/45155] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:21:03,822 [Listener at localhost/45155] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:21:03,822 [Listener at localhost/45155] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:21:03,824 [Listener at localhost/45155] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:21:03,824 [Listener at localhost/45155] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:21:03,825 [Listener at localhost/45155] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:21:03,825 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@46f699d5] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:21:03,826 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-7f94b3d0-d801-4a3a-80c5-f0a5c86996d0) exiting.
2020-12-03 07:21:03,826 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-e2a4702c-e5d8-49ec-98d9-afcba9a4bf2b) exiting.
2020-12-03 07:21:03,969 [Listener at localhost/45155] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@ab7a938{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:21:03,970 [Listener at localhost/45155] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@3faf2e7d{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:21:03,971 [Listener at localhost/45155] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5bf22f18{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:21:03,972 [Listener at localhost/45155] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@297ea53a{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:21:03,974 [Listener at localhost/45155] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 33627
2020-12-03 07:21:03,982 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:03,983 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:03,983 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:39159] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:03,983 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:39159] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-425068830-172.17.0.8-1606980057018 (Datanode Uuid 81972425-7fba-4dbf-b586-2759576dcb2a) service to localhost/127.0.0.1:39159
2020-12-03 07:21:03,985 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:39159] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-425068830-172.17.0.8-1606980057018 (Datanode Uuid 81972425-7fba-4dbf-b586-2759576dcb2a)
2020-12-03 07:21:03,985 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:39159] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:03,986 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-425068830-172.17.0.8-1606980057018] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:03,987 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-425068830-172.17.0.8-1606980057018] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:04,010 [Listener at localhost/45155] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:21:04,011 [Listener at localhost/45155] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:21:04,013 [Listener at localhost/45155] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:21:04,013 [Listener at localhost/45155] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:21:04,017 [Listener at localhost/45155] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:21:04,018 [Listener at localhost/45155] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:21:04,018 [Listener at localhost/45155] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:21:04,019 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@60f7cc1d] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:21:04,019 [Listener at localhost/45155] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 1, 17
2020-12-03 07:21:04,019 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@37bd68c3] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:21:04,020 [Listener at localhost/45155] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 18 Total time for transactions(ms): 22 Number of transactions batched in Syncs: 2 Number of syncs: 17 SyncTimes(ms): 8 1 
2020-12-03 07:21:04,022 [Listener at localhost/45155] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000018
2020-12-03 07:21:04,023 [Listener at localhost/45155] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000018
2020-12-03 07:21:04,024 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:21:04,025 [CacheReplicationMonitor(160473686)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:21:04,031 [Listener at localhost/45155] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 39159
2020-12-03 07:21:04,035 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:04,035 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:04,037 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:21:04,037 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:21:04,097 [Listener at localhost/45155] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:21:04,098 [Listener at localhost/45155] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:21:04,099 [Listener at localhost/45155] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@895e367{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:21:04,101 [Listener at localhost/45155] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@50313382{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:21:04,101 [Listener at localhost/45155] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5c7bfdc1{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:21:04,102 [Listener at localhost/45155] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@475c9c31{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:21:04,105 [Listener at localhost/45155] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-12-03 07:21:04,112 [Listener at localhost/45155] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-12-03 07:21:04,113 [Listener at localhost/45155] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-12-03 07:21:04,138 [Listener at localhost/45155] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=3
2020-12-03 07:21:04,141 [Listener at localhost/45155] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode [-upgrade]
2020-12-03 07:21:04,145 [Listener at localhost/45155] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:21:04,148 [Listener at localhost/45155] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:21:04,148 [Listener at localhost/45155] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:21:04,149 [Listener at localhost/45155] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-12-03 07:21:04,164 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7923f5b3] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:21:04,164 [Listener at localhost/45155] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:21:04,165 [Listener at localhost/45155] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:04,167 [Listener at localhost/45155] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:21:04,168 [Listener at localhost/45155] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:21:04,169 [Listener at localhost/45155] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:04,172 [Listener at localhost/45155] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:21:04,173 [Listener at localhost/45155] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:21:04,173 [Listener at localhost/45155] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:21:04,174 [Listener at localhost/45155] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:21:04,176 [Listener at localhost/45155] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:21:04,177 [Listener at localhost/45155] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:21:04,178 [Listener at localhost/45155] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 46791
2020-12-03 07:21:04,178 [Listener at localhost/45155] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:21:04,182 [Listener at localhost/45155] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@11a7ba62{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:21:04,183 [Listener at localhost/45155] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@30404dba{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:21:04,194 [Listener at localhost/45155] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@79a1728c{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:21:04,199 [Listener at localhost/45155] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@a7f0ab6{HTTP/1.1,[http/1.1]}{localhost:46791}
2020-12-03 07:21:04,200 [Listener at localhost/45155] INFO  server.Server (Server.java:doStart(419)) - Started @9194ms
2020-12-03 07:21:04,229 [Listener at localhost/45155] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:21:04,230 [Listener at localhost/45155] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:21:04,230 [Listener at localhost/45155] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:21:04,230 [Listener at localhost/45155] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:21:04,231 [Listener at localhost/45155] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:21:04,231 [Listener at localhost/45155] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:21:04,231 [Listener at localhost/45155] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:21:04,231 [Listener at localhost/45155] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:21:04,232 [Listener at localhost/45155] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:04,232 [Listener at localhost/45155] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:04,232 [Listener at localhost/45155] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=20, effected=1000
2020-12-03 07:21:04,232 [Listener at localhost/45155] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:21:04,233 [Listener at localhost/45155] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:04,233 [Listener at localhost/45155] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:21:04,233 [Listener at localhost/45155] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:21:04
2020-12-03 07:21:04,233 [Listener at localhost/45155] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:21:04,234 [Listener at localhost/45155] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:04,234 [Listener at localhost/45155] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:21:04,234 [Listener at localhost/45155] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:21:04,241 [Listener at localhost/45155] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:04,242 [Listener at localhost/45155] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:04,242 [Listener at localhost/45155] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:21:04,242 [Listener at localhost/45155] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:21:04,243 [Listener at localhost/45155] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:04,243 [Listener at localhost/45155] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:21:04,243 [Listener at localhost/45155] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:21:04,243 [Listener at localhost/45155] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:21:04,244 [Listener at localhost/45155] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:21:04,244 [Listener at localhost/45155] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:21:04,244 [Listener at localhost/45155] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:21:04,244 [Listener at localhost/45155] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:21:04,244 [Listener at localhost/45155] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:21:04,244 [Listener at localhost/45155] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:21:04,244 [Listener at localhost/45155] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:21:04,245 [Listener at localhost/45155] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:21:04,245 [Listener at localhost/45155] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:21:04,245 [Listener at localhost/45155] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:04,246 [Listener at localhost/45155] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:21:04,246 [Listener at localhost/45155] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:21:04,248 [Listener at localhost/45155] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:21:04,248 [Listener at localhost/45155] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:21:04,249 [Listener at localhost/45155] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:21:04,249 [Listener at localhost/45155] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:21:04,249 [Listener at localhost/45155] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:21:04,249 [Listener at localhost/45155] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:21:04,249 [Listener at localhost/45155] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:21:04,249 [Listener at localhost/45155] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:04,250 [Listener at localhost/45155] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:21:04,250 [Listener at localhost/45155] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:21:04,252 [Listener at localhost/45155] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:21:04,252 [Listener at localhost/45155] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:21:04,252 [Listener at localhost/45155] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:21:04,253 [Listener at localhost/45155] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:21:04,254 [Listener at localhost/45155] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:21:04,254 [Listener at localhost/45155] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:21:04,254 [Listener at localhost/45155] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:04,255 [Listener at localhost/45155] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:21:04,255 [Listener at localhost/45155] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:21:04,307 [Listener at localhost/45155] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 2630@9bd33dce04e9
2020-12-03 07:21:04,358 [Listener at localhost/45155] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 2630@9bd33dce04e9
2020-12-03 07:21:04,359 [Listener at localhost/45155] INFO  common.Storage (NNStorage.java:processStartupOptionsForUpgrade(935)) - Using clusterid: testClusterID
2020-12-03 07:21:04,361 [Listener at localhost/45155] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-12-03 07:21:04,364 [Listener at localhost/45155] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-12-03 07:21:04,373 [Listener at localhost/45155] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:21:04,379 [Listener at localhost/45155] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:21:04,381 [Listener at localhost/45155] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:21:04,382 [Listener at localhost/45155] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-12-03 07:21:04,385 [Listener at localhost/45155] INFO  namenode.FSImage (FSImage.java:loadEdits(910)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@5aae8eb5 expecting start txid #1
2020-12-03 07:21:04,386 [Listener at localhost/45155] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000018, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000018 maxTxnsToRead = 9223372036854775807
2020-12-03 07:21:04,386 [Listener at localhost/45155] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:loadEditRecords(217)) - Acquiring write lock to replay edit log
2020-12-03 07:21:04,387 [Listener at localhost/45155] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000018' to transaction ID 1
2020-12-03 07:21:04,402 [Listener at localhost/45155] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:loadEditRecords(284)) - op=LogSegmentOp [opCode=OP_START_LOG_SEGMENT, txid=1], startOpt=UPGRADE, numEdits=0, totalEdits=0
2020-12-03 07:21:04,402 [Listener at localhost/45155] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:applyEditLogOp(388)) - replaying edit log: LogSegmentOp [opCode=OP_START_LOG_SEGMENT, txid=1]
2020-12-03 07:21:04,405 [Listener at localhost/45155] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:loadEditRecords(284)) - op=MkdirOp [length=0, inodeId=16386, path=/test, timestamp=1606980062499, permissions=root:supergroup:rwxr-xr-x, aclEntries=null, opCode=OP_MKDIR, txid=2, xAttrs=[]], startOpt=UPGRADE, numEdits=1, totalEdits=1
2020-12-03 07:21:04,405 [Listener at localhost/45155] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:applyEditLogOp(388)) - replaying edit log: MkdirOp [length=0, inodeId=16386, path=/test, timestamp=1606980062499, permissions=root:supergroup:rwxr-xr-x, aclEntries=null, opCode=OP_MKDIR, txid=2, xAttrs=[]]
2020-12-03 07:21:04,405 [Listener at localhost/45155] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:loadEditRecords(284)) - op=SetQuotaOp [src=/test, nsQuota=100, dsQuota=1000, opCode=OP_SET_QUOTA, txid=3], startOpt=UPGRADE, numEdits=2, totalEdits=2
2020-12-03 07:21:04,405 [Listener at localhost/45155] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:applyEditLogOp(388)) - replaying edit log: SetQuotaOp [src=/test, nsQuota=100, dsQuota=1000, opCode=OP_SET_QUOTA, txid=3]
2020-12-03 07:21:04,406 [Listener at localhost/45155] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:loadEditRecords(284)) - op=AllowSnapshotOp [snapshotRoot=/test], startOpt=UPGRADE, numEdits=3, totalEdits=3
2020-12-03 07:21:04,406 [Listener at localhost/45155] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:applyEditLogOp(388)) - replaying edit log: AllowSnapshotOp [snapshotRoot=/test]
2020-12-03 07:21:04,407 [Listener at localhost/45155] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:loadEditRecords(284)) - op=AddOp [length=0, inodeId=16387, path=/test/testUpgrade, replication=3, mtime=1606980062569, atime=1606980062569, blockSize=4, blocks=[], permissions=root:supergroup:rw-r--r--, aclEntries=null, clientName=DFSClient_NONMAPREDUCE_742258692_1, clientMachine=127.0.0.1, overwrite=true, RpcClientId=18c30b59-4f7a-4dab-9f18-e65cd6773072, RpcCallId=28, storagePolicyId=0, erasureCodingPolicyId=0, opCode=OP_ADD, txid=5], startOpt=UPGRADE, numEdits=4, totalEdits=4
2020-12-03 07:21:04,407 [Listener at localhost/45155] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:applyEditLogOp(388)) - replaying edit log: AddOp [length=0, inodeId=16387, path=/test/testUpgrade, replication=3, mtime=1606980062569, atime=1606980062569, blockSize=4, blocks=[], permissions=root:supergroup:rw-r--r--, aclEntries=null, clientName=DFSClient_NONMAPREDUCE_742258692_1, clientMachine=127.0.0.1, overwrite=true, RpcClientId=18c30b59-4f7a-4dab-9f18-e65cd6773072, RpcCallId=28, storagePolicyId=0, erasureCodingPolicyId=0, opCode=OP_ADD, txid=5]
2020-12-03 07:21:04,408 [Listener at localhost/45155] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:loadEditRecords(284)) - op=AllocateBlockIdOp [blockId=1073741825, opCode=OP_ALLOCATE_BLOCK_ID, txid=6], startOpt=UPGRADE, numEdits=5, totalEdits=5
2020-12-03 07:21:04,408 [Listener at localhost/45155] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:applyEditLogOp(388)) - replaying edit log: AllocateBlockIdOp [blockId=1073741825, opCode=OP_ALLOCATE_BLOCK_ID, txid=6]
2020-12-03 07:21:04,409 [Listener at localhost/45155] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:loadEditRecords(284)) - op=SetGenstampV2Op [GenStampV2=1001, opCode=OP_SET_GENSTAMP_V2, txid=7], startOpt=UPGRADE, numEdits=6, totalEdits=6
2020-12-03 07:21:04,409 [Listener at localhost/45155] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:applyEditLogOp(388)) - replaying edit log: SetGenstampV2Op [GenStampV2=1001, opCode=OP_SET_GENSTAMP_V2, txid=7]
2020-12-03 07:21:04,409 [Listener at localhost/45155] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:loadEditRecords(284)) - op=AddBlockOp [path=/test/testUpgrade, penultimateBlock=NULL, lastBlock=blk_1073741825_1001, RpcClientId=, RpcCallId=-2], startOpt=UPGRADE, numEdits=7, totalEdits=7
2020-12-03 07:21:04,409 [Listener at localhost/45155] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:applyEditLogOp(388)) - replaying edit log: AddBlockOp [path=/test/testUpgrade, penultimateBlock=NULL, lastBlock=blk_1073741825_1001, RpcClientId=, RpcCallId=-2]
2020-12-03 07:21:04,410 [Listener at localhost/45155] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:loadEditRecords(284)) - op=AllocateBlockIdOp [blockId=1073741826, opCode=OP_ALLOCATE_BLOCK_ID, txid=9], startOpt=UPGRADE, numEdits=8, totalEdits=8
2020-12-03 07:21:04,410 [Listener at localhost/45155] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:applyEditLogOp(388)) - replaying edit log: AllocateBlockIdOp [blockId=1073741826, opCode=OP_ALLOCATE_BLOCK_ID, txid=9]
2020-12-03 07:21:04,410 [Listener at localhost/45155] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:loadEditRecords(284)) - op=SetGenstampV2Op [GenStampV2=1002, opCode=OP_SET_GENSTAMP_V2, txid=10], startOpt=UPGRADE, numEdits=9, totalEdits=9
2020-12-03 07:21:04,410 [Listener at localhost/45155] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:applyEditLogOp(388)) - replaying edit log: SetGenstampV2Op [GenStampV2=1002, opCode=OP_SET_GENSTAMP_V2, txid=10]
2020-12-03 07:21:04,411 [Listener at localhost/45155] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:loadEditRecords(284)) - op=AddBlockOp [path=/test/testUpgrade, penultimateBlock=blk_1073741825_1001, lastBlock=blk_1073741826_1002, RpcClientId=, RpcCallId=-2], startOpt=UPGRADE, numEdits=10, totalEdits=10
2020-12-03 07:21:04,411 [Listener at localhost/45155] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:applyEditLogOp(388)) - replaying edit log: AddBlockOp [path=/test/testUpgrade, penultimateBlock=blk_1073741825_1001, lastBlock=blk_1073741826_1002, RpcClientId=, RpcCallId=-2]
2020-12-03 07:21:04,411 [Listener at localhost/45155] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:loadEditRecords(284)) - op=CloseOp [length=0, inodeId=0, path=/test/testUpgrade, replication=3, mtime=1606980062855, atime=1606980062569, blockSize=4, blocks=[blk_1073741825_1001, blk_1073741826_1002], permissions=root:supergroup:rw-r--r--, aclEntries=null, clientName=, clientMachine=, overwrite=false, storagePolicyId=0, erasureCodingPolicyId=0, opCode=OP_CLOSE, txid=12], startOpt=UPGRADE, numEdits=11, totalEdits=11
2020-12-03 07:21:04,412 [Listener at localhost/45155] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:applyEditLogOp(388)) - replaying edit log: CloseOp [length=0, inodeId=0, path=/test/testUpgrade, replication=3, mtime=1606980062855, atime=1606980062569, blockSize=4, blocks=[blk_1073741825_1001, blk_1073741826_1002], permissions=root:supergroup:rw-r--r--, aclEntries=null, clientName=, clientMachine=, overwrite=false, storagePolicyId=0, erasureCodingPolicyId=0, opCode=OP_CLOSE, txid=12]
2020-12-03 07:21:04,412 [Listener at localhost/45155] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:loadEditRecords(284)) - op=CreateSnapshotOp [snapshotRoot=/test, snapshotName=ss0, RpcClientId=18c30b59-4f7a-4dab-9f18-e65cd6773072, RpcCallId=39], startOpt=UPGRADE, numEdits=12, totalEdits=12
2020-12-03 07:21:04,412 [Listener at localhost/45155] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:applyEditLogOp(388)) - replaying edit log: CreateSnapshotOp [snapshotRoot=/test, snapshotName=ss0, RpcClientId=18c30b59-4f7a-4dab-9f18-e65cd6773072, RpcCallId=39]
2020-12-03 07:21:04,413 [Listener at localhost/45155] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:loadEditRecords(284)) - op=AllocateBlockIdOp [blockId=1073741827, opCode=OP_ALLOCATE_BLOCK_ID, txid=14], startOpt=UPGRADE, numEdits=13, totalEdits=13
2020-12-03 07:21:04,413 [Listener at localhost/45155] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:applyEditLogOp(388)) - replaying edit log: AllocateBlockIdOp [blockId=1073741827, opCode=OP_ALLOCATE_BLOCK_ID, txid=14]
2020-12-03 07:21:04,413 [Listener at localhost/45155] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:loadEditRecords(284)) - op=SetGenstampV2Op [GenStampV2=1003, opCode=OP_SET_GENSTAMP_V2, txid=15], startOpt=UPGRADE, numEdits=14, totalEdits=14
2020-12-03 07:21:04,413 [Listener at localhost/45155] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:applyEditLogOp(388)) - replaying edit log: SetGenstampV2Op [GenStampV2=1003, opCode=OP_SET_GENSTAMP_V2, txid=15]
2020-12-03 07:21:04,413 [Listener at localhost/45155] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:loadEditRecords(284)) - op=TruncateOp [src=/test/testUpgrade, clientName=DFSClient_NONMAPREDUCE_742258692_1, clientMachine=127.0.0.1, newLength=7, timestamp=1606980062882, truncateBlock=blk_1073741827_1003, opCode=OP_TRUNCATE, txid=16], startOpt=UPGRADE, numEdits=15, totalEdits=15
2020-12-03 07:21:04,414 [Listener at localhost/45155] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:applyEditLogOp(388)) - replaying edit log: TruncateOp [src=/test/testUpgrade, clientName=DFSClient_NONMAPREDUCE_742258692_1, clientMachine=127.0.0.1, newLength=7, timestamp=1606980062882, truncateBlock=blk_1073741827_1003, opCode=OP_TRUNCATE, txid=16]
2020-12-03 07:21:04,414 [Listener at localhost/45155] DEBUG hdfs.StateChange (FSDirTruncateOp.java:prepareFileForTruncate(252)) - BLOCK* prepareFileForTruncate: Scheduling copy-on-truncate to new size 3  new block blk_1073741827_1003 old block blk_1073741826_1002
2020-12-03 07:21:04,415 [Listener at localhost/45155] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:loadEditRecords(284)) - op=CloseOp [length=0, inodeId=0, path=/test/testUpgrade, replication=3, mtime=1606980063544, atime=1606980062569, blockSize=4, blocks=[blk_1073741825_1001, blk_1073741827_1003], permissions=root:supergroup:rw-r--r--, aclEntries=null, clientName=, clientMachine=, overwrite=false, storagePolicyId=0, erasureCodingPolicyId=0, opCode=OP_CLOSE, txid=17], startOpt=UPGRADE, numEdits=16, totalEdits=16
2020-12-03 07:21:04,415 [Listener at localhost/45155] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:applyEditLogOp(388)) - replaying edit log: CloseOp [length=0, inodeId=0, path=/test/testUpgrade, replication=3, mtime=1606980063544, atime=1606980062569, blockSize=4, blocks=[blk_1073741825_1001, blk_1073741827_1003], permissions=root:supergroup:rw-r--r--, aclEntries=null, clientName=, clientMachine=, overwrite=false, storagePolicyId=0, erasureCodingPolicyId=0, opCode=OP_CLOSE, txid=17]
2020-12-03 07:21:04,415 [Listener at localhost/45155] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:loadEditRecords(284)) - op=LogSegmentOp [opCode=OP_END_LOG_SEGMENT, txid=18], startOpt=UPGRADE, numEdits=17, totalEdits=17
2020-12-03 07:21:04,416 [Listener at localhost/45155] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:applyEditLogOp(388)) - replaying edit log: LogSegmentOp [opCode=OP_END_LOG_SEGMENT, txid=18]
2020-12-03 07:21:04,416 [Listener at localhost/45155] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:loadEditRecords(347)) - replaying edit log finished
2020-12-03 07:21:04,440 [Listener at localhost/45155] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(188)) - Loaded 1 edits file(s) (the last named /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000018, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000018) of total size 1059.0, total edits 18.0, total load time 30.0 ms
2020-12-03 07:21:04,441 [Listener at localhost/45155] INFO  namenode.FSImage (FSImage.java:doUpgrade(469)) - Starting upgrade of local storage directories.
   old LV = -65; old CTime = 1606980057018.
   new LV = -65; new CTime = 1606980064441
2020-12-03 07:21:04,442 [Listener at localhost/45155] INFO  namenode.NNUpgradeUtil (NNUpgradeUtil.java:doPreUpgrade(118)) - Starting upgrade of storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1
2020-12-03 07:21:04,447 [Listener at localhost/45155] INFO  namenode.NNUpgradeUtil (NNUpgradeUtil.java:doPreUpgrade(118)) - Starting upgrade of storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2
2020-12-03 07:21:04,464 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000018 using no compression
2020-12-03 07:21:04,464 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000018 using no compression
2020-12-03 07:21:04,496 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000018 of size 757 bytes saved in 0 seconds .
2020-12-03 07:21:04,496 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000018 of size 757 bytes saved in 0 seconds .
2020-12-03 07:21:04,552 [Listener at localhost/45155] INFO  namenode.FSImageTransactionalStorageInspector (FSImageTransactionalStorageInspector.java:inspectDirectory(78)) - No version file in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1
2020-12-03 07:21:04,552 [Listener at localhost/45155] INFO  namenode.FSImageTransactionalStorageInspector (FSImageTransactionalStorageInspector.java:inspectDirectory(78)) - No version file in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2
2020-12-03 07:21:04,553 [Listener at localhost/45155] INFO  namenode.FSImageTransactionalStorageInspector (FSImageTransactionalStorageInspector.java:inspectDirectory(78)) - No version file in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1
2020-12-03 07:21:04,554 [Listener at localhost/45155] INFO  namenode.FSImageTransactionalStorageInspector (FSImageTransactionalStorageInspector.java:inspectDirectory(78)) - No version file in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2
2020-12-03 07:21:04,554 [Listener at localhost/45155] INFO  namenode.NNUpgradeUtil (NNUpgradeUtil.java:doUpgrade(185)) - Performing upgrade of storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1
2020-12-03 07:21:04,586 [Listener at localhost/45155] INFO  namenode.NNUpgradeUtil (NNUpgradeUtil.java:doUpgrade(185)) - Performing upgrade of storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2
2020-12-03 07:21:04,630 [Listener at localhost/45155] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:21:04,631 [Listener at localhost/45155] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 19
2020-12-03 07:21:04,733 [Listener at localhost/45155] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:21:04,733 [Listener at localhost/45155] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 477 msecs
2020-12-03 07:21:04,734 [Listener at localhost/45155] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:21:04,735 [Listener at localhost/45155] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:21:04,736 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:21:04,746 [Listener at localhost/37869] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:37869 to access this namenode/service.
2020-12-03 07:21:04,747 [Listener at localhost/37869] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:21:04,787 [Listener at localhost/37869] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:21:04,789 [Listener at localhost/37869] INFO  hdfs.StateChange (BlockManagerSafeMode.java:reportStatus(617)) - STATE* Safe mode ON. 
The reported blocks 0 needs additional 2 blocks to reach the threshold 0.9990 of total blocks 3.
The minimum number of live datanodes is not required. Safe mode will be turned off automatically once the thresholds have been reached.
2020-12-03 07:21:04,797 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:21:04,797 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:21:04,801 [Listener at localhost/37869] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:37869
2020-12-03 07:21:04,802 [Listener at localhost/37869] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:21:04,802 [Listener at localhost/37869] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:21:04,812 [Listener at localhost/37869] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 9 milliseconds
name space=3
storage space=33
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:21:04,820 [CacheReplicationMonitor(110939807)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:21:04,824 [Listener at localhost/37869] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:21:04,825 [Listener at localhost/37869] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:21:04,826 [Listener at localhost/37869] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:21:04,827 [Listener at localhost/37869] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:21:04,829 [Listener at localhost/37869] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:04,830 [Listener at localhost/37869] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:21:04,830 [Listener at localhost/37869] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:21:04,831 [Listener at localhost/37869] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:04,831 [Listener at localhost/37869] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:04,831 [Listener at localhost/37869] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:04,832 [Listener at localhost/37869] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:21:04,833 [Listener at localhost/37869] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:33245
2020-12-03 07:21:04,833 [Listener at localhost/37869] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:21:04,833 [Listener at localhost/37869] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:21:04,835 [Listener at localhost/37869] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:04,837 [Listener at localhost/37869] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:21:04,838 [Listener at localhost/37869] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:21:04,838 [Listener at localhost/37869] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:04,841 [Listener at localhost/37869] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:21:04,842 [Listener at localhost/37869] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:21:04,842 [Listener at localhost/37869] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:21:04,843 [Listener at localhost/37869] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:21:04,844 [Listener at localhost/37869] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 42995
2020-12-03 07:21:04,844 [Listener at localhost/37869] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:21:04,846 [Listener at localhost/37869] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@65004ff6{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:21:04,847 [Listener at localhost/37869] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@562c877a{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:21:04,856 [Listener at localhost/37869] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5b22b970{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:21:04,857 [Listener at localhost/37869] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@22d1886d{HTTP/1.1,[http/1.1]}{localhost:42995}
2020-12-03 07:21:04,857 [Listener at localhost/37869] INFO  server.Server (Server.java:doStart(419)) - Started @9852ms
2020-12-03 07:21:04,962 [Listener at localhost/37869] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:32884
2020-12-03 07:21:04,963 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1cbb3d3b] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:21:04,964 [Listener at localhost/37869] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:21:04,964 [Listener at localhost/37869] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:21:04,965 [Listener at localhost/37869] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:21:04,966 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:21:04,977 [Listener at localhost/33305] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:33305
2020-12-03 07:21:04,990 [Listener at localhost/33305] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:21:04,991 [Listener at localhost/33305] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:21:04,992 [Thread-230] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37869 starting to offer service
2020-12-03 07:21:04,997 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:21:04,997 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:21:05,006 [Listener at localhost/33305] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:21:05,012 [Thread-230] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37869
2020-12-03 07:21:05,013 [Thread-230] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:21:05,013 [Listener at localhost/33305] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:21:05,014 [Listener at localhost/33305] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:21:05,015 [Listener at localhost/33305] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:21:05,016 [Listener at localhost/33305] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:05,016 [Listener at localhost/33305] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:21:05,024 [Listener at localhost/33305] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:21:05,025 [Listener at localhost/33305] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:05,025 [Listener at localhost/33305] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:05,025 [Listener at localhost/33305] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:05,026 [Listener at localhost/33305] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:21:05,027 [Listener at localhost/33305] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:41706
2020-12-03 07:21:05,027 [Listener at localhost/33305] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:21:05,027 [Listener at localhost/33305] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:21:05,029 [Listener at localhost/33305] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:05,031 [Listener at localhost/33305] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:21:05,052 [Listener at localhost/33305] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:21:05,053 [Listener at localhost/33305] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:05,052 [Thread-230] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 2630@9bd33dce04e9
2020-12-03 07:21:05,055 [Listener at localhost/33305] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:21:05,056 [Listener at localhost/33305] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:21:05,056 [Listener at localhost/33305] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:21:05,056 [Listener at localhost/33305] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:21:05,058 [Listener at localhost/33305] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 40122
2020-12-03 07:21:05,058 [Listener at localhost/33305] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:21:05,061 [Listener at localhost/33305] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4e4c3a38{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:21:05,062 [Listener at localhost/33305] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@c27d163{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:21:05,071 [Listener at localhost/33305] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@f8f56b9{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:21:05,075 [Listener at localhost/33305] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2c656f16{HTTP/1.1,[http/1.1]}{localhost:40122}
2020-12-03 07:21:05,075 [Listener at localhost/33305] INFO  server.Server (Server.java:doStart(419)) - Started @10070ms
2020-12-03 07:21:05,096 [Listener at localhost/33305] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:33006
2020-12-03 07:21:05,096 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4f186450] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:21:05,096 [Listener at localhost/33305] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:21:05,097 [Listener at localhost/33305] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:21:05,097 [Listener at localhost/33305] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:21:05,098 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:21:05,104 [Listener at localhost/45885] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:45885
2020-12-03 07:21:05,128 [Listener at localhost/45885] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:21:05,131 [Listener at localhost/45885] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:21:05,133 [Thread-253] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37869 starting to offer service
2020-12-03 07:21:05,140 [Thread-230] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 2630@9bd33dce04e9
2020-12-03 07:21:05,141 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:21:05,141 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:21:05,149 [Listener at localhost/45885] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:21:05,154 [Thread-253] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37869
2020-12-03 07:21:05,156 [Thread-253] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:21:05,156 [Listener at localhost/45885] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:21:05,157 [Listener at localhost/45885] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:21:05,159 [Listener at localhost/45885] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:21:05,160 [Listener at localhost/45885] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:05,160 [Listener at localhost/45885] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:21:05,161 [Listener at localhost/45885] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:21:05,161 [Listener at localhost/45885] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:05,161 [Listener at localhost/45885] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:05,161 [Listener at localhost/45885] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:05,161 [Listener at localhost/45885] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:21:05,162 [Listener at localhost/45885] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:33147
2020-12-03 07:21:05,162 [Listener at localhost/45885] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:21:05,163 [Listener at localhost/45885] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:21:05,164 [Listener at localhost/45885] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:05,166 [Listener at localhost/45885] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:21:05,166 [Listener at localhost/45885] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:21:05,167 [Listener at localhost/45885] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:05,169 [Listener at localhost/45885] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:21:05,169 [Listener at localhost/45885] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:21:05,169 [Listener at localhost/45885] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:21:05,170 [Listener at localhost/45885] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:21:05,170 [Listener at localhost/45885] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 40228
2020-12-03 07:21:05,171 [Listener at localhost/45885] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:21:05,173 [Listener at localhost/45885] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@61f3fbb8{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:21:05,173 [Listener at localhost/45885] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@432034a{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:21:05,183 [Listener at localhost/45885] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@4e25147a{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:21:05,185 [Listener at localhost/45885] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6b68cb27{HTTP/1.1,[http/1.1]}{localhost:40228}
2020-12-03 07:21:05,186 [Listener at localhost/45885] INFO  server.Server (Server.java:doStart(419)) - Started @10180ms
2020-12-03 07:21:05,202 [Listener at localhost/45885] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:42750
2020-12-03 07:21:05,204 [Listener at localhost/45885] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:21:05,204 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@56303475] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:21:05,204 [Listener at localhost/45885] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:21:05,205 [Listener at localhost/45885] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:21:05,206 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:21:05,212 [Listener at localhost/33229] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:33229
2020-12-03 07:21:05,224 [Thread-230] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:05,224 [Thread-230] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:05,225 [Thread-230] INFO  common.Storage (BlockPoolSliceStorage.java:doUpgrade(450)) - Upgrading block pool storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-425068830-172.17.0.8-1606980057018.
   old LV = -57; old CTime = 1606980057018.
   new LV = -57; new CTime = 1606980064441
2020-12-03 07:21:05,225 [Listener at localhost/33229] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:21:05,226 [Listener at localhost/33229] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:21:05,227 [Thread-275] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37869 starting to offer service
2020-12-03 07:21:05,231 [Thread-253] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 2630@9bd33dce04e9
2020-12-03 07:21:05,236 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:21:05,236 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:21:05,245 [Thread-275] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37869
2020-12-03 07:21:05,248 [Thread-275] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:21:05,260 [IPC Server handler 3 on default port 37869] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:05,261 [Listener at localhost/33229] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:05,261 [Listener at localhost/33229] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:05,263 [Thread-230] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:05,264 [Thread-230] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:05,264 [Thread-230] INFO  common.Storage (BlockPoolSliceStorage.java:doUpgrade(450)) - Upgrading block pool storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-425068830-172.17.0.8-1606980057018.
   old LV = -57; old CTime = 1606980057018.
   new LV = -57; new CTime = 1606980064441
2020-12-03 07:21:05,266 [Thread-230] INFO  common.Storage (DataStorage.java:loadBlockPoolSliceStorage(480)) - loadBlockPoolSliceStorage: 2 upgrade tasks
2020-12-03 07:21:05,266 [pool-58-thread-2] INFO  common.Storage (DataStorage.java:linkBlocks(1082)) - Start linking block files from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-425068830-172.17.0.8-1606980057018/previous.tmp/finalized to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-425068830-172.17.0.8-1606980057018/current/finalized
2020-12-03 07:21:05,266 [pool-58-thread-1] INFO  common.Storage (DataStorage.java:linkBlocks(1082)) - Start linking block files from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-425068830-172.17.0.8-1606980057018/previous.tmp/finalized to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-425068830-172.17.0.8-1606980057018/current/finalized
2020-12-03 07:21:05,270 [pool-58-thread-2] INFO  common.Storage (DataStorage.java:linkBlocks(1082)) - Start linking block files from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-425068830-172.17.0.8-1606980057018/previous.tmp/rbw to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-425068830-172.17.0.8-1606980057018/current/rbw
2020-12-03 07:21:05,270 [pool-58-thread-1] INFO  common.Storage (DataStorage.java:linkBlocks(1082)) - Start linking block files from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-425068830-172.17.0.8-1606980057018/previous.tmp/rbw to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-425068830-172.17.0.8-1606980057018/current/rbw
2020-12-03 07:21:05,271 [pool-58-thread-1] INFO  common.Storage (BlockPoolSliceStorage.java:linkAllBlocks(696)) - Linked blocks from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-425068830-172.17.0.8-1606980057018/previous.tmp to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-425068830-172.17.0.8-1606980057018/current. HardLinkStats: 4 Directories, including 3 Empty Directories, 0 single Link operations, 1 multi-Link operations, linking 4 files, total 4 linkable files.  Also physically copied 0 other files.
2020-12-03 07:21:05,271 [pool-58-thread-2] INFO  common.Storage (BlockPoolSliceStorage.java:linkAllBlocks(696)) - Linked blocks from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-425068830-172.17.0.8-1606980057018/previous.tmp to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-425068830-172.17.0.8-1606980057018/current. HardLinkStats: 4 Directories, including 3 Empty Directories, 0 single Link operations, 1 multi-Link operations, linking 2 files, total 2 linkable files.  Also physically copied 0 other files.
2020-12-03 07:21:05,335 [Thread-275] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 2630@9bd33dce04e9
2020-12-03 07:21:05,337 [pool-58-thread-1] INFO  common.Storage (BlockPoolSliceStorage.java:doUpgrade(509)) - Upgrade of block pool BP-425068830-172.17.0.8-1606980057018 at /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-425068830-172.17.0.8-1606980057018 is complete
2020-12-03 07:21:05,337 [pool-58-thread-2] INFO  common.Storage (BlockPoolSliceStorage.java:doUpgrade(509)) - Upgrade of block pool BP-425068830-172.17.0.8-1606980057018 at /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-425068830-172.17.0.8-1606980057018 is complete
2020-12-03 07:21:05,339 [Thread-230] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1142161323;bpid=BP-425068830-172.17.0.8-1606980057018;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1142161323;c=1606980064441;bpid=BP-425068830-172.17.0.8-1606980057018;dnuuid=81972425-7fba-4dbf-b586-2759576dcb2a
2020-12-03 07:21:05,342 [Thread-230] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-e2a4702c-e5d8-49ec-98d9-afcba9a4bf2b
2020-12-03 07:21:05,344 [Thread-230] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-12-03 07:21:05,346 [Thread-230] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-7f94b3d0-d801-4a3a-80c5-f0a5c86996d0
2020-12-03 07:21:05,346 [Thread-230] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-12-03 07:21:05,349 [Thread-230] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:21:05,350 [Thread-230] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:21:05,351 [Thread-230] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:21:05,351 [Thread-230] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:21:05,351 [Thread-230] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:21:05,353 [Thread-230] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:05,353 [Thread-289] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:21:05,354 [Thread-290] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:21:05,366 [IPC Server handler 4 on default port 37869] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:05,374 [Listener at localhost/33229] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:05,387 [Listener at localhost/33229] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:05,387 [Thread-253] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 2630@9bd33dce04e9
2020-12-03 07:21:05,408 [Thread-289] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-425068830-172.17.0.8-1606980057018 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 54ms
2020-12-03 07:21:05,418 [Thread-290] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-425068830-172.17.0.8-1606980057018 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 64ms
2020-12-03 07:21:05,418 [Thread-230] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-425068830-172.17.0.8-1606980057018: 65ms
2020-12-03 07:21:05,419 [Thread-293] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:21:05,419 [Thread-294] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:21:05,419 [Thread-293] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-425068830-172.17.0.8-1606980057018/current/replicas doesn't exist 
2020-12-03 07:21:05,419 [Thread-294] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-425068830-172.17.0.8-1606980057018/current/replicas doesn't exist 
2020-12-03 07:21:05,427 [Thread-294] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 8ms
2020-12-03 07:21:05,427 [Thread-293] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 8ms
2020-12-03 07:21:05,429 [Thread-230] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-425068830-172.17.0.8-1606980057018: 11ms
2020-12-03 07:21:05,445 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-7f94b3d0-d801-4a3a-80c5-f0a5c86996d0): no suitable block pools found to scan.  Waiting 1814396851 ms.
2020-12-03 07:21:05,446 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-e2a4702c-e5d8-49ec-98d9-afcba9a4bf2b): no suitable block pools found to scan.  Waiting 1814396850 ms.
2020-12-03 07:21:05,446 [Thread-230] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:51 AM with interval of 21600000ms
2020-12-03 07:21:05,454 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:37869] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-425068830-172.17.0.8-1606980057018 (Datanode Uuid 81972425-7fba-4dbf-b586-2759576dcb2a) service to localhost/127.0.0.1:37869 beginning handshake with NN
2020-12-03 07:21:05,460 [IPC Server handler 5 on default port 37869] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:33245, datanodeUuid=81972425-7fba-4dbf-b586-2759576dcb2a, infoPort=32884, infoSecurePort=0, ipcPort=33305, storageInfo=lv=-57;cid=testClusterID;nsid=1142161323;c=1606980064441) storage 81972425-7fba-4dbf-b586-2759576dcb2a
2020-12-03 07:21:05,461 [IPC Server handler 5 on default port 37869] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:33245
2020-12-03 07:21:05,461 [IPC Server handler 5 on default port 37869] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 81972425-7fba-4dbf-b586-2759576dcb2a (127.0.0.1:33245).
2020-12-03 07:21:05,467 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:37869] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-425068830-172.17.0.8-1606980057018 (Datanode Uuid 81972425-7fba-4dbf-b586-2759576dcb2a) service to localhost/127.0.0.1:37869 successfully registered with NN
2020-12-03 07:21:05,467 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:37869] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:37869 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-12-03 07:21:05,475 [IPC Server handler 7 on default port 37869] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-e2a4702c-e5d8-49ec-98d9-afcba9a4bf2b for DN 127.0.0.1:33245
2020-12-03 07:21:05,475 [IPC Server handler 7 on default port 37869] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-7f94b3d0-d801-4a3a-80c5-f0a5c86996d0 for DN 127.0.0.1:33245
2020-12-03 07:21:05,489 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xed3c4c534adf4941: Processing first storage report for DS-e2a4702c-e5d8-49ec-98d9-afcba9a4bf2b from datanode 81972425-7fba-4dbf-b586-2759576dcb2a
2020-12-03 07:21:05,495 [Thread-275] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 2630@9bd33dce04e9
2020-12-03 07:21:05,499 [Thread-253] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:05,500 [Thread-253] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:05,500 [Thread-253] INFO  common.Storage (BlockPoolSliceStorage.java:doUpgrade(450)) - Upgrading block pool storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-425068830-172.17.0.8-1606980057018.
   old LV = -57; old CTime = 1606980057018.
   new LV = -57; new CTime = 1606980064441
2020-12-03 07:21:05,502 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xed3c4c534adf4941: from storage DS-e2a4702c-e5d8-49ec-98d9-afcba9a4bf2b node DatanodeRegistration(127.0.0.1:33245, datanodeUuid=81972425-7fba-4dbf-b586-2759576dcb2a, infoPort=32884, infoSecurePort=0, ipcPort=33305, storageInfo=lv=-57;cid=testClusterID;nsid=1142161323;c=1606980064441), blocks: 1, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:21:05,503 [IPC Server handler 9 on default port 37869] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:05,504 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xed3c4c534adf4941: Processing first storage report for DS-7f94b3d0-d801-4a3a-80c5-f0a5c86996d0 from datanode 81972425-7fba-4dbf-b586-2759576dcb2a
2020-12-03 07:21:05,504 [Block report processor] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:21:05,507 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(395)) - STATE* Safe mode is OFF
2020-12-03 07:21:05,507 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:21:05,507 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 1 racks and 1 datanodes
2020-12-03 07:21:05,507 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:21:05,509 [Block report processor] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_1073741827_1003 curReplicas 1 curExpectedReplicas 3 oldReplicas 0 oldExpectedReplicas  3 curPri  0 oldPri  4
2020-12-03 07:21:05,510 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xed3c4c534adf4941: from storage DS-7f94b3d0-d801-4a3a-80c5-f0a5c86996d0 node DatanodeRegistration(127.0.0.1:33245, datanodeUuid=81972425-7fba-4dbf-b586-2759576dcb2a, infoPort=32884, infoSecurePort=0, ipcPort=33305, storageInfo=lv=-57;cid=testClusterID;nsid=1142161323;c=1606980064441), blocks: 2, hasStaleStorage: false, processing time: 6 msecs, invalidatedBlocks: 0
2020-12-03 07:21:05,512 [Listener at localhost/33229] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:05,512 [Listener at localhost/33229] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:05,518 [Thread-253] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:05,518 [Thread-253] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:05,518 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 3
2020-12-03 07:21:05,518 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:21:05,519 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 2
2020-12-03 07:21:05,519 [Thread-253] INFO  common.Storage (BlockPoolSliceStorage.java:doUpgrade(450)) - Upgrading block pool storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-425068830-172.17.0.8-1606980057018.
   old LV = -57; old CTime = 1606980057018.
   new LV = -57; new CTime = 1606980064441
2020-12-03 07:21:05,519 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:21:05,519 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:21:05,519 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 11 msec
2020-12-03 07:21:05,520 [pool-66-thread-1] INFO  common.Storage (DataStorage.java:linkBlocks(1082)) - Start linking block files from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-425068830-172.17.0.8-1606980057018/previous.tmp/finalized to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-425068830-172.17.0.8-1606980057018/current/finalized
2020-12-03 07:21:05,520 [pool-66-thread-2] INFO  common.Storage (DataStorage.java:linkBlocks(1082)) - Start linking block files from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-425068830-172.17.0.8-1606980057018/previous.tmp/finalized to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-425068830-172.17.0.8-1606980057018/current/finalized
2020-12-03 07:21:05,523 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:37869] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xed3c4c534adf4941,  containing 2 storage report(s), of which we sent 2. The reports had 3 total blocks and used 1 RPC(s). This took 0 msec to generate and 34 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:21:05,520 [Thread-253] INFO  common.Storage (DataStorage.java:loadBlockPoolSliceStorage(480)) - loadBlockPoolSliceStorage: 2 upgrade tasks
2020-12-03 07:21:05,526 [pool-66-thread-2] INFO  common.Storage (DataStorage.java:linkBlocks(1082)) - Start linking block files from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-425068830-172.17.0.8-1606980057018/previous.tmp/rbw to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-425068830-172.17.0.8-1606980057018/current/rbw
2020-12-03 07:21:05,527 [pool-66-thread-1] INFO  common.Storage (DataStorage.java:linkBlocks(1082)) - Start linking block files from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-425068830-172.17.0.8-1606980057018/previous.tmp/rbw to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-425068830-172.17.0.8-1606980057018/current/rbw
2020-12-03 07:21:05,527 [pool-66-thread-2] INFO  common.Storage (BlockPoolSliceStorage.java:linkAllBlocks(696)) - Linked blocks from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-425068830-172.17.0.8-1606980057018/previous.tmp to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-425068830-172.17.0.8-1606980057018/current. HardLinkStats: 4 Directories, including 3 Empty Directories, 0 single Link operations, 1 multi-Link operations, linking 2 files, total 2 linkable files.  Also physically copied 0 other files.
2020-12-03 07:21:05,527 [pool-66-thread-1] INFO  common.Storage (BlockPoolSliceStorage.java:linkAllBlocks(696)) - Linked blocks from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-425068830-172.17.0.8-1606980057018/previous.tmp to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-425068830-172.17.0.8-1606980057018/current. HardLinkStats: 4 Directories, including 3 Empty Directories, 0 single Link operations, 1 multi-Link operations, linking 4 files, total 4 linkable files.  Also physically copied 0 other files.
2020-12-03 07:21:05,571 [Thread-275] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:05,574 [Thread-275] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:05,574 [Thread-275] INFO  common.Storage (BlockPoolSliceStorage.java:doUpgrade(450)) - Upgrading block pool storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-425068830-172.17.0.8-1606980057018.
   old LV = -57; old CTime = 1606980057018.
   new LV = -57; new CTime = 1606980064441
2020-12-03 07:21:05,577 [pool-66-thread-1] INFO  common.Storage (BlockPoolSliceStorage.java:doUpgrade(509)) - Upgrade of block pool BP-425068830-172.17.0.8-1606980057018 at /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-425068830-172.17.0.8-1606980057018 is complete
2020-12-03 07:21:05,577 [pool-66-thread-2] INFO  common.Storage (BlockPoolSliceStorage.java:doUpgrade(509)) - Upgrade of block pool BP-425068830-172.17.0.8-1606980057018 at /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-425068830-172.17.0.8-1606980057018 is complete
2020-12-03 07:21:05,580 [Thread-253] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1142161323;bpid=BP-425068830-172.17.0.8-1606980057018;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1142161323;c=1606980064441;bpid=BP-425068830-172.17.0.8-1606980057018;dnuuid=0b0f70d2-7565-48f3-b01c-1adf7b4ab560
2020-12-03 07:21:05,583 [Thread-253] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-9a7d7b8b-ec12-469a-9a7d-60ed5e71167a
2020-12-03 07:21:05,586 [Thread-253] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: DISK
2020-12-03 07:21:05,588 [Thread-275] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:05,588 [Thread-275] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:05,588 [Thread-275] INFO  common.Storage (BlockPoolSliceStorage.java:doUpgrade(450)) - Upgrading block pool storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-425068830-172.17.0.8-1606980057018.
   old LV = -57; old CTime = 1606980057018.
   new LV = -57; new CTime = 1606980064441
2020-12-03 07:21:05,589 [Thread-253] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-d40683d6-ae9f-4bbb-bc67-169f6d82dbbb
2020-12-03 07:21:05,589 [Thread-253] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: DISK
2020-12-03 07:21:05,592 [Thread-253] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:21:05,593 [pool-73-thread-1] INFO  common.Storage (DataStorage.java:linkBlocks(1082)) - Start linking block files from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-425068830-172.17.0.8-1606980057018/previous.tmp/finalized to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-425068830-172.17.0.8-1606980057018/current/finalized
2020-12-03 07:21:05,593 [Thread-275] INFO  common.Storage (DataStorage.java:loadBlockPoolSliceStorage(480)) - loadBlockPoolSliceStorage: 2 upgrade tasks
2020-12-03 07:21:05,593 [pool-73-thread-2] INFO  common.Storage (DataStorage.java:linkBlocks(1082)) - Start linking block files from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-425068830-172.17.0.8-1606980057018/previous.tmp/finalized to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-425068830-172.17.0.8-1606980057018/current/finalized
2020-12-03 07:21:05,594 [Thread-253] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:21:05,595 [pool-73-thread-1] INFO  common.Storage (DataStorage.java:linkBlocks(1082)) - Start linking block files from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-425068830-172.17.0.8-1606980057018/previous.tmp/rbw to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-425068830-172.17.0.8-1606980057018/current/rbw
2020-12-03 07:21:05,595 [Thread-253] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:21:05,595 [pool-73-thread-2] INFO  common.Storage (DataStorage.java:linkBlocks(1082)) - Start linking block files from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-425068830-172.17.0.8-1606980057018/previous.tmp/rbw to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-425068830-172.17.0.8-1606980057018/current/rbw
2020-12-03 07:21:05,595 [pool-73-thread-1] INFO  common.Storage (BlockPoolSliceStorage.java:linkAllBlocks(696)) - Linked blocks from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-425068830-172.17.0.8-1606980057018/previous.tmp to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-425068830-172.17.0.8-1606980057018/current. HardLinkStats: 4 Directories, including 3 Empty Directories, 0 single Link operations, 1 multi-Link operations, linking 2 files, total 2 linkable files.  Also physically copied 0 other files.
2020-12-03 07:21:05,595 [Thread-253] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:21:05,596 [pool-73-thread-2] INFO  common.Storage (BlockPoolSliceStorage.java:linkAllBlocks(696)) - Linked blocks from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-425068830-172.17.0.8-1606980057018/previous.tmp to /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-425068830-172.17.0.8-1606980057018/current. HardLinkStats: 4 Directories, including 3 Empty Directories, 0 single Link operations, 1 multi-Link operations, linking 4 files, total 4 linkable files.  Also physically copied 0 other files.
2020-12-03 07:21:05,599 [Thread-253] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:21:05,602 [Thread-253] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:05,603 [Thread-301] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:21:05,605 [Thread-302] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:21:05,616 [IPC Server handler 6 on default port 37869] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:05,618 [Listener at localhost/33229] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:05,619 [Listener at localhost/33229] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:05,673 [pool-73-thread-2] INFO  common.Storage (BlockPoolSliceStorage.java:doUpgrade(509)) - Upgrade of block pool BP-425068830-172.17.0.8-1606980057018 at /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-425068830-172.17.0.8-1606980057018 is complete
2020-12-03 07:21:05,673 [pool-73-thread-1] INFO  common.Storage (BlockPoolSliceStorage.java:doUpgrade(509)) - Upgrade of block pool BP-425068830-172.17.0.8-1606980057018 at /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-425068830-172.17.0.8-1606980057018 is complete
2020-12-03 07:21:05,673 [Thread-275] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1142161323;bpid=BP-425068830-172.17.0.8-1606980057018;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1142161323;c=1606980064441;bpid=BP-425068830-172.17.0.8-1606980057018;dnuuid=5326576b-2216-4538-9245-8b0fb17c9d46
2020-12-03 07:21:05,677 [Thread-275] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-c38ad29d-afe4-4ee0-be21-3867655f82fb
2020-12-03 07:21:05,682 [Thread-275] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, StorageType: DISK
2020-12-03 07:21:05,686 [Thread-302] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-425068830-172.17.0.8-1606980057018 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 80ms
2020-12-03 07:21:05,686 [Thread-301] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-425068830-172.17.0.8-1606980057018 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 82ms
2020-12-03 07:21:05,702 [Thread-275] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-07458f0c-3587-41d4-abeb-821d73c89765
2020-12-03 07:21:05,707 [Thread-253] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-425068830-172.17.0.8-1606980057018: 104ms
2020-12-03 07:21:05,707 [Thread-275] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, StorageType: DISK
2020-12-03 07:21:05,708 [Thread-307] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:21:05,708 [Thread-275] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:21:05,708 [Thread-307] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-425068830-172.17.0.8-1606980057018/current/replicas doesn't exist 
2020-12-03 07:21:05,711 [Thread-308] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:21:05,712 [Thread-307] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 5ms
2020-12-03 07:21:05,712 [Thread-308] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-425068830-172.17.0.8-1606980057018/current/replicas doesn't exist 
2020-12-03 07:21:05,713 [Thread-275] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:21:05,713 [Thread-275] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:21:05,713 [Thread-308] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 1ms
2020-12-03 07:21:05,714 [Thread-275] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:21:05,714 [Thread-253] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-425068830-172.17.0.8-1606980057018: 7ms
2020-12-03 07:21:05,714 [Thread-275] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:21:05,715 [Thread-275] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:05,715 [Thread-309] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:21:05,716 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-d40683d6-ae9f-4bbb-bc67-169f6d82dbbb): no suitable block pools found to scan.  Waiting 1814396580 ms.
2020-12-03 07:21:05,716 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-9a7d7b8b-ec12-469a-9a7d-60ed5e71167a): no suitable block pools found to scan.  Waiting 1814396580 ms.
2020-12-03 07:21:05,716 [Thread-310] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:21:05,717 [Thread-253] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 12:56 PM with interval of 21600000ms
2020-12-03 07:21:05,723 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:37869] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-425068830-172.17.0.8-1606980057018 (Datanode Uuid 0b0f70d2-7565-48f3-b01c-1adf7b4ab560) service to localhost/127.0.0.1:37869 beginning handshake with NN
2020-12-03 07:21:05,734 [IPC Server handler 0 on default port 37869] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:41706, datanodeUuid=0b0f70d2-7565-48f3-b01c-1adf7b4ab560, infoPort=33006, infoSecurePort=0, ipcPort=45885, storageInfo=lv=-57;cid=testClusterID;nsid=1142161323;c=1606980064441) storage 0b0f70d2-7565-48f3-b01c-1adf7b4ab560
2020-12-03 07:21:05,734 [IPC Server handler 0 on default port 37869] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41706
2020-12-03 07:21:05,734 [IPC Server handler 0 on default port 37869] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 0b0f70d2-7565-48f3-b01c-1adf7b4ab560 (127.0.0.1:41706).
2020-12-03 07:21:05,737 [IPC Server handler 1 on default port 37869] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:05,737 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:37869] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-425068830-172.17.0.8-1606980057018 (Datanode Uuid 0b0f70d2-7565-48f3-b01c-1adf7b4ab560) service to localhost/127.0.0.1:37869 successfully registered with NN
2020-12-03 07:21:05,738 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:37869] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:37869 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-12-03 07:21:05,740 [Listener at localhost/33229] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:05,740 [Listener at localhost/33229] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:05,741 [IPC Server handler 2 on default port 37869] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-9a7d7b8b-ec12-469a-9a7d-60ed5e71167a for DN 127.0.0.1:41706
2020-12-03 07:21:05,745 [IPC Server handler 2 on default port 37869] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d40683d6-ae9f-4bbb-bc67-169f6d82dbbb for DN 127.0.0.1:41706
2020-12-03 07:21:05,760 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xc24d145acecca140: Processing first storage report for DS-9a7d7b8b-ec12-469a-9a7d-60ed5e71167a from datanode 0b0f70d2-7565-48f3-b01c-1adf7b4ab560
2020-12-03 07:21:05,761 [Block report processor] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_1073741825_1001 curReplicas 2 curExpectedReplicas 3 oldReplicas 1 oldExpectedReplicas  3 curPri  2 oldPri  0
2020-12-03 07:21:05,761 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xc24d145acecca140: from storage DS-9a7d7b8b-ec12-469a-9a7d-60ed5e71167a node DatanodeRegistration(127.0.0.1:41706, datanodeUuid=0b0f70d2-7565-48f3-b01c-1adf7b4ab560, infoPort=33006, infoSecurePort=0, ipcPort=45885, storageInfo=lv=-57;cid=testClusterID;nsid=1142161323;c=1606980064441), blocks: 1, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:05,761 [Thread-309] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-425068830-172.17.0.8-1606980057018 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 45ms
2020-12-03 07:21:05,761 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xc24d145acecca140: Processing first storage report for DS-d40683d6-ae9f-4bbb-bc67-169f6d82dbbb from datanode 0b0f70d2-7565-48f3-b01c-1adf7b4ab560
2020-12-03 07:21:05,761 [Block report processor] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_1073741826_1002 curReplicas 2 curExpectedReplicas 3 oldReplicas 1 oldExpectedReplicas  3 curPri  2 oldPri  0
2020-12-03 07:21:05,761 [Block report processor] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_1073741827_1003 curReplicas 2 curExpectedReplicas 3 oldReplicas 1 oldExpectedReplicas  3 curPri  2 oldPri  0
2020-12-03 07:21:05,762 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xc24d145acecca140: from storage DS-d40683d6-ae9f-4bbb-bc67-169f6d82dbbb node DatanodeRegistration(127.0.0.1:41706, datanodeUuid=0b0f70d2-7565-48f3-b01c-1adf7b4ab560, infoPort=33006, infoSecurePort=0, ipcPort=45885, storageInfo=lv=-57;cid=testClusterID;nsid=1142161323;c=1606980064441), blocks: 2, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:05,762 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:37869] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xc24d145acecca140,  containing 2 storage report(s), of which we sent 2. The reports had 3 total blocks and used 1 RPC(s). This took 3 msec to generate and 4 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:21:05,769 [Thread-310] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-425068830-172.17.0.8-1606980057018 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 53ms
2020-12-03 07:21:05,769 [Thread-275] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-425068830-172.17.0.8-1606980057018: 55ms
2020-12-03 07:21:05,770 [Thread-316] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:21:05,770 [Thread-317] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:21:05,770 [Thread-316] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-425068830-172.17.0.8-1606980057018/current/replicas doesn't exist 
2020-12-03 07:21:05,771 [Thread-317] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-425068830-172.17.0.8-1606980057018/current/replicas doesn't exist 
2020-12-03 07:21:05,785 [Thread-316] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 14ms
2020-12-03 07:21:05,787 [Thread-317] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 16ms
2020-12-03 07:21:05,787 [Thread-275] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-425068830-172.17.0.8-1606980057018: 18ms
2020-12-03 07:21:05,790 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-07458f0c-3587-41d4-abeb-821d73c89765): no suitable block pools found to scan.  Waiting 1814396506 ms.
2020-12-03 07:21:05,790 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-c38ad29d-afe4-4ee0-be21-3867655f82fb): no suitable block pools found to scan.  Waiting 1814396506 ms.
2020-12-03 07:21:05,791 [Thread-275] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:44 AM with interval of 21600000ms
2020-12-03 07:21:05,792 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:37869] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-425068830-172.17.0.8-1606980057018 (Datanode Uuid 5326576b-2216-4538-9245-8b0fb17c9d46) service to localhost/127.0.0.1:37869 beginning handshake with NN
2020-12-03 07:21:05,794 [IPC Server handler 4 on default port 37869] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:33147, datanodeUuid=5326576b-2216-4538-9245-8b0fb17c9d46, infoPort=42750, infoSecurePort=0, ipcPort=33229, storageInfo=lv=-57;cid=testClusterID;nsid=1142161323;c=1606980064441) storage 5326576b-2216-4538-9245-8b0fb17c9d46
2020-12-03 07:21:05,794 [IPC Server handler 4 on default port 37869] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:33147
2020-12-03 07:21:05,794 [IPC Server handler 4 on default port 37869] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 5326576b-2216-4538-9245-8b0fb17c9d46 (127.0.0.1:33147).
2020-12-03 07:21:05,795 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:37869] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-425068830-172.17.0.8-1606980057018 (Datanode Uuid 5326576b-2216-4538-9245-8b0fb17c9d46) service to localhost/127.0.0.1:37869 successfully registered with NN
2020-12-03 07:21:05,795 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:37869] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:37869 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-12-03 07:21:05,799 [IPC Server handler 5 on default port 37869] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c38ad29d-afe4-4ee0-be21-3867655f82fb for DN 127.0.0.1:33147
2020-12-03 07:21:05,799 [IPC Server handler 5 on default port 37869] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-07458f0c-3587-41d4-abeb-821d73c89765 for DN 127.0.0.1:33147
2020-12-03 07:21:05,801 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xd8b23d641ec9159d: Processing first storage report for DS-07458f0c-3587-41d4-abeb-821d73c89765 from datanode 5326576b-2216-4538-9245-8b0fb17c9d46
2020-12-03 07:21:05,801 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xd8b23d641ec9159d: from storage DS-07458f0c-3587-41d4-abeb-821d73c89765 node DatanodeRegistration(127.0.0.1:33147, datanodeUuid=5326576b-2216-4538-9245-8b0fb17c9d46, infoPort=42750, infoSecurePort=0, ipcPort=33229, storageInfo=lv=-57;cid=testClusterID;nsid=1142161323;c=1606980064441), blocks: 2, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:21:05,801 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xd8b23d641ec9159d: Processing first storage report for DS-c38ad29d-afe4-4ee0-be21-3867655f82fb from datanode 5326576b-2216-4538-9245-8b0fb17c9d46
2020-12-03 07:21:05,801 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xd8b23d641ec9159d: from storage DS-c38ad29d-afe4-4ee0-be21-3867655f82fb node DatanodeRegistration(127.0.0.1:33147, datanodeUuid=5326576b-2216-4538-9245-8b0fb17c9d46, infoPort=42750, infoSecurePort=0, ipcPort=33229, storageInfo=lv=-57;cid=testClusterID;nsid=1142161323;c=1606980064441), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:05,802 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:37869] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xd8b23d641ec9159d,  containing 2 storage report(s), of which we sent 2. The reports had 3 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:21:05,842 [IPC Server handler 9 on default port 37869] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:05,843 [Listener at localhost/33229] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:21:05,846 [IPC Server handler 8 on default port 37869] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testUpgrade	dst=null	perm=null	proto=rpc
2020-12-03 07:21:05,848 [IPC Server handler 6 on default port 37869] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/test/testUpgrade	dst=null	perm=null	proto=rpc
2020-12-03 07:21:05,851 [IPC Server handler 0 on default port 37869] DEBUG hdfs.StateChange (NameNodeRpcServer.java:truncate(1087)) - *DIR* NameNode.truncate: /test/testUpgrade to 6
2020-12-03 07:21:05,852 [IPC Server handler 0 on default port 37869] DEBUG hdfs.StateChange (FSNamesystem.java:truncate(2136)) - DIR* NameSystem.truncate: src=/test/testUpgrade newLength=6
2020-12-03 07:21:05,856 [IPC Server handler 0 on default port 37869] DEBUG hdfs.StateChange (FSDirTruncateOp.java:prepareFileForTruncate(252)) - BLOCK* prepareFileForTruncate: Scheduling copy-on-truncate to new size 2  new block blk_1073741828_1004 old block blk_1073741827_1003
2020-12-03 07:21:05,860 [IPC Server handler 0 on default port 37869] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=truncate	src=/test/testUpgrade	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:21:05,885 [IPC Server handler 1 on default port 37869] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testUpgrade	dst=null	perm=null	proto=rpc
2020-12-03 07:21:05,903 [IPC Server handler 2 on default port 37869] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/test/testUpgrade	dst=null	perm=null	proto=rpc
2020-12-03 07:21:05,942 [IPC Server handler 3 on default port 37869] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/test/testUpgrade	dst=null	perm=null	proto=rpc
2020-12-03 07:21:06,047 [IPC Server handler 4 on default port 37869] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/test/testUpgrade	dst=null	perm=null	proto=rpc
2020-12-03 07:21:06,153 [IPC Server handler 5 on default port 37869] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/test/testUpgrade	dst=null	perm=null	proto=rpc
2020-12-03 07:21:06,258 [IPC Server handler 7 on default port 37869] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/test/testUpgrade	dst=null	perm=null	proto=rpc
2020-12-03 07:21:06,364 [IPC Server handler 9 on default port 37869] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/test/testUpgrade	dst=null	perm=null	proto=rpc
2020-12-03 07:21:06,469 [IPC Server handler 8 on default port 37869] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/test/testUpgrade	dst=null	perm=null	proto=rpc
2020-12-03 07:21:06,574 [IPC Server handler 0 on default port 37869] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/test/testUpgrade	dst=null	perm=null	proto=rpc
2020-12-03 07:21:06,679 [IPC Server handler 1 on default port 37869] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/test/testUpgrade	dst=null	perm=null	proto=rpc
2020-12-03 07:21:06,784 [IPC Server handler 3 on default port 37869] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/test/testUpgrade	dst=null	perm=null	proto=rpc
2020-12-03 07:21:06,800 [org.apache.hadoop.hdfs.server.datanode.BlockRecoveryWorker$1@4c2fa7ad] INFO  datanode.DataNode (BlockRecoveryWorker.java:logRecoverBlock(549)) - BlockRecoveryWorker: NameNode at localhost/127.0.0.1:37869 calls recoverBlock(BP-425068830-172.17.0.8-1606980057018:blk_1073741827_1003, targets=[DatanodeInfoWithStorage[127.0.0.1:33245,null,null], DatanodeInfoWithStorage[127.0.0.1:41706,null,null], DatanodeInfoWithStorage[127.0.0.1:33147,null,null]], newGenerationStamp=1004, newBlock=blk_1073741828_1004, isStriped=false)
2020-12-03 07:21:06,804 [IPC Server handler 2 on default port 33305] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:initReplicaRecoveryImpl(2588)) - initReplicaRecovery: blk_1073741827_1003, recoveryId=1004, replica=FinalizedReplica, blk_1073741827_1003, FINALIZED
  getNumBytes()     = 3
  getBytesOnDisk()  = 3
  getVisibleLength()= 3
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-425068830-172.17.0.8-1606980057018/current/finalized/subdir0/subdir0/blk_1073741827
2020-12-03 07:21:06,804 [IPC Server handler 2 on default port 33305] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:initReplicaRecoveryImpl(2646)) - initReplicaRecovery: changing replica state for blk_1073741827_1003 from FINALIZED to RUR
2020-12-03 07:21:06,809 [IPC Server handler 0 on default port 45885] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:initReplicaRecoveryImpl(2588)) - initReplicaRecovery: blk_1073741827_1003, recoveryId=1004, replica=FinalizedReplica, blk_1073741827_1003, FINALIZED
  getNumBytes()     = 3
  getBytesOnDisk()  = 3
  getVisibleLength()= 3
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-425068830-172.17.0.8-1606980057018/current/finalized/subdir0/subdir0/blk_1073741827
2020-12-03 07:21:06,810 [IPC Server handler 0 on default port 45885] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:initReplicaRecoveryImpl(2646)) - initReplicaRecovery: changing replica state for blk_1073741827_1003 from FINALIZED to RUR
2020-12-03 07:21:06,811 [org.apache.hadoop.hdfs.server.datanode.BlockRecoveryWorker$1@4c2fa7ad] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:initReplicaRecoveryImpl(2588)) - initReplicaRecovery: blk_1073741827_1003, recoveryId=1004, replica=FinalizedReplica, blk_1073741827_1003, FINALIZED
  getNumBytes()     = 3
  getBytesOnDisk()  = 3
  getVisibleLength()= 3
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-425068830-172.17.0.8-1606980057018/current/finalized/subdir0/subdir0/blk_1073741827
2020-12-03 07:21:06,811 [org.apache.hadoop.hdfs.server.datanode.BlockRecoveryWorker$1@4c2fa7ad] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:initReplicaRecoveryImpl(2646)) - initReplicaRecovery: changing replica state for blk_1073741827_1003 from FINALIZED to RUR
2020-12-03 07:21:06,811 [org.apache.hadoop.hdfs.server.datanode.BlockRecoveryWorker$1@4c2fa7ad] INFO  datanode.DataNode (BlockRecoveryWorker.java:syncBlock(200)) - BlockRecoveryWorker: block=BP-425068830-172.17.0.8-1606980057018:blk_1073741827_1003 (length=3), isTruncateRecovery=true, syncList=[block:blk_1073741827_1003[numBytes=3,originalReplicaState=FINALIZED] node:DatanodeInfoWithStorage[127.0.0.1:33245,null,null], block:blk_1073741827_1003[numBytes=3,originalReplicaState=FINALIZED] node:DatanodeInfoWithStorage[127.0.0.1:41706,null,null], block:blk_1073741827_1003[numBytes=3,originalReplicaState=FINALIZED] node:DatanodeInfoWithStorage[127.0.0.1:33147,null,null]]
2020-12-03 07:21:06,812 [org.apache.hadoop.hdfs.server.datanode.BlockRecoveryWorker$1@4c2fa7ad] INFO  datanode.DataNode (BlockRecoveryWorker.java:syncBlock(293)) - BlockRecoveryWorker: block=BP-425068830-172.17.0.8-1606980057018:blk_1073741827_1003 (length=3), bestState=FINALIZED, newBlock=BP-425068830-172.17.0.8-1606980057018:blk_1073741828_1004 (length=2), participatingList=[block:blk_1073741827_1003[numBytes=3,originalReplicaState=FINALIZED] node:DatanodeInfoWithStorage[127.0.0.1:33245,null,null], block:blk_1073741827_1003[numBytes=3,originalReplicaState=FINALIZED] node:DatanodeInfoWithStorage[127.0.0.1:41706,null,null], block:blk_1073741827_1003[numBytes=3,originalReplicaState=FINALIZED] node:DatanodeInfoWithStorage[127.0.0.1:33147,null,null]]
2020-12-03 07:21:06,812 [IPC Server handler 1 on default port 33305] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:updateReplicaUnderRecovery(2667)) - updateReplica: BP-425068830-172.17.0.8-1606980057018:blk_1073741827_1003, recoveryId=1004, length=2, replica=ReplicaUnderRecovery, blk_1073741827_1003, RUR
  getNumBytes()     = 3
  getBytesOnDisk()  = 3
  getVisibleLength()= 3
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-425068830-172.17.0.8-1606980057018/current/finalized/subdir0/subdir0/blk_1073741827
  recoveryId=1004
  original=FinalizedReplica, blk_1073741827_1003, FINALIZED
  getNumBytes()     = 3
  getBytesOnDisk()  = 3
  getVisibleLength()= 3
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-425068830-172.17.0.8-1606980057018/current/finalized/subdir0/subdir0/blk_1073741827
2020-12-03 07:21:06,827 [IPC Server handler 1 on default port 33305] INFO  datanode.DataNode (LocalReplica.java:breakHardLinksIfNeeded(244)) - Breaking hardlink for 2x-linked block ReplicaUnderRecovery, blk_1073741827_1003, RUR
  getNumBytes()     = 3
  getBytesOnDisk()  = 3
  getVisibleLength()= 3
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-425068830-172.17.0.8-1606980057018/current/finalized/subdir0/subdir0/blk_1073741827
  recoveryId=1004
  original=FinalizedReplica, blk_1073741827_1003, FINALIZED
  getNumBytes()     = 3
  getBytesOnDisk()  = 3
  getVisibleLength()= 3
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-425068830-172.17.0.8-1606980057018/current/finalized/subdir0/subdir0/blk_1073741827
2020-12-03 07:21:06,841 [IPC Server handler 1 on default port 33305] INFO  datanode.LocalReplica (LocalReplica.java:truncateBlock(473)) - truncateBlock: blockFile=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-425068830-172.17.0.8-1606980057018/tmp/subdir0/subdir0/blk_1073741828, metaFile=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-425068830-172.17.0.8-1606980057018/tmp/subdir0/subdir0/blk_1073741828_1004.meta, oldlen=3, newlen=2
2020-12-03 07:21:06,844 [IPC Server handler 1 on default port 45885] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:updateReplicaUnderRecovery(2667)) - updateReplica: BP-425068830-172.17.0.8-1606980057018:blk_1073741827_1003, recoveryId=1004, length=2, replica=ReplicaUnderRecovery, blk_1073741827_1003, RUR
  getNumBytes()     = 3
  getBytesOnDisk()  = 3
  getVisibleLength()= 3
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-425068830-172.17.0.8-1606980057018/current/finalized/subdir0/subdir0/blk_1073741827
  recoveryId=1004
  original=FinalizedReplica, blk_1073741827_1003, FINALIZED
  getNumBytes()     = 3
  getBytesOnDisk()  = 3
  getVisibleLength()= 3
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-425068830-172.17.0.8-1606980057018/current/finalized/subdir0/subdir0/blk_1073741827
2020-12-03 07:21:06,856 [IPC Server handler 1 on default port 45885] INFO  datanode.DataNode (LocalReplica.java:breakHardLinksIfNeeded(244)) - Breaking hardlink for 2x-linked block ReplicaUnderRecovery, blk_1073741827_1003, RUR
  getNumBytes()     = 3
  getBytesOnDisk()  = 3
  getVisibleLength()= 3
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-425068830-172.17.0.8-1606980057018/current/finalized/subdir0/subdir0/blk_1073741827
  recoveryId=1004
  original=FinalizedReplica, blk_1073741827_1003, FINALIZED
  getNumBytes()     = 3
  getBytesOnDisk()  = 3
  getVisibleLength()= 3
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-425068830-172.17.0.8-1606980057018/current/finalized/subdir0/subdir0/blk_1073741827
2020-12-03 07:21:06,867 [IPC Server handler 1 on default port 45885] INFO  datanode.LocalReplica (LocalReplica.java:truncateBlock(473)) - truncateBlock: blockFile=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-425068830-172.17.0.8-1606980057018/tmp/subdir0/subdir0/blk_1073741828, metaFile=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-425068830-172.17.0.8-1606980057018/tmp/subdir0/subdir0/blk_1073741828_1004.meta, oldlen=3, newlen=2
2020-12-03 07:21:06,870 [org.apache.hadoop.hdfs.server.datanode.BlockRecoveryWorker$1@4c2fa7ad] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:updateReplicaUnderRecovery(2667)) - updateReplica: BP-425068830-172.17.0.8-1606980057018:blk_1073741827_1003[numBytes=3,originalReplicaState=FINALIZED], recoveryId=1004, length=2, replica=ReplicaUnderRecovery, blk_1073741827_1003, RUR
  getNumBytes()     = 3
  getBytesOnDisk()  = 3
  getVisibleLength()= 3
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-425068830-172.17.0.8-1606980057018/current/finalized/subdir0/subdir0/blk_1073741827
  recoveryId=1004
  original=FinalizedReplica, blk_1073741827_1003, FINALIZED
  getNumBytes()     = 3
  getBytesOnDisk()  = 3
  getVisibleLength()= 3
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-425068830-172.17.0.8-1606980057018/current/finalized/subdir0/subdir0/blk_1073741827
2020-12-03 07:21:06,884 [org.apache.hadoop.hdfs.server.datanode.BlockRecoveryWorker$1@4c2fa7ad] INFO  datanode.DataNode (LocalReplica.java:breakHardLinksIfNeeded(244)) - Breaking hardlink for 2x-linked block ReplicaUnderRecovery, blk_1073741827_1003, RUR
  getNumBytes()     = 3
  getBytesOnDisk()  = 3
  getVisibleLength()= 3
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-425068830-172.17.0.8-1606980057018/current/finalized/subdir0/subdir0/blk_1073741827
  recoveryId=1004
  original=FinalizedReplica, blk_1073741827_1003, FINALIZED
  getNumBytes()     = 3
  getBytesOnDisk()  = 3
  getVisibleLength()= 3
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-425068830-172.17.0.8-1606980057018/current/finalized/subdir0/subdir0/blk_1073741827
2020-12-03 07:21:06,888 [IPC Server handler 9 on default port 37869] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/test/testUpgrade	dst=null	perm=null	proto=rpc
2020-12-03 07:21:06,902 [org.apache.hadoop.hdfs.server.datanode.BlockRecoveryWorker$1@4c2fa7ad] INFO  datanode.LocalReplica (LocalReplica.java:truncateBlock(473)) - truncateBlock: blockFile=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-425068830-172.17.0.8-1606980057018/tmp/subdir0/subdir0/blk_1073741828, metaFile=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-425068830-172.17.0.8-1606980057018/tmp/subdir0/subdir0/blk_1073741828_1004.meta, oldlen=3, newlen=2
2020-12-03 07:21:06,904 [IPC Server handler 8 on default port 37869] INFO  namenode.FSNamesystem (FSNamesystem.java:commitBlockSynchronization(3655)) - commitBlockSynchronization(oldBlock=BP-425068830-172.17.0.8-1606980057018:blk_1073741827_1003, newgenerationstamp=1004, newlength=2, newtargets=[127.0.0.1:33245, 127.0.0.1:41706, 127.0.0.1:33147], closeFile=true, deleteBlock=false)
2020-12-03 07:21:06,905 [IPC Server handler 8 on default port 37869] DEBUG hdfs.StateChange (FSNamesystem.java:closeFile(4036)) - closeFile: /test/testUpgrade with 2 blocks is persisted to the file system
2020-12-03 07:21:06,908 [IPC Server handler 8 on default port 37869] WARN  ipc.Server (Server.java:logException(2974)) - IPC Server handler 8 on default port 37869, call Call#104 Retry#0 org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol.commitBlockSynchronization from 127.0.0.1:37346
java.lang.AssertionError
	at org.apache.hadoop.hdfs.server.blockmanagement.BlocksMap.removeBlock(BlocksMap.java:103)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.removeBlockFromMap(BlockManager.java:4633)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.removeBlock(BlockManager.java:4394)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.commitBlockSynchronization(FSNamesystem.java:3790)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.commitBlockSynchronization(NameNodeRpcServer.java:998)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolServerSideTranslatorPB.commitBlockSynchronization(DatanodeProtocolServerSideTranslatorPB.java:302)
	at org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$DatanodeProtocolService$2.callBlockingMethod(DatanodeProtocolProtos.java:31676)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
2020-12-03 07:21:06,912 [org.apache.hadoop.hdfs.server.datanode.BlockRecoveryWorker$1@4c2fa7ad] WARN  datanode.DataNode (BlockRecoveryWorker.java:run(607)) - recoverBlocks FAILED: RecoveringBlock{BP-425068830-172.17.0.8-1606980057018:blk_1073741827_1003; getBlockSize()=3; corrupt=false; offset=-1; locs=[DatanodeInfoWithStorage[127.0.0.1:33245,null,null], DatanodeInfoWithStorage[127.0.0.1:41706,null,null], DatanodeInfoWithStorage[127.0.0.1:33147,null,null]]}
org.apache.hadoop.ipc.RemoteException(java.lang.AssertionError): java.lang.AssertionError
	at org.apache.hadoop.hdfs.server.blockmanagement.BlocksMap.removeBlock(BlocksMap.java:103)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.removeBlockFromMap(BlockManager.java:4633)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.removeBlock(BlockManager.java:4394)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.commitBlockSynchronization(FSNamesystem.java:3790)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.commitBlockSynchronization(NameNodeRpcServer.java:998)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolServerSideTranslatorPB.commitBlockSynchronization(DatanodeProtocolServerSideTranslatorPB.java:302)
	at org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$DatanodeProtocolService$2.callBlockingMethod(DatanodeProtocolProtos.java:31676)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1545)
	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
	at com.sun.proxy.$Proxy24.commitBlockSynchronization(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.commitBlockSynchronization(DatanodeProtocolClientSideTranslatorPB.java:327)
	at org.apache.hadoop.hdfs.server.datanode.BlockRecoveryWorker$RecoveryTaskContiguous.syncBlock(BlockRecoveryWorker.java:333)
	at org.apache.hadoop.hdfs.server.datanode.BlockRecoveryWorker$RecoveryTaskContiguous.recover(BlockRecoveryWorker.java:188)
	at org.apache.hadoop.hdfs.server.datanode.BlockRecoveryWorker$1.run(BlockRecoveryWorker.java:604)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:21:06,997 [IPC Server handler 0 on default port 37869] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/test/testUpgrade	dst=null	perm=null	proto=rpc
2020-12-03 07:21:07,001 [IPC Server handler 1 on default port 37869] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testUpgrade	dst=null	perm=null	proto=rpc
2020-12-03 07:21:07,002 [IPC Server handler 2 on default port 37869] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/test/testUpgrade	dst=null	perm=null	proto=rpc
2020-12-03 07:21:07,006 [Listener at localhost/33229] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:07,010 [Listener at localhost/33229] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:07,012 [Listener at localhost/33229] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:21:07,013 [Listener at localhost/33229] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 2
2020-12-03 07:21:07,013 [Listener at localhost/33229] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:21:07,013 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@70e3f36f] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:21:07,014 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-c38ad29d-afe4-4ee0-be21-3867655f82fb) exiting.
2020-12-03 07:21:07,014 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-07458f0c-3587-41d4-abeb-821d73c89765) exiting.
2020-12-03 07:21:07,030 [Listener at localhost/33229] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@4e25147a{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:21:07,031 [Listener at localhost/33229] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6b68cb27{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:21:07,031 [Listener at localhost/33229] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@432034a{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:21:07,032 [Listener at localhost/33229] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@61f3fbb8{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:21:07,033 [Listener at localhost/33229] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 33229
2020-12-03 07:21:07,038 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:07,039 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:07,039 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:37869] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:07,039 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:37869] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-425068830-172.17.0.8-1606980057018 (Datanode Uuid 5326576b-2216-4538-9245-8b0fb17c9d46) service to localhost/127.0.0.1:37869
2020-12-03 07:21:07,040 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:37869] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-425068830-172.17.0.8-1606980057018 (Datanode Uuid 5326576b-2216-4538-9245-8b0fb17c9d46)
2020-12-03 07:21:07,040 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:37869] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:07,041 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-425068830-172.17.0.8-1606980057018] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:07,041 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-425068830-172.17.0.8-1606980057018] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:07,044 [Listener at localhost/33229] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:21:07,044 [Listener at localhost/33229] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:21:07,045 [Listener at localhost/33229] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:21:07,045 [Listener at localhost/33229] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:21:07,047 [Listener at localhost/33229] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:21:07,047 [Listener at localhost/33229] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 1
2020-12-03 07:21:07,048 [Listener at localhost/33229] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:21:07,048 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@4a7761b1] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:21:07,049 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-9a7d7b8b-ec12-469a-9a7d-60ed5e71167a) exiting.
2020-12-03 07:21:07,049 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-d40683d6-ae9f-4bbb-bc67-169f6d82dbbb) exiting.
2020-12-03 07:21:07,075 [Listener at localhost/33229] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@f8f56b9{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:21:07,076 [Listener at localhost/33229] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2c656f16{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:21:07,077 [Listener at localhost/33229] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@c27d163{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:21:07,077 [Listener at localhost/33229] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4e4c3a38{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:21:07,078 [Listener at localhost/33229] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 45885
2020-12-03 07:21:07,085 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:07,085 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:07,085 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:37869] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:07,085 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:37869] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-425068830-172.17.0.8-1606980057018 (Datanode Uuid 0b0f70d2-7565-48f3-b01c-1adf7b4ab560) service to localhost/127.0.0.1:37869
2020-12-03 07:21:07,086 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:37869] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-425068830-172.17.0.8-1606980057018 (Datanode Uuid 0b0f70d2-7565-48f3-b01c-1adf7b4ab560)
2020-12-03 07:21:07,086 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:37869] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:07,091 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-425068830-172.17.0.8-1606980057018] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:07,093 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-425068830-172.17.0.8-1606980057018] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:07,095 [Listener at localhost/33229] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:21:07,095 [Listener at localhost/33229] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:21:07,096 [Listener at localhost/33229] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:21:07,096 [Listener at localhost/33229] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:21:07,097 [Listener at localhost/33229] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:21:07,097 [Listener at localhost/33229] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:21:07,098 [Listener at localhost/33229] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:21:07,098 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@1542af63] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:21:07,100 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-e2a4702c-e5d8-49ec-98d9-afcba9a4bf2b) exiting.
2020-12-03 07:21:07,100 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-7f94b3d0-d801-4a3a-80c5-f0a5c86996d0) exiting.
2020-12-03 07:21:07,120 [Listener at localhost/33229] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5b22b970{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:21:07,121 [Listener at localhost/33229] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@22d1886d{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:21:07,121 [Listener at localhost/33229] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@562c877a{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:21:07,122 [Listener at localhost/33229] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@65004ff6{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:21:07,122 [Listener at localhost/33229] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 33305
2020-12-03 07:21:07,125 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:07,125 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:07,125 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:37869] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:07,126 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:37869] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-425068830-172.17.0.8-1606980057018 (Datanode Uuid 81972425-7fba-4dbf-b586-2759576dcb2a) service to localhost/127.0.0.1:37869
2020-12-03 07:21:07,126 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:37869] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-425068830-172.17.0.8-1606980057018 (Datanode Uuid 81972425-7fba-4dbf-b586-2759576dcb2a)
2020-12-03 07:21:07,126 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:37869] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:07,127 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-425068830-172.17.0.8-1606980057018] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:07,128 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-425068830-172.17.0.8-1606980057018] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:07,134 [Listener at localhost/33229] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:21:07,134 [Listener at localhost/33229] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:21:07,135 [Listener at localhost/33229] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:21:07,136 [Listener at localhost/33229] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:21:07,138 [Listener at localhost/33229] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:21:07,138 [Listener at localhost/33229] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:21:07,139 [Listener at localhost/33229] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:21:07,139 [Listener at localhost/33229] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 19, 23
2020-12-03 07:21:07,140 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@4c27d39d] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:21:07,139 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@4a9486c0] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:21:07,142 [Listener at localhost/33229] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 6 Total time for transactions(ms): 8 Number of transactions batched in Syncs: 19 Number of syncs: 6 SyncTimes(ms): 6 2 
2020-12-03 07:21:07,143 [Listener at localhost/33229] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000019 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000019-0000000000000000024
2020-12-03 07:21:07,144 [Listener at localhost/33229] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000019 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000019-0000000000000000024
2020-12-03 07:21:07,145 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:21:07,145 [CacheReplicationMonitor(110939807)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:21:07,153 [Listener at localhost/33229] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 37869
2020-12-03 07:21:07,155 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:07,155 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:07,160 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:21:07,160 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:21:07,168 [Listener at localhost/33229] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:21:07,169 [Listener at localhost/33229] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:21:07,170 [Listener at localhost/33229] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@79a1728c{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:21:07,172 [Listener at localhost/33229] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@a7f0ab6{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:21:07,172 [Listener at localhost/33229] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@30404dba{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:21:07,173 [Listener at localhost/33229] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@11a7ba62{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:21:07,174 [Listener at localhost/33229] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-12-03 07:21:07,180 [Listener at localhost/33229] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-12-03 07:21:07,180 [Listener at localhost/33229] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-12-03 07:21:07,195 [Listener at localhost/33229] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:21:07,196 [Listener at localhost/33229] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:21:07,196 [Listener at localhost/33229] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:21:07,196 [Listener at localhost/33229] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:21:07,196 [Listener at localhost/33229] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:21:07,197 [Listener at localhost/33229] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:21:07,197 [Listener at localhost/33229] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:21:07,197 [Listener at localhost/33229] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:21:07,198 [Listener at localhost/33229] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:07,198 [Listener at localhost/33229] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:07,198 [Listener at localhost/33229] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=20, effected=1000
2020-12-03 07:21:07,198 [Listener at localhost/33229] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:21:07,199 [Listener at localhost/33229] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:07,199 [Listener at localhost/33229] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:21:07,199 [Listener at localhost/33229] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:21:07
2020-12-03 07:21:07,199 [Listener at localhost/33229] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:21:07,200 [Listener at localhost/33229] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:07,200 [Listener at localhost/33229] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:21:07,200 [Listener at localhost/33229] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:21:07,212 [Listener at localhost/33229] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:07,212 [Listener at localhost/33229] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:07,213 [Listener at localhost/33229] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:21:07,213 [Listener at localhost/33229] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:21:07,213 [Listener at localhost/33229] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:07,213 [Listener at localhost/33229] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:21:07,213 [Listener at localhost/33229] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:21:07,213 [Listener at localhost/33229] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:21:07,213 [Listener at localhost/33229] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:21:07,214 [Listener at localhost/33229] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:21:07,214 [Listener at localhost/33229] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:21:07,214 [Listener at localhost/33229] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:21:07,214 [Listener at localhost/33229] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:21:07,214 [Listener at localhost/33229] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:21:07,214 [Listener at localhost/33229] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:21:07,214 [Listener at localhost/33229] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:21:07,215 [Listener at localhost/33229] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:21:07,215 [Listener at localhost/33229] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:07,215 [Listener at localhost/33229] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:21:07,215 [Listener at localhost/33229] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:21:07,221 [Listener at localhost/33229] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:21:07,222 [Listener at localhost/33229] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:21:07,222 [Listener at localhost/33229] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:21:07,222 [Listener at localhost/33229] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:21:07,222 [Listener at localhost/33229] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:21:07,222 [Listener at localhost/33229] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:21:07,222 [Listener at localhost/33229] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:21:07,222 [Listener at localhost/33229] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:07,223 [Listener at localhost/33229] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:21:07,223 [Listener at localhost/33229] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:21:07,224 [Listener at localhost/33229] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:21:07,224 [Listener at localhost/33229] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:21:07,224 [Listener at localhost/33229] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:21:07,224 [Listener at localhost/33229] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:21:07,224 [Listener at localhost/33229] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:21:07,224 [Listener at localhost/33229] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:21:07,224 [Listener at localhost/33229] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:07,225 [Listener at localhost/33229] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:21:07,225 [Listener at localhost/33229] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
"rollBack" will remove the current state of the file system,
returning you to the state prior to initiating your recent.
upgrade. This action is permanent and cannot be undone. If you
are performing a rollback in an HA environment, you should be
certain that no NameNode process is running on any host.2020-12-03 07:21:07,227 [Listener at localhost/33229] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:21:07,228 [Listener at localhost/33229] INFO  namenode.FSImage (FSImage.java:doRollback(532)) - Can perform rollback for Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1; location= null
2020-12-03 07:21:07,228 [Listener at localhost/33229] INFO  namenode.FSImage (FSImage.java:doRollback(532)) - Can perform rollback for Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2; location= null
2020-12-03 07:21:07,229 [Listener at localhost/33229] INFO  namenode.FSImage (FSImage.java:doRollback(555)) - Rolling back storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1.
   new LV = -65; new CTime = 1606980057018
2020-12-03 07:21:07,230 [Listener at localhost/33229] INFO  namenode.NNUpgradeUtil (NNUpgradeUtil.java:doRollBack(235)) - Rollback of /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 is complete.
2020-12-03 07:21:07,230 [Listener at localhost/33229] INFO  namenode.FSImage (FSImage.java:doRollback(555)) - Rolling back storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2.
   new LV = -65; new CTime = 1606980057018
2020-12-03 07:21:07,231 [Listener at localhost/33229] INFO  namenode.NNUpgradeUtil (NNUpgradeUtil.java:doRollBack(235)) - Rollback of /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 is complete.
2020-12-03 07:21:07,232 [Listener at localhost/33229] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=3
2020-12-03 07:21:07,233 [Listener at localhost/33229] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:21:07,237 [Listener at localhost/33229] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:21:07,238 [Listener at localhost/33229] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:21:07,239 [Listener at localhost/33229] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:21:07,240 [Listener at localhost/33229] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-12-03 07:21:07,251 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@58399d82] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:21:07,251 [Listener at localhost/33229] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:21:07,251 [Listener at localhost/33229] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:07,253 [Listener at localhost/33229] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:21:07,253 [Listener at localhost/33229] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:21:07,254 [Listener at localhost/33229] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:07,255 [Listener at localhost/33229] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:21:07,256 [Listener at localhost/33229] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:21:07,256 [Listener at localhost/33229] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:21:07,256 [Listener at localhost/33229] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:21:07,258 [Listener at localhost/33229] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:21:07,258 [Listener at localhost/33229] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:21:07,258 [Listener at localhost/33229] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 41396
2020-12-03 07:21:07,259 [Listener at localhost/33229] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:21:07,261 [Listener at localhost/33229] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7bb004b8{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:21:07,262 [Listener at localhost/33229] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@652ce654{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:21:07,268 [Listener at localhost/33229] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@59429fac{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:21:07,272 [Listener at localhost/33229] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@57aa341b{HTTP/1.1,[http/1.1]}{localhost:41396}
2020-12-03 07:21:07,272 [Listener at localhost/33229] INFO  server.Server (Server.java:doStart(419)) - Started @12266ms
2020-12-03 07:21:07,274 [Listener at localhost/33229] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:21:07,275 [Listener at localhost/33229] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:21:07,275 [Listener at localhost/33229] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:21:07,275 [Listener at localhost/33229] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:21:07,275 [Listener at localhost/33229] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:21:07,275 [Listener at localhost/33229] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:21:07,276 [Listener at localhost/33229] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:21:07,276 [Listener at localhost/33229] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:21:07,276 [Listener at localhost/33229] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:07,277 [Listener at localhost/33229] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:07,277 [Listener at localhost/33229] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=20, effected=1000
2020-12-03 07:21:07,277 [Listener at localhost/33229] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:21:07,277 [Listener at localhost/33229] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:07,278 [Listener at localhost/33229] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:21:07,278 [Listener at localhost/33229] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:21:07
2020-12-03 07:21:07,279 [Listener at localhost/33229] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:21:07,279 [Listener at localhost/33229] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:07,279 [Listener at localhost/33229] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:21:07,279 [Listener at localhost/33229] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:21:07,293 [Listener at localhost/33229] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:07,294 [Listener at localhost/33229] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:07,294 [Listener at localhost/33229] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:21:07,294 [Listener at localhost/33229] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:21:07,295 [Listener at localhost/33229] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:07,295 [Listener at localhost/33229] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:21:07,295 [Listener at localhost/33229] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:21:07,295 [Listener at localhost/33229] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:21:07,296 [Listener at localhost/33229] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:21:07,296 [Listener at localhost/33229] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:21:07,296 [Listener at localhost/33229] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:21:07,296 [Listener at localhost/33229] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:21:07,297 [Listener at localhost/33229] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:21:07,297 [Listener at localhost/33229] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:21:07,297 [Listener at localhost/33229] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:21:07,297 [Listener at localhost/33229] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:21:07,298 [Listener at localhost/33229] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:21:07,298 [Listener at localhost/33229] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:07,298 [Listener at localhost/33229] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:21:07,299 [Listener at localhost/33229] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:21:07,307 [Listener at localhost/33229] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:21:07,307 [Listener at localhost/33229] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:21:07,307 [Listener at localhost/33229] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:21:07,308 [Listener at localhost/33229] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:21:07,308 [Listener at localhost/33229] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:21:07,308 [Listener at localhost/33229] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:21:07,308 [Listener at localhost/33229] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:21:07,309 [Listener at localhost/33229] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:07,309 [Listener at localhost/33229] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:21:07,310 [Listener at localhost/33229] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:21:07,312 [Listener at localhost/33229] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:21:07,312 [Listener at localhost/33229] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:21:07,312 [Listener at localhost/33229] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:21:07,313 [Listener at localhost/33229] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:21:07,313 [Listener at localhost/33229] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:21:07,313 [Listener at localhost/33229] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:21:07,313 [Listener at localhost/33229] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:07,314 [Listener at localhost/33229] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:21:07,314 [Listener at localhost/33229] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:21:07,365 [Listener at localhost/33229] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 2630@9bd33dce04e9
2020-12-03 07:21:07,424 [Listener at localhost/33229] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 2630@9bd33dce04e9
2020-12-03 07:21:07,428 [Listener at localhost/33229] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-12-03 07:21:07,428 [Listener at localhost/33229] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-12-03 07:21:07,429 [Listener at localhost/33229] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:21:07,433 [Listener at localhost/33229] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:21:07,433 [Listener at localhost/33229] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:21:07,434 [Listener at localhost/33229] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-12-03 07:21:07,434 [Listener at localhost/33229] INFO  namenode.FSImage (FSImage.java:loadEdits(910)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@588cd519 expecting start txid #1
2020-12-03 07:21:07,434 [Listener at localhost/33229] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000018, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000018 maxTxnsToRead = 9223372036854775807
2020-12-03 07:21:07,435 [Listener at localhost/33229] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:loadEditRecords(217)) - Acquiring write lock to replay edit log
2020-12-03 07:21:07,435 [Listener at localhost/33229] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000018' to transaction ID 1
2020-12-03 07:21:07,435 [Listener at localhost/33229] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:loadEditRecords(284)) - op=LogSegmentOp [opCode=OP_START_LOG_SEGMENT, txid=1], startOpt=REGULAR, numEdits=0, totalEdits=0
2020-12-03 07:21:07,435 [Listener at localhost/33229] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:applyEditLogOp(388)) - replaying edit log: LogSegmentOp [opCode=OP_START_LOG_SEGMENT, txid=1]
2020-12-03 07:21:07,436 [Listener at localhost/33229] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:loadEditRecords(284)) - op=MkdirOp [length=0, inodeId=16386, path=/test, timestamp=1606980062499, permissions=root:supergroup:rwxr-xr-x, aclEntries=null, opCode=OP_MKDIR, txid=2, xAttrs=[]], startOpt=REGULAR, numEdits=1, totalEdits=1
2020-12-03 07:21:07,436 [Listener at localhost/33229] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:applyEditLogOp(388)) - replaying edit log: MkdirOp [length=0, inodeId=16386, path=/test, timestamp=1606980062499, permissions=root:supergroup:rwxr-xr-x, aclEntries=null, opCode=OP_MKDIR, txid=2, xAttrs=[]]
2020-12-03 07:21:07,436 [Listener at localhost/33229] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:loadEditRecords(284)) - op=SetQuotaOp [src=/test, nsQuota=100, dsQuota=1000, opCode=OP_SET_QUOTA, txid=3], startOpt=REGULAR, numEdits=2, totalEdits=2
2020-12-03 07:21:07,436 [Listener at localhost/33229] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:applyEditLogOp(388)) - replaying edit log: SetQuotaOp [src=/test, nsQuota=100, dsQuota=1000, opCode=OP_SET_QUOTA, txid=3]
2020-12-03 07:21:07,437 [Listener at localhost/33229] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:loadEditRecords(284)) - op=AllowSnapshotOp [snapshotRoot=/test], startOpt=REGULAR, numEdits=3, totalEdits=3
2020-12-03 07:21:07,437 [Listener at localhost/33229] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:applyEditLogOp(388)) - replaying edit log: AllowSnapshotOp [snapshotRoot=/test]
2020-12-03 07:21:07,437 [Listener at localhost/33229] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:loadEditRecords(284)) - op=AddOp [length=0, inodeId=16387, path=/test/testUpgrade, replication=3, mtime=1606980062569, atime=1606980062569, blockSize=4, blocks=[], permissions=root:supergroup:rw-r--r--, aclEntries=null, clientName=DFSClient_NONMAPREDUCE_742258692_1, clientMachine=127.0.0.1, overwrite=true, RpcClientId=18c30b59-4f7a-4dab-9f18-e65cd6773072, RpcCallId=28, storagePolicyId=0, erasureCodingPolicyId=0, opCode=OP_ADD, txid=5], startOpt=REGULAR, numEdits=4, totalEdits=4
2020-12-03 07:21:07,437 [Listener at localhost/33229] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:applyEditLogOp(388)) - replaying edit log: AddOp [length=0, inodeId=16387, path=/test/testUpgrade, replication=3, mtime=1606980062569, atime=1606980062569, blockSize=4, blocks=[], permissions=root:supergroup:rw-r--r--, aclEntries=null, clientName=DFSClient_NONMAPREDUCE_742258692_1, clientMachine=127.0.0.1, overwrite=true, RpcClientId=18c30b59-4f7a-4dab-9f18-e65cd6773072, RpcCallId=28, storagePolicyId=0, erasureCodingPolicyId=0, opCode=OP_ADD, txid=5]
2020-12-03 07:21:07,438 [Listener at localhost/33229] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:loadEditRecords(284)) - op=AllocateBlockIdOp [blockId=1073741825, opCode=OP_ALLOCATE_BLOCK_ID, txid=6], startOpt=REGULAR, numEdits=5, totalEdits=5
2020-12-03 07:21:07,438 [Listener at localhost/33229] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:applyEditLogOp(388)) - replaying edit log: AllocateBlockIdOp [blockId=1073741825, opCode=OP_ALLOCATE_BLOCK_ID, txid=6]
2020-12-03 07:21:07,438 [Listener at localhost/33229] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:loadEditRecords(284)) - op=SetGenstampV2Op [GenStampV2=1001, opCode=OP_SET_GENSTAMP_V2, txid=7], startOpt=REGULAR, numEdits=6, totalEdits=6
2020-12-03 07:21:07,438 [Listener at localhost/33229] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:applyEditLogOp(388)) - replaying edit log: SetGenstampV2Op [GenStampV2=1001, opCode=OP_SET_GENSTAMP_V2, txid=7]
2020-12-03 07:21:07,439 [Listener at localhost/33229] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:loadEditRecords(284)) - op=AddBlockOp [path=/test/testUpgrade, penultimateBlock=NULL, lastBlock=blk_1073741825_1001, RpcClientId=, RpcCallId=-2], startOpt=REGULAR, numEdits=7, totalEdits=7
2020-12-03 07:21:07,439 [Listener at localhost/33229] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:applyEditLogOp(388)) - replaying edit log: AddBlockOp [path=/test/testUpgrade, penultimateBlock=NULL, lastBlock=blk_1073741825_1001, RpcClientId=, RpcCallId=-2]
2020-12-03 07:21:07,439 [Listener at localhost/33229] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:loadEditRecords(284)) - op=AllocateBlockIdOp [blockId=1073741826, opCode=OP_ALLOCATE_BLOCK_ID, txid=9], startOpt=REGULAR, numEdits=8, totalEdits=8
2020-12-03 07:21:07,439 [Listener at localhost/33229] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:applyEditLogOp(388)) - replaying edit log: AllocateBlockIdOp [blockId=1073741826, opCode=OP_ALLOCATE_BLOCK_ID, txid=9]
2020-12-03 07:21:07,440 [Listener at localhost/33229] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:loadEditRecords(284)) - op=SetGenstampV2Op [GenStampV2=1002, opCode=OP_SET_GENSTAMP_V2, txid=10], startOpt=REGULAR, numEdits=9, totalEdits=9
2020-12-03 07:21:07,440 [Listener at localhost/33229] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:applyEditLogOp(388)) - replaying edit log: SetGenstampV2Op [GenStampV2=1002, opCode=OP_SET_GENSTAMP_V2, txid=10]
2020-12-03 07:21:07,440 [Listener at localhost/33229] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:loadEditRecords(284)) - op=AddBlockOp [path=/test/testUpgrade, penultimateBlock=blk_1073741825_1001, lastBlock=blk_1073741826_1002, RpcClientId=, RpcCallId=-2], startOpt=REGULAR, numEdits=10, totalEdits=10
2020-12-03 07:21:07,440 [Listener at localhost/33229] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:applyEditLogOp(388)) - replaying edit log: AddBlockOp [path=/test/testUpgrade, penultimateBlock=blk_1073741825_1001, lastBlock=blk_1073741826_1002, RpcClientId=, RpcCallId=-2]
2020-12-03 07:21:07,441 [Listener at localhost/33229] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:loadEditRecords(284)) - op=CloseOp [length=0, inodeId=0, path=/test/testUpgrade, replication=3, mtime=1606980062855, atime=1606980062569, blockSize=4, blocks=[blk_1073741825_1001, blk_1073741826_1002], permissions=root:supergroup:rw-r--r--, aclEntries=null, clientName=, clientMachine=, overwrite=false, storagePolicyId=0, erasureCodingPolicyId=0, opCode=OP_CLOSE, txid=12], startOpt=REGULAR, numEdits=11, totalEdits=11
2020-12-03 07:21:07,441 [Listener at localhost/33229] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:applyEditLogOp(388)) - replaying edit log: CloseOp [length=0, inodeId=0, path=/test/testUpgrade, replication=3, mtime=1606980062855, atime=1606980062569, blockSize=4, blocks=[blk_1073741825_1001, blk_1073741826_1002], permissions=root:supergroup:rw-r--r--, aclEntries=null, clientName=, clientMachine=, overwrite=false, storagePolicyId=0, erasureCodingPolicyId=0, opCode=OP_CLOSE, txid=12]
2020-12-03 07:21:07,441 [Listener at localhost/33229] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:loadEditRecords(284)) - op=CreateSnapshotOp [snapshotRoot=/test, snapshotName=ss0, RpcClientId=18c30b59-4f7a-4dab-9f18-e65cd6773072, RpcCallId=39], startOpt=REGULAR, numEdits=12, totalEdits=12
2020-12-03 07:21:07,441 [Listener at localhost/33229] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:applyEditLogOp(388)) - replaying edit log: CreateSnapshotOp [snapshotRoot=/test, snapshotName=ss0, RpcClientId=18c30b59-4f7a-4dab-9f18-e65cd6773072, RpcCallId=39]
2020-12-03 07:21:07,442 [Listener at localhost/33229] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:loadEditRecords(284)) - op=AllocateBlockIdOp [blockId=1073741827, opCode=OP_ALLOCATE_BLOCK_ID, txid=14], startOpt=REGULAR, numEdits=13, totalEdits=13
2020-12-03 07:21:07,442 [Listener at localhost/33229] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:applyEditLogOp(388)) - replaying edit log: AllocateBlockIdOp [blockId=1073741827, opCode=OP_ALLOCATE_BLOCK_ID, txid=14]
2020-12-03 07:21:07,442 [Listener at localhost/33229] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:loadEditRecords(284)) - op=SetGenstampV2Op [GenStampV2=1003, opCode=OP_SET_GENSTAMP_V2, txid=15], startOpt=REGULAR, numEdits=14, totalEdits=14
2020-12-03 07:21:07,442 [Listener at localhost/33229] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:applyEditLogOp(388)) - replaying edit log: SetGenstampV2Op [GenStampV2=1003, opCode=OP_SET_GENSTAMP_V2, txid=15]
2020-12-03 07:21:07,442 [Listener at localhost/33229] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:loadEditRecords(284)) - op=TruncateOp [src=/test/testUpgrade, clientName=DFSClient_NONMAPREDUCE_742258692_1, clientMachine=127.0.0.1, newLength=7, timestamp=1606980062882, truncateBlock=blk_1073741827_1003, opCode=OP_TRUNCATE, txid=16], startOpt=REGULAR, numEdits=15, totalEdits=15
2020-12-03 07:21:07,442 [Listener at localhost/33229] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:applyEditLogOp(388)) - replaying edit log: TruncateOp [src=/test/testUpgrade, clientName=DFSClient_NONMAPREDUCE_742258692_1, clientMachine=127.0.0.1, newLength=7, timestamp=1606980062882, truncateBlock=blk_1073741827_1003, opCode=OP_TRUNCATE, txid=16]
2020-12-03 07:21:07,443 [Listener at localhost/33229] DEBUG hdfs.StateChange (FSDirTruncateOp.java:prepareFileForTruncate(252)) - BLOCK* prepareFileForTruncate: Scheduling copy-on-truncate to new size 3  new block blk_1073741827_1003 old block blk_1073741826_1002
2020-12-03 07:21:07,443 [Listener at localhost/33229] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:loadEditRecords(284)) - op=CloseOp [length=0, inodeId=0, path=/test/testUpgrade, replication=3, mtime=1606980063544, atime=1606980062569, blockSize=4, blocks=[blk_1073741825_1001, blk_1073741827_1003], permissions=root:supergroup:rw-r--r--, aclEntries=null, clientName=, clientMachine=, overwrite=false, storagePolicyId=0, erasureCodingPolicyId=0, opCode=OP_CLOSE, txid=17], startOpt=REGULAR, numEdits=16, totalEdits=16
2020-12-03 07:21:07,443 [Listener at localhost/33229] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:applyEditLogOp(388)) - replaying edit log: CloseOp [length=0, inodeId=0, path=/test/testUpgrade, replication=3, mtime=1606980063544, atime=1606980062569, blockSize=4, blocks=[blk_1073741825_1001, blk_1073741827_1003], permissions=root:supergroup:rw-r--r--, aclEntries=null, clientName=, clientMachine=, overwrite=false, storagePolicyId=0, erasureCodingPolicyId=0, opCode=OP_CLOSE, txid=17]
2020-12-03 07:21:07,444 [Listener at localhost/33229] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:loadEditRecords(284)) - op=LogSegmentOp [opCode=OP_END_LOG_SEGMENT, txid=18], startOpt=REGULAR, numEdits=17, totalEdits=17
2020-12-03 07:21:07,444 [Listener at localhost/33229] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:applyEditLogOp(388)) - replaying edit log: LogSegmentOp [opCode=OP_END_LOG_SEGMENT, txid=18]
2020-12-03 07:21:07,444 [Listener at localhost/33229] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:loadEditRecords(347)) - replaying edit log finished
2020-12-03 07:21:07,444 [Listener at localhost/33229] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(188)) - Loaded 1 edits file(s) (the last named /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000018, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000018) of total size 1059.0, total edits 18.0, total load time 10.0 ms
2020-12-03 07:21:07,444 [Listener at localhost/33229] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:21:07,445 [Listener at localhost/33229] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 19
2020-12-03 07:21:07,518 [Listener at localhost/33229] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:21:07,518 [Listener at localhost/33229] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 203 msecs
2020-12-03 07:21:07,519 [Listener at localhost/33229] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:21:07,520 [Listener at localhost/33229] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:21:07,520 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:21:07,527 [Listener at localhost/33125] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:33125 to access this namenode/service.
2020-12-03 07:21:07,527 [Listener at localhost/33125] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:21:07,558 [Listener at localhost/33125] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:21:07,560 [Listener at localhost/33125] INFO  hdfs.StateChange (BlockManagerSafeMode.java:reportStatus(617)) - STATE* Safe mode ON. 
The reported blocks 0 needs additional 2 blocks to reach the threshold 0.9990 of total blocks 3.
The minimum number of live datanodes is not required. Safe mode will be turned off automatically once the thresholds have been reached.
2020-12-03 07:21:07,566 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:21:07,566 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:21:07,571 [Listener at localhost/33125] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:33125
2020-12-03 07:21:07,572 [Listener at localhost/33125] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:21:07,572 [Listener at localhost/33125] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:21:07,573 [Listener at localhost/33125] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 1 milliseconds
name space=3
storage space=33
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:21:07,579 [CacheReplicationMonitor(598514225)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:21:07,580 [Listener at localhost/33125] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:21:07,582 [Listener at localhost/33125] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:21:07,582 [Listener at localhost/33125] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:21:07,585 [Listener at localhost/33125] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:21:07,585 [Listener at localhost/33125] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:07,585 [Listener at localhost/33125] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:21:07,586 [Listener at localhost/33125] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:21:07,586 [Listener at localhost/33125] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:07,586 [Listener at localhost/33125] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:07,586 [Listener at localhost/33125] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:07,586 [Listener at localhost/33125] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:21:07,587 [Listener at localhost/33125] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:41248
2020-12-03 07:21:07,587 [Listener at localhost/33125] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:21:07,587 [Listener at localhost/33125] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:21:07,589 [Listener at localhost/33125] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:07,590 [Listener at localhost/33125] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:21:07,591 [Listener at localhost/33125] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:21:07,591 [Listener at localhost/33125] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:07,593 [Listener at localhost/33125] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:21:07,594 [Listener at localhost/33125] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:21:07,594 [Listener at localhost/33125] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:21:07,595 [Listener at localhost/33125] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:21:07,596 [Listener at localhost/33125] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 38155
2020-12-03 07:21:07,596 [Listener at localhost/33125] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:21:07,598 [Listener at localhost/33125] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@70242f38{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:21:07,599 [Listener at localhost/33125] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@48c3205a{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:21:07,605 [Listener at localhost/33125] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@77b9d0c7{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:21:07,608 [Listener at localhost/33125] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@65fd6708{HTTP/1.1,[http/1.1]}{localhost:38155}
2020-12-03 07:21:07,608 [Listener at localhost/33125] INFO  server.Server (Server.java:doStart(419)) - Started @12602ms
2020-12-03 07:21:07,633 [Listener at localhost/33125] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:46077
2020-12-03 07:21:07,633 [Listener at localhost/33125] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:21:07,633 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@127f9161] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:21:07,634 [Listener at localhost/33125] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:21:07,634 [Listener at localhost/33125] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:21:07,635 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:21:07,640 [Listener at localhost/41151] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:41151
2020-12-03 07:21:07,651 [Listener at localhost/41151] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:21:07,652 [Listener at localhost/41151] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:21:07,653 [Thread-385] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33125 starting to offer service
2020-12-03 07:21:07,665 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:21:07,665 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:21:07,672 [Listener at localhost/41151] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:21:07,675 [Listener at localhost/41151] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:21:07,677 [Listener at localhost/41151] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:21:07,680 [Listener at localhost/41151] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:21:07,680 [Listener at localhost/41151] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:07,680 [Listener at localhost/41151] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:21:07,681 [Listener at localhost/41151] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:21:07,681 [Listener at localhost/41151] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:07,681 [Listener at localhost/41151] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:07,681 [Listener at localhost/41151] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:07,681 [Listener at localhost/41151] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:21:07,682 [Listener at localhost/41151] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:45667
2020-12-03 07:21:07,682 [Listener at localhost/41151] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:21:07,682 [Thread-385] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33125
2020-12-03 07:21:07,683 [Listener at localhost/41151] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:21:07,684 [Thread-385] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:21:07,686 [Listener at localhost/41151] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:07,689 [Listener at localhost/41151] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:21:07,690 [Listener at localhost/41151] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:21:07,690 [Listener at localhost/41151] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:07,693 [Listener at localhost/41151] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:21:07,694 [Listener at localhost/41151] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:21:07,694 [Listener at localhost/41151] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:21:07,694 [Listener at localhost/41151] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:21:07,695 [Listener at localhost/41151] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 35005
2020-12-03 07:21:07,696 [Listener at localhost/41151] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:21:07,697 [Listener at localhost/41151] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@766a4535{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:21:07,698 [Listener at localhost/41151] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@14e2e1c3{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:21:07,704 [Listener at localhost/41151] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6fd1660{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:21:07,707 [Listener at localhost/41151] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4a6c18ad{HTTP/1.1,[http/1.1]}{localhost:35005}
2020-12-03 07:21:07,707 [Listener at localhost/41151] INFO  server.Server (Server.java:doStart(419)) - Started @12701ms
2020-12-03 07:21:07,710 [Thread-385] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 2630@9bd33dce04e9
2020-12-03 07:21:07,731 [Listener at localhost/41151] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:37880
2020-12-03 07:21:07,732 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@20095ab4] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:21:07,732 [Listener at localhost/41151] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:21:07,732 [Listener at localhost/41151] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:21:07,732 [Listener at localhost/41151] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:21:07,733 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:21:07,738 [Listener at localhost/40420] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:40420
2020-12-03 07:21:07,744 [Thread-385] INFO  common.Storage (DataStorage.java:doRollback(921)) - Layout version rolled back to -57 for storage /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:21:07,751 [Listener at localhost/40420] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:21:07,752 [Listener at localhost/40420] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:21:07,753 [Thread-408] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33125 starting to offer service
2020-12-03 07:21:07,764 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:21:07,764 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:21:07,769 [Thread-408] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33125
2020-12-03 07:21:07,771 [Thread-408] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:21:07,771 [Listener at localhost/40420] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:21:07,773 [Listener at localhost/40420] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:21:07,773 [Listener at localhost/40420] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:21:07,776 [Listener at localhost/40420] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:21:07,776 [Listener at localhost/40420] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:07,776 [Listener at localhost/40420] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:21:07,776 [Listener at localhost/40420] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:21:07,777 [Listener at localhost/40420] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:07,777 [Listener at localhost/40420] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:07,777 [Listener at localhost/40420] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:07,777 [Listener at localhost/40420] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:21:07,778 [Listener at localhost/40420] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:40609
2020-12-03 07:21:07,778 [Listener at localhost/40420] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:21:07,778 [Listener at localhost/40420] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:21:07,779 [Listener at localhost/40420] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:07,781 [Listener at localhost/40420] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:21:07,781 [Listener at localhost/40420] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:21:07,782 [Listener at localhost/40420] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:07,783 [Listener at localhost/40420] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:21:07,784 [Listener at localhost/40420] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:21:07,784 [Listener at localhost/40420] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:21:07,784 [Listener at localhost/40420] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:21:07,785 [Listener at localhost/40420] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 41191
2020-12-03 07:21:07,785 [Listener at localhost/40420] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:21:07,786 [Listener at localhost/40420] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@352e787a{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:21:07,787 [Listener at localhost/40420] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@15bc339{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:21:07,794 [Listener at localhost/40420] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@256a1825{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:21:07,797 [Listener at localhost/40420] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@29a4f594{HTTP/1.1,[http/1.1]}{localhost:41191}
2020-12-03 07:21:07,798 [Listener at localhost/40420] INFO  server.Server (Server.java:doStart(419)) - Started @12792ms
2020-12-03 07:21:07,819 [Listener at localhost/40420] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:34263
2020-12-03 07:21:07,820 [Listener at localhost/40420] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:21:07,820 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5327a06e] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:21:07,820 [Listener at localhost/40420] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:21:07,821 [Listener at localhost/40420] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:21:07,822 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:21:07,826 [Listener at localhost/44900] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:44900
2020-12-03 07:21:07,838 [Listener at localhost/44900] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:21:07,839 [Listener at localhost/44900] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:21:07,840 [Thread-430] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33125 starting to offer service
2020-12-03 07:21:07,844 [Thread-408] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 2630@9bd33dce04e9
2020-12-03 07:21:07,846 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:21:07,846 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:21:07,852 [Thread-430] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33125
2020-12-03 07:21:07,854 [Thread-430] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:21:07,860 [IPC Server handler 3 on default port 33125] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:07,861 [Listener at localhost/44900] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:07,861 [Listener at localhost/44900] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:07,904 [Thread-385] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 2630@9bd33dce04e9
2020-12-03 07:21:07,932 [Thread-430] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 2630@9bd33dce04e9
2020-12-03 07:21:07,932 [Thread-408] INFO  common.Storage (DataStorage.java:doRollback(921)) - Layout version rolled back to -57 for storage /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:21:07,964 [IPC Server handler 4 on default port 33125] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:07,967 [Listener at localhost/44900] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:07,967 [Listener at localhost/44900] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:07,972 [Thread-385] INFO  common.Storage (DataStorage.java:doRollback(921)) - Layout version rolled back to -57 for storage /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:21:08,024 [Thread-430] INFO  common.Storage (DataStorage.java:doRollback(921)) - Layout version rolled back to -57 for storage /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:21:08,068 [IPC Server handler 5 on default port 33125] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:08,069 [Listener at localhost/44900] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:08,069 [Listener at localhost/44900] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:08,089 [Thread-385] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:08,089 [Thread-385] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:08,090 [Thread-385] INFO  common.Storage (BlockPoolSliceStorage.java:doRollback(618)) - Rolling back storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-425068830-172.17.0.8-1606980057018.
   target LV = -65; target CTime = 1606980057018
2020-12-03 07:21:08,091 [Thread-385] INFO  common.Storage (BlockPoolSliceStorage.java:doRollback(633)) - Rollback of /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-425068830-172.17.0.8-1606980057018 is complete
2020-12-03 07:21:08,132 [Thread-408] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 2630@9bd33dce04e9
2020-12-03 07:21:08,171 [IPC Server handler 6 on default port 33125] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:08,172 [Listener at localhost/44900] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:08,172 [Listener at localhost/44900] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:08,201 [Thread-385] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:08,201 [Thread-385] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:08,202 [Thread-385] INFO  common.Storage (BlockPoolSliceStorage.java:doRollback(618)) - Rolling back storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-425068830-172.17.0.8-1606980057018.
   target LV = -65; target CTime = 1606980057018
2020-12-03 07:21:08,203 [Thread-385] INFO  common.Storage (BlockPoolSliceStorage.java:doRollback(633)) - Rollback of /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-425068830-172.17.0.8-1606980057018 is complete
2020-12-03 07:21:08,228 [Thread-430] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 2630@9bd33dce04e9
2020-12-03 07:21:08,230 [Thread-408] INFO  common.Storage (DataStorage.java:doRollback(921)) - Layout version rolled back to -57 for storage /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:21:08,268 [Thread-385] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1142161323;bpid=BP-425068830-172.17.0.8-1606980057018;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1142161323;c=1606980057018;bpid=BP-425068830-172.17.0.8-1606980057018;dnuuid=81972425-7fba-4dbf-b586-2759576dcb2a
2020-12-03 07:21:08,272 [Thread-385] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-e2a4702c-e5d8-49ec-98d9-afcba9a4bf2b
2020-12-03 07:21:08,275 [Thread-385] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-12-03 07:21:08,276 [IPC Server handler 7 on default port 33125] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:08,277 [Thread-385] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-7f94b3d0-d801-4a3a-80c5-f0a5c86996d0
2020-12-03 07:21:08,279 [Thread-385] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-12-03 07:21:08,279 [Listener at localhost/44900] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:08,280 [Listener at localhost/44900] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:08,280 [Thread-385] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:21:08,283 [Thread-385] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:21:08,284 [Thread-385] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:21:08,284 [Thread-385] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:21:08,284 [Thread-385] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:21:08,287 [Thread-385] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:08,287 [Thread-444] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:21:08,288 [Thread-445] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:21:08,291 [Thread-444] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-425068830-172.17.0.8-1606980057018/current: 24591
2020-12-03 07:21:08,291 [Thread-445] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-425068830-172.17.0.8-1606980057018/current: 24605
2020-12-03 07:21:08,302 [Thread-445] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-425068830-172.17.0.8-1606980057018 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 14ms
2020-12-03 07:21:08,306 [Thread-444] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-425068830-172.17.0.8-1606980057018 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 18ms
2020-12-03 07:21:08,306 [Thread-385] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-425068830-172.17.0.8-1606980057018: 18ms
2020-12-03 07:21:08,307 [Thread-446] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:21:08,307 [Thread-447] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:21:08,309 [Thread-446] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(925)) - Successfully read replica from cache file : /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-425068830-172.17.0.8-1606980057018/current/replicas
2020-12-03 07:21:08,309 [Thread-447] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(925)) - Successfully read replica from cache file : /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-425068830-172.17.0.8-1606980057018/current/replicas
2020-12-03 07:21:08,309 [Thread-446] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 3ms
2020-12-03 07:21:08,309 [Thread-447] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 3ms
2020-12-03 07:21:08,310 [Thread-385] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-425068830-172.17.0.8-1606980057018: 3ms
2020-12-03 07:21:08,310 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-7f94b3d0-d801-4a3a-80c5-f0a5c86996d0): no suitable block pools found to scan.  Waiting 1814393986 ms.
2020-12-03 07:21:08,311 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-e2a4702c-e5d8-49ec-98d9-afcba9a4bf2b): no suitable block pools found to scan.  Waiting 1814393985 ms.
2020-12-03 07:21:08,311 [Thread-385] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 8:40 AM with interval of 21600000ms
2020-12-03 07:21:08,313 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:33125] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-425068830-172.17.0.8-1606980057018 (Datanode Uuid 81972425-7fba-4dbf-b586-2759576dcb2a) service to localhost/127.0.0.1:33125 beginning handshake with NN
2020-12-03 07:21:08,315 [IPC Server handler 8 on default port 33125] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:41248, datanodeUuid=81972425-7fba-4dbf-b586-2759576dcb2a, infoPort=46077, infoSecurePort=0, ipcPort=41151, storageInfo=lv=-57;cid=testClusterID;nsid=1142161323;c=1606980057018) storage 81972425-7fba-4dbf-b586-2759576dcb2a
2020-12-03 07:21:08,315 [IPC Server handler 8 on default port 33125] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41248
2020-12-03 07:21:08,315 [IPC Server handler 8 on default port 33125] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 81972425-7fba-4dbf-b586-2759576dcb2a (127.0.0.1:41248).
2020-12-03 07:21:08,321 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:33125] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-425068830-172.17.0.8-1606980057018 (Datanode Uuid 81972425-7fba-4dbf-b586-2759576dcb2a) service to localhost/127.0.0.1:33125 successfully registered with NN
2020-12-03 07:21:08,321 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:33125] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:33125 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-12-03 07:21:08,325 [IPC Server handler 9 on default port 33125] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-e2a4702c-e5d8-49ec-98d9-afcba9a4bf2b for DN 127.0.0.1:41248
2020-12-03 07:21:08,325 [Thread-430] INFO  common.Storage (DataStorage.java:doRollback(921)) - Layout version rolled back to -57 for storage /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:21:08,326 [IPC Server handler 9 on default port 33125] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-7f94b3d0-d801-4a3a-80c5-f0a5c86996d0 for DN 127.0.0.1:41248
2020-12-03 07:21:08,329 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xd5458149fe4e3b16: Processing first storage report for DS-e2a4702c-e5d8-49ec-98d9-afcba9a4bf2b from datanode 81972425-7fba-4dbf-b586-2759576dcb2a
2020-12-03 07:21:08,330 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xd5458149fe4e3b16: from storage DS-e2a4702c-e5d8-49ec-98d9-afcba9a4bf2b node DatanodeRegistration(127.0.0.1:41248, datanodeUuid=81972425-7fba-4dbf-b586-2759576dcb2a, infoPort=46077, infoSecurePort=0, ipcPort=41151, storageInfo=lv=-57;cid=testClusterID;nsid=1142161323;c=1606980057018), blocks: 1, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:08,330 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xd5458149fe4e3b16: Processing first storage report for DS-7f94b3d0-d801-4a3a-80c5-f0a5c86996d0 from datanode 81972425-7fba-4dbf-b586-2759576dcb2a
2020-12-03 07:21:08,330 [Block report processor] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:21:08,332 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(395)) - STATE* Safe mode is OFF
2020-12-03 07:21:08,332 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:21:08,332 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 1 racks and 1 datanodes
2020-12-03 07:21:08,332 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:21:08,336 [Block report processor] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_1073741827_1003 curReplicas 1 curExpectedReplicas 3 oldReplicas 0 oldExpectedReplicas  3 curPri  0 oldPri  4
2020-12-03 07:21:08,336 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xd5458149fe4e3b16: from storage DS-7f94b3d0-d801-4a3a-80c5-f0a5c86996d0 node DatanodeRegistration(127.0.0.1:41248, datanodeUuid=81972425-7fba-4dbf-b586-2759576dcb2a, infoPort=46077, infoSecurePort=0, ipcPort=41151, storageInfo=lv=-57;cid=testClusterID;nsid=1142161323;c=1606980057018), blocks: 2, hasStaleStorage: false, processing time: 7 msecs, invalidatedBlocks: 0
2020-12-03 07:21:08,342 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 3
2020-12-03 07:21:08,342 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:21:08,342 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 2
2020-12-03 07:21:08,342 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:21:08,342 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:21:08,342 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 9 msec
2020-12-03 07:21:08,343 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:33125] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xd5458149fe4e3b16,  containing 2 storage report(s), of which we sent 2. The reports had 3 total blocks and used 1 RPC(s). This took 0 msec to generate and 14 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:21:08,343 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:33125] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:08,343 [Thread-408] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:08,344 [Thread-408] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:08,344 [Thread-408] INFO  common.Storage (BlockPoolSliceStorage.java:doRollback(618)) - Rolling back storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-425068830-172.17.0.8-1606980057018.
   target LV = -65; target CTime = 1606980057018
2020-12-03 07:21:08,345 [Thread-408] INFO  common.Storage (BlockPoolSliceStorage.java:doRollback(633)) - Rollback of /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-425068830-172.17.0.8-1606980057018 is complete
2020-12-03 07:21:08,381 [IPC Server handler 2 on default port 33125] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:08,382 [Listener at localhost/44900] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:08,382 [Listener at localhost/44900] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:08,449 [Thread-408] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:08,450 [Thread-408] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:08,450 [Thread-408] INFO  common.Storage (BlockPoolSliceStorage.java:doRollback(618)) - Rolling back storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-425068830-172.17.0.8-1606980057018.
   target LV = -65; target CTime = 1606980057018
2020-12-03 07:21:08,452 [Thread-408] INFO  common.Storage (BlockPoolSliceStorage.java:doRollback(633)) - Rollback of /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-425068830-172.17.0.8-1606980057018 is complete
2020-12-03 07:21:08,453 [Thread-430] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:08,453 [Thread-430] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:08,454 [Thread-430] INFO  common.Storage (BlockPoolSliceStorage.java:doRollback(618)) - Rolling back storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-425068830-172.17.0.8-1606980057018.
   target LV = -65; target CTime = 1606980057018
2020-12-03 07:21:08,455 [Thread-430] INFO  common.Storage (BlockPoolSliceStorage.java:doRollback(633)) - Rollback of /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-425068830-172.17.0.8-1606980057018 is complete
2020-12-03 07:21:08,484 [IPC Server handler 1 on default port 33125] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:08,485 [Listener at localhost/44900] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:08,485 [Listener at localhost/44900] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:08,500 [Thread-408] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1142161323;bpid=BP-425068830-172.17.0.8-1606980057018;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1142161323;c=1606980057018;bpid=BP-425068830-172.17.0.8-1606980057018;dnuuid=0b0f70d2-7565-48f3-b01c-1adf7b4ab560
2020-12-03 07:21:08,503 [Thread-408] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-9a7d7b8b-ec12-469a-9a7d-60ed5e71167a
2020-12-03 07:21:08,503 [Thread-408] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: DISK
2020-12-03 07:21:08,507 [Thread-408] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-d40683d6-ae9f-4bbb-bc67-169f6d82dbbb
2020-12-03 07:21:08,507 [Thread-408] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: DISK
2020-12-03 07:21:08,509 [Thread-408] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:21:08,510 [Thread-408] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:21:08,510 [Thread-408] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:21:08,510 [Thread-408] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:21:08,511 [Thread-408] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:21:08,512 [Thread-408] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:08,512 [Thread-454] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:21:08,513 [Thread-455] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:21:08,514 [Thread-454] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-425068830-172.17.0.8-1606980057018/current: 24591
2020-12-03 07:21:08,515 [Thread-455] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-425068830-172.17.0.8-1606980057018/current: 24605
2020-12-03 07:21:08,524 [Thread-454] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-425068830-172.17.0.8-1606980057018 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 12ms
2020-12-03 07:21:08,526 [Thread-455] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-425068830-172.17.0.8-1606980057018 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 14ms
2020-12-03 07:21:08,526 [Thread-408] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-425068830-172.17.0.8-1606980057018: 14ms
2020-12-03 07:21:08,528 [Thread-457] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:21:08,528 [Thread-456] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:21:08,532 [Thread-456] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(925)) - Successfully read replica from cache file : /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-425068830-172.17.0.8-1606980057018/current/replicas
2020-12-03 07:21:08,532 [Thread-457] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(925)) - Successfully read replica from cache file : /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-425068830-172.17.0.8-1606980057018/current/replicas
2020-12-03 07:21:08,532 [Thread-456] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 4ms
2020-12-03 07:21:08,532 [Thread-457] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 5ms
2020-12-03 07:21:08,532 [Thread-408] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-425068830-172.17.0.8-1606980057018: 6ms
2020-12-03 07:21:08,533 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-9a7d7b8b-ec12-469a-9a7d-60ed5e71167a): no suitable block pools found to scan.  Waiting 1814393763 ms.
2020-12-03 07:21:08,533 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-d40683d6-ae9f-4bbb-bc67-169f6d82dbbb): no suitable block pools found to scan.  Waiting 1814393763 ms.
2020-12-03 07:21:08,534 [Thread-408] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 8:51 AM with interval of 21600000ms
2020-12-03 07:21:08,543 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:33125] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-425068830-172.17.0.8-1606980057018 (Datanode Uuid 0b0f70d2-7565-48f3-b01c-1adf7b4ab560) service to localhost/127.0.0.1:33125 beginning handshake with NN
2020-12-03 07:21:08,545 [IPC Server handler 3 on default port 33125] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:45667, datanodeUuid=0b0f70d2-7565-48f3-b01c-1adf7b4ab560, infoPort=37880, infoSecurePort=0, ipcPort=40420, storageInfo=lv=-57;cid=testClusterID;nsid=1142161323;c=1606980057018) storage 0b0f70d2-7565-48f3-b01c-1adf7b4ab560
2020-12-03 07:21:08,545 [IPC Server handler 3 on default port 33125] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:45667
2020-12-03 07:21:08,545 [IPC Server handler 3 on default port 33125] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 0b0f70d2-7565-48f3-b01c-1adf7b4ab560 (127.0.0.1:45667).
2020-12-03 07:21:08,545 [Thread-430] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:08,546 [Thread-430] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:08,546 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:33125] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-425068830-172.17.0.8-1606980057018 (Datanode Uuid 0b0f70d2-7565-48f3-b01c-1adf7b4ab560) service to localhost/127.0.0.1:33125 successfully registered with NN
2020-12-03 07:21:08,546 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:33125] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:33125 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-12-03 07:21:08,546 [Thread-430] INFO  common.Storage (BlockPoolSliceStorage.java:doRollback(618)) - Rolling back storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-425068830-172.17.0.8-1606980057018.
   target LV = -65; target CTime = 1606980057018
2020-12-03 07:21:08,551 [IPC Server handler 4 on default port 33125] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-9a7d7b8b-ec12-469a-9a7d-60ed5e71167a for DN 127.0.0.1:45667
2020-12-03 07:21:08,553 [IPC Server handler 4 on default port 33125] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d40683d6-ae9f-4bbb-bc67-169f6d82dbbb for DN 127.0.0.1:45667
2020-12-03 07:21:08,554 [Thread-430] INFO  common.Storage (BlockPoolSliceStorage.java:doRollback(633)) - Rollback of /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-425068830-172.17.0.8-1606980057018 is complete
2020-12-03 07:21:08,555 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xc927eca663d92868: Processing first storage report for DS-9a7d7b8b-ec12-469a-9a7d-60ed5e71167a from datanode 0b0f70d2-7565-48f3-b01c-1adf7b4ab560
2020-12-03 07:21:08,555 [Block report processor] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_1073741825_1001 curReplicas 2 curExpectedReplicas 3 oldReplicas 1 oldExpectedReplicas  3 curPri  2 oldPri  0
2020-12-03 07:21:08,556 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xc927eca663d92868: from storage DS-9a7d7b8b-ec12-469a-9a7d-60ed5e71167a node DatanodeRegistration(127.0.0.1:45667, datanodeUuid=0b0f70d2-7565-48f3-b01c-1adf7b4ab560, infoPort=37880, infoSecurePort=0, ipcPort=40420, storageInfo=lv=-57;cid=testClusterID;nsid=1142161323;c=1606980057018), blocks: 1, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:08,556 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xc927eca663d92868: Processing first storage report for DS-d40683d6-ae9f-4bbb-bc67-169f6d82dbbb from datanode 0b0f70d2-7565-48f3-b01c-1adf7b4ab560
2020-12-03 07:21:08,556 [Block report processor] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_1073741826_1002 curReplicas 2 curExpectedReplicas 3 oldReplicas 1 oldExpectedReplicas  3 curPri  2 oldPri  0
2020-12-03 07:21:08,556 [Block report processor] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_1073741827_1003 curReplicas 2 curExpectedReplicas 3 oldReplicas 1 oldExpectedReplicas  3 curPri  2 oldPri  0
2020-12-03 07:21:08,556 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xc927eca663d92868: from storage DS-d40683d6-ae9f-4bbb-bc67-169f6d82dbbb node DatanodeRegistration(127.0.0.1:45667, datanodeUuid=0b0f70d2-7565-48f3-b01c-1adf7b4ab560, infoPort=37880, infoSecurePort=0, ipcPort=40420, storageInfo=lv=-57;cid=testClusterID;nsid=1142161323;c=1606980057018), blocks: 2, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:21:08,557 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:33125] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xc927eca663d92868,  containing 2 storage report(s), of which we sent 2. The reports had 3 total blocks and used 1 RPC(s). This took 1 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:21:08,557 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:33125] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:08,587 [IPC Server handler 6 on default port 33125] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:08,588 [Listener at localhost/44900] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:08,588 [Listener at localhost/44900] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:08,606 [Thread-430] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1142161323;bpid=BP-425068830-172.17.0.8-1606980057018;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1142161323;c=1606980057018;bpid=BP-425068830-172.17.0.8-1606980057018;dnuuid=5326576b-2216-4538-9245-8b0fb17c9d46
2020-12-03 07:21:08,610 [Thread-430] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-c38ad29d-afe4-4ee0-be21-3867655f82fb
2020-12-03 07:21:08,612 [Thread-430] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, StorageType: DISK
2020-12-03 07:21:08,617 [Thread-430] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-07458f0c-3587-41d4-abeb-821d73c89765
2020-12-03 07:21:08,620 [Thread-430] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, StorageType: DISK
2020-12-03 07:21:08,621 [Thread-430] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:21:08,622 [Thread-430] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:21:08,623 [Thread-430] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:21:08,623 [Thread-430] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:21:08,623 [Thread-430] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:21:08,625 [Thread-430] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:08,626 [Thread-463] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:21:08,626 [Thread-464] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:21:08,628 [Thread-463] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-425068830-172.17.0.8-1606980057018/current: 24591
2020-12-03 07:21:08,628 [Thread-464] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-425068830-172.17.0.8-1606980057018/current: 24605
2020-12-03 07:21:08,651 [Thread-464] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-425068830-172.17.0.8-1606980057018 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 25ms
2020-12-03 07:21:08,651 [Thread-463] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-425068830-172.17.0.8-1606980057018 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 25ms
2020-12-03 07:21:08,663 [Thread-430] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-425068830-172.17.0.8-1606980057018: 38ms
2020-12-03 07:21:08,664 [Thread-466] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:21:08,664 [Thread-465] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:21:08,666 [Thread-466] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(925)) - Successfully read replica from cache file : /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-425068830-172.17.0.8-1606980057018/current/replicas
2020-12-03 07:21:08,667 [Thread-466] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 2ms
2020-12-03 07:21:08,669 [Thread-465] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(925)) - Successfully read replica from cache file : /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-425068830-172.17.0.8-1606980057018/current/replicas
2020-12-03 07:21:08,670 [Thread-465] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 5ms
2020-12-03 07:21:08,670 [Thread-430] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-425068830-172.17.0.8-1606980057018: 6ms
2020-12-03 07:21:08,671 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-07458f0c-3587-41d4-abeb-821d73c89765): no suitable block pools found to scan.  Waiting 1814393625 ms.
2020-12-03 07:21:08,671 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-c38ad29d-afe4-4ee0-be21-3867655f82fb): no suitable block pools found to scan.  Waiting 1814393625 ms.
2020-12-03 07:21:08,671 [Thread-430] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 9:13 AM with interval of 21600000ms
2020-12-03 07:21:08,673 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:33125] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-425068830-172.17.0.8-1606980057018 (Datanode Uuid 5326576b-2216-4538-9245-8b0fb17c9d46) service to localhost/127.0.0.1:33125 beginning handshake with NN
2020-12-03 07:21:08,675 [IPC Server handler 7 on default port 33125] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:40609, datanodeUuid=5326576b-2216-4538-9245-8b0fb17c9d46, infoPort=34263, infoSecurePort=0, ipcPort=44900, storageInfo=lv=-57;cid=testClusterID;nsid=1142161323;c=1606980057018) storage 5326576b-2216-4538-9245-8b0fb17c9d46
2020-12-03 07:21:08,675 [IPC Server handler 7 on default port 33125] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:40609
2020-12-03 07:21:08,675 [IPC Server handler 7 on default port 33125] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 5326576b-2216-4538-9245-8b0fb17c9d46 (127.0.0.1:40609).
2020-12-03 07:21:08,676 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:33125] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-425068830-172.17.0.8-1606980057018 (Datanode Uuid 5326576b-2216-4538-9245-8b0fb17c9d46) service to localhost/127.0.0.1:33125 successfully registered with NN
2020-12-03 07:21:08,676 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:33125] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:33125 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-12-03 07:21:08,681 [IPC Server handler 8 on default port 33125] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c38ad29d-afe4-4ee0-be21-3867655f82fb for DN 127.0.0.1:40609
2020-12-03 07:21:08,681 [IPC Server handler 8 on default port 33125] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-07458f0c-3587-41d4-abeb-821d73c89765 for DN 127.0.0.1:40609
2020-12-03 07:21:08,683 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x575ee94357de4f0f: Processing first storage report for DS-07458f0c-3587-41d4-abeb-821d73c89765 from datanode 5326576b-2216-4538-9245-8b0fb17c9d46
2020-12-03 07:21:08,684 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x575ee94357de4f0f: from storage DS-07458f0c-3587-41d4-abeb-821d73c89765 node DatanodeRegistration(127.0.0.1:40609, datanodeUuid=5326576b-2216-4538-9245-8b0fb17c9d46, infoPort=34263, infoSecurePort=0, ipcPort=44900, storageInfo=lv=-57;cid=testClusterID;nsid=1142161323;c=1606980057018), blocks: 2, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:08,684 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x575ee94357de4f0f: Processing first storage report for DS-c38ad29d-afe4-4ee0-be21-3867655f82fb from datanode 5326576b-2216-4538-9245-8b0fb17c9d46
2020-12-03 07:21:08,684 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x575ee94357de4f0f: from storage DS-c38ad29d-afe4-4ee0-be21-3867655f82fb node DatanodeRegistration(127.0.0.1:40609, datanodeUuid=5326576b-2216-4538-9245-8b0fb17c9d46, infoPort=34263, infoSecurePort=0, ipcPort=44900, storageInfo=lv=-57;cid=testClusterID;nsid=1142161323;c=1606980057018), blocks: 1, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:21:08,685 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:33125] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x575ee94357de4f0f,  containing 2 storage report(s), of which we sent 2. The reports had 3 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:21:08,685 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:33125] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:08,689 [IPC Server handler 0 on default port 33125] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:08,691 [Listener at localhost/44900] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:21:08,695 [IPC Server handler 2 on default port 33125] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testUpgrade	dst=null	perm=null	proto=rpc
2020-12-03 07:21:08,696 [IPC Server handler 1 on default port 33125] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testUpgrade	dst=null	perm=null	proto=rpc
2020-12-03 07:21:08,698 [IPC Server handler 3 on default port 33125] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testUpgrade	dst=null	perm=null	proto=rpc
2020-12-03 07:21:08,699 [IPC Server handler 4 on default port 33125] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/test/testUpgrade	dst=null	perm=null	proto=rpc
2020-12-03 07:21:08,702 [Listener at localhost/44900] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:08,706 [Listener at localhost/44900] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:08,708 [Listener at localhost/44900] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:21:08,708 [Listener at localhost/44900] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 2
2020-12-03 07:21:08,709 [Listener at localhost/44900] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:21:08,709 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@6e106680] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:21:08,712 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-07458f0c-3587-41d4-abeb-821d73c89765) exiting.
2020-12-03 07:21:08,712 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-c38ad29d-afe4-4ee0-be21-3867655f82fb) exiting.
2020-12-03 07:21:08,736 [Listener at localhost/44900] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@256a1825{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:21:08,737 [Listener at localhost/44900] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@29a4f594{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:21:08,737 [Listener at localhost/44900] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@15bc339{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:21:08,738 [Listener at localhost/44900] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@352e787a{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:21:08,739 [Listener at localhost/44900] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 44900
2020-12-03 07:21:08,744 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:08,744 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:08,745 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:33125] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:08,748 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:33125] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-425068830-172.17.0.8-1606980057018 (Datanode Uuid 5326576b-2216-4538-9245-8b0fb17c9d46) service to localhost/127.0.0.1:33125
2020-12-03 07:21:08,748 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:33125] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-425068830-172.17.0.8-1606980057018 (Datanode Uuid 5326576b-2216-4538-9245-8b0fb17c9d46)
2020-12-03 07:21:08,748 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:33125] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:08,750 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-425068830-172.17.0.8-1606980057018] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:08,750 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-425068830-172.17.0.8-1606980057018] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:08,761 [Listener at localhost/44900] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:21:08,761 [Listener at localhost/44900] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:21:08,763 [Listener at localhost/44900] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:21:08,763 [Listener at localhost/44900] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:21:08,775 [Listener at localhost/44900] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:21:08,775 [Listener at localhost/44900] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 1
2020-12-03 07:21:08,776 [Listener at localhost/44900] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:21:08,776 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@54562ea6] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:21:08,779 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-d40683d6-ae9f-4bbb-bc67-169f6d82dbbb) exiting.
2020-12-03 07:21:08,780 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-9a7d7b8b-ec12-469a-9a7d-60ed5e71167a) exiting.
2020-12-03 07:21:08,898 [Listener at localhost/44900] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6fd1660{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:21:08,899 [Listener at localhost/44900] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4a6c18ad{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:21:08,899 [Listener at localhost/44900] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@14e2e1c3{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:21:08,899 [Listener at localhost/44900] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@766a4535{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:21:08,900 [Listener at localhost/44900] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 40420
2020-12-03 07:21:08,907 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:08,907 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:08,909 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:33125] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:08,909 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:33125] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-425068830-172.17.0.8-1606980057018 (Datanode Uuid 0b0f70d2-7565-48f3-b01c-1adf7b4ab560) service to localhost/127.0.0.1:33125
2020-12-03 07:21:08,909 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:33125] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-425068830-172.17.0.8-1606980057018 (Datanode Uuid 0b0f70d2-7565-48f3-b01c-1adf7b4ab560)
2020-12-03 07:21:08,909 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:33125] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:08,910 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-425068830-172.17.0.8-1606980057018] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:08,911 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-425068830-172.17.0.8-1606980057018] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:08,926 [Listener at localhost/44900] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:21:08,926 [Listener at localhost/44900] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:21:08,929 [Listener at localhost/44900] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:21:08,929 [Listener at localhost/44900] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:21:08,930 [Listener at localhost/44900] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:21:08,930 [Listener at localhost/44900] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:21:08,931 [Listener at localhost/44900] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:21:08,931 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@42e22a53] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:21:08,932 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-7f94b3d0-d801-4a3a-80c5-f0a5c86996d0) exiting.
2020-12-03 07:21:08,932 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-e2a4702c-e5d8-49ec-98d9-afcba9a4bf2b) exiting.
2020-12-03 07:21:08,950 [Listener at localhost/44900] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@77b9d0c7{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:21:08,950 [Listener at localhost/44900] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@65fd6708{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:21:08,951 [Listener at localhost/44900] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@48c3205a{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:21:08,951 [Listener at localhost/44900] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@70242f38{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:21:08,953 [Listener at localhost/44900] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 41151
2020-12-03 07:21:08,961 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:08,965 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:08,965 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:33125] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:08,965 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:33125] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-425068830-172.17.0.8-1606980057018 (Datanode Uuid 81972425-7fba-4dbf-b586-2759576dcb2a) service to localhost/127.0.0.1:33125
2020-12-03 07:21:08,965 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:33125] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-425068830-172.17.0.8-1606980057018 (Datanode Uuid 81972425-7fba-4dbf-b586-2759576dcb2a)
2020-12-03 07:21:08,966 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:33125] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:08,966 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-425068830-172.17.0.8-1606980057018] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:08,967 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-425068830-172.17.0.8-1606980057018] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:08,984 [Listener at localhost/44900] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:21:08,985 [Listener at localhost/44900] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:21:08,987 [Listener at localhost/44900] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:21:08,987 [Listener at localhost/44900] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:21:08,988 [Listener at localhost/44900] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:21:08,988 [Listener at localhost/44900] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:21:08,988 [Listener at localhost/44900] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:21:08,988 [Listener at localhost/44900] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 19, 19
2020-12-03 07:21:08,989 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@178270b2] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:21:08,988 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@795fd838] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:21:08,994 [Listener at localhost/44900] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 2 Total time for transactions(ms): 7 Number of transactions batched in Syncs: 18 Number of syncs: 3 SyncTimes(ms): 3 1 
2020-12-03 07:21:08,995 [Listener at localhost/44900] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000019 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000019-0000000000000000020
2020-12-03 07:21:08,996 [Listener at localhost/44900] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000019 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000019-0000000000000000020
2020-12-03 07:21:08,996 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:21:08,996 [CacheReplicationMonitor(598514225)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:21:09,027 [Listener at localhost/44900] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 33125
2020-12-03 07:21:09,033 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:09,033 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:09,034 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:21:09,033 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:21:09,055 [Listener at localhost/44900] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:21:09,055 [Listener at localhost/44900] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:21:09,057 [Listener at localhost/44900] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@59429fac{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:21:09,063 [Listener at localhost/44900] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@57aa341b{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:21:09,064 [Listener at localhost/44900] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@652ce654{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:21:09,064 [Listener at localhost/44900] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7bb004b8{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:21:09,065 [Listener at localhost/44900] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-12-03 07:21:09,069 [Listener at localhost/44900] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-12-03 07:21:09,069 [Listener at localhost/44900] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-12-03 07:21:09,077 [Listener at localhost/44900] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=3
2020-12-03 07:21:09,079 [Listener at localhost/44900] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:21:09,082 [Listener at localhost/44900] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:21:09,083 [Listener at localhost/44900] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:21:09,084 [Listener at localhost/44900] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:21:09,085 [Listener at localhost/44900] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-12-03 07:21:09,119 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6d4c273c] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:21:09,119 [Listener at localhost/44900] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:21:09,119 [Listener at localhost/44900] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:09,121 [Listener at localhost/44900] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:21:09,121 [Listener at localhost/44900] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:21:09,121 [Listener at localhost/44900] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:09,123 [Listener at localhost/44900] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:21:09,124 [Listener at localhost/44900] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:21:09,124 [Listener at localhost/44900] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:21:09,124 [Listener at localhost/44900] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:21:09,126 [Listener at localhost/44900] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:21:09,127 [Listener at localhost/44900] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:21:09,127 [Listener at localhost/44900] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 34578
2020-12-03 07:21:09,127 [Listener at localhost/44900] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:21:09,130 [Listener at localhost/44900] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@64bfd6fd{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:21:09,131 [Listener at localhost/44900] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@253b380a{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:21:09,136 [Listener at localhost/44900] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@4a5905d9{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:21:09,141 [Listener at localhost/44900] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1a3e5f23{HTTP/1.1,[http/1.1]}{localhost:34578}
2020-12-03 07:21:09,141 [Listener at localhost/44900] INFO  server.Server (Server.java:doStart(419)) - Started @14135ms
2020-12-03 07:21:09,143 [Listener at localhost/44900] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:21:09,143 [Listener at localhost/44900] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:21:09,143 [Listener at localhost/44900] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:21:09,143 [Listener at localhost/44900] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:21:09,144 [Listener at localhost/44900] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:21:09,144 [Listener at localhost/44900] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:21:09,144 [Listener at localhost/44900] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:21:09,144 [Listener at localhost/44900] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:21:09,145 [Listener at localhost/44900] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:09,145 [Listener at localhost/44900] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:09,145 [Listener at localhost/44900] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=20, effected=1000
2020-12-03 07:21:09,145 [Listener at localhost/44900] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:21:09,145 [Listener at localhost/44900] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:09,146 [Listener at localhost/44900] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:21:09,146 [Listener at localhost/44900] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:21:09
2020-12-03 07:21:09,146 [Listener at localhost/44900] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:21:09,147 [Listener at localhost/44900] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:09,147 [Listener at localhost/44900] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:21:09,147 [Listener at localhost/44900] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:21:09,158 [Listener at localhost/44900] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:09,158 [Listener at localhost/44900] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:09,159 [Listener at localhost/44900] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:21:09,159 [Listener at localhost/44900] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:21:09,159 [Listener at localhost/44900] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:09,159 [Listener at localhost/44900] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:21:09,159 [Listener at localhost/44900] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:21:09,160 [Listener at localhost/44900] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:21:09,160 [Listener at localhost/44900] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:21:09,160 [Listener at localhost/44900] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:21:09,160 [Listener at localhost/44900] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:21:09,160 [Listener at localhost/44900] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:21:09,160 [Listener at localhost/44900] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:21:09,160 [Listener at localhost/44900] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:21:09,160 [Listener at localhost/44900] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:21:09,161 [Listener at localhost/44900] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:21:09,161 [Listener at localhost/44900] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:21:09,161 [Listener at localhost/44900] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:09,161 [Listener at localhost/44900] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:21:09,162 [Listener at localhost/44900] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:21:09,165 [Listener at localhost/44900] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:21:09,166 [Listener at localhost/44900] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:21:09,166 [Listener at localhost/44900] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:21:09,166 [Listener at localhost/44900] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:21:09,166 [Listener at localhost/44900] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:21:09,166 [Listener at localhost/44900] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:21:09,166 [Listener at localhost/44900] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:21:09,166 [Listener at localhost/44900] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:09,167 [Listener at localhost/44900] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:21:09,167 [Listener at localhost/44900] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:21:09,168 [Listener at localhost/44900] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:21:09,168 [Listener at localhost/44900] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:21:09,168 [Listener at localhost/44900] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:21:09,169 [Listener at localhost/44900] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:21:09,169 [Listener at localhost/44900] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:21:09,169 [Listener at localhost/44900] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:21:09,169 [Listener at localhost/44900] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:09,169 [Listener at localhost/44900] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:21:09,169 [Listener at localhost/44900] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:21:09,234 [Listener at localhost/44900] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 2630@9bd33dce04e9
2020-12-03 07:21:09,276 [Listener at localhost/44900] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 2630@9bd33dce04e9
2020-12-03 07:21:09,279 [Listener at localhost/44900] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-12-03 07:21:09,279 [Listener at localhost/44900] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-12-03 07:21:09,280 [Listener at localhost/44900] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:21:09,285 [Listener at localhost/44900] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:21:09,286 [Listener at localhost/44900] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:21:09,287 [Listener at localhost/44900] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-12-03 07:21:09,287 [Listener at localhost/44900] INFO  namenode.FSImage (FSImage.java:loadEdits(910)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@ec1b2e4 expecting start txid #1
2020-12-03 07:21:09,287 [Listener at localhost/44900] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000018, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000018 maxTxnsToRead = 9223372036854775807
2020-12-03 07:21:09,287 [Listener at localhost/44900] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:loadEditRecords(217)) - Acquiring write lock to replay edit log
2020-12-03 07:21:09,288 [Listener at localhost/44900] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000018' to transaction ID 1
2020-12-03 07:21:09,288 [Listener at localhost/44900] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:loadEditRecords(284)) - op=LogSegmentOp [opCode=OP_START_LOG_SEGMENT, txid=1], startOpt=REGULAR, numEdits=0, totalEdits=0
2020-12-03 07:21:09,288 [Listener at localhost/44900] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:applyEditLogOp(388)) - replaying edit log: LogSegmentOp [opCode=OP_START_LOG_SEGMENT, txid=1]
2020-12-03 07:21:09,289 [Listener at localhost/44900] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:loadEditRecords(284)) - op=MkdirOp [length=0, inodeId=16386, path=/test, timestamp=1606980062499, permissions=root:supergroup:rwxr-xr-x, aclEntries=null, opCode=OP_MKDIR, txid=2, xAttrs=[]], startOpt=REGULAR, numEdits=1, totalEdits=1
2020-12-03 07:21:09,289 [Listener at localhost/44900] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:applyEditLogOp(388)) - replaying edit log: MkdirOp [length=0, inodeId=16386, path=/test, timestamp=1606980062499, permissions=root:supergroup:rwxr-xr-x, aclEntries=null, opCode=OP_MKDIR, txid=2, xAttrs=[]]
2020-12-03 07:21:09,289 [Listener at localhost/44900] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:loadEditRecords(284)) - op=SetQuotaOp [src=/test, nsQuota=100, dsQuota=1000, opCode=OP_SET_QUOTA, txid=3], startOpt=REGULAR, numEdits=2, totalEdits=2
2020-12-03 07:21:09,290 [Listener at localhost/44900] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:applyEditLogOp(388)) - replaying edit log: SetQuotaOp [src=/test, nsQuota=100, dsQuota=1000, opCode=OP_SET_QUOTA, txid=3]
2020-12-03 07:21:09,290 [Listener at localhost/44900] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:loadEditRecords(284)) - op=AllowSnapshotOp [snapshotRoot=/test], startOpt=REGULAR, numEdits=3, totalEdits=3
2020-12-03 07:21:09,290 [Listener at localhost/44900] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:applyEditLogOp(388)) - replaying edit log: AllowSnapshotOp [snapshotRoot=/test]
2020-12-03 07:21:09,291 [Listener at localhost/44900] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:loadEditRecords(284)) - op=AddOp [length=0, inodeId=16387, path=/test/testUpgrade, replication=3, mtime=1606980062569, atime=1606980062569, blockSize=4, blocks=[], permissions=root:supergroup:rw-r--r--, aclEntries=null, clientName=DFSClient_NONMAPREDUCE_742258692_1, clientMachine=127.0.0.1, overwrite=true, RpcClientId=18c30b59-4f7a-4dab-9f18-e65cd6773072, RpcCallId=28, storagePolicyId=0, erasureCodingPolicyId=0, opCode=OP_ADD, txid=5], startOpt=REGULAR, numEdits=4, totalEdits=4
2020-12-03 07:21:09,291 [Listener at localhost/44900] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:applyEditLogOp(388)) - replaying edit log: AddOp [length=0, inodeId=16387, path=/test/testUpgrade, replication=3, mtime=1606980062569, atime=1606980062569, blockSize=4, blocks=[], permissions=root:supergroup:rw-r--r--, aclEntries=null, clientName=DFSClient_NONMAPREDUCE_742258692_1, clientMachine=127.0.0.1, overwrite=true, RpcClientId=18c30b59-4f7a-4dab-9f18-e65cd6773072, RpcCallId=28, storagePolicyId=0, erasureCodingPolicyId=0, opCode=OP_ADD, txid=5]
2020-12-03 07:21:09,292 [Listener at localhost/44900] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:loadEditRecords(284)) - op=AllocateBlockIdOp [blockId=1073741825, opCode=OP_ALLOCATE_BLOCK_ID, txid=6], startOpt=REGULAR, numEdits=5, totalEdits=5
2020-12-03 07:21:09,292 [Listener at localhost/44900] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:applyEditLogOp(388)) - replaying edit log: AllocateBlockIdOp [blockId=1073741825, opCode=OP_ALLOCATE_BLOCK_ID, txid=6]
2020-12-03 07:21:09,292 [Listener at localhost/44900] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:loadEditRecords(284)) - op=SetGenstampV2Op [GenStampV2=1001, opCode=OP_SET_GENSTAMP_V2, txid=7], startOpt=REGULAR, numEdits=6, totalEdits=6
2020-12-03 07:21:09,292 [Listener at localhost/44900] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:applyEditLogOp(388)) - replaying edit log: SetGenstampV2Op [GenStampV2=1001, opCode=OP_SET_GENSTAMP_V2, txid=7]
2020-12-03 07:21:09,293 [Listener at localhost/44900] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:loadEditRecords(284)) - op=AddBlockOp [path=/test/testUpgrade, penultimateBlock=NULL, lastBlock=blk_1073741825_1001, RpcClientId=, RpcCallId=-2], startOpt=REGULAR, numEdits=7, totalEdits=7
2020-12-03 07:21:09,293 [Listener at localhost/44900] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:applyEditLogOp(388)) - replaying edit log: AddBlockOp [path=/test/testUpgrade, penultimateBlock=NULL, lastBlock=blk_1073741825_1001, RpcClientId=, RpcCallId=-2]
2020-12-03 07:21:09,295 [Listener at localhost/44900] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:loadEditRecords(284)) - op=AllocateBlockIdOp [blockId=1073741826, opCode=OP_ALLOCATE_BLOCK_ID, txid=9], startOpt=REGULAR, numEdits=8, totalEdits=8
2020-12-03 07:21:09,295 [Listener at localhost/44900] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:applyEditLogOp(388)) - replaying edit log: AllocateBlockIdOp [blockId=1073741826, opCode=OP_ALLOCATE_BLOCK_ID, txid=9]
2020-12-03 07:21:09,295 [Listener at localhost/44900] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:loadEditRecords(284)) - op=SetGenstampV2Op [GenStampV2=1002, opCode=OP_SET_GENSTAMP_V2, txid=10], startOpt=REGULAR, numEdits=9, totalEdits=9
2020-12-03 07:21:09,295 [Listener at localhost/44900] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:applyEditLogOp(388)) - replaying edit log: SetGenstampV2Op [GenStampV2=1002, opCode=OP_SET_GENSTAMP_V2, txid=10]
2020-12-03 07:21:09,296 [Listener at localhost/44900] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:loadEditRecords(284)) - op=AddBlockOp [path=/test/testUpgrade, penultimateBlock=blk_1073741825_1001, lastBlock=blk_1073741826_1002, RpcClientId=, RpcCallId=-2], startOpt=REGULAR, numEdits=10, totalEdits=10
2020-12-03 07:21:09,296 [Listener at localhost/44900] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:applyEditLogOp(388)) - replaying edit log: AddBlockOp [path=/test/testUpgrade, penultimateBlock=blk_1073741825_1001, lastBlock=blk_1073741826_1002, RpcClientId=, RpcCallId=-2]
2020-12-03 07:21:09,296 [Listener at localhost/44900] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:loadEditRecords(284)) - op=CloseOp [length=0, inodeId=0, path=/test/testUpgrade, replication=3, mtime=1606980062855, atime=1606980062569, blockSize=4, blocks=[blk_1073741825_1001, blk_1073741826_1002], permissions=root:supergroup:rw-r--r--, aclEntries=null, clientName=, clientMachine=, overwrite=false, storagePolicyId=0, erasureCodingPolicyId=0, opCode=OP_CLOSE, txid=12], startOpt=REGULAR, numEdits=11, totalEdits=11
2020-12-03 07:21:09,296 [Listener at localhost/44900] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:applyEditLogOp(388)) - replaying edit log: CloseOp [length=0, inodeId=0, path=/test/testUpgrade, replication=3, mtime=1606980062855, atime=1606980062569, blockSize=4, blocks=[blk_1073741825_1001, blk_1073741826_1002], permissions=root:supergroup:rw-r--r--, aclEntries=null, clientName=, clientMachine=, overwrite=false, storagePolicyId=0, erasureCodingPolicyId=0, opCode=OP_CLOSE, txid=12]
2020-12-03 07:21:09,297 [Listener at localhost/44900] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:loadEditRecords(284)) - op=CreateSnapshotOp [snapshotRoot=/test, snapshotName=ss0, RpcClientId=18c30b59-4f7a-4dab-9f18-e65cd6773072, RpcCallId=39], startOpt=REGULAR, numEdits=12, totalEdits=12
2020-12-03 07:21:09,297 [Listener at localhost/44900] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:applyEditLogOp(388)) - replaying edit log: CreateSnapshotOp [snapshotRoot=/test, snapshotName=ss0, RpcClientId=18c30b59-4f7a-4dab-9f18-e65cd6773072, RpcCallId=39]
2020-12-03 07:21:09,298 [Listener at localhost/44900] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:loadEditRecords(284)) - op=AllocateBlockIdOp [blockId=1073741827, opCode=OP_ALLOCATE_BLOCK_ID, txid=14], startOpt=REGULAR, numEdits=13, totalEdits=13
2020-12-03 07:21:09,298 [Listener at localhost/44900] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:applyEditLogOp(388)) - replaying edit log: AllocateBlockIdOp [blockId=1073741827, opCode=OP_ALLOCATE_BLOCK_ID, txid=14]
2020-12-03 07:21:09,298 [Listener at localhost/44900] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:loadEditRecords(284)) - op=SetGenstampV2Op [GenStampV2=1003, opCode=OP_SET_GENSTAMP_V2, txid=15], startOpt=REGULAR, numEdits=14, totalEdits=14
2020-12-03 07:21:09,298 [Listener at localhost/44900] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:applyEditLogOp(388)) - replaying edit log: SetGenstampV2Op [GenStampV2=1003, opCode=OP_SET_GENSTAMP_V2, txid=15]
2020-12-03 07:21:09,299 [Listener at localhost/44900] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:loadEditRecords(284)) - op=TruncateOp [src=/test/testUpgrade, clientName=DFSClient_NONMAPREDUCE_742258692_1, clientMachine=127.0.0.1, newLength=7, timestamp=1606980062882, truncateBlock=blk_1073741827_1003, opCode=OP_TRUNCATE, txid=16], startOpt=REGULAR, numEdits=15, totalEdits=15
2020-12-03 07:21:09,299 [Listener at localhost/44900] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:applyEditLogOp(388)) - replaying edit log: TruncateOp [src=/test/testUpgrade, clientName=DFSClient_NONMAPREDUCE_742258692_1, clientMachine=127.0.0.1, newLength=7, timestamp=1606980062882, truncateBlock=blk_1073741827_1003, opCode=OP_TRUNCATE, txid=16]
2020-12-03 07:21:09,299 [Listener at localhost/44900] DEBUG hdfs.StateChange (FSDirTruncateOp.java:prepareFileForTruncate(252)) - BLOCK* prepareFileForTruncate: Scheduling copy-on-truncate to new size 3  new block blk_1073741827_1003 old block blk_1073741826_1002
2020-12-03 07:21:09,300 [Listener at localhost/44900] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:loadEditRecords(284)) - op=CloseOp [length=0, inodeId=0, path=/test/testUpgrade, replication=3, mtime=1606980063544, atime=1606980062569, blockSize=4, blocks=[blk_1073741825_1001, blk_1073741827_1003], permissions=root:supergroup:rw-r--r--, aclEntries=null, clientName=, clientMachine=, overwrite=false, storagePolicyId=0, erasureCodingPolicyId=0, opCode=OP_CLOSE, txid=17], startOpt=REGULAR, numEdits=16, totalEdits=16
2020-12-03 07:21:09,300 [Listener at localhost/44900] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:applyEditLogOp(388)) - replaying edit log: CloseOp [length=0, inodeId=0, path=/test/testUpgrade, replication=3, mtime=1606980063544, atime=1606980062569, blockSize=4, blocks=[blk_1073741825_1001, blk_1073741827_1003], permissions=root:supergroup:rw-r--r--, aclEntries=null, clientName=, clientMachine=, overwrite=false, storagePolicyId=0, erasureCodingPolicyId=0, opCode=OP_CLOSE, txid=17]
2020-12-03 07:21:09,301 [Listener at localhost/44900] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:loadEditRecords(284)) - op=LogSegmentOp [opCode=OP_END_LOG_SEGMENT, txid=18], startOpt=REGULAR, numEdits=17, totalEdits=17
2020-12-03 07:21:09,301 [Listener at localhost/44900] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:applyEditLogOp(388)) - replaying edit log: LogSegmentOp [opCode=OP_END_LOG_SEGMENT, txid=18]
2020-12-03 07:21:09,301 [Listener at localhost/44900] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:loadEditRecords(347)) - replaying edit log finished
2020-12-03 07:21:09,302 [Listener at localhost/44900] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(188)) - Loaded 1 edits file(s) (the last named /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000018, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000018) of total size 1059.0, total edits 18.0, total load time 14.0 ms
2020-12-03 07:21:09,302 [Listener at localhost/44900] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:loadEditRecords(217)) - Acquiring write lock to replay edit log
2020-12-03 07:21:09,302 [Listener at localhost/44900] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000019-0000000000000000020' to transaction ID 1
2020-12-03 07:21:09,303 [Listener at localhost/44900] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:loadEditRecords(284)) - op=LogSegmentOp [opCode=OP_START_LOG_SEGMENT, txid=19], startOpt=REGULAR, numEdits=0, totalEdits=18
2020-12-03 07:21:09,303 [Listener at localhost/44900] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:applyEditLogOp(388)) - replaying edit log: LogSegmentOp [opCode=OP_START_LOG_SEGMENT, txid=19]
2020-12-03 07:21:09,303 [Listener at localhost/44900] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:loadEditRecords(284)) - op=LogSegmentOp [opCode=OP_END_LOG_SEGMENT, txid=20], startOpt=REGULAR, numEdits=1, totalEdits=19
2020-12-03 07:21:09,303 [Listener at localhost/44900] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:applyEditLogOp(388)) - replaying edit log: LogSegmentOp [opCode=OP_END_LOG_SEGMENT, txid=20]
2020-12-03 07:21:09,304 [Listener at localhost/44900] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:loadEditRecords(347)) - replaying edit log finished
2020-12-03 07:21:09,304 [Listener at localhost/44900] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:21:09,305 [Listener at localhost/44900] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 21
2020-12-03 07:21:09,403 [Listener at localhost/44900] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:21:09,403 [Listener at localhost/44900] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 233 msecs
2020-12-03 07:21:09,404 [Listener at localhost/44900] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:21:09,405 [Listener at localhost/44900] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:21:09,405 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:21:09,413 [Listener at localhost/44262] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:44262 to access this namenode/service.
2020-12-03 07:21:09,414 [Listener at localhost/44262] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:21:09,443 [Listener at localhost/44262] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:21:09,445 [Listener at localhost/44262] INFO  hdfs.StateChange (BlockManagerSafeMode.java:reportStatus(617)) - STATE* Safe mode ON. 
The reported blocks 0 needs additional 2 blocks to reach the threshold 0.9990 of total blocks 3.
The minimum number of live datanodes is not required. Safe mode will be turned off automatically once the thresholds have been reached.
2020-12-03 07:21:09,451 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:21:09,451 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:21:09,456 [Listener at localhost/44262] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:44262
2020-12-03 07:21:09,457 [Listener at localhost/44262] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:21:09,457 [Listener at localhost/44262] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:21:09,460 [Listener at localhost/44262] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 1 milliseconds
name space=3
storage space=33
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:21:09,464 [CacheReplicationMonitor(905440010)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:21:09,467 [Listener at localhost/44262] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:21:09,468 [Listener at localhost/44262] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:21:09,469 [Listener at localhost/44262] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:21:09,470 [Listener at localhost/44262] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:21:09,473 [Listener at localhost/44262] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:09,473 [Listener at localhost/44262] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:21:09,473 [Listener at localhost/44262] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:21:09,474 [Listener at localhost/44262] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:09,474 [Listener at localhost/44262] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:09,474 [Listener at localhost/44262] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:09,475 [Listener at localhost/44262] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:21:09,476 [Listener at localhost/44262] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:38668
2020-12-03 07:21:09,476 [Listener at localhost/44262] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:21:09,477 [Listener at localhost/44262] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:21:09,478 [Listener at localhost/44262] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:09,480 [Listener at localhost/44262] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:21:09,481 [Listener at localhost/44262] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:21:09,481 [Listener at localhost/44262] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:09,484 [Listener at localhost/44262] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:21:09,485 [Listener at localhost/44262] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:21:09,485 [Listener at localhost/44262] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:21:09,485 [Listener at localhost/44262] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:21:09,486 [Listener at localhost/44262] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 39166
2020-12-03 07:21:09,486 [Listener at localhost/44262] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:21:09,488 [Listener at localhost/44262] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6441c486{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:21:09,489 [Listener at localhost/44262] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@234a8f27{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:21:09,496 [Listener at localhost/44262] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@2c708440{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:21:09,497 [Listener at localhost/44262] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3047254d{HTTP/1.1,[http/1.1]}{localhost:39166}
2020-12-03 07:21:09,500 [Listener at localhost/44262] INFO  server.Server (Server.java:doStart(419)) - Started @14494ms
2020-12-03 07:21:09,521 [Listener at localhost/44262] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:37203
2020-12-03 07:21:09,522 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4e92466a] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:21:09,522 [Listener at localhost/44262] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:21:09,522 [Listener at localhost/44262] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:21:09,523 [Listener at localhost/44262] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:21:09,524 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:21:09,536 [Listener at localhost/42373] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:42373
2020-12-03 07:21:09,547 [Listener at localhost/42373] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:21:09,547 [Listener at localhost/42373] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:21:09,548 [Thread-524] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44262 starting to offer service
2020-12-03 07:21:09,552 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:21:09,552 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:21:09,568 [Listener at localhost/42373] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:21:09,569 [Listener at localhost/42373] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:21:09,569 [Thread-524] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44262
2020-12-03 07:21:09,571 [Listener at localhost/42373] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:21:09,571 [Thread-524] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:21:09,573 [Listener at localhost/42373] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:21:09,574 [Listener at localhost/42373] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:09,574 [Listener at localhost/42373] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:21:09,575 [Listener at localhost/42373] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:21:09,575 [Listener at localhost/42373] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:09,575 [Listener at localhost/42373] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:09,575 [Listener at localhost/42373] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:09,575 [Listener at localhost/42373] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:21:09,576 [Listener at localhost/42373] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:34644
2020-12-03 07:21:09,576 [Listener at localhost/42373] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:21:09,576 [Listener at localhost/42373] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:21:09,577 [Listener at localhost/42373] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:09,579 [Listener at localhost/42373] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:21:09,579 [Listener at localhost/42373] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:21:09,580 [Listener at localhost/42373] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:09,582 [Listener at localhost/42373] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:21:09,583 [Listener at localhost/42373] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:21:09,583 [Listener at localhost/42373] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:21:09,583 [Listener at localhost/42373] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:21:09,584 [Listener at localhost/42373] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 43390
2020-12-03 07:21:09,584 [Listener at localhost/42373] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:21:09,587 [Listener at localhost/42373] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6a9b0a6f{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:21:09,587 [Listener at localhost/42373] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@191a709b{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:21:09,595 [Listener at localhost/42373] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@47ec7422{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:21:09,596 [Listener at localhost/42373] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@48535004{HTTP/1.1,[http/1.1]}{localhost:43390}
2020-12-03 07:21:09,599 [Listener at localhost/42373] INFO  server.Server (Server.java:doStart(419)) - Started @14593ms
2020-12-03 07:21:09,616 [Listener at localhost/42373] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:42260
2020-12-03 07:21:09,616 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2b56f5f8] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:21:09,616 [Listener at localhost/42373] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:21:09,617 [Listener at localhost/42373] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:21:09,617 [Listener at localhost/42373] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:21:09,618 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:21:09,620 [Thread-524] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 2630@9bd33dce04e9
2020-12-03 07:21:09,622 [Listener at localhost/42034] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:42034
2020-12-03 07:21:09,636 [Listener at localhost/42034] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:21:09,637 [Listener at localhost/42034] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:21:09,638 [Thread-547] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44262 starting to offer service
2020-12-03 07:21:09,641 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:21:09,642 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:21:09,648 [Listener at localhost/42034] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:21:09,648 [Thread-547] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44262
2020-12-03 07:21:09,650 [Thread-547] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:21:09,650 [Listener at localhost/42034] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:21:09,651 [Listener at localhost/42034] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:21:09,651 [Listener at localhost/42034] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:21:09,653 [Listener at localhost/42034] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:09,653 [Listener at localhost/42034] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:21:09,653 [Listener at localhost/42034] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:21:09,654 [Listener at localhost/42034] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:09,654 [Listener at localhost/42034] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:09,654 [Listener at localhost/42034] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:09,654 [Listener at localhost/42034] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:21:09,655 [Listener at localhost/42034] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:45291
2020-12-03 07:21:09,655 [Listener at localhost/42034] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:21:09,655 [Listener at localhost/42034] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:21:09,656 [Listener at localhost/42034] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:09,658 [Listener at localhost/42034] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:21:09,659 [Listener at localhost/42034] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:21:09,659 [Listener at localhost/42034] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:09,660 [Listener at localhost/42034] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:21:09,661 [Listener at localhost/42034] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:21:09,661 [Listener at localhost/42034] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:21:09,661 [Listener at localhost/42034] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:21:09,662 [Listener at localhost/42034] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 39177
2020-12-03 07:21:09,662 [Listener at localhost/42034] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:21:09,664 [Listener at localhost/42034] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2b61a019{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:21:09,665 [Listener at localhost/42034] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7ce9e05a{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:21:09,671 [Listener at localhost/42034] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@314c8b4a{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:21:09,671 [Listener at localhost/42034] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@26d820eb{HTTP/1.1,[http/1.1]}{localhost:39177}
2020-12-03 07:21:09,674 [Listener at localhost/42034] INFO  server.Server (Server.java:doStart(419)) - Started @14668ms
2020-12-03 07:21:09,691 [Listener at localhost/42034] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:46543
2020-12-03 07:21:09,692 [Listener at localhost/42034] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:21:09,692 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@9fec931] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:21:09,692 [Listener at localhost/42034] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:21:09,693 [Listener at localhost/42034] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:21:09,695 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:21:09,697 [Thread-524] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 2630@9bd33dce04e9
2020-12-03 07:21:09,697 [Thread-547] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 2630@9bd33dce04e9
2020-12-03 07:21:09,703 [Listener at localhost/35349] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:35349
2020-12-03 07:21:09,717 [Listener at localhost/35349] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:21:09,718 [Listener at localhost/35349] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:21:09,719 [Thread-569] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44262 starting to offer service
2020-12-03 07:21:09,726 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:21:09,729 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:21:09,737 [Thread-569] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44262
2020-12-03 07:21:09,739 [Thread-569] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:21:09,756 [IPC Server handler 3 on default port 44262] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:09,757 [Listener at localhost/35349] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:09,757 [Listener at localhost/35349] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:09,765 [Thread-524] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:09,766 [Thread-524] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:09,772 [Thread-569] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 2630@9bd33dce04e9
2020-12-03 07:21:09,772 [Thread-547] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 2630@9bd33dce04e9
2020-12-03 07:21:09,834 [Thread-524] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:09,834 [Thread-524] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:09,848 [Thread-547] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:09,849 [Thread-547] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:09,861 [IPC Server handler 4 on default port 44262] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:09,874 [Listener at localhost/35349] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:09,874 [Listener at localhost/35349] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:09,898 [Thread-524] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1142161323;bpid=BP-425068830-172.17.0.8-1606980057018;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1142161323;c=1606980057018;bpid=BP-425068830-172.17.0.8-1606980057018;dnuuid=81972425-7fba-4dbf-b586-2759576dcb2a
2020-12-03 07:21:09,901 [Thread-524] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-e2a4702c-e5d8-49ec-98d9-afcba9a4bf2b
2020-12-03 07:21:09,901 [Thread-524] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-12-03 07:21:09,904 [Thread-524] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-7f94b3d0-d801-4a3a-80c5-f0a5c86996d0
2020-12-03 07:21:09,904 [Thread-524] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-12-03 07:21:09,915 [Thread-569] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 2630@9bd33dce04e9
2020-12-03 07:21:09,915 [Thread-524] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:21:09,916 [Thread-524] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:21:09,917 [Thread-524] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:21:09,917 [Thread-524] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:21:09,917 [Thread-524] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:21:09,927 [Thread-524] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:09,928 [Thread-583] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:21:09,928 [Thread-584] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:21:09,936 [Thread-584] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-425068830-172.17.0.8-1606980057018/current: 24605
2020-12-03 07:21:09,937 [Thread-583] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-425068830-172.17.0.8-1606980057018/current: 24591
2020-12-03 07:21:09,944 [Thread-584] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-425068830-172.17.0.8-1606980057018 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 10ms
2020-12-03 07:21:09,945 [Thread-547] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:09,945 [Thread-583] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-425068830-172.17.0.8-1606980057018 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 17ms
2020-12-03 07:21:09,945 [Thread-524] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-425068830-172.17.0.8-1606980057018: 18ms
2020-12-03 07:21:09,945 [Thread-547] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:09,945 [Thread-585] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:21:09,946 [Thread-586] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:21:09,952 [Thread-585] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(925)) - Successfully read replica from cache file : /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-425068830-172.17.0.8-1606980057018/current/replicas
2020-12-03 07:21:09,952 [Thread-586] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(925)) - Successfully read replica from cache file : /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-425068830-172.17.0.8-1606980057018/current/replicas
2020-12-03 07:21:09,952 [Thread-585] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 7ms
2020-12-03 07:21:09,953 [Thread-586] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 7ms
2020-12-03 07:21:09,981 [Thread-524] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-425068830-172.17.0.8-1606980057018: 35ms
2020-12-03 07:21:09,981 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-7f94b3d0-d801-4a3a-80c5-f0a5c86996d0): no suitable block pools found to scan.  Waiting 1814392315 ms.
2020-12-03 07:21:09,982 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-e2a4702c-e5d8-49ec-98d9-afcba9a4bf2b): no suitable block pools found to scan.  Waiting 1814392314 ms.
2020-12-03 07:21:09,982 [Thread-524] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 1:14 PM with interval of 21600000ms
2020-12-03 07:21:09,985 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:44262] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-425068830-172.17.0.8-1606980057018 (Datanode Uuid 81972425-7fba-4dbf-b586-2759576dcb2a) service to localhost/127.0.0.1:44262 beginning handshake with NN
2020-12-03 07:21:09,986 [IPC Server handler 5 on default port 44262] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:38668, datanodeUuid=81972425-7fba-4dbf-b586-2759576dcb2a, infoPort=37203, infoSecurePort=0, ipcPort=42373, storageInfo=lv=-57;cid=testClusterID;nsid=1142161323;c=1606980057018) storage 81972425-7fba-4dbf-b586-2759576dcb2a
2020-12-03 07:21:09,986 [IPC Server handler 5 on default port 44262] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38668
2020-12-03 07:21:09,987 [IPC Server handler 5 on default port 44262] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 81972425-7fba-4dbf-b586-2759576dcb2a (127.0.0.1:38668).
2020-12-03 07:21:09,991 [Thread-547] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1142161323;bpid=BP-425068830-172.17.0.8-1606980057018;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1142161323;c=1606980057018;bpid=BP-425068830-172.17.0.8-1606980057018;dnuuid=0b0f70d2-7565-48f3-b01c-1adf7b4ab560
2020-12-03 07:21:09,991 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:44262] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-425068830-172.17.0.8-1606980057018 (Datanode Uuid 81972425-7fba-4dbf-b586-2759576dcb2a) service to localhost/127.0.0.1:44262 successfully registered with NN
2020-12-03 07:21:09,991 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:44262] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:44262 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-12-03 07:21:09,996 [IPC Server handler 6 on default port 44262] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:09,998 [Listener at localhost/35349] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:09,998 [Listener at localhost/35349] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:09,999 [IPC Server handler 7 on default port 44262] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-e2a4702c-e5d8-49ec-98d9-afcba9a4bf2b for DN 127.0.0.1:38668
2020-12-03 07:21:09,999 [IPC Server handler 7 on default port 44262] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-7f94b3d0-d801-4a3a-80c5-f0a5c86996d0 for DN 127.0.0.1:38668
2020-12-03 07:21:10,000 [Thread-547] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-9a7d7b8b-ec12-469a-9a7d-60ed5e71167a
2020-12-03 07:21:10,004 [Thread-547] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: DISK
2020-12-03 07:21:10,005 [Thread-547] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-d40683d6-ae9f-4bbb-bc67-169f6d82dbbb
2020-12-03 07:21:10,005 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x124379c5e3823452: Processing first storage report for DS-e2a4702c-e5d8-49ec-98d9-afcba9a4bf2b from datanode 81972425-7fba-4dbf-b586-2759576dcb2a
2020-12-03 07:21:10,005 [Thread-547] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: DISK
2020-12-03 07:21:10,008 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x124379c5e3823452: from storage DS-e2a4702c-e5d8-49ec-98d9-afcba9a4bf2b node DatanodeRegistration(127.0.0.1:38668, datanodeUuid=81972425-7fba-4dbf-b586-2759576dcb2a, infoPort=37203, infoSecurePort=0, ipcPort=42373, storageInfo=lv=-57;cid=testClusterID;nsid=1142161323;c=1606980057018), blocks: 1, hasStaleStorage: true, processing time: 2 msecs, invalidatedBlocks: 0
2020-12-03 07:21:10,008 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x124379c5e3823452: Processing first storage report for DS-7f94b3d0-d801-4a3a-80c5-f0a5c86996d0 from datanode 81972425-7fba-4dbf-b586-2759576dcb2a
2020-12-03 07:21:10,008 [Block report processor] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:21:10,008 [Thread-547] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:21:10,011 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(395)) - STATE* Safe mode is OFF
2020-12-03 07:21:10,011 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:21:10,012 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 1 racks and 1 datanodes
2020-12-03 07:21:10,012 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:21:10,015 [Block report processor] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_1073741827_1003 curReplicas 1 curExpectedReplicas 3 oldReplicas 0 oldExpectedReplicas  3 curPri  0 oldPri  4
2020-12-03 07:21:10,016 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x124379c5e3823452: from storage DS-7f94b3d0-d801-4a3a-80c5-f0a5c86996d0 node DatanodeRegistration(127.0.0.1:38668, datanodeUuid=81972425-7fba-4dbf-b586-2759576dcb2a, infoPort=37203, infoSecurePort=0, ipcPort=42373, storageInfo=lv=-57;cid=testClusterID;nsid=1142161323;c=1606980057018), blocks: 2, hasStaleStorage: false, processing time: 7 msecs, invalidatedBlocks: 0
2020-12-03 07:21:10,021 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 3
2020-12-03 07:21:10,022 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:21:10,022 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 2
2020-12-03 07:21:10,022 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:21:10,022 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:21:10,022 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 11 msec
2020-12-03 07:21:10,023 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:44262] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x124379c5e3823452,  containing 2 storage report(s), of which we sent 2. The reports had 3 total blocks and used 1 RPC(s). This took 0 msec to generate and 19 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:21:10,023 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:44262] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:10,026 [Thread-547] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:21:10,029 [Thread-569] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:10,037 [Thread-547] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:21:10,037 [Thread-547] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:21:10,038 [Thread-547] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:21:10,040 [Thread-547] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:10,040 [Thread-569] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:10,040 [Thread-593] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:21:10,041 [Thread-594] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:21:10,042 [Thread-593] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-425068830-172.17.0.8-1606980057018/current: 24591
2020-12-03 07:21:10,042 [Thread-594] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-425068830-172.17.0.8-1606980057018/current: 24605
2020-12-03 07:21:10,050 [Thread-593] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-425068830-172.17.0.8-1606980057018 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 10ms
2020-12-03 07:21:10,053 [Thread-594] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-425068830-172.17.0.8-1606980057018 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 12ms
2020-12-03 07:21:10,053 [Thread-547] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-425068830-172.17.0.8-1606980057018: 13ms
2020-12-03 07:21:10,053 [Thread-595] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:21:10,054 [Thread-596] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:21:10,056 [Thread-595] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(925)) - Successfully read replica from cache file : /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-425068830-172.17.0.8-1606980057018/current/replicas
2020-12-03 07:21:10,056 [Thread-596] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(925)) - Successfully read replica from cache file : /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-425068830-172.17.0.8-1606980057018/current/replicas
2020-12-03 07:21:10,056 [Thread-595] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 3ms
2020-12-03 07:21:10,056 [Thread-596] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 3ms
2020-12-03 07:21:10,056 [Thread-547] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-425068830-172.17.0.8-1606980057018: 3ms
2020-12-03 07:21:10,057 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-9a7d7b8b-ec12-469a-9a7d-60ed5e71167a): no suitable block pools found to scan.  Waiting 1814392239 ms.
2020-12-03 07:21:10,059 [Thread-547] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 8:22 AM with interval of 21600000ms
2020-12-03 07:21:10,059 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-d40683d6-ae9f-4bbb-bc67-169f6d82dbbb): no suitable block pools found to scan.  Waiting 1814392237 ms.
2020-12-03 07:21:10,061 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:44262] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-425068830-172.17.0.8-1606980057018 (Datanode Uuid 0b0f70d2-7565-48f3-b01c-1adf7b4ab560) service to localhost/127.0.0.1:44262 beginning handshake with NN
2020-12-03 07:21:10,062 [IPC Server handler 9 on default port 44262] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34644, datanodeUuid=0b0f70d2-7565-48f3-b01c-1adf7b4ab560, infoPort=42260, infoSecurePort=0, ipcPort=42034, storageInfo=lv=-57;cid=testClusterID;nsid=1142161323;c=1606980057018) storage 0b0f70d2-7565-48f3-b01c-1adf7b4ab560
2020-12-03 07:21:10,063 [IPC Server handler 9 on default port 44262] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:34644
2020-12-03 07:21:10,063 [IPC Server handler 9 on default port 44262] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 0b0f70d2-7565-48f3-b01c-1adf7b4ab560 (127.0.0.1:34644).
2020-12-03 07:21:10,064 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:44262] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-425068830-172.17.0.8-1606980057018 (Datanode Uuid 0b0f70d2-7565-48f3-b01c-1adf7b4ab560) service to localhost/127.0.0.1:44262 successfully registered with NN
2020-12-03 07:21:10,064 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:44262] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:44262 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-12-03 07:21:10,069 [IPC Server handler 0 on default port 44262] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-9a7d7b8b-ec12-469a-9a7d-60ed5e71167a for DN 127.0.0.1:34644
2020-12-03 07:21:10,072 [IPC Server handler 0 on default port 44262] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d40683d6-ae9f-4bbb-bc67-169f6d82dbbb for DN 127.0.0.1:34644
2020-12-03 07:21:10,073 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x842c958ba657b00: Processing first storage report for DS-9a7d7b8b-ec12-469a-9a7d-60ed5e71167a from datanode 0b0f70d2-7565-48f3-b01c-1adf7b4ab560
2020-12-03 07:21:10,074 [Block report processor] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_1073741825_1001 curReplicas 2 curExpectedReplicas 3 oldReplicas 1 oldExpectedReplicas  3 curPri  2 oldPri  0
2020-12-03 07:21:10,074 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x842c958ba657b00: from storage DS-9a7d7b8b-ec12-469a-9a7d-60ed5e71167a node DatanodeRegistration(127.0.0.1:34644, datanodeUuid=0b0f70d2-7565-48f3-b01c-1adf7b4ab560, infoPort=42260, infoSecurePort=0, ipcPort=42034, storageInfo=lv=-57;cid=testClusterID;nsid=1142161323;c=1606980057018), blocks: 1, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:21:10,074 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x842c958ba657b00: Processing first storage report for DS-d40683d6-ae9f-4bbb-bc67-169f6d82dbbb from datanode 0b0f70d2-7565-48f3-b01c-1adf7b4ab560
2020-12-03 07:21:10,074 [Block report processor] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_1073741826_1002 curReplicas 2 curExpectedReplicas 3 oldReplicas 1 oldExpectedReplicas  3 curPri  2 oldPri  0
2020-12-03 07:21:10,075 [Block report processor] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_1073741827_1003 curReplicas 2 curExpectedReplicas 3 oldReplicas 1 oldExpectedReplicas  3 curPri  2 oldPri  0
2020-12-03 07:21:10,075 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x842c958ba657b00: from storage DS-d40683d6-ae9f-4bbb-bc67-169f6d82dbbb node DatanodeRegistration(127.0.0.1:34644, datanodeUuid=0b0f70d2-7565-48f3-b01c-1adf7b4ab560, infoPort=42260, infoSecurePort=0, ipcPort=42034, storageInfo=lv=-57;cid=testClusterID;nsid=1142161323;c=1606980057018), blocks: 2, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:10,075 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:44262] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x842c958ba657b00,  containing 2 storage report(s), of which we sent 2. The reports had 3 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:21:10,076 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:44262] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:10,092 [Thread-569] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:10,093 [Thread-569] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:10,100 [IPC Server handler 2 on default port 44262] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:10,101 [Listener at localhost/35349] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:10,101 [Listener at localhost/35349] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:10,143 [Thread-569] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1142161323;bpid=BP-425068830-172.17.0.8-1606980057018;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1142161323;c=1606980057018;bpid=BP-425068830-172.17.0.8-1606980057018;dnuuid=5326576b-2216-4538-9245-8b0fb17c9d46
2020-12-03 07:21:10,145 [Thread-569] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-c38ad29d-afe4-4ee0-be21-3867655f82fb
2020-12-03 07:21:10,145 [Thread-569] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, StorageType: DISK
2020-12-03 07:21:10,150 [Thread-569] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-07458f0c-3587-41d4-abeb-821d73c89765
2020-12-03 07:21:10,151 [Thread-569] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, StorageType: DISK
2020-12-03 07:21:10,165 [Thread-569] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:21:10,166 [Thread-569] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:21:10,167 [Thread-569] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:21:10,167 [Thread-569] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:21:10,167 [Thread-569] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:21:10,167 [Thread-569] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:10,168 [Thread-602] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:21:10,168 [Thread-603] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:21:10,169 [Thread-602] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-425068830-172.17.0.8-1606980057018/current: 24591
2020-12-03 07:21:10,169 [Thread-603] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-425068830-172.17.0.8-1606980057018/current: 24605
2020-12-03 07:21:10,177 [Thread-602] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-425068830-172.17.0.8-1606980057018 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 9ms
2020-12-03 07:21:10,178 [Thread-603] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-425068830-172.17.0.8-1606980057018 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 10ms
2020-12-03 07:21:10,178 [Thread-569] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-425068830-172.17.0.8-1606980057018: 11ms
2020-12-03 07:21:10,179 [Thread-604] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:21:10,179 [Thread-605] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:21:10,181 [Thread-604] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(925)) - Successfully read replica from cache file : /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-425068830-172.17.0.8-1606980057018/current/replicas
2020-12-03 07:21:10,181 [Thread-605] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(925)) - Successfully read replica from cache file : /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-425068830-172.17.0.8-1606980057018/current/replicas
2020-12-03 07:21:10,182 [Thread-604] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 3ms
2020-12-03 07:21:10,182 [Thread-605] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-425068830-172.17.0.8-1606980057018 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 3ms
2020-12-03 07:21:10,182 [Thread-569] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-425068830-172.17.0.8-1606980057018: 3ms
2020-12-03 07:21:10,183 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-07458f0c-3587-41d4-abeb-821d73c89765): no suitable block pools found to scan.  Waiting 1814392113 ms.
2020-12-03 07:21:10,183 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-c38ad29d-afe4-4ee0-be21-3867655f82fb): no suitable block pools found to scan.  Waiting 1814392113 ms.
2020-12-03 07:21:10,183 [Thread-569] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 10:03 AM with interval of 21600000ms
2020-12-03 07:21:10,186 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:44262] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-425068830-172.17.0.8-1606980057018 (Datanode Uuid 5326576b-2216-4538-9245-8b0fb17c9d46) service to localhost/127.0.0.1:44262 beginning handshake with NN
2020-12-03 07:21:10,187 [IPC Server handler 3 on default port 44262] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:45291, datanodeUuid=5326576b-2216-4538-9245-8b0fb17c9d46, infoPort=46543, infoSecurePort=0, ipcPort=35349, storageInfo=lv=-57;cid=testClusterID;nsid=1142161323;c=1606980057018) storage 5326576b-2216-4538-9245-8b0fb17c9d46
2020-12-03 07:21:10,187 [IPC Server handler 3 on default port 44262] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:45291
2020-12-03 07:21:10,188 [IPC Server handler 3 on default port 44262] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 5326576b-2216-4538-9245-8b0fb17c9d46 (127.0.0.1:45291).
2020-12-03 07:21:10,188 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:44262] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-425068830-172.17.0.8-1606980057018 (Datanode Uuid 5326576b-2216-4538-9245-8b0fb17c9d46) service to localhost/127.0.0.1:44262 successfully registered with NN
2020-12-03 07:21:10,189 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:44262] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:44262 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-12-03 07:21:10,194 [IPC Server handler 4 on default port 44262] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c38ad29d-afe4-4ee0-be21-3867655f82fb for DN 127.0.0.1:45291
2020-12-03 07:21:10,194 [IPC Server handler 4 on default port 44262] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-07458f0c-3587-41d4-abeb-821d73c89765 for DN 127.0.0.1:45291
2020-12-03 07:21:10,197 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x727b12127acd3d9f: Processing first storage report for DS-07458f0c-3587-41d4-abeb-821d73c89765 from datanode 5326576b-2216-4538-9245-8b0fb17c9d46
2020-12-03 07:21:10,197 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x727b12127acd3d9f: from storage DS-07458f0c-3587-41d4-abeb-821d73c89765 node DatanodeRegistration(127.0.0.1:45291, datanodeUuid=5326576b-2216-4538-9245-8b0fb17c9d46, infoPort=46543, infoSecurePort=0, ipcPort=35349, storageInfo=lv=-57;cid=testClusterID;nsid=1142161323;c=1606980057018), blocks: 2, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:21:10,198 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x727b12127acd3d9f: Processing first storage report for DS-c38ad29d-afe4-4ee0-be21-3867655f82fb from datanode 5326576b-2216-4538-9245-8b0fb17c9d46
2020-12-03 07:21:10,198 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x727b12127acd3d9f: from storage DS-c38ad29d-afe4-4ee0-be21-3867655f82fb node DatanodeRegistration(127.0.0.1:45291, datanodeUuid=5326576b-2216-4538-9245-8b0fb17c9d46, infoPort=46543, infoSecurePort=0, ipcPort=35349, storageInfo=lv=-57;cid=testClusterID;nsid=1142161323;c=1606980057018), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:10,199 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:44262] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x727b12127acd3d9f,  containing 2 storage report(s), of which we sent 2. The reports had 3 total blocks and used 1 RPC(s). This took 0 msec to generate and 4 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:21:10,200 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:44262] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:10,207 [IPC Server handler 6 on default port 44262] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:10,208 [Listener at localhost/35349] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:21:10,211 [IPC Server handler 7 on default port 44262] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testUpgrade	dst=null	perm=null	proto=rpc
2020-12-03 07:21:10,213 [IPC Server handler 8 on default port 44262] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/test/testUpgrade	dst=null	perm=null	proto=rpc
2020-12-03 07:21:10,215 [Listener at localhost/35349] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:10,221 [IPC Server handler 0 on default port 44262] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/test/.snapshot/ss0/testUpgrade	dst=null	perm=null	proto=rpc
2020-12-03 07:21:10,223 [Listener at localhost/35349] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:10,232 [IPC Server handler 1 on default port 44262] INFO  hdfs.StateChange (FSNamesystem.java:enterSafeMode(4674)) - STATE* Safe mode is ON.
It was turned on manually. Use "hdfs dfsadmin -safemode leave" to turn safe mode off.
2020-12-03 07:21:10,232 [IPC Server handler 1 on default port 44262] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_enter	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:10,239 [IPC Server handler 2 on default port 44262] INFO  namenode.FSImage (FSImage.java:saveNamespace(1147)) - Save namespace ...
2020-12-03 07:21:10,239 [IPC Server handler 2 on default port 44262] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 21, 21
2020-12-03 07:21:10,242 [IPC Server handler 2 on default port 44262] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 2 Total time for transactions(ms): 7 Number of transactions batched in Syncs: 20 Number of syncs: 3 SyncTimes(ms): 3 2 
2020-12-03 07:21:10,244 [IPC Server handler 2 on default port 44262] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000021 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000021-0000000000000000022
2020-12-03 07:21:10,246 [IPC Server handler 2 on default port 44262] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000021 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000021-0000000000000000022
2020-12-03 07:21:10,256 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000022 using no compression
2020-12-03 07:21:10,256 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000022 using no compression
2020-12-03 07:21:10,263 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000022 of size 757 bytes saved in 0 seconds .
2020-12-03 07:21:10,264 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000022 of size 757 bytes saved in 0 seconds .
2020-12-03 07:21:10,338 [IPC Server handler 2 on default port 44262] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 2 images with txid >= 0
2020-12-03 07:21:10,420 [IPC Server handler 2 on default port 44262] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 23
2020-12-03 07:21:10,506 [IPC Server handler 2 on default port 44262] INFO  namenode.FSNamesystem (FSNamesystem.java:saveNamespace(4500)) - New namespace image has been created
2020-12-03 07:21:10,506 [IPC Server handler 2 on default port 44262] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=saveNamespace	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:10,510 [Listener at localhost/35349] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:21:10,510 [Listener at localhost/35349] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:21:10,510 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@58a4a74d] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:21:10,510 [Listener at localhost/35349] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 23, 23
2020-12-03 07:21:10,510 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@54aca26f] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:21:10,515 [Listener at localhost/35349] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 2 Total time for transactions(ms): 6 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 2 1 
2020-12-03 07:21:10,516 [Listener at localhost/35349] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000023 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000023-0000000000000000024
2020-12-03 07:21:10,517 [Listener at localhost/35349] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000023 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000023-0000000000000000024
2020-12-03 07:21:10,517 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:21:10,517 [CacheReplicationMonitor(905440010)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:21:10,526 [Listener at localhost/35349] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 44262
2020-12-03 07:21:10,527 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:10,527 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:10,529 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:21:10,529 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:21:10,543 [Listener at localhost/35349] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:21:10,543 [Listener at localhost/35349] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:21:10,546 [Listener at localhost/35349] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@4a5905d9{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:21:10,547 [Listener at localhost/35349] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@1a3e5f23{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:21:10,548 [Listener at localhost/35349] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@253b380a{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:21:10,548 [Listener at localhost/35349] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@64bfd6fd{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:21:10,552 [Listener at localhost/35349] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:21:10,552 [Listener at localhost/35349] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-12-03 07:21:10,553 [Listener at localhost/35349] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://localhost:44262
2020-12-03 07:21:10,553 [Listener at localhost/35349] INFO  namenode.NameNode (NameNode.java:<init>(944)) - Clients should use localhost:44262 to access this namenode/service.
2020-12-03 07:21:10,566 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6eb82908] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:21:10,566 [Listener at localhost/35349] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:34578
2020-12-03 07:21:10,566 [Listener at localhost/35349] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:10,568 [Listener at localhost/35349] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:21:10,568 [Listener at localhost/35349] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:21:10,569 [Listener at localhost/35349] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:10,571 [Listener at localhost/35349] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:21:10,571 [Listener at localhost/35349] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:21:10,571 [Listener at localhost/35349] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:21:10,572 [Listener at localhost/35349] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:21:10,573 [Listener at localhost/35349] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:21:10,574 [Listener at localhost/35349] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:21:10,574 [Listener at localhost/35349] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 34578
2020-12-03 07:21:10,575 [Listener at localhost/35349] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:21:10,580 [Listener at localhost/35349] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5e2f3be5{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:21:10,580 [Listener at localhost/35349] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@dc7b462{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:21:10,587 [Listener at localhost/35349] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@4bb003e9{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:21:10,588 [Listener at localhost/35349] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@12aa4996{HTTP/1.1,[http/1.1]}{localhost:34578}
2020-12-03 07:21:10,596 [Listener at localhost/35349] INFO  server.Server (Server.java:doStart(419)) - Started @15591ms
2020-12-03 07:21:10,599 [Listener at localhost/35349] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:21:10,600 [Listener at localhost/35349] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:21:10,600 [Listener at localhost/35349] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:21:10,600 [Listener at localhost/35349] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:21:10,600 [Listener at localhost/35349] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:21:10,600 [Listener at localhost/35349] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:21:10,600 [Listener at localhost/35349] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:21:10,601 [Listener at localhost/35349] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:21:10,601 [Listener at localhost/35349] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:10,602 [Listener at localhost/35349] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:10,602 [Listener at localhost/35349] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=20, effected=1000
2020-12-03 07:21:10,602 [Listener at localhost/35349] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:21:10,602 [Listener at localhost/35349] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:10,602 [Listener at localhost/35349] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:21:10,603 [Listener at localhost/35349] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:21:10
2020-12-03 07:21:10,603 [Listener at localhost/35349] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:21:10,603 [Listener at localhost/35349] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:10,604 [Listener at localhost/35349] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:21:10,604 [Listener at localhost/35349] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:21:10,609 [Listener at localhost/35349] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:10,609 [Listener at localhost/35349] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:10,610 [Listener at localhost/35349] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:21:10,610 [Listener at localhost/35349] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:21:10,610 [Listener at localhost/35349] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:10,610 [Listener at localhost/35349] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:21:10,610 [Listener at localhost/35349] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:21:10,611 [Listener at localhost/35349] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:21:10,611 [Listener at localhost/35349] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:21:10,611 [Listener at localhost/35349] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:21:10,611 [Listener at localhost/35349] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:21:10,611 [Listener at localhost/35349] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:21:10,611 [Listener at localhost/35349] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:21:10,611 [Listener at localhost/35349] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:21:10,612 [Listener at localhost/35349] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:21:10,612 [Listener at localhost/35349] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:21:10,612 [Listener at localhost/35349] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:21:10,612 [Listener at localhost/35349] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:10,613 [Listener at localhost/35349] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:21:10,613 [Listener at localhost/35349] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:21:10,615 [Listener at localhost/35349] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:21:10,615 [Listener at localhost/35349] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:21:10,615 [Listener at localhost/35349] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:21:10,615 [Listener at localhost/35349] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:21:10,615 [Listener at localhost/35349] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:21:10,615 [Listener at localhost/35349] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:21:10,616 [Listener at localhost/35349] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:21:10,616 [Listener at localhost/35349] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:10,616 [Listener at localhost/35349] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:21:10,616 [Listener at localhost/35349] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:21:10,617 [Listener at localhost/35349] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:21:10,617 [Listener at localhost/35349] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:21:10,617 [Listener at localhost/35349] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:21:10,617 [Listener at localhost/35349] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:21:10,618 [Listener at localhost/35349] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:21:10,618 [Listener at localhost/35349] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:21:10,618 [Listener at localhost/35349] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:10,618 [Listener at localhost/35349] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:21:10,618 [Listener at localhost/35349] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:21:10,683 [Listener at localhost/35349] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 2630@9bd33dce04e9
2020-12-03 07:21:10,757 [Listener at localhost/35349] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 2630@9bd33dce04e9
2020-12-03 07:21:10,760 [Listener at localhost/35349] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-12-03 07:21:10,761 [Listener at localhost/35349] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-12-03 07:21:10,762 [Listener at localhost/35349] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000022, cpktTxId=0000000000000000022)
2020-12-03 07:21:10,766 [Listener at localhost/35349] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 3 INodes.
2020-12-03 07:21:10,770 [Listener at localhost/35349] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:21:10,770 [Listener at localhost/35349] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 22 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000022
2020-12-03 07:21:10,770 [Listener at localhost/35349] INFO  namenode.FSImage (FSImage.java:loadEdits(910)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@6e495b48 expecting start txid #23
2020-12-03 07:21:10,771 [Listener at localhost/35349] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000023-0000000000000000024, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000023-0000000000000000024 maxTxnsToRead = 9223372036854775807
2020-12-03 07:21:10,771 [Listener at localhost/35349] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:loadEditRecords(217)) - Acquiring write lock to replay edit log
2020-12-03 07:21:10,771 [Listener at localhost/35349] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000023-0000000000000000024' to transaction ID 23
2020-12-03 07:21:10,771 [Listener at localhost/35349] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:loadEditRecords(284)) - op=LogSegmentOp [opCode=OP_START_LOG_SEGMENT, txid=23], startOpt=REGULAR, numEdits=0, totalEdits=0
2020-12-03 07:21:10,771 [Listener at localhost/35349] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:applyEditLogOp(388)) - replaying edit log: LogSegmentOp [opCode=OP_START_LOG_SEGMENT, txid=23]
2020-12-03 07:21:10,772 [Listener at localhost/35349] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:loadEditRecords(284)) - op=LogSegmentOp [opCode=OP_END_LOG_SEGMENT, txid=24], startOpt=REGULAR, numEdits=1, totalEdits=1
2020-12-03 07:21:10,772 [Listener at localhost/35349] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:applyEditLogOp(388)) - replaying edit log: LogSegmentOp [opCode=OP_END_LOG_SEGMENT, txid=24]
2020-12-03 07:21:10,772 [Listener at localhost/35349] TRACE namenode.FSEditLogLoader (FSEditLogLoader.java:loadEditRecords(347)) - replaying edit log finished
2020-12-03 07:21:10,772 [Listener at localhost/35349] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(188)) - Loaded 1 edits file(s) (the last named /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000023-0000000000000000024, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000023-0000000000000000024) of total size 42.0, total edits 2.0, total load time 1.0 ms
2020-12-03 07:21:10,772 [Listener at localhost/35349] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:21:10,773 [Listener at localhost/35349] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 25
2020-12-03 07:21:10,917 [Listener at localhost/35349] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:21:10,918 [Listener at localhost/35349] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 298 msecs
2020-12-03 07:21:10,918 [Listener at localhost/35349] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:44262
2020-12-03 07:21:10,919 [Listener at localhost/35349] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:21:10,920 [Socket Reader #1 for port 44262] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 44262
2020-12-03 07:21:10,936 [Listener at localhost/44262] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:21:10,974 [Listener at localhost/44262] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:21:10,976 [Listener at localhost/44262] INFO  hdfs.StateChange (BlockManagerSafeMode.java:reportStatus(617)) - STATE* Safe mode ON. 
The reported blocks 0 needs additional 2 blocks to reach the threshold 0.9990 of total blocks 3.
The minimum number of live datanodes is not required. Safe mode will be turned off automatically once the thresholds have been reached.
2020-12-03 07:21:10,980 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:21:10,980 [IPC Server listener on 44262] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 44262: starting
2020-12-03 07:21:10,994 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:44262] WARN  datanode.DataNode (BPServiceActor.java:offerService(731)) - IOException in offerService
java.io.EOFException: End of File Exception between local host is: "9bd33dce04e9/172.17.0.8"; destination host is: "localhost":44262; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:791)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
	at com.sun.proxy.$Proxy24.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:168)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:517)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:648)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:849)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
2020-12-03 07:21:10,998 [Listener at localhost/44262] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:44262
2020-12-03 07:21:10,999 [Listener at localhost/44262] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:21:10,999 [Listener at localhost/44262] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:21:11,000 [Listener at localhost/44262] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 1 milliseconds
name space=3
storage space=33
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:21:11,005 [Listener at localhost/44262] WARN  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitClusterUp(1436)) - Waiting for the Mini HDFS Cluster to start...
2020-12-03 07:21:11,005 [CacheReplicationMonitor(24219494)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:21:11,073 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:44262] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActor(672)) - DatanodeCommand action : DNA_REGISTER from localhost/127.0.0.1:44262 with active state
2020-12-03 07:21:11,075 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:44262] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-425068830-172.17.0.8-1606980057018 (Datanode Uuid 0b0f70d2-7565-48f3-b01c-1adf7b4ab560) service to localhost/127.0.0.1:44262 beginning handshake with NN
2020-12-03 07:21:11,077 [IPC Server handler 0 on default port 44262] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34644, datanodeUuid=0b0f70d2-7565-48f3-b01c-1adf7b4ab560, infoPort=42260, infoSecurePort=0, ipcPort=42034, storageInfo=lv=-57;cid=testClusterID;nsid=1142161323;c=1606980057018) storage 0b0f70d2-7565-48f3-b01c-1adf7b4ab560
2020-12-03 07:21:11,078 [IPC Server handler 0 on default port 44262] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:34644
2020-12-03 07:21:11,078 [IPC Server handler 0 on default port 44262] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 0b0f70d2-7565-48f3-b01c-1adf7b4ab560 (127.0.0.1:34644).
2020-12-03 07:21:11,081 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:44262] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-425068830-172.17.0.8-1606980057018 (Datanode Uuid 0b0f70d2-7565-48f3-b01c-1adf7b4ab560) service to localhost/127.0.0.1:44262 successfully registered with NN
2020-12-03 07:21:11,083 [IPC Server handler 5 on default port 44262] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-9a7d7b8b-ec12-469a-9a7d-60ed5e71167a for DN 127.0.0.1:34644
2020-12-03 07:21:11,083 [IPC Server handler 5 on default port 44262] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d40683d6-ae9f-4bbb-bc67-169f6d82dbbb for DN 127.0.0.1:34644
2020-12-03 07:21:11,087 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x842c958ba657b01: Processing first storage report for DS-9a7d7b8b-ec12-469a-9a7d-60ed5e71167a from datanode 0b0f70d2-7565-48f3-b01c-1adf7b4ab560
2020-12-03 07:21:11,087 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x842c958ba657b01: from storage DS-9a7d7b8b-ec12-469a-9a7d-60ed5e71167a node DatanodeRegistration(127.0.0.1:34644, datanodeUuid=0b0f70d2-7565-48f3-b01c-1adf7b4ab560, infoPort=42260, infoSecurePort=0, ipcPort=42034, storageInfo=lv=-57;cid=testClusterID;nsid=1142161323;c=1606980057018), blocks: 1, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:21:11,087 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x842c958ba657b01: Processing first storage report for DS-d40683d6-ae9f-4bbb-bc67-169f6d82dbbb from datanode 0b0f70d2-7565-48f3-b01c-1adf7b4ab560
2020-12-03 07:21:11,087 [Block report processor] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:21:11,090 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(395)) - STATE* Safe mode is OFF
2020-12-03 07:21:11,090 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:21:11,090 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 1 racks and 1 datanodes
2020-12-03 07:21:11,090 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:21:11,092 [Block report processor] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_1073741827_1003 curReplicas 1 curExpectedReplicas 3 oldReplicas 0 oldExpectedReplicas  3 curPri  0 oldPri  4
2020-12-03 07:21:11,092 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x842c958ba657b01: from storage DS-d40683d6-ae9f-4bbb-bc67-169f6d82dbbb node DatanodeRegistration(127.0.0.1:34644, datanodeUuid=0b0f70d2-7565-48f3-b01c-1adf7b4ab560, infoPort=42260, infoSecurePort=0, ipcPort=42034, storageInfo=lv=-57;cid=testClusterID;nsid=1142161323;c=1606980057018), blocks: 2, hasStaleStorage: false, processing time: 5 msecs, invalidatedBlocks: 0
2020-12-03 07:21:11,097 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 3
2020-12-03 07:21:11,098 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:21:11,098 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 2
2020-12-03 07:21:11,098 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:21:11,098 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:21:11,098 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 8 msec
2020-12-03 07:21:11,099 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:44262] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x842c958ba657b01,  containing 2 storage report(s), of which we sent 2. The reports had 3 total blocks and used 1 RPC(s). This took 0 msec to generate and 13 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:21:11,099 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:44262] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:11,192 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:44262] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActor(672)) - DatanodeCommand action : DNA_REGISTER from localhost/127.0.0.1:44262 with active state
2020-12-03 07:21:11,193 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:44262] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-425068830-172.17.0.8-1606980057018 (Datanode Uuid 5326576b-2216-4538-9245-8b0fb17c9d46) service to localhost/127.0.0.1:44262 beginning handshake with NN
2020-12-03 07:21:11,194 [IPC Server handler 7 on default port 44262] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:45291, datanodeUuid=5326576b-2216-4538-9245-8b0fb17c9d46, infoPort=46543, infoSecurePort=0, ipcPort=35349, storageInfo=lv=-57;cid=testClusterID;nsid=1142161323;c=1606980057018) storage 5326576b-2216-4538-9245-8b0fb17c9d46
2020-12-03 07:21:11,194 [IPC Server handler 7 on default port 44262] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:45291
2020-12-03 07:21:11,194 [IPC Server handler 7 on default port 44262] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 5326576b-2216-4538-9245-8b0fb17c9d46 (127.0.0.1:45291).
2020-12-03 07:21:11,195 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:44262] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-425068830-172.17.0.8-1606980057018 (Datanode Uuid 5326576b-2216-4538-9245-8b0fb17c9d46) service to localhost/127.0.0.1:44262 successfully registered with NN
2020-12-03 07:21:11,197 [IPC Server handler 8 on default port 44262] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c38ad29d-afe4-4ee0-be21-3867655f82fb for DN 127.0.0.1:45291
2020-12-03 07:21:11,197 [IPC Server handler 8 on default port 44262] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-07458f0c-3587-41d4-abeb-821d73c89765 for DN 127.0.0.1:45291
2020-12-03 07:21:11,199 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x727b12127acd3da0: Processing first storage report for DS-07458f0c-3587-41d4-abeb-821d73c89765 from datanode 5326576b-2216-4538-9245-8b0fb17c9d46
2020-12-03 07:21:11,199 [Block report processor] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_1073741826_1002 curReplicas 2 curExpectedReplicas 3 oldReplicas 1 oldExpectedReplicas  3 curPri  2 oldPri  0
2020-12-03 07:21:11,199 [Block report processor] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_1073741827_1003 curReplicas 2 curExpectedReplicas 3 oldReplicas 1 oldExpectedReplicas  3 curPri  2 oldPri  0
2020-12-03 07:21:11,200 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x727b12127acd3da0: from storage DS-07458f0c-3587-41d4-abeb-821d73c89765 node DatanodeRegistration(127.0.0.1:45291, datanodeUuid=5326576b-2216-4538-9245-8b0fb17c9d46, infoPort=46543, infoSecurePort=0, ipcPort=35349, storageInfo=lv=-57;cid=testClusterID;nsid=1142161323;c=1606980057018), blocks: 2, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:11,200 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x727b12127acd3da0: Processing first storage report for DS-c38ad29d-afe4-4ee0-be21-3867655f82fb from datanode 5326576b-2216-4538-9245-8b0fb17c9d46
2020-12-03 07:21:11,200 [Block report processor] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_1073741825_1001 curReplicas 2 curExpectedReplicas 3 oldReplicas 1 oldExpectedReplicas  3 curPri  2 oldPri  0
2020-12-03 07:21:11,200 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x727b12127acd3da0: from storage DS-c38ad29d-afe4-4ee0-be21-3867655f82fb node DatanodeRegistration(127.0.0.1:45291, datanodeUuid=5326576b-2216-4538-9245-8b0fb17c9d46, infoPort=46543, infoSecurePort=0, ipcPort=35349, storageInfo=lv=-57;cid=testClusterID;nsid=1142161323;c=1606980057018), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:11,200 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:44262] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x727b12127acd3da0,  containing 2 storage report(s), of which we sent 2. The reports had 3 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:21:11,201 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:44262] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:12,002 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:44262] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActor(672)) - DatanodeCommand action : DNA_REGISTER from localhost/127.0.0.1:44262 with active state
2020-12-03 07:21:12,004 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:44262] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-425068830-172.17.0.8-1606980057018 (Datanode Uuid 81972425-7fba-4dbf-b586-2759576dcb2a) service to localhost/127.0.0.1:44262 beginning handshake with NN
2020-12-03 07:21:12,005 [IPC Server handler 0 on default port 44262] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:38668, datanodeUuid=81972425-7fba-4dbf-b586-2759576dcb2a, infoPort=37203, infoSecurePort=0, ipcPort=42373, storageInfo=lv=-57;cid=testClusterID;nsid=1142161323;c=1606980057018) storage 81972425-7fba-4dbf-b586-2759576dcb2a
2020-12-03 07:21:12,005 [IPC Server handler 0 on default port 44262] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38668
2020-12-03 07:21:12,005 [Listener at localhost/44262] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:restartNameNode(2191)) - Restarted the namenode
2020-12-03 07:21:12,005 [IPC Server handler 0 on default port 44262] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 81972425-7fba-4dbf-b586-2759576dcb2a (127.0.0.1:38668).
2020-12-03 07:21:12,007 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:44262] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-425068830-172.17.0.8-1606980057018 (Datanode Uuid 81972425-7fba-4dbf-b586-2759576dcb2a) service to localhost/127.0.0.1:44262 successfully registered with NN
2020-12-03 07:21:12,010 [IPC Server handler 5 on default port 44262] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-e2a4702c-e5d8-49ec-98d9-afcba9a4bf2b for DN 127.0.0.1:38668
2020-12-03 07:21:12,010 [IPC Server handler 5 on default port 44262] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-7f94b3d0-d801-4a3a-80c5-f0a5c86996d0 for DN 127.0.0.1:38668
2020-12-03 07:21:12,040 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x124379c5e3823453: Processing first storage report for DS-e2a4702c-e5d8-49ec-98d9-afcba9a4bf2b from datanode 81972425-7fba-4dbf-b586-2759576dcb2a
2020-12-03 07:21:12,041 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x124379c5e3823453: from storage DS-e2a4702c-e5d8-49ec-98d9-afcba9a4bf2b node DatanodeRegistration(127.0.0.1:38668, datanodeUuid=81972425-7fba-4dbf-b586-2759576dcb2a, infoPort=37203, infoSecurePort=0, ipcPort=42373, storageInfo=lv=-57;cid=testClusterID;nsid=1142161323;c=1606980057018), blocks: 1, hasStaleStorage: true, processing time: 11 msecs, invalidatedBlocks: 0
2020-12-03 07:21:12,043 [IPC Server handler 2 on default port 44262] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:12,044 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x124379c5e3823453: Processing first storage report for DS-7f94b3d0-d801-4a3a-80c5-f0a5c86996d0 from datanode 81972425-7fba-4dbf-b586-2759576dcb2a
2020-12-03 07:21:12,044 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x124379c5e3823453: from storage DS-7f94b3d0-d801-4a3a-80c5-f0a5c86996d0 node DatanodeRegistration(127.0.0.1:38668, datanodeUuid=81972425-7fba-4dbf-b586-2759576dcb2a, infoPort=37203, infoSecurePort=0, ipcPort=42373, storageInfo=lv=-57;cid=testClusterID;nsid=1142161323;c=1606980057018), blocks: 2, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:21:12,045 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:44262] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x124379c5e3823453,  containing 2 storage report(s), of which we sent 2. The reports had 3 total blocks and used 1 RPC(s). This took 1 msec to generate and 34 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:21:12,045 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:44262] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:12,045 [Listener at localhost/44262] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:21:12,050 [IPC Server handler 6 on default port 44262] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testUpgrade	dst=null	perm=null	proto=rpc
2020-12-03 07:21:12,053 [IPC Server handler 7 on default port 44262] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/test/testUpgrade	dst=null	perm=null	proto=rpc
2020-12-03 07:21:12,075 [IPC Server handler 8 on default port 44262] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/test/.snapshot/ss0/testUpgrade	dst=null	perm=null	proto=rpc
2020-12-03 07:21:12,079 [Listener at localhost/44262] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:12,109 [IPC Server handler 1 on default port 44262] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=deleteSnapshot	src=/test/.snapshot/ss0	dst=null	perm=null	proto=rpc
2020-12-03 07:21:12,119 [IPC Server handler 4 on default port 44262] DEBUG hdfs.StateChange (NameNodeRpcServer.java:delete(1103)) - *DIR* Namenode.delete: src=/test, recursive=true
2020-12-03 07:21:12,121 [IPC Server handler 4 on default port 44262] DEBUG hdfs.StateChange (FSDirDeleteOp.java:deleteInternal(180)) - DIR* NameSystem.delete: /test
2020-12-03 07:21:12,121 [IPC Server handler 4 on default port 44262] DEBUG hdfs.StateChange (FSDirDeleteOp.java:delete(55)) - DIR* FSDirectory.delete: /test
2020-12-03 07:21:12,123 [IPC Server handler 4 on default port 44262] DEBUG hdfs.StateChange (FSDirDeleteOp.java:unprotectedDelete(269)) - DIR* FSDirectory.unprotectedDelete: /test is removed
2020-12-03 07:21:12,124 [IPC Server handler 4 on default port 44262] DEBUG hdfs.StateChange (FSDirDeleteOp.java:deleteInternal(201)) - DIR* Namesystem.delete: /test is removed
2020-12-03 07:21:12,125 [IPC Server handler 4 on default port 44262] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/test	dst=null	perm=null	proto=rpc
2020-12-03 07:21:12,129 [IPC Server handler 0 on default port 44262] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testUpgrade	dst=null	perm=null	proto=rpc
2020-12-03 07:21:12,129 [Listener at localhost/44262] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:21:12,129 [Listener at localhost/44262] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 2
2020-12-03 07:21:12,130 [Listener at localhost/44262] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:21:12,130 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@7144655b] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:21:12,133 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-07458f0c-3587-41d4-abeb-821d73c89765) exiting.
2020-12-03 07:21:12,133 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-c38ad29d-afe4-4ee0-be21-3867655f82fb) exiting.
2020-12-03 07:21:12,149 [Listener at localhost/44262] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@314c8b4a{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:21:12,150 [Listener at localhost/44262] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@26d820eb{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:21:12,150 [Listener at localhost/44262] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7ce9e05a{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:21:12,151 [Listener at localhost/44262] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2b61a019{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:21:12,159 [Listener at localhost/44262] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 35349
2020-12-03 07:21:12,167 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:12,168 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:12,169 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:44262] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:12,170 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:44262] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-425068830-172.17.0.8-1606980057018 (Datanode Uuid 5326576b-2216-4538-9245-8b0fb17c9d46) service to localhost/127.0.0.1:44262
2020-12-03 07:21:12,170 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:44262] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-425068830-172.17.0.8-1606980057018 (Datanode Uuid 5326576b-2216-4538-9245-8b0fb17c9d46)
2020-12-03 07:21:12,170 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:44262] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:12,177 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-425068830-172.17.0.8-1606980057018] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:12,177 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-425068830-172.17.0.8-1606980057018] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:12,179 [Listener at localhost/44262] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:21:12,180 [Listener at localhost/44262] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:21:12,180 [Listener at localhost/44262] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:21:12,180 [Listener at localhost/44262] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:21:12,182 [Listener at localhost/44262] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:21:12,182 [Listener at localhost/44262] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 1
2020-12-03 07:21:12,182 [Listener at localhost/44262] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:21:12,182 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@4f82663e] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:21:12,183 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-9a7d7b8b-ec12-469a-9a7d-60ed5e71167a) exiting.
2020-12-03 07:21:12,183 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-d40683d6-ae9f-4bbb-bc67-169f6d82dbbb) exiting.
2020-12-03 07:21:12,199 [Listener at localhost/44262] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@47ec7422{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:21:12,199 [Listener at localhost/44262] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@48535004{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:21:12,200 [Listener at localhost/44262] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@191a709b{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:21:12,200 [Listener at localhost/44262] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6a9b0a6f{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:21:12,201 [Listener at localhost/44262] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 42034
2020-12-03 07:21:12,204 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:12,204 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:12,206 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:44262] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:12,206 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:44262] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-425068830-172.17.0.8-1606980057018 (Datanode Uuid 0b0f70d2-7565-48f3-b01c-1adf7b4ab560) service to localhost/127.0.0.1:44262
2020-12-03 07:21:12,206 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:44262] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-425068830-172.17.0.8-1606980057018 (Datanode Uuid 0b0f70d2-7565-48f3-b01c-1adf7b4ab560)
2020-12-03 07:21:12,206 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:44262] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:12,207 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-425068830-172.17.0.8-1606980057018] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:12,208 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-425068830-172.17.0.8-1606980057018] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:12,211 [Listener at localhost/44262] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:21:12,211 [Listener at localhost/44262] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:21:12,212 [Listener at localhost/44262] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:21:12,212 [Listener at localhost/44262] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:21:12,214 [Listener at localhost/44262] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:21:12,214 [Listener at localhost/44262] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:21:12,214 [Listener at localhost/44262] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:21:12,214 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@1237e0be] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:21:12,216 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-7f94b3d0-d801-4a3a-80c5-f0a5c86996d0) exiting.
2020-12-03 07:21:12,216 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-e2a4702c-e5d8-49ec-98d9-afcba9a4bf2b) exiting.
2020-12-03 07:21:12,234 [Listener at localhost/44262] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@2c708440{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:21:12,235 [Listener at localhost/44262] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@3047254d{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:21:12,236 [Listener at localhost/44262] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@234a8f27{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:21:12,236 [Listener at localhost/44262] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6441c486{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:21:12,237 [Listener at localhost/44262] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 42373
2020-12-03 07:21:12,242 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:12,242 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:21:12,243 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:44262] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:21:12,244 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:44262] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-425068830-172.17.0.8-1606980057018 (Datanode Uuid 81972425-7fba-4dbf-b586-2759576dcb2a) service to localhost/127.0.0.1:44262
2020-12-03 07:21:12,244 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:44262] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-425068830-172.17.0.8-1606980057018 (Datanode Uuid 81972425-7fba-4dbf-b586-2759576dcb2a)
2020-12-03 07:21:12,244 [BP-425068830-172.17.0.8-1606980057018 heartbeating to localhost/127.0.0.1:44262] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-425068830-172.17.0.8-1606980057018
2020-12-03 07:21:12,245 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-425068830-172.17.0.8-1606980057018] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:12,246 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-425068830-172.17.0.8-1606980057018] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:21:12,252 [Listener at localhost/44262] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:21:12,252 [Listener at localhost/44262] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:21:12,253 [Listener at localhost/44262] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:21:12,253 [Listener at localhost/44262] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:21:12,255 [Listener at localhost/44262] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:21:12,255 [Listener at localhost/44262] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:21:12,255 [Listener at localhost/44262] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:21:12,255 [Listener at localhost/44262] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 25, 27
2020-12-03 07:21:12,255 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@8ff5094] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:21:12,255 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@363f0ba0] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:21:12,256 [Listener at localhost/44262] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 4 Total time for transactions(ms): 7 Number of transactions batched in Syncs: 24 Number of syncs: 5 SyncTimes(ms): 3 2 
2020-12-03 07:21:12,257 [Listener at localhost/44262] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000025 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000025-0000000000000000028
2020-12-03 07:21:12,257 [Listener at localhost/44262] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000025 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000025-0000000000000000028
2020-12-03 07:21:12,257 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:21:12,258 [CacheReplicationMonitor(24219494)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:21:12,266 [Listener at localhost/44262] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 44262
2020-12-03 07:21:12,268 [IPC Server listener on 44262] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 44262
2020-12-03 07:21:12,268 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:21:12,269 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:21:12,269 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:21:12,278 [Listener at localhost/44262] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:21:12,278 [Listener at localhost/44262] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:21:12,280 [Listener at localhost/44262] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@4bb003e9{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:21:12,281 [Listener at localhost/44262] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@12aa4996{HTTP/1.1,[http/1.1]}{localhost:34578}
2020-12-03 07:21:12,281 [Listener at localhost/44262] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@dc7b462{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:21:12,282 [Listener at localhost/44262] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5e2f3be5{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:21:12,282 [Listener at localhost/44262] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping NameNode metrics system...
2020-12-03 07:21:12,291 [Listener at localhost/44262] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - NameNode metrics system stopped.
2020-12-03 07:21:12,292 [Listener at localhost/44262] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - NameNode metrics system shutdown complete.
msx-rc 0
