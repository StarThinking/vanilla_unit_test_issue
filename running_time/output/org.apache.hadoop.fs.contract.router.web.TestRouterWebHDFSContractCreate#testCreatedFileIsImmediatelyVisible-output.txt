2020-12-03 07:22:35,841 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=4, numDataNodes=4
2020-12-03 07:22:35,877 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:initMiniDFSCluster(875)) - MiniDFSCluster disabling checkpointing in the Standby node since no HTTP ports have been specified.
2020-12-03 07:22:35,878 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:initMiniDFSCluster(881)) - MiniDFSCluster disabling log-roll triggering in the Standby node since no IPC ports have been specified.
Formatting using clusterid: testClusterID
2020-12-03 07:22:36,580 [JUnit] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:22:36,595 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:22:36,596 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:22:36,597 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:22:36,605 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:22:36,605 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:22:36,605 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:22:36,610 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns0
2020-12-03 07:22:36,610 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: true
2020-12-03 07:22:36,674 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:36,679 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2020-12-03 07:22:36,680 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:22:36,680 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:22:36,688 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:22:36,689 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:22:36
2020-12-03 07:22:36,691 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:22:36,691 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:36,693 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-12-03 07:22:36,693 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:22:36,714 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:22:36,715 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:22:36,724 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:22:36,724 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:22:36,724 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:22:36,724 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:22:36,725 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:22:36,726 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:22:36,726 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:22:36,726 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:22:36,726 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:22:36,727 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:22:36,727 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:22:36,765 [JUnit] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GLOBAL serial map: bits=29 maxEntries=536870911
2020-12-03 07:22:36,766 [JUnit] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - USER serial map: bits=24 maxEntries=16777215
2020-12-03 07:22:36,766 [JUnit] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GROUP serial map: bits=24 maxEntries=16777215
2020-12-03 07:22:36,766 [JUnit] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - XATTR serial map: bits=24 maxEntries=16777215
2020-12-03 07:22:36,790 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:22:36,790 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:36,791 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-12-03 07:22:36,791 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:22:36,798 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:22:36,798 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:22:36,798 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:22:36,799 [JUnit] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:22:36,806 [JUnit] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:22:36,809 [JUnit] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:22:36,815 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:22:36,815 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:36,816 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-12-03 07:22:36,816 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:22:36,828 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:22:36,828 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:22:36,828 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:22:36,834 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:22:36,834 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:22:36,837 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:22:36,837 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:36,838 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-12-03 07:22:36,838 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:22:36,877 [JUnit] INFO  namenode.FSImage (FSImage.java:format(185)) - Allocated new BlockPoolId: BP-1217207052-172.17.0.3-1606980156864
2020-12-03 07:22:37,092 [JUnit] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-12-03 07:22:37,247 [JUnit] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-12-03 07:22:37,333 [JUnit] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-0-through-1 has been successfully formatted.
2020-12-03 07:22:37,371 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:22:37,371 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:22:37,519 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:22:37,519 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:22:37,595 [JUnit] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-12-03 07:22:37,690 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:copyNameDirs(1264)) - Copying namedir from primary node dir file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1 to file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-3
2020-12-03 07:22:37,711 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:copyNameDirs(1264)) - Copying namedir from primary node dir file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1 to file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-4
2020-12-03 07:22:37,718 [JUnit] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:22:37,931 [JUnit] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-namenode.properties,hadoop-metrics2.properties
2020-12-03 07:22:38,038 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2020-12-03 07:22:38,038 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:22:38,046 [JUnit] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://ns0
2020-12-03 07:22:38,047 [JUnit] INFO  namenode.NameNode (NameNode.java:<init>(944)) - Clients should use ns0 to access this namenode/service.
2020-12-03 07:22:38,105 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@72ade7e3] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:38,125 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:22:38,155 [JUnit] INFO  util.log (Log.java:initialized(192)) - Logging initialized @3317ms
2020-12-03 07:22:38,286 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:38,290 [JUnit] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:22:38,303 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:38,306 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:22:38,307 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:38,307 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:38,339 [JUnit] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:22:38,340 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:22:38,353 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 33883
2020-12-03 07:22:38,355 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:38,419 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@60129b9a{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:22:38,421 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@492691d7{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:22:38,726 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@512535ff{/,file:///tmp/jetty-localhost-33883-hdfs-_-any-7901113808691929051.dir/webapp/,AVAILABLE}{/hdfs}
2020-12-03 07:22:38,734 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@331acdad{HTTP/1.1,[http/1.1]}{localhost:33883}
2020-12-03 07:22:38,734 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @3896ms
2020-12-03 07:22:38,745 [JUnit] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:22:38,746 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:22:38,746 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:22:38,746 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:22:38,747 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:22:38,747 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:22:38,747 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:22:38,748 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns0
2020-12-03 07:22:38,748 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: true
2020-12-03 07:22:38,749 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:38,750 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:22:38,750 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:22:38,750 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:22:38,751 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:22:38
2020-12-03 07:22:38,751 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:22:38,751 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:38,752 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:22:38,752 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:22:38,769 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:22:38,769 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:22:38,770 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:22:38,770 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:22:38,771 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:22:38,771 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:22:38,771 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:22:38,771 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:22:38,772 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:22:38,772 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:22:38,772 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:22:38,772 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:22:38,773 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:22:38,774 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:22:38,774 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:38,774 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:22:38,775 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:22:38,777 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:22:38,778 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:22:38,778 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:22:38,778 [JUnit] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:22:38,778 [JUnit] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:22:38,779 [JUnit] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:22:38,779 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:22:38,779 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:38,780 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:22:38,780 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:22:38,783 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:22:38,783 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:22:38,783 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:22:38,784 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:22:38,784 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:22:38,784 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:22:38,785 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:38,785 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:22:38,786 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:22:38,858 [JUnit] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 7615@1e0d9a01dc20
2020-12-03 07:22:38,958 [JUnit] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 7615@1e0d9a01dc20
2020-12-03 07:22:38,959 [JUnit] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-0-through-1
2020-12-03 07:22:38,963 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:22:38,964 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:22:39,000 [JUnit] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:22:39,007 [JUnit] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:22:39,008 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-12-03 07:22:39,013 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2020-12-03 07:22:39,014 [JUnit] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:22:39,014 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 225 msecs
2020-12-03 07:22:39,217 [JUnit] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to 0.0.0.0:0
2020-12-03 07:22:39,266 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:39,282 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:39,600 [Listener at 0.0.0.0/42246] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:22:39,624 [Listener at 0.0.0.0/42246] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:22:39,639 [Listener at 0.0.0.0/42246] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:22:39,639 [Listener at 0.0.0.0/42246] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:22:39,640 [Listener at 0.0.0.0/42246] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:22:39,681 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:39,681 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:39,684 [Listener at 0.0.0.0/42246] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:42246
2020-12-03 07:22:39,686 [Listener at 0.0.0.0/42246] INFO  namenode.FSNamesystem (FSNamesystem.java:startStandbyServices(1391)) - Starting services required for standby state
2020-12-03 07:22:39,688 [Listener at 0.0.0.0/42246] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.log-roll.period(-1) assuming SECONDS
2020-12-03 07:22:39,688 [Listener at 0.0.0.0/42246] INFO  ha.EditLogTailer (EditLogTailer.java:<init>(208)) - Not going to trigger log rolls on active node because dfs.ha.log-roll.period is negative.
2020-12-03 07:22:39,688 [Listener at 0.0.0.0/42246] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.period.backoff-max(0) assuming SECONDS
2020-12-03 07:22:39,689 [Listener at 0.0.0.0/42246] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.rolledits.timeout(60) assuming SECONDS
2020-12-03 07:22:39,692 [Listener at 0.0.0.0/42246] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:22:39,692 [Listener at 0.0.0.0/42246] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-12-03 07:22:39,692 [Listener at 0.0.0.0/42246] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://ns0
2020-12-03 07:22:39,693 [Listener at 0.0.0.0/42246] INFO  namenode.NameNode (NameNode.java:<init>(944)) - Clients should use ns0 to access this namenode/service.
2020-12-03 07:22:39,700 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@15bcf458] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:39,700 [Listener at 0.0.0.0/42246] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:22:39,703 [Listener at 0.0.0.0/42246] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:39,705 [Listener at 0.0.0.0/42246] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:22:39,709 [Listener at 0.0.0.0/42246] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:39,711 [Listener at 0.0.0.0/42246] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:22:39,711 [Listener at 0.0.0.0/42246] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:39,711 [Listener at 0.0.0.0/42246] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:39,714 [Listener at 0.0.0.0/42246] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:22:39,714 [Listener at 0.0.0.0/42246] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:22:39,715 [Listener at 0.0.0.0/42246] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 45519
2020-12-03 07:22:39,716 [Listener at 0.0.0.0/42246] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:39,719 [Listener at 0.0.0.0/42246] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@14bb2297{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:22:39,721 [Listener at 0.0.0.0/42246] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@797501a{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:22:40,030 [Listener at 0.0.0.0/42246] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7544a1e4{/,file:///tmp/jetty-localhost-45519-hdfs-_-any-1861338443517585987.dir/webapp/,AVAILABLE}{/hdfs}
2020-12-03 07:22:40,032 [Listener at 0.0.0.0/42246] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@70e0accd{HTTP/1.1,[http/1.1]}{localhost:45519}
2020-12-03 07:22:40,032 [Listener at 0.0.0.0/42246] INFO  server.Server (Server.java:doStart(419)) - Started @5194ms
2020-12-03 07:22:40,036 [Listener at 0.0.0.0/42246] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:22:40,037 [Listener at 0.0.0.0/42246] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:22:40,037 [Listener at 0.0.0.0/42246] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:22:40,037 [Listener at 0.0.0.0/42246] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:22:40,037 [Listener at 0.0.0.0/42246] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:22:40,038 [Listener at 0.0.0.0/42246] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:22:40,038 [Listener at 0.0.0.0/42246] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:22:40,039 [Listener at 0.0.0.0/42246] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns0
2020-12-03 07:22:40,039 [Listener at 0.0.0.0/42246] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: true
2020-12-03 07:22:40,040 [Listener at 0.0.0.0/42246] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:40,040 [Listener at 0.0.0.0/42246] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:22:40,040 [Listener at 0.0.0.0/42246] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:22:40,041 [Listener at 0.0.0.0/42246] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:22:40,042 [Listener at 0.0.0.0/42246] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:22:40
2020-12-03 07:22:40,042 [Listener at 0.0.0.0/42246] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:22:40,042 [Listener at 0.0.0.0/42246] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:40,042 [Listener at 0.0.0.0/42246] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:22:40,043 [Listener at 0.0.0.0/42246] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:22:40,056 [Listener at 0.0.0.0/42246] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:22:40,056 [Listener at 0.0.0.0/42246] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:22:40,057 [Listener at 0.0.0.0/42246] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:22:40,057 [Listener at 0.0.0.0/42246] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:22:40,057 [Listener at 0.0.0.0/42246] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:22:40,057 [Listener at 0.0.0.0/42246] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:22:40,057 [Listener at 0.0.0.0/42246] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:22:40,058 [Listener at 0.0.0.0/42246] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:22:40,058 [Listener at 0.0.0.0/42246] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:22:40,058 [Listener at 0.0.0.0/42246] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:22:40,058 [Listener at 0.0.0.0/42246] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:22:40,058 [Listener at 0.0.0.0/42246] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:22:40,058 [Listener at 0.0.0.0/42246] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:22:40,059 [Listener at 0.0.0.0/42246] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:22:40,059 [Listener at 0.0.0.0/42246] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:40,059 [Listener at 0.0.0.0/42246] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:22:40,060 [Listener at 0.0.0.0/42246] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:22:40,066 [Listener at 0.0.0.0/42246] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:22:40,067 [Listener at 0.0.0.0/42246] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:22:40,067 [Listener at 0.0.0.0/42246] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:22:40,067 [Listener at 0.0.0.0/42246] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:22:40,067 [Listener at 0.0.0.0/42246] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:22:40,068 [Listener at 0.0.0.0/42246] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:22:40,068 [Listener at 0.0.0.0/42246] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:22:40,068 [Listener at 0.0.0.0/42246] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:40,068 [Listener at 0.0.0.0/42246] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:22:40,069 [Listener at 0.0.0.0/42246] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:22:40,070 [Listener at 0.0.0.0/42246] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:22:40,071 [Listener at 0.0.0.0/42246] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:22:40,071 [Listener at 0.0.0.0/42246] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:22:40,071 [Listener at 0.0.0.0/42246] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:22:40,071 [Listener at 0.0.0.0/42246] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:22:40,072 [Listener at 0.0.0.0/42246] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:22:40,072 [Listener at 0.0.0.0/42246] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:40,072 [Listener at 0.0.0.0/42246] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:22:40,072 [Listener at 0.0.0.0/42246] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:22:40,530 [Listener at 0.0.0.0/42246] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-3/in_use.lock acquired by nodename 7615@1e0d9a01dc20
2020-12-03 07:22:40,626 [Listener at 0.0.0.0/42246] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-4/in_use.lock acquired by nodename 7615@1e0d9a01dc20
2020-12-03 07:22:40,627 [Listener at 0.0.0.0/42246] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-0-through-1
2020-12-03 07:22:40,633 [Listener at 0.0.0.0/42246] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:22:40,634 [Listener at 0.0.0.0/42246] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-3/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:22:40,637 [Listener at 0.0.0.0/42246] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:22:40,639 [Listener at 0.0.0.0/42246] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:22:40,640 [Listener at 0.0.0.0/42246] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-3/current/fsimage_0000000000000000000
2020-12-03 07:22:40,640 [Listener at 0.0.0.0/42246] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2020-12-03 07:22:40,641 [Listener at 0.0.0.0/42246] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:22:40,641 [Listener at 0.0.0.0/42246] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 566 msecs
2020-12-03 07:22:40,642 [Listener at 0.0.0.0/42246] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to 0.0.0.0:0
2020-12-03 07:22:40,644 [Listener at 0.0.0.0/42246] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:40,645 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:40,656 [Listener at 0.0.0.0/37628] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:22:40,681 [Listener at 0.0.0.0/37628] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:22:40,684 [Listener at 0.0.0.0/37628] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:22:40,684 [Listener at 0.0.0.0/37628] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:22:40,685 [Listener at 0.0.0.0/37628] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:22:40,696 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:40,696 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:40,701 [Listener at 0.0.0.0/37628] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:37628
2020-12-03 07:22:40,702 [Listener at 0.0.0.0/37628] INFO  namenode.FSNamesystem (FSNamesystem.java:startStandbyServices(1391)) - Starting services required for standby state
2020-12-03 07:22:40,702 [Listener at 0.0.0.0/37628] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.log-roll.period(-1) assuming SECONDS
2020-12-03 07:22:40,702 [Listener at 0.0.0.0/37628] INFO  ha.EditLogTailer (EditLogTailer.java:<init>(208)) - Not going to trigger log rolls on active node because dfs.ha.log-roll.period is negative.
2020-12-03 07:22:40,702 [Listener at 0.0.0.0/37628] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.period.backoff-max(0) assuming SECONDS
2020-12-03 07:22:40,703 [Listener at 0.0.0.0/37628] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.rolledits.timeout(60) assuming SECONDS
Formatting using clusterid: testClusterID
2020-12-03 07:22:40,710 [Listener at 0.0.0.0/37628] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:22:40,711 [Listener at 0.0.0.0/37628] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:22:40,711 [Listener at 0.0.0.0/37628] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:22:40,711 [Listener at 0.0.0.0/37628] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:22:40,711 [Listener at 0.0.0.0/37628] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:22:40,712 [Listener at 0.0.0.0/37628] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:22:40,712 [Listener at 0.0.0.0/37628] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:22:40,712 [Listener at 0.0.0.0/37628] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns1
2020-12-03 07:22:40,712 [Listener at 0.0.0.0/37628] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: true
2020-12-03 07:22:40,713 [Listener at 0.0.0.0/37628] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:40,713 [Listener at 0.0.0.0/37628] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:22:40,714 [Listener at 0.0.0.0/37628] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:22:40,714 [Listener at 0.0.0.0/37628] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:22:40,715 [Listener at 0.0.0.0/37628] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:22:40
2020-12-03 07:22:40,715 [Listener at 0.0.0.0/37628] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:22:40,715 [Listener at 0.0.0.0/37628] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:40,715 [Listener at 0.0.0.0/37628] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:22:40,715 [Listener at 0.0.0.0/37628] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:22:40,728 [Listener at 0.0.0.0/37628] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:22:40,728 [Listener at 0.0.0.0/37628] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:22:40,729 [Listener at 0.0.0.0/37628] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:22:40,729 [Listener at 0.0.0.0/37628] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:22:40,729 [Listener at 0.0.0.0/37628] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:22:40,729 [Listener at 0.0.0.0/37628] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:22:40,730 [Listener at 0.0.0.0/37628] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:22:40,730 [Listener at 0.0.0.0/37628] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:22:40,730 [Listener at 0.0.0.0/37628] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:22:40,730 [Listener at 0.0.0.0/37628] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:22:40,730 [Listener at 0.0.0.0/37628] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:22:40,731 [Listener at 0.0.0.0/37628] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:22:40,731 [Listener at 0.0.0.0/37628] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:22:40,731 [Listener at 0.0.0.0/37628] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:22:40,731 [Listener at 0.0.0.0/37628] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:40,732 [Listener at 0.0.0.0/37628] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:22:40,732 [Listener at 0.0.0.0/37628] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:22:40,738 [Listener at 0.0.0.0/37628] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:22:40,739 [Listener at 0.0.0.0/37628] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:22:40,739 [Listener at 0.0.0.0/37628] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:22:40,739 [Listener at 0.0.0.0/37628] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:22:40,739 [Listener at 0.0.0.0/37628] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:22:40,739 [Listener at 0.0.0.0/37628] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:22:40,740 [Listener at 0.0.0.0/37628] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:22:40,740 [Listener at 0.0.0.0/37628] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:40,740 [Listener at 0.0.0.0/37628] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:22:40,740 [Listener at 0.0.0.0/37628] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:22:40,742 [Listener at 0.0.0.0/37628] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:22:40,742 [Listener at 0.0.0.0/37628] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:22:40,742 [Listener at 0.0.0.0/37628] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:22:40,743 [Listener at 0.0.0.0/37628] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:22:40,743 [Listener at 0.0.0.0/37628] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:22:40,743 [Listener at 0.0.0.0/37628] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:22:40,743 [Listener at 0.0.0.0/37628] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:40,743 [Listener at 0.0.0.0/37628] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:22:40,744 [Listener at 0.0.0.0/37628] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:22:40,747 [Listener at 0.0.0.0/37628] INFO  namenode.FSImage (FSImage.java:format(185)) - Allocated new BlockPoolId: BP-1235373120-172.17.0.3-1606980160747
2020-12-03 07:22:40,918 [Listener at 0.0.0.0/37628] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5 has been successfully formatted.
2020-12-03 07:22:41,067 [Listener at 0.0.0.0/37628] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6 has been successfully formatted.
2020-12-03 07:22:41,189 [Listener at 0.0.0.0/37628] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-2-through-3 has been successfully formatted.
2020-12-03 07:22:41,201 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:22:41,201 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:22:41,207 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:22:41,208 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:22:41,260 [Listener at 0.0.0.0/37628] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-12-03 07:22:41,263 [Listener at 0.0.0.0/37628] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:copyNameDirs(1264)) - Copying namedir from primary node dir file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5 to file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-7
2020-12-03 07:22:41,269 [Listener at 0.0.0.0/37628] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:copyNameDirs(1264)) - Copying namedir from primary node dir file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5 to file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-8
2020-12-03 07:22:41,274 [Listener at 0.0.0.0/37628] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:22:41,275 [Listener at 0.0.0.0/37628] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-12-03 07:22:41,276 [Listener at 0.0.0.0/37628] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://ns0
2020-12-03 07:22:41,276 [Listener at 0.0.0.0/37628] INFO  namenode.NameNode (NameNode.java:<init>(944)) - Clients should use ns1 to access this namenode/service.
2020-12-03 07:22:41,288 [Listener at 0.0.0.0/37628] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:22:41,290 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1a6f5124] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:41,291 [Listener at 0.0.0.0/37628] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:41,292 [Listener at 0.0.0.0/37628] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:22:41,295 [Listener at 0.0.0.0/37628] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:41,296 [Listener at 0.0.0.0/37628] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:22:41,296 [Listener at 0.0.0.0/37628] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:41,296 [Listener at 0.0.0.0/37628] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:41,298 [Listener at 0.0.0.0/37628] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:22:41,299 [Listener at 0.0.0.0/37628] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:22:41,299 [Listener at 0.0.0.0/37628] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 46268
2020-12-03 07:22:41,300 [Listener at 0.0.0.0/37628] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:41,305 [Listener at 0.0.0.0/37628] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@32f61a31{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:22:41,306 [Listener at 0.0.0.0/37628] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@669253b7{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:22:41,536 [Listener at 0.0.0.0/37628] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@581d969c{/,file:///tmp/jetty-localhost-46268-hdfs-_-any-1162345157519788069.dir/webapp/,AVAILABLE}{/hdfs}
2020-12-03 07:22:41,539 [Listener at 0.0.0.0/37628] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@22db8f4{HTTP/1.1,[http/1.1]}{localhost:46268}
2020-12-03 07:22:41,540 [Listener at 0.0.0.0/37628] INFO  server.Server (Server.java:doStart(419)) - Started @6701ms
2020-12-03 07:22:41,543 [Listener at 0.0.0.0/37628] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:22:41,544 [Listener at 0.0.0.0/37628] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:22:41,544 [Listener at 0.0.0.0/37628] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:22:41,545 [Listener at 0.0.0.0/37628] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:22:41,545 [Listener at 0.0.0.0/37628] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:22:41,545 [Listener at 0.0.0.0/37628] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:22:41,545 [Listener at 0.0.0.0/37628] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:22:41,546 [Listener at 0.0.0.0/37628] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns1
2020-12-03 07:22:41,546 [Listener at 0.0.0.0/37628] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: true
2020-12-03 07:22:41,547 [Listener at 0.0.0.0/37628] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:41,548 [Listener at 0.0.0.0/37628] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:22:41,548 [Listener at 0.0.0.0/37628] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:22:41,549 [Listener at 0.0.0.0/37628] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:22:41,549 [Listener at 0.0.0.0/37628] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:22:41
2020-12-03 07:22:41,552 [Listener at 0.0.0.0/37628] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:22:41,552 [Listener at 0.0.0.0/37628] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:41,561 [Listener at 0.0.0.0/37628] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:22:41,561 [Listener at 0.0.0.0/37628] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:22:41,578 [Listener at 0.0.0.0/37628] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:22:41,579 [Listener at 0.0.0.0/37628] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:22:41,579 [Listener at 0.0.0.0/37628] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:22:41,580 [Listener at 0.0.0.0/37628] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:22:41,580 [Listener at 0.0.0.0/37628] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:22:41,581 [Listener at 0.0.0.0/37628] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:22:41,581 [Listener at 0.0.0.0/37628] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:22:41,581 [Listener at 0.0.0.0/37628] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:22:41,581 [Listener at 0.0.0.0/37628] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:22:41,582 [Listener at 0.0.0.0/37628] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:22:41,582 [Listener at 0.0.0.0/37628] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:22:41,582 [Listener at 0.0.0.0/37628] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:22:41,582 [Listener at 0.0.0.0/37628] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:22:41,583 [Listener at 0.0.0.0/37628] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:22:41,583 [Listener at 0.0.0.0/37628] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:41,584 [Listener at 0.0.0.0/37628] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:22:41,584 [Listener at 0.0.0.0/37628] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:22:41,591 [Listener at 0.0.0.0/37628] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:22:41,591 [Listener at 0.0.0.0/37628] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:22:41,592 [Listener at 0.0.0.0/37628] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:22:41,592 [Listener at 0.0.0.0/37628] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:22:41,592 [Listener at 0.0.0.0/37628] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:22:41,592 [Listener at 0.0.0.0/37628] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:22:41,593 [Listener at 0.0.0.0/37628] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:22:41,593 [Listener at 0.0.0.0/37628] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:41,594 [Listener at 0.0.0.0/37628] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:22:41,594 [Listener at 0.0.0.0/37628] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:22:41,596 [Listener at 0.0.0.0/37628] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:22:41,596 [Listener at 0.0.0.0/37628] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:22:41,597 [Listener at 0.0.0.0/37628] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:22:41,597 [Listener at 0.0.0.0/37628] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:22:41,597 [Listener at 0.0.0.0/37628] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:22:41,597 [Listener at 0.0.0.0/37628] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:22:41,598 [Listener at 0.0.0.0/37628] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:41,598 [Listener at 0.0.0.0/37628] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:22:41,598 [Listener at 0.0.0.0/37628] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:22:41,647 [Listener at 0.0.0.0/37628] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/in_use.lock acquired by nodename 7615@1e0d9a01dc20
2020-12-03 07:22:41,690 [Listener at 0.0.0.0/37628] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6/in_use.lock acquired by nodename 7615@1e0d9a01dc20
2020-12-03 07:22:41,691 [Listener at 0.0.0.0/37628] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-2-through-3
2020-12-03 07:22:41,695 [Listener at 0.0.0.0/37628] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:22:41,695 [Listener at 0.0.0.0/37628] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:22:41,706 [Listener at 0.0.0.0/37628] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:22:41,717 [Listener at 0.0.0.0/37628] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:22:41,720 [Listener at 0.0.0.0/37628] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/current/fsimage_0000000000000000000
2020-12-03 07:22:41,720 [Listener at 0.0.0.0/37628] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2020-12-03 07:22:41,721 [Listener at 0.0.0.0/37628] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:22:41,721 [Listener at 0.0.0.0/37628] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 120 msecs
2020-12-03 07:22:41,722 [Listener at 0.0.0.0/37628] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to 0.0.0.0:0
2020-12-03 07:22:41,723 [Listener at 0.0.0.0/37628] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:41,725 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:41,733 [Listener at 0.0.0.0/41189] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:22:41,757 [Listener at 0.0.0.0/41189] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:22:41,761 [Listener at 0.0.0.0/41189] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:22:41,761 [Listener at 0.0.0.0/41189] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:22:41,761 [Listener at 0.0.0.0/41189] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:22:41,769 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:41,769 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:41,780 [Listener at 0.0.0.0/41189] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:41189
2020-12-03 07:22:41,780 [Listener at 0.0.0.0/41189] INFO  namenode.FSNamesystem (FSNamesystem.java:startStandbyServices(1391)) - Starting services required for standby state
2020-12-03 07:22:41,781 [Listener at 0.0.0.0/41189] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.log-roll.period(-1) assuming SECONDS
2020-12-03 07:22:41,781 [Listener at 0.0.0.0/41189] INFO  ha.EditLogTailer (EditLogTailer.java:<init>(208)) - Not going to trigger log rolls on active node because dfs.ha.log-roll.period is negative.
2020-12-03 07:22:41,782 [Listener at 0.0.0.0/41189] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.period.backoff-max(0) assuming SECONDS
2020-12-03 07:22:41,782 [Listener at 0.0.0.0/41189] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.rolledits.timeout(60) assuming SECONDS
2020-12-03 07:22:41,785 [Listener at 0.0.0.0/41189] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:22:41,786 [Listener at 0.0.0.0/41189] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-12-03 07:22:41,787 [Listener at 0.0.0.0/41189] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://ns0
2020-12-03 07:22:41,787 [Listener at 0.0.0.0/41189] INFO  namenode.NameNode (NameNode.java:<init>(944)) - Clients should use ns1 to access this namenode/service.
2020-12-03 07:22:41,800 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@28c0b664] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:41,800 [Listener at 0.0.0.0/41189] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:22:41,804 [Listener at 0.0.0.0/41189] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:41,807 [Listener at 0.0.0.0/41189] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:22:41,811 [Listener at 0.0.0.0/41189] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:41,812 [Listener at 0.0.0.0/41189] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:22:41,813 [Listener at 0.0.0.0/41189] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:41,813 [Listener at 0.0.0.0/41189] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:41,816 [Listener at 0.0.0.0/41189] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:22:41,816 [Listener at 0.0.0.0/41189] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:22:41,817 [Listener at 0.0.0.0/41189] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 43904
2020-12-03 07:22:41,817 [Listener at 0.0.0.0/41189] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:41,822 [Listener at 0.0.0.0/41189] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6d1310f6{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:22:41,823 [Listener at 0.0.0.0/41189] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@54e7391d{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:22:42,053 [Listener at 0.0.0.0/41189] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1dfd5f51{/,file:///tmp/jetty-localhost-43904-hdfs-_-any-4381865770287636392.dir/webapp/,AVAILABLE}{/hdfs}
2020-12-03 07:22:42,059 [Listener at 0.0.0.0/41189] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3c321bdb{HTTP/1.1,[http/1.1]}{localhost:43904}
2020-12-03 07:22:42,060 [Listener at 0.0.0.0/41189] INFO  server.Server (Server.java:doStart(419)) - Started @7222ms
2020-12-03 07:22:42,062 [Listener at 0.0.0.0/41189] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:22:42,063 [Listener at 0.0.0.0/41189] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:22:42,063 [Listener at 0.0.0.0/41189] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:22:42,063 [Listener at 0.0.0.0/41189] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:22:42,064 [Listener at 0.0.0.0/41189] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:22:42,064 [Listener at 0.0.0.0/41189] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:22:42,064 [Listener at 0.0.0.0/41189] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:22:42,064 [Listener at 0.0.0.0/41189] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns1
2020-12-03 07:22:42,065 [Listener at 0.0.0.0/41189] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: true
2020-12-03 07:22:42,065 [Listener at 0.0.0.0/41189] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:42,065 [Listener at 0.0.0.0/41189] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:22:42,066 [Listener at 0.0.0.0/41189] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:22:42,066 [Listener at 0.0.0.0/41189] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:22:42,067 [Listener at 0.0.0.0/41189] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:22:42
2020-12-03 07:22:42,067 [Listener at 0.0.0.0/41189] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:22:42,068 [Listener at 0.0.0.0/41189] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:42,068 [Listener at 0.0.0.0/41189] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:22:42,068 [Listener at 0.0.0.0/41189] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:22:42,083 [Listener at 0.0.0.0/41189] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:22:42,084 [Listener at 0.0.0.0/41189] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:22:42,084 [Listener at 0.0.0.0/41189] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:22:42,085 [Listener at 0.0.0.0/41189] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:22:42,085 [Listener at 0.0.0.0/41189] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:22:42,085 [Listener at 0.0.0.0/41189] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:22:42,085 [Listener at 0.0.0.0/41189] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:22:42,086 [Listener at 0.0.0.0/41189] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:22:42,086 [Listener at 0.0.0.0/41189] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:22:42,086 [Listener at 0.0.0.0/41189] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:22:42,086 [Listener at 0.0.0.0/41189] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:22:42,086 [Listener at 0.0.0.0/41189] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:22:42,086 [Listener at 0.0.0.0/41189] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:22:42,087 [Listener at 0.0.0.0/41189] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:22:42,087 [Listener at 0.0.0.0/41189] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:42,088 [Listener at 0.0.0.0/41189] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:22:42,088 [Listener at 0.0.0.0/41189] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:22:42,095 [Listener at 0.0.0.0/41189] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:22:42,095 [Listener at 0.0.0.0/41189] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:22:42,095 [Listener at 0.0.0.0/41189] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:22:42,095 [Listener at 0.0.0.0/41189] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:22:42,095 [Listener at 0.0.0.0/41189] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:22:42,095 [Listener at 0.0.0.0/41189] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:22:42,096 [Listener at 0.0.0.0/41189] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:22:42,096 [Listener at 0.0.0.0/41189] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:42,096 [Listener at 0.0.0.0/41189] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:22:42,096 [Listener at 0.0.0.0/41189] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:22:42,098 [Listener at 0.0.0.0/41189] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:22:42,098 [Listener at 0.0.0.0/41189] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:22:42,098 [Listener at 0.0.0.0/41189] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:22:42,099 [Listener at 0.0.0.0/41189] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:22:42,099 [Listener at 0.0.0.0/41189] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:22:42,099 [Listener at 0.0.0.0/41189] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:22:42,099 [Listener at 0.0.0.0/41189] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:42,099 [Listener at 0.0.0.0/41189] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:22:42,099 [Listener at 0.0.0.0/41189] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:22:42,141 [Listener at 0.0.0.0/41189] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-7/in_use.lock acquired by nodename 7615@1e0d9a01dc20
2020-12-03 07:22:42,166 [Listener at 0.0.0.0/41189] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-8/in_use.lock acquired by nodename 7615@1e0d9a01dc20
2020-12-03 07:22:42,167 [Listener at 0.0.0.0/41189] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-2-through-3
2020-12-03 07:22:42,170 [Listener at 0.0.0.0/41189] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:22:42,171 [Listener at 0.0.0.0/41189] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-7/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:22:42,175 [Listener at 0.0.0.0/41189] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:22:42,176 [Listener at 0.0.0.0/41189] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:22:42,176 [Listener at 0.0.0.0/41189] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-7/current/fsimage_0000000000000000000
2020-12-03 07:22:42,177 [Listener at 0.0.0.0/41189] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2020-12-03 07:22:42,177 [Listener at 0.0.0.0/41189] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:22:42,177 [Listener at 0.0.0.0/41189] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 77 msecs
2020-12-03 07:22:42,178 [Listener at 0.0.0.0/41189] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to 0.0.0.0:0
2020-12-03 07:22:42,179 [Listener at 0.0.0.0/41189] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:42,180 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:42,187 [Listener at 0.0.0.0/40615] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:22:42,466 [Listener at 0.0.0.0/40615] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:22:42,469 [Listener at 0.0.0.0/40615] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:22:42,469 [Listener at 0.0.0.0/40615] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:22:42,469 [Listener at 0.0.0.0/40615] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:22:42,480 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:42,481 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:42,485 [Listener at 0.0.0.0/40615] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:40615
2020-12-03 07:22:42,485 [Listener at 0.0.0.0/40615] INFO  namenode.FSNamesystem (FSNamesystem.java:startStandbyServices(1391)) - Starting services required for standby state
2020-12-03 07:22:42,486 [Listener at 0.0.0.0/40615] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.log-roll.period(-1) assuming SECONDS
2020-12-03 07:22:42,486 [Listener at 0.0.0.0/40615] INFO  ha.EditLogTailer (EditLogTailer.java:<init>(208)) - Not going to trigger log rolls on active node because dfs.ha.log-roll.period is negative.
2020-12-03 07:22:42,486 [Listener at 0.0.0.0/40615] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.period.backoff-max(0) assuming SECONDS
2020-12-03 07:22:42,486 [Listener at 0.0.0.0/40615] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.rolledits.timeout(60) assuming SECONDS
2020-12-03 07:22:42,513 [Listener at 0.0.0.0/40615] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-12-03 07:22:42,540 [Listener at 0.0.0.0/40615] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-12-03 07:22:42,558 [Listener at 0.0.0.0/40615] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-12-03 07:22:42,580 [Listener at 0.0.0.0/40615] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:22:42,594 [Listener at 0.0.0.0/40615] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:42,601 [Listener at 0.0.0.0/40615] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:22:42,606 [Listener at 0.0.0.0/40615] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:22:42,608 [Listener at 0.0.0.0/40615] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:42,613 [Listener at 0.0.0.0/40615] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:22:42,622 [Listener at 0.0.0.0/40615] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:37691
2020-12-03 07:22:42,624 [Listener at 0.0.0.0/40615] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:22:42,624 [Listener at 0.0.0.0/40615] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:22:42,662 [Listener at 0.0.0.0/40615] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:42,663 [Listener at 0.0.0.0/40615] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:22:42,675 [Listener at 0.0.0.0/40615] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:42,676 [Listener at 0.0.0.0/40615] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:22:42,676 [Listener at 0.0.0.0/40615] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:42,677 [Listener at 0.0.0.0/40615] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:42,682 [Listener at 0.0.0.0/40615] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 41575
2020-12-03 07:22:42,683 [Listener at 0.0.0.0/40615] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:42,686 [Listener at 0.0.0.0/40615] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3773862a{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:22:42,687 [Listener at 0.0.0.0/40615] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@589b028e{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:22:42,897 [Listener at 0.0.0.0/40615] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@350b3a17{/,file:///tmp/jetty-localhost-41575-datanode-_-any-5617993523977604811.dir/webapp/,AVAILABLE}{/datanode}
2020-12-03 07:22:42,898 [Listener at 0.0.0.0/40615] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@38600b{HTTP/1.1,[http/1.1]}{localhost:41575}
2020-12-03 07:22:42,899 [Listener at 0.0.0.0/40615] INFO  server.Server (Server.java:doStart(419)) - Started @8061ms
2020-12-03 07:22:43,697 [Listener at 0.0.0.0/40615] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:45489
2020-12-03 07:22:43,698 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@267bbe1a] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:43,700 [Listener at 0.0.0.0/40615] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:22:43,700 [Listener at 0.0.0.0/40615] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:22:43,720 [Listener at 0.0.0.0/40615] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:43,721 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:43,729 [Listener at localhost/40468] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:40468
2020-12-03 07:22:43,750 [Listener at localhost/40468] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns0,ns1
2020-12-03 07:22:43,752 [Listener at localhost/40468] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns0,ns1
2020-12-03 07:22:43,771 [Thread-156] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42246 starting to offer service
2020-12-03 07:22:43,771 [Thread-157] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37628 starting to offer service
2020-12-03 07:22:43,771 [Thread-159] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40615 starting to offer service
2020-12-03 07:22:43,771 [Thread-158] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:41189 starting to offer service
2020-12-03 07:22:43,784 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:43,784 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:43,801 [Listener at localhost/40468] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-12-03 07:22:43,804 [Listener at localhost/40468] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-12-03 07:22:43,805 [Listener at localhost/40468] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-12-03 07:22:43,807 [Listener at localhost/40468] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:22:43,807 [Listener at localhost/40468] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:43,808 [Listener at localhost/40468] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:22:43,808 [Listener at localhost/40468] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:22:43,808 [Listener at localhost/40468] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:43,809 [Listener at localhost/40468] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:22:43,810 [Listener at localhost/40468] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:46607
2020-12-03 07:22:43,810 [Listener at localhost/40468] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:22:43,810 [Listener at localhost/40468] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:22:43,815 [Listener at localhost/40468] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:43,822 [Listener at localhost/40468] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:22:43,827 [Listener at localhost/40468] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:43,828 [Listener at localhost/40468] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:22:43,828 [Listener at localhost/40468] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:43,828 [Listener at localhost/40468] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:43,829 [Listener at localhost/40468] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 35874
2020-12-03 07:22:43,829 [Listener at localhost/40468] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:43,834 [Listener at localhost/40468] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@72ba28ee{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:22:43,834 [Listener at localhost/40468] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4ebadd3d{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:22:44,095 [Listener at localhost/40468] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@57bd802b{/,file:///tmp/jetty-localhost-35874-datanode-_-any-3109847288784744923.dir/webapp/,AVAILABLE}{/datanode}
2020-12-03 07:22:44,100 [Listener at localhost/40468] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7dc64762{HTTP/1.1,[http/1.1]}{localhost:35874}
2020-12-03 07:22:44,101 [Listener at localhost/40468] INFO  server.Server (Server.java:doStart(419)) - Started @9263ms
2020-12-03 07:22:44,238 [Thread-158] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:44,240 [Listener at localhost/40468] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:36630
2020-12-03 07:22:44,241 [Listener at localhost/40468] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:22:44,241 [Listener at localhost/40468] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:22:44,242 [Listener at localhost/40468] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:44,243 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:44,244 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2c779e5] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:44,248 [Listener at localhost/35721] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:35721
2020-12-03 07:22:44,253 [Listener at localhost/35721] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns0,ns1
2020-12-03 07:22:44,254 [Listener at localhost/35721] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns0,ns1
2020-12-03 07:22:44,255 [Thread-185] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42246 starting to offer service
2020-12-03 07:22:44,255 [Thread-186] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37628 starting to offer service
2020-12-03 07:22:44,257 [Thread-187] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:41189 starting to offer service
2020-12-03 07:22:44,258 [Thread-188] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40615 starting to offer service
2020-12-03 07:22:44,259 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:44,259 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:44,261 [Listener at localhost/35721] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-12-03 07:22:44,263 [Listener at localhost/35721] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-12-03 07:22:44,263 [Listener at localhost/35721] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-12-03 07:22:44,266 [Listener at localhost/35721] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:22:44,267 [Listener at localhost/35721] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:44,267 [Listener at localhost/35721] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:22:44,269 [Listener at localhost/35721] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:22:44,269 [Listener at localhost/35721] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:44,270 [Listener at localhost/35721] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:22:44,271 [Listener at localhost/35721] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:32791
2020-12-03 07:22:44,271 [Listener at localhost/35721] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:22:44,271 [Listener at localhost/35721] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:22:44,282 [Listener at localhost/35721] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:44,283 [Listener at localhost/35721] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:22:44,284 [Thread-185] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:44,286 [Listener at localhost/35721] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:44,295 [Listener at localhost/35721] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:22:44,296 [Listener at localhost/35721] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:44,296 [Listener at localhost/35721] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:44,324 [Listener at localhost/35721] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 33153
2020-12-03 07:22:44,324 [Listener at localhost/35721] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:44,326 [Listener at localhost/35721] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2d84cb86{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:22:44,327 [Listener at localhost/35721] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@588ffeb{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:22:44,353 [Thread-158] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 7615@1e0d9a01dc20
2020-12-03 07:22:44,354 [Thread-158] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1 is not formatted for namespace 1596799538. Formatting...
2020-12-03 07:22:44,355 [Thread-158] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-40230fce-682c-44e3-ba88-45564f51101d for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1 
2020-12-03 07:22:44,391 [Thread-185] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 7615@1e0d9a01dc20
2020-12-03 07:22:44,392 [Thread-185] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3 is not formatted for namespace 324671252. Formatting...
2020-12-03 07:22:44,392 [Thread-185] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-74bf8983-5f9d-4008-9db0-e9461d0d0ffa for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3 
2020-12-03 07:22:44,600 [Listener at localhost/35721] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@264c5d07{/,file:///tmp/jetty-localhost-33153-datanode-_-any-1200020774352175208.dir/webapp/,AVAILABLE}{/datanode}
2020-12-03 07:22:44,601 [Listener at localhost/35721] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@847f3e7{HTTP/1.1,[http/1.1]}{localhost:33153}
2020-12-03 07:22:44,602 [Listener at localhost/35721] INFO  server.Server (Server.java:doStart(419)) - Started @9763ms
2020-12-03 07:22:44,609 [Thread-158] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 7615@1e0d9a01dc20
2020-12-03 07:22:44,609 [Thread-158] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2 is not formatted for namespace 1596799538. Formatting...
2020-12-03 07:22:44,612 [Thread-158] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-3c828317-de65-40e3-b326-d448a3a4057d for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2 
2020-12-03 07:22:44,637 [Listener at localhost/35721] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:46535
2020-12-03 07:22:44,638 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@19593091] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:44,638 [Listener at localhost/35721] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:22:44,638 [Listener at localhost/35721] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:22:44,639 [Listener at localhost/35721] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:44,640 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:44,645 [Listener at localhost/40600] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:40600
2020-12-03 07:22:44,671 [Thread-185] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 7615@1e0d9a01dc20
2020-12-03 07:22:44,672 [Thread-185] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4 is not formatted for namespace 324671252. Formatting...
2020-12-03 07:22:44,675 [Thread-185] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-babb1fcd-9d27-47f3-9171-b3180daa923a for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4 
2020-12-03 07:22:44,695 [Listener at localhost/40600] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns0,ns1
2020-12-03 07:22:44,697 [Listener at localhost/40600] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns0,ns1
2020-12-03 07:22:44,707 [Thread-210] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42246 starting to offer service
2020-12-03 07:22:44,708 [Thread-211] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37628 starting to offer service
2020-12-03 07:22:44,710 [Thread-212] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:41189 starting to offer service
2020-12-03 07:22:44,716 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:44,716 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:44,716 [Thread-213] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40615 starting to offer service
2020-12-03 07:22:44,745 [Listener at localhost/40600] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 3 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-12-03 07:22:44,747 [Listener at localhost/40600] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7
2020-12-03 07:22:44,777 [Listener at localhost/40600] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-12-03 07:22:44,778 [Thread-212] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:44,787 [Listener at localhost/40600] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:22:44,788 [Listener at localhost/40600] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:44,788 [Listener at localhost/40600] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:22:44,789 [Listener at localhost/40600] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:22:44,789 [Listener at localhost/40600] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:44,790 [Listener at localhost/40600] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:22:44,791 [Listener at localhost/40600] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:33452
2020-12-03 07:22:44,791 [Listener at localhost/40600] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:22:44,791 [Listener at localhost/40600] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:22:44,800 [Listener at localhost/40600] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:44,820 [Listener at localhost/40600] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:22:44,823 [Listener at localhost/40600] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:44,824 [Listener at localhost/40600] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:22:44,824 [Listener at localhost/40600] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:44,824 [Listener at localhost/40600] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:44,825 [Listener at localhost/40600] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 38717
2020-12-03 07:22:44,825 [Listener at localhost/40600] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:44,827 [Thread-158] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1235373120-172.17.0.3-1606980160747
2020-12-03 07:22:44,827 [Thread-158] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-1235373120-172.17.0.3-1606980160747
2020-12-03 07:22:44,828 [Thread-158] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1 and block pool id BP-1235373120-172.17.0.3-1606980160747 is not formatted. Formatting ...
2020-12-03 07:22:44,828 [Thread-158] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1235373120-172.17.0.3-1606980160747 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-1235373120-172.17.0.3-1606980160747/current
2020-12-03 07:22:44,828 [Thread-212] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 7615@1e0d9a01dc20
2020-12-03 07:22:44,829 [Thread-212] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5 is not formatted for namespace 1596799538. Formatting...
2020-12-03 07:22:44,829 [Listener at localhost/40600] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@37a64f9d{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:22:44,830 [Listener at localhost/40600] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@f9b5552{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:22:44,831 [Thread-212] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-bd3e7214-c1b2-4043-86e7-9863535e580f for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5 
2020-12-03 07:22:44,843 [Thread-185] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1217207052-172.17.0.3-1606980156864
2020-12-03 07:22:44,844 [Thread-185] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-1217207052-172.17.0.3-1606980156864
2020-12-03 07:22:44,844 [Thread-185] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3 and block pool id BP-1217207052-172.17.0.3-1606980156864 is not formatted. Formatting ...
2020-12-03 07:22:44,845 [Thread-185] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1217207052-172.17.0.3-1606980156864 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-1217207052-172.17.0.3-1606980156864/current
2020-12-03 07:22:45,039 [Listener at localhost/40600] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@30cecdca{/,file:///tmp/jetty-localhost-38717-datanode-_-any-519677113199614452.dir/webapp/,AVAILABLE}{/datanode}
2020-12-03 07:22:45,039 [Listener at localhost/40600] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6edc4161{HTTP/1.1,[http/1.1]}{localhost:38717}
2020-12-03 07:22:45,040 [Listener at localhost/40600] INFO  server.Server (Server.java:doStart(419)) - Started @10201ms
2020-12-03 07:22:45,113 [Thread-212] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 7615@1e0d9a01dc20
2020-12-03 07:22:45,114 [Thread-212] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6 is not formatted for namespace 1596799538. Formatting...
2020-12-03 07:22:45,115 [Thread-212] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-e877e98a-df8b-4ebc-98c4-d460f14efb90 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6 
2020-12-03 07:22:45,149 [Thread-185] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1217207052-172.17.0.3-1606980156864
2020-12-03 07:22:45,150 [Thread-158] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1235373120-172.17.0.3-1606980160747
2020-12-03 07:22:45,150 [Thread-185] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-1217207052-172.17.0.3-1606980156864
2020-12-03 07:22:45,150 [Thread-185] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4 and block pool id BP-1217207052-172.17.0.3-1606980156864 is not formatted. Formatting ...
2020-12-03 07:22:45,150 [Thread-185] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1217207052-172.17.0.3-1606980156864 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-1217207052-172.17.0.3-1606980156864/current
2020-12-03 07:22:45,150 [Thread-158] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-1235373120-172.17.0.3-1606980160747
2020-12-03 07:22:45,151 [Thread-158] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2 and block pool id BP-1235373120-172.17.0.3-1606980160747 is not formatted. Formatting ...
2020-12-03 07:22:45,151 [Thread-158] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1235373120-172.17.0.3-1606980160747 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-1235373120-172.17.0.3-1606980160747/current
2020-12-03 07:22:45,157 [Listener at localhost/40600] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:40179
2020-12-03 07:22:45,158 [Listener at localhost/40600] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:22:45,158 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5226e402] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:45,158 [Listener at localhost/40600] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:22:45,159 [Listener at localhost/40600] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:45,160 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:45,169 [Listener at localhost/37550] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:37550
2020-12-03 07:22:45,179 [Listener at localhost/37550] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns0,ns1
2020-12-03 07:22:45,180 [Listener at localhost/37550] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns0,ns1
2020-12-03 07:22:45,181 [Thread-235] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42246 starting to offer service
2020-12-03 07:22:45,181 [Thread-236] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37628 starting to offer service
2020-12-03 07:22:45,184 [Thread-237] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:41189 starting to offer service
2020-12-03 07:22:45,184 [Thread-238] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40615 starting to offer service
2020-12-03 07:22:45,191 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:45,191 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:45,220 [Thread-237] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:45,294 [Thread-237] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/in_use.lock acquired by nodename 7615@1e0d9a01dc20
2020-12-03 07:22:45,294 [Thread-237] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7 is not formatted for namespace 1596799538. Formatting...
2020-12-03 07:22:45,295 [Thread-237] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-290a7f2a-32af-42b2-89c3-1b2c2b279b33 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7 
2020-12-03 07:22:45,325 [Thread-158] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1596799538;bpid=BP-1235373120-172.17.0.3-1606980160747;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1596799538;c=1606980160747;bpid=BP-1235373120-172.17.0.3-1606980160747;dnuuid=null
2020-12-03 07:22:45,327 [Thread-188] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:45,331 [Thread-188] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3 has already been used.
2020-12-03 07:22:45,331 [Thread-188] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4 has already been used.
2020-12-03 07:22:45,325 [Thread-185] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=324671252;bpid=BP-1217207052-172.17.0.3-1606980156864;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=324671252;c=1606980156864;bpid=BP-1217207052-172.17.0.3-1606980156864;dnuuid=null
2020-12-03 07:22:45,332 [Thread-157] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:45,333 [Thread-157] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1 has already been used.
2020-12-03 07:22:45,333 [Thread-157] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2 has already been used.
2020-12-03 07:22:45,352 [Thread-188] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1235373120-172.17.0.3-1606980160747
2020-12-03 07:22:45,352 [Thread-212] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1235373120-172.17.0.3-1606980160747
2020-12-03 07:22:45,352 [Thread-188] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-1235373120-172.17.0.3-1606980160747
2020-12-03 07:22:45,353 [Thread-212] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-1235373120-172.17.0.3-1606980160747
2020-12-03 07:22:45,353 [Thread-212] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5 and block pool id BP-1235373120-172.17.0.3-1606980160747 is not formatted. Formatting ...
2020-12-03 07:22:45,353 [Thread-212] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1235373120-172.17.0.3-1606980160747 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-1235373120-172.17.0.3-1606980160747/current
2020-12-03 07:22:45,353 [Thread-188] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3 and block pool id BP-1235373120-172.17.0.3-1606980160747 is not formatted. Formatting ...
2020-12-03 07:22:45,355 [Thread-188] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1235373120-172.17.0.3-1606980160747 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-1235373120-172.17.0.3-1606980160747/current
2020-12-03 07:22:45,356 [Thread-157] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1217207052-172.17.0.3-1606980156864
2020-12-03 07:22:45,356 [Thread-157] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-1217207052-172.17.0.3-1606980156864
2020-12-03 07:22:45,357 [Thread-157] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1 and block pool id BP-1217207052-172.17.0.3-1606980156864 is not formatted. Formatting ...
2020-12-03 07:22:45,357 [Thread-157] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1217207052-172.17.0.3-1606980156864 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-1217207052-172.17.0.3-1606980156864/current
2020-12-03 07:22:45,613 [Thread-188] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1235373120-172.17.0.3-1606980160747
2020-12-03 07:22:45,613 [Thread-188] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-1235373120-172.17.0.3-1606980160747
2020-12-03 07:22:45,614 [Thread-188] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4 and block pool id BP-1235373120-172.17.0.3-1606980160747 is not formatted. Formatting ...
2020-12-03 07:22:45,614 [Thread-188] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1235373120-172.17.0.3-1606980160747 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-1235373120-172.17.0.3-1606980160747/current
2020-12-03 07:22:45,618 [Thread-237] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/in_use.lock acquired by nodename 7615@1e0d9a01dc20
2020-12-03 07:22:45,618 [Thread-237] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8 is not formatted for namespace 1596799538. Formatting...
2020-12-03 07:22:45,621 [Thread-237] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-e7b706cd-4e9c-48c6-b202-c15d8d57696f for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8 
2020-12-03 07:22:45,625 [Thread-157] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1217207052-172.17.0.3-1606980156864
2020-12-03 07:22:45,626 [Thread-157] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-1217207052-172.17.0.3-1606980156864
2020-12-03 07:22:45,626 [Thread-157] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2 and block pool id BP-1217207052-172.17.0.3-1606980156864 is not formatted. Formatting ...
2020-12-03 07:22:45,626 [Thread-157] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1217207052-172.17.0.3-1606980156864 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-1217207052-172.17.0.3-1606980156864/current
2020-12-03 07:22:45,632 [Thread-212] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1235373120-172.17.0.3-1606980160747
2020-12-03 07:22:45,633 [Thread-212] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-1235373120-172.17.0.3-1606980160747
2020-12-03 07:22:45,633 [Thread-212] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6 and block pool id BP-1235373120-172.17.0.3-1606980160747 is not formatted. Formatting ...
2020-12-03 07:22:45,633 [Thread-212] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1235373120-172.17.0.3-1606980160747 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-1235373120-172.17.0.3-1606980160747/current
2020-12-03 07:22:45,777 [Thread-188] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1596799538;bpid=BP-1235373120-172.17.0.3-1606980160747;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1596799538;c=1606980160747;bpid=BP-1235373120-172.17.0.3-1606980160747;dnuuid=null
2020-12-03 07:22:45,818 [Thread-157] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=324671252;bpid=BP-1217207052-172.17.0.3-1606980156864;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=324671252;c=1606980156864;bpid=BP-1217207052-172.17.0.3-1606980156864;dnuuid=null
2020-12-03 07:22:45,827 [Thread-212] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1596799538;bpid=BP-1235373120-172.17.0.3-1606980160747;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1596799538;c=1606980160747;bpid=BP-1235373120-172.17.0.3-1606980160747;dnuuid=null
2020-12-03 07:22:45,828 [Thread-211] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:45,831 [Thread-211] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5 has already been used.
2020-12-03 07:22:45,831 [Thread-211] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6 has already been used.
2020-12-03 07:22:45,835 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1235373120-172.17.0.3-1606980160747
2020-12-03 07:22:45,835 [Thread-237] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-1235373120-172.17.0.3-1606980160747
2020-12-03 07:22:45,836 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7 and block pool id BP-1235373120-172.17.0.3-1606980160747 is not formatted. Formatting ...
2020-12-03 07:22:45,836 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1235373120-172.17.0.3-1606980160747 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-1235373120-172.17.0.3-1606980160747/current
2020-12-03 07:22:45,843 [Thread-211] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1217207052-172.17.0.3-1606980156864
2020-12-03 07:22:45,843 [Thread-211] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-1217207052-172.17.0.3-1606980156864
2020-12-03 07:22:45,843 [Thread-211] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5 and block pool id BP-1217207052-172.17.0.3-1606980156864 is not formatted. Formatting ...
2020-12-03 07:22:45,843 [Thread-211] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1217207052-172.17.0.3-1606980156864 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-1217207052-172.17.0.3-1606980156864/current
2020-12-03 07:22:45,863 [IPC Server handler 7 on default port 42246] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:45,872 [Listener at localhost/37550] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:45,872 [Listener at localhost/37550] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:45,976 [IPC Server handler 4 on default port 42246] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:45,978 [Listener at localhost/37550] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:45,978 [Listener at localhost/37550] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:45,993 [Thread-185] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID da8c2a33-61a0-489f-ae14-f61765804689
2020-12-03 07:22:46,028 [Thread-157] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID cf6dffe3-142c-4551-9b92-aa40255ddbb7
2020-12-03 07:22:46,063 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1235373120-172.17.0.3-1606980160747
2020-12-03 07:22:46,063 [Thread-237] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-1235373120-172.17.0.3-1606980160747
2020-12-03 07:22:46,064 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8 and block pool id BP-1235373120-172.17.0.3-1606980160747 is not formatted. Formatting ...
2020-12-03 07:22:46,064 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1235373120-172.17.0.3-1606980160747 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-1235373120-172.17.0.3-1606980160747/current
2020-12-03 07:22:46,068 [Thread-211] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1217207052-172.17.0.3-1606980156864
2020-12-03 07:22:46,069 [Thread-211] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-1217207052-172.17.0.3-1606980156864
2020-12-03 07:22:46,069 [Thread-211] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6 and block pool id BP-1217207052-172.17.0.3-1606980156864 is not formatted. Formatting ...
2020-12-03 07:22:46,069 [Thread-211] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1217207052-172.17.0.3-1606980156864 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-1217207052-172.17.0.3-1606980156864/current
2020-12-03 07:22:46,082 [IPC Server handler 6 on default port 42246] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:46,083 [Listener at localhost/37550] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:46,083 [Listener at localhost/37550] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:46,176 [Thread-157] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-40230fce-682c-44e3-ba88-45564f51101d
2020-12-03 07:22:46,177 [Thread-157] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, StorageType: DISK
2020-12-03 07:22:46,176 [Thread-185] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-74bf8983-5f9d-4008-9db0-e9461d0d0ffa
2020-12-03 07:22:46,178 [Thread-185] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, StorageType: DISK
2020-12-03 07:22:46,180 [Thread-157] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-3c828317-de65-40e3-b326-d448a3a4057d
2020-12-03 07:22:46,180 [Thread-157] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, StorageType: DISK
2020-12-03 07:22:46,182 [Thread-185] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-babb1fcd-9d27-47f3-9171-b3180daa923a
2020-12-03 07:22:46,182 [Thread-185] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, StorageType: DISK
2020-12-03 07:22:46,195 [IPC Server handler 9 on default port 42246] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:46,196 [Listener at localhost/37550] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:46,196 [Listener at localhost/37550] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:46,198 [Thread-157] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:22:46,198 [Thread-185] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:22:46,209 [Thread-185] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-12-03 07:22:46,207 [Thread-158] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-12-03 07:22:46,207 [Thread-157] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-12-03 07:22:46,213 [Thread-188] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1235373120-172.17.0.3-1606980160747
2020-12-03 07:22:46,215 [Thread-256] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1235373120-172.17.0.3-1606980160747 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3...
2020-12-03 07:22:46,215 [Thread-257] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1235373120-172.17.0.3-1606980160747 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4...
2020-12-03 07:22:46,224 [Thread-158] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-12-03 07:22:46,226 [Thread-157] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-12-03 07:22:46,224 [Thread-185] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-12-03 07:22:46,227 [Thread-237] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1596799538;bpid=BP-1235373120-172.17.0.3-1606980160747;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1596799538;c=1606980160747;bpid=BP-1235373120-172.17.0.3-1606980160747;dnuuid=null
2020-12-03 07:22:46,227 [Thread-236] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:46,227 [Thread-236] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7 has already been used.
2020-12-03 07:22:46,227 [Thread-236] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8 has already been used.
2020-12-03 07:22:46,229 [Thread-211] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=324671252;bpid=BP-1217207052-172.17.0.3-1606980156864;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=324671252;c=1606980156864;bpid=BP-1217207052-172.17.0.3-1606980156864;dnuuid=null
2020-12-03 07:22:46,230 [Thread-158] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-12-03 07:22:46,230 [Thread-185] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-12-03 07:22:46,230 [Thread-158] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-12-03 07:22:46,230 [Thread-185] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-12-03 07:22:46,230 [Thread-158] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1235373120-172.17.0.3-1606980160747
2020-12-03 07:22:46,230 [Thread-185] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1217207052-172.17.0.3-1606980156864
2020-12-03 07:22:46,232 [Thread-258] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1235373120-172.17.0.3-1606980160747 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1...
2020-12-03 07:22:46,232 [Thread-157] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-12-03 07:22:46,233 [Thread-157] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1217207052-172.17.0.3-1606980156864
2020-12-03 07:22:46,238 [Thread-259] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1235373120-172.17.0.3-1606980160747 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2...
2020-12-03 07:22:46,249 [Thread-236] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1217207052-172.17.0.3-1606980156864
2020-12-03 07:22:46,271 [Thread-236] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-1217207052-172.17.0.3-1606980156864
2020-12-03 07:22:46,302 [Thread-236] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7 and block pool id BP-1217207052-172.17.0.3-1606980156864 is not formatted. Formatting ...
2020-12-03 07:22:46,302 [Thread-236] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1217207052-172.17.0.3-1606980156864 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-1217207052-172.17.0.3-1606980156864/current
2020-12-03 07:22:46,328 [IPC Server handler 2 on default port 42246] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:46,330 [Listener at localhost/37550] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:46,330 [Listener at localhost/37550] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:46,336 [Thread-257] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1235373120-172.17.0.3-1606980160747 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4: 121ms
2020-12-03 07:22:46,341 [Thread-258] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1235373120-172.17.0.3-1606980160747 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1: 109ms
2020-12-03 07:22:46,341 [Thread-256] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1235373120-172.17.0.3-1606980160747 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3: 127ms
2020-12-03 07:22:46,342 [Thread-188] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1235373120-172.17.0.3-1606980160747: 128ms
2020-12-03 07:22:46,342 [Thread-259] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1235373120-172.17.0.3-1606980160747 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2: 104ms
2020-12-03 07:22:46,342 [Thread-158] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1235373120-172.17.0.3-1606980160747: 110ms
2020-12-03 07:22:46,344 [Thread-265] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1235373120-172.17.0.3-1606980160747 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3...
2020-12-03 07:22:46,344 [Thread-265] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-1235373120-172.17.0.3-1606980160747/current/replicas doesn't exist 
2020-12-03 07:22:46,347 [Thread-266] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1235373120-172.17.0.3-1606980160747 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4...
2020-12-03 07:22:46,347 [Thread-264] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1235373120-172.17.0.3-1606980160747 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1...
2020-12-03 07:22:46,351 [Thread-268] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1217207052-172.17.0.3-1606980156864 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1...
2020-12-03 07:22:46,353 [Thread-267] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1217207052-172.17.0.3-1606980156864 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3...
2020-12-03 07:22:46,348 [Thread-264] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-1235373120-172.17.0.3-1606980160747/current/replicas doesn't exist 
2020-12-03 07:22:46,347 [Thread-266] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-1235373120-172.17.0.3-1606980160747/current/replicas doesn't exist 
2020-12-03 07:22:46,353 [Thread-271] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1217207052-172.17.0.3-1606980156864 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4...
2020-12-03 07:22:46,360 [Thread-265] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1235373120-172.17.0.3-1606980160747 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3: 15ms
2020-12-03 07:22:46,363 [Thread-264] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1235373120-172.17.0.3-1606980160747 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1: 16ms
2020-12-03 07:22:46,364 [Thread-270] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1217207052-172.17.0.3-1606980156864 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2...
2020-12-03 07:22:46,368 [Thread-269] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1235373120-172.17.0.3-1606980160747 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2...
2020-12-03 07:22:46,368 [Thread-266] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1235373120-172.17.0.3-1606980160747 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4: 20ms
2020-12-03 07:22:46,369 [Thread-269] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-1235373120-172.17.0.3-1606980160747/current/replicas doesn't exist 
2020-12-03 07:22:46,369 [Thread-188] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1235373120-172.17.0.3-1606980160747: 26ms
2020-12-03 07:22:46,369 [Thread-269] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1235373120-172.17.0.3-1606980160747 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2: 1ms
2020-12-03 07:22:46,371 [Thread-158] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1235373120-172.17.0.3-1606980160747: 27ms
2020-12-03 07:22:46,381 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1235373120-172.17.0.3-1606980160747 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-12-03 07:22:46,382 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, DS-3c828317-de65-40e3-b326-d448a3a4057d): finished scanning block pool BP-1235373120-172.17.0.3-1606980160747
2020-12-03 07:22:46,381 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1235373120-172.17.0.3-1606980160747 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-12-03 07:22:46,381 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1235373120-172.17.0.3-1606980160747 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-12-03 07:22:46,381 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1235373120-172.17.0.3-1606980160747 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-12-03 07:22:46,389 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, DS-40230fce-682c-44e3-ba88-45564f51101d): finished scanning block pool BP-1235373120-172.17.0.3-1606980160747
2020-12-03 07:22:46,389 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, DS-74bf8983-5f9d-4008-9db0-e9461d0d0ffa): finished scanning block pool BP-1235373120-172.17.0.3-1606980160747
2020-12-03 07:22:46,392 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, DS-babb1fcd-9d27-47f3-9171-b3180daa923a): finished scanning block pool BP-1235373120-172.17.0.3-1606980160747
2020-12-03 07:22:46,406 [Thread-268] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1217207052-172.17.0.3-1606980156864 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1: 53ms
2020-12-03 07:22:46,410 [Thread-270] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1217207052-172.17.0.3-1606980156864 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2: 42ms
2020-12-03 07:22:46,410 [Thread-157] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1217207052-172.17.0.3-1606980156864: 62ms
2020-12-03 07:22:46,411 [Thread-281] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1217207052-172.17.0.3-1606980156864 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2...
2020-12-03 07:22:46,411 [Thread-280] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1217207052-172.17.0.3-1606980156864 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1...
2020-12-03 07:22:46,411 [Thread-281] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-1217207052-172.17.0.3-1606980156864/current/replicas doesn't exist 
2020-12-03 07:22:46,411 [Thread-280] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-1217207052-172.17.0.3-1606980156864/current/replicas doesn't exist 
2020-12-03 07:22:46,412 [Thread-280] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1217207052-172.17.0.3-1606980156864 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1: 0ms
2020-12-03 07:22:46,412 [Thread-281] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1217207052-172.17.0.3-1606980156864 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2: 1ms
2020-12-03 07:22:46,412 [Thread-157] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1217207052-172.17.0.3-1606980156864: 2ms
2020-12-03 07:22:46,415 [Thread-271] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1217207052-172.17.0.3-1606980156864 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4: 60ms
2020-12-03 07:22:46,415 [Thread-267] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1217207052-172.17.0.3-1606980156864 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3: 62ms
2020-12-03 07:22:46,420 [Thread-185] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1217207052-172.17.0.3-1606980156864: 72ms
2020-12-03 07:22:46,421 [Thread-282] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1217207052-172.17.0.3-1606980156864 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3...
2020-12-03 07:22:46,421 [Thread-283] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1217207052-172.17.0.3-1606980156864 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4...
2020-12-03 07:22:46,421 [Thread-282] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-1217207052-172.17.0.3-1606980156864/current/replicas doesn't exist 
2020-12-03 07:22:46,421 [Thread-283] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-1217207052-172.17.0.3-1606980156864/current/replicas doesn't exist 
2020-12-03 07:22:46,422 [Thread-283] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1217207052-172.17.0.3-1606980156864 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4: 1ms
2020-12-03 07:22:46,423 [Thread-282] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1217207052-172.17.0.3-1606980156864 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3: 2ms
2020-12-03 07:22:46,423 [Thread-185] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1217207052-172.17.0.3-1606980156864: 2ms
2020-12-03 07:22:46,428 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1217207052-172.17.0.3-1606980156864 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-12-03 07:22:46,428 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, DS-babb1fcd-9d27-47f3-9171-b3180daa923a): finished scanning block pool BP-1217207052-172.17.0.3-1606980156864
2020-12-03 07:22:46,429 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1217207052-172.17.0.3-1606980156864 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-12-03 07:22:46,429 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, DS-40230fce-682c-44e3-ba88-45564f51101d): finished scanning block pool BP-1217207052-172.17.0.3-1606980156864
2020-12-03 07:22:46,429 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, DS-babb1fcd-9d27-47f3-9171-b3180daa923a): no suitable block pools found to scan.  Waiting 1814399952 ms.
2020-12-03 07:22:46,430 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1217207052-172.17.0.3-1606980156864 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-12-03 07:22:46,430 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, DS-40230fce-682c-44e3-ba88-45564f51101d): no suitable block pools found to scan.  Waiting 1814399951 ms.
2020-12-03 07:22:46,430 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, DS-74bf8983-5f9d-4008-9db0-e9461d0d0ffa): finished scanning block pool BP-1217207052-172.17.0.3-1606980156864
2020-12-03 07:22:46,430 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1217207052-172.17.0.3-1606980156864 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-12-03 07:22:46,430 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, DS-3c828317-de65-40e3-b326-d448a3a4057d): finished scanning block pool BP-1217207052-172.17.0.3-1606980156864
2020-12-03 07:22:46,430 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, DS-74bf8983-5f9d-4008-9db0-e9461d0d0ffa): no suitable block pools found to scan.  Waiting 1814399950 ms.
2020-12-03 07:22:46,431 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, DS-3c828317-de65-40e3-b326-d448a3a4057d): no suitable block pools found to scan.  Waiting 1814399949 ms.
2020-12-03 07:22:46,433 [IPC Server handler 5 on default port 42246] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:46,434 [Thread-158] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 1:08 PM with interval of 21600000ms
2020-12-03 07:22:46,435 [Listener at localhost/37550] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:46,435 [Listener at localhost/37550] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:46,435 [Thread-188] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:30 AM with interval of 21600000ms
2020-12-03 07:22:46,446 [BP-1217207052-172.17.0.3-1606980156864 heartbeating to localhost/127.0.0.1:42246] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1217207052-172.17.0.3-1606980156864 (Datanode Uuid da8c2a33-61a0-489f-ae14-f61765804689) service to localhost/127.0.0.1:42246 beginning handshake with NN
2020-12-03 07:22:46,447 [BP-1217207052-172.17.0.3-1606980156864 heartbeating to localhost/127.0.0.1:37628] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1217207052-172.17.0.3-1606980156864 (Datanode Uuid da8c2a33-61a0-489f-ae14-f61765804689) service to localhost/127.0.0.1:37628 beginning handshake with NN
2020-12-03 07:22:46,449 [BP-1217207052-172.17.0.3-1606980156864 heartbeating to localhost/127.0.0.1:42246] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1217207052-172.17.0.3-1606980156864 (Datanode Uuid cf6dffe3-142c-4551-9b92-aa40255ddbb7) service to localhost/127.0.0.1:42246 beginning handshake with NN
2020-12-03 07:22:46,449 [BP-1235373120-172.17.0.3-1606980160747 heartbeating to localhost/127.0.0.1:40615] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1235373120-172.17.0.3-1606980160747 (Datanode Uuid cf6dffe3-142c-4551-9b92-aa40255ddbb7) service to localhost/127.0.0.1:40615 beginning handshake with NN
2020-12-03 07:22:46,449 [BP-1235373120-172.17.0.3-1606980160747 heartbeating to localhost/127.0.0.1:40615] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1235373120-172.17.0.3-1606980160747 (Datanode Uuid da8c2a33-61a0-489f-ae14-f61765804689) service to localhost/127.0.0.1:40615 beginning handshake with NN
2020-12-03 07:22:46,449 [BP-1235373120-172.17.0.3-1606980160747 heartbeating to localhost/127.0.0.1:41189] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1235373120-172.17.0.3-1606980160747 (Datanode Uuid cf6dffe3-142c-4551-9b92-aa40255ddbb7) service to localhost/127.0.0.1:41189 beginning handshake with NN
2020-12-03 07:22:46,449 [BP-1217207052-172.17.0.3-1606980156864 heartbeating to localhost/127.0.0.1:37628] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1217207052-172.17.0.3-1606980156864 (Datanode Uuid cf6dffe3-142c-4551-9b92-aa40255ddbb7) service to localhost/127.0.0.1:37628 beginning handshake with NN
2020-12-03 07:22:46,449 [BP-1235373120-172.17.0.3-1606980160747 heartbeating to localhost/127.0.0.1:41189] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1235373120-172.17.0.3-1606980160747 (Datanode Uuid da8c2a33-61a0-489f-ae14-f61765804689) service to localhost/127.0.0.1:41189 beginning handshake with NN
2020-12-03 07:22:46,464 [Thread-212] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID f47a982f-3e85-4226-b9b0-c434f3f5cab7
2020-12-03 07:22:46,470 [Thread-212] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-bd3e7214-c1b2-4043-86e7-9863535e580f
2020-12-03 07:22:46,470 [Thread-212] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, StorageType: DISK
2020-12-03 07:22:46,472 [IPC Server handler 7 on default port 40615] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:37691, datanodeUuid=cf6dffe3-142c-4551-9b92-aa40255ddbb7, infoPort=45489, infoSecurePort=0, ipcPort=40468, storageInfo=lv=-57;cid=testClusterID;nsid=1596799538;c=1606980160747) storage cf6dffe3-142c-4551-9b92-aa40255ddbb7
2020-12-03 07:22:46,472 [IPC Server handler 5 on default port 41189] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:46607, datanodeUuid=da8c2a33-61a0-489f-ae14-f61765804689, infoPort=36630, infoSecurePort=0, ipcPort=35721, storageInfo=lv=-57;cid=testClusterID;nsid=1596799538;c=1606980160747) storage da8c2a33-61a0-489f-ae14-f61765804689
2020-12-03 07:22:46,479 [IPC Server handler 7 on default port 40615] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:37691
2020-12-03 07:22:46,484 [IPC Server handler 7 on default port 40615] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN cf6dffe3-142c-4551-9b92-aa40255ddbb7 (127.0.0.1:37691).
2020-12-03 07:22:46,482 [IPC Server handler 1 on default port 37628] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:37691, datanodeUuid=cf6dffe3-142c-4551-9b92-aa40255ddbb7, infoPort=45489, infoSecurePort=0, ipcPort=40468, storageInfo=lv=-57;cid=testClusterID;nsid=324671252;c=1606980156864) storage cf6dffe3-142c-4551-9b92-aa40255ddbb7
2020-12-03 07:22:46,481 [IPC Server handler 5 on default port 41189] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:46607
2020-12-03 07:22:46,485 [IPC Server handler 8 on default port 42246] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:46607, datanodeUuid=da8c2a33-61a0-489f-ae14-f61765804689, infoPort=36630, infoSecurePort=0, ipcPort=35721, storageInfo=lv=-57;cid=testClusterID;nsid=324671252;c=1606980156864) storage da8c2a33-61a0-489f-ae14-f61765804689
2020-12-03 07:22:46,485 [IPC Server handler 5 on default port 41189] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN da8c2a33-61a0-489f-ae14-f61765804689 (127.0.0.1:46607).
2020-12-03 07:22:46,486 [IPC Server handler 1 on default port 37628] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:37691
2020-12-03 07:22:46,486 [IPC Server handler 1 on default port 37628] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN cf6dffe3-142c-4551-9b92-aa40255ddbb7 (127.0.0.1:37691).
2020-12-03 07:22:46,492 [IPC Server handler 8 on default port 42246] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:46607
2020-12-03 07:22:46,492 [IPC Server handler 8 on default port 42246] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN da8c2a33-61a0-489f-ae14-f61765804689 (127.0.0.1:46607).
2020-12-03 07:22:46,499 [Thread-212] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-e877e98a-df8b-4ebc-98c4-d460f14efb90
2020-12-03 07:22:46,499 [Thread-212] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, StorageType: DISK
2020-12-03 07:22:46,500 [Thread-212] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:22:46,500 [IPC Server handler 8 on default port 41189] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:37691, datanodeUuid=cf6dffe3-142c-4551-9b92-aa40255ddbb7, infoPort=45489, infoSecurePort=0, ipcPort=40468, storageInfo=lv=-57;cid=testClusterID;nsid=1596799538;c=1606980160747) storage cf6dffe3-142c-4551-9b92-aa40255ddbb7
2020-12-03 07:22:46,501 [BP-1217207052-172.17.0.3-1606980156864 heartbeating to localhost/127.0.0.1:42246] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1217207052-172.17.0.3-1606980156864 (Datanode Uuid da8c2a33-61a0-489f-ae14-f61765804689) service to localhost/127.0.0.1:42246 successfully registered with NN
2020-12-03 07:22:46,501 [BP-1235373120-172.17.0.3-1606980160747 heartbeating to localhost/127.0.0.1:41189] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1235373120-172.17.0.3-1606980160747 (Datanode Uuid da8c2a33-61a0-489f-ae14-f61765804689) service to localhost/127.0.0.1:41189 successfully registered with NN
2020-12-03 07:22:46,501 [BP-1217207052-172.17.0.3-1606980156864 heartbeating to localhost/127.0.0.1:42246] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:42246 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:22:46,501 [BP-1235373120-172.17.0.3-1606980160747 heartbeating to localhost/127.0.0.1:41189] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:41189 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:22:46,501 [Thread-212] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-12-03 07:22:46,502 [Thread-212] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-12-03 07:22:46,502 [Thread-212] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-12-03 07:22:46,502 [Thread-212] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-12-03 07:22:46,501 [IPC Server handler 8 on default port 41189] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:37691
2020-12-03 07:22:46,503 [IPC Server handler 3 on default port 42246] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:37691, datanodeUuid=cf6dffe3-142c-4551-9b92-aa40255ddbb7, infoPort=45489, infoSecurePort=0, ipcPort=40468, storageInfo=lv=-57;cid=testClusterID;nsid=324671252;c=1606980156864) storage cf6dffe3-142c-4551-9b92-aa40255ddbb7
2020-12-03 07:22:46,503 [IPC Server handler 3 on default port 42246] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:37691
2020-12-03 07:22:46,504 [IPC Server handler 3 on default port 42246] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN cf6dffe3-142c-4551-9b92-aa40255ddbb7 (127.0.0.1:37691).
2020-12-03 07:22:46,501 [Thread-211] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1217207052-172.17.0.3-1606980156864
2020-12-03 07:22:46,505 [Thread-288] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1217207052-172.17.0.3-1606980156864 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5...
2020-12-03 07:22:46,505 [Thread-289] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1217207052-172.17.0.3-1606980156864 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6...
2020-12-03 07:22:46,511 [Thread-236] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1217207052-172.17.0.3-1606980156864
2020-12-03 07:22:46,512 [Thread-236] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-1217207052-172.17.0.3-1606980156864
2020-12-03 07:22:46,512 [Thread-236] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8 and block pool id BP-1217207052-172.17.0.3-1606980156864 is not formatted. Formatting ...
2020-12-03 07:22:46,512 [Thread-236] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1217207052-172.17.0.3-1606980156864 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-1217207052-172.17.0.3-1606980156864/current
2020-12-03 07:22:46,512 [BP-1217207052-172.17.0.3-1606980156864 heartbeating to localhost/127.0.0.1:42246] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1217207052-172.17.0.3-1606980156864 (Datanode Uuid cf6dffe3-142c-4551-9b92-aa40255ddbb7) service to localhost/127.0.0.1:42246 successfully registered with NN
2020-12-03 07:22:46,512 [BP-1217207052-172.17.0.3-1606980156864 heartbeating to localhost/127.0.0.1:42246] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:42246 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:22:46,526 [IPC Server handler 8 on default port 41189] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN cf6dffe3-142c-4551-9b92-aa40255ddbb7 (127.0.0.1:37691).
2020-12-03 07:22:46,528 [IPC Server handler 8 on default port 40615] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:46607, datanodeUuid=da8c2a33-61a0-489f-ae14-f61765804689, infoPort=36630, infoSecurePort=0, ipcPort=35721, storageInfo=lv=-57;cid=testClusterID;nsid=1596799538;c=1606980160747) storage da8c2a33-61a0-489f-ae14-f61765804689
2020-12-03 07:22:46,528 [BP-1235373120-172.17.0.3-1606980160747 heartbeating to localhost/127.0.0.1:40615] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1235373120-172.17.0.3-1606980160747 (Datanode Uuid cf6dffe3-142c-4551-9b92-aa40255ddbb7) service to localhost/127.0.0.1:40615 successfully registered with NN
2020-12-03 07:22:46,528 [IPC Server handler 8 on default port 40615] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:46607
2020-12-03 07:22:46,528 [BP-1235373120-172.17.0.3-1606980160747 heartbeating to localhost/127.0.0.1:40615] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:40615 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:22:46,529 [BP-1235373120-172.17.0.3-1606980160747 heartbeating to localhost/127.0.0.1:41189] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1235373120-172.17.0.3-1606980160747 (Datanode Uuid cf6dffe3-142c-4551-9b92-aa40255ddbb7) service to localhost/127.0.0.1:41189 successfully registered with NN
2020-12-03 07:22:46,529 [BP-1235373120-172.17.0.3-1606980160747 heartbeating to localhost/127.0.0.1:41189] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:41189 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:22:46,532 [IPC Server handler 9 on default port 37628] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:46607, datanodeUuid=da8c2a33-61a0-489f-ae14-f61765804689, infoPort=36630, infoSecurePort=0, ipcPort=35721, storageInfo=lv=-57;cid=testClusterID;nsid=324671252;c=1606980156864) storage da8c2a33-61a0-489f-ae14-f61765804689
2020-12-03 07:22:46,532 [IPC Server handler 9 on default port 37628] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:46607
2020-12-03 07:22:46,535 [BP-1217207052-172.17.0.3-1606980156864 heartbeating to localhost/127.0.0.1:37628] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1217207052-172.17.0.3-1606980156864 (Datanode Uuid cf6dffe3-142c-4551-9b92-aa40255ddbb7) service to localhost/127.0.0.1:37628 successfully registered with NN
2020-12-03 07:22:46,536 [BP-1217207052-172.17.0.3-1606980156864 heartbeating to localhost/127.0.0.1:37628] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:37628 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:22:46,544 [IPC Server handler 8 on default port 40615] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN da8c2a33-61a0-489f-ae14-f61765804689 (127.0.0.1:46607).
2020-12-03 07:22:46,551 [BP-1235373120-172.17.0.3-1606980160747 heartbeating to localhost/127.0.0.1:40615] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1235373120-172.17.0.3-1606980160747 (Datanode Uuid da8c2a33-61a0-489f-ae14-f61765804689) service to localhost/127.0.0.1:40615 successfully registered with NN
2020-12-03 07:22:46,551 [BP-1235373120-172.17.0.3-1606980160747 heartbeating to localhost/127.0.0.1:40615] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:40615 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:22:46,554 [IPC Server handler 9 on default port 37628] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN da8c2a33-61a0-489f-ae14-f61765804689 (127.0.0.1:46607).
2020-12-03 07:22:46,554 [Thread-212] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1235373120-172.17.0.3-1606980160747
2020-12-03 07:22:46,556 [BP-1217207052-172.17.0.3-1606980156864 heartbeating to localhost/127.0.0.1:37628] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1217207052-172.17.0.3-1606980156864 (Datanode Uuid da8c2a33-61a0-489f-ae14-f61765804689) service to localhost/127.0.0.1:37628 successfully registered with NN
2020-12-03 07:22:46,556 [BP-1217207052-172.17.0.3-1606980156864 heartbeating to localhost/127.0.0.1:37628] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:37628 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:22:46,592 [Thread-288] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1217207052-172.17.0.3-1606980156864 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5: 87ms
2020-12-03 07:22:46,593 [IPC Server handler 0 on default port 42246] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-40230fce-682c-44e3-ba88-45564f51101d for DN 127.0.0.1:37691
2020-12-03 07:22:46,594 [IPC Server handler 0 on default port 42246] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-3c828317-de65-40e3-b326-d448a3a4057d for DN 127.0.0.1:37691
2020-12-03 07:22:46,594 [IPC Server handler 1 on default port 42246] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:46,597 [Thread-289] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1217207052-172.17.0.3-1606980156864 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6: 91ms
2020-12-03 07:22:46,597 [Thread-211] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1217207052-172.17.0.3-1606980156864: 92ms
2020-12-03 07:22:46,598 [Thread-292] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1217207052-172.17.0.3-1606980156864 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5...
2020-12-03 07:22:46,598 [Thread-292] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-1217207052-172.17.0.3-1606980156864/current/replicas doesn't exist 
2020-12-03 07:22:46,598 [Thread-293] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1235373120-172.17.0.3-1606980160747 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5...
2020-12-03 07:22:46,598 [Thread-295] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1235373120-172.17.0.3-1606980160747 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6...
2020-12-03 07:22:46,598 [Thread-294] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1217207052-172.17.0.3-1606980156864 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6...
2020-12-03 07:22:46,598 [Thread-292] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1217207052-172.17.0.3-1606980156864 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5: 1ms
2020-12-03 07:22:46,599 [Thread-294] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-1217207052-172.17.0.3-1606980156864/current/replicas doesn't exist 
2020-12-03 07:22:46,599 [Thread-294] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1217207052-172.17.0.3-1606980156864 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6: 1ms
2020-12-03 07:22:46,601 [Listener at localhost/37550] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:46,602 [Listener at localhost/37550] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:46,603 [Thread-211] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1217207052-172.17.0.3-1606980156864: 6ms
2020-12-03 07:22:46,610 [Thread-211] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 10:59 AM with interval of 21600000ms
2020-12-03 07:22:46,610 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1217207052-172.17.0.3-1606980156864 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-12-03 07:22:46,611 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1217207052-172.17.0.3-1606980156864 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-12-03 07:22:46,608 [IPC Server handler 4 on default port 40615] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-74bf8983-5f9d-4008-9db0-e9461d0d0ffa for DN 127.0.0.1:46607
2020-12-03 07:22:46,619 [BP-1217207052-172.17.0.3-1606980156864 heartbeating to localhost/127.0.0.1:37628] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1217207052-172.17.0.3-1606980156864 (Datanode Uuid f47a982f-3e85-4226-b9b0-c434f3f5cab7) service to localhost/127.0.0.1:37628 beginning handshake with NN
2020-12-03 07:22:46,623 [IPC Server handler 7 on default port 42246] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-74bf8983-5f9d-4008-9db0-e9461d0d0ffa for DN 127.0.0.1:46607
2020-12-03 07:22:46,622 [BP-1217207052-172.17.0.3-1606980156864 heartbeating to localhost/127.0.0.1:42246] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1217207052-172.17.0.3-1606980156864 (Datanode Uuid f47a982f-3e85-4226-b9b0-c434f3f5cab7) service to localhost/127.0.0.1:42246 beginning handshake with NN
2020-12-03 07:22:46,622 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, DS-e877e98a-df8b-4ebc-98c4-d460f14efb90): finished scanning block pool BP-1217207052-172.17.0.3-1606980156864
2020-12-03 07:22:46,619 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, DS-bd3e7214-c1b2-4043-86e7-9863535e580f): finished scanning block pool BP-1217207052-172.17.0.3-1606980156864
2020-12-03 07:22:46,609 [IPC Server handler 7 on default port 37628] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-74bf8983-5f9d-4008-9db0-e9461d0d0ffa for DN 127.0.0.1:46607
2020-12-03 07:22:46,632 [IPC Server handler 7 on default port 37628] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-babb1fcd-9d27-47f3-9171-b3180daa923a for DN 127.0.0.1:46607
2020-12-03 07:22:46,636 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, DS-e877e98a-df8b-4ebc-98c4-d460f14efb90): no suitable block pools found to scan.  Waiting 1814399973 ms.
2020-12-03 07:22:46,608 [IPC Server handler 9 on default port 41189] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-74bf8983-5f9d-4008-9db0-e9461d0d0ffa for DN 127.0.0.1:46607
2020-12-03 07:22:46,626 [Thread-236] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=324671252;bpid=BP-1217207052-172.17.0.3-1606980156864;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=324671252;c=1606980156864;bpid=BP-1217207052-172.17.0.3-1606980156864;dnuuid=null
2020-12-03 07:22:46,619 [IPC Server handler 4 on default port 40615] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-babb1fcd-9d27-47f3-9171-b3180daa923a for DN 127.0.0.1:46607
2020-12-03 07:22:46,625 [IPC Server handler 7 on default port 42246] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-babb1fcd-9d27-47f3-9171-b3180daa923a for DN 127.0.0.1:46607
2020-12-03 07:22:46,637 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, DS-bd3e7214-c1b2-4043-86e7-9863535e580f): no suitable block pools found to scan.  Waiting 1814399972 ms.
2020-12-03 07:22:46,636 [IPC Server handler 9 on default port 41189] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-babb1fcd-9d27-47f3-9171-b3180daa923a for DN 127.0.0.1:46607
2020-12-03 07:22:46,638 [IPC Server handler 3 on default port 40615] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-40230fce-682c-44e3-ba88-45564f51101d for DN 127.0.0.1:37691
2020-12-03 07:22:46,638 [IPC Server handler 6 on default port 37628] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-40230fce-682c-44e3-ba88-45564f51101d for DN 127.0.0.1:37691
2020-12-03 07:22:46,644 [IPC Server handler 4 on default port 42246] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:32791, datanodeUuid=f47a982f-3e85-4226-b9b0-c434f3f5cab7, infoPort=46535, infoSecurePort=0, ipcPort=40600, storageInfo=lv=-57;cid=testClusterID;nsid=324671252;c=1606980156864) storage f47a982f-3e85-4226-b9b0-c434f3f5cab7
2020-12-03 07:22:46,645 [IPC Server handler 4 on default port 42246] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:32791
2020-12-03 07:22:46,645 [IPC Server handler 4 on default port 42246] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN f47a982f-3e85-4226-b9b0-c434f3f5cab7 (127.0.0.1:32791).
2020-12-03 07:22:46,645 [IPC Server handler 2 on default port 41189] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-40230fce-682c-44e3-ba88-45564f51101d for DN 127.0.0.1:37691
2020-12-03 07:22:46,648 [BP-1217207052-172.17.0.3-1606980156864 heartbeating to localhost/127.0.0.1:42246] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1217207052-172.17.0.3-1606980156864 (Datanode Uuid f47a982f-3e85-4226-b9b0-c434f3f5cab7) service to localhost/127.0.0.1:42246 successfully registered with NN
2020-12-03 07:22:46,648 [BP-1217207052-172.17.0.3-1606980156864 heartbeating to localhost/127.0.0.1:42246] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:42246 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:22:46,650 [IPC Server handler 3 on default port 40615] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-3c828317-de65-40e3-b326-d448a3a4057d for DN 127.0.0.1:37691
2020-12-03 07:22:46,650 [IPC Server handler 6 on default port 37628] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-3c828317-de65-40e3-b326-d448a3a4057d for DN 127.0.0.1:37691
2020-12-03 07:22:46,651 [IPC Server handler 5 on default port 37628] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:32791, datanodeUuid=f47a982f-3e85-4226-b9b0-c434f3f5cab7, infoPort=46535, infoSecurePort=0, ipcPort=40600, storageInfo=lv=-57;cid=testClusterID;nsid=324671252;c=1606980156864) storage f47a982f-3e85-4226-b9b0-c434f3f5cab7
2020-12-03 07:22:46,653 [IPC Server handler 5 on default port 37628] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:32791
2020-12-03 07:22:46,653 [IPC Server handler 5 on default port 37628] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN f47a982f-3e85-4226-b9b0-c434f3f5cab7 (127.0.0.1:32791).
2020-12-03 07:22:46,654 [BP-1217207052-172.17.0.3-1606980156864 heartbeating to localhost/127.0.0.1:37628] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1217207052-172.17.0.3-1606980156864 (Datanode Uuid f47a982f-3e85-4226-b9b0-c434f3f5cab7) service to localhost/127.0.0.1:37628 successfully registered with NN
2020-12-03 07:22:46,654 [BP-1217207052-172.17.0.3-1606980156864 heartbeating to localhost/127.0.0.1:37628] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:37628 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:22:46,655 [IPC Server handler 2 on default port 41189] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-3c828317-de65-40e3-b326-d448a3a4057d for DN 127.0.0.1:37691
2020-12-03 07:22:46,658 [Thread-293] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1235373120-172.17.0.3-1606980160747 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5: 60ms
2020-12-03 07:22:46,659 [Thread-295] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1235373120-172.17.0.3-1606980160747 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6: 61ms
2020-12-03 07:22:46,667 [Thread-212] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1235373120-172.17.0.3-1606980160747: 69ms
2020-12-03 07:22:46,670 [IPC Server handler 0 on default port 37628] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-bd3e7214-c1b2-4043-86e7-9863535e580f for DN 127.0.0.1:32791
2020-12-03 07:22:46,670 [IPC Server handler 6 on default port 42246] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-bd3e7214-c1b2-4043-86e7-9863535e580f for DN 127.0.0.1:32791
2020-12-03 07:22:46,671 [IPC Server handler 0 on default port 37628] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-e877e98a-df8b-4ebc-98c4-d460f14efb90 for DN 127.0.0.1:32791
2020-12-03 07:22:46,671 [Thread-302] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1235373120-172.17.0.3-1606980160747 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6...
2020-12-03 07:22:46,672 [Thread-302] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-1235373120-172.17.0.3-1606980160747/current/replicas doesn't exist 
2020-12-03 07:22:46,671 [Thread-301] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1235373120-172.17.0.3-1606980160747 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5...
2020-12-03 07:22:46,671 [IPC Server handler 6 on default port 42246] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-e877e98a-df8b-4ebc-98c4-d460f14efb90 for DN 127.0.0.1:32791
2020-12-03 07:22:46,675 [Thread-302] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1235373120-172.17.0.3-1606980160747 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6: 3ms
2020-12-03 07:22:46,672 [Thread-301] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-1235373120-172.17.0.3-1606980160747/current/replicas doesn't exist 
2020-12-03 07:22:46,678 [Thread-301] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1235373120-172.17.0.3-1606980160747 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5: 6ms
2020-12-03 07:22:46,678 [Thread-212] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1235373120-172.17.0.3-1606980160747: 7ms
2020-12-03 07:22:46,678 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1235373120-172.17.0.3-1606980160747 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-12-03 07:22:46,683 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1235373120-172.17.0.3-1606980160747 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-12-03 07:22:46,684 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, DS-e877e98a-df8b-4ebc-98c4-d460f14efb90): finished scanning block pool BP-1235373120-172.17.0.3-1606980160747
2020-12-03 07:22:46,684 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, DS-e877e98a-df8b-4ebc-98c4-d460f14efb90): no suitable block pools found to scan.  Waiting 1814399925 ms.
2020-12-03 07:22:46,691 [BP-1235373120-172.17.0.3-1606980160747 heartbeating to localhost/127.0.0.1:41189] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1235373120-172.17.0.3-1606980160747 (Datanode Uuid f47a982f-3e85-4226-b9b0-c434f3f5cab7) service to localhost/127.0.0.1:41189 beginning handshake with NN
2020-12-03 07:22:46,692 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, DS-bd3e7214-c1b2-4043-86e7-9863535e580f): finished scanning block pool BP-1235373120-172.17.0.3-1606980160747
2020-12-03 07:22:46,701 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x1fa76c381932fd08: Processing first storage report for DS-babb1fcd-9d27-47f3-9171-b3180daa923a from datanode da8c2a33-61a0-489f-ae14-f61765804689
2020-12-03 07:22:46,691 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x6db0eea5711034f3: Processing first storage report for DS-babb1fcd-9d27-47f3-9171-b3180daa923a from datanode da8c2a33-61a0-489f-ae14-f61765804689
2020-12-03 07:22:46,691 [BP-1235373120-172.17.0.3-1606980160747 heartbeating to localhost/127.0.0.1:40615] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1235373120-172.17.0.3-1606980160747 (Datanode Uuid f47a982f-3e85-4226-b9b0-c434f3f5cab7) service to localhost/127.0.0.1:40615 beginning handshake with NN
2020-12-03 07:22:46,701 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xe9f4131272515754: Processing first storage report for DS-babb1fcd-9d27-47f3-9171-b3180daa923a from datanode da8c2a33-61a0-489f-ae14-f61765804689
2020-12-03 07:22:46,702 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, DS-bd3e7214-c1b2-4043-86e7-9863535e580f): no suitable block pools found to scan.  Waiting 1814399907 ms.
2020-12-03 07:22:46,702 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x7ab639ccc93fdf8e: Processing first storage report for DS-40230fce-682c-44e3-ba88-45564f51101d from datanode cf6dffe3-142c-4551-9b92-aa40255ddbb7
2020-12-03 07:22:46,708 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x1fa76c381932fd08: from storage DS-babb1fcd-9d27-47f3-9171-b3180daa923a node DatanodeRegistration(127.0.0.1:46607, datanodeUuid=da8c2a33-61a0-489f-ae14-f61765804689, infoPort=36630, infoSecurePort=0, ipcPort=35721, storageInfo=lv=-57;cid=testClusterID;nsid=1596799538;c=1606980160747), blocks: 0, hasStaleStorage: true, processing time: 3 msecs, invalidatedBlocks: 0
2020-12-03 07:22:46,709 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x7ab639ccc93fdf8e: from storage DS-40230fce-682c-44e3-ba88-45564f51101d node DatanodeRegistration(127.0.0.1:37691, datanodeUuid=cf6dffe3-142c-4551-9b92-aa40255ddbb7, infoPort=45489, infoSecurePort=0, ipcPort=40468, storageInfo=lv=-57;cid=testClusterID;nsid=1596799538;c=1606980160747), blocks: 0, hasStaleStorage: true, processing time: 2 msecs, invalidatedBlocks: 0
2020-12-03 07:22:46,709 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x6db0eea5711034f3: from storage DS-babb1fcd-9d27-47f3-9171-b3180daa923a node DatanodeRegistration(127.0.0.1:46607, datanodeUuid=da8c2a33-61a0-489f-ae14-f61765804689, infoPort=36630, infoSecurePort=0, ipcPort=35721, storageInfo=lv=-57;cid=testClusterID;nsid=324671252;c=1606980156864), blocks: 0, hasStaleStorage: true, processing time: 17 msecs, invalidatedBlocks: 0
2020-12-03 07:22:46,709 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xe9f4131272515754: from storage DS-babb1fcd-9d27-47f3-9171-b3180daa923a node DatanodeRegistration(127.0.0.1:46607, datanodeUuid=da8c2a33-61a0-489f-ae14-f61765804689, infoPort=36630, infoSecurePort=0, ipcPort=35721, storageInfo=lv=-57;cid=testClusterID;nsid=324671252;c=1606980156864), blocks: 0, hasStaleStorage: true, processing time: 2 msecs, invalidatedBlocks: 0
2020-12-03 07:22:46,709 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x66041fb320f71a4a: Processing first storage report for DS-e877e98a-df8b-4ebc-98c4-d460f14efb90 from datanode f47a982f-3e85-4226-b9b0-c434f3f5cab7
2020-12-03 07:22:46,709 [IPC Server handler 3 on default port 41189] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:32791, datanodeUuid=f47a982f-3e85-4226-b9b0-c434f3f5cab7, infoPort=46535, infoSecurePort=0, ipcPort=40600, storageInfo=lv=-57;cid=testClusterID;nsid=1596799538;c=1606980160747) storage f47a982f-3e85-4226-b9b0-c434f3f5cab7
2020-12-03 07:22:46,709 [IPC Server handler 7 on default port 40615] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:32791, datanodeUuid=f47a982f-3e85-4226-b9b0-c434f3f5cab7, infoPort=46535, infoSecurePort=0, ipcPort=40600, storageInfo=lv=-57;cid=testClusterID;nsid=1596799538;c=1606980160747) storage f47a982f-3e85-4226-b9b0-c434f3f5cab7
2020-12-03 07:22:46,709 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x66041fb320f71a4a: from storage DS-e877e98a-df8b-4ebc-98c4-d460f14efb90 node DatanodeRegistration(127.0.0.1:32791, datanodeUuid=f47a982f-3e85-4226-b9b0-c434f3f5cab7, infoPort=46535, infoSecurePort=0, ipcPort=40600, storageInfo=lv=-57;cid=testClusterID;nsid=324671252;c=1606980156864), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:22:46,710 [IPC Server handler 8 on default port 42246] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:46,710 [IPC Server handler 3 on default port 41189] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:32791
2020-12-03 07:22:46,710 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xd68f765b73b5a384: Processing first storage report for DS-40230fce-682c-44e3-ba88-45564f51101d from datanode cf6dffe3-142c-4551-9b92-aa40255ddbb7
2020-12-03 07:22:46,710 [IPC Server handler 7 on default port 40615] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:32791
2020-12-03 07:22:46,710 [IPC Server handler 7 on default port 40615] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN f47a982f-3e85-4226-b9b0-c434f3f5cab7 (127.0.0.1:32791).
2020-12-03 07:22:46,710 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x1af729890c65af27: Processing first storage report for DS-e877e98a-df8b-4ebc-98c4-d460f14efb90 from datanode f47a982f-3e85-4226-b9b0-c434f3f5cab7
2020-12-03 07:22:46,711 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x9c6cec4d0c8091f4: Processing first storage report for DS-40230fce-682c-44e3-ba88-45564f51101d from datanode cf6dffe3-142c-4551-9b92-aa40255ddbb7
2020-12-03 07:22:46,710 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xd68f765b73b5a384: from storage DS-40230fce-682c-44e3-ba88-45564f51101d node DatanodeRegistration(127.0.0.1:37691, datanodeUuid=cf6dffe3-142c-4551-9b92-aa40255ddbb7, infoPort=45489, infoSecurePort=0, ipcPort=40468, storageInfo=lv=-57;cid=testClusterID;nsid=324671252;c=1606980156864), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:46,710 [IPC Server handler 3 on default port 41189] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN f47a982f-3e85-4226-b9b0-c434f3f5cab7 (127.0.0.1:32791).
2020-12-03 07:22:46,711 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x6db0eea5711034f3: Processing first storage report for DS-74bf8983-5f9d-4008-9db0-e9461d0d0ffa from datanode da8c2a33-61a0-489f-ae14-f61765804689
2020-12-03 07:22:46,711 [Listener at localhost/37550] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:46,711 [Listener at localhost/37550] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:46,712 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x6db0eea5711034f3: from storage DS-74bf8983-5f9d-4008-9db0-e9461d0d0ffa node DatanodeRegistration(127.0.0.1:46607, datanodeUuid=da8c2a33-61a0-489f-ae14-f61765804689, infoPort=36630, infoSecurePort=0, ipcPort=35721, storageInfo=lv=-57;cid=testClusterID;nsid=324671252;c=1606980156864), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:22:46,711 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x9c6cec4d0c8091f4: from storage DS-40230fce-682c-44e3-ba88-45564f51101d node DatanodeRegistration(127.0.0.1:37691, datanodeUuid=cf6dffe3-142c-4551-9b92-aa40255ddbb7, infoPort=45489, infoSecurePort=0, ipcPort=40468, storageInfo=lv=-57;cid=testClusterID;nsid=1596799538;c=1606980160747), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:46,711 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x1af729890c65af27: from storage DS-e877e98a-df8b-4ebc-98c4-d460f14efb90 node DatanodeRegistration(127.0.0.1:32791, datanodeUuid=f47a982f-3e85-4226-b9b0-c434f3f5cab7, infoPort=46535, infoSecurePort=0, ipcPort=40600, storageInfo=lv=-57;cid=testClusterID;nsid=324671252;c=1606980156864), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:22:46,712 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x890e4bfb934a16bc: Processing first storage report for DS-40230fce-682c-44e3-ba88-45564f51101d from datanode cf6dffe3-142c-4551-9b92-aa40255ddbb7
2020-12-03 07:22:46,712 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x1fa76c381932fd08: Processing first storage report for DS-74bf8983-5f9d-4008-9db0-e9461d0d0ffa from datanode da8c2a33-61a0-489f-ae14-f61765804689
2020-12-03 07:22:46,712 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x66041fb320f71a4a: Processing first storage report for DS-bd3e7214-c1b2-4043-86e7-9863535e580f from datanode f47a982f-3e85-4226-b9b0-c434f3f5cab7
2020-12-03 07:22:46,711 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xfc1780be43e6f6b0: Processing first storage report for DS-babb1fcd-9d27-47f3-9171-b3180daa923a from datanode da8c2a33-61a0-489f-ae14-f61765804689
2020-12-03 07:22:46,712 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x66041fb320f71a4a: from storage DS-bd3e7214-c1b2-4043-86e7-9863535e580f node DatanodeRegistration(127.0.0.1:32791, datanodeUuid=f47a982f-3e85-4226-b9b0-c434f3f5cab7, infoPort=46535, infoSecurePort=0, ipcPort=40600, storageInfo=lv=-57;cid=testClusterID;nsid=324671252;c=1606980156864), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:22:46,712 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x1fa76c381932fd08: from storage DS-74bf8983-5f9d-4008-9db0-e9461d0d0ffa node DatanodeRegistration(127.0.0.1:46607, datanodeUuid=da8c2a33-61a0-489f-ae14-f61765804689, infoPort=36630, infoSecurePort=0, ipcPort=35721, storageInfo=lv=-57;cid=testClusterID;nsid=1596799538;c=1606980160747), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:22:46,713 [BP-1235373120-172.17.0.3-1606980160747 heartbeating to localhost/127.0.0.1:40615] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1235373120-172.17.0.3-1606980160747 (Datanode Uuid f47a982f-3e85-4226-b9b0-c434f3f5cab7) service to localhost/127.0.0.1:40615 successfully registered with NN
2020-12-03 07:22:46,712 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x890e4bfb934a16bc: from storage DS-40230fce-682c-44e3-ba88-45564f51101d node DatanodeRegistration(127.0.0.1:37691, datanodeUuid=cf6dffe3-142c-4551-9b92-aa40255ddbb7, infoPort=45489, infoSecurePort=0, ipcPort=40468, storageInfo=lv=-57;cid=testClusterID;nsid=324671252;c=1606980156864), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:22:46,713 [BP-1235373120-172.17.0.3-1606980160747 heartbeating to localhost/127.0.0.1:40615] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:40615 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:22:46,713 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x9c6cec4d0c8091f4: Processing first storage report for DS-3c828317-de65-40e3-b326-d448a3a4057d from datanode cf6dffe3-142c-4551-9b92-aa40255ddbb7
2020-12-03 07:22:46,713 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x9c6cec4d0c8091f4: from storage DS-3c828317-de65-40e3-b326-d448a3a4057d node DatanodeRegistration(127.0.0.1:37691, datanodeUuid=cf6dffe3-142c-4551-9b92-aa40255ddbb7, infoPort=45489, infoSecurePort=0, ipcPort=40468, storageInfo=lv=-57;cid=testClusterID;nsid=1596799538;c=1606980160747), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:22:46,713 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xd68f765b73b5a384: Processing first storage report for DS-3c828317-de65-40e3-b326-d448a3a4057d from datanode cf6dffe3-142c-4551-9b92-aa40255ddbb7
2020-12-03 07:22:46,713 [BP-1235373120-172.17.0.3-1606980160747 heartbeating to localhost/127.0.0.1:41189] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1235373120-172.17.0.3-1606980160747 (Datanode Uuid f47a982f-3e85-4226-b9b0-c434f3f5cab7) service to localhost/127.0.0.1:41189 successfully registered with NN
2020-12-03 07:22:46,713 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xfc1780be43e6f6b0: from storage DS-babb1fcd-9d27-47f3-9171-b3180daa923a node DatanodeRegistration(127.0.0.1:46607, datanodeUuid=da8c2a33-61a0-489f-ae14-f61765804689, infoPort=36630, infoSecurePort=0, ipcPort=35721, storageInfo=lv=-57;cid=testClusterID;nsid=1596799538;c=1606980160747), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:22:46,714 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x7ab639ccc93fdf8e: Processing first storage report for DS-3c828317-de65-40e3-b326-d448a3a4057d from datanode cf6dffe3-142c-4551-9b92-aa40255ddbb7
2020-12-03 07:22:46,714 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x7ab639ccc93fdf8e: from storage DS-3c828317-de65-40e3-b326-d448a3a4057d node DatanodeRegistration(127.0.0.1:37691, datanodeUuid=cf6dffe3-142c-4551-9b92-aa40255ddbb7, infoPort=45489, infoSecurePort=0, ipcPort=40468, storageInfo=lv=-57;cid=testClusterID;nsid=1596799538;c=1606980160747), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:46,714 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xfc1780be43e6f6b0: Processing first storage report for DS-74bf8983-5f9d-4008-9db0-e9461d0d0ffa from datanode da8c2a33-61a0-489f-ae14-f61765804689
2020-12-03 07:22:46,714 [BP-1235373120-172.17.0.3-1606980160747 heartbeating to localhost/127.0.0.1:41189] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:41189 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:22:46,714 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xd68f765b73b5a384: from storage DS-3c828317-de65-40e3-b326-d448a3a4057d node DatanodeRegistration(127.0.0.1:37691, datanodeUuid=cf6dffe3-142c-4551-9b92-aa40255ddbb7, infoPort=45489, infoSecurePort=0, ipcPort=40468, storageInfo=lv=-57;cid=testClusterID;nsid=324671252;c=1606980156864), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:22:46,713 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xe9f4131272515754: Processing first storage report for DS-74bf8983-5f9d-4008-9db0-e9461d0d0ffa from datanode da8c2a33-61a0-489f-ae14-f61765804689
2020-12-03 07:22:46,714 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xfc1780be43e6f6b0: from storage DS-74bf8983-5f9d-4008-9db0-e9461d0d0ffa node DatanodeRegistration(127.0.0.1:46607, datanodeUuid=da8c2a33-61a0-489f-ae14-f61765804689, infoPort=36630, infoSecurePort=0, ipcPort=35721, storageInfo=lv=-57;cid=testClusterID;nsid=1596799538;c=1606980160747), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:46,715 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xe9f4131272515754: from storage DS-74bf8983-5f9d-4008-9db0-e9461d0d0ffa node DatanodeRegistration(127.0.0.1:46607, datanodeUuid=da8c2a33-61a0-489f-ae14-f61765804689, infoPort=36630, infoSecurePort=0, ipcPort=35721, storageInfo=lv=-57;cid=testClusterID;nsid=324671252;c=1606980156864), blocks: 0, hasStaleStorage: false, processing time: 2 msecs, invalidatedBlocks: 0
2020-12-03 07:22:46,715 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x1af729890c65af27: Processing first storage report for DS-bd3e7214-c1b2-4043-86e7-9863535e580f from datanode f47a982f-3e85-4226-b9b0-c434f3f5cab7
2020-12-03 07:22:46,715 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x1af729890c65af27: from storage DS-bd3e7214-c1b2-4043-86e7-9863535e580f node DatanodeRegistration(127.0.0.1:32791, datanodeUuid=f47a982f-3e85-4226-b9b0-c434f3f5cab7, infoPort=46535, infoSecurePort=0, ipcPort=40600, storageInfo=lv=-57;cid=testClusterID;nsid=324671252;c=1606980156864), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:46,716 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x890e4bfb934a16bc: Processing first storage report for DS-3c828317-de65-40e3-b326-d448a3a4057d from datanode cf6dffe3-142c-4551-9b92-aa40255ddbb7
2020-12-03 07:22:46,716 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x890e4bfb934a16bc: from storage DS-3c828317-de65-40e3-b326-d448a3a4057d node DatanodeRegistration(127.0.0.1:37691, datanodeUuid=cf6dffe3-142c-4551-9b92-aa40255ddbb7, infoPort=45489, infoSecurePort=0, ipcPort=40468, storageInfo=lv=-57;cid=testClusterID;nsid=324671252;c=1606980156864), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:46,717 [IPC Server handler 6 on default port 41189] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-bd3e7214-c1b2-4043-86e7-9863535e580f for DN 127.0.0.1:32791
2020-12-03 07:22:46,718 [IPC Server handler 6 on default port 41189] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-e877e98a-df8b-4ebc-98c4-d460f14efb90 for DN 127.0.0.1:32791
2020-12-03 07:22:46,722 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xba43e565d6f9dc24: Processing first storage report for DS-e877e98a-df8b-4ebc-98c4-d460f14efb90 from datanode f47a982f-3e85-4226-b9b0-c434f3f5cab7
2020-12-03 07:22:46,722 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xba43e565d6f9dc24: from storage DS-e877e98a-df8b-4ebc-98c4-d460f14efb90 node DatanodeRegistration(127.0.0.1:32791, datanodeUuid=f47a982f-3e85-4226-b9b0-c434f3f5cab7, infoPort=46535, infoSecurePort=0, ipcPort=40600, storageInfo=lv=-57;cid=testClusterID;nsid=1596799538;c=1606980160747), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:46,722 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xba43e565d6f9dc24: Processing first storage report for DS-bd3e7214-c1b2-4043-86e7-9863535e580f from datanode f47a982f-3e85-4226-b9b0-c434f3f5cab7
2020-12-03 07:22:46,722 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xba43e565d6f9dc24: from storage DS-bd3e7214-c1b2-4043-86e7-9863535e580f node DatanodeRegistration(127.0.0.1:32791, datanodeUuid=f47a982f-3e85-4226-b9b0-c434f3f5cab7, infoPort=46535, infoSecurePort=0, ipcPort=40600, storageInfo=lv=-57;cid=testClusterID;nsid=1596799538;c=1606980160747), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:46,723 [IPC Server handler 8 on default port 40615] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-bd3e7214-c1b2-4043-86e7-9863535e580f for DN 127.0.0.1:32791
2020-12-03 07:22:46,723 [IPC Server handler 8 on default port 40615] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-e877e98a-df8b-4ebc-98c4-d460f14efb90 for DN 127.0.0.1:32791
2020-12-03 07:22:46,726 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xe39c443a353f49ae: Processing first storage report for DS-e877e98a-df8b-4ebc-98c4-d460f14efb90 from datanode f47a982f-3e85-4226-b9b0-c434f3f5cab7
2020-12-03 07:22:46,727 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xe39c443a353f49ae: from storage DS-e877e98a-df8b-4ebc-98c4-d460f14efb90 node DatanodeRegistration(127.0.0.1:32791, datanodeUuid=f47a982f-3e85-4226-b9b0-c434f3f5cab7, infoPort=46535, infoSecurePort=0, ipcPort=40600, storageInfo=lv=-57;cid=testClusterID;nsid=1596799538;c=1606980160747), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:22:46,728 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xe39c443a353f49ae: Processing first storage report for DS-bd3e7214-c1b2-4043-86e7-9863535e580f from datanode f47a982f-3e85-4226-b9b0-c434f3f5cab7
2020-12-03 07:22:46,728 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xe39c443a353f49ae: from storage DS-bd3e7214-c1b2-4043-86e7-9863535e580f node DatanodeRegistration(127.0.0.1:32791, datanodeUuid=f47a982f-3e85-4226-b9b0-c434f3f5cab7, infoPort=46535, infoSecurePort=0, ipcPort=40600, storageInfo=lv=-57;cid=testClusterID;nsid=1596799538;c=1606980160747), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:46,750 [BP-1235373120-172.17.0.3-1606980160747 heartbeating to localhost/127.0.0.1:40615] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xe39c443a353f49ae,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 24 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:22:46,751 [BP-1235373120-172.17.0.3-1606980160747 heartbeating to localhost/127.0.0.1:41189] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xfc1780be43e6f6b0,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 10 msec to generate and 87 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:22:46,751 [BP-1217207052-172.17.0.3-1606980156864 heartbeating to localhost/127.0.0.1:37628] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x6db0eea5711034f3,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 10 msec to generate and 87 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:22:46,751 [BP-1217207052-172.17.0.3-1606980156864 heartbeating to localhost/127.0.0.1:37628] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xd68f765b73b5a384,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 8 msec to generate and 87 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:22:46,757 [BP-1217207052-172.17.0.3-1606980156864 heartbeating to localhost/127.0.0.1:42246] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x1af729890c65af27,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 71 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:22:46,757 [BP-1217207052-172.17.0.3-1606980156864 heartbeating to localhost/127.0.0.1:42246] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x890e4bfb934a16bc,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 12 msec to generate and 95 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:22:46,756 [BP-1217207052-172.17.0.3-1606980156864 heartbeating to localhost/127.0.0.1:42246] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xe9f4131272515754,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 7 msec to generate and 99 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:22:46,756 [BP-1235373120-172.17.0.3-1606980160747 heartbeating to localhost/127.0.0.1:41189] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x7ab639ccc93fdf8e,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 6 msec to generate and 94 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:22:46,754 [BP-1217207052-172.17.0.3-1606980156864 heartbeating to localhost/127.0.0.1:37628] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x66041fb320f71a4a,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 81 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:22:46,755 [BP-1235373120-172.17.0.3-1606980160747 heartbeating to localhost/127.0.0.1:40615] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x1fa76c381932fd08,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 10 msec to generate and 94 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:22:46,755 [BP-1235373120-172.17.0.3-1606980160747 heartbeating to localhost/127.0.0.1:40615] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x9c6cec4d0c8091f4,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 6 msec to generate and 92 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:22:46,754 [BP-1235373120-172.17.0.3-1606980160747 heartbeating to localhost/127.0.0.1:41189] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xba43e565d6f9dc24,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 34 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:22:46,761 [Thread-237] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID ce121cb5-ea3a-4b2b-95c9-141da466dba7
2020-12-03 07:22:46,767 [Thread-237] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-290a7f2a-32af-42b2-89c3-1b2c2b279b33
2020-12-03 07:22:46,768 [Thread-237] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, StorageType: DISK
2020-12-03 07:22:46,771 [Thread-237] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-e7b706cd-4e9c-48c6-b202-c15d8d57696f
2020-12-03 07:22:46,771 [Thread-237] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, StorageType: DISK
2020-12-03 07:22:46,772 [Thread-237] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:22:46,774 [Thread-237] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7
2020-12-03 07:22:46,777 [Thread-236] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1217207052-172.17.0.3-1606980156864
2020-12-03 07:22:46,777 [Thread-237] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7
2020-12-03 07:22:46,778 [Thread-305] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1217207052-172.17.0.3-1606980156864 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7...
2020-12-03 07:22:46,778 [Thread-237] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-12-03 07:22:46,778 [Thread-306] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1217207052-172.17.0.3-1606980156864 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8...
2020-12-03 07:22:46,778 [Thread-237] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-12-03 07:22:46,779 [Thread-237] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1235373120-172.17.0.3-1606980160747
2020-12-03 07:22:46,813 [IPC Server handler 3 on default port 42246] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:46,814 [Thread-306] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1217207052-172.17.0.3-1606980156864 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8: 36ms
2020-12-03 07:22:46,814 [Thread-305] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1217207052-172.17.0.3-1606980156864 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7: 37ms
2020-12-03 07:22:46,816 [Thread-236] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1217207052-172.17.0.3-1606980156864: 39ms
2020-12-03 07:22:46,817 [Thread-309] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1217207052-172.17.0.3-1606980156864 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7...
2020-12-03 07:22:46,817 [Thread-311] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1217207052-172.17.0.3-1606980156864 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8...
2020-12-03 07:22:46,817 [Thread-309] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-1217207052-172.17.0.3-1606980156864/current/replicas doesn't exist 
2020-12-03 07:22:46,817 [Thread-311] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-1217207052-172.17.0.3-1606980156864/current/replicas doesn't exist 
2020-12-03 07:22:46,818 [Thread-311] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1217207052-172.17.0.3-1606980156864 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8: 1ms
2020-12-03 07:22:46,818 [Thread-310] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1235373120-172.17.0.3-1606980160747 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7...
2020-12-03 07:22:46,824 [Listener at localhost/37550] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:46,824 [Listener at localhost/37550] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:46,824 [Thread-312] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1235373120-172.17.0.3-1606980160747 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8...
2020-12-03 07:22:46,828 [Thread-309] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1217207052-172.17.0.3-1606980156864 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7: 11ms
2020-12-03 07:22:46,828 [Thread-236] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1217207052-172.17.0.3-1606980156864: 11ms
2020-12-03 07:22:46,830 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1217207052-172.17.0.3-1606980156864 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-12-03 07:22:46,831 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, DS-e7b706cd-4e9c-48c6-b202-c15d8d57696f): finished scanning block pool BP-1217207052-172.17.0.3-1606980156864
2020-12-03 07:22:46,831 [Thread-236] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:59 AM with interval of 21600000ms
2020-12-03 07:22:46,831 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1217207052-172.17.0.3-1606980156864 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7
2020-12-03 07:22:46,832 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, DS-290a7f2a-32af-42b2-89c3-1b2c2b279b33): finished scanning block pool BP-1217207052-172.17.0.3-1606980156864
2020-12-03 07:22:46,832 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, DS-e7b706cd-4e9c-48c6-b202-c15d8d57696f): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-12-03 07:22:46,839 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, DS-290a7f2a-32af-42b2-89c3-1b2c2b279b33): no suitable block pools found to scan.  Waiting 1814399995 ms.
2020-12-03 07:22:46,835 [BP-1217207052-172.17.0.3-1606980156864 heartbeating to localhost/127.0.0.1:42246] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1217207052-172.17.0.3-1606980156864 (Datanode Uuid ce121cb5-ea3a-4b2b-95c9-141da466dba7) service to localhost/127.0.0.1:42246 beginning handshake with NN
2020-12-03 07:22:46,839 [BP-1217207052-172.17.0.3-1606980156864 heartbeating to localhost/127.0.0.1:37628] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1217207052-172.17.0.3-1606980156864 (Datanode Uuid ce121cb5-ea3a-4b2b-95c9-141da466dba7) service to localhost/127.0.0.1:37628 beginning handshake with NN
2020-12-03 07:22:46,844 [IPC Server handler 2 on default port 37628] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:33452, datanodeUuid=ce121cb5-ea3a-4b2b-95c9-141da466dba7, infoPort=40179, infoSecurePort=0, ipcPort=37550, storageInfo=lv=-57;cid=testClusterID;nsid=324671252;c=1606980156864) storage ce121cb5-ea3a-4b2b-95c9-141da466dba7
2020-12-03 07:22:46,844 [IPC Server handler 2 on default port 37628] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:33452
2020-12-03 07:22:46,844 [IPC Server handler 2 on default port 37628] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN ce121cb5-ea3a-4b2b-95c9-141da466dba7 (127.0.0.1:33452).
2020-12-03 07:22:46,845 [IPC Server handler 1 on default port 42246] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:33452, datanodeUuid=ce121cb5-ea3a-4b2b-95c9-141da466dba7, infoPort=40179, infoSecurePort=0, ipcPort=37550, storageInfo=lv=-57;cid=testClusterID;nsid=324671252;c=1606980156864) storage ce121cb5-ea3a-4b2b-95c9-141da466dba7
2020-12-03 07:22:46,845 [IPC Server handler 1 on default port 42246] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:33452
2020-12-03 07:22:46,846 [BP-1217207052-172.17.0.3-1606980156864 heartbeating to localhost/127.0.0.1:37628] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1217207052-172.17.0.3-1606980156864 (Datanode Uuid ce121cb5-ea3a-4b2b-95c9-141da466dba7) service to localhost/127.0.0.1:37628 successfully registered with NN
2020-12-03 07:22:46,846 [IPC Server handler 1 on default port 42246] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN ce121cb5-ea3a-4b2b-95c9-141da466dba7 (127.0.0.1:33452).
2020-12-03 07:22:46,846 [BP-1217207052-172.17.0.3-1606980156864 heartbeating to localhost/127.0.0.1:37628] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:37628 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:22:46,847 [BP-1217207052-172.17.0.3-1606980156864 heartbeating to localhost/127.0.0.1:42246] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1217207052-172.17.0.3-1606980156864 (Datanode Uuid ce121cb5-ea3a-4b2b-95c9-141da466dba7) service to localhost/127.0.0.1:42246 successfully registered with NN
2020-12-03 07:22:46,847 [BP-1217207052-172.17.0.3-1606980156864 heartbeating to localhost/127.0.0.1:42246] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:42246 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:22:46,853 [IPC Server handler 1 on default port 37628] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-290a7f2a-32af-42b2-89c3-1b2c2b279b33 for DN 127.0.0.1:33452
2020-12-03 07:22:46,853 [IPC Server handler 1 on default port 37628] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-e7b706cd-4e9c-48c6-b202-c15d8d57696f for DN 127.0.0.1:33452
2020-12-03 07:22:46,854 [IPC Server handler 0 on default port 42246] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-290a7f2a-32af-42b2-89c3-1b2c2b279b33 for DN 127.0.0.1:33452
2020-12-03 07:22:46,854 [IPC Server handler 0 on default port 42246] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-e7b706cd-4e9c-48c6-b202-c15d8d57696f for DN 127.0.0.1:33452
2020-12-03 07:22:46,862 [Thread-310] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1235373120-172.17.0.3-1606980160747 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7: 38ms
2020-12-03 07:22:46,866 [Thread-312] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1235373120-172.17.0.3-1606980160747 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8: 41ms
2020-12-03 07:22:46,866 [Thread-237] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1235373120-172.17.0.3-1606980160747: 50ms
2020-12-03 07:22:46,867 [Thread-318] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1235373120-172.17.0.3-1606980160747 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7...
2020-12-03 07:22:46,867 [Thread-319] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1235373120-172.17.0.3-1606980160747 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8...
2020-12-03 07:22:46,868 [Thread-318] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-1235373120-172.17.0.3-1606980160747/current/replicas doesn't exist 
2020-12-03 07:22:46,868 [Thread-319] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-1235373120-172.17.0.3-1606980160747/current/replicas doesn't exist 
2020-12-03 07:22:46,868 [Thread-319] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1235373120-172.17.0.3-1606980160747 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8: 1ms
2020-12-03 07:22:46,868 [Thread-318] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1235373120-172.17.0.3-1606980160747 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7: 1ms
2020-12-03 07:22:46,872 [Thread-237] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1235373120-172.17.0.3-1606980160747: 6ms
2020-12-03 07:22:46,873 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1235373120-172.17.0.3-1606980160747 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7
2020-12-03 07:22:46,873 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1235373120-172.17.0.3-1606980160747 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-12-03 07:22:46,873 [BP-1235373120-172.17.0.3-1606980160747 heartbeating to localhost/127.0.0.1:41189] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1235373120-172.17.0.3-1606980160747 (Datanode Uuid ce121cb5-ea3a-4b2b-95c9-141da466dba7) service to localhost/127.0.0.1:41189 beginning handshake with NN
2020-12-03 07:22:46,873 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, DS-290a7f2a-32af-42b2-89c3-1b2c2b279b33): finished scanning block pool BP-1235373120-172.17.0.3-1606980160747
2020-12-03 07:22:46,873 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, DS-e7b706cd-4e9c-48c6-b202-c15d8d57696f): finished scanning block pool BP-1235373120-172.17.0.3-1606980160747
2020-12-03 07:22:46,873 [BP-1235373120-172.17.0.3-1606980160747 heartbeating to localhost/127.0.0.1:40615] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1235373120-172.17.0.3-1606980160747 (Datanode Uuid ce121cb5-ea3a-4b2b-95c9-141da466dba7) service to localhost/127.0.0.1:40615 beginning handshake with NN
2020-12-03 07:22:46,874 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, DS-e7b706cd-4e9c-48c6-b202-c15d8d57696f): no suitable block pools found to scan.  Waiting 1814399956 ms.
2020-12-03 07:22:46,874 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, DS-290a7f2a-32af-42b2-89c3-1b2c2b279b33): no suitable block pools found to scan.  Waiting 1814399956 ms.
2020-12-03 07:22:46,875 [IPC Server handler 1 on default port 41189] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:33452, datanodeUuid=ce121cb5-ea3a-4b2b-95c9-141da466dba7, infoPort=40179, infoSecurePort=0, ipcPort=37550, storageInfo=lv=-57;cid=testClusterID;nsid=1596799538;c=1606980160747) storage ce121cb5-ea3a-4b2b-95c9-141da466dba7
2020-12-03 07:22:46,876 [IPC Server handler 1 on default port 40615] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:33452, datanodeUuid=ce121cb5-ea3a-4b2b-95c9-141da466dba7, infoPort=40179, infoSecurePort=0, ipcPort=37550, storageInfo=lv=-57;cid=testClusterID;nsid=1596799538;c=1606980160747) storage ce121cb5-ea3a-4b2b-95c9-141da466dba7
2020-12-03 07:22:46,876 [IPC Server handler 1 on default port 41189] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:33452
2020-12-03 07:22:46,876 [IPC Server handler 1 on default port 40615] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:33452
2020-12-03 07:22:46,876 [IPC Server handler 1 on default port 41189] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN ce121cb5-ea3a-4b2b-95c9-141da466dba7 (127.0.0.1:33452).
2020-12-03 07:22:46,877 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xe6fc6fe55566f24d: Processing first storage report for DS-290a7f2a-32af-42b2-89c3-1b2c2b279b33 from datanode ce121cb5-ea3a-4b2b-95c9-141da466dba7
2020-12-03 07:22:46,876 [IPC Server handler 1 on default port 40615] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN ce121cb5-ea3a-4b2b-95c9-141da466dba7 (127.0.0.1:33452).
2020-12-03 07:22:46,877 [BP-1235373120-172.17.0.3-1606980160747 heartbeating to localhost/127.0.0.1:41189] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1235373120-172.17.0.3-1606980160747 (Datanode Uuid ce121cb5-ea3a-4b2b-95c9-141da466dba7) service to localhost/127.0.0.1:41189 successfully registered with NN
2020-12-03 07:22:46,877 [BP-1235373120-172.17.0.3-1606980160747 heartbeating to localhost/127.0.0.1:41189] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:41189 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:22:46,877 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xe6fc6fe55566f24d: from storage DS-290a7f2a-32af-42b2-89c3-1b2c2b279b33 node DatanodeRegistration(127.0.0.1:33452, datanodeUuid=ce121cb5-ea3a-4b2b-95c9-141da466dba7, infoPort=40179, infoSecurePort=0, ipcPort=37550, storageInfo=lv=-57;cid=testClusterID;nsid=324671252;c=1606980156864), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:46,877 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xfef20cf5b757098f: Processing first storage report for DS-290a7f2a-32af-42b2-89c3-1b2c2b279b33 from datanode ce121cb5-ea3a-4b2b-95c9-141da466dba7
2020-12-03 07:22:46,878 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xfef20cf5b757098f: from storage DS-290a7f2a-32af-42b2-89c3-1b2c2b279b33 node DatanodeRegistration(127.0.0.1:33452, datanodeUuid=ce121cb5-ea3a-4b2b-95c9-141da466dba7, infoPort=40179, infoSecurePort=0, ipcPort=37550, storageInfo=lv=-57;cid=testClusterID;nsid=324671252;c=1606980156864), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:22:46,878 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xfef20cf5b757098f: Processing first storage report for DS-e7b706cd-4e9c-48c6-b202-c15d8d57696f from datanode ce121cb5-ea3a-4b2b-95c9-141da466dba7
2020-12-03 07:22:46,878 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xfef20cf5b757098f: from storage DS-e7b706cd-4e9c-48c6-b202-c15d8d57696f node DatanodeRegistration(127.0.0.1:33452, datanodeUuid=ce121cb5-ea3a-4b2b-95c9-141da466dba7, infoPort=40179, infoSecurePort=0, ipcPort=37550, storageInfo=lv=-57;cid=testClusterID;nsid=324671252;c=1606980156864), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:22:46,878 [BP-1235373120-172.17.0.3-1606980160747 heartbeating to localhost/127.0.0.1:40615] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1235373120-172.17.0.3-1606980160747 (Datanode Uuid ce121cb5-ea3a-4b2b-95c9-141da466dba7) service to localhost/127.0.0.1:40615 successfully registered with NN
2020-12-03 07:22:46,878 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xe6fc6fe55566f24d: Processing first storage report for DS-e7b706cd-4e9c-48c6-b202-c15d8d57696f from datanode ce121cb5-ea3a-4b2b-95c9-141da466dba7
2020-12-03 07:22:46,879 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xe6fc6fe55566f24d: from storage DS-e7b706cd-4e9c-48c6-b202-c15d8d57696f node DatanodeRegistration(127.0.0.1:33452, datanodeUuid=ce121cb5-ea3a-4b2b-95c9-141da466dba7, infoPort=40179, infoSecurePort=0, ipcPort=37550, storageInfo=lv=-57;cid=testClusterID;nsid=324671252;c=1606980156864), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:46,878 [BP-1235373120-172.17.0.3-1606980160747 heartbeating to localhost/127.0.0.1:40615] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:40615 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:22:46,880 [IPC Server handler 5 on default port 41189] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-290a7f2a-32af-42b2-89c3-1b2c2b279b33 for DN 127.0.0.1:33452
2020-12-03 07:22:46,880 [IPC Server handler 5 on default port 41189] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-e7b706cd-4e9c-48c6-b202-c15d8d57696f for DN 127.0.0.1:33452
2020-12-03 07:22:46,882 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x2c6e0ef993e3e848: Processing first storage report for DS-290a7f2a-32af-42b2-89c3-1b2c2b279b33 from datanode ce121cb5-ea3a-4b2b-95c9-141da466dba7
2020-12-03 07:22:46,883 [BP-1217207052-172.17.0.3-1606980156864 heartbeating to localhost/127.0.0.1:42246] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xfef20cf5b757098f,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 18 msec to generate and 8 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:22:46,883 [IPC Server handler 2 on default port 40615] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-290a7f2a-32af-42b2-89c3-1b2c2b279b33 for DN 127.0.0.1:33452
2020-12-03 07:22:46,883 [BP-1217207052-172.17.0.3-1606980156864 heartbeating to localhost/127.0.0.1:37628] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xe6fc6fe55566f24d,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 17 msec to generate and 6 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:22:46,887 [IPC Server handler 2 on default port 40615] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-e7b706cd-4e9c-48c6-b202-c15d8d57696f for DN 127.0.0.1:33452
2020-12-03 07:22:46,884 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x2c6e0ef993e3e848: from storage DS-290a7f2a-32af-42b2-89c3-1b2c2b279b33 node DatanodeRegistration(127.0.0.1:33452, datanodeUuid=ce121cb5-ea3a-4b2b-95c9-141da466dba7, infoPort=40179, infoSecurePort=0, ipcPort=37550, storageInfo=lv=-57;cid=testClusterID;nsid=1596799538;c=1606980160747), blocks: 0, hasStaleStorage: true, processing time: 2 msecs, invalidatedBlocks: 0
2020-12-03 07:22:46,888 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x2c6e0ef993e3e848: Processing first storage report for DS-e7b706cd-4e9c-48c6-b202-c15d8d57696f from datanode ce121cb5-ea3a-4b2b-95c9-141da466dba7
2020-12-03 07:22:46,888 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x2c6e0ef993e3e848: from storage DS-e7b706cd-4e9c-48c6-b202-c15d8d57696f node DatanodeRegistration(127.0.0.1:33452, datanodeUuid=ce121cb5-ea3a-4b2b-95c9-141da466dba7, infoPort=40179, infoSecurePort=0, ipcPort=37550, storageInfo=lv=-57;cid=testClusterID;nsid=1596799538;c=1606980160747), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:22:46,889 [BP-1235373120-172.17.0.3-1606980160747 heartbeating to localhost/127.0.0.1:41189] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x2c6e0ef993e3e848,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 8 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:22:46,891 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x1a4e54454b791892: Processing first storage report for DS-290a7f2a-32af-42b2-89c3-1b2c2b279b33 from datanode ce121cb5-ea3a-4b2b-95c9-141da466dba7
2020-12-03 07:22:46,891 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x1a4e54454b791892: from storage DS-290a7f2a-32af-42b2-89c3-1b2c2b279b33 node DatanodeRegistration(127.0.0.1:33452, datanodeUuid=ce121cb5-ea3a-4b2b-95c9-141da466dba7, infoPort=40179, infoSecurePort=0, ipcPort=37550, storageInfo=lv=-57;cid=testClusterID;nsid=1596799538;c=1606980160747), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:46,892 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x1a4e54454b791892: Processing first storage report for DS-e7b706cd-4e9c-48c6-b202-c15d8d57696f from datanode ce121cb5-ea3a-4b2b-95c9-141da466dba7
2020-12-03 07:22:46,892 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x1a4e54454b791892: from storage DS-e7b706cd-4e9c-48c6-b202-c15d8d57696f node DatanodeRegistration(127.0.0.1:33452, datanodeUuid=ce121cb5-ea3a-4b2b-95c9-141da466dba7, infoPort=40179, infoSecurePort=0, ipcPort=37550, storageInfo=lv=-57;cid=testClusterID;nsid=1596799538;c=1606980160747), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:46,895 [BP-1235373120-172.17.0.3-1606980160747 heartbeating to localhost/127.0.0.1:40615] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x1a4e54454b791892,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 7 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:22:46,926 [IPC Server handler 7 on default port 42246] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:46,937 [IPC Server handler 7 on default port 37628] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:46,946 [IPC Server handler 9 on default port 41189] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:46,959 [IPC Server handler 4 on default port 40615] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:46,961 [Listener at localhost/37550] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:22:46,971 [IPC Server handler 6 on default port 42246] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:46,978 [IPC Server handler 6 on default port 37628] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:46,997 [IPC Server handler 2 on default port 41189] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:47,007 [IPC Server handler 3 on default port 40615] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:47,010 [Listener at localhost/37550] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:22:47,064 [Listener at localhost/37550] INFO  router.RouterRpcServer (RouterRpcServer.java:<init>(251)) - RPC server binding to /0.0.0.0:0 with 10 handlers for Router null
2020-12-03 07:22:47,065 [Listener at localhost/37550] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:47,066 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:47,077 [Listener at 0.0.0.0/39265] INFO  router.ConnectionManager (ConnectionManager.java:<init>(120)) - Cleaning connection pools every 60 seconds
2020-12-03 07:22:47,078 [Listener at 0.0.0.0/39265] INFO  router.ConnectionManager (ConnectionManager.java:<init>(125)) - Cleaning connections every 10 seconds
2020-12-03 07:22:47,078 [Listener at 0.0.0.0/39265] INFO  router.ConnectionManager (ConnectionManager.java:start(139)) - Cleaning every 10 seconds
2020-12-03 07:22:47,099 [Listener at 0.0.0.0/39265] INFO  router.RouterAdminServer (RouterAdminServer.java:<init>(132)) - Admin server binding to 0.0.0.0:0
2020-12-03 07:22:47,100 [Listener at 0.0.0.0/39265] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 100, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:47,104 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:47,114 [Listener at 0.0.0.0/39104] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns0
2020-12-03 07:22:47,117 [Listener at 0.0.0.0/39104] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns0
2020-12-03 07:22:47,117 [Listener at 0.0.0.0/39104] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns0
2020-12-03 07:22:47,117 [Listener at 0.0.0.0/39104] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns1
2020-12-03 07:22:47,118 [Listener at 0.0.0.0/39104] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns1
2020-12-03 07:22:47,119 [Listener at 0.0.0.0/39104] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - Router metrics system started (again)
2020-12-03 07:22:47,137 [Listener at 0.0.0.0/39104] INFO  store.StateStoreService (StateStoreService.java:serviceInit(185)) - Registered StateStoreMBean: Hadoop:service=Router,name=StateStore
2020-12-03 07:22:47,138 [Listener at 0.0.0.0/39104] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.federation.router.cache.ttl(5000) assuming MILLISECONDS
2020-12-03 07:22:47,144 [Listener at 0.0.0.0/39104] INFO  metrics.FederationRPCPerformanceMonitor (FederationRPCPerformanceMonitor.java:init(91)) - Registered FederationRPCMBean: Hadoop:service=Router,name=FederationRPC
2020-12-03 07:22:47,152 [Listener at 0.0.0.0/39104] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn0 RPC address: 127.0.0.1:41189
2020-12-03 07:22:47,152 [Listener at 0.0.0.0/39104] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn0 Service RPC address: 127.0.0.1:41189
2020-12-03 07:22:47,152 [Listener at 0.0.0.0/39104] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn0 Lifeline RPC address: 127.0.0.1:41189
2020-12-03 07:22:47,152 [Listener at 0.0.0.0/39104] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn0 Web address: 127.0.0.1:46268
2020-12-03 07:22:47,153 [Listener at 0.0.0.0/39104] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn0 RPC address: 127.0.0.1:42246
2020-12-03 07:22:47,153 [Listener at 0.0.0.0/39104] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn0 Service RPC address: 127.0.0.1:42246
2020-12-03 07:22:47,153 [Listener at 0.0.0.0/39104] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn0 Lifeline RPC address: 127.0.0.1:42246
2020-12-03 07:22:47,154 [Listener at 0.0.0.0/39104] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn0 Web address: 127.0.0.1:33883
2020-12-03 07:22:47,154 [Listener at 0.0.0.0/39104] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn1 RPC address: 127.0.0.1:40615
2020-12-03 07:22:47,155 [Listener at 0.0.0.0/39104] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn1 Service RPC address: 127.0.0.1:40615
2020-12-03 07:22:47,155 [Listener at 0.0.0.0/39104] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn1 Lifeline RPC address: 127.0.0.1:40615
2020-12-03 07:22:47,155 [Listener at 0.0.0.0/39104] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn1 Web address: 127.0.0.1:43904
2020-12-03 07:22:47,156 [Listener at 0.0.0.0/39104] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn1 RPC address: 127.0.0.1:37628
2020-12-03 07:22:47,156 [Listener at 0.0.0.0/39104] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn1 Service RPC address: 127.0.0.1:37628
2020-12-03 07:22:47,156 [Listener at 0.0.0.0/39104] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn1 Lifeline RPC address: 127.0.0.1:37628
2020-12-03 07:22:47,156 [Listener at 0.0.0.0/39104] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn1 Web address: 127.0.0.1:45519
2020-12-03 07:22:47,177 [Listener at 0.0.0.0/39104] INFO  router.RouterRpcServer (RouterRpcServer.java:<init>(251)) - RPC server binding to /0.0.0.0:0 with 10 handlers for Router null
2020-12-03 07:22:47,179 [Listener at 0.0.0.0/39104] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:47,179 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:47,183 [Listener at 0.0.0.0/40691] INFO  router.ConnectionManager (ConnectionManager.java:<init>(120)) - Cleaning connection pools every 60 seconds
2020-12-03 07:22:47,183 [Listener at 0.0.0.0/40691] INFO  router.ConnectionManager (ConnectionManager.java:<init>(125)) - Cleaning connections every 10 seconds
2020-12-03 07:22:47,184 [Listener at 0.0.0.0/40691] INFO  router.ConnectionManager (ConnectionManager.java:start(139)) - Cleaning every 10 seconds
2020-12-03 07:22:47,185 [Listener at 0.0.0.0/40691] INFO  router.RouterAdminServer (RouterAdminServer.java:<init>(132)) - Admin server binding to 0.0.0.0:0
2020-12-03 07:22:47,186 [Listener at 0.0.0.0/40691] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 100, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:47,187 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:47,192 [Listener at 0.0.0.0/42910] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns0
2020-12-03 07:22:47,192 [Listener at 0.0.0.0/42910] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns0
2020-12-03 07:22:47,192 [Listener at 0.0.0.0/42910] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns0
2020-12-03 07:22:47,193 [Listener at 0.0.0.0/42910] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns1
2020-12-03 07:22:47,193 [Listener at 0.0.0.0/42910] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns1
2020-12-03 07:22:47,194 [Listener at 0.0.0.0/42910] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - Router metrics system started (again)
2020-12-03 07:22:47,199 [Listener at 0.0.0.0/42910] INFO  store.StateStoreService (StateStoreService.java:serviceInit(185)) - Registered StateStoreMBean: Hadoop:service=Router,name=StateStore-1
2020-12-03 07:22:47,200 [Listener at 0.0.0.0/42910] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.federation.router.cache.ttl(5000) assuming MILLISECONDS
2020-12-03 07:22:47,201 [Listener at 0.0.0.0/42910] INFO  metrics.FederationRPCPerformanceMonitor (FederationRPCPerformanceMonitor.java:init(91)) - Registered FederationRPCMBean: Hadoop:service=Router,name=FederationRPC-1
2020-12-03 07:22:47,202 [Listener at 0.0.0.0/42910] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn0 RPC address: 127.0.0.1:41189
2020-12-03 07:22:47,202 [Listener at 0.0.0.0/42910] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn0 Service RPC address: 127.0.0.1:41189
2020-12-03 07:22:47,203 [Listener at 0.0.0.0/42910] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn0 Lifeline RPC address: 127.0.0.1:41189
2020-12-03 07:22:47,203 [Listener at 0.0.0.0/42910] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn0 Web address: 127.0.0.1:46268
2020-12-03 07:22:47,204 [Listener at 0.0.0.0/42910] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn0 RPC address: 127.0.0.1:42246
2020-12-03 07:22:47,204 [Listener at 0.0.0.0/42910] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn0 Service RPC address: 127.0.0.1:42246
2020-12-03 07:22:47,204 [Listener at 0.0.0.0/42910] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn0 Lifeline RPC address: 127.0.0.1:42246
2020-12-03 07:22:47,204 [Listener at 0.0.0.0/42910] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn0 Web address: 127.0.0.1:33883
2020-12-03 07:22:47,205 [Listener at 0.0.0.0/42910] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn1 RPC address: 127.0.0.1:40615
2020-12-03 07:22:47,205 [Listener at 0.0.0.0/42910] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn1 Service RPC address: 127.0.0.1:40615
2020-12-03 07:22:47,205 [Listener at 0.0.0.0/42910] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn1 Lifeline RPC address: 127.0.0.1:40615
2020-12-03 07:22:47,205 [Listener at 0.0.0.0/42910] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn1 Web address: 127.0.0.1:43904
2020-12-03 07:22:47,206 [Listener at 0.0.0.0/42910] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn1 RPC address: 127.0.0.1:37628
2020-12-03 07:22:47,206 [Listener at 0.0.0.0/42910] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn1 Service RPC address: 127.0.0.1:37628
2020-12-03 07:22:47,206 [Listener at 0.0.0.0/42910] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn1 Lifeline RPC address: 127.0.0.1:37628
2020-12-03 07:22:47,206 [Listener at 0.0.0.0/42910] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn1 Web address: 127.0.0.1:45519
2020-12-03 07:22:47,227 [Listener at 0.0.0.0/42910] INFO  router.RouterRpcServer (RouterRpcServer.java:<init>(251)) - RPC server binding to /0.0.0.0:0 with 10 handlers for Router null
2020-12-03 07:22:47,228 [Listener at 0.0.0.0/42910] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:47,229 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:47,235 [Listener at 0.0.0.0/45164] INFO  router.ConnectionManager (ConnectionManager.java:<init>(120)) - Cleaning connection pools every 60 seconds
2020-12-03 07:22:47,235 [Listener at 0.0.0.0/45164] INFO  router.ConnectionManager (ConnectionManager.java:<init>(125)) - Cleaning connections every 10 seconds
2020-12-03 07:22:47,236 [Listener at 0.0.0.0/45164] INFO  router.ConnectionManager (ConnectionManager.java:start(139)) - Cleaning every 10 seconds
2020-12-03 07:22:47,237 [Listener at 0.0.0.0/45164] INFO  router.RouterAdminServer (RouterAdminServer.java:<init>(132)) - Admin server binding to 0.0.0.0:0
2020-12-03 07:22:47,238 [Listener at 0.0.0.0/45164] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 100, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:47,238 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:47,249 [Listener at 0.0.0.0/37266] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns1
2020-12-03 07:22:47,250 [Listener at 0.0.0.0/37266] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns0
2020-12-03 07:22:47,250 [Listener at 0.0.0.0/37266] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns0
2020-12-03 07:22:47,250 [Listener at 0.0.0.0/37266] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns1
2020-12-03 07:22:47,250 [Listener at 0.0.0.0/37266] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns1
2020-12-03 07:22:47,251 [Listener at 0.0.0.0/37266] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - Router metrics system started (again)
2020-12-03 07:22:47,252 [Listener at 0.0.0.0/37266] INFO  store.StateStoreService (StateStoreService.java:serviceInit(185)) - Registered StateStoreMBean: Hadoop:service=Router,name=StateStore-2
2020-12-03 07:22:47,252 [Listener at 0.0.0.0/37266] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.federation.router.cache.ttl(5000) assuming MILLISECONDS
2020-12-03 07:22:47,254 [Listener at 0.0.0.0/37266] INFO  metrics.FederationRPCPerformanceMonitor (FederationRPCPerformanceMonitor.java:init(91)) - Registered FederationRPCMBean: Hadoop:service=Router,name=FederationRPC-2
2020-12-03 07:22:47,255 [Listener at 0.0.0.0/37266] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn0 RPC address: 127.0.0.1:41189
2020-12-03 07:22:47,255 [Listener at 0.0.0.0/37266] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn0 Service RPC address: 127.0.0.1:41189
2020-12-03 07:22:47,255 [Listener at 0.0.0.0/37266] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn0 Lifeline RPC address: 127.0.0.1:41189
2020-12-03 07:22:47,255 [Listener at 0.0.0.0/37266] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn0 Web address: 127.0.0.1:46268
2020-12-03 07:22:47,256 [Listener at 0.0.0.0/37266] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn0 RPC address: 127.0.0.1:42246
2020-12-03 07:22:47,256 [Listener at 0.0.0.0/37266] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn0 Service RPC address: 127.0.0.1:42246
2020-12-03 07:22:47,256 [Listener at 0.0.0.0/37266] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn0 Lifeline RPC address: 127.0.0.1:42246
2020-12-03 07:22:47,257 [Listener at 0.0.0.0/37266] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn0 Web address: 127.0.0.1:33883
2020-12-03 07:22:47,257 [Listener at 0.0.0.0/37266] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn1 RPC address: 127.0.0.1:40615
2020-12-03 07:22:47,257 [Listener at 0.0.0.0/37266] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn1 Service RPC address: 127.0.0.1:40615
2020-12-03 07:22:47,258 [Listener at 0.0.0.0/37266] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn1 Lifeline RPC address: 127.0.0.1:40615
2020-12-03 07:22:47,258 [Listener at 0.0.0.0/37266] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn1 Web address: 127.0.0.1:43904
2020-12-03 07:22:47,259 [Listener at 0.0.0.0/37266] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn1 RPC address: 127.0.0.1:37628
2020-12-03 07:22:47,259 [Listener at 0.0.0.0/37266] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn1 Service RPC address: 127.0.0.1:37628
2020-12-03 07:22:47,259 [Listener at 0.0.0.0/37266] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn1 Lifeline RPC address: 127.0.0.1:37628
2020-12-03 07:22:47,259 [Listener at 0.0.0.0/37266] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn1 Web address: 127.0.0.1:45519
2020-12-03 07:22:47,280 [Listener at 0.0.0.0/37266] INFO  router.RouterRpcServer (RouterRpcServer.java:<init>(251)) - RPC server binding to /0.0.0.0:0 with 10 handlers for Router null
2020-12-03 07:22:47,281 [Listener at 0.0.0.0/37266] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:47,282 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:47,289 [Listener at 0.0.0.0/37277] INFO  router.ConnectionManager (ConnectionManager.java:<init>(120)) - Cleaning connection pools every 60 seconds
2020-12-03 07:22:47,289 [Listener at 0.0.0.0/37277] INFO  router.ConnectionManager (ConnectionManager.java:<init>(125)) - Cleaning connections every 10 seconds
2020-12-03 07:22:47,289 [Listener at 0.0.0.0/37277] INFO  router.ConnectionManager (ConnectionManager.java:start(139)) - Cleaning every 10 seconds
2020-12-03 07:22:47,291 [Listener at 0.0.0.0/37277] INFO  router.RouterAdminServer (RouterAdminServer.java:<init>(132)) - Admin server binding to 0.0.0.0:0
2020-12-03 07:22:47,293 [Listener at 0.0.0.0/37277] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 100, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:47,293 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:47,300 [Listener at 0.0.0.0/39111] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns1
2020-12-03 07:22:47,301 [Listener at 0.0.0.0/39111] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns0
2020-12-03 07:22:47,301 [Listener at 0.0.0.0/39111] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns0
2020-12-03 07:22:47,301 [Listener at 0.0.0.0/39111] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns1
2020-12-03 07:22:47,302 [Listener at 0.0.0.0/39111] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns1
2020-12-03 07:22:47,302 [Listener at 0.0.0.0/39111] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - Router metrics system started (again)
2020-12-03 07:22:47,303 [Listener at 0.0.0.0/39111] INFO  store.StateStoreService (StateStoreService.java:serviceInit(185)) - Registered StateStoreMBean: Hadoop:service=Router,name=StateStore-3
2020-12-03 07:22:47,304 [Listener at 0.0.0.0/39111] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.federation.router.cache.ttl(5000) assuming MILLISECONDS
2020-12-03 07:22:47,305 [Listener at 0.0.0.0/39111] INFO  metrics.FederationRPCPerformanceMonitor (FederationRPCPerformanceMonitor.java:init(91)) - Registered FederationRPCMBean: Hadoop:service=Router,name=FederationRPC-3
2020-12-03 07:22:47,307 [Listener at 0.0.0.0/39111] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn0 RPC address: 127.0.0.1:41189
2020-12-03 07:22:47,307 [Listener at 0.0.0.0/39111] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn0 Service RPC address: 127.0.0.1:41189
2020-12-03 07:22:47,308 [Listener at 0.0.0.0/39111] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn0 Lifeline RPC address: 127.0.0.1:41189
2020-12-03 07:22:47,308 [Listener at 0.0.0.0/39111] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn0 Web address: 127.0.0.1:46268
2020-12-03 07:22:47,308 [Listener at 0.0.0.0/39111] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn1 RPC address: 127.0.0.1:40615
2020-12-03 07:22:47,309 [Listener at 0.0.0.0/39111] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn1 Service RPC address: 127.0.0.1:40615
2020-12-03 07:22:47,309 [Listener at 0.0.0.0/39111] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn1 Lifeline RPC address: 127.0.0.1:40615
2020-12-03 07:22:47,309 [Listener at 0.0.0.0/39111] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn1 Web address: 127.0.0.1:43904
2020-12-03 07:22:47,310 [Listener at 0.0.0.0/39111] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn0 RPC address: 127.0.0.1:42246
2020-12-03 07:22:47,310 [Listener at 0.0.0.0/39111] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn0 Service RPC address: 127.0.0.1:42246
2020-12-03 07:22:47,310 [Listener at 0.0.0.0/39111] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn0 Lifeline RPC address: 127.0.0.1:42246
2020-12-03 07:22:47,310 [Listener at 0.0.0.0/39111] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn0 Web address: 127.0.0.1:33883
2020-12-03 07:22:47,311 [Listener at 0.0.0.0/39111] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn1 RPC address: 127.0.0.1:37628
2020-12-03 07:22:47,311 [Listener at 0.0.0.0/39111] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn1 Service RPC address: 127.0.0.1:37628
2020-12-03 07:22:47,311 [Listener at 0.0.0.0/39111] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn1 Lifeline RPC address: 127.0.0.1:37628
2020-12-03 07:22:47,312 [Listener at 0.0.0.0/39111] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn1 Web address: 127.0.0.1:45519
2020-12-03 07:22:47,320 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 1e0d9a01dc20:39265: State Store unavailable
2020-12-03 07:22:47,320 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2b917fb0] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:47,320 [Listener at 0.0.0.0/39111] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-12-03 07:22:47,324 [Listener at 0.0.0.0/39111] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.serviceStart(StateStoreService.java:197)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.service.CompositeService.serviceStart(CompositeService.java:121)
	at org.apache.hadoop.hdfs.server.federation.router.Router.serviceStart(Router.java:265)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.hdfs.server.federation.MiniRouterDFSCluster.startRouters(MiniRouterDFSCluster.java:757)
	at org.apache.hadoop.fs.contract.router.web.RouterWebHDFSContract.createCluster(RouterWebHDFSContract.java:69)
	at org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractCreate.createCluster(TestRouterWebHDFSContractCreate.java:37)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2020-12-03 07:22:47,332 [Listener at 0.0.0.0/39111] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-12-03 07:22:47,333 [Listener at 0.0.0.0/39111] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-12-03 07:22:47,333 [Listener at 0.0.0.0/39111] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreConnectionMonitorService
2020-12-03 07:22:47,334 [Listener at 0.0.0.0/39111] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreCacheUpdateService
2020-12-03 07:22:47,334 [StateStoreConnectionMonitorService-0] INFO  store.StateStoreConnectionMonitorService (StateStoreConnectionMonitorService.java:periodicInvoke(63)) - Attempting to open state store driver.
2020-12-03 07:22:47,336 [StateStoreConnectionMonitorService-0] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-12-03 07:22:47,337 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:47,337 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:47,339 [Listener at 0.0.0.0/39111] INFO  router.RouterRpcServer (RouterRpcServer.java:serviceStart(322)) - Router RPC up at: /0.0.0.0:39265
2020-12-03 07:22:47,352 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-12-03 07:22:47,354 [StateStoreConnectionMonitorService-0] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreConnectionMonitorService.periodicInvoke(StateStoreConnectionMonitorService.java:64)
	at org.apache.hadoop.hdfs.server.federation.router.PeriodicService$1.run(PeriodicService.java:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:22:47,355 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:47,358 [Listener at 0.0.0.0/39111] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for router at: http://0.0.0.0:0
2020-12-03 07:22:47,354 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:47,359 [Listener at 0.0.0.0/39111] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:47,362 [Listener at 0.0.0.0/39111] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:47,355 [StateStoreConnectionMonitorService-0] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-12-03 07:22:47,363 [StateStoreConnectionMonitorService-0] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-12-03 07:22:47,363 [Listener at 0.0.0.0/39111] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.router is not defined
2020-12-03 07:22:47,363 [Listener at 0.0.0.0/39111] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:47,365 [Listener at 0.0.0.0/39111] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:47,366 [Listener at 0.0.0.0/39111] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context router
2020-12-03 07:22:47,366 [Listener at 0.0.0.0/39111] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:47,366 [Listener at 0.0.0.0/39111] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:47,369 [Listener at 0.0.0.0/39111] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:22:47,369 [Listener at 0.0.0.0/39111] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.federation.router;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:22:47,370 [Listener at 0.0.0.0/39111] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 35188
2020-12-03 07:22:47,370 [Listener at 0.0.0.0/39111] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:47,374 [Listener at 0.0.0.0/39111] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@69fa8e76{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:22:47,374 [Listener at 0.0.0.0/39111] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@31f20c9f{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:47,383 [Listener at 0.0.0.0/39111] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@71cb3139{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/router/,AVAILABLE}{/router}
2020-12-03 07:22:47,384 [Listener at 0.0.0.0/39111] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1639f93a{HTTP/1.1,[http/1.1]}{0.0.0.0:35188}
2020-12-03 07:22:47,384 [Listener at 0.0.0.0/39111] INFO  server.Server (Server.java:doStart(419)) - Started @12546ms
2020-12-03 07:22:47,384 [Listener at 0.0.0.0/39111] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn0
2020-12-03 07:22:47,385 [Listener at 0.0.0.0/39111] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn0
2020-12-03 07:22:47,385 [Listener at 0.0.0.0/39111] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn1
2020-12-03 07:22:47,385 [Listener at 0.0.0.0/39111] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn1
2020-12-03 07:22:47,386 [Listener at 0.0.0.0/39111] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service RouterHeartbeatService
2020-12-03 07:22:47,388 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 1e0d9a01dc20:39265: State Store unavailable
2020-12-03 07:22:47,397 [Listener at 0.0.0.0/39111] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(117)) - Registered FSNamesystem MBean: Hadoop:service=NameNode,name=FSNamesystem-4
2020-12-03 07:22:47,404 [Listener at 0.0.0.0/39111] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(126)) - Registered FSNamesystemState MBean: Hadoop:service=NameNode,name=FSNamesystemState-4
2020-12-03 07:22:47,411 [Listener at 0.0.0.0/39111] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(134)) - Registered NameNodeInfo MBean: Hadoop:service=NameNode,name=NameNodeInfo-4
2020-12-03 07:22:47,411 [Listener at 0.0.0.0/39111] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(143)) - Registered NameNodeStatus MBean: Hadoop:service=NameNode,name=NameNodeStatus-4
2020-12-03 07:22:47,417 [Listener at 0.0.0.0/39111] INFO  metrics.FederationMetrics (FederationMetrics.java:<init>(126)) - Registered Router MBean: Hadoop:service=Router,name=FederationState
2020-12-03 07:22:47,417 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 1e0d9a01dc20:40691: State Store unavailable
2020-12-03 07:22:47,418 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2eaef76d] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:47,418 [Listener at 0.0.0.0/39111] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-12-03 07:22:47,419 [Listener at 0.0.0.0/39111] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.serviceStart(StateStoreService.java:197)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.service.CompositeService.serviceStart(CompositeService.java:121)
	at org.apache.hadoop.hdfs.server.federation.router.Router.serviceStart(Router.java:265)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.hdfs.server.federation.MiniRouterDFSCluster.startRouters(MiniRouterDFSCluster.java:757)
	at org.apache.hadoop.fs.contract.router.web.RouterWebHDFSContract.createCluster(RouterWebHDFSContract.java:69)
	at org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractCreate.createCluster(TestRouterWebHDFSContractCreate.java:37)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2020-12-03 07:22:47,419 [Listener at 0.0.0.0/39111] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-12-03 07:22:47,420 [Listener at 0.0.0.0/39111] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-12-03 07:22:47,420 [Listener at 0.0.0.0/39111] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreConnectionMonitorService
2020-12-03 07:22:47,421 [Listener at 0.0.0.0/39111] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreCacheUpdateService
2020-12-03 07:22:47,421 [StateStoreConnectionMonitorService-0] INFO  store.StateStoreConnectionMonitorService (StateStoreConnectionMonitorService.java:periodicInvoke(63)) - Attempting to open state store driver.
2020-12-03 07:22:47,422 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-12-03 07:22:47,422 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:47,422 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:47,423 [Listener at 0.0.0.0/39111] INFO  router.RouterRpcServer (RouterRpcServer.java:serviceStart(322)) - Router RPC up at: /0.0.0.0:40691
2020-12-03 07:22:47,425 [StateStoreConnectionMonitorService-0] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-12-03 07:22:47,425 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:47,426 [StateStoreConnectionMonitorService-0] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreConnectionMonitorService.periodicInvoke(StateStoreConnectionMonitorService.java:64)
	at org.apache.hadoop.hdfs.server.federation.router.PeriodicService$1.run(PeriodicService.java:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:22:47,425 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:47,432 [StateStoreConnectionMonitorService-0] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-12-03 07:22:47,435 [Listener at 0.0.0.0/39111] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for router at: http://0.0.0.0:0
2020-12-03 07:22:47,435 [StateStoreConnectionMonitorService-0] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-12-03 07:22:47,435 [Listener at 0.0.0.0/39111] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:47,437 [Listener at 0.0.0.0/39111] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:47,437 [Listener at 0.0.0.0/39111] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.router is not defined
2020-12-03 07:22:47,438 [Listener at 0.0.0.0/39111] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:47,440 [Listener at 0.0.0.0/39111] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:47,440 [Listener at 0.0.0.0/39111] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context router
2020-12-03 07:22:47,440 [Listener at 0.0.0.0/39111] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:47,440 [Listener at 0.0.0.0/39111] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:47,442 [Listener at 0.0.0.0/39111] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:22:47,442 [Listener at 0.0.0.0/39111] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.federation.router;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:22:47,443 [Listener at 0.0.0.0/39111] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 46087
2020-12-03 07:22:47,443 [Listener at 0.0.0.0/39111] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:47,446 [Listener at 0.0.0.0/39111] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1da4b6b3{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:22:47,446 [Listener at 0.0.0.0/39111] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7e1f584d{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:47,454 [Listener at 0.0.0.0/39111] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@46d567cb{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/router/,AVAILABLE}{/router}
2020-12-03 07:22:47,463 [Listener at 0.0.0.0/39111] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@363a3d15{HTTP/1.1,[http/1.1]}{0.0.0.0:46087}
2020-12-03 07:22:47,464 [Listener at 0.0.0.0/39111] INFO  server.Server (Server.java:doStart(419)) - Started @12625ms
2020-12-03 07:22:47,464 [Listener at 0.0.0.0/39111] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn0
2020-12-03 07:22:47,464 [Listener at 0.0.0.0/39111] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn0
2020-12-03 07:22:47,465 [Listener at 0.0.0.0/39111] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn1
2020-12-03 07:22:47,465 [Listener at 0.0.0.0/39111] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn1
2020-12-03 07:22:47,479 [Listener at 0.0.0.0/39111] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service RouterHeartbeatService
2020-12-03 07:22:47,482 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 1e0d9a01dc20:40691: State Store unavailable
2020-12-03 07:22:47,482 [Listener at 0.0.0.0/39111] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(117)) - Registered FSNamesystem MBean: Hadoop:service=NameNode,name=FSNamesystem-5
2020-12-03 07:22:47,482 [Listener at 0.0.0.0/39111] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(126)) - Registered FSNamesystemState MBean: Hadoop:service=NameNode,name=FSNamesystemState-5
2020-12-03 07:22:47,483 [Listener at 0.0.0.0/39111] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(134)) - Registered NameNodeInfo MBean: Hadoop:service=NameNode,name=NameNodeInfo-5
2020-12-03 07:22:47,483 [Listener at 0.0.0.0/39111] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(143)) - Registered NameNodeStatus MBean: Hadoop:service=NameNode,name=NameNodeStatus-5
2020-12-03 07:22:47,483 [Listener at 0.0.0.0/39111] INFO  metrics.FederationMetrics (FederationMetrics.java:<init>(126)) - Registered Router MBean: Hadoop:service=Router,name=FederationState-1
2020-12-03 07:22:47,484 [Listener at 0.0.0.0/39111] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-12-03 07:22:47,484 [Listener at 0.0.0.0/39111] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.serviceStart(StateStoreService.java:197)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.service.CompositeService.serviceStart(CompositeService.java:121)
	at org.apache.hadoop.hdfs.server.federation.router.Router.serviceStart(Router.java:265)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.hdfs.server.federation.MiniRouterDFSCluster.startRouters(MiniRouterDFSCluster.java:757)
	at org.apache.hadoop.fs.contract.router.web.RouterWebHDFSContract.createCluster(RouterWebHDFSContract.java:69)
	at org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractCreate.createCluster(TestRouterWebHDFSContractCreate.java:37)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2020-12-03 07:22:47,485 [Listener at 0.0.0.0/39111] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-12-03 07:22:47,485 [Listener at 0.0.0.0/39111] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-12-03 07:22:47,485 [Listener at 0.0.0.0/39111] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreConnectionMonitorService
2020-12-03 07:22:47,488 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 1e0d9a01dc20:45164: State Store unavailable
2020-12-03 07:22:47,488 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4efc25fc] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:47,488 [Listener at 0.0.0.0/39111] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreCacheUpdateService
2020-12-03 07:22:47,488 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-12-03 07:22:47,489 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:47,509 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:47,489 [StateStoreConnectionMonitorService-0] INFO  store.StateStoreConnectionMonitorService (StateStoreConnectionMonitorService.java:periodicInvoke(63)) - Attempting to open state store driver.
2020-12-03 07:22:47,516 [StateStoreConnectionMonitorService-0] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-12-03 07:22:47,518 [StateStoreConnectionMonitorService-0] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreConnectionMonitorService.periodicInvoke(StateStoreConnectionMonitorService.java:64)
	at org.apache.hadoop.hdfs.server.federation.router.PeriodicService$1.run(PeriodicService.java:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:22:47,521 [StateStoreConnectionMonitorService-0] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-12-03 07:22:47,521 [StateStoreConnectionMonitorService-0] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-12-03 07:22:47,528 [Listener at 0.0.0.0/39111] INFO  router.RouterRpcServer (RouterRpcServer.java:serviceStart(322)) - Router RPC up at: /0.0.0.0:45164
2020-12-03 07:22:47,541 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:47,541 [Listener at 0.0.0.0/39111] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for router at: http://0.0.0.0:0
2020-12-03 07:22:47,543 [Listener at 0.0.0.0/39111] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:47,543 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:47,549 [Listener at 0.0.0.0/39111] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:47,550 [Listener at 0.0.0.0/39111] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.router is not defined
2020-12-03 07:22:47,550 [Listener at 0.0.0.0/39111] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:47,558 [Listener at 0.0.0.0/39111] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:47,559 [Listener at 0.0.0.0/39111] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context router
2020-12-03 07:22:47,561 [Listener at 0.0.0.0/39111] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:47,562 [Listener at 0.0.0.0/39111] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:47,564 [Listener at 0.0.0.0/39111] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:22:47,564 [Listener at 0.0.0.0/39111] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.federation.router;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:22:47,564 [Listener at 0.0.0.0/39111] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 37750
2020-12-03 07:22:47,564 [Listener at 0.0.0.0/39111] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:47,568 [Listener at 0.0.0.0/39111] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5176d279{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:22:47,569 [Listener at 0.0.0.0/39111] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@d74bac4{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:47,575 [Listener at 0.0.0.0/39111] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@4c59e45e{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/router/,AVAILABLE}{/router}
2020-12-03 07:22:47,576 [Listener at 0.0.0.0/39111] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@58ec7116{HTTP/1.1,[http/1.1]}{0.0.0.0:37750}
2020-12-03 07:22:47,577 [Listener at 0.0.0.0/39111] INFO  server.Server (Server.java:doStart(419)) - Started @12738ms
2020-12-03 07:22:47,577 [Listener at 0.0.0.0/39111] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn0
2020-12-03 07:22:47,578 [Listener at 0.0.0.0/39111] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn0
2020-12-03 07:22:47,587 [Listener at 0.0.0.0/39111] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn1
2020-12-03 07:22:47,588 [Listener at 0.0.0.0/39111] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn1
2020-12-03 07:22:47,588 [Listener at 0.0.0.0/39111] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service RouterHeartbeatService
2020-12-03 07:22:47,592 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 1e0d9a01dc20:45164: State Store unavailable
2020-12-03 07:22:47,592 [Listener at 0.0.0.0/39111] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(117)) - Registered FSNamesystem MBean: Hadoop:service=NameNode,name=FSNamesystem-6
2020-12-03 07:22:47,592 [Listener at 0.0.0.0/39111] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(126)) - Registered FSNamesystemState MBean: Hadoop:service=NameNode,name=FSNamesystemState-6
2020-12-03 07:22:47,593 [Listener at 0.0.0.0/39111] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(134)) - Registered NameNodeInfo MBean: Hadoop:service=NameNode,name=NameNodeInfo-6
2020-12-03 07:22:47,593 [Listener at 0.0.0.0/39111] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(143)) - Registered NameNodeStatus MBean: Hadoop:service=NameNode,name=NameNodeStatus-6
2020-12-03 07:22:47,593 [Listener at 0.0.0.0/39111] INFO  metrics.FederationMetrics (FederationMetrics.java:<init>(126)) - Registered Router MBean: Hadoop:service=Router,name=FederationState-2
2020-12-03 07:22:47,594 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 1e0d9a01dc20:37277: State Store unavailable
2020-12-03 07:22:47,594 [Listener at 0.0.0.0/39111] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-12-03 07:22:47,594 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@36fcf6c0] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:47,594 [Listener at 0.0.0.0/39111] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.serviceStart(StateStoreService.java:197)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.service.CompositeService.serviceStart(CompositeService.java:121)
	at org.apache.hadoop.hdfs.server.federation.router.Router.serviceStart(Router.java:265)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.hdfs.server.federation.MiniRouterDFSCluster.startRouters(MiniRouterDFSCluster.java:757)
	at org.apache.hadoop.fs.contract.router.web.RouterWebHDFSContract.createCluster(RouterWebHDFSContract.java:69)
	at org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractCreate.createCluster(TestRouterWebHDFSContractCreate.java:37)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2020-12-03 07:22:47,597 [Listener at 0.0.0.0/39111] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-12-03 07:22:47,597 [Listener at 0.0.0.0/39111] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-12-03 07:22:47,597 [Listener at 0.0.0.0/39111] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreConnectionMonitorService
2020-12-03 07:22:47,600 [IPC Server handler 4 on default port 37628] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:47,602 [Listener at 0.0.0.0/39111] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreCacheUpdateService
2020-12-03 07:22:47,602 [StateStoreConnectionMonitorService-0] INFO  store.StateStoreConnectionMonitorService (StateStoreConnectionMonitorService.java:periodicInvoke(63)) - Attempting to open state store driver.
2020-12-03 07:22:47,602 [IPC Server handler 5 on default port 40615] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:47,602 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-12-03 07:22:47,602 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:47,603 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:47,603 [IPC Server handler 5 on default port 42246] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:47,603 [IPC Server handler 0 on default port 41189] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:47,603 [IPC Server handler 7 on default port 41189] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:47,604 [IPC Server handler 3 on default port 42246] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:47,604 [IPC Server handler 1 on default port 42246] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:47,604 [IPC Server handler 9 on default port 40615] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:47,604 [IPC Server handler 1 on default port 40615] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:47,612 [IPC Server handler 2 on default port 37628] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:47,613 [Listener at 0.0.0.0/39111] INFO  router.RouterRpcServer (RouterRpcServer.java:serviceStart(322)) - Router RPC up at: /0.0.0.0:37277
2020-12-03 07:22:47,612 [IPC Server handler 3 on default port 37628] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:47,613 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:47,613 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:47,641 [StateStoreConnectionMonitorService-0] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-12-03 07:22:47,651 [Listener at 0.0.0.0/39111] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for router at: http://0.0.0.0:0
2020-12-03 07:22:47,652 [Listener at 0.0.0.0/39111] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:47,653 [StateStoreConnectionMonitorService-0] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreConnectionMonitorService.periodicInvoke(StateStoreConnectionMonitorService.java:64)
	at org.apache.hadoop.hdfs.server.federation.router.PeriodicService$1.run(PeriodicService.java:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:22:47,653 [StateStoreConnectionMonitorService-0] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-12-03 07:22:47,653 [StateStoreConnectionMonitorService-0] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-12-03 07:22:47,654 [Listener at 0.0.0.0/39111] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:47,654 [IPC Server handler 1 on default port 41189] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:47,655 [Listener at 0.0.0.0/39111] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.router is not defined
2020-12-03 07:22:47,655 [Listener at 0.0.0.0/39111] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:47,658 [Listener at 0.0.0.0/39111] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:47,659 [Listener at 0.0.0.0/39111] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context router
2020-12-03 07:22:47,659 [Listener at 0.0.0.0/39111] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:47,659 [Listener at 0.0.0.0/39111] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:47,661 [Listener at 0.0.0.0/39111] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:22:47,661 [Listener at 0.0.0.0/39111] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.federation.router;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:22:47,662 [Listener at 0.0.0.0/39111] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 34470
2020-12-03 07:22:47,662 [Listener at 0.0.0.0/39111] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:47,671 [Listener at 0.0.0.0/39111] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@68217d41{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:22:47,673 [Listener at 0.0.0.0/39111] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3e5d4f6b{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:47,841 [Listener at 0.0.0.0/39111] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@39e43310{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/router/,AVAILABLE}{/router}
2020-12-03 07:22:47,868 [Listener at 0.0.0.0/39111] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@eb507b9{HTTP/1.1,[http/1.1]}{0.0.0.0:34470}
2020-12-03 07:22:47,869 [Listener at 0.0.0.0/39111] INFO  server.Server (Server.java:doStart(419)) - Started @13030ms
2020-12-03 07:22:47,869 [Listener at 0.0.0.0/39111] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn0
2020-12-03 07:22:47,869 [Listener at 0.0.0.0/39111] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn1
2020-12-03 07:22:47,870 [Listener at 0.0.0.0/39111] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn0
2020-12-03 07:22:47,875 [Listener at 0.0.0.0/39111] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn1
2020-12-03 07:22:47,876 [Listener at 0.0.0.0/39111] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service RouterHeartbeatService
2020-12-03 07:22:47,880 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 1e0d9a01dc20:37277: State Store unavailable
2020-12-03 07:22:47,887 [IPC Server handler 6 on default port 42246] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:47,887 [IPC Server handler 9 on default port 41189] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:47,893 [Listener at 0.0.0.0/39111] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(117)) - Registered FSNamesystem MBean: Hadoop:service=NameNode,name=FSNamesystem-7
2020-12-03 07:22:47,894 [Listener at 0.0.0.0/39111] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(126)) - Registered FSNamesystemState MBean: Hadoop:service=NameNode,name=FSNamesystemState-7
2020-12-03 07:22:47,894 [Listener at 0.0.0.0/39111] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(134)) - Registered NameNodeInfo MBean: Hadoop:service=NameNode,name=NameNodeInfo-7
2020-12-03 07:22:47,894 [Listener at 0.0.0.0/39111] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(143)) - Registered NameNodeStatus MBean: Hadoop:service=NameNode,name=NameNodeStatus-7
2020-12-03 07:22:47,895 [Listener at 0.0.0.0/39111] INFO  metrics.FederationMetrics (FederationMetrics.java:<init>(126)) - Registered Router MBean: Hadoop:service=Router,name=FederationState-3
2020-12-03 07:22:47,898 [IPC Server handler 4 on default port 40615] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:47,928 [IPC Server handler 6 on default port 37628] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:47,936 [Listener at 0.0.0.0/39111] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:22:47,937 [Edit log tailer] WARN  ha.EditLogTailer (EditLogTailer.java:doWork(528)) - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.sleep(EditLogTailer.java:433)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:526)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:440)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:457)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:484)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:453)
2020-12-03 07:22:47,938 [Listener at 0.0.0.0/39111] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:22:47,950 [Listener at 0.0.0.0/39111] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-0-through-1/current
2020-12-03 07:22:47,951 [Listener at 0.0.0.0/39111] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current
2020-12-03 07:22:47,951 [Listener at 0.0.0.0/39111] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/current
2020-12-03 07:22:47,954 [Listener at 0.0.0.0/39111] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1233)) - Catching up to latest edits from old active before taking over writer role in edits logs
2020-12-03 07:22:47,956 [Listener at 0.0.0.0/39111] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:markAllDatanodesStale(1840)) - Marking all datanodes as stale
2020-12-03 07:22:47,999 [Listener at 0.0.0.0/39111] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1244)) - Reprocessing replication and invalidation queues
2020-12-03 07:22:47,999 [Listener at 0.0.0.0/39111] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:22:48,000 [Listener at 0.0.0.0/39111] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1255)) - Will take over writing edit logs at txnid 1
2020-12-03 07:22:48,001 [Listener at 0.0.0.0/39111] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 1
2020-12-03 07:22:48,062 [Listener at 0.0.0.0/39111] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:22:48,092 [Listener at 0.0.0.0/39111] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 30 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:22:48,132 [Listener at 0.0.0.0/39111] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:22:48,137 [CacheReplicationMonitor(66061390)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:22:48,133 [Edit log tailer] WARN  ha.EditLogTailer (EditLogTailer.java:doWork(528)) - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.sleep(EditLogTailer.java:433)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:526)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:440)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:457)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:484)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:453)
2020-12-03 07:22:48,137 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 0
2020-12-03 07:22:48,138 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:22:48,138 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:22:48,138 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:22:48,138 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:22:48,138 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 137 msec
2020-12-03 07:22:48,138 [Listener at 0.0.0.0/39111] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:22:48,140 [Listener at 0.0.0.0/39111] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-2-through-3/current
2020-12-03 07:22:48,140 [Listener at 0.0.0.0/39111] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/current
2020-12-03 07:22:48,140 [Listener at 0.0.0.0/39111] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6/current
2020-12-03 07:22:48,140 [Listener at 0.0.0.0/39111] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1233)) - Catching up to latest edits from old active before taking over writer role in edits logs
2020-12-03 07:22:48,172 [Listener at 0.0.0.0/39111] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:markAllDatanodesStale(1840)) - Marking all datanodes as stale
2020-12-03 07:22:48,218 [Listener at 0.0.0.0/39111] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1244)) - Reprocessing replication and invalidation queues
2020-12-03 07:22:48,219 [Listener at 0.0.0.0/39111] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:22:48,219 [Listener at 0.0.0.0/39111] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1255)) - Will take over writing edit logs at txnid 1
2020-12-03 07:22:48,220 [Listener at 0.0.0.0/39111] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 1
2020-12-03 07:22:48,236 [Listener at 0.0.0.0/39111] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:22:48,247 [Listener at 0.0.0.0/39111] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 10 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:22:48,293 [CacheReplicationMonitor(1948833993)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:22:48,297 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 0
2020-12-03 07:22:48,297 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:22:48,297 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:22:48,298 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:22:48,298 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:22:48,298 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 78 msec
2020-12-03 07:22:49,339 [Thread-474] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = webhdfs://0.0.0.0:46087 implemented by org.apache.hadoop.hdfs.web.WebHdfsFileSystem@6e3517fd
Dec 03, 2020 7:22:49 AM com.sun.jersey.api.core.PackagesResourceConfig init
INFO: Scanning for root resource and provider classes in the packages:
  org.apache.hadoop.hdfs.server.federation.router
  org.apache.hadoop.hdfs.web.resources
2020-12-03 07:22:49,516 [BP-1235373120-172.17.0.3-1606980160747 heartbeating to localhost/127.0.0.1:41189] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-1235373120-172.17.0.3-1606980160747 (Datanode Uuid da8c2a33-61a0-489f-ae14-f61765804689) service to localhost/127.0.0.1:41189 trying to claim ACTIVE state with txid=1
2020-12-03 07:22:49,517 [BP-1235373120-172.17.0.3-1606980160747 heartbeating to localhost/127.0.0.1:41189] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-1235373120-172.17.0.3-1606980160747 (Datanode Uuid da8c2a33-61a0-489f-ae14-f61765804689) service to localhost/127.0.0.1:41189
2020-12-03 07:22:49,516 [BP-1217207052-172.17.0.3-1606980156864 heartbeating to localhost/127.0.0.1:42246] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-1217207052-172.17.0.3-1606980156864 (Datanode Uuid da8c2a33-61a0-489f-ae14-f61765804689) service to localhost/127.0.0.1:42246 trying to claim ACTIVE state with txid=1
2020-12-03 07:22:49,517 [BP-1217207052-172.17.0.3-1606980156864 heartbeating to localhost/127.0.0.1:42246] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-1217207052-172.17.0.3-1606980156864 (Datanode Uuid da8c2a33-61a0-489f-ae14-f61765804689) service to localhost/127.0.0.1:42246
2020-12-03 07:22:49,519 [BP-1217207052-172.17.0.3-1606980156864 heartbeating to localhost/127.0.0.1:42246] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-1217207052-172.17.0.3-1606980156864 (Datanode Uuid cf6dffe3-142c-4551-9b92-aa40255ddbb7) service to localhost/127.0.0.1:42246 trying to claim ACTIVE state with txid=1
2020-12-03 07:22:49,519 [BP-1217207052-172.17.0.3-1606980156864 heartbeating to localhost/127.0.0.1:42246] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-1217207052-172.17.0.3-1606980156864 (Datanode Uuid cf6dffe3-142c-4551-9b92-aa40255ddbb7) service to localhost/127.0.0.1:42246
2020-12-03 07:22:49,533 [BP-1235373120-172.17.0.3-1606980160747 heartbeating to localhost/127.0.0.1:41189] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-1235373120-172.17.0.3-1606980160747 (Datanode Uuid cf6dffe3-142c-4551-9b92-aa40255ddbb7) service to localhost/127.0.0.1:41189 trying to claim ACTIVE state with txid=1
2020-12-03 07:22:49,533 [BP-1235373120-172.17.0.3-1606980160747 heartbeating to localhost/127.0.0.1:41189] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-1235373120-172.17.0.3-1606980160747 (Datanode Uuid cf6dffe3-142c-4551-9b92-aa40255ddbb7) service to localhost/127.0.0.1:41189
2020-12-03 07:22:49,652 [BP-1217207052-172.17.0.3-1606980156864 heartbeating to localhost/127.0.0.1:42246] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-1217207052-172.17.0.3-1606980156864 (Datanode Uuid f47a982f-3e85-4226-b9b0-c434f3f5cab7) service to localhost/127.0.0.1:42246 trying to claim ACTIVE state with txid=1
2020-12-03 07:22:49,652 [BP-1217207052-172.17.0.3-1606980156864 heartbeating to localhost/127.0.0.1:42246] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-1217207052-172.17.0.3-1606980156864 (Datanode Uuid f47a982f-3e85-4226-b9b0-c434f3f5cab7) service to localhost/127.0.0.1:42246
2020-12-03 07:22:49,727 [BP-1235373120-172.17.0.3-1606980160747 heartbeating to localhost/127.0.0.1:41189] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-1235373120-172.17.0.3-1606980160747 (Datanode Uuid f47a982f-3e85-4226-b9b0-c434f3f5cab7) service to localhost/127.0.0.1:41189 trying to claim ACTIVE state with txid=1
2020-12-03 07:22:49,728 [BP-1235373120-172.17.0.3-1606980160747 heartbeating to localhost/127.0.0.1:41189] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-1235373120-172.17.0.3-1606980160747 (Datanode Uuid f47a982f-3e85-4226-b9b0-c434f3f5cab7) service to localhost/127.0.0.1:41189
2020-12-03 07:22:49,850 [BP-1217207052-172.17.0.3-1606980156864 heartbeating to localhost/127.0.0.1:42246] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-1217207052-172.17.0.3-1606980156864 (Datanode Uuid ce121cb5-ea3a-4b2b-95c9-141da466dba7) service to localhost/127.0.0.1:42246 trying to claim ACTIVE state with txid=1
2020-12-03 07:22:49,851 [BP-1217207052-172.17.0.3-1606980156864 heartbeating to localhost/127.0.0.1:42246] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-1217207052-172.17.0.3-1606980156864 (Datanode Uuid ce121cb5-ea3a-4b2b-95c9-141da466dba7) service to localhost/127.0.0.1:42246
2020-12-03 07:22:49,882 [BP-1235373120-172.17.0.3-1606980160747 heartbeating to localhost/127.0.0.1:41189] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-1235373120-172.17.0.3-1606980160747 (Datanode Uuid ce121cb5-ea3a-4b2b-95c9-141da466dba7) service to localhost/127.0.0.1:41189 trying to claim ACTIVE state with txid=1
2020-12-03 07:22:49,884 [BP-1235373120-172.17.0.3-1606980160747 heartbeating to localhost/127.0.0.1:41189] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-1235373120-172.17.0.3-1606980160747 (Datanode Uuid ce121cb5-ea3a-4b2b-95c9-141da466dba7) service to localhost/127.0.0.1:41189
Dec 03, 2020 7:22:50 AM com.sun.jersey.api.core.ScanningResourceConfig logClasses
INFO: Root resource classes found:
  class org.apache.hadoop.hdfs.server.federation.router.RouterWebHdfsMethods
Dec 03, 2020 7:22:50 AM com.sun.jersey.api.core.ScanningResourceConfig logClasses
INFO: Provider classes found:
  class org.apache.hadoop.hdfs.web.resources.ExceptionHandler
  class org.apache.hadoop.hdfs.web.resources.UserProvider
Dec 03, 2020 7:22:50 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
Dec 03, 2020 7:22:51 AM com.sun.jersey.spi.inject.Errors processErrorMessages
WARNING: The following warnings have been detected with resource and/or provider classes:
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.putRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.PutOpParam,org.apache.hadoop.hdfs.web.resources.DestinationParam,org.apache.hadoop.hdfs.web.resources.OwnerParam,org.apache.hadoop.hdfs.web.resources.GroupParam,org.apache.hadoop.hdfs.web.resources.PermissionParam,org.apache.hadoop.hdfs.web.resources.UnmaskedPermissionParam,org.apache.hadoop.hdfs.web.resources.OverwriteParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,org.apache.hadoop.hdfs.web.resources.ReplicationParam,org.apache.hadoop.hdfs.web.resources.BlockSizeParam,org.apache.hadoop.hdfs.web.resources.ModificationTimeParam,org.apache.hadoop.hdfs.web.resources.AccessTimeParam,org.apache.hadoop.hdfs.web.resources.RenameOptionSetParam,org.apache.hadoop.hdfs.web.resources.CreateParentParam,org.apache.hadoop.hdfs.web.resources.TokenArgumentParam,org.apache.hadoop.hdfs.web.resources.AclPermissionParam,org.apache.hadoop.hdfs.web.resources.XAttrNameParam,org.apache.hadoop.hdfs.web.resources.XAttrValueParam,org.apache.hadoop.hdfs.web.resources.XAttrSetFlagParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam,org.apache.hadoop.hdfs.web.resources.OldSnapshotNameParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.CreateFlagParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam,org.apache.hadoop.hdfs.web.resources.StoragePolicyParam,org.apache.hadoop.hdfs.web.resources.ECPolicyParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.postRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.PostOpParam,org.apache.hadoop.hdfs.web.resources.ConcatSourcesParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.NewLengthParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.deleteRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.DeleteOpParam,org.apache.hadoop.hdfs.web.resources.RecursiveParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.getRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.GetOpParam,org.apache.hadoop.hdfs.web.resources.OffsetParam,org.apache.hadoop.hdfs.web.resources.LengthParam,org.apache.hadoop.hdfs.web.resources.RenewerParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,java.util.List,org.apache.hadoop.hdfs.web.resources.XAttrEncodingParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.FsActionParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam,org.apache.hadoop.hdfs.web.resources.OldSnapshotNameParam,org.apache.hadoop.hdfs.web.resources.TokenKindParam,org.apache.hadoop.hdfs.web.resources.TokenServiceParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam,org.apache.hadoop.hdfs.web.resources.StartAfterParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
2020-12-03 07:22:51,539 [IPC Server handler 2 on default port 42246] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:22:51,614 [Thread-474] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - verify that a newly created file exists as soon as open returns
Dec 03, 2020 7:22:51 AM com.sun.jersey.api.core.PackagesResourceConfig init
INFO: Scanning for root resource and provider classes in the packages:
  org.apache.hadoop.hdfs.server.namenode.web.resources
  org.apache.hadoop.hdfs.web.resources
2020-12-03 07:22:52,354 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-12-03 07:22:52,389 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 1e0d9a01dc20:39265: State Store unavailable
2020-12-03 07:22:52,423 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-12-03 07:22:52,482 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 1e0d9a01dc20:40691: State Store unavailable
2020-12-03 07:22:52,489 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-12-03 07:22:52,594 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 1e0d9a01dc20:45164: State Store unavailable
2020-12-03 07:22:52,603 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
Dec 03, 2020 7:22:52 AM com.sun.jersey.api.core.ScanningResourceConfig logClasses
INFO: Root resource classes found:
  class org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods
Dec 03, 2020 7:22:52 AM com.sun.jersey.api.core.ScanningResourceConfig logClasses
INFO: Provider classes found:
  class org.apache.hadoop.hdfs.web.resources.ExceptionHandler
  class org.apache.hadoop.hdfs.web.resources.UserProvider
Dec 03, 2020 7:22:52 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
2020-12-03 07:22:52,883 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 1e0d9a01dc20:37277: State Store unavailable
Dec 03, 2020 7:22:53 AM com.sun.jersey.spi.inject.Errors processErrorMessages
WARNING: The following warnings have been detected with resource and/or provider classes:
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.putRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.PutOpParam,org.apache.hadoop.hdfs.web.resources.DestinationParam,org.apache.hadoop.hdfs.web.resources.OwnerParam,org.apache.hadoop.hdfs.web.resources.GroupParam,org.apache.hadoop.hdfs.web.resources.PermissionParam,org.apache.hadoop.hdfs.web.resources.UnmaskedPermissionParam,org.apache.hadoop.hdfs.web.resources.OverwriteParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,org.apache.hadoop.hdfs.web.resources.ReplicationParam,org.apache.hadoop.hdfs.web.resources.BlockSizeParam,org.apache.hadoop.hdfs.web.resources.ModificationTimeParam,org.apache.hadoop.hdfs.web.resources.AccessTimeParam,org.apache.hadoop.hdfs.web.resources.RenameOptionSetParam,org.apache.hadoop.hdfs.web.resources.CreateParentParam,org.apache.hadoop.hdfs.web.resources.TokenArgumentParam,org.apache.hadoop.hdfs.web.resources.AclPermissionParam,org.apache.hadoop.hdfs.web.resources.XAttrNameParam,org.apache.hadoop.hdfs.web.resources.XAttrValueParam,org.apache.hadoop.hdfs.web.resources.XAttrSetFlagParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam,org.apache.hadoop.hdfs.web.resources.OldSnapshotNameParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.CreateFlagParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam,org.apache.hadoop.hdfs.web.resources.StoragePolicyParam,org.apache.hadoop.hdfs.web.resources.ECPolicyParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.postRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.PostOpParam,org.apache.hadoop.hdfs.web.resources.ConcatSourcesParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.NewLengthParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.deleteRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.DeleteOpParam,org.apache.hadoop.hdfs.web.resources.RecursiveParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.getRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.GetOpParam,org.apache.hadoop.hdfs.web.resources.OffsetParam,org.apache.hadoop.hdfs.web.resources.LengthParam,org.apache.hadoop.hdfs.web.resources.RenewerParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,java.util.List,org.apache.hadoop.hdfs.web.resources.XAttrEncodingParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.FsActionParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam,org.apache.hadoop.hdfs.web.resources.OldSnapshotNameParam,org.apache.hadoop.hdfs.web.resources.TokenKindParam,org.apache.hadoop.hdfs.web.resources.TokenServiceParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam,org.apache.hadoop.hdfs.web.resources.StartAfterParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
2020-12-03 07:22:53,278 [IPC Server handler 3 on default port 42246] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testCreatedFileIsImmediatelyVisible	dst=null	perm=null	proto=rpc
2020-12-03 07:22:53,300 [Thread-474] INFO  contract.ContractTestUtils (ContractTestUtils.java:skip(521)) - Skipping: This Filesystem delays visibility of newly created files
2020-12-03 07:22:53,480 [IPC Server handler 1 on default port 42246] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/test/testCreatedFileIsImmediatelyVisible	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:22:53,528 [nioEventLoopGroup-7-1] INFO  datanode.webhdfs (WebHdfsHandler.java:run(147)) - 127.0.0.1 PUT /webhdfs/v1/test/testCreatedFileIsImmediatelyVisible?op=CREATE&user.name=root&namenoderpcaddress=1e0d9a01dc20:40691&blocksize=1024&buffersize=4096&createflag=&createparent=true&overwrite=false&permission=644&replication=1&unmaskedpermission=666 201
2020-12-03 07:22:54,160 [IPC Server handler 7 on default port 37628] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:54,160 [IPC Server handler 6 on default port 37628] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:54,161 [IPC Server handler 9 on default port 41189] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:54,166 [IPC Server handler 2 on default port 40615] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:54,166 [IPC Server handler 5 on default port 37628] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:54,168 [IPC Server handler 2 on default port 42246] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:54,169 [IPC Server handler 7 on default port 40615] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:54,174 [IPC Server handler 8 on default port 42246] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:54,175 [IPC Server handler 5 on default port 41189] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:54,171 [IPC Server handler 4 on default port 40615] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:54,175 [IPC Server handler 0 on default port 42246] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:54,175 [IPC Server handler 8 on default port 41189] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:54,174 [IPC Server handler 2 on default port 41189] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:54,175 [IPC Server handler 9 on default port 42246] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:54,181 [IPC Server handler 9 on default port 37628] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:54,183 [IPC Server handler 3 on default port 42246] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /test/testCreatedFileIsImmediatelyVisible is closed by DFSClient_NONMAPREDUCE_-875326861_699
2020-12-03 07:22:54,184 [IPC Server handler 1 on default port 40615] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:54,396 [IPC Server handler 5 on default port 42246] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test	dst=null	perm=null	proto=rpc
2020-12-03 07:22:54,447 [IPC Server handler 4 on default port 42246] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/test	dst=null	perm=null	proto=rpc
2020-12-03 07:22:54,471 [Listener at 0.0.0.0/39111] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:22:54,471 [Listener at 0.0.0.0/39111] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 3
2020-12-03 07:22:54,472 [Listener at 0.0.0.0/39111] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:22:54,472 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@59712875] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:22:54,494 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, DS-290a7f2a-32af-42b2-89c3-1b2c2b279b33) exiting.
2020-12-03 07:22:54,495 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, DS-e7b706cd-4e9c-48c6-b202-c15d8d57696f) exiting.
2020-12-03 07:22:54,532 [Listener at 0.0.0.0/39111] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@30cecdca{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:22:54,536 [Listener at 0.0.0.0/39111] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6edc4161{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:54,537 [Listener at 0.0.0.0/39111] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@f9b5552{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:22:54,537 [Listener at 0.0.0.0/39111] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@37a64f9d{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:22:54,543 [Listener at 0.0.0.0/39111] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 37550
2020-12-03 07:22:54,545 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:54,551 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:54,551 [BP-1217207052-172.17.0.3-1606980156864 heartbeating to localhost/127.0.0.1:42246] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:54,551 [BP-1217207052-172.17.0.3-1606980156864 heartbeating to localhost/127.0.0.1:42246] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1217207052-172.17.0.3-1606980156864 (Datanode Uuid ce121cb5-ea3a-4b2b-95c9-141da466dba7) service to localhost/127.0.0.1:42246
2020-12-03 07:22:54,552 [BP-1217207052-172.17.0.3-1606980156864 heartbeating to localhost/127.0.0.1:37628] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:54,553 [BP-1235373120-172.17.0.3-1606980160747 heartbeating to localhost/127.0.0.1:40615] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:54,553 [BP-1217207052-172.17.0.3-1606980156864 heartbeating to localhost/127.0.0.1:37628] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1217207052-172.17.0.3-1606980156864 (Datanode Uuid ce121cb5-ea3a-4b2b-95c9-141da466dba7) service to localhost/127.0.0.1:37628
2020-12-03 07:22:54,554 [BP-1217207052-172.17.0.3-1606980156864 heartbeating to localhost/127.0.0.1:37628] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1217207052-172.17.0.3-1606980156864 (Datanode Uuid ce121cb5-ea3a-4b2b-95c9-141da466dba7)
2020-12-03 07:22:54,554 [BP-1217207052-172.17.0.3-1606980156864 heartbeating to localhost/127.0.0.1:37628] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1217207052-172.17.0.3-1606980156864
2020-12-03 07:22:54,552 [BP-1235373120-172.17.0.3-1606980160747 heartbeating to localhost/127.0.0.1:41189] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:54,555 [BP-1235373120-172.17.0.3-1606980160747 heartbeating to localhost/127.0.0.1:41189] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1235373120-172.17.0.3-1606980160747 (Datanode Uuid ce121cb5-ea3a-4b2b-95c9-141da466dba7) service to localhost/127.0.0.1:41189
2020-12-03 07:22:54,555 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-1217207052-172.17.0.3-1606980156864] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:54,553 [BP-1235373120-172.17.0.3-1606980160747 heartbeating to localhost/127.0.0.1:40615] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1235373120-172.17.0.3-1606980160747 (Datanode Uuid ce121cb5-ea3a-4b2b-95c9-141da466dba7) service to localhost/127.0.0.1:40615
2020-12-03 07:22:54,557 [BP-1235373120-172.17.0.3-1606980160747 heartbeating to localhost/127.0.0.1:40615] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1235373120-172.17.0.3-1606980160747 (Datanode Uuid ce121cb5-ea3a-4b2b-95c9-141da466dba7)
2020-12-03 07:22:54,557 [BP-1235373120-172.17.0.3-1606980160747 heartbeating to localhost/127.0.0.1:40615] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1235373120-172.17.0.3-1606980160747
2020-12-03 07:22:54,558 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-1235373120-172.17.0.3-1606980160747] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:54,558 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-1235373120-172.17.0.3-1606980160747] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:54,555 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-1217207052-172.17.0.3-1606980156864] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:54,567 [Listener at 0.0.0.0/39111] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:22:54,568 [Listener at 0.0.0.0/39111] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:22:54,570 [Listener at 0.0.0.0/39111] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:22:54,570 [Listener at 0.0.0.0/39111] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:22:54,584 [Listener at 0.0.0.0/39111] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:22:54,585 [Listener at 0.0.0.0/39111] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 2
2020-12-03 07:22:54,585 [Listener at 0.0.0.0/39111] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:22:54,588 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@4b1c0397] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:22:54,589 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, DS-bd3e7214-c1b2-4043-86e7-9863535e580f) exiting.
2020-12-03 07:22:54,591 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, DS-e877e98a-df8b-4ebc-98c4-d460f14efb90) exiting.
2020-12-03 07:22:54,649 [Listener at 0.0.0.0/39111] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@264c5d07{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:22:54,653 [Listener at 0.0.0.0/39111] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@847f3e7{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:54,653 [Listener at 0.0.0.0/39111] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@588ffeb{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:22:54,654 [Listener at 0.0.0.0/39111] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2d84cb86{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:22:54,669 [Listener at 0.0.0.0/39111] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 40600
2020-12-03 07:22:54,708 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:54,708 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:54,708 [BP-1217207052-172.17.0.3-1606980156864 heartbeating to localhost/127.0.0.1:42246] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:54,709 [BP-1217207052-172.17.0.3-1606980156864 heartbeating to localhost/127.0.0.1:37628] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:54,709 [BP-1217207052-172.17.0.3-1606980156864 heartbeating to localhost/127.0.0.1:42246] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1217207052-172.17.0.3-1606980156864 (Datanode Uuid f47a982f-3e85-4226-b9b0-c434f3f5cab7) service to localhost/127.0.0.1:42246
2020-12-03 07:22:54,709 [BP-1217207052-172.17.0.3-1606980156864 heartbeating to localhost/127.0.0.1:37628] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1217207052-172.17.0.3-1606980156864 (Datanode Uuid f47a982f-3e85-4226-b9b0-c434f3f5cab7) service to localhost/127.0.0.1:37628
2020-12-03 07:22:54,709 [BP-1217207052-172.17.0.3-1606980156864 heartbeating to localhost/127.0.0.1:37628] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1217207052-172.17.0.3-1606980156864 (Datanode Uuid f47a982f-3e85-4226-b9b0-c434f3f5cab7)
2020-12-03 07:22:54,709 [BP-1217207052-172.17.0.3-1606980156864 heartbeating to localhost/127.0.0.1:37628] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1217207052-172.17.0.3-1606980156864
2020-12-03 07:22:54,711 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-1217207052-172.17.0.3-1606980156864] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:54,711 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-1217207052-172.17.0.3-1606980156864] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:54,712 [BP-1235373120-172.17.0.3-1606980160747 heartbeating to localhost/127.0.0.1:41189] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:54,712 [BP-1235373120-172.17.0.3-1606980160747 heartbeating to localhost/127.0.0.1:41189] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1235373120-172.17.0.3-1606980160747 (Datanode Uuid f47a982f-3e85-4226-b9b0-c434f3f5cab7) service to localhost/127.0.0.1:41189
2020-12-03 07:22:54,712 [BP-1235373120-172.17.0.3-1606980160747 heartbeating to localhost/127.0.0.1:40615] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:54,712 [BP-1235373120-172.17.0.3-1606980160747 heartbeating to localhost/127.0.0.1:40615] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1235373120-172.17.0.3-1606980160747 (Datanode Uuid f47a982f-3e85-4226-b9b0-c434f3f5cab7) service to localhost/127.0.0.1:40615
2020-12-03 07:22:54,712 [BP-1235373120-172.17.0.3-1606980160747 heartbeating to localhost/127.0.0.1:40615] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1235373120-172.17.0.3-1606980160747 (Datanode Uuid f47a982f-3e85-4226-b9b0-c434f3f5cab7)
2020-12-03 07:22:54,712 [BP-1235373120-172.17.0.3-1606980160747 heartbeating to localhost/127.0.0.1:40615] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1235373120-172.17.0.3-1606980160747
2020-12-03 07:22:54,713 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-1235373120-172.17.0.3-1606980160747] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:54,714 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-1235373120-172.17.0.3-1606980160747] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:54,736 [Listener at 0.0.0.0/39111] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:22:54,736 [Listener at 0.0.0.0/39111] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:22:54,738 [Listener at 0.0.0.0/39111] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:22:54,738 [Listener at 0.0.0.0/39111] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:22:54,743 [Listener at 0.0.0.0/39111] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:22:54,743 [Listener at 0.0.0.0/39111] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 1
2020-12-03 07:22:54,743 [Listener at 0.0.0.0/39111] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:22:54,743 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@6d367020] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:22:54,754 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, DS-babb1fcd-9d27-47f3-9171-b3180daa923a) exiting.
2020-12-03 07:22:54,754 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, DS-74bf8983-5f9d-4008-9db0-e9461d0d0ffa) exiting.
2020-12-03 07:22:54,796 [Listener at 0.0.0.0/39111] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@57bd802b{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:22:54,797 [Listener at 0.0.0.0/39111] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7dc64762{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:54,797 [Listener at 0.0.0.0/39111] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4ebadd3d{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:22:54,798 [Listener at 0.0.0.0/39111] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@72ba28ee{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:22:54,800 [Listener at 0.0.0.0/39111] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 35721
2020-12-03 07:22:54,804 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:54,804 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:54,806 [BP-1217207052-172.17.0.3-1606980156864 heartbeating to localhost/127.0.0.1:37628] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:54,806 [BP-1235373120-172.17.0.3-1606980160747 heartbeating to localhost/127.0.0.1:40615] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:54,806 [BP-1217207052-172.17.0.3-1606980156864 heartbeating to localhost/127.0.0.1:37628] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1217207052-172.17.0.3-1606980156864 (Datanode Uuid da8c2a33-61a0-489f-ae14-f61765804689) service to localhost/127.0.0.1:37628
2020-12-03 07:22:54,806 [BP-1235373120-172.17.0.3-1606980160747 heartbeating to localhost/127.0.0.1:41189] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:54,806 [BP-1217207052-172.17.0.3-1606980156864 heartbeating to localhost/127.0.0.1:42246] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:54,807 [BP-1235373120-172.17.0.3-1606980160747 heartbeating to localhost/127.0.0.1:41189] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1235373120-172.17.0.3-1606980160747 (Datanode Uuid da8c2a33-61a0-489f-ae14-f61765804689) service to localhost/127.0.0.1:41189
2020-12-03 07:22:54,806 [BP-1235373120-172.17.0.3-1606980160747 heartbeating to localhost/127.0.0.1:40615] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1235373120-172.17.0.3-1606980160747 (Datanode Uuid da8c2a33-61a0-489f-ae14-f61765804689) service to localhost/127.0.0.1:40615
2020-12-03 07:22:54,807 [BP-1235373120-172.17.0.3-1606980160747 heartbeating to localhost/127.0.0.1:40615] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1235373120-172.17.0.3-1606980160747 (Datanode Uuid da8c2a33-61a0-489f-ae14-f61765804689)
2020-12-03 07:22:54,807 [BP-1217207052-172.17.0.3-1606980156864 heartbeating to localhost/127.0.0.1:42246] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1217207052-172.17.0.3-1606980156864 (Datanode Uuid da8c2a33-61a0-489f-ae14-f61765804689) service to localhost/127.0.0.1:42246
2020-12-03 07:22:54,807 [BP-1235373120-172.17.0.3-1606980160747 heartbeating to localhost/127.0.0.1:40615] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1235373120-172.17.0.3-1606980160747
2020-12-03 07:22:54,807 [BP-1217207052-172.17.0.3-1606980156864 heartbeating to localhost/127.0.0.1:42246] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1217207052-172.17.0.3-1606980156864 (Datanode Uuid da8c2a33-61a0-489f-ae14-f61765804689)
2020-12-03 07:22:54,808 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-1235373120-172.17.0.3-1606980160747] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:54,809 [BP-1217207052-172.17.0.3-1606980156864 heartbeating to localhost/127.0.0.1:42246] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1217207052-172.17.0.3-1606980156864
2020-12-03 07:22:54,809 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-1235373120-172.17.0.3-1606980160747] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:54,810 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-1217207052-172.17.0.3-1606980156864] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:54,814 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-1217207052-172.17.0.3-1606980156864] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:54,820 [Listener at 0.0.0.0/39111] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:22:54,820 [Listener at 0.0.0.0/39111] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:22:54,823 [Listener at 0.0.0.0/39111] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:22:54,823 [Listener at 0.0.0.0/39111] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:22:54,828 [Listener at 0.0.0.0/39111] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:22:54,828 [Listener at 0.0.0.0/39111] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:22:54,829 [Listener at 0.0.0.0/39111] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:22:54,829 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@450794b4] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:22:54,830 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, DS-3c828317-de65-40e3-b326-d448a3a4057d) exiting.
2020-12-03 07:22:54,830 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, DS-40230fce-682c-44e3-ba88-45564f51101d) exiting.
2020-12-03 07:22:54,858 [Listener at 0.0.0.0/39111] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@350b3a17{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:22:54,858 [Listener at 0.0.0.0/39111] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@38600b{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:54,859 [Listener at 0.0.0.0/39111] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@589b028e{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:22:54,859 [Listener at 0.0.0.0/39111] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3773862a{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:22:54,860 [Listener at 0.0.0.0/39111] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 40468
2020-12-03 07:22:54,864 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:54,867 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:54,867 [BP-1217207052-172.17.0.3-1606980156864 heartbeating to localhost/127.0.0.1:37628] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:54,867 [BP-1235373120-172.17.0.3-1606980160747 heartbeating to localhost/127.0.0.1:41189] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:54,868 [BP-1217207052-172.17.0.3-1606980156864 heartbeating to localhost/127.0.0.1:37628] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1217207052-172.17.0.3-1606980156864 (Datanode Uuid cf6dffe3-142c-4551-9b92-aa40255ddbb7) service to localhost/127.0.0.1:37628
2020-12-03 07:22:54,868 [BP-1235373120-172.17.0.3-1606980160747 heartbeating to localhost/127.0.0.1:40615] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:54,867 [BP-1217207052-172.17.0.3-1606980156864 heartbeating to localhost/127.0.0.1:42246] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:54,868 [BP-1235373120-172.17.0.3-1606980160747 heartbeating to localhost/127.0.0.1:40615] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1235373120-172.17.0.3-1606980160747 (Datanode Uuid cf6dffe3-142c-4551-9b92-aa40255ddbb7) service to localhost/127.0.0.1:40615
2020-12-03 07:22:54,868 [BP-1235373120-172.17.0.3-1606980160747 heartbeating to localhost/127.0.0.1:41189] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1235373120-172.17.0.3-1606980160747 (Datanode Uuid cf6dffe3-142c-4551-9b92-aa40255ddbb7) service to localhost/127.0.0.1:41189
2020-12-03 07:22:54,868 [BP-1235373120-172.17.0.3-1606980160747 heartbeating to localhost/127.0.0.1:41189] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1235373120-172.17.0.3-1606980160747 (Datanode Uuid cf6dffe3-142c-4551-9b92-aa40255ddbb7)
2020-12-03 07:22:54,869 [BP-1235373120-172.17.0.3-1606980160747 heartbeating to localhost/127.0.0.1:41189] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1235373120-172.17.0.3-1606980160747
2020-12-03 07:22:54,868 [BP-1217207052-172.17.0.3-1606980156864 heartbeating to localhost/127.0.0.1:42246] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1217207052-172.17.0.3-1606980156864 (Datanode Uuid cf6dffe3-142c-4551-9b92-aa40255ddbb7) service to localhost/127.0.0.1:42246
2020-12-03 07:22:54,869 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-1235373120-172.17.0.3-1606980160747] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:54,869 [BP-1217207052-172.17.0.3-1606980156864 heartbeating to localhost/127.0.0.1:42246] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1217207052-172.17.0.3-1606980156864 (Datanode Uuid cf6dffe3-142c-4551-9b92-aa40255ddbb7)
2020-12-03 07:22:54,869 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-1235373120-172.17.0.3-1606980160747] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:54,869 [BP-1217207052-172.17.0.3-1606980156864 heartbeating to localhost/127.0.0.1:42246] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1217207052-172.17.0.3-1606980156864
2020-12-03 07:22:54,878 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-1217207052-172.17.0.3-1606980156864] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:54,878 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-1217207052-172.17.0.3-1606980156864] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:54,880 [Listener at 0.0.0.0/39111] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:22:54,880 [Listener at 0.0.0.0/39111] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:22:54,882 [Listener at 0.0.0.0/39111] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:22:54,883 [Listener at 0.0.0.0/39111] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:22:54,888 [Listener at 0.0.0.0/39111] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:22:54,889 [Listener at 0.0.0.0/39111] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:22:54,889 [Listener at 0.0.0.0/39111] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:22:54,894 [Listener at 0.0.0.0/39111] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 1, 5
2020-12-03 07:22:54,894 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@67d86804] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:22:54,899 [Listener at 0.0.0.0/39111] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 6 Total time for transactions(ms): 63 Number of transactions batched in Syncs: 0 Number of syncs: 7 SyncTimes(ms): 12 2 3 
2020-12-03 07:22:54,899 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@7afb1741] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:22:54,904 [Listener at 0.0.0.0/39111] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-0-through-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-0-through-1/current/edits_0000000000000000001-0000000000000000006
2020-12-03 07:22:54,905 [Listener at 0.0.0.0/39111] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000006
2020-12-03 07:22:54,906 [Listener at 0.0.0.0/39111] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000006
2020-12-03 07:22:54,907 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:22:54,908 [CacheReplicationMonitor(66061390)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:22:54,909 [Listener at 0.0.0.0/39111] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 42246
2020-12-03 07:22:54,915 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:54,915 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:54,915 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:22:54,919 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:22:54,957 [Listener at 0.0.0.0/39111] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:22:54,958 [Listener at 0.0.0.0/39111] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:22:54,960 [Listener at 0.0.0.0/39111] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@512535ff{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:22:54,963 [Listener at 0.0.0.0/39111] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@331acdad{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:54,964 [Listener at 0.0.0.0/39111] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@492691d7{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:22:54,964 [Listener at 0.0.0.0/39111] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@60129b9a{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:22:54,977 [Listener at 0.0.0.0/39111] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:22:54,977 [Listener at 0.0.0.0/39111] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:22:54,977 [Edit log tailer] WARN  ha.EditLogTailer (EditLogTailer.java:doWork(528)) - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.sleep(EditLogTailer.java:433)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:526)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:440)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:457)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:484)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:453)
2020-12-03 07:22:54,978 [Listener at 0.0.0.0/39111] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 37628
2020-12-03 07:22:54,982 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:54,982 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:54,982 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:22:54,982 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:22:55,003 [Listener at 0.0.0.0/39111] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:22:55,007 [Listener at 0.0.0.0/39111] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:22:55,010 [Listener at 0.0.0.0/39111] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@7544a1e4{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:22:55,013 [Listener at 0.0.0.0/39111] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@70e0accd{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:55,013 [Listener at 0.0.0.0/39111] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@797501a{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:22:55,013 [Listener at 0.0.0.0/39111] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@14bb2297{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:22:55,018 [Listener at 0.0.0.0/39111] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:22:55,018 [Listener at 0.0.0.0/39111] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:22:55,018 [Listener at 0.0.0.0/39111] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 1, 1
2020-12-03 07:22:55,019 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@6fa69af7] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:22:55,018 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@4b1a43d8] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:22:55,025 [Listener at 0.0.0.0/39111] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 2 Total time for transactions(ms): 15 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 2 2 2 
2020-12-03 07:22:55,026 [Listener at 0.0.0.0/39111] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-2-through-3/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-2-through-3/current/edits_0000000000000000001-0000000000000000002
2020-12-03 07:22:55,027 [Listener at 0.0.0.0/39111] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/current/edits_0000000000000000001-0000000000000000002
2020-12-03 07:22:55,028 [Listener at 0.0.0.0/39111] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6/current/edits_0000000000000000001-0000000000000000002
2020-12-03 07:22:55,029 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:22:55,029 [CacheReplicationMonitor(1948833993)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:22:55,029 [Listener at 0.0.0.0/39111] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 41189
2020-12-03 07:22:55,032 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:55,032 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:55,034 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:22:55,034 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:22:55,046 [Listener at 0.0.0.0/39111] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:22:55,047 [Listener at 0.0.0.0/39111] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:22:55,050 [Listener at 0.0.0.0/39111] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@581d969c{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:22:55,052 [Listener at 0.0.0.0/39111] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@22db8f4{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:55,052 [Listener at 0.0.0.0/39111] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@669253b7{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:22:55,052 [Listener at 0.0.0.0/39111] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@32f61a31{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:22:55,060 [Listener at 0.0.0.0/39111] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:22:55,060 [Listener at 0.0.0.0/39111] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:22:55,060 [Edit log tailer] WARN  ha.EditLogTailer (EditLogTailer.java:doWork(528)) - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.sleep(EditLogTailer.java:433)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:526)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:440)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:457)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:484)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:453)
2020-12-03 07:22:55,061 [Listener at 0.0.0.0/39111] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 40615
2020-12-03 07:22:55,062 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:55,062 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:22:55,062 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:22:55,068 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:55,082 [Listener at 0.0.0.0/39111] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:22:55,085 [Listener at 0.0.0.0/39111] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:22:55,089 [Listener at 0.0.0.0/39111] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1dfd5f51{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:22:55,093 [Listener at 0.0.0.0/39111] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@3c321bdb{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:55,093 [Listener at 0.0.0.0/39111] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@54e7391d{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:22:55,093 [Listener at 0.0.0.0/39111] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6d1310f6{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:22:55,135 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 1e0d9a01dc20:39265: State Store unavailable
2020-12-03 07:22:55,143 [Thread-481] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - RouterHeartbeatService is shutting down
2020-12-03 07:22:55,146 [Thread-481] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service RouterHeartbeatService
2020-12-03 07:22:55,150 [Thread-481] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn1 is shutting down
2020-12-03 07:22:55,150 [Thread-481] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn1
2020-12-03 07:22:55,155 [Thread-481] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn1 is shutting down
2020-12-03 07:22:55,155 [Thread-481] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn1
2020-12-03 07:22:55,160 [Thread-481] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn0 is shutting down
2020-12-03 07:22:55,161 [Thread-481] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn0
2020-12-03 07:22:55,168 [Thread-481] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn0 is shutting down
2020-12-03 07:22:55,169 [Thread-481] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn0
2020-12-03 07:22:55,192 [Thread-481] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@71cb3139{/,null,UNAVAILABLE}{/router}
2020-12-03 07:22:55,193 [Thread-481] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@1639f93a{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2020-12-03 07:22:55,196 [Thread-481] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@31f20c9f{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:55,199 [Thread-481] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@69fa8e76{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:22:55,204 [Thread-481] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 39104
2020-12-03 07:22:55,206 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:55,210 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:55,215 [Thread-481] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 39265
2020-12-03 07:22:55,219 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:55,221 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:55,231 [Thread-481] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreCacheUpdateService is shutting down
2020-12-03 07:22:55,232 [Thread-481] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreCacheUpdateService
2020-12-03 07:22:55,237 [Thread-481] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreConnectionMonitorService is shutting down
2020-12-03 07:22:55,237 [Thread-481] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreConnectionMonitorService
2020-12-03 07:22:56,134 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 1e0d9a01dc20:40691: State Store unavailable
2020-12-03 07:22:56,148 [Thread-482] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - RouterHeartbeatService is shutting down
2020-12-03 07:22:56,148 [Thread-482] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service RouterHeartbeatService
2020-12-03 07:22:56,154 [Thread-482] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn1 is shutting down
2020-12-03 07:22:56,155 [Thread-482] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn1
2020-12-03 07:22:56,180 [Thread-482] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn1 is shutting down
2020-12-03 07:22:56,181 [Thread-482] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn1
2020-12-03 07:22:56,184 [Thread-482] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn0 is shutting down
2020-12-03 07:22:56,184 [Thread-482] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn0
2020-12-03 07:22:56,195 [Thread-482] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn0 is shutting down
2020-12-03 07:22:56,195 [Thread-482] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn0
2020-12-03 07:22:56,201 [Thread-482] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@46d567cb{/,null,UNAVAILABLE}{/router}
2020-12-03 07:22:56,203 [Thread-482] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@363a3d15{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2020-12-03 07:22:56,205 [Thread-482] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7e1f584d{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:56,206 [Thread-482] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1da4b6b3{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:22:56,209 [Thread-482] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 42910
2020-12-03 07:22:56,212 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:56,222 [Thread-482] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 40691
2020-12-03 07:22:56,220 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:56,226 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:56,226 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:56,228 [Thread-482] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping Router metrics system...
2020-12-03 07:22:56,230 [Thread-482] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - Router metrics system stopped.
2020-12-03 07:22:56,231 [Thread-482] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - Router metrics system shutdown complete.
2020-12-03 07:22:56,234 [Thread-482] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreCacheUpdateService is shutting down
2020-12-03 07:22:56,234 [Thread-482] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreCacheUpdateService
2020-12-03 07:22:56,236 [Thread-482] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreConnectionMonitorService is shutting down
2020-12-03 07:22:56,236 [Thread-482] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreConnectionMonitorService
2020-12-03 07:22:57,131 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 1e0d9a01dc20:45164: State Store unavailable
2020-12-03 07:22:57,132 [Thread-483] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - RouterHeartbeatService is shutting down
2020-12-03 07:22:57,133 [Thread-483] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service RouterHeartbeatService
2020-12-03 07:22:57,133 [Thread-483] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn1 is shutting down
2020-12-03 07:22:57,133 [Thread-483] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn1
2020-12-03 07:22:57,134 [Thread-483] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn1 is shutting down
2020-12-03 07:22:57,134 [Thread-483] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn1
2020-12-03 07:22:57,135 [Thread-483] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn0 is shutting down
2020-12-03 07:22:57,135 [Thread-483] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn0
2020-12-03 07:22:57,135 [Thread-483] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn0 is shutting down
2020-12-03 07:22:57,135 [Thread-483] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn0
2020-12-03 07:22:57,138 [Thread-483] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@4c59e45e{/,null,UNAVAILABLE}{/router}
2020-12-03 07:22:57,139 [Thread-483] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@58ec7116{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2020-12-03 07:22:57,140 [Thread-483] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@d74bac4{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:57,141 [Thread-483] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5176d279{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:22:57,142 [Thread-483] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 37266
2020-12-03 07:22:57,143 [Thread-483] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 45164
2020-12-03 07:22:57,143 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:57,143 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:57,149 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:57,150 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:57,150 [Thread-483] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreCacheUpdateService is shutting down
2020-12-03 07:22:57,151 [Thread-483] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreCacheUpdateService
2020-12-03 07:22:57,151 [Thread-483] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreConnectionMonitorService is shutting down
2020-12-03 07:22:57,152 [Thread-483] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreConnectionMonitorService
2020-12-03 07:22:57,603 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-12-03 07:22:57,884 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 1e0d9a01dc20:37277: State Store unavailable
2020-12-03 07:22:58,132 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 1e0d9a01dc20:37277: State Store unavailable
2020-12-03 07:22:58,132 [Thread-484] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - RouterHeartbeatService is shutting down
2020-12-03 07:22:58,133 [Thread-484] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service RouterHeartbeatService
2020-12-03 07:22:58,133 [Thread-484] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn1 is shutting down
2020-12-03 07:22:58,133 [Thread-484] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn1
2020-12-03 07:22:58,134 [Thread-484] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn0 is shutting down
2020-12-03 07:22:58,134 [Thread-484] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn0
2020-12-03 07:22:58,134 [Thread-484] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn1 is shutting down
2020-12-03 07:22:58,134 [Thread-484] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn1
2020-12-03 07:22:58,135 [Thread-484] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn0 is shutting down
2020-12-03 07:22:58,135 [Thread-484] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn0
2020-12-03 07:22:58,137 [Thread-484] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@39e43310{/,null,UNAVAILABLE}{/router}
2020-12-03 07:22:58,139 [Thread-484] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@eb507b9{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2020-12-03 07:22:58,139 [Thread-484] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3e5d4f6b{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:58,140 [Thread-484] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@68217d41{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:22:58,141 [Thread-484] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 39111
2020-12-03 07:22:58,142 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:58,142 [Thread-484] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 37277
2020-12-03 07:22:58,142 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:58,143 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:58,144 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:58,145 [Thread-484] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreCacheUpdateService is shutting down
2020-12-03 07:22:58,145 [Thread-484] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreCacheUpdateService
2020-12-03 07:22:58,146 [Thread-484] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreConnectionMonitorService is shutting down
2020-12-03 07:22:58,146 [Thread-484] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreConnectionMonitorService
msx-rc 0
