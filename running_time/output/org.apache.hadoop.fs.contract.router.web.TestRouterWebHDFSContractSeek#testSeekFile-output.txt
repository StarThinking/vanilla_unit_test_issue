2020-12-03 07:23:29,656 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=4, numDataNodes=4
2020-12-03 07:23:29,694 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:initMiniDFSCluster(875)) - MiniDFSCluster disabling checkpointing in the Standby node since no HTTP ports have been specified.
2020-12-03 07:23:29,694 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:initMiniDFSCluster(881)) - MiniDFSCluster disabling log-roll triggering in the Standby node since no IPC ports have been specified.
Formatting using clusterid: testClusterID
2020-12-03 07:23:30,509 [JUnit] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:23:30,526 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:23:30,528 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:23:30,528 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:23:30,537 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:23:30,537 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:23:30,538 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:23:30,543 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns0
2020-12-03 07:23:30,543 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: true
2020-12-03 07:23:30,605 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:30,611 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2020-12-03 07:23:30,611 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:23:30,612 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:23:30,620 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:23:30,620 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:23:30
2020-12-03 07:23:30,623 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:23:30,623 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:30,625 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-12-03 07:23:30,626 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:23:30,648 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:23:30,648 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:23:30,661 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:23:30,661 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:23:30,662 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:23:30,662 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:23:30,663 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:23:30,664 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:23:30,664 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:23:30,664 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:23:30,665 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:23:30,665 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:23:30,665 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:23:30,718 [JUnit] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GLOBAL serial map: bits=29 maxEntries=536870911
2020-12-03 07:23:30,718 [JUnit] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - USER serial map: bits=24 maxEntries=16777215
2020-12-03 07:23:30,719 [JUnit] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GROUP serial map: bits=24 maxEntries=16777215
2020-12-03 07:23:30,719 [JUnit] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - XATTR serial map: bits=24 maxEntries=16777215
2020-12-03 07:23:30,746 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:23:30,747 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:30,748 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-12-03 07:23:30,748 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:23:30,756 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:23:30,757 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:23:30,757 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:23:30,758 [JUnit] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:23:30,778 [JUnit] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:23:30,782 [JUnit] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:23:30,789 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:23:30,790 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:30,791 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-12-03 07:23:30,791 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:23:30,805 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:23:30,806 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:23:30,806 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:23:30,812 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:23:30,813 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:23:30,817 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:23:30,817 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:30,818 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-12-03 07:23:30,818 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:23:30,872 [JUnit] INFO  namenode.FSImage (FSImage.java:format(185)) - Allocated new BlockPoolId: BP-1192165426-172.17.0.8-1606980210852
2020-12-03 07:23:31,539 [JUnit] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-12-03 07:23:31,607 [JUnit] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-12-03 07:23:31,658 [JUnit] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-0-through-1 has been successfully formatted.
2020-12-03 07:23:31,704 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:23:31,704 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:23:31,896 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:23:31,903 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:23:32,072 [JUnit] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-12-03 07:23:32,170 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:copyNameDirs(1264)) - Copying namedir from primary node dir file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1 to file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-3
2020-12-03 07:23:32,196 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:copyNameDirs(1264)) - Copying namedir from primary node dir file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1 to file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-4
2020-12-03 07:23:32,206 [JUnit] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:23:32,649 [JUnit] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-namenode.properties,hadoop-metrics2.properties
2020-12-03 07:23:32,772 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2020-12-03 07:23:32,772 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:23:32,790 [JUnit] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://ns0
2020-12-03 07:23:32,791 [JUnit] INFO  namenode.NameNode (NameNode.java:<init>(944)) - Clients should use ns0 to access this namenode/service.
2020-12-03 07:23:32,843 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@239105a8] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:32,860 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:23:32,886 [JUnit] INFO  util.log (Log.java:initialized(192)) - Logging initialized @4562ms
2020-12-03 07:23:33,042 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:33,048 [JUnit] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:23:33,066 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:33,069 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:23:33,070 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:33,070 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:33,111 [JUnit] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:23:33,112 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:23:33,127 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 34751
2020-12-03 07:23:33,129 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:33,181 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@78d6692f{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:23:33,183 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@27216cd{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:23:33,539 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@71529963{/,file:///tmp/jetty-localhost-34751-hdfs-_-any-6065345400242530562.dir/webapp/,AVAILABLE}{/hdfs}
2020-12-03 07:23:33,549 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@41d426b5{HTTP/1.1,[http/1.1]}{localhost:34751}
2020-12-03 07:23:33,550 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @5226ms
2020-12-03 07:23:33,566 [JUnit] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:23:33,567 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:23:33,568 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:23:33,568 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:23:33,568 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:23:33,569 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:23:33,569 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:23:33,570 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns0
2020-12-03 07:23:33,570 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: true
2020-12-03 07:23:33,571 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:33,572 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:23:33,572 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:23:33,573 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:23:33,573 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:23:33
2020-12-03 07:23:33,574 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:23:33,574 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:33,575 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:23:33,575 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:23:33,580 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:23:33,581 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:23:33,581 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:23:33,582 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:23:33,582 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:23:33,582 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:23:33,583 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:23:33,583 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:23:33,583 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:23:33,583 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:23:33,584 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:23:33,584 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:23:33,584 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:23:33,585 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:23:33,586 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:33,586 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:23:33,587 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:23:33,590 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:23:33,591 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:23:33,591 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:23:33,591 [JUnit] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:23:33,592 [JUnit] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:23:33,592 [JUnit] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:23:33,592 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:23:33,593 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:33,593 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:23:33,593 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:23:33,601 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:23:33,602 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:23:33,602 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:23:33,603 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:23:33,603 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:23:33,603 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:23:33,603 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:33,604 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:23:33,604 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:23:33,639 [JUnit] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 10408@1c04ae08cdfc
2020-12-03 07:23:33,711 [JUnit] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 10408@1c04ae08cdfc
2020-12-03 07:23:33,712 [JUnit] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-0-through-1
2020-12-03 07:23:33,717 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:23:33,718 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:23:33,784 [JUnit] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:23:33,800 [JUnit] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:23:33,801 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-12-03 07:23:33,809 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2020-12-03 07:23:33,809 [JUnit] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:23:33,810 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 203 msecs
2020-12-03 07:23:34,025 [JUnit] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to 0.0.0.0:0
2020-12-03 07:23:34,066 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:34,080 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:34,378 [Listener at 0.0.0.0/32986] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:23:34,414 [Listener at 0.0.0.0/32986] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:23:34,429 [Listener at 0.0.0.0/32986] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:23:34,429 [Listener at 0.0.0.0/32986] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:23:34,429 [Listener at 0.0.0.0/32986] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:23:34,475 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:34,475 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:34,483 [Listener at 0.0.0.0/32986] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:32986
2020-12-03 07:23:34,485 [Listener at 0.0.0.0/32986] INFO  namenode.FSNamesystem (FSNamesystem.java:startStandbyServices(1391)) - Starting services required for standby state
2020-12-03 07:23:34,487 [Listener at 0.0.0.0/32986] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.log-roll.period(-1) assuming SECONDS
2020-12-03 07:23:34,488 [Listener at 0.0.0.0/32986] INFO  ha.EditLogTailer (EditLogTailer.java:<init>(208)) - Not going to trigger log rolls on active node because dfs.ha.log-roll.period is negative.
2020-12-03 07:23:34,488 [Listener at 0.0.0.0/32986] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.period.backoff-max(0) assuming SECONDS
2020-12-03 07:23:34,488 [Listener at 0.0.0.0/32986] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.rolledits.timeout(60) assuming SECONDS
2020-12-03 07:23:34,493 [Listener at 0.0.0.0/32986] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:23:34,494 [Listener at 0.0.0.0/32986] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-12-03 07:23:34,495 [Listener at 0.0.0.0/32986] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://ns0
2020-12-03 07:23:34,495 [Listener at 0.0.0.0/32986] INFO  namenode.NameNode (NameNode.java:<init>(944)) - Clients should use ns0 to access this namenode/service.
2020-12-03 07:23:34,507 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5af9926a] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:34,508 [Listener at 0.0.0.0/32986] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:23:34,512 [Listener at 0.0.0.0/32986] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:34,514 [Listener at 0.0.0.0/32986] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:23:34,519 [Listener at 0.0.0.0/32986] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:34,521 [Listener at 0.0.0.0/32986] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:23:34,521 [Listener at 0.0.0.0/32986] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:34,521 [Listener at 0.0.0.0/32986] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:34,524 [Listener at 0.0.0.0/32986] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:23:34,525 [Listener at 0.0.0.0/32986] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:23:34,526 [Listener at 0.0.0.0/32986] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 34811
2020-12-03 07:23:34,526 [Listener at 0.0.0.0/32986] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:34,530 [Listener at 0.0.0.0/32986] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@69adf72c{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:23:34,531 [Listener at 0.0.0.0/32986] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1a15b789{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:23:34,726 [Listener at 0.0.0.0/32986] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@70e0accd{/,file:///tmp/jetty-localhost-34811-hdfs-_-any-958959951810121839.dir/webapp/,AVAILABLE}{/hdfs}
2020-12-03 07:23:34,728 [Listener at 0.0.0.0/32986] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7957dc72{HTTP/1.1,[http/1.1]}{localhost:34811}
2020-12-03 07:23:34,729 [Listener at 0.0.0.0/32986] INFO  server.Server (Server.java:doStart(419)) - Started @6404ms
2020-12-03 07:23:34,734 [Listener at 0.0.0.0/32986] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:23:34,735 [Listener at 0.0.0.0/32986] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:23:34,735 [Listener at 0.0.0.0/32986] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:23:34,736 [Listener at 0.0.0.0/32986] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:23:34,744 [Listener at 0.0.0.0/32986] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:23:34,745 [Listener at 0.0.0.0/32986] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:23:34,745 [Listener at 0.0.0.0/32986] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:23:34,746 [Listener at 0.0.0.0/32986] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns0
2020-12-03 07:23:34,746 [Listener at 0.0.0.0/32986] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: true
2020-12-03 07:23:34,747 [Listener at 0.0.0.0/32986] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:34,748 [Listener at 0.0.0.0/32986] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:23:34,748 [Listener at 0.0.0.0/32986] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:23:34,748 [Listener at 0.0.0.0/32986] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:23:34,749 [Listener at 0.0.0.0/32986] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:23:34
2020-12-03 07:23:34,749 [Listener at 0.0.0.0/32986] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:23:34,750 [Listener at 0.0.0.0/32986] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:34,750 [Listener at 0.0.0.0/32986] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:23:34,750 [Listener at 0.0.0.0/32986] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:23:34,763 [Listener at 0.0.0.0/32986] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:23:34,763 [Listener at 0.0.0.0/32986] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:23:34,765 [Listener at 0.0.0.0/32986] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:23:34,765 [Listener at 0.0.0.0/32986] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:23:34,765 [Listener at 0.0.0.0/32986] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:23:34,766 [Listener at 0.0.0.0/32986] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:23:34,769 [Listener at 0.0.0.0/32986] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:23:34,769 [Listener at 0.0.0.0/32986] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:23:34,770 [Listener at 0.0.0.0/32986] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:23:34,770 [Listener at 0.0.0.0/32986] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:23:34,770 [Listener at 0.0.0.0/32986] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:23:34,771 [Listener at 0.0.0.0/32986] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:23:34,771 [Listener at 0.0.0.0/32986] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:23:34,772 [Listener at 0.0.0.0/32986] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:23:34,772 [Listener at 0.0.0.0/32986] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:34,773 [Listener at 0.0.0.0/32986] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:23:34,773 [Listener at 0.0.0.0/32986] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:23:34,780 [Listener at 0.0.0.0/32986] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:23:34,780 [Listener at 0.0.0.0/32986] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:23:34,780 [Listener at 0.0.0.0/32986] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:23:34,780 [Listener at 0.0.0.0/32986] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:23:34,781 [Listener at 0.0.0.0/32986] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:23:34,781 [Listener at 0.0.0.0/32986] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:23:34,781 [Listener at 0.0.0.0/32986] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:23:34,781 [Listener at 0.0.0.0/32986] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:34,782 [Listener at 0.0.0.0/32986] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:23:34,782 [Listener at 0.0.0.0/32986] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:23:34,784 [Listener at 0.0.0.0/32986] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:23:34,784 [Listener at 0.0.0.0/32986] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:23:34,784 [Listener at 0.0.0.0/32986] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:23:34,785 [Listener at 0.0.0.0/32986] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:23:34,785 [Listener at 0.0.0.0/32986] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:23:34,785 [Listener at 0.0.0.0/32986] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:23:34,785 [Listener at 0.0.0.0/32986] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:34,786 [Listener at 0.0.0.0/32986] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:23:34,786 [Listener at 0.0.0.0/32986] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:23:34,815 [Listener at 0.0.0.0/32986] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-3/in_use.lock acquired by nodename 10408@1c04ae08cdfc
2020-12-03 07:23:34,847 [Listener at 0.0.0.0/32986] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-4/in_use.lock acquired by nodename 10408@1c04ae08cdfc
2020-12-03 07:23:34,848 [Listener at 0.0.0.0/32986] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-0-through-1
2020-12-03 07:23:34,853 [Listener at 0.0.0.0/32986] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:23:34,853 [Listener at 0.0.0.0/32986] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-3/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:23:34,883 [Listener at 0.0.0.0/32986] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:23:34,885 [Listener at 0.0.0.0/32986] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:23:34,886 [Listener at 0.0.0.0/32986] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-3/current/fsimage_0000000000000000000
2020-12-03 07:23:34,886 [Listener at 0.0.0.0/32986] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2020-12-03 07:23:34,886 [Listener at 0.0.0.0/32986] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:23:34,887 [Listener at 0.0.0.0/32986] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 99 msecs
2020-12-03 07:23:34,888 [Listener at 0.0.0.0/32986] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to 0.0.0.0:0
2020-12-03 07:23:34,889 [Listener at 0.0.0.0/32986] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:34,890 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:34,896 [Listener at 0.0.0.0/42813] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:23:34,920 [Listener at 0.0.0.0/42813] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:23:34,921 [Listener at 0.0.0.0/42813] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:23:34,922 [Listener at 0.0.0.0/42813] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:23:34,922 [Listener at 0.0.0.0/42813] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:23:34,926 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:34,926 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:34,930 [Listener at 0.0.0.0/42813] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:42813
2020-12-03 07:23:34,931 [Listener at 0.0.0.0/42813] INFO  namenode.FSNamesystem (FSNamesystem.java:startStandbyServices(1391)) - Starting services required for standby state
2020-12-03 07:23:34,931 [Listener at 0.0.0.0/42813] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.log-roll.period(-1) assuming SECONDS
2020-12-03 07:23:34,931 [Listener at 0.0.0.0/42813] INFO  ha.EditLogTailer (EditLogTailer.java:<init>(208)) - Not going to trigger log rolls on active node because dfs.ha.log-roll.period is negative.
2020-12-03 07:23:34,932 [Listener at 0.0.0.0/42813] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.period.backoff-max(0) assuming SECONDS
2020-12-03 07:23:34,932 [Listener at 0.0.0.0/42813] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.rolledits.timeout(60) assuming SECONDS
Formatting using clusterid: testClusterID
2020-12-03 07:23:34,948 [Listener at 0.0.0.0/42813] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:23:34,949 [Listener at 0.0.0.0/42813] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:23:34,949 [Listener at 0.0.0.0/42813] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:23:34,949 [Listener at 0.0.0.0/42813] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:23:34,949 [Listener at 0.0.0.0/42813] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:23:34,949 [Listener at 0.0.0.0/42813] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:23:34,949 [Listener at 0.0.0.0/42813] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:23:34,950 [Listener at 0.0.0.0/42813] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns1
2020-12-03 07:23:34,950 [Listener at 0.0.0.0/42813] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: true
2020-12-03 07:23:34,951 [Listener at 0.0.0.0/42813] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:34,953 [Listener at 0.0.0.0/42813] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:23:34,953 [Listener at 0.0.0.0/42813] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:23:34,954 [Listener at 0.0.0.0/42813] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:23:34,954 [Listener at 0.0.0.0/42813] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:23:34
2020-12-03 07:23:34,954 [Listener at 0.0.0.0/42813] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:23:34,955 [Listener at 0.0.0.0/42813] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:34,955 [Listener at 0.0.0.0/42813] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:23:34,955 [Listener at 0.0.0.0/42813] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:23:34,971 [Listener at 0.0.0.0/42813] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:23:34,971 [Listener at 0.0.0.0/42813] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:23:34,972 [Listener at 0.0.0.0/42813] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:23:34,972 [Listener at 0.0.0.0/42813] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:23:34,972 [Listener at 0.0.0.0/42813] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:23:34,973 [Listener at 0.0.0.0/42813] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:23:34,973 [Listener at 0.0.0.0/42813] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:23:34,973 [Listener at 0.0.0.0/42813] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:23:34,973 [Listener at 0.0.0.0/42813] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:23:34,974 [Listener at 0.0.0.0/42813] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:23:34,974 [Listener at 0.0.0.0/42813] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:23:34,974 [Listener at 0.0.0.0/42813] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:23:34,974 [Listener at 0.0.0.0/42813] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:23:34,975 [Listener at 0.0.0.0/42813] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:23:34,975 [Listener at 0.0.0.0/42813] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:34,976 [Listener at 0.0.0.0/42813] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:23:34,976 [Listener at 0.0.0.0/42813] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:23:34,984 [Listener at 0.0.0.0/42813] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:23:34,984 [Listener at 0.0.0.0/42813] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:23:34,984 [Listener at 0.0.0.0/42813] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:23:34,984 [Listener at 0.0.0.0/42813] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:23:34,985 [Listener at 0.0.0.0/42813] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:23:34,985 [Listener at 0.0.0.0/42813] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:23:34,985 [Listener at 0.0.0.0/42813] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:23:34,985 [Listener at 0.0.0.0/42813] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:34,986 [Listener at 0.0.0.0/42813] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:23:34,986 [Listener at 0.0.0.0/42813] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:23:34,988 [Listener at 0.0.0.0/42813] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:23:34,989 [Listener at 0.0.0.0/42813] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:23:34,989 [Listener at 0.0.0.0/42813] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:23:34,989 [Listener at 0.0.0.0/42813] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:23:34,989 [Listener at 0.0.0.0/42813] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:23:34,989 [Listener at 0.0.0.0/42813] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:23:34,990 [Listener at 0.0.0.0/42813] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:34,990 [Listener at 0.0.0.0/42813] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:23:34,990 [Listener at 0.0.0.0/42813] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:23:34,994 [Listener at 0.0.0.0/42813] INFO  namenode.FSImage (FSImage.java:format(185)) - Allocated new BlockPoolId: BP-1199477258-172.17.0.8-1606980214994
2020-12-03 07:23:35,051 [Listener at 0.0.0.0/42813] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5 has been successfully formatted.
2020-12-03 07:23:35,120 [Listener at 0.0.0.0/42813] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6 has been successfully formatted.
2020-12-03 07:23:35,196 [Listener at 0.0.0.0/42813] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-2-through-3 has been successfully formatted.
2020-12-03 07:23:35,215 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:23:35,215 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:23:35,225 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:23:35,225 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:23:35,259 [Listener at 0.0.0.0/42813] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-12-03 07:23:35,262 [Listener at 0.0.0.0/42813] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:copyNameDirs(1264)) - Copying namedir from primary node dir file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5 to file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-7
2020-12-03 07:23:35,269 [Listener at 0.0.0.0/42813] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:copyNameDirs(1264)) - Copying namedir from primary node dir file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5 to file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-8
2020-12-03 07:23:35,277 [Listener at 0.0.0.0/42813] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:23:35,278 [Listener at 0.0.0.0/42813] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-12-03 07:23:35,278 [Listener at 0.0.0.0/42813] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://ns0
2020-12-03 07:23:35,279 [Listener at 0.0.0.0/42813] INFO  namenode.NameNode (NameNode.java:<init>(944)) - Clients should use ns1 to access this namenode/service.
2020-12-03 07:23:35,288 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1edb61b1] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:35,289 [Listener at 0.0.0.0/42813] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:23:35,291 [Listener at 0.0.0.0/42813] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:35,292 [Listener at 0.0.0.0/42813] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:23:35,295 [Listener at 0.0.0.0/42813] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:35,297 [Listener at 0.0.0.0/42813] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:23:35,297 [Listener at 0.0.0.0/42813] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:35,297 [Listener at 0.0.0.0/42813] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:35,300 [Listener at 0.0.0.0/42813] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:23:35,300 [Listener at 0.0.0.0/42813] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:23:35,301 [Listener at 0.0.0.0/42813] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 42421
2020-12-03 07:23:35,301 [Listener at 0.0.0.0/42813] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:35,304 [Listener at 0.0.0.0/42813] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@f5c79a6{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:23:35,305 [Listener at 0.0.0.0/42813] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5305c37d{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:23:35,508 [Listener at 0.0.0.0/42813] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@22db8f4{/,file:///tmp/jetty-localhost-42421-hdfs-_-any-4238634967681252729.dir/webapp/,AVAILABLE}{/hdfs}
2020-12-03 07:23:35,510 [Listener at 0.0.0.0/42813] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2b46a8c1{HTTP/1.1,[http/1.1]}{localhost:42421}
2020-12-03 07:23:35,510 [Listener at 0.0.0.0/42813] INFO  server.Server (Server.java:doStart(419)) - Started @7186ms
2020-12-03 07:23:35,512 [Listener at 0.0.0.0/42813] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:23:35,513 [Listener at 0.0.0.0/42813] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:23:35,513 [Listener at 0.0.0.0/42813] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:23:35,513 [Listener at 0.0.0.0/42813] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:23:35,514 [Listener at 0.0.0.0/42813] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:23:35,514 [Listener at 0.0.0.0/42813] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:23:35,514 [Listener at 0.0.0.0/42813] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:23:35,514 [Listener at 0.0.0.0/42813] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns1
2020-12-03 07:23:35,515 [Listener at 0.0.0.0/42813] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: true
2020-12-03 07:23:35,516 [Listener at 0.0.0.0/42813] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:35,520 [Listener at 0.0.0.0/42813] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:23:35,524 [Listener at 0.0.0.0/42813] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:23:35,524 [Listener at 0.0.0.0/42813] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:23:35,525 [Listener at 0.0.0.0/42813] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:23:35
2020-12-03 07:23:35,525 [Listener at 0.0.0.0/42813] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:23:35,525 [Listener at 0.0.0.0/42813] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:35,526 [Listener at 0.0.0.0/42813] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:23:35,526 [Listener at 0.0.0.0/42813] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:23:35,540 [Listener at 0.0.0.0/42813] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:23:35,540 [Listener at 0.0.0.0/42813] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:23:35,541 [Listener at 0.0.0.0/42813] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:23:35,541 [Listener at 0.0.0.0/42813] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:23:35,542 [Listener at 0.0.0.0/42813] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:23:35,542 [Listener at 0.0.0.0/42813] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:23:35,542 [Listener at 0.0.0.0/42813] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:23:35,542 [Listener at 0.0.0.0/42813] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:23:35,542 [Listener at 0.0.0.0/42813] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:23:35,542 [Listener at 0.0.0.0/42813] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:23:35,543 [Listener at 0.0.0.0/42813] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:23:35,543 [Listener at 0.0.0.0/42813] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:23:35,543 [Listener at 0.0.0.0/42813] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:23:35,543 [Listener at 0.0.0.0/42813] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:23:35,544 [Listener at 0.0.0.0/42813] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:35,544 [Listener at 0.0.0.0/42813] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:23:35,544 [Listener at 0.0.0.0/42813] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:23:35,551 [Listener at 0.0.0.0/42813] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:23:35,552 [Listener at 0.0.0.0/42813] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:23:35,552 [Listener at 0.0.0.0/42813] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:23:35,552 [Listener at 0.0.0.0/42813] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:23:35,553 [Listener at 0.0.0.0/42813] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:23:35,553 [Listener at 0.0.0.0/42813] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:23:35,553 [Listener at 0.0.0.0/42813] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:23:35,554 [Listener at 0.0.0.0/42813] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:35,554 [Listener at 0.0.0.0/42813] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:23:35,554 [Listener at 0.0.0.0/42813] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:23:35,557 [Listener at 0.0.0.0/42813] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:23:35,557 [Listener at 0.0.0.0/42813] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:23:35,557 [Listener at 0.0.0.0/42813] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:23:35,558 [Listener at 0.0.0.0/42813] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:23:35,558 [Listener at 0.0.0.0/42813] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:23:35,558 [Listener at 0.0.0.0/42813] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:23:35,559 [Listener at 0.0.0.0/42813] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:35,559 [Listener at 0.0.0.0/42813] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:23:35,559 [Listener at 0.0.0.0/42813] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:23:35,600 [Listener at 0.0.0.0/42813] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/in_use.lock acquired by nodename 10408@1c04ae08cdfc
2020-12-03 07:23:35,635 [Listener at 0.0.0.0/42813] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6/in_use.lock acquired by nodename 10408@1c04ae08cdfc
2020-12-03 07:23:35,636 [Listener at 0.0.0.0/42813] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-2-through-3
2020-12-03 07:23:35,638 [Listener at 0.0.0.0/42813] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:23:35,639 [Listener at 0.0.0.0/42813] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:23:35,641 [Listener at 0.0.0.0/42813] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:23:35,642 [Listener at 0.0.0.0/42813] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:23:35,642 [Listener at 0.0.0.0/42813] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/current/fsimage_0000000000000000000
2020-12-03 07:23:35,642 [Listener at 0.0.0.0/42813] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2020-12-03 07:23:35,642 [Listener at 0.0.0.0/42813] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:23:35,642 [Listener at 0.0.0.0/42813] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 81 msecs
2020-12-03 07:23:35,643 [Listener at 0.0.0.0/42813] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to 0.0.0.0:0
2020-12-03 07:23:35,644 [Listener at 0.0.0.0/42813] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:35,645 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:35,649 [Listener at 0.0.0.0/39762] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:23:35,676 [Listener at 0.0.0.0/39762] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:23:35,681 [Listener at 0.0.0.0/39762] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:23:35,681 [Listener at 0.0.0.0/39762] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:23:35,682 [Listener at 0.0.0.0/39762] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:23:35,687 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:35,687 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:35,689 [Listener at 0.0.0.0/39762] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:39762
2020-12-03 07:23:35,689 [Listener at 0.0.0.0/39762] INFO  namenode.FSNamesystem (FSNamesystem.java:startStandbyServices(1391)) - Starting services required for standby state
2020-12-03 07:23:35,690 [Listener at 0.0.0.0/39762] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.log-roll.period(-1) assuming SECONDS
2020-12-03 07:23:35,690 [Listener at 0.0.0.0/39762] INFO  ha.EditLogTailer (EditLogTailer.java:<init>(208)) - Not going to trigger log rolls on active node because dfs.ha.log-roll.period is negative.
2020-12-03 07:23:35,690 [Listener at 0.0.0.0/39762] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.period.backoff-max(0) assuming SECONDS
2020-12-03 07:23:35,690 [Listener at 0.0.0.0/39762] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.rolledits.timeout(60) assuming SECONDS
2020-12-03 07:23:35,693 [Listener at 0.0.0.0/39762] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:23:35,693 [Listener at 0.0.0.0/39762] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-12-03 07:23:35,694 [Listener at 0.0.0.0/39762] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://ns0
2020-12-03 07:23:35,694 [Listener at 0.0.0.0/39762] INFO  namenode.NameNode (NameNode.java:<init>(944)) - Clients should use ns1 to access this namenode/service.
2020-12-03 07:23:35,701 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2c444798] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:35,701 [Listener at 0.0.0.0/39762] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:23:35,703 [Listener at 0.0.0.0/39762] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:35,704 [Listener at 0.0.0.0/39762] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:23:35,706 [Listener at 0.0.0.0/39762] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:35,707 [Listener at 0.0.0.0/39762] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:23:35,707 [Listener at 0.0.0.0/39762] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:35,708 [Listener at 0.0.0.0/39762] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:35,709 [Listener at 0.0.0.0/39762] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:23:35,710 [Listener at 0.0.0.0/39762] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:23:35,710 [Listener at 0.0.0.0/39762] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 45234
2020-12-03 07:23:35,711 [Listener at 0.0.0.0/39762] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:35,714 [Listener at 0.0.0.0/39762] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3228d990{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:23:35,715 [Listener at 0.0.0.0/39762] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@50b8ae8d{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:23:35,884 [Listener at 0.0.0.0/39762] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3c321bdb{/,file:///tmp/jetty-localhost-45234-hdfs-_-any-410058243952235866.dir/webapp/,AVAILABLE}{/hdfs}
2020-12-03 07:23:35,886 [Listener at 0.0.0.0/39762] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@24855019{HTTP/1.1,[http/1.1]}{localhost:45234}
2020-12-03 07:23:35,886 [Listener at 0.0.0.0/39762] INFO  server.Server (Server.java:doStart(419)) - Started @7562ms
2020-12-03 07:23:35,888 [Listener at 0.0.0.0/39762] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:23:35,888 [Listener at 0.0.0.0/39762] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:23:35,889 [Listener at 0.0.0.0/39762] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:23:35,889 [Listener at 0.0.0.0/39762] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:23:35,889 [Listener at 0.0.0.0/39762] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:23:35,889 [Listener at 0.0.0.0/39762] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:23:35,889 [Listener at 0.0.0.0/39762] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:23:35,890 [Listener at 0.0.0.0/39762] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns1
2020-12-03 07:23:35,890 [Listener at 0.0.0.0/39762] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: true
2020-12-03 07:23:35,891 [Listener at 0.0.0.0/39762] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:35,891 [Listener at 0.0.0.0/39762] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:23:35,891 [Listener at 0.0.0.0/39762] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:23:35,891 [Listener at 0.0.0.0/39762] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:23:35,892 [Listener at 0.0.0.0/39762] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:23:35
2020-12-03 07:23:35,892 [Listener at 0.0.0.0/39762] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:23:35,892 [Listener at 0.0.0.0/39762] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:35,892 [Listener at 0.0.0.0/39762] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:23:35,893 [Listener at 0.0.0.0/39762] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:23:35,904 [Listener at 0.0.0.0/39762] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:23:35,905 [Listener at 0.0.0.0/39762] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:23:35,905 [Listener at 0.0.0.0/39762] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:23:35,905 [Listener at 0.0.0.0/39762] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:23:35,906 [Listener at 0.0.0.0/39762] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:23:35,906 [Listener at 0.0.0.0/39762] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:23:35,906 [Listener at 0.0.0.0/39762] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:23:35,906 [Listener at 0.0.0.0/39762] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:23:35,906 [Listener at 0.0.0.0/39762] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:23:35,906 [Listener at 0.0.0.0/39762] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:23:35,907 [Listener at 0.0.0.0/39762] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:23:35,907 [Listener at 0.0.0.0/39762] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:23:35,907 [Listener at 0.0.0.0/39762] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:23:35,907 [Listener at 0.0.0.0/39762] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:23:35,908 [Listener at 0.0.0.0/39762] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:35,908 [Listener at 0.0.0.0/39762] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:23:35,908 [Listener at 0.0.0.0/39762] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:23:35,914 [Listener at 0.0.0.0/39762] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:23:35,914 [Listener at 0.0.0.0/39762] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:23:35,914 [Listener at 0.0.0.0/39762] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:23:35,915 [Listener at 0.0.0.0/39762] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:23:35,915 [Listener at 0.0.0.0/39762] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:23:35,915 [Listener at 0.0.0.0/39762] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:23:35,915 [Listener at 0.0.0.0/39762] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:23:35,915 [Listener at 0.0.0.0/39762] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:35,916 [Listener at 0.0.0.0/39762] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:23:35,916 [Listener at 0.0.0.0/39762] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:23:35,918 [Listener at 0.0.0.0/39762] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:23:35,918 [Listener at 0.0.0.0/39762] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:23:35,918 [Listener at 0.0.0.0/39762] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:23:35,918 [Listener at 0.0.0.0/39762] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:23:35,919 [Listener at 0.0.0.0/39762] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:23:35,919 [Listener at 0.0.0.0/39762] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:23:35,919 [Listener at 0.0.0.0/39762] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:35,919 [Listener at 0.0.0.0/39762] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:23:35,919 [Listener at 0.0.0.0/39762] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:23:36,006 [Listener at 0.0.0.0/39762] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-7/in_use.lock acquired by nodename 10408@1c04ae08cdfc
2020-12-03 07:23:36,076 [Listener at 0.0.0.0/39762] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-8/in_use.lock acquired by nodename 10408@1c04ae08cdfc
2020-12-03 07:23:36,076 [Listener at 0.0.0.0/39762] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-2-through-3
2020-12-03 07:23:36,079 [Listener at 0.0.0.0/39762] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:23:36,079 [Listener at 0.0.0.0/39762] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-7/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:23:36,081 [Listener at 0.0.0.0/39762] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:23:36,082 [Listener at 0.0.0.0/39762] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:23:36,082 [Listener at 0.0.0.0/39762] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-7/current/fsimage_0000000000000000000
2020-12-03 07:23:36,082 [Listener at 0.0.0.0/39762] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2020-12-03 07:23:36,083 [Listener at 0.0.0.0/39762] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:23:36,083 [Listener at 0.0.0.0/39762] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 162 msecs
2020-12-03 07:23:36,083 [Listener at 0.0.0.0/39762] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to 0.0.0.0:0
2020-12-03 07:23:36,084 [Listener at 0.0.0.0/39762] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:36,085 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:36,089 [Listener at 0.0.0.0/40028] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:23:36,194 [Listener at 0.0.0.0/40028] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:23:36,197 [Listener at 0.0.0.0/40028] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:23:36,197 [Listener at 0.0.0.0/40028] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:23:36,197 [Listener at 0.0.0.0/40028] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:23:36,201 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:36,201 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:36,203 [Listener at 0.0.0.0/40028] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:40028
2020-12-03 07:23:36,203 [Listener at 0.0.0.0/40028] INFO  namenode.FSNamesystem (FSNamesystem.java:startStandbyServices(1391)) - Starting services required for standby state
2020-12-03 07:23:36,203 [Listener at 0.0.0.0/40028] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.log-roll.period(-1) assuming SECONDS
2020-12-03 07:23:36,204 [Listener at 0.0.0.0/40028] INFO  ha.EditLogTailer (EditLogTailer.java:<init>(208)) - Not going to trigger log rolls on active node because dfs.ha.log-roll.period is negative.
2020-12-03 07:23:36,204 [Listener at 0.0.0.0/40028] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.period.backoff-max(0) assuming SECONDS
2020-12-03 07:23:36,204 [Listener at 0.0.0.0/40028] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.rolledits.timeout(60) assuming SECONDS
2020-12-03 07:23:36,214 [Listener at 0.0.0.0/40028] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-12-03 07:23:36,232 [Listener at 0.0.0.0/40028] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-12-03 07:23:36,244 [Listener at 0.0.0.0/40028] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-12-03 07:23:36,249 [Listener at 0.0.0.0/40028] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:23:36,254 [Listener at 0.0.0.0/40028] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:36,267 [Listener at 0.0.0.0/40028] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:23:36,274 [Listener at 0.0.0.0/40028] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:23:36,276 [Listener at 0.0.0.0/40028] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:36,281 [Listener at 0.0.0.0/40028] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:23:36,290 [Listener at 0.0.0.0/40028] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:36211
2020-12-03 07:23:36,293 [Listener at 0.0.0.0/40028] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:23:36,293 [Listener at 0.0.0.0/40028] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:23:36,315 [Listener at 0.0.0.0/40028] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:36,316 [Listener at 0.0.0.0/40028] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:23:36,319 [Listener at 0.0.0.0/40028] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:36,319 [Listener at 0.0.0.0/40028] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:23:36,320 [Listener at 0.0.0.0/40028] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:36,320 [Listener at 0.0.0.0/40028] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:36,324 [Listener at 0.0.0.0/40028] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 33425
2020-12-03 07:23:36,324 [Listener at 0.0.0.0/40028] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:36,327 [Listener at 0.0.0.0/40028] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2472c7d8{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:23:36,328 [Listener at 0.0.0.0/40028] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@22175d4f{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:23:36,496 [Listener at 0.0.0.0/40028] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@38600b{/,file:///tmp/jetty-localhost-33425-datanode-_-any-4478244111465685441.dir/webapp/,AVAILABLE}{/datanode}
2020-12-03 07:23:36,498 [Listener at 0.0.0.0/40028] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@669d2b1b{HTTP/1.1,[http/1.1]}{localhost:33425}
2020-12-03 07:23:36,499 [Listener at 0.0.0.0/40028] INFO  server.Server (Server.java:doStart(419)) - Started @8174ms
2020-12-03 07:23:37,107 [Listener at 0.0.0.0/40028] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:34740
2020-12-03 07:23:37,108 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5a101b1c] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:37,109 [Listener at 0.0.0.0/40028] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:23:37,109 [Listener at 0.0.0.0/40028] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:23:37,126 [Listener at 0.0.0.0/40028] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:37,127 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:37,134 [Listener at localhost/34886] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:34886
2020-12-03 07:23:37,149 [Listener at localhost/34886] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns0,ns1
2020-12-03 07:23:37,150 [Listener at localhost/34886] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns0,ns1
2020-12-03 07:23:37,162 [Thread-156] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:32986 starting to offer service
2020-12-03 07:23:37,162 [Thread-158] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:39762 starting to offer service
2020-12-03 07:23:37,162 [Thread-157] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42813 starting to offer service
2020-12-03 07:23:37,163 [Thread-159] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40028 starting to offer service
2020-12-03 07:23:37,172 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:37,172 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:37,177 [Listener at localhost/34886] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-12-03 07:23:37,178 [Listener at localhost/34886] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-12-03 07:23:37,179 [Listener at localhost/34886] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-12-03 07:23:37,180 [Listener at localhost/34886] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:23:37,180 [Listener at localhost/34886] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:37,181 [Listener at localhost/34886] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:23:37,181 [Listener at localhost/34886] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:23:37,182 [Listener at localhost/34886] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:37,182 [Listener at localhost/34886] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:23:37,183 [Listener at localhost/34886] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:41280
2020-12-03 07:23:37,183 [Listener at localhost/34886] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:23:37,183 [Listener at localhost/34886] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:23:37,186 [Listener at localhost/34886] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:37,187 [Listener at localhost/34886] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:23:37,188 [Listener at localhost/34886] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:37,189 [Listener at localhost/34886] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:23:37,189 [Listener at localhost/34886] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:37,189 [Listener at localhost/34886] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:37,190 [Listener at localhost/34886] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 38031
2020-12-03 07:23:37,190 [Listener at localhost/34886] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:37,192 [Listener at localhost/34886] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6ac97b84{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:23:37,192 [Listener at localhost/34886] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@35c09b94{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:23:37,384 [Listener at localhost/34886] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6a84bc2a{/,file:///tmp/jetty-localhost-38031-datanode-_-any-357043852530163614.dir/webapp/,AVAILABLE}{/datanode}
2020-12-03 07:23:37,385 [Listener at localhost/34886] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@5183d589{HTTP/1.1,[http/1.1]}{localhost:38031}
2020-12-03 07:23:37,386 [Listener at localhost/34886] INFO  server.Server (Server.java:doStart(419)) - Started @9061ms
2020-12-03 07:23:37,449 [Thread-159] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:23:37,507 [Listener at localhost/34886] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:33342
2020-12-03 07:23:37,508 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@682c1e93] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:37,508 [Listener at localhost/34886] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:23:37,508 [Listener at localhost/34886] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:23:37,508 [Listener at localhost/34886] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:37,509 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:37,512 [Listener at localhost/39821] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:39821
2020-12-03 07:23:37,516 [Listener at localhost/39821] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns0,ns1
2020-12-03 07:23:37,517 [Listener at localhost/39821] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns0,ns1
2020-12-03 07:23:37,518 [Thread-185] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:32986 starting to offer service
2020-12-03 07:23:37,518 [Thread-186] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42813 starting to offer service
2020-12-03 07:23:37,519 [Thread-187] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:39762 starting to offer service
2020-12-03 07:23:37,519 [Thread-188] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40028 starting to offer service
2020-12-03 07:23:37,521 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:37,521 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:37,527 [Thread-185] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:23:37,529 [Listener at localhost/39821] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-12-03 07:23:37,531 [Listener at localhost/39821] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-12-03 07:23:37,531 [Listener at localhost/39821] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-12-03 07:23:37,532 [Listener at localhost/39821] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:23:37,533 [Listener at localhost/39821] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:37,533 [Listener at localhost/39821] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:23:37,534 [Listener at localhost/39821] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:23:37,534 [Listener at localhost/39821] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:37,534 [Listener at localhost/39821] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:23:37,535 [Listener at localhost/39821] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:43860
2020-12-03 07:23:37,535 [Listener at localhost/39821] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:23:37,535 [Listener at localhost/39821] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:23:37,538 [Listener at localhost/39821] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:37,539 [Listener at localhost/39821] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:23:37,540 [Listener at localhost/39821] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:37,541 [Listener at localhost/39821] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:23:37,541 [Listener at localhost/39821] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:37,541 [Listener at localhost/39821] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:37,542 [Listener at localhost/39821] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 36133
2020-12-03 07:23:37,542 [Listener at localhost/39821] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:37,544 [Listener at localhost/39821] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@baf1bb3{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:23:37,545 [Listener at localhost/39821] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@25d958c6{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:23:37,564 [Thread-159] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 10408@1c04ae08cdfc
2020-12-03 07:23:37,565 [Thread-159] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1 is not formatted for namespace 1338103220. Formatting...
2020-12-03 07:23:37,566 [Thread-159] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-d252d603-5c4f-4562-918f-2c3750f127c8 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1 
2020-12-03 07:23:37,608 [Thread-185] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 10408@1c04ae08cdfc
2020-12-03 07:23:37,608 [Thread-185] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3 is not formatted for namespace 2077292191. Formatting...
2020-12-03 07:23:37,610 [Thread-185] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-92e3d219-e1a4-4f3f-97a2-fca243ee2c69 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3 
2020-12-03 07:23:37,715 [Listener at localhost/39821] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5d39f2d8{/,file:///tmp/jetty-localhost-36133-datanode-_-any-150591618867385155.dir/webapp/,AVAILABLE}{/datanode}
2020-12-03 07:23:37,716 [Listener at localhost/39821] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6ad6fa53{HTTP/1.1,[http/1.1]}{localhost:36133}
2020-12-03 07:23:37,716 [Listener at localhost/39821] INFO  server.Server (Server.java:doStart(419)) - Started @9392ms
2020-12-03 07:23:37,734 [Listener at localhost/39821] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:36036
2020-12-03 07:23:37,734 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5e742e4] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:37,734 [Listener at localhost/39821] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:23:37,734 [Listener at localhost/39821] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:23:37,735 [Listener at localhost/39821] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:37,736 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:37,739 [Listener at localhost/37605] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:37605
2020-12-03 07:23:37,743 [Listener at localhost/37605] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns0,ns1
2020-12-03 07:23:37,744 [Listener at localhost/37605] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns0,ns1
2020-12-03 07:23:37,745 [Thread-210] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:32986 starting to offer service
2020-12-03 07:23:37,745 [Thread-211] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42813 starting to offer service
2020-12-03 07:23:37,746 [Thread-212] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:39762 starting to offer service
2020-12-03 07:23:37,747 [Thread-213] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40028 starting to offer service
2020-12-03 07:23:37,747 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:37,749 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:37,752 [Thread-211] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:23:37,753 [Listener at localhost/37605] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 3 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-12-03 07:23:37,754 [Listener at localhost/37605] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7
2020-12-03 07:23:37,755 [Listener at localhost/37605] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-12-03 07:23:37,756 [Listener at localhost/37605] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:23:37,756 [Listener at localhost/37605] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:37,757 [Listener at localhost/37605] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:23:37,757 [Listener at localhost/37605] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:23:37,758 [Listener at localhost/37605] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:37,758 [Listener at localhost/37605] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:23:37,759 [Listener at localhost/37605] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:33459
2020-12-03 07:23:37,759 [Listener at localhost/37605] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:23:37,759 [Listener at localhost/37605] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:23:37,761 [Listener at localhost/37605] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:37,762 [Listener at localhost/37605] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:23:37,764 [Listener at localhost/37605] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:37,764 [Listener at localhost/37605] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:23:37,764 [Listener at localhost/37605] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:37,765 [Listener at localhost/37605] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:37,765 [Listener at localhost/37605] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 37399
2020-12-03 07:23:37,765 [Listener at localhost/37605] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:37,767 [Listener at localhost/37605] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6d2d99fc{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:23:37,767 [Listener at localhost/37605] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5e3a39cd{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:23:37,826 [Thread-159] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 10408@1c04ae08cdfc
2020-12-03 07:23:37,826 [Thread-211] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 10408@1c04ae08cdfc
2020-12-03 07:23:37,826 [Thread-159] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2 is not formatted for namespace 1338103220. Formatting...
2020-12-03 07:23:37,826 [Thread-211] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5 is not formatted for namespace 2077292191. Formatting...
2020-12-03 07:23:37,827 [Thread-159] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-2c8d6396-1620-4cc7-8cb0-a097b414b982 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2 
2020-12-03 07:23:37,827 [Thread-211] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-191698f0-bb42-4b8c-af23-5c0b24e998b3 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5 
2020-12-03 07:23:37,876 [Thread-185] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 10408@1c04ae08cdfc
2020-12-03 07:23:37,877 [Thread-185] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4 is not formatted for namespace 2077292191. Formatting...
2020-12-03 07:23:37,877 [Thread-185] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-ed4e0c39-1e32-430e-b11d-10ea474dda16 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4 
2020-12-03 07:23:37,940 [Listener at localhost/37605] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1440c311{/,file:///tmp/jetty-localhost-37399-datanode-_-any-8597494873177320638.dir/webapp/,AVAILABLE}{/datanode}
2020-12-03 07:23:37,941 [Listener at localhost/37605] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@189b5fb1{HTTP/1.1,[http/1.1]}{localhost:37399}
2020-12-03 07:23:37,942 [Listener at localhost/37605] INFO  server.Server (Server.java:doStart(419)) - Started @9617ms
2020-12-03 07:23:37,978 [Listener at localhost/37605] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:36875
2020-12-03 07:23:37,979 [Listener at localhost/37605] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:23:37,979 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1ddd3478] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:37,979 [Listener at localhost/37605] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:23:37,979 [Listener at localhost/37605] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:37,980 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:37,983 [Listener at localhost/37926] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:37926
2020-12-03 07:23:37,988 [Listener at localhost/37926] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns0,ns1
2020-12-03 07:23:37,988 [Listener at localhost/37926] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns0,ns1
2020-12-03 07:23:37,989 [Thread-235] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:32986 starting to offer service
2020-12-03 07:23:37,989 [Thread-236] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42813 starting to offer service
2020-12-03 07:23:37,990 [Thread-237] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:39762 starting to offer service
2020-12-03 07:23:37,991 [Thread-238] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40028 starting to offer service
2020-12-03 07:23:37,992 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:37,993 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:38,022 [Thread-237] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:23:38,043 [Thread-159] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1199477258-172.17.0.8-1606980214994
2020-12-03 07:23:38,044 [Thread-159] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-1199477258-172.17.0.8-1606980214994
2020-12-03 07:23:38,044 [Thread-159] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1 and block pool id BP-1199477258-172.17.0.8-1606980214994 is not formatted. Formatting ...
2020-12-03 07:23:38,044 [Thread-159] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1199477258-172.17.0.8-1606980214994 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-1199477258-172.17.0.8-1606980214994/current
2020-12-03 07:23:38,072 [Thread-185] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1192165426-172.17.0.8-1606980210852
2020-12-03 07:23:38,072 [Thread-185] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-1192165426-172.17.0.8-1606980210852
2020-12-03 07:23:38,072 [Thread-185] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3 and block pool id BP-1192165426-172.17.0.8-1606980210852 is not formatted. Formatting ...
2020-12-03 07:23:38,073 [Thread-185] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1192165426-172.17.0.8-1606980210852 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-1192165426-172.17.0.8-1606980210852/current
2020-12-03 07:23:38,114 [Thread-237] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/in_use.lock acquired by nodename 10408@1c04ae08cdfc
2020-12-03 07:23:38,114 [Thread-211] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 10408@1c04ae08cdfc
2020-12-03 07:23:38,114 [Thread-237] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7 is not formatted for namespace 1338103220. Formatting...
2020-12-03 07:23:38,114 [Thread-211] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6 is not formatted for namespace 2077292191. Formatting...
2020-12-03 07:23:38,116 [Thread-237] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-707a6798-cced-414e-becf-df59de1fd486 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7 
2020-12-03 07:23:38,116 [Thread-211] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-d66a95d5-e758-44e2-aeb8-ddd60f895dee for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6 
2020-12-03 07:23:38,227 [Thread-159] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1199477258-172.17.0.8-1606980214994
2020-12-03 07:23:38,228 [Thread-159] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-1199477258-172.17.0.8-1606980214994
2020-12-03 07:23:38,228 [Thread-159] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2 and block pool id BP-1199477258-172.17.0.8-1606980214994 is not formatted. Formatting ...
2020-12-03 07:23:38,228 [Thread-159] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1199477258-172.17.0.8-1606980214994 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-1199477258-172.17.0.8-1606980214994/current
2020-12-03 07:23:38,264 [Thread-185] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1192165426-172.17.0.8-1606980210852
2020-12-03 07:23:38,264 [Thread-185] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-1192165426-172.17.0.8-1606980210852
2020-12-03 07:23:38,264 [Thread-185] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4 and block pool id BP-1192165426-172.17.0.8-1606980210852 is not formatted. Formatting ...
2020-12-03 07:23:38,265 [Thread-185] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1192165426-172.17.0.8-1606980210852 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-1192165426-172.17.0.8-1606980210852/current
2020-12-03 07:23:38,309 [Thread-211] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1192165426-172.17.0.8-1606980210852
2020-12-03 07:23:38,310 [Thread-211] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-1192165426-172.17.0.8-1606980210852
2020-12-03 07:23:38,310 [Thread-211] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5 and block pool id BP-1192165426-172.17.0.8-1606980210852 is not formatted. Formatting ...
2020-12-03 07:23:38,310 [Thread-211] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1192165426-172.17.0.8-1606980210852 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-1192165426-172.17.0.8-1606980210852/current
2020-12-03 07:23:38,409 [Thread-237] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/in_use.lock acquired by nodename 10408@1c04ae08cdfc
2020-12-03 07:23:38,409 [Thread-237] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8 is not formatted for namespace 1338103220. Formatting...
2020-12-03 07:23:38,409 [Thread-237] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-78e24e72-4b84-4d28-a4dd-af91ad349ab5 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8 
2020-12-03 07:23:38,412 [Thread-157] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:23:38,412 [Thread-157] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1 has already been used.
2020-12-03 07:23:38,412 [Thread-159] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1338103220;bpid=BP-1199477258-172.17.0.8-1606980214994;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1338103220;c=1606980214994;bpid=BP-1199477258-172.17.0.8-1606980214994;dnuuid=null
2020-12-03 07:23:38,412 [Thread-157] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2 has already been used.
2020-12-03 07:23:38,426 [Thread-157] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1192165426-172.17.0.8-1606980210852
2020-12-03 07:23:38,426 [Thread-157] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-1192165426-172.17.0.8-1606980210852
2020-12-03 07:23:38,427 [Thread-157] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1 and block pool id BP-1192165426-172.17.0.8-1606980210852 is not formatted. Formatting ...
2020-12-03 07:23:38,427 [Thread-157] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1192165426-172.17.0.8-1606980210852 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-1192165426-172.17.0.8-1606980210852/current
2020-12-03 07:23:38,452 [Thread-185] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=2077292191;bpid=BP-1192165426-172.17.0.8-1606980210852;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=2077292191;c=1606980210852;bpid=BP-1192165426-172.17.0.8-1606980210852;dnuuid=null
2020-12-03 07:23:38,453 [Thread-187] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:23:38,454 [Thread-187] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3 has already been used.
2020-12-03 07:23:38,454 [Thread-187] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4 has already been used.
2020-12-03 07:23:38,465 [Thread-187] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1199477258-172.17.0.8-1606980214994
2020-12-03 07:23:38,465 [Thread-187] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-1199477258-172.17.0.8-1606980214994
2020-12-03 07:23:38,466 [Thread-187] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3 and block pool id BP-1199477258-172.17.0.8-1606980214994 is not formatted. Formatting ...
2020-12-03 07:23:38,466 [Thread-187] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1199477258-172.17.0.8-1606980214994 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-1199477258-172.17.0.8-1606980214994/current
2020-12-03 07:23:38,518 [Thread-211] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1192165426-172.17.0.8-1606980210852
2020-12-03 07:23:38,519 [Thread-211] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-1192165426-172.17.0.8-1606980210852
2020-12-03 07:23:38,519 [Thread-211] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6 and block pool id BP-1192165426-172.17.0.8-1606980210852 is not formatted. Formatting ...
2020-12-03 07:23:38,519 [Thread-211] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1192165426-172.17.0.8-1606980210852 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-1192165426-172.17.0.8-1606980210852/current
2020-12-03 07:23:38,549 [IPC Server handler 2 on default port 32986] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:38,558 [Listener at localhost/37926] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:38,558 [Listener at localhost/37926] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:38,620 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1199477258-172.17.0.8-1606980214994
2020-12-03 07:23:38,620 [Thread-157] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1192165426-172.17.0.8-1606980210852
2020-12-03 07:23:38,620 [Thread-237] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-1199477258-172.17.0.8-1606980214994
2020-12-03 07:23:38,620 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7 and block pool id BP-1199477258-172.17.0.8-1606980214994 is not formatted. Formatting ...
2020-12-03 07:23:38,620 [Thread-157] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-1192165426-172.17.0.8-1606980210852
2020-12-03 07:23:38,621 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1199477258-172.17.0.8-1606980214994 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-1199477258-172.17.0.8-1606980214994/current
2020-12-03 07:23:38,621 [Thread-157] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2 and block pool id BP-1192165426-172.17.0.8-1606980210852 is not formatted. Formatting ...
2020-12-03 07:23:38,621 [Thread-157] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1192165426-172.17.0.8-1606980210852 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-1192165426-172.17.0.8-1606980210852/current
2020-12-03 07:23:38,661 [IPC Server handler 4 on default port 32986] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:38,662 [Listener at localhost/37926] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:38,662 [Listener at localhost/37926] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:38,666 [Thread-187] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1199477258-172.17.0.8-1606980214994
2020-12-03 07:23:38,667 [Thread-187] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-1199477258-172.17.0.8-1606980214994
2020-12-03 07:23:38,667 [Thread-187] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4 and block pool id BP-1199477258-172.17.0.8-1606980214994 is not formatted. Formatting ...
2020-12-03 07:23:38,667 [Thread-187] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1199477258-172.17.0.8-1606980214994 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-1199477258-172.17.0.8-1606980214994/current
2020-12-03 07:23:38,704 [Thread-211] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=2077292191;bpid=BP-1192165426-172.17.0.8-1606980210852;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=2077292191;c=1606980210852;bpid=BP-1192165426-172.17.0.8-1606980210852;dnuuid=null
2020-12-03 07:23:38,705 [Thread-212] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:23:38,705 [Thread-212] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5 has already been used.
2020-12-03 07:23:38,705 [Thread-212] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6 has already been used.
2020-12-03 07:23:38,719 [Thread-212] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1199477258-172.17.0.8-1606980214994
2020-12-03 07:23:38,720 [Thread-212] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-1199477258-172.17.0.8-1606980214994
2020-12-03 07:23:38,720 [Thread-212] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5 and block pool id BP-1199477258-172.17.0.8-1606980214994 is not formatted. Formatting ...
2020-12-03 07:23:38,720 [Thread-212] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1199477258-172.17.0.8-1606980214994 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-1199477258-172.17.0.8-1606980214994/current
2020-12-03 07:23:38,765 [IPC Server handler 0 on default port 32986] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:38,766 [Listener at localhost/37926] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:38,767 [Listener at localhost/37926] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:38,803 [Thread-157] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=2077292191;bpid=BP-1192165426-172.17.0.8-1606980210852;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=2077292191;c=1606980210852;bpid=BP-1192165426-172.17.0.8-1606980210852;dnuuid=null
2020-12-03 07:23:38,815 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1199477258-172.17.0.8-1606980214994
2020-12-03 07:23:38,816 [Thread-237] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-1199477258-172.17.0.8-1606980214994
2020-12-03 07:23:38,816 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8 and block pool id BP-1199477258-172.17.0.8-1606980214994 is not formatted. Formatting ...
2020-12-03 07:23:38,816 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1199477258-172.17.0.8-1606980214994 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-1199477258-172.17.0.8-1606980214994/current
2020-12-03 07:23:38,836 [Thread-187] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1338103220;bpid=BP-1199477258-172.17.0.8-1606980214994;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1338103220;c=1606980214994;bpid=BP-1199477258-172.17.0.8-1606980214994;dnuuid=null
2020-12-03 07:23:38,873 [IPC Server handler 9 on default port 32986] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:38,874 [Listener at localhost/37926] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:38,874 [Listener at localhost/37926] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:38,893 [Thread-212] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1199477258-172.17.0.8-1606980214994
2020-12-03 07:23:38,893 [Thread-212] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-1199477258-172.17.0.8-1606980214994
2020-12-03 07:23:38,894 [Thread-212] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6 and block pool id BP-1199477258-172.17.0.8-1606980214994 is not formatted. Formatting ...
2020-12-03 07:23:38,894 [Thread-212] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1199477258-172.17.0.8-1606980214994 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-1199477258-172.17.0.8-1606980214994/current
2020-12-03 07:23:38,976 [IPC Server handler 1 on default port 32986] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:38,977 [Listener at localhost/37926] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:38,977 [Listener at localhost/37926] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:39,013 [Thread-159] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID d23de78e-12d8-4e37-95c6-1061610640b4
2020-12-03 07:23:39,013 [Thread-236] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:23:39,013 [Thread-237] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1338103220;bpid=BP-1199477258-172.17.0.8-1606980214994;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1338103220;c=1606980214994;bpid=BP-1199477258-172.17.0.8-1606980214994;dnuuid=null
2020-12-03 07:23:39,014 [Thread-236] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7 has already been used.
2020-12-03 07:23:39,014 [Thread-236] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8 has already been used.
2020-12-03 07:23:39,029 [Thread-236] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1192165426-172.17.0.8-1606980210852
2020-12-03 07:23:39,029 [Thread-236] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-1192165426-172.17.0.8-1606980210852
2020-12-03 07:23:39,029 [Thread-236] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7 and block pool id BP-1192165426-172.17.0.8-1606980210852 is not formatted. Formatting ...
2020-12-03 07:23:39,029 [Thread-236] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1192165426-172.17.0.8-1606980210852 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-1192165426-172.17.0.8-1606980210852/current
2020-12-03 07:23:39,055 [Thread-185] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 50567619-bc66-4185-aad7-ed7a22a9939e
2020-12-03 07:23:39,080 [IPC Server handler 3 on default port 32986] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:39,080 [Listener at localhost/37926] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:39,081 [Listener at localhost/37926] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:39,098 [Thread-212] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1338103220;bpid=BP-1199477258-172.17.0.8-1606980214994;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1338103220;c=1606980214994;bpid=BP-1199477258-172.17.0.8-1606980214994;dnuuid=null
2020-12-03 07:23:39,168 [Thread-159] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-d252d603-5c4f-4562-918f-2c3750f127c8
2020-12-03 07:23:39,168 [Thread-185] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-92e3d219-e1a4-4f3f-97a2-fca243ee2c69
2020-12-03 07:23:39,171 [Thread-185] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, StorageType: DISK
2020-12-03 07:23:39,171 [Thread-159] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, StorageType: DISK
2020-12-03 07:23:39,173 [Thread-185] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-ed4e0c39-1e32-430e-b11d-10ea474dda16
2020-12-03 07:23:39,174 [Thread-185] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, StorageType: DISK
2020-12-03 07:23:39,176 [Thread-159] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-2c8d6396-1620-4cc7-8cb0-a097b414b982
2020-12-03 07:23:39,176 [Thread-159] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, StorageType: DISK
2020-12-03 07:23:39,181 [Thread-185] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:23:39,181 [Thread-159] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:23:39,183 [IPC Server handler 6 on default port 32986] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:39,183 [Listener at localhost/37926] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:39,184 [Listener at localhost/37926] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:39,188 [Thread-187] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-12-03 07:23:39,188 [Thread-185] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-12-03 07:23:39,197 [Thread-159] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-12-03 07:23:39,197 [Thread-157] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-12-03 07:23:39,230 [Thread-185] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-12-03 07:23:39,232 [Thread-185] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-12-03 07:23:39,233 [Thread-185] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-12-03 07:23:39,246 [Thread-185] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1192165426-172.17.0.8-1606980210852
2020-12-03 07:23:39,252 [Thread-157] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-12-03 07:23:39,252 [Thread-157] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-12-03 07:23:39,253 [Thread-157] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-12-03 07:23:39,246 [Thread-187] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-12-03 07:23:39,253 [Thread-236] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1192165426-172.17.0.8-1606980210852
2020-12-03 07:23:39,254 [Thread-236] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-1192165426-172.17.0.8-1606980210852
2020-12-03 07:23:39,255 [Thread-187] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-12-03 07:23:39,264 [Thread-159] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-12-03 07:23:39,264 [Thread-187] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1199477258-172.17.0.8-1606980214994
2020-12-03 07:23:39,255 [Thread-236] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8 and block pool id BP-1192165426-172.17.0.8-1606980210852 is not formatted. Formatting ...
2020-12-03 07:23:39,264 [Thread-157] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1192165426-172.17.0.8-1606980210852
2020-12-03 07:23:39,264 [Thread-256] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1192165426-172.17.0.8-1606980210852 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3...
2020-12-03 07:23:39,264 [Thread-257] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1192165426-172.17.0.8-1606980210852 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4...
2020-12-03 07:23:39,264 [Thread-159] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-12-03 07:23:39,264 [Thread-236] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1192165426-172.17.0.8-1606980210852 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-1192165426-172.17.0.8-1606980210852/current
2020-12-03 07:23:39,265 [Thread-159] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1199477258-172.17.0.8-1606980214994
2020-12-03 07:23:39,265 [Thread-259] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1192165426-172.17.0.8-1606980210852 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2...
2020-12-03 07:23:39,265 [Thread-258] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1192165426-172.17.0.8-1606980210852 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1...
2020-12-03 07:23:39,286 [IPC Server handler 5 on default port 32986] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:39,297 [Listener at localhost/37926] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:39,298 [Listener at localhost/37926] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:39,319 [Thread-211] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 6474728c-8e98-4f1d-a1f7-e54d7a9024e5
2020-12-03 07:23:39,332 [Thread-211] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-191698f0-bb42-4b8c-af23-5c0b24e998b3
2020-12-03 07:23:39,343 [Thread-211] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, StorageType: DISK
2020-12-03 07:23:39,346 [Thread-211] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-d66a95d5-e758-44e2-aeb8-ddd60f895dee
2020-12-03 07:23:39,351 [Thread-211] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, StorageType: DISK
2020-12-03 07:23:39,352 [Thread-211] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:23:39,353 [Thread-211] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-12-03 07:23:39,354 [Thread-212] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1199477258-172.17.0.8-1606980214994
2020-12-03 07:23:39,363 [Thread-211] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-12-03 07:23:39,363 [Thread-266] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1199477258-172.17.0.8-1606980214994 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5...
2020-12-03 07:23:39,363 [Thread-211] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-12-03 07:23:39,366 [Thread-259] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1192165426-172.17.0.8-1606980210852 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2: 101ms
2020-12-03 07:23:39,363 [Thread-267] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1199477258-172.17.0.8-1606980214994 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6...
2020-12-03 07:23:39,368 [Thread-211] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-12-03 07:23:39,369 [Thread-211] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1192165426-172.17.0.8-1606980210852
2020-12-03 07:23:39,369 [Thread-256] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1192165426-172.17.0.8-1606980210852 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3: 105ms
2020-12-03 07:23:39,372 [Thread-257] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1192165426-172.17.0.8-1606980210852 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4: 107ms
2020-12-03 07:23:39,372 [Thread-258] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1192165426-172.17.0.8-1606980210852 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1: 106ms
2020-12-03 07:23:39,372 [Thread-185] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1192165426-172.17.0.8-1606980210852: 120ms
2020-12-03 07:23:39,372 [Thread-157] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1192165426-172.17.0.8-1606980210852: 108ms
2020-12-03 07:23:39,375 [Thread-268] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1199477258-172.17.0.8-1606980214994 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1...
2020-12-03 07:23:39,375 [Thread-269] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1199477258-172.17.0.8-1606980214994 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3...
2020-12-03 07:23:39,375 [Thread-270] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1199477258-172.17.0.8-1606980214994 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2...
2020-12-03 07:23:39,375 [Thread-272] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1192165426-172.17.0.8-1606980210852 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3...
2020-12-03 07:23:39,375 [Thread-271] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1192165426-172.17.0.8-1606980210852 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1...
2020-12-03 07:23:39,375 [Thread-273] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1199477258-172.17.0.8-1606980214994 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4...
2020-12-03 07:23:39,375 [Thread-272] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-1192165426-172.17.0.8-1606980210852/current/replicas doesn't exist 
2020-12-03 07:23:39,377 [Thread-275] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1192165426-172.17.0.8-1606980210852 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2...
2020-12-03 07:23:39,375 [Thread-271] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-1192165426-172.17.0.8-1606980210852/current/replicas doesn't exist 
2020-12-03 07:23:39,378 [Thread-275] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-1192165426-172.17.0.8-1606980210852/current/replicas doesn't exist 
2020-12-03 07:23:39,378 [Thread-274] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1192165426-172.17.0.8-1606980210852 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4...
2020-12-03 07:23:39,378 [Thread-274] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-1192165426-172.17.0.8-1606980210852/current/replicas doesn't exist 
2020-12-03 07:23:39,385 [Thread-274] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1192165426-172.17.0.8-1606980210852 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4: 7ms
2020-12-03 07:23:39,385 [Thread-272] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1192165426-172.17.0.8-1606980210852 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3: 9ms
2020-12-03 07:23:39,385 [Thread-275] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1192165426-172.17.0.8-1606980210852 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2: 8ms
2020-12-03 07:23:39,386 [Thread-271] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1192165426-172.17.0.8-1606980210852 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1: 10ms
2020-12-03 07:23:39,388 [Thread-185] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1192165426-172.17.0.8-1606980210852: 13ms
2020-12-03 07:23:39,388 [Thread-157] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1192165426-172.17.0.8-1606980210852: 14ms
2020-12-03 07:23:39,392 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1192165426-172.17.0.8-1606980210852 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-12-03 07:23:39,394 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, DS-92e3d219-e1a4-4f3f-97a2-fca243ee2c69): finished scanning block pool BP-1192165426-172.17.0.8-1606980210852
2020-12-03 07:23:39,392 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1192165426-172.17.0.8-1606980210852 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-12-03 07:23:39,392 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1192165426-172.17.0.8-1606980210852 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-12-03 07:23:39,393 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1192165426-172.17.0.8-1606980210852 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-12-03 07:23:39,402 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, DS-ed4e0c39-1e32-430e-b11d-10ea474dda16): finished scanning block pool BP-1192165426-172.17.0.8-1606980210852
2020-12-03 07:23:39,402 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, DS-2c8d6396-1620-4cc7-8cb0-a097b414b982): finished scanning block pool BP-1192165426-172.17.0.8-1606980210852
2020-12-03 07:23:39,404 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, DS-d252d603-5c4f-4562-918f-2c3750f127c8): finished scanning block pool BP-1192165426-172.17.0.8-1606980210852
2020-12-03 07:23:39,404 [Thread-267] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1199477258-172.17.0.8-1606980214994 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6: 36ms
2020-12-03 07:23:39,404 [Thread-266] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1199477258-172.17.0.8-1606980214994 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5: 42ms
2020-12-03 07:23:39,410 [Thread-212] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1199477258-172.17.0.8-1606980214994: 56ms
2020-12-03 07:23:39,418 [Thread-286] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1199477258-172.17.0.8-1606980214994 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5...
2020-12-03 07:23:39,418 [Thread-289] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1199477258-172.17.0.8-1606980214994 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6...
2020-12-03 07:23:39,418 [Thread-286] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-1199477258-172.17.0.8-1606980214994/current/replicas doesn't exist 
2020-12-03 07:23:39,419 [Thread-269] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1199477258-172.17.0.8-1606980214994 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3: 44ms
2020-12-03 07:23:39,419 [IPC Server handler 8 on default port 32986] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:39,420 [Listener at localhost/37926] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:39,420 [Listener at localhost/37926] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:39,412 [Thread-270] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1199477258-172.17.0.8-1606980214994 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2: 38ms
2020-12-03 07:23:39,415 [Thread-268] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1199477258-172.17.0.8-1606980214994 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1: 40ms
2020-12-03 07:23:39,413 [Thread-273] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1199477258-172.17.0.8-1606980214994 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4: 37ms
2020-12-03 07:23:39,430 [Thread-159] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1199477258-172.17.0.8-1606980214994: 56ms
2020-12-03 07:23:39,431 [Thread-290] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1199477258-172.17.0.8-1606980214994 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1...
2020-12-03 07:23:39,431 [Thread-290] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-1199477258-172.17.0.8-1606980214994/current/replicas doesn't exist 
2020-12-03 07:23:39,432 [Thread-290] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1199477258-172.17.0.8-1606980214994 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1: 0ms
2020-12-03 07:23:39,419 [Thread-286] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1199477258-172.17.0.8-1606980214994 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5: 1ms
2020-12-03 07:23:39,418 [Thread-289] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-1199477258-172.17.0.8-1606980214994/current/replicas doesn't exist 
2020-12-03 07:23:39,418 [Thread-288] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1192165426-172.17.0.8-1606980210852 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6...
2020-12-03 07:23:39,434 [Thread-289] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1199477258-172.17.0.8-1606980214994 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6: 15ms
2020-12-03 07:23:39,434 [Thread-212] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1199477258-172.17.0.8-1606980214994: 16ms
2020-12-03 07:23:39,418 [Thread-287] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1192165426-172.17.0.8-1606980210852 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5...
2020-12-03 07:23:39,437 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1199477258-172.17.0.8-1606980214994 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-12-03 07:23:39,431 [Thread-291] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1199477258-172.17.0.8-1606980214994 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2...
2020-12-03 07:23:39,431 [Thread-236] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=2077292191;bpid=BP-1192165426-172.17.0.8-1606980210852;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=2077292191;c=1606980210852;bpid=BP-1192165426-172.17.0.8-1606980210852;dnuuid=null
2020-12-03 07:23:39,430 [Thread-187] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1199477258-172.17.0.8-1606980214994: 56ms
2020-12-03 07:23:39,452 [Thread-291] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-1199477258-172.17.0.8-1606980214994/current/replicas doesn't exist 
2020-12-03 07:23:39,452 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, DS-191698f0-bb42-4b8c-af23-5c0b24e998b3): finished scanning block pool BP-1199477258-172.17.0.8-1606980214994
2020-12-03 07:23:39,453 [Thread-296] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1199477258-172.17.0.8-1606980214994 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4...
2020-12-03 07:23:39,453 [Thread-296] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-1199477258-172.17.0.8-1606980214994/current/replicas doesn't exist 
2020-12-03 07:23:39,453 [Thread-291] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1199477258-172.17.0.8-1606980214994 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2: 1ms
2020-12-03 07:23:39,453 [Thread-159] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1199477258-172.17.0.8-1606980214994: 22ms
2020-12-03 07:23:39,453 [Thread-295] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1199477258-172.17.0.8-1606980214994 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3...
2020-12-03 07:23:39,453 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1199477258-172.17.0.8-1606980214994 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-12-03 07:23:39,453 [Thread-295] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-1199477258-172.17.0.8-1606980214994/current/replicas doesn't exist 
2020-12-03 07:23:39,454 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, DS-d66a95d5-e758-44e2-aeb8-ddd60f895dee): finished scanning block pool BP-1199477258-172.17.0.8-1606980214994
2020-12-03 07:23:39,454 [Thread-295] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1199477258-172.17.0.8-1606980214994 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3: 0ms
2020-12-03 07:23:39,454 [Thread-296] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1199477258-172.17.0.8-1606980214994 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4: 1ms
2020-12-03 07:23:39,454 [Thread-187] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1199477258-172.17.0.8-1606980214994: 2ms
2020-12-03 07:23:39,462 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, DS-d66a95d5-e758-44e2-aeb8-ddd60f895dee): no suitable block pools found to scan.  Waiting 1814399975 ms.
2020-12-03 07:23:39,462 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1199477258-172.17.0.8-1606980214994 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-12-03 07:23:39,462 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1199477258-172.17.0.8-1606980214994 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-12-03 07:23:39,463 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, DS-92e3d219-e1a4-4f3f-97a2-fca243ee2c69): finished scanning block pool BP-1199477258-172.17.0.8-1606980214994
2020-12-03 07:23:39,463 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, DS-ed4e0c39-1e32-430e-b11d-10ea474dda16): finished scanning block pool BP-1199477258-172.17.0.8-1606980214994
2020-12-03 07:23:39,463 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1199477258-172.17.0.8-1606980214994 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-12-03 07:23:39,464 [Thread-185] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 7:55 AM with interval of 21600000ms
2020-12-03 07:23:39,463 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, DS-191698f0-bb42-4b8c-af23-5c0b24e998b3): no suitable block pools found to scan.  Waiting 1814399974 ms.
2020-12-03 07:23:39,465 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, DS-92e3d219-e1a4-4f3f-97a2-fca243ee2c69): no suitable block pools found to scan.  Waiting 1814399927 ms.
2020-12-03 07:23:39,465 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, DS-ed4e0c39-1e32-430e-b11d-10ea474dda16): no suitable block pools found to scan.  Waiting 1814399927 ms.
2020-12-03 07:23:39,465 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, DS-d252d603-5c4f-4562-918f-2c3750f127c8): finished scanning block pool BP-1199477258-172.17.0.8-1606980214994
2020-12-03 07:23:39,464 [Thread-157] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:23 AM with interval of 21600000ms
2020-12-03 07:23:39,464 [Thread-212] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 12:08 PM with interval of 21600000ms
2020-12-03 07:23:39,464 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1199477258-172.17.0.8-1606980214994 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-12-03 07:23:39,465 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, DS-d252d603-5c4f-4562-918f-2c3750f127c8): no suitable block pools found to scan.  Waiting 1814399927 ms.
2020-12-03 07:23:39,466 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, DS-2c8d6396-1620-4cc7-8cb0-a097b414b982): finished scanning block pool BP-1199477258-172.17.0.8-1606980214994
2020-12-03 07:23:39,466 [Thread-288] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1192165426-172.17.0.8-1606980210852 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6: 32ms
2020-12-03 07:23:39,466 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, DS-2c8d6396-1620-4cc7-8cb0-a097b414b982): no suitable block pools found to scan.  Waiting 1814399926 ms.
2020-12-03 07:23:39,473 [BP-1199477258-172.17.0.8-1606980214994 heartbeating to localhost/127.0.0.1:39762] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1199477258-172.17.0.8-1606980214994 (Datanode Uuid d23de78e-12d8-4e37-95c6-1061610640b4) service to localhost/127.0.0.1:39762 beginning handshake with NN
2020-12-03 07:23:39,473 [BP-1192165426-172.17.0.8-1606980210852 heartbeating to localhost/127.0.0.1:42813] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1192165426-172.17.0.8-1606980210852 (Datanode Uuid 50567619-bc66-4185-aad7-ed7a22a9939e) service to localhost/127.0.0.1:42813 beginning handshake with NN
2020-12-03 07:23:39,473 [BP-1192165426-172.17.0.8-1606980210852 heartbeating to localhost/127.0.0.1:32986] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1192165426-172.17.0.8-1606980210852 (Datanode Uuid 50567619-bc66-4185-aad7-ed7a22a9939e) service to localhost/127.0.0.1:32986 beginning handshake with NN
2020-12-03 07:23:39,473 [BP-1199477258-172.17.0.8-1606980214994 heartbeating to localhost/127.0.0.1:40028] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1199477258-172.17.0.8-1606980214994 (Datanode Uuid 6474728c-8e98-4f1d-a1f7-e54d7a9024e5) service to localhost/127.0.0.1:40028 beginning handshake with NN
2020-12-03 07:23:39,473 [BP-1199477258-172.17.0.8-1606980214994 heartbeating to localhost/127.0.0.1:40028] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1199477258-172.17.0.8-1606980214994 (Datanode Uuid 50567619-bc66-4185-aad7-ed7a22a9939e) service to localhost/127.0.0.1:40028 beginning handshake with NN
2020-12-03 07:23:39,473 [BP-1199477258-172.17.0.8-1606980214994 heartbeating to localhost/127.0.0.1:40028] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1199477258-172.17.0.8-1606980214994 (Datanode Uuid d23de78e-12d8-4e37-95c6-1061610640b4) service to localhost/127.0.0.1:40028 beginning handshake with NN
2020-12-03 07:23:39,473 [BP-1199477258-172.17.0.8-1606980214994 heartbeating to localhost/127.0.0.1:39762] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1199477258-172.17.0.8-1606980214994 (Datanode Uuid 50567619-bc66-4185-aad7-ed7a22a9939e) service to localhost/127.0.0.1:39762 beginning handshake with NN
2020-12-03 07:23:39,473 [BP-1199477258-172.17.0.8-1606980214994 heartbeating to localhost/127.0.0.1:39762] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1199477258-172.17.0.8-1606980214994 (Datanode Uuid 6474728c-8e98-4f1d-a1f7-e54d7a9024e5) service to localhost/127.0.0.1:39762 beginning handshake with NN
2020-12-03 07:23:39,475 [Thread-287] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1192165426-172.17.0.8-1606980210852 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5: 23ms
2020-12-03 07:23:39,475 [Thread-211] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1192165426-172.17.0.8-1606980210852: 57ms
2020-12-03 07:23:39,475 [BP-1192165426-172.17.0.8-1606980210852 heartbeating to localhost/127.0.0.1:32986] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1192165426-172.17.0.8-1606980210852 (Datanode Uuid d23de78e-12d8-4e37-95c6-1061610640b4) service to localhost/127.0.0.1:32986 beginning handshake with NN
2020-12-03 07:23:39,475 [BP-1192165426-172.17.0.8-1606980210852 heartbeating to localhost/127.0.0.1:42813] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1192165426-172.17.0.8-1606980210852 (Datanode Uuid d23de78e-12d8-4e37-95c6-1061610640b4) service to localhost/127.0.0.1:42813 beginning handshake with NN
2020-12-03 07:23:39,476 [Thread-301] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1192165426-172.17.0.8-1606980210852 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5...
2020-12-03 07:23:39,476 [Thread-302] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1192165426-172.17.0.8-1606980210852 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6...
2020-12-03 07:23:39,476 [Thread-301] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-1192165426-172.17.0.8-1606980210852/current/replicas doesn't exist 
2020-12-03 07:23:39,476 [Thread-302] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-1192165426-172.17.0.8-1606980210852/current/replicas doesn't exist 
2020-12-03 07:23:39,476 [Thread-301] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1192165426-172.17.0.8-1606980210852 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5: 1ms
2020-12-03 07:23:39,476 [Thread-302] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1192165426-172.17.0.8-1606980210852 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6: 1ms
2020-12-03 07:23:39,476 [Thread-211] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1192165426-172.17.0.8-1606980210852: 2ms
2020-12-03 07:23:39,477 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1192165426-172.17.0.8-1606980210852 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-12-03 07:23:39,477 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1192165426-172.17.0.8-1606980210852 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-12-03 07:23:39,477 [BP-1192165426-172.17.0.8-1606980210852 heartbeating to localhost/127.0.0.1:42813] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1192165426-172.17.0.8-1606980210852 (Datanode Uuid 6474728c-8e98-4f1d-a1f7-e54d7a9024e5) service to localhost/127.0.0.1:42813 beginning handshake with NN
2020-12-03 07:23:39,477 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, DS-191698f0-bb42-4b8c-af23-5c0b24e998b3): finished scanning block pool BP-1192165426-172.17.0.8-1606980210852
2020-12-03 07:23:39,477 [BP-1192165426-172.17.0.8-1606980210852 heartbeating to localhost/127.0.0.1:32986] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1192165426-172.17.0.8-1606980210852 (Datanode Uuid 6474728c-8e98-4f1d-a1f7-e54d7a9024e5) service to localhost/127.0.0.1:32986 beginning handshake with NN
2020-12-03 07:23:39,477 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, DS-d66a95d5-e758-44e2-aeb8-ddd60f895dee): finished scanning block pool BP-1192165426-172.17.0.8-1606980210852
2020-12-03 07:23:39,478 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, DS-191698f0-bb42-4b8c-af23-5c0b24e998b3): no suitable block pools found to scan.  Waiting 1814399959 ms.
2020-12-03 07:23:39,478 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, DS-d66a95d5-e758-44e2-aeb8-ddd60f895dee): no suitable block pools found to scan.  Waiting 1814399959 ms.
2020-12-03 07:23:39,491 [IPC Server handler 2 on default port 39762] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:43860, datanodeUuid=6474728c-8e98-4f1d-a1f7-e54d7a9024e5, infoPort=36036, infoSecurePort=0, ipcPort=37605, storageInfo=lv=-57;cid=testClusterID;nsid=1338103220;c=1606980214994) storage 6474728c-8e98-4f1d-a1f7-e54d7a9024e5
2020-12-03 07:23:39,491 [IPC Server handler 2 on default port 32986] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:36211, datanodeUuid=d23de78e-12d8-4e37-95c6-1061610640b4, infoPort=34740, infoSecurePort=0, ipcPort=34886, storageInfo=lv=-57;cid=testClusterID;nsid=2077292191;c=1606980210852) storage d23de78e-12d8-4e37-95c6-1061610640b4
2020-12-03 07:23:39,492 [IPC Server handler 1 on default port 40028] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:43860, datanodeUuid=6474728c-8e98-4f1d-a1f7-e54d7a9024e5, infoPort=36036, infoSecurePort=0, ipcPort=37605, storageInfo=lv=-57;cid=testClusterID;nsid=1338103220;c=1606980214994) storage 6474728c-8e98-4f1d-a1f7-e54d7a9024e5
2020-12-03 07:23:39,493 [IPC Server handler 8 on default port 42813] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:43860, datanodeUuid=6474728c-8e98-4f1d-a1f7-e54d7a9024e5, infoPort=36036, infoSecurePort=0, ipcPort=37605, storageInfo=lv=-57;cid=testClusterID;nsid=2077292191;c=1606980210852) storage 6474728c-8e98-4f1d-a1f7-e54d7a9024e5
2020-12-03 07:23:39,496 [IPC Server handler 8 on default port 42813] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:43860
2020-12-03 07:23:39,496 [IPC Server handler 2 on default port 39762] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:43860
2020-12-03 07:23:39,496 [IPC Server handler 1 on default port 40028] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:43860
2020-12-03 07:23:39,496 [IPC Server handler 2 on default port 32986] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36211
2020-12-03 07:23:39,496 [IPC Server handler 1 on default port 40028] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 6474728c-8e98-4f1d-a1f7-e54d7a9024e5 (127.0.0.1:43860).
2020-12-03 07:23:39,496 [IPC Server handler 2 on default port 39762] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 6474728c-8e98-4f1d-a1f7-e54d7a9024e5 (127.0.0.1:43860).
2020-12-03 07:23:39,496 [IPC Server handler 8 on default port 42813] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 6474728c-8e98-4f1d-a1f7-e54d7a9024e5 (127.0.0.1:43860).
2020-12-03 07:23:39,496 [IPC Server handler 2 on default port 32986] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN d23de78e-12d8-4e37-95c6-1061610640b4 (127.0.0.1:36211).
2020-12-03 07:23:39,501 [IPC Server handler 2 on default port 40028] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:36211, datanodeUuid=d23de78e-12d8-4e37-95c6-1061610640b4, infoPort=34740, infoSecurePort=0, ipcPort=34886, storageInfo=lv=-57;cid=testClusterID;nsid=1338103220;c=1606980214994) storage d23de78e-12d8-4e37-95c6-1061610640b4
2020-12-03 07:23:39,501 [IPC Server handler 3 on default port 39762] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:41280, datanodeUuid=50567619-bc66-4185-aad7-ed7a22a9939e, infoPort=33342, infoSecurePort=0, ipcPort=39821, storageInfo=lv=-57;cid=testClusterID;nsid=1338103220;c=1606980214994) storage 50567619-bc66-4185-aad7-ed7a22a9939e
2020-12-03 07:23:39,502 [IPC Server handler 2 on default port 40028] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36211
2020-12-03 07:23:39,502 [IPC Server handler 6 on default port 42813] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:36211, datanodeUuid=d23de78e-12d8-4e37-95c6-1061610640b4, infoPort=34740, infoSecurePort=0, ipcPort=34886, storageInfo=lv=-57;cid=testClusterID;nsid=2077292191;c=1606980210852) storage d23de78e-12d8-4e37-95c6-1061610640b4
2020-12-03 07:23:39,501 [IPC Server handler 4 on default port 32986] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:41280, datanodeUuid=50567619-bc66-4185-aad7-ed7a22a9939e, infoPort=33342, infoSecurePort=0, ipcPort=39821, storageInfo=lv=-57;cid=testClusterID;nsid=2077292191;c=1606980210852) storage 50567619-bc66-4185-aad7-ed7a22a9939e
2020-12-03 07:23:39,503 [IPC Server handler 6 on default port 42813] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36211
2020-12-03 07:23:39,502 [IPC Server handler 3 on default port 39762] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41280
2020-12-03 07:23:39,503 [IPC Server handler 6 on default port 42813] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN d23de78e-12d8-4e37-95c6-1061610640b4 (127.0.0.1:36211).
2020-12-03 07:23:39,503 [IPC Server handler 4 on default port 32986] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41280
2020-12-03 07:23:39,503 [IPC Server handler 2 on default port 40028] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN d23de78e-12d8-4e37-95c6-1061610640b4 (127.0.0.1:36211).
2020-12-03 07:23:39,505 [IPC Server handler 4 on default port 32986] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 50567619-bc66-4185-aad7-ed7a22a9939e (127.0.0.1:41280).
2020-12-03 07:23:39,504 [IPC Server handler 7 on default port 42813] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:41280, datanodeUuid=50567619-bc66-4185-aad7-ed7a22a9939e, infoPort=33342, infoSecurePort=0, ipcPort=39821, storageInfo=lv=-57;cid=testClusterID;nsid=2077292191;c=1606980210852) storage 50567619-bc66-4185-aad7-ed7a22a9939e
2020-12-03 07:23:39,504 [IPC Server handler 3 on default port 39762] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 50567619-bc66-4185-aad7-ed7a22a9939e (127.0.0.1:41280).
2020-12-03 07:23:39,506 [IPC Server handler 7 on default port 42813] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41280
2020-12-03 07:23:39,506 [IPC Server handler 5 on default port 39762] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:36211, datanodeUuid=d23de78e-12d8-4e37-95c6-1061610640b4, infoPort=34740, infoSecurePort=0, ipcPort=34886, storageInfo=lv=-57;cid=testClusterID;nsid=1338103220;c=1606980214994) storage d23de78e-12d8-4e37-95c6-1061610640b4
2020-12-03 07:23:39,506 [IPC Server handler 0 on default port 32986] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:43860, datanodeUuid=6474728c-8e98-4f1d-a1f7-e54d7a9024e5, infoPort=36036, infoSecurePort=0, ipcPort=37605, storageInfo=lv=-57;cid=testClusterID;nsid=2077292191;c=1606980210852) storage 6474728c-8e98-4f1d-a1f7-e54d7a9024e5
2020-12-03 07:23:39,505 [IPC Server handler 3 on default port 40028] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:41280, datanodeUuid=50567619-bc66-4185-aad7-ed7a22a9939e, infoPort=33342, infoSecurePort=0, ipcPort=39821, storageInfo=lv=-57;cid=testClusterID;nsid=1338103220;c=1606980214994) storage 50567619-bc66-4185-aad7-ed7a22a9939e
2020-12-03 07:23:39,506 [IPC Server handler 0 on default port 32986] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:43860
2020-12-03 07:23:39,506 [IPC Server handler 0 on default port 32986] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 6474728c-8e98-4f1d-a1f7-e54d7a9024e5 (127.0.0.1:43860).
2020-12-03 07:23:39,506 [IPC Server handler 5 on default port 39762] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36211
2020-12-03 07:23:39,507 [BP-1192165426-172.17.0.8-1606980210852 heartbeating to localhost/127.0.0.1:32986] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1192165426-172.17.0.8-1606980210852 (Datanode Uuid 50567619-bc66-4185-aad7-ed7a22a9939e) service to localhost/127.0.0.1:32986 successfully registered with NN
2020-12-03 07:23:39,506 [IPC Server handler 7 on default port 42813] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 50567619-bc66-4185-aad7-ed7a22a9939e (127.0.0.1:41280).
2020-12-03 07:23:39,507 [BP-1192165426-172.17.0.8-1606980210852 heartbeating to localhost/127.0.0.1:32986] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1192165426-172.17.0.8-1606980210852 (Datanode Uuid d23de78e-12d8-4e37-95c6-1061610640b4) service to localhost/127.0.0.1:32986 successfully registered with NN
2020-12-03 07:23:39,507 [BP-1199477258-172.17.0.8-1606980214994 heartbeating to localhost/127.0.0.1:40028] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1199477258-172.17.0.8-1606980214994 (Datanode Uuid 6474728c-8e98-4f1d-a1f7-e54d7a9024e5) service to localhost/127.0.0.1:40028 successfully registered with NN
2020-12-03 07:23:39,507 [IPC Server handler 5 on default port 39762] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN d23de78e-12d8-4e37-95c6-1061610640b4 (127.0.0.1:36211).
2020-12-03 07:23:39,507 [BP-1199477258-172.17.0.8-1606980214994 heartbeating to localhost/127.0.0.1:39762] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1199477258-172.17.0.8-1606980214994 (Datanode Uuid 6474728c-8e98-4f1d-a1f7-e54d7a9024e5) service to localhost/127.0.0.1:39762 successfully registered with NN
2020-12-03 07:23:39,507 [BP-1192165426-172.17.0.8-1606980210852 heartbeating to localhost/127.0.0.1:42813] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1192165426-172.17.0.8-1606980210852 (Datanode Uuid 6474728c-8e98-4f1d-a1f7-e54d7a9024e5) service to localhost/127.0.0.1:42813 successfully registered with NN
2020-12-03 07:23:39,507 [BP-1199477258-172.17.0.8-1606980214994 heartbeating to localhost/127.0.0.1:40028] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1199477258-172.17.0.8-1606980214994 (Datanode Uuid d23de78e-12d8-4e37-95c6-1061610640b4) service to localhost/127.0.0.1:40028 successfully registered with NN
2020-12-03 07:23:39,507 [BP-1199477258-172.17.0.8-1606980214994 heartbeating to localhost/127.0.0.1:39762] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1199477258-172.17.0.8-1606980214994 (Datanode Uuid 50567619-bc66-4185-aad7-ed7a22a9939e) service to localhost/127.0.0.1:39762 successfully registered with NN
2020-12-03 07:23:39,506 [IPC Server handler 3 on default port 40028] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41280
2020-12-03 07:23:39,508 [BP-1199477258-172.17.0.8-1606980214994 heartbeating to localhost/127.0.0.1:39762] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1199477258-172.17.0.8-1606980214994 (Datanode Uuid d23de78e-12d8-4e37-95c6-1061610640b4) service to localhost/127.0.0.1:39762 successfully registered with NN
2020-12-03 07:23:39,508 [BP-1199477258-172.17.0.8-1606980214994 heartbeating to localhost/127.0.0.1:39762] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:39762 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:39,509 [BP-1192165426-172.17.0.8-1606980210852 heartbeating to localhost/127.0.0.1:42813] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1192165426-172.17.0.8-1606980210852 (Datanode Uuid d23de78e-12d8-4e37-95c6-1061610640b4) service to localhost/127.0.0.1:42813 successfully registered with NN
2020-12-03 07:23:39,508 [IPC Server handler 3 on default port 40028] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 50567619-bc66-4185-aad7-ed7a22a9939e (127.0.0.1:41280).
2020-12-03 07:23:39,508 [BP-1199477258-172.17.0.8-1606980214994 heartbeating to localhost/127.0.0.1:39762] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:39762 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:39,508 [BP-1199477258-172.17.0.8-1606980214994 heartbeating to localhost/127.0.0.1:40028] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:40028 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:39,508 [BP-1192165426-172.17.0.8-1606980210852 heartbeating to localhost/127.0.0.1:42813] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:42813 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:39,508 [BP-1199477258-172.17.0.8-1606980214994 heartbeating to localhost/127.0.0.1:39762] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:39762 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:39,508 [BP-1192165426-172.17.0.8-1606980210852 heartbeating to localhost/127.0.0.1:42813] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1192165426-172.17.0.8-1606980210852 (Datanode Uuid 50567619-bc66-4185-aad7-ed7a22a9939e) service to localhost/127.0.0.1:42813 successfully registered with NN
2020-12-03 07:23:39,508 [BP-1199477258-172.17.0.8-1606980214994 heartbeating to localhost/127.0.0.1:40028] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:40028 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:39,507 [BP-1192165426-172.17.0.8-1606980210852 heartbeating to localhost/127.0.0.1:32986] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:32986 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:39,507 [BP-1192165426-172.17.0.8-1606980210852 heartbeating to localhost/127.0.0.1:32986] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:32986 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:39,507 [BP-1192165426-172.17.0.8-1606980210852 heartbeating to localhost/127.0.0.1:32986] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1192165426-172.17.0.8-1606980210852 (Datanode Uuid 6474728c-8e98-4f1d-a1f7-e54d7a9024e5) service to localhost/127.0.0.1:32986 successfully registered with NN
2020-12-03 07:23:39,510 [BP-1199477258-172.17.0.8-1606980214994 heartbeating to localhost/127.0.0.1:40028] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1199477258-172.17.0.8-1606980214994 (Datanode Uuid 50567619-bc66-4185-aad7-ed7a22a9939e) service to localhost/127.0.0.1:40028 successfully registered with NN
2020-12-03 07:23:39,509 [BP-1192165426-172.17.0.8-1606980210852 heartbeating to localhost/127.0.0.1:42813] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:42813 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:39,509 [BP-1192165426-172.17.0.8-1606980210852 heartbeating to localhost/127.0.0.1:42813] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:42813 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:39,510 [BP-1199477258-172.17.0.8-1606980214994 heartbeating to localhost/127.0.0.1:40028] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:40028 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:39,510 [BP-1192165426-172.17.0.8-1606980210852 heartbeating to localhost/127.0.0.1:32986] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:32986 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:39,525 [IPC Server handler 9 on default port 32986] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:39,536 [IPC Server handler 3 on default port 42813] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d252d603-5c4f-4562-918f-2c3750f127c8 for DN 127.0.0.1:36211
2020-12-03 07:23:39,536 [IPC Server handler 4 on default port 40028] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-92e3d219-e1a4-4f3f-97a2-fca243ee2c69 for DN 127.0.0.1:41280
2020-12-03 07:23:39,536 [IPC Server handler 3 on default port 32986] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d252d603-5c4f-4562-918f-2c3750f127c8 for DN 127.0.0.1:36211
2020-12-03 07:23:39,536 [IPC Server handler 6 on default port 39762] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d252d603-5c4f-4562-918f-2c3750f127c8 for DN 127.0.0.1:36211
2020-12-03 07:23:39,537 [IPC Server handler 6 on default port 39762] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-2c8d6396-1620-4cc7-8cb0-a097b414b982 for DN 127.0.0.1:36211
2020-12-03 07:23:39,537 [IPC Server handler 3 on default port 32986] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-2c8d6396-1620-4cc7-8cb0-a097b414b982 for DN 127.0.0.1:36211
2020-12-03 07:23:39,537 [IPC Server handler 4 on default port 40028] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-ed4e0c39-1e32-430e-b11d-10ea474dda16 for DN 127.0.0.1:41280
2020-12-03 07:23:39,537 [IPC Server handler 3 on default port 42813] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-2c8d6396-1620-4cc7-8cb0-a097b414b982 for DN 127.0.0.1:36211
2020-12-03 07:23:39,539 [Listener at localhost/37926] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:39,540 [Listener at localhost/37926] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:39,539 [IPC Server handler 6 on default port 32986] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-92e3d219-e1a4-4f3f-97a2-fca243ee2c69 for DN 127.0.0.1:41280
2020-12-03 07:23:39,539 [IPC Server handler 7 on default port 39762] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-191698f0-bb42-4b8c-af23-5c0b24e998b3 for DN 127.0.0.1:43860
2020-12-03 07:23:39,541 [IPC Server handler 6 on default port 32986] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-ed4e0c39-1e32-430e-b11d-10ea474dda16 for DN 127.0.0.1:41280
2020-12-03 07:23:39,540 [IPC Server handler 2 on default port 42813] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-191698f0-bb42-4b8c-af23-5c0b24e998b3 for DN 127.0.0.1:43860
2020-12-03 07:23:39,539 [IPC Server handler 7 on default port 40028] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-191698f0-bb42-4b8c-af23-5c0b24e998b3 for DN 127.0.0.1:43860
2020-12-03 07:23:39,544 [IPC Server handler 2 on default port 42813] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d66a95d5-e758-44e2-aeb8-ddd60f895dee for DN 127.0.0.1:43860
2020-12-03 07:23:39,546 [IPC Server handler 7 on default port 40028] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d66a95d5-e758-44e2-aeb8-ddd60f895dee for DN 127.0.0.1:43860
2020-12-03 07:23:39,543 [IPC Server handler 1 on default port 32986] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-191698f0-bb42-4b8c-af23-5c0b24e998b3 for DN 127.0.0.1:43860
2020-12-03 07:23:39,543 [IPC Server handler 7 on default port 39762] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d66a95d5-e758-44e2-aeb8-ddd60f895dee for DN 127.0.0.1:43860
2020-12-03 07:23:39,547 [IPC Server handler 1 on default port 32986] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d66a95d5-e758-44e2-aeb8-ddd60f895dee for DN 127.0.0.1:43860
2020-12-03 07:23:39,548 [IPC Server handler 4 on default port 39762] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-92e3d219-e1a4-4f3f-97a2-fca243ee2c69 for DN 127.0.0.1:41280
2020-12-03 07:23:39,547 [IPC Server handler 5 on default port 40028] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d252d603-5c4f-4562-918f-2c3750f127c8 for DN 127.0.0.1:36211
2020-12-03 07:23:39,546 [IPC Server handler 4 on default port 42813] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-92e3d219-e1a4-4f3f-97a2-fca243ee2c69 for DN 127.0.0.1:41280
2020-12-03 07:23:39,549 [IPC Server handler 4 on default port 42813] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-ed4e0c39-1e32-430e-b11d-10ea474dda16 for DN 127.0.0.1:41280
2020-12-03 07:23:39,548 [IPC Server handler 5 on default port 40028] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-2c8d6396-1620-4cc7-8cb0-a097b414b982 for DN 127.0.0.1:36211
2020-12-03 07:23:39,548 [IPC Server handler 4 on default port 39762] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-ed4e0c39-1e32-430e-b11d-10ea474dda16 for DN 127.0.0.1:41280
2020-12-03 07:23:39,586 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x66bcace072e3ab14: Processing first storage report for DS-2c8d6396-1620-4cc7-8cb0-a097b414b982 from datanode d23de78e-12d8-4e37-95c6-1061610640b4
2020-12-03 07:23:39,586 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x44d36d8264dd36d8: Processing first storage report for DS-d66a95d5-e758-44e2-aeb8-ddd60f895dee from datanode 6474728c-8e98-4f1d-a1f7-e54d7a9024e5
2020-12-03 07:23:39,586 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xeac8ff73ec51ca1c: Processing first storage report for DS-2c8d6396-1620-4cc7-8cb0-a097b414b982 from datanode d23de78e-12d8-4e37-95c6-1061610640b4
2020-12-03 07:23:39,586 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x683261a6cb9a469b: Processing first storage report for DS-2c8d6396-1620-4cc7-8cb0-a097b414b982 from datanode d23de78e-12d8-4e37-95c6-1061610640b4
2020-12-03 07:23:39,589 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x66bcace072e3ab14: from storage DS-2c8d6396-1620-4cc7-8cb0-a097b414b982 node DatanodeRegistration(127.0.0.1:36211, datanodeUuid=d23de78e-12d8-4e37-95c6-1061610640b4, infoPort=34740, infoSecurePort=0, ipcPort=34886, storageInfo=lv=-57;cid=testClusterID;nsid=1338103220;c=1606980214994), blocks: 0, hasStaleStorage: true, processing time: 2 msecs, invalidatedBlocks: 0
2020-12-03 07:23:39,589 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x683261a6cb9a469b: from storage DS-2c8d6396-1620-4cc7-8cb0-a097b414b982 node DatanodeRegistration(127.0.0.1:36211, datanodeUuid=d23de78e-12d8-4e37-95c6-1061610640b4, infoPort=34740, infoSecurePort=0, ipcPort=34886, storageInfo=lv=-57;cid=testClusterID;nsid=2077292191;c=1606980210852), blocks: 0, hasStaleStorage: true, processing time: 2 msecs, invalidatedBlocks: 0
2020-12-03 07:23:39,589 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x2e93a278b1b663f8: Processing first storage report for DS-d66a95d5-e758-44e2-aeb8-ddd60f895dee from datanode 6474728c-8e98-4f1d-a1f7-e54d7a9024e5
2020-12-03 07:23:39,589 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x5c86127bdbf7a30: Processing first storage report for DS-d66a95d5-e758-44e2-aeb8-ddd60f895dee from datanode 6474728c-8e98-4f1d-a1f7-e54d7a9024e5
2020-12-03 07:23:39,589 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x44d36d8264dd36d8: from storage DS-d66a95d5-e758-44e2-aeb8-ddd60f895dee node DatanodeRegistration(127.0.0.1:43860, datanodeUuid=6474728c-8e98-4f1d-a1f7-e54d7a9024e5, infoPort=36036, infoSecurePort=0, ipcPort=37605, storageInfo=lv=-57;cid=testClusterID;nsid=2077292191;c=1606980210852), blocks: 0, hasStaleStorage: true, processing time: 2 msecs, invalidatedBlocks: 0
2020-12-03 07:23:39,589 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xeac8ff73ec51ca1c: from storage DS-2c8d6396-1620-4cc7-8cb0-a097b414b982 node DatanodeRegistration(127.0.0.1:36211, datanodeUuid=d23de78e-12d8-4e37-95c6-1061610640b4, infoPort=34740, infoSecurePort=0, ipcPort=34886, storageInfo=lv=-57;cid=testClusterID;nsid=1338103220;c=1606980214994), blocks: 0, hasStaleStorage: true, processing time: 2 msecs, invalidatedBlocks: 0
2020-12-03 07:23:39,589 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x89a05cfe7b4ddfe: Processing first storage report for DS-2c8d6396-1620-4cc7-8cb0-a097b414b982 from datanode d23de78e-12d8-4e37-95c6-1061610640b4
2020-12-03 07:23:39,589 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x5c86127bdbf7a30: from storage DS-d66a95d5-e758-44e2-aeb8-ddd60f895dee node DatanodeRegistration(127.0.0.1:43860, datanodeUuid=6474728c-8e98-4f1d-a1f7-e54d7a9024e5, infoPort=36036, infoSecurePort=0, ipcPort=37605, storageInfo=lv=-57;cid=testClusterID;nsid=2077292191;c=1606980210852), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:39,589 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x2e93a278b1b663f8: from storage DS-d66a95d5-e758-44e2-aeb8-ddd60f895dee node DatanodeRegistration(127.0.0.1:43860, datanodeUuid=6474728c-8e98-4f1d-a1f7-e54d7a9024e5, infoPort=36036, infoSecurePort=0, ipcPort=37605, storageInfo=lv=-57;cid=testClusterID;nsid=1338103220;c=1606980214994), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:39,589 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x318d580a387120ec: Processing first storage report for DS-92e3d219-e1a4-4f3f-97a2-fca243ee2c69 from datanode 50567619-bc66-4185-aad7-ed7a22a9939e
2020-12-03 07:23:39,589 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x89a05cfe7b4ddfe: from storage DS-2c8d6396-1620-4cc7-8cb0-a097b414b982 node DatanodeRegistration(127.0.0.1:36211, datanodeUuid=d23de78e-12d8-4e37-95c6-1061610640b4, infoPort=34740, infoSecurePort=0, ipcPort=34886, storageInfo=lv=-57;cid=testClusterID;nsid=2077292191;c=1606980210852), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:39,589 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xb19ae620ea781d51: Processing first storage report for DS-92e3d219-e1a4-4f3f-97a2-fca243ee2c69 from datanode 50567619-bc66-4185-aad7-ed7a22a9939e
2020-12-03 07:23:39,590 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x70ef80a25fc3bac6: Processing first storage report for DS-92e3d219-e1a4-4f3f-97a2-fca243ee2c69 from datanode 50567619-bc66-4185-aad7-ed7a22a9939e
2020-12-03 07:23:39,590 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x318d580a387120ec: from storage DS-92e3d219-e1a4-4f3f-97a2-fca243ee2c69 node DatanodeRegistration(127.0.0.1:41280, datanodeUuid=50567619-bc66-4185-aad7-ed7a22a9939e, infoPort=33342, infoSecurePort=0, ipcPort=39821, storageInfo=lv=-57;cid=testClusterID;nsid=2077292191;c=1606980210852), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:39,590 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x59c9586f2ff26089: Processing first storage report for DS-92e3d219-e1a4-4f3f-97a2-fca243ee2c69 from datanode 50567619-bc66-4185-aad7-ed7a22a9939e
2020-12-03 07:23:39,590 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x70ef80a25fc3bac6: from storage DS-92e3d219-e1a4-4f3f-97a2-fca243ee2c69 node DatanodeRegistration(127.0.0.1:41280, datanodeUuid=50567619-bc66-4185-aad7-ed7a22a9939e, infoPort=33342, infoSecurePort=0, ipcPort=39821, storageInfo=lv=-57;cid=testClusterID;nsid=2077292191;c=1606980210852), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:39,590 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xb19ae620ea781d51: from storage DS-92e3d219-e1a4-4f3f-97a2-fca243ee2c69 node DatanodeRegistration(127.0.0.1:41280, datanodeUuid=50567619-bc66-4185-aad7-ed7a22a9939e, infoPort=33342, infoSecurePort=0, ipcPort=39821, storageInfo=lv=-57;cid=testClusterID;nsid=1338103220;c=1606980214994), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:39,590 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x44d36d8264dd36d8: Processing first storage report for DS-191698f0-bb42-4b8c-af23-5c0b24e998b3 from datanode 6474728c-8e98-4f1d-a1f7-e54d7a9024e5
2020-12-03 07:23:39,590 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x59c9586f2ff26089: from storage DS-92e3d219-e1a4-4f3f-97a2-fca243ee2c69 node DatanodeRegistration(127.0.0.1:41280, datanodeUuid=50567619-bc66-4185-aad7-ed7a22a9939e, infoPort=33342, infoSecurePort=0, ipcPort=39821, storageInfo=lv=-57;cid=testClusterID;nsid=1338103220;c=1606980214994), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:23:39,590 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x683261a6cb9a469b: Processing first storage report for DS-d252d603-5c4f-4562-918f-2c3750f127c8 from datanode d23de78e-12d8-4e37-95c6-1061610640b4
2020-12-03 07:23:39,591 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x66bcace072e3ab14: Processing first storage report for DS-d252d603-5c4f-4562-918f-2c3750f127c8 from datanode d23de78e-12d8-4e37-95c6-1061610640b4
2020-12-03 07:23:39,591 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x683261a6cb9a469b: from storage DS-d252d603-5c4f-4562-918f-2c3750f127c8 node DatanodeRegistration(127.0.0.1:36211, datanodeUuid=d23de78e-12d8-4e37-95c6-1061610640b4, infoPort=34740, infoSecurePort=0, ipcPort=34886, storageInfo=lv=-57;cid=testClusterID;nsid=2077292191;c=1606980210852), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:39,591 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x44d36d8264dd36d8: from storage DS-191698f0-bb42-4b8c-af23-5c0b24e998b3 node DatanodeRegistration(127.0.0.1:43860, datanodeUuid=6474728c-8e98-4f1d-a1f7-e54d7a9024e5, infoPort=36036, infoSecurePort=0, ipcPort=37605, storageInfo=lv=-57;cid=testClusterID;nsid=2077292191;c=1606980210852), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:39,590 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x61afac5f11c6c6fa: Processing first storage report for DS-d66a95d5-e758-44e2-aeb8-ddd60f895dee from datanode 6474728c-8e98-4f1d-a1f7-e54d7a9024e5
2020-12-03 07:23:39,591 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x89a05cfe7b4ddfe: Processing first storage report for DS-d252d603-5c4f-4562-918f-2c3750f127c8 from datanode d23de78e-12d8-4e37-95c6-1061610640b4
2020-12-03 07:23:39,591 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x5c86127bdbf7a30: Processing first storage report for DS-191698f0-bb42-4b8c-af23-5c0b24e998b3 from datanode 6474728c-8e98-4f1d-a1f7-e54d7a9024e5
2020-12-03 07:23:39,591 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x66bcace072e3ab14: from storage DS-d252d603-5c4f-4562-918f-2c3750f127c8 node DatanodeRegistration(127.0.0.1:36211, datanodeUuid=d23de78e-12d8-4e37-95c6-1061610640b4, infoPort=34740, infoSecurePort=0, ipcPort=34886, storageInfo=lv=-57;cid=testClusterID;nsid=1338103220;c=1606980214994), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:39,591 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x5c86127bdbf7a30: from storage DS-191698f0-bb42-4b8c-af23-5c0b24e998b3 node DatanodeRegistration(127.0.0.1:43860, datanodeUuid=6474728c-8e98-4f1d-a1f7-e54d7a9024e5, infoPort=36036, infoSecurePort=0, ipcPort=37605, storageInfo=lv=-57;cid=testClusterID;nsid=2077292191;c=1606980210852), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:23:39,591 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x89a05cfe7b4ddfe: from storage DS-d252d603-5c4f-4562-918f-2c3750f127c8 node DatanodeRegistration(127.0.0.1:36211, datanodeUuid=d23de78e-12d8-4e37-95c6-1061610640b4, infoPort=34740, infoSecurePort=0, ipcPort=34886, storageInfo=lv=-57;cid=testClusterID;nsid=2077292191;c=1606980210852), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:23:39,591 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x61afac5f11c6c6fa: from storage DS-d66a95d5-e758-44e2-aeb8-ddd60f895dee node DatanodeRegistration(127.0.0.1:43860, datanodeUuid=6474728c-8e98-4f1d-a1f7-e54d7a9024e5, infoPort=36036, infoSecurePort=0, ipcPort=37605, storageInfo=lv=-57;cid=testClusterID;nsid=1338103220;c=1606980214994), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:23:39,592 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x70ef80a25fc3bac6: Processing first storage report for DS-ed4e0c39-1e32-430e-b11d-10ea474dda16 from datanode 50567619-bc66-4185-aad7-ed7a22a9939e
2020-12-03 07:23:39,592 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xeac8ff73ec51ca1c: Processing first storage report for DS-d252d603-5c4f-4562-918f-2c3750f127c8 from datanode d23de78e-12d8-4e37-95c6-1061610640b4
2020-12-03 07:23:39,592 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x318d580a387120ec: Processing first storage report for DS-ed4e0c39-1e32-430e-b11d-10ea474dda16 from datanode 50567619-bc66-4185-aad7-ed7a22a9939e
2020-12-03 07:23:39,591 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x2e93a278b1b663f8: Processing first storage report for DS-191698f0-bb42-4b8c-af23-5c0b24e998b3 from datanode 6474728c-8e98-4f1d-a1f7-e54d7a9024e5
2020-12-03 07:23:39,592 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x318d580a387120ec: from storage DS-ed4e0c39-1e32-430e-b11d-10ea474dda16 node DatanodeRegistration(127.0.0.1:41280, datanodeUuid=50567619-bc66-4185-aad7-ed7a22a9939e, infoPort=33342, infoSecurePort=0, ipcPort=39821, storageInfo=lv=-57;cid=testClusterID;nsid=2077292191;c=1606980210852), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:39,592 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xeac8ff73ec51ca1c: from storage DS-d252d603-5c4f-4562-918f-2c3750f127c8 node DatanodeRegistration(127.0.0.1:36211, datanodeUuid=d23de78e-12d8-4e37-95c6-1061610640b4, infoPort=34740, infoSecurePort=0, ipcPort=34886, storageInfo=lv=-57;cid=testClusterID;nsid=1338103220;c=1606980214994), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:39,592 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x70ef80a25fc3bac6: from storage DS-ed4e0c39-1e32-430e-b11d-10ea474dda16 node DatanodeRegistration(127.0.0.1:41280, datanodeUuid=50567619-bc66-4185-aad7-ed7a22a9939e, infoPort=33342, infoSecurePort=0, ipcPort=39821, storageInfo=lv=-57;cid=testClusterID;nsid=2077292191;c=1606980210852), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:39,592 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xb19ae620ea781d51: Processing first storage report for DS-ed4e0c39-1e32-430e-b11d-10ea474dda16 from datanode 50567619-bc66-4185-aad7-ed7a22a9939e
2020-12-03 07:23:39,592 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x2e93a278b1b663f8: from storage DS-191698f0-bb42-4b8c-af23-5c0b24e998b3 node DatanodeRegistration(127.0.0.1:43860, datanodeUuid=6474728c-8e98-4f1d-a1f7-e54d7a9024e5, infoPort=36036, infoSecurePort=0, ipcPort=37605, storageInfo=lv=-57;cid=testClusterID;nsid=1338103220;c=1606980214994), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:23:39,593 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xb19ae620ea781d51: from storage DS-ed4e0c39-1e32-430e-b11d-10ea474dda16 node DatanodeRegistration(127.0.0.1:41280, datanodeUuid=50567619-bc66-4185-aad7-ed7a22a9939e, infoPort=33342, infoSecurePort=0, ipcPort=39821, storageInfo=lv=-57;cid=testClusterID;nsid=1338103220;c=1606980214994), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:39,593 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x59c9586f2ff26089: Processing first storage report for DS-ed4e0c39-1e32-430e-b11d-10ea474dda16 from datanode 50567619-bc66-4185-aad7-ed7a22a9939e
2020-12-03 07:23:39,593 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x61afac5f11c6c6fa: Processing first storage report for DS-191698f0-bb42-4b8c-af23-5c0b24e998b3 from datanode 6474728c-8e98-4f1d-a1f7-e54d7a9024e5
2020-12-03 07:23:39,593 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x59c9586f2ff26089: from storage DS-ed4e0c39-1e32-430e-b11d-10ea474dda16 node DatanodeRegistration(127.0.0.1:41280, datanodeUuid=50567619-bc66-4185-aad7-ed7a22a9939e, infoPort=33342, infoSecurePort=0, ipcPort=39821, storageInfo=lv=-57;cid=testClusterID;nsid=1338103220;c=1606980214994), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:39,593 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x61afac5f11c6c6fa: from storage DS-191698f0-bb42-4b8c-af23-5c0b24e998b3 node DatanodeRegistration(127.0.0.1:43860, datanodeUuid=6474728c-8e98-4f1d-a1f7-e54d7a9024e5, infoPort=36036, infoSecurePort=0, ipcPort=37605, storageInfo=lv=-57;cid=testClusterID;nsid=1338103220;c=1606980214994), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:39,614 [BP-1199477258-172.17.0.8-1606980214994 heartbeating to localhost/127.0.0.1:40028] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xeac8ff73ec51ca1c,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 47 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:23:39,614 [BP-1192165426-172.17.0.8-1606980210852 heartbeating to localhost/127.0.0.1:32986] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x70ef80a25fc3bac6,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 44 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:23:39,614 [BP-1192165426-172.17.0.8-1606980210852 heartbeating to localhost/127.0.0.1:32986] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x44d36d8264dd36d8,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 44 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:23:39,614 [BP-1199477258-172.17.0.8-1606980214994 heartbeating to localhost/127.0.0.1:39762] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x59c9586f2ff26089,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 44 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:23:39,614 [BP-1192165426-172.17.0.8-1606980210852 heartbeating to localhost/127.0.0.1:32986] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x89a05cfe7b4ddfe,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 44 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:23:39,614 [BP-1192165426-172.17.0.8-1606980210852 heartbeating to localhost/127.0.0.1:42813] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x318d580a387120ec,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 48 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:23:39,614 [BP-1192165426-172.17.0.8-1606980210852 heartbeating to localhost/127.0.0.1:42813] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x683261a6cb9a469b,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 44 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:23:39,614 [BP-1199477258-172.17.0.8-1606980214994 heartbeating to localhost/127.0.0.1:40028] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xb19ae620ea781d51,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 48 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:23:39,614 [BP-1199477258-172.17.0.8-1606980214994 heartbeating to localhost/127.0.0.1:39762] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x2e93a278b1b663f8,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 44 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:23:39,614 [BP-1192165426-172.17.0.8-1606980210852 heartbeating to localhost/127.0.0.1:42813] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x5c86127bdbf7a30,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 44 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:23:39,614 [BP-1199477258-172.17.0.8-1606980214994 heartbeating to localhost/127.0.0.1:39762] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x66bcace072e3ab14,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 48 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:23:39,614 [BP-1199477258-172.17.0.8-1606980214994 heartbeating to localhost/127.0.0.1:40028] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x61afac5f11c6c6fa,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 48 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:23:39,629 [Thread-237] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID e1a5f8c8-f07f-476b-9f72-5bd254411763
2020-12-03 07:23:39,631 [Thread-237] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-707a6798-cced-414e-becf-df59de1fd486
2020-12-03 07:23:39,631 [Thread-237] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, StorageType: DISK
2020-12-03 07:23:39,634 [Thread-237] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-78e24e72-4b84-4d28-a4dd-af91ad349ab5
2020-12-03 07:23:39,634 [Thread-237] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, StorageType: DISK
2020-12-03 07:23:39,635 [Thread-237] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:23:39,636 [Thread-236] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1192165426-172.17.0.8-1606980210852
2020-12-03 07:23:39,636 [Thread-237] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7
2020-12-03 07:23:39,636 [Thread-305] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1192165426-172.17.0.8-1606980210852 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7...
2020-12-03 07:23:39,637 [Thread-306] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1192165426-172.17.0.8-1606980210852 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8...
2020-12-03 07:23:39,637 [Thread-237] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7
2020-12-03 07:23:39,637 [Thread-237] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-12-03 07:23:39,637 [Thread-237] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-12-03 07:23:39,638 [Thread-237] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1199477258-172.17.0.8-1606980214994
2020-12-03 07:23:39,642 [IPC Server handler 4 on default port 32986] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:39,642 [Listener at localhost/37926] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:39,643 [Listener at localhost/37926] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:39,658 [Thread-305] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1192165426-172.17.0.8-1606980210852 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7: 22ms
2020-12-03 07:23:39,658 [Thread-306] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1192165426-172.17.0.8-1606980210852 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8: 22ms
2020-12-03 07:23:39,659 [Thread-236] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1192165426-172.17.0.8-1606980210852: 22ms
2020-12-03 07:23:39,659 [Thread-309] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1192165426-172.17.0.8-1606980210852 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7...
2020-12-03 07:23:39,659 [Thread-310] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1199477258-172.17.0.8-1606980214994 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7...
2020-12-03 07:23:39,659 [Thread-309] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-1192165426-172.17.0.8-1606980210852/current/replicas doesn't exist 
2020-12-03 07:23:39,659 [Thread-311] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1192165426-172.17.0.8-1606980210852 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8...
2020-12-03 07:23:39,659 [Thread-312] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1199477258-172.17.0.8-1606980214994 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8...
2020-12-03 07:23:39,660 [Thread-311] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-1192165426-172.17.0.8-1606980210852/current/replicas doesn't exist 
2020-12-03 07:23:39,660 [Thread-309] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1192165426-172.17.0.8-1606980210852 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7: 0ms
2020-12-03 07:23:39,660 [Thread-311] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1192165426-172.17.0.8-1606980210852 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8: 0ms
2020-12-03 07:23:39,660 [Thread-236] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1192165426-172.17.0.8-1606980210852: 1ms
2020-12-03 07:23:39,661 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1192165426-172.17.0.8-1606980210852 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7
2020-12-03 07:23:39,661 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1192165426-172.17.0.8-1606980210852 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-12-03 07:23:39,661 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, DS-707a6798-cced-414e-becf-df59de1fd486): finished scanning block pool BP-1192165426-172.17.0.8-1606980210852
2020-12-03 07:23:39,661 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, DS-78e24e72-4b84-4d28-a4dd-af91ad349ab5): finished scanning block pool BP-1192165426-172.17.0.8-1606980210852
2020-12-03 07:23:39,661 [Thread-236] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 9:10 AM with interval of 21600000ms
2020-12-03 07:23:39,662 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, DS-707a6798-cced-414e-becf-df59de1fd486): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:23:39,662 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, DS-78e24e72-4b84-4d28-a4dd-af91ad349ab5): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:23:39,663 [BP-1192165426-172.17.0.8-1606980210852 heartbeating to localhost/127.0.0.1:42813] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1192165426-172.17.0.8-1606980210852 (Datanode Uuid e1a5f8c8-f07f-476b-9f72-5bd254411763) service to localhost/127.0.0.1:42813 beginning handshake with NN
2020-12-03 07:23:39,663 [BP-1192165426-172.17.0.8-1606980210852 heartbeating to localhost/127.0.0.1:32986] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1192165426-172.17.0.8-1606980210852 (Datanode Uuid e1a5f8c8-f07f-476b-9f72-5bd254411763) service to localhost/127.0.0.1:32986 beginning handshake with NN
2020-12-03 07:23:39,664 [IPC Server handler 9 on default port 42813] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:33459, datanodeUuid=e1a5f8c8-f07f-476b-9f72-5bd254411763, infoPort=36875, infoSecurePort=0, ipcPort=37926, storageInfo=lv=-57;cid=testClusterID;nsid=2077292191;c=1606980210852) storage e1a5f8c8-f07f-476b-9f72-5bd254411763
2020-12-03 07:23:39,664 [IPC Server handler 9 on default port 42813] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:33459
2020-12-03 07:23:39,664 [IPC Server handler 9 on default port 42813] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN e1a5f8c8-f07f-476b-9f72-5bd254411763 (127.0.0.1:33459).
2020-12-03 07:23:39,664 [IPC Server handler 2 on default port 32986] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:33459, datanodeUuid=e1a5f8c8-f07f-476b-9f72-5bd254411763, infoPort=36875, infoSecurePort=0, ipcPort=37926, storageInfo=lv=-57;cid=testClusterID;nsid=2077292191;c=1606980210852) storage e1a5f8c8-f07f-476b-9f72-5bd254411763
2020-12-03 07:23:39,665 [IPC Server handler 2 on default port 32986] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:33459
2020-12-03 07:23:39,665 [IPC Server handler 2 on default port 32986] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN e1a5f8c8-f07f-476b-9f72-5bd254411763 (127.0.0.1:33459).
2020-12-03 07:23:39,665 [BP-1192165426-172.17.0.8-1606980210852 heartbeating to localhost/127.0.0.1:42813] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1192165426-172.17.0.8-1606980210852 (Datanode Uuid e1a5f8c8-f07f-476b-9f72-5bd254411763) service to localhost/127.0.0.1:42813 successfully registered with NN
2020-12-03 07:23:39,665 [BP-1192165426-172.17.0.8-1606980210852 heartbeating to localhost/127.0.0.1:42813] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:42813 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:39,668 [IPC Server handler 8 on default port 42813] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-707a6798-cced-414e-becf-df59de1fd486 for DN 127.0.0.1:33459
2020-12-03 07:23:39,668 [IPC Server handler 8 on default port 42813] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-78e24e72-4b84-4d28-a4dd-af91ad349ab5 for DN 127.0.0.1:33459
2020-12-03 07:23:39,668 [BP-1192165426-172.17.0.8-1606980210852 heartbeating to localhost/127.0.0.1:32986] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1192165426-172.17.0.8-1606980210852 (Datanode Uuid e1a5f8c8-f07f-476b-9f72-5bd254411763) service to localhost/127.0.0.1:32986 successfully registered with NN
2020-12-03 07:23:39,669 [BP-1192165426-172.17.0.8-1606980210852 heartbeating to localhost/127.0.0.1:32986] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:32986 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:39,672 [IPC Server handler 0 on default port 32986] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-707a6798-cced-414e-becf-df59de1fd486 for DN 127.0.0.1:33459
2020-12-03 07:23:39,673 [IPC Server handler 0 on default port 32986] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-78e24e72-4b84-4d28-a4dd-af91ad349ab5 for DN 127.0.0.1:33459
2020-12-03 07:23:39,680 [Thread-312] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1199477258-172.17.0.8-1606980214994 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8: 20ms
2020-12-03 07:23:39,680 [Thread-310] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1199477258-172.17.0.8-1606980214994 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7: 20ms
2020-12-03 07:23:39,681 [Thread-237] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1199477258-172.17.0.8-1606980214994: 22ms
2020-12-03 07:23:39,681 [Thread-318] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1199477258-172.17.0.8-1606980214994 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7...
2020-12-03 07:23:39,681 [Thread-319] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1199477258-172.17.0.8-1606980214994 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8...
2020-12-03 07:23:39,681 [Thread-318] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-1199477258-172.17.0.8-1606980214994/current/replicas doesn't exist 
2020-12-03 07:23:39,681 [Thread-319] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-1199477258-172.17.0.8-1606980214994/current/replicas doesn't exist 
2020-12-03 07:23:39,682 [Thread-318] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1199477258-172.17.0.8-1606980214994 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7: 1ms
2020-12-03 07:23:39,682 [Thread-319] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1199477258-172.17.0.8-1606980214994 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8: 1ms
2020-12-03 07:23:39,682 [Thread-237] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1199477258-172.17.0.8-1606980214994: 2ms
2020-12-03 07:23:39,683 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x5a36ebec7eedec97: Processing first storage report for DS-78e24e72-4b84-4d28-a4dd-af91ad349ab5 from datanode e1a5f8c8-f07f-476b-9f72-5bd254411763
2020-12-03 07:23:39,683 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xdfc01077318fbd82: Processing first storage report for DS-78e24e72-4b84-4d28-a4dd-af91ad349ab5 from datanode e1a5f8c8-f07f-476b-9f72-5bd254411763
2020-12-03 07:23:39,683 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1199477258-172.17.0.8-1606980214994 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7
2020-12-03 07:23:39,683 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xdfc01077318fbd82: from storage DS-78e24e72-4b84-4d28-a4dd-af91ad349ab5 node DatanodeRegistration(127.0.0.1:33459, datanodeUuid=e1a5f8c8-f07f-476b-9f72-5bd254411763, infoPort=36875, infoSecurePort=0, ipcPort=37926, storageInfo=lv=-57;cid=testClusterID;nsid=2077292191;c=1606980210852), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:39,683 [BP-1199477258-172.17.0.8-1606980214994 heartbeating to localhost/127.0.0.1:39762] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1199477258-172.17.0.8-1606980214994 (Datanode Uuid e1a5f8c8-f07f-476b-9f72-5bd254411763) service to localhost/127.0.0.1:39762 beginning handshake with NN
2020-12-03 07:23:39,683 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x5a36ebec7eedec97: from storage DS-78e24e72-4b84-4d28-a4dd-af91ad349ab5 node DatanodeRegistration(127.0.0.1:33459, datanodeUuid=e1a5f8c8-f07f-476b-9f72-5bd254411763, infoPort=36875, infoSecurePort=0, ipcPort=37926, storageInfo=lv=-57;cid=testClusterID;nsid=2077292191;c=1606980210852), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:39,683 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1199477258-172.17.0.8-1606980214994 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-12-03 07:23:39,683 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x5a36ebec7eedec97: Processing first storage report for DS-707a6798-cced-414e-becf-df59de1fd486 from datanode e1a5f8c8-f07f-476b-9f72-5bd254411763
2020-12-03 07:23:39,683 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, DS-707a6798-cced-414e-becf-df59de1fd486): finished scanning block pool BP-1199477258-172.17.0.8-1606980214994
2020-12-03 07:23:39,683 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xdfc01077318fbd82: Processing first storage report for DS-707a6798-cced-414e-becf-df59de1fd486 from datanode e1a5f8c8-f07f-476b-9f72-5bd254411763
2020-12-03 07:23:39,683 [BP-1199477258-172.17.0.8-1606980214994 heartbeating to localhost/127.0.0.1:40028] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1199477258-172.17.0.8-1606980214994 (Datanode Uuid e1a5f8c8-f07f-476b-9f72-5bd254411763) service to localhost/127.0.0.1:40028 beginning handshake with NN
2020-12-03 07:23:39,684 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xdfc01077318fbd82: from storage DS-707a6798-cced-414e-becf-df59de1fd486 node DatanodeRegistration(127.0.0.1:33459, datanodeUuid=e1a5f8c8-f07f-476b-9f72-5bd254411763, infoPort=36875, infoSecurePort=0, ipcPort=37926, storageInfo=lv=-57;cid=testClusterID;nsid=2077292191;c=1606980210852), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:39,684 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, DS-78e24e72-4b84-4d28-a4dd-af91ad349ab5): finished scanning block pool BP-1199477258-172.17.0.8-1606980214994
2020-12-03 07:23:39,684 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x5a36ebec7eedec97: from storage DS-707a6798-cced-414e-becf-df59de1fd486 node DatanodeRegistration(127.0.0.1:33459, datanodeUuid=e1a5f8c8-f07f-476b-9f72-5bd254411763, infoPort=36875, infoSecurePort=0, ipcPort=37926, storageInfo=lv=-57;cid=testClusterID;nsid=2077292191;c=1606980210852), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:39,684 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, DS-707a6798-cced-414e-becf-df59de1fd486): no suitable block pools found to scan.  Waiting 1814399977 ms.
2020-12-03 07:23:39,684 [IPC Server handler 1 on default port 39762] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:33459, datanodeUuid=e1a5f8c8-f07f-476b-9f72-5bd254411763, infoPort=36875, infoSecurePort=0, ipcPort=37926, storageInfo=lv=-57;cid=testClusterID;nsid=1338103220;c=1606980214994) storage e1a5f8c8-f07f-476b-9f72-5bd254411763
2020-12-03 07:23:39,684 [BP-1192165426-172.17.0.8-1606980210852 heartbeating to localhost/127.0.0.1:42813] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xdfc01077318fbd82,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 10 msec to generate and 4 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:23:39,685 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, DS-78e24e72-4b84-4d28-a4dd-af91ad349ab5): no suitable block pools found to scan.  Waiting 1814399977 ms.
2020-12-03 07:23:39,684 [IPC Server handler 1 on default port 39762] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:33459
2020-12-03 07:23:39,684 [BP-1192165426-172.17.0.8-1606980210852 heartbeating to localhost/127.0.0.1:32986] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x5a36ebec7eedec97,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 7 msec to generate and 4 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:23:39,685 [IPC Server handler 1 on default port 39762] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN e1a5f8c8-f07f-476b-9f72-5bd254411763 (127.0.0.1:33459).
2020-12-03 07:23:39,685 [IPC Server handler 0 on default port 40028] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:33459, datanodeUuid=e1a5f8c8-f07f-476b-9f72-5bd254411763, infoPort=36875, infoSecurePort=0, ipcPort=37926, storageInfo=lv=-57;cid=testClusterID;nsid=1338103220;c=1606980214994) storage e1a5f8c8-f07f-476b-9f72-5bd254411763
2020-12-03 07:23:39,685 [IPC Server handler 0 on default port 40028] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:33459
2020-12-03 07:23:39,685 [IPC Server handler 0 on default port 40028] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN e1a5f8c8-f07f-476b-9f72-5bd254411763 (127.0.0.1:33459).
2020-12-03 07:23:39,686 [BP-1199477258-172.17.0.8-1606980214994 heartbeating to localhost/127.0.0.1:39762] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1199477258-172.17.0.8-1606980214994 (Datanode Uuid e1a5f8c8-f07f-476b-9f72-5bd254411763) service to localhost/127.0.0.1:39762 successfully registered with NN
2020-12-03 07:23:39,686 [BP-1199477258-172.17.0.8-1606980214994 heartbeating to localhost/127.0.0.1:39762] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:39762 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:39,686 [BP-1199477258-172.17.0.8-1606980214994 heartbeating to localhost/127.0.0.1:40028] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1199477258-172.17.0.8-1606980214994 (Datanode Uuid e1a5f8c8-f07f-476b-9f72-5bd254411763) service to localhost/127.0.0.1:40028 successfully registered with NN
2020-12-03 07:23:39,686 [BP-1199477258-172.17.0.8-1606980214994 heartbeating to localhost/127.0.0.1:40028] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:40028 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:39,688 [IPC Server handler 3 on default port 39762] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-707a6798-cced-414e-becf-df59de1fd486 for DN 127.0.0.1:33459
2020-12-03 07:23:39,688 [IPC Server handler 3 on default port 39762] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-78e24e72-4b84-4d28-a4dd-af91ad349ab5 for DN 127.0.0.1:33459
2020-12-03 07:23:39,689 [IPC Server handler 2 on default port 40028] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-707a6798-cced-414e-becf-df59de1fd486 for DN 127.0.0.1:33459
2020-12-03 07:23:39,689 [IPC Server handler 2 on default port 40028] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-78e24e72-4b84-4d28-a4dd-af91ad349ab5 for DN 127.0.0.1:33459
2020-12-03 07:23:39,690 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x217e258c792acc5e: Processing first storage report for DS-78e24e72-4b84-4d28-a4dd-af91ad349ab5 from datanode e1a5f8c8-f07f-476b-9f72-5bd254411763
2020-12-03 07:23:39,690 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x217e258c792acc5e: from storage DS-78e24e72-4b84-4d28-a4dd-af91ad349ab5 node DatanodeRegistration(127.0.0.1:33459, datanodeUuid=e1a5f8c8-f07f-476b-9f72-5bd254411763, infoPort=36875, infoSecurePort=0, ipcPort=37926, storageInfo=lv=-57;cid=testClusterID;nsid=1338103220;c=1606980214994), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:39,691 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xe9fa5f2d2fd71f11: Processing first storage report for DS-78e24e72-4b84-4d28-a4dd-af91ad349ab5 from datanode e1a5f8c8-f07f-476b-9f72-5bd254411763
2020-12-03 07:23:39,691 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x217e258c792acc5e: Processing first storage report for DS-707a6798-cced-414e-becf-df59de1fd486 from datanode e1a5f8c8-f07f-476b-9f72-5bd254411763
2020-12-03 07:23:39,691 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xe9fa5f2d2fd71f11: from storage DS-78e24e72-4b84-4d28-a4dd-af91ad349ab5 node DatanodeRegistration(127.0.0.1:33459, datanodeUuid=e1a5f8c8-f07f-476b-9f72-5bd254411763, infoPort=36875, infoSecurePort=0, ipcPort=37926, storageInfo=lv=-57;cid=testClusterID;nsid=1338103220;c=1606980214994), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:39,691 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x217e258c792acc5e: from storage DS-707a6798-cced-414e-becf-df59de1fd486 node DatanodeRegistration(127.0.0.1:33459, datanodeUuid=e1a5f8c8-f07f-476b-9f72-5bd254411763, infoPort=36875, infoSecurePort=0, ipcPort=37926, storageInfo=lv=-57;cid=testClusterID;nsid=1338103220;c=1606980214994), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:39,691 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xe9fa5f2d2fd71f11: Processing first storage report for DS-707a6798-cced-414e-becf-df59de1fd486 from datanode e1a5f8c8-f07f-476b-9f72-5bd254411763
2020-12-03 07:23:39,691 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xe9fa5f2d2fd71f11: from storage DS-707a6798-cced-414e-becf-df59de1fd486 node DatanodeRegistration(127.0.0.1:33459, datanodeUuid=e1a5f8c8-f07f-476b-9f72-5bd254411763, infoPort=36875, infoSecurePort=0, ipcPort=37926, storageInfo=lv=-57;cid=testClusterID;nsid=1338103220;c=1606980214994), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:23:39,692 [BP-1199477258-172.17.0.8-1606980214994 heartbeating to localhost/127.0.0.1:39762] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x217e258c792acc5e,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:23:39,692 [BP-1199477258-172.17.0.8-1606980214994 heartbeating to localhost/127.0.0.1:40028] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xe9fa5f2d2fd71f11,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:23:39,744 [IPC Server handler 1 on default port 32986] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:39,751 [IPC Server handler 7 on default port 42813] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:39,757 [IPC Server handler 5 on default port 39762] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:39,761 [IPC Server handler 3 on default port 40028] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:39,762 [Listener at localhost/37926] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:23:39,768 [IPC Server handler 6 on default port 32986] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:39,771 [IPC Server handler 3 on default port 42813] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:39,774 [IPC Server handler 6 on default port 39762] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:39,778 [IPC Server handler 7 on default port 40028] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:39,780 [Listener at localhost/37926] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:23:39,825 [Listener at localhost/37926] INFO  router.RouterRpcServer (RouterRpcServer.java:<init>(251)) - RPC server binding to /0.0.0.0:0 with 10 handlers for Router null
2020-12-03 07:23:39,827 [Listener at localhost/37926] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:39,828 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:39,837 [Listener at 0.0.0.0/43798] INFO  router.ConnectionManager (ConnectionManager.java:<init>(120)) - Cleaning connection pools every 60 seconds
2020-12-03 07:23:39,837 [Listener at 0.0.0.0/43798] INFO  router.ConnectionManager (ConnectionManager.java:<init>(125)) - Cleaning connections every 10 seconds
2020-12-03 07:23:39,838 [Listener at 0.0.0.0/43798] INFO  router.ConnectionManager (ConnectionManager.java:start(139)) - Cleaning every 10 seconds
2020-12-03 07:23:39,855 [Listener at 0.0.0.0/43798] INFO  router.RouterAdminServer (RouterAdminServer.java:<init>(132)) - Admin server binding to 0.0.0.0:0
2020-12-03 07:23:39,855 [Listener at 0.0.0.0/43798] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 100, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:39,856 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:39,860 [Listener at 0.0.0.0/38326] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns0
2020-12-03 07:23:39,862 [Listener at 0.0.0.0/38326] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns0
2020-12-03 07:23:39,862 [Listener at 0.0.0.0/38326] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns0
2020-12-03 07:23:39,862 [Listener at 0.0.0.0/38326] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns1
2020-12-03 07:23:39,862 [Listener at 0.0.0.0/38326] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns1
2020-12-03 07:23:39,863 [Listener at 0.0.0.0/38326] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - Router metrics system started (again)
2020-12-03 07:23:39,876 [Listener at 0.0.0.0/38326] INFO  store.StateStoreService (StateStoreService.java:serviceInit(185)) - Registered StateStoreMBean: Hadoop:service=Router,name=StateStore
2020-12-03 07:23:39,876 [Listener at 0.0.0.0/38326] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.federation.router.cache.ttl(5000) assuming MILLISECONDS
2020-12-03 07:23:39,880 [Listener at 0.0.0.0/38326] INFO  metrics.FederationRPCPerformanceMonitor (FederationRPCPerformanceMonitor.java:init(91)) - Registered FederationRPCMBean: Hadoop:service=Router,name=FederationRPC
2020-12-03 07:23:39,886 [Listener at 0.0.0.0/38326] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn0 RPC address: 127.0.0.1:39762
2020-12-03 07:23:39,886 [Listener at 0.0.0.0/38326] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn0 Service RPC address: 127.0.0.1:39762
2020-12-03 07:23:39,886 [Listener at 0.0.0.0/38326] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn0 Lifeline RPC address: 127.0.0.1:39762
2020-12-03 07:23:39,886 [Listener at 0.0.0.0/38326] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn0 Web address: 127.0.0.1:42421
2020-12-03 07:23:39,887 [Listener at 0.0.0.0/38326] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn0 RPC address: 127.0.0.1:32986
2020-12-03 07:23:39,887 [Listener at 0.0.0.0/38326] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn0 Service RPC address: 127.0.0.1:32986
2020-12-03 07:23:39,887 [Listener at 0.0.0.0/38326] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn0 Lifeline RPC address: 127.0.0.1:32986
2020-12-03 07:23:39,887 [Listener at 0.0.0.0/38326] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn0 Web address: 127.0.0.1:34751
2020-12-03 07:23:39,888 [Listener at 0.0.0.0/38326] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn1 RPC address: 127.0.0.1:40028
2020-12-03 07:23:39,888 [Listener at 0.0.0.0/38326] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn1 Service RPC address: 127.0.0.1:40028
2020-12-03 07:23:39,888 [Listener at 0.0.0.0/38326] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn1 Lifeline RPC address: 127.0.0.1:40028
2020-12-03 07:23:39,889 [Listener at 0.0.0.0/38326] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn1 Web address: 127.0.0.1:45234
2020-12-03 07:23:39,889 [Listener at 0.0.0.0/38326] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn1 RPC address: 127.0.0.1:42813
2020-12-03 07:23:39,889 [Listener at 0.0.0.0/38326] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn1 Service RPC address: 127.0.0.1:42813
2020-12-03 07:23:39,890 [Listener at 0.0.0.0/38326] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn1 Lifeline RPC address: 127.0.0.1:42813
2020-12-03 07:23:39,890 [Listener at 0.0.0.0/38326] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn1 Web address: 127.0.0.1:34811
2020-12-03 07:23:39,905 [Listener at 0.0.0.0/38326] INFO  router.RouterRpcServer (RouterRpcServer.java:<init>(251)) - RPC server binding to /0.0.0.0:0 with 10 handlers for Router null
2020-12-03 07:23:39,906 [Listener at 0.0.0.0/38326] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:39,907 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:39,910 [Listener at 0.0.0.0/33397] INFO  router.ConnectionManager (ConnectionManager.java:<init>(120)) - Cleaning connection pools every 60 seconds
2020-12-03 07:23:39,910 [Listener at 0.0.0.0/33397] INFO  router.ConnectionManager (ConnectionManager.java:<init>(125)) - Cleaning connections every 10 seconds
2020-12-03 07:23:39,911 [Listener at 0.0.0.0/33397] INFO  router.ConnectionManager (ConnectionManager.java:start(139)) - Cleaning every 10 seconds
2020-12-03 07:23:39,912 [Listener at 0.0.0.0/33397] INFO  router.RouterAdminServer (RouterAdminServer.java:<init>(132)) - Admin server binding to 0.0.0.0:0
2020-12-03 07:23:39,912 [Listener at 0.0.0.0/33397] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 100, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:39,913 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:39,915 [Listener at 0.0.0.0/37989] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns0
2020-12-03 07:23:39,915 [Listener at 0.0.0.0/37989] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns0
2020-12-03 07:23:39,915 [Listener at 0.0.0.0/37989] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns0
2020-12-03 07:23:39,916 [Listener at 0.0.0.0/37989] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns1
2020-12-03 07:23:39,916 [Listener at 0.0.0.0/37989] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns1
2020-12-03 07:23:39,916 [Listener at 0.0.0.0/37989] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - Router metrics system started (again)
2020-12-03 07:23:39,917 [Listener at 0.0.0.0/37989] INFO  store.StateStoreService (StateStoreService.java:serviceInit(185)) - Registered StateStoreMBean: Hadoop:service=Router,name=StateStore-1
2020-12-03 07:23:39,917 [Listener at 0.0.0.0/37989] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.federation.router.cache.ttl(5000) assuming MILLISECONDS
2020-12-03 07:23:39,918 [Listener at 0.0.0.0/37989] INFO  metrics.FederationRPCPerformanceMonitor (FederationRPCPerformanceMonitor.java:init(91)) - Registered FederationRPCMBean: Hadoop:service=Router,name=FederationRPC-1
2020-12-03 07:23:39,919 [Listener at 0.0.0.0/37989] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn0 RPC address: 127.0.0.1:39762
2020-12-03 07:23:39,919 [Listener at 0.0.0.0/37989] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn0 Service RPC address: 127.0.0.1:39762
2020-12-03 07:23:39,919 [Listener at 0.0.0.0/37989] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn0 Lifeline RPC address: 127.0.0.1:39762
2020-12-03 07:23:39,919 [Listener at 0.0.0.0/37989] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn0 Web address: 127.0.0.1:42421
2020-12-03 07:23:39,920 [Listener at 0.0.0.0/37989] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn0 RPC address: 127.0.0.1:32986
2020-12-03 07:23:39,920 [Listener at 0.0.0.0/37989] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn0 Service RPC address: 127.0.0.1:32986
2020-12-03 07:23:39,920 [Listener at 0.0.0.0/37989] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn0 Lifeline RPC address: 127.0.0.1:32986
2020-12-03 07:23:39,920 [Listener at 0.0.0.0/37989] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn0 Web address: 127.0.0.1:34751
2020-12-03 07:23:39,920 [Listener at 0.0.0.0/37989] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn1 RPC address: 127.0.0.1:40028
2020-12-03 07:23:39,921 [Listener at 0.0.0.0/37989] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn1 Service RPC address: 127.0.0.1:40028
2020-12-03 07:23:39,921 [Listener at 0.0.0.0/37989] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn1 Lifeline RPC address: 127.0.0.1:40028
2020-12-03 07:23:39,921 [Listener at 0.0.0.0/37989] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn1 Web address: 127.0.0.1:45234
2020-12-03 07:23:39,926 [Listener at 0.0.0.0/37989] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn1 RPC address: 127.0.0.1:42813
2020-12-03 07:23:39,926 [Listener at 0.0.0.0/37989] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn1 Service RPC address: 127.0.0.1:42813
2020-12-03 07:23:39,926 [Listener at 0.0.0.0/37989] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn1 Lifeline RPC address: 127.0.0.1:42813
2020-12-03 07:23:39,926 [Listener at 0.0.0.0/37989] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn1 Web address: 127.0.0.1:34811
2020-12-03 07:23:39,946 [Listener at 0.0.0.0/37989] INFO  router.RouterRpcServer (RouterRpcServer.java:<init>(251)) - RPC server binding to /0.0.0.0:0 with 10 handlers for Router null
2020-12-03 07:23:39,947 [Listener at 0.0.0.0/37989] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:39,948 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:39,970 [Listener at 0.0.0.0/46601] INFO  router.ConnectionManager (ConnectionManager.java:<init>(120)) - Cleaning connection pools every 60 seconds
2020-12-03 07:23:39,971 [Listener at 0.0.0.0/46601] INFO  router.ConnectionManager (ConnectionManager.java:<init>(125)) - Cleaning connections every 10 seconds
2020-12-03 07:23:39,972 [Listener at 0.0.0.0/46601] INFO  router.ConnectionManager (ConnectionManager.java:start(139)) - Cleaning every 10 seconds
2020-12-03 07:23:39,974 [Listener at 0.0.0.0/46601] INFO  router.RouterAdminServer (RouterAdminServer.java:<init>(132)) - Admin server binding to 0.0.0.0:0
2020-12-03 07:23:39,974 [Listener at 0.0.0.0/46601] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 100, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:39,975 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:40,005 [Listener at 0.0.0.0/45005] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns1
2020-12-03 07:23:40,006 [Listener at 0.0.0.0/45005] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns0
2020-12-03 07:23:40,006 [Listener at 0.0.0.0/45005] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns0
2020-12-03 07:23:40,006 [Listener at 0.0.0.0/45005] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns1
2020-12-03 07:23:40,006 [Listener at 0.0.0.0/45005] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns1
2020-12-03 07:23:40,007 [Listener at 0.0.0.0/45005] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - Router metrics system started (again)
2020-12-03 07:23:40,008 [Listener at 0.0.0.0/45005] INFO  store.StateStoreService (StateStoreService.java:serviceInit(185)) - Registered StateStoreMBean: Hadoop:service=Router,name=StateStore-2
2020-12-03 07:23:40,008 [Listener at 0.0.0.0/45005] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.federation.router.cache.ttl(5000) assuming MILLISECONDS
2020-12-03 07:23:40,009 [Listener at 0.0.0.0/45005] INFO  metrics.FederationRPCPerformanceMonitor (FederationRPCPerformanceMonitor.java:init(91)) - Registered FederationRPCMBean: Hadoop:service=Router,name=FederationRPC-2
2020-12-03 07:23:40,010 [Listener at 0.0.0.0/45005] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn0 RPC address: 127.0.0.1:39762
2020-12-03 07:23:40,010 [Listener at 0.0.0.0/45005] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn0 Service RPC address: 127.0.0.1:39762
2020-12-03 07:23:40,010 [Listener at 0.0.0.0/45005] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn0 Lifeline RPC address: 127.0.0.1:39762
2020-12-03 07:23:40,010 [Listener at 0.0.0.0/45005] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn0 Web address: 127.0.0.1:42421
2020-12-03 07:23:40,013 [Listener at 0.0.0.0/45005] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn0 RPC address: 127.0.0.1:32986
2020-12-03 07:23:40,013 [Listener at 0.0.0.0/45005] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn0 Service RPC address: 127.0.0.1:32986
2020-12-03 07:23:40,013 [Listener at 0.0.0.0/45005] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn0 Lifeline RPC address: 127.0.0.1:32986
2020-12-03 07:23:40,013 [Listener at 0.0.0.0/45005] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn0 Web address: 127.0.0.1:34751
2020-12-03 07:23:40,013 [Listener at 0.0.0.0/45005] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn1 RPC address: 127.0.0.1:40028
2020-12-03 07:23:40,014 [Listener at 0.0.0.0/45005] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn1 Service RPC address: 127.0.0.1:40028
2020-12-03 07:23:40,014 [Listener at 0.0.0.0/45005] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn1 Lifeline RPC address: 127.0.0.1:40028
2020-12-03 07:23:40,014 [Listener at 0.0.0.0/45005] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn1 Web address: 127.0.0.1:45234
2020-12-03 07:23:40,014 [Listener at 0.0.0.0/45005] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn1 RPC address: 127.0.0.1:42813
2020-12-03 07:23:40,014 [Listener at 0.0.0.0/45005] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn1 Service RPC address: 127.0.0.1:42813
2020-12-03 07:23:40,014 [Listener at 0.0.0.0/45005] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn1 Lifeline RPC address: 127.0.0.1:42813
2020-12-03 07:23:40,015 [Listener at 0.0.0.0/45005] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn1 Web address: 127.0.0.1:34811
2020-12-03 07:23:40,030 [Listener at 0.0.0.0/45005] INFO  router.RouterRpcServer (RouterRpcServer.java:<init>(251)) - RPC server binding to /0.0.0.0:0 with 10 handlers for Router null
2020-12-03 07:23:40,031 [Listener at 0.0.0.0/45005] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:40,032 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:40,035 [Listener at 0.0.0.0/45719] INFO  router.ConnectionManager (ConnectionManager.java:<init>(120)) - Cleaning connection pools every 60 seconds
2020-12-03 07:23:40,036 [Listener at 0.0.0.0/45719] INFO  router.ConnectionManager (ConnectionManager.java:<init>(125)) - Cleaning connections every 10 seconds
2020-12-03 07:23:40,036 [Listener at 0.0.0.0/45719] INFO  router.ConnectionManager (ConnectionManager.java:start(139)) - Cleaning every 10 seconds
2020-12-03 07:23:40,037 [Listener at 0.0.0.0/45719] INFO  router.RouterAdminServer (RouterAdminServer.java:<init>(132)) - Admin server binding to 0.0.0.0:0
2020-12-03 07:23:40,038 [Listener at 0.0.0.0/45719] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 100, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:40,039 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:40,042 [Listener at 0.0.0.0/43063] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns1
2020-12-03 07:23:40,043 [Listener at 0.0.0.0/43063] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns0
2020-12-03 07:23:40,043 [Listener at 0.0.0.0/43063] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns0
2020-12-03 07:23:40,043 [Listener at 0.0.0.0/43063] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns1
2020-12-03 07:23:40,043 [Listener at 0.0.0.0/43063] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns1
2020-12-03 07:23:40,044 [Listener at 0.0.0.0/43063] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - Router metrics system started (again)
2020-12-03 07:23:40,045 [Listener at 0.0.0.0/43063] INFO  store.StateStoreService (StateStoreService.java:serviceInit(185)) - Registered StateStoreMBean: Hadoop:service=Router,name=StateStore-3
2020-12-03 07:23:40,045 [Listener at 0.0.0.0/43063] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.federation.router.cache.ttl(5000) assuming MILLISECONDS
2020-12-03 07:23:40,046 [Listener at 0.0.0.0/43063] INFO  metrics.FederationRPCPerformanceMonitor (FederationRPCPerformanceMonitor.java:init(91)) - Registered FederationRPCMBean: Hadoop:service=Router,name=FederationRPC-3
2020-12-03 07:23:40,046 [Listener at 0.0.0.0/43063] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn0 RPC address: 127.0.0.1:39762
2020-12-03 07:23:40,046 [Listener at 0.0.0.0/43063] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn0 Service RPC address: 127.0.0.1:39762
2020-12-03 07:23:40,046 [Listener at 0.0.0.0/43063] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn0 Lifeline RPC address: 127.0.0.1:39762
2020-12-03 07:23:40,046 [Listener at 0.0.0.0/43063] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn0 Web address: 127.0.0.1:42421
2020-12-03 07:23:40,047 [Listener at 0.0.0.0/43063] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn1 RPC address: 127.0.0.1:40028
2020-12-03 07:23:40,047 [Listener at 0.0.0.0/43063] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn1 Service RPC address: 127.0.0.1:40028
2020-12-03 07:23:40,047 [Listener at 0.0.0.0/43063] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn1 Lifeline RPC address: 127.0.0.1:40028
2020-12-03 07:23:40,047 [Listener at 0.0.0.0/43063] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn1 Web address: 127.0.0.1:45234
2020-12-03 07:23:40,048 [Listener at 0.0.0.0/43063] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn0 RPC address: 127.0.0.1:32986
2020-12-03 07:23:40,048 [Listener at 0.0.0.0/43063] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn0 Service RPC address: 127.0.0.1:32986
2020-12-03 07:23:40,048 [Listener at 0.0.0.0/43063] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn0 Lifeline RPC address: 127.0.0.1:32986
2020-12-03 07:23:40,048 [Listener at 0.0.0.0/43063] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn0 Web address: 127.0.0.1:34751
2020-12-03 07:23:40,049 [Listener at 0.0.0.0/43063] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn1 RPC address: 127.0.0.1:42813
2020-12-03 07:23:40,049 [Listener at 0.0.0.0/43063] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn1 Service RPC address: 127.0.0.1:42813
2020-12-03 07:23:40,049 [Listener at 0.0.0.0/43063] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn1 Lifeline RPC address: 127.0.0.1:42813
2020-12-03 07:23:40,049 [Listener at 0.0.0.0/43063] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn1 Web address: 127.0.0.1:34811
2020-12-03 07:23:40,054 [Listener at 0.0.0.0/43063] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-12-03 07:23:40,054 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@100c567f] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:40,054 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 1c04ae08cdfc:43798: State Store unavailable
2020-12-03 07:23:40,057 [Listener at 0.0.0.0/43063] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.serviceStart(StateStoreService.java:197)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.service.CompositeService.serviceStart(CompositeService.java:121)
	at org.apache.hadoop.hdfs.server.federation.router.Router.serviceStart(Router.java:265)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.hdfs.server.federation.MiniRouterDFSCluster.startRouters(MiniRouterDFSCluster.java:757)
	at org.apache.hadoop.fs.contract.router.web.RouterWebHDFSContract.createCluster(RouterWebHDFSContract.java:69)
	at org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractSeek.createCluster(TestRouterWebHDFSContractSeek.java:36)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2020-12-03 07:23:40,061 [Listener at 0.0.0.0/43063] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-12-03 07:23:40,062 [Listener at 0.0.0.0/43063] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-12-03 07:23:40,062 [Listener at 0.0.0.0/43063] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreConnectionMonitorService
2020-12-03 07:23:40,063 [Listener at 0.0.0.0/43063] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreCacheUpdateService
2020-12-03 07:23:40,063 [StateStoreConnectionMonitorService-0] INFO  store.StateStoreConnectionMonitorService (StateStoreConnectionMonitorService.java:periodicInvoke(63)) - Attempting to open state store driver.
2020-12-03 07:23:40,064 [StateStoreConnectionMonitorService-0] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-12-03 07:23:40,068 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:40,068 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:40,068 [StateStoreConnectionMonitorService-0] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreConnectionMonitorService.periodicInvoke(StateStoreConnectionMonitorService.java:64)
	at org.apache.hadoop.hdfs.server.federation.router.PeriodicService$1.run(PeriodicService.java:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:23:40,068 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-12-03 07:23:40,071 [StateStoreConnectionMonitorService-0] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-12-03 07:23:40,077 [StateStoreConnectionMonitorService-0] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-12-03 07:23:40,077 [Listener at 0.0.0.0/43063] INFO  router.RouterRpcServer (RouterRpcServer.java:serviceStart(322)) - Router RPC up at: /0.0.0.0:43798
2020-12-03 07:23:40,078 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:40,078 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:40,083 [Listener at 0.0.0.0/43063] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for router at: http://0.0.0.0:0
2020-12-03 07:23:40,084 [Listener at 0.0.0.0/43063] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:40,086 [Listener at 0.0.0.0/43063] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:40,087 [Listener at 0.0.0.0/43063] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.router is not defined
2020-12-03 07:23:40,087 [Listener at 0.0.0.0/43063] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:40,089 [Listener at 0.0.0.0/43063] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:40,090 [Listener at 0.0.0.0/43063] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context router
2020-12-03 07:23:40,090 [Listener at 0.0.0.0/43063] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:40,090 [Listener at 0.0.0.0/43063] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:40,093 [Listener at 0.0.0.0/43063] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:23:40,093 [Listener at 0.0.0.0/43063] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.federation.router;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:23:40,094 [Listener at 0.0.0.0/43063] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 38421
2020-12-03 07:23:40,094 [Listener at 0.0.0.0/43063] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:40,096 [Listener at 0.0.0.0/43063] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@f446158{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:23:40,097 [Listener at 0.0.0.0/43063] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@504e1599{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:40,103 [Listener at 0.0.0.0/43063] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@68f32020{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/router/,AVAILABLE}{/router}
2020-12-03 07:23:40,105 [Listener at 0.0.0.0/43063] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@409986fe{HTTP/1.1,[http/1.1]}{0.0.0.0:38421}
2020-12-03 07:23:40,105 [Listener at 0.0.0.0/43063] INFO  server.Server (Server.java:doStart(419)) - Started @11781ms
2020-12-03 07:23:40,105 [Listener at 0.0.0.0/43063] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn0
2020-12-03 07:23:40,106 [Listener at 0.0.0.0/43063] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn0
2020-12-03 07:23:40,106 [Listener at 0.0.0.0/43063] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn1
2020-12-03 07:23:40,106 [Listener at 0.0.0.0/43063] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn1
2020-12-03 07:23:40,107 [Listener at 0.0.0.0/43063] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service RouterHeartbeatService
2020-12-03 07:23:40,108 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 1c04ae08cdfc:43798: State Store unavailable
2020-12-03 07:23:40,110 [Listener at 0.0.0.0/43063] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(117)) - Registered FSNamesystem MBean: Hadoop:service=NameNode,name=FSNamesystem-4
2020-12-03 07:23:40,110 [Listener at 0.0.0.0/43063] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(126)) - Registered FSNamesystemState MBean: Hadoop:service=NameNode,name=FSNamesystemState-4
2020-12-03 07:23:40,112 [Listener at 0.0.0.0/43063] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(134)) - Registered NameNodeInfo MBean: Hadoop:service=NameNode,name=NameNodeInfo-4
2020-12-03 07:23:40,113 [Listener at 0.0.0.0/43063] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(143)) - Registered NameNodeStatus MBean: Hadoop:service=NameNode,name=NameNodeStatus-4
2020-12-03 07:23:40,116 [Listener at 0.0.0.0/43063] INFO  metrics.FederationMetrics (FederationMetrics.java:<init>(126)) - Registered Router MBean: Hadoop:service=Router,name=FederationState
2020-12-03 07:23:40,117 [Listener at 0.0.0.0/43063] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-12-03 07:23:40,118 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@118102ee] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:40,117 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 1c04ae08cdfc:33397: State Store unavailable
2020-12-03 07:23:40,118 [Listener at 0.0.0.0/43063] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.serviceStart(StateStoreService.java:197)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.service.CompositeService.serviceStart(CompositeService.java:121)
	at org.apache.hadoop.hdfs.server.federation.router.Router.serviceStart(Router.java:265)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.hdfs.server.federation.MiniRouterDFSCluster.startRouters(MiniRouterDFSCluster.java:757)
	at org.apache.hadoop.fs.contract.router.web.RouterWebHDFSContract.createCluster(RouterWebHDFSContract.java:69)
	at org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractSeek.createCluster(TestRouterWebHDFSContractSeek.java:36)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2020-12-03 07:23:40,119 [Listener at 0.0.0.0/43063] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-12-03 07:23:40,120 [Listener at 0.0.0.0/43063] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-12-03 07:23:40,120 [Listener at 0.0.0.0/43063] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreConnectionMonitorService
2020-12-03 07:23:40,121 [Listener at 0.0.0.0/43063] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreCacheUpdateService
2020-12-03 07:23:40,121 [StateStoreConnectionMonitorService-0] INFO  store.StateStoreConnectionMonitorService (StateStoreConnectionMonitorService.java:periodicInvoke(63)) - Attempting to open state store driver.
2020-12-03 07:23:40,121 [StateStoreConnectionMonitorService-0] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-12-03 07:23:40,122 [StateStoreConnectionMonitorService-0] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreConnectionMonitorService.periodicInvoke(StateStoreConnectionMonitorService.java:64)
	at org.apache.hadoop.hdfs.server.federation.router.PeriodicService$1.run(PeriodicService.java:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:23:40,123 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:40,123 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:40,123 [StateStoreConnectionMonitorService-0] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-12-03 07:23:40,123 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-12-03 07:23:40,124 [StateStoreConnectionMonitorService-0] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-12-03 07:23:40,126 [Listener at 0.0.0.0/43063] INFO  router.RouterRpcServer (RouterRpcServer.java:serviceStart(322)) - Router RPC up at: /0.0.0.0:33397
2020-12-03 07:23:40,126 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:40,126 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:40,128 [Listener at 0.0.0.0/43063] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for router at: http://0.0.0.0:0
2020-12-03 07:23:40,128 [Listener at 0.0.0.0/43063] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:40,130 [Listener at 0.0.0.0/43063] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:40,131 [Listener at 0.0.0.0/43063] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.router is not defined
2020-12-03 07:23:40,131 [Listener at 0.0.0.0/43063] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:40,133 [Listener at 0.0.0.0/43063] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:40,133 [Listener at 0.0.0.0/43063] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context router
2020-12-03 07:23:40,133 [Listener at 0.0.0.0/43063] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:40,133 [Listener at 0.0.0.0/43063] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:40,135 [Listener at 0.0.0.0/43063] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:23:40,135 [Listener at 0.0.0.0/43063] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.federation.router;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:23:40,135 [Listener at 0.0.0.0/43063] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 35181
2020-12-03 07:23:40,136 [Listener at 0.0.0.0/43063] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:40,138 [Listener at 0.0.0.0/43063] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7dff6d05{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:23:40,138 [Listener at 0.0.0.0/43063] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@34fe326d{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:40,144 [Listener at 0.0.0.0/43063] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@43a51d00{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/router/,AVAILABLE}{/router}
2020-12-03 07:23:40,146 [Listener at 0.0.0.0/43063] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2e23c180{HTTP/1.1,[http/1.1]}{0.0.0.0:35181}
2020-12-03 07:23:40,146 [Listener at 0.0.0.0/43063] INFO  server.Server (Server.java:doStart(419)) - Started @11821ms
2020-12-03 07:23:40,146 [Listener at 0.0.0.0/43063] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn0
2020-12-03 07:23:40,146 [Listener at 0.0.0.0/43063] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn0
2020-12-03 07:23:40,147 [Listener at 0.0.0.0/43063] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn1
2020-12-03 07:23:40,147 [Listener at 0.0.0.0/43063] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn1
2020-12-03 07:23:40,147 [Listener at 0.0.0.0/43063] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service RouterHeartbeatService
2020-12-03 07:23:40,148 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 1c04ae08cdfc:33397: State Store unavailable
2020-12-03 07:23:40,148 [Listener at 0.0.0.0/43063] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(117)) - Registered FSNamesystem MBean: Hadoop:service=NameNode,name=FSNamesystem-5
2020-12-03 07:23:40,149 [Listener at 0.0.0.0/43063] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(126)) - Registered FSNamesystemState MBean: Hadoop:service=NameNode,name=FSNamesystemState-5
2020-12-03 07:23:40,149 [Listener at 0.0.0.0/43063] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(134)) - Registered NameNodeInfo MBean: Hadoop:service=NameNode,name=NameNodeInfo-5
2020-12-03 07:23:40,149 [Listener at 0.0.0.0/43063] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(143)) - Registered NameNodeStatus MBean: Hadoop:service=NameNode,name=NameNodeStatus-5
2020-12-03 07:23:40,149 [Listener at 0.0.0.0/43063] INFO  metrics.FederationMetrics (FederationMetrics.java:<init>(126)) - Registered Router MBean: Hadoop:service=Router,name=FederationState-1
2020-12-03 07:23:40,150 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 1c04ae08cdfc:46601: State Store unavailable
2020-12-03 07:23:40,150 [Listener at 0.0.0.0/43063] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-12-03 07:23:40,150 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@75308740] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:40,150 [Listener at 0.0.0.0/43063] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.serviceStart(StateStoreService.java:197)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.service.CompositeService.serviceStart(CompositeService.java:121)
	at org.apache.hadoop.hdfs.server.federation.router.Router.serviceStart(Router.java:265)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.hdfs.server.federation.MiniRouterDFSCluster.startRouters(MiniRouterDFSCluster.java:757)
	at org.apache.hadoop.fs.contract.router.web.RouterWebHDFSContract.createCluster(RouterWebHDFSContract.java:69)
	at org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractSeek.createCluster(TestRouterWebHDFSContractSeek.java:36)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2020-12-03 07:23:40,151 [Listener at 0.0.0.0/43063] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-12-03 07:23:40,151 [Listener at 0.0.0.0/43063] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-12-03 07:23:40,151 [Listener at 0.0.0.0/43063] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreConnectionMonitorService
2020-12-03 07:23:40,151 [Listener at 0.0.0.0/43063] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreCacheUpdateService
2020-12-03 07:23:40,152 [StateStoreConnectionMonitorService-0] INFO  store.StateStoreConnectionMonitorService (StateStoreConnectionMonitorService.java:periodicInvoke(63)) - Attempting to open state store driver.
2020-12-03 07:23:40,153 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-12-03 07:23:40,153 [StateStoreConnectionMonitorService-0] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-12-03 07:23:40,153 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:40,153 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:40,154 [StateStoreConnectionMonitorService-0] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreConnectionMonitorService.periodicInvoke(StateStoreConnectionMonitorService.java:64)
	at org.apache.hadoop.hdfs.server.federation.router.PeriodicService$1.run(PeriodicService.java:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:23:40,156 [StateStoreConnectionMonitorService-0] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-12-03 07:23:40,156 [StateStoreConnectionMonitorService-0] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-12-03 07:23:40,157 [Listener at 0.0.0.0/43063] INFO  router.RouterRpcServer (RouterRpcServer.java:serviceStart(322)) - Router RPC up at: /0.0.0.0:46601
2020-12-03 07:23:40,158 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:40,158 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:40,159 [Listener at 0.0.0.0/43063] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for router at: http://0.0.0.0:0
2020-12-03 07:23:40,160 [Listener at 0.0.0.0/43063] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:40,161 [Listener at 0.0.0.0/43063] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:40,162 [Listener at 0.0.0.0/43063] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.router is not defined
2020-12-03 07:23:40,162 [Listener at 0.0.0.0/43063] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:40,164 [Listener at 0.0.0.0/43063] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:40,164 [Listener at 0.0.0.0/43063] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context router
2020-12-03 07:23:40,164 [Listener at 0.0.0.0/43063] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:40,164 [Listener at 0.0.0.0/43063] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:40,166 [Listener at 0.0.0.0/43063] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:23:40,166 [Listener at 0.0.0.0/43063] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.federation.router;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:23:40,166 [Listener at 0.0.0.0/43063] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 36908
2020-12-03 07:23:40,166 [Listener at 0.0.0.0/43063] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:40,168 [Listener at 0.0.0.0/43063] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5ff90645{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:23:40,169 [Listener at 0.0.0.0/43063] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@74aa9c72{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:40,175 [Listener at 0.0.0.0/43063] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6ea04618{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/router/,AVAILABLE}{/router}
2020-12-03 07:23:40,177 [Listener at 0.0.0.0/43063] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6dd82486{HTTP/1.1,[http/1.1]}{0.0.0.0:36908}
2020-12-03 07:23:40,177 [Listener at 0.0.0.0/43063] INFO  server.Server (Server.java:doStart(419)) - Started @11853ms
2020-12-03 07:23:40,177 [Listener at 0.0.0.0/43063] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn0
2020-12-03 07:23:40,178 [Listener at 0.0.0.0/43063] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn0
2020-12-03 07:23:40,178 [Listener at 0.0.0.0/43063] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn1
2020-12-03 07:23:40,178 [Listener at 0.0.0.0/43063] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn1
2020-12-03 07:23:40,178 [Listener at 0.0.0.0/43063] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service RouterHeartbeatService
2020-12-03 07:23:40,179 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 1c04ae08cdfc:46601: State Store unavailable
2020-12-03 07:23:40,180 [Listener at 0.0.0.0/43063] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(117)) - Registered FSNamesystem MBean: Hadoop:service=NameNode,name=FSNamesystem-6
2020-12-03 07:23:40,180 [Listener at 0.0.0.0/43063] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(126)) - Registered FSNamesystemState MBean: Hadoop:service=NameNode,name=FSNamesystemState-6
2020-12-03 07:23:40,180 [Listener at 0.0.0.0/43063] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(134)) - Registered NameNodeInfo MBean: Hadoop:service=NameNode,name=NameNodeInfo-6
2020-12-03 07:23:40,180 [Listener at 0.0.0.0/43063] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(143)) - Registered NameNodeStatus MBean: Hadoop:service=NameNode,name=NameNodeStatus-6
2020-12-03 07:23:40,181 [Listener at 0.0.0.0/43063] INFO  metrics.FederationMetrics (FederationMetrics.java:<init>(126)) - Registered Router MBean: Hadoop:service=Router,name=FederationState-2
2020-12-03 07:23:40,181 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 1c04ae08cdfc:45719: State Store unavailable
2020-12-03 07:23:40,184 [Listener at 0.0.0.0/43063] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-12-03 07:23:40,188 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2d23faef] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:40,188 [Listener at 0.0.0.0/43063] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.serviceStart(StateStoreService.java:197)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.service.CompositeService.serviceStart(CompositeService.java:121)
	at org.apache.hadoop.hdfs.server.federation.router.Router.serviceStart(Router.java:265)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.hdfs.server.federation.MiniRouterDFSCluster.startRouters(MiniRouterDFSCluster.java:757)
	at org.apache.hadoop.fs.contract.router.web.RouterWebHDFSContract.createCluster(RouterWebHDFSContract.java:69)
	at org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractSeek.createCluster(TestRouterWebHDFSContractSeek.java:36)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2020-12-03 07:23:40,191 [Listener at 0.0.0.0/43063] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-12-03 07:23:40,191 [Listener at 0.0.0.0/43063] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-12-03 07:23:40,191 [Listener at 0.0.0.0/43063] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreConnectionMonitorService
2020-12-03 07:23:40,192 [Listener at 0.0.0.0/43063] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreCacheUpdateService
2020-12-03 07:23:40,192 [StateStoreConnectionMonitorService-0] INFO  store.StateStoreConnectionMonitorService (StateStoreConnectionMonitorService.java:periodicInvoke(63)) - Attempting to open state store driver.
2020-12-03 07:23:40,193 [StateStoreConnectionMonitorService-0] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-12-03 07:23:40,193 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:40,195 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:40,195 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-12-03 07:23:40,195 [StateStoreConnectionMonitorService-0] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreConnectionMonitorService.periodicInvoke(StateStoreConnectionMonitorService.java:64)
	at org.apache.hadoop.hdfs.server.federation.router.PeriodicService$1.run(PeriodicService.java:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:23:40,201 [Listener at 0.0.0.0/43063] INFO  router.RouterRpcServer (RouterRpcServer.java:serviceStart(322)) - Router RPC up at: /0.0.0.0:45719
2020-12-03 07:23:40,201 [StateStoreConnectionMonitorService-0] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-12-03 07:23:40,201 [StateStoreConnectionMonitorService-0] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-12-03 07:23:40,201 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:40,202 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:40,203 [Listener at 0.0.0.0/43063] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for router at: http://0.0.0.0:0
2020-12-03 07:23:40,203 [Listener at 0.0.0.0/43063] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:40,206 [Listener at 0.0.0.0/43063] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:40,207 [Listener at 0.0.0.0/43063] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.router is not defined
2020-12-03 07:23:40,207 [Listener at 0.0.0.0/43063] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:40,213 [IPC Server handler 8 on default port 39762] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:40,213 [IPC Server handler 8 on default port 32986] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:40,213 [IPC Server handler 8 on default port 40028] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:40,213 [IPC Server handler 2 on default port 32986] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:40,213 [IPC Server handler 9 on default port 40028] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:40,213 [IPC Server handler 1 on default port 39762] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:40,213 [IPC Server handler 1 on default port 42813] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:40,213 [IPC Server handler 9 on default port 39762] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:40,213 [IPC Server handler 5 on default port 42813] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:40,213 [IPC Server handler 4 on default port 32986] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:40,214 [Listener at 0.0.0.0/43063] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:40,214 [IPC Server handler 9 on default port 42813] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:40,214 [IPC Server handler 0 on default port 40028] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:40,215 [Listener at 0.0.0.0/43063] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context router
2020-12-03 07:23:40,216 [Listener at 0.0.0.0/43063] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:40,216 [Listener at 0.0.0.0/43063] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:40,218 [Listener at 0.0.0.0/43063] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:23:40,218 [Listener at 0.0.0.0/43063] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.federation.router;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:23:40,219 [Listener at 0.0.0.0/43063] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 36271
2020-12-03 07:23:40,219 [Listener at 0.0.0.0/43063] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:40,221 [Listener at 0.0.0.0/43063] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@39c1fe0b{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:23:40,222 [Listener at 0.0.0.0/43063] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@62891fc8{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:40,232 [Listener at 0.0.0.0/43063] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@86733{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/router/,AVAILABLE}{/router}
2020-12-03 07:23:40,236 [Listener at 0.0.0.0/43063] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@186cb891{HTTP/1.1,[http/1.1]}{0.0.0.0:36271}
2020-12-03 07:23:40,237 [Listener at 0.0.0.0/43063] INFO  server.Server (Server.java:doStart(419)) - Started @11912ms
2020-12-03 07:23:40,239 [Listener at 0.0.0.0/43063] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn0
2020-12-03 07:23:40,239 [Listener at 0.0.0.0/43063] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn1
2020-12-03 07:23:40,240 [Listener at 0.0.0.0/43063] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn0
2020-12-03 07:23:40,283 [Listener at 0.0.0.0/43063] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn1
2020-12-03 07:23:40,287 [Listener at 0.0.0.0/43063] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service RouterHeartbeatService
2020-12-03 07:23:40,294 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 1c04ae08cdfc:45719: State Store unavailable
2020-12-03 07:23:40,296 [Listener at 0.0.0.0/43063] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(117)) - Registered FSNamesystem MBean: Hadoop:service=NameNode,name=FSNamesystem-7
2020-12-03 07:23:40,298 [IPC Server handler 9 on default port 32986] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:40,298 [IPC Server handler 2 on default port 39762] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:40,306 [Listener at 0.0.0.0/43063] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(126)) - Registered FSNamesystemState MBean: Hadoop:service=NameNode,name=FSNamesystemState-7
2020-12-03 07:23:40,306 [Listener at 0.0.0.0/43063] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(134)) - Registered NameNodeInfo MBean: Hadoop:service=NameNode,name=NameNodeInfo-7
2020-12-03 07:23:40,307 [Listener at 0.0.0.0/43063] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(143)) - Registered NameNodeStatus MBean: Hadoop:service=NameNode,name=NameNodeStatus-7
2020-12-03 07:23:40,307 [IPC Server handler 6 on default port 42813] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:40,307 [IPC Server handler 1 on default port 40028] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:40,307 [Listener at 0.0.0.0/43063] INFO  metrics.FederationMetrics (FederationMetrics.java:<init>(126)) - Registered Router MBean: Hadoop:service=Router,name=FederationState-3
2020-12-03 07:23:40,342 [Listener at 0.0.0.0/43063] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:23:40,342 [Edit log tailer] WARN  ha.EditLogTailer (EditLogTailer.java:doWork(528)) - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.sleep(EditLogTailer.java:433)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:526)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:440)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:457)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:484)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:453)
2020-12-03 07:23:40,345 [Listener at 0.0.0.0/43063] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:23:40,347 [Listener at 0.0.0.0/43063] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-0-through-1/current
2020-12-03 07:23:40,349 [Listener at 0.0.0.0/43063] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current
2020-12-03 07:23:40,349 [Listener at 0.0.0.0/43063] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/current
2020-12-03 07:23:40,349 [Listener at 0.0.0.0/43063] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1233)) - Catching up to latest edits from old active before taking over writer role in edits logs
2020-12-03 07:23:40,351 [Listener at 0.0.0.0/43063] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:markAllDatanodesStale(1840)) - Marking all datanodes as stale
2020-12-03 07:23:40,367 [Listener at 0.0.0.0/43063] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1244)) - Reprocessing replication and invalidation queues
2020-12-03 07:23:40,367 [Listener at 0.0.0.0/43063] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:23:40,368 [Listener at 0.0.0.0/43063] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1255)) - Will take over writing edit logs at txnid 1
2020-12-03 07:23:40,368 [Listener at 0.0.0.0/43063] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 1
2020-12-03 07:23:40,394 [Listener at 0.0.0.0/43063] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:23:40,401 [Listener at 0.0.0.0/43063] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 5 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:23:40,408 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 0
2020-12-03 07:23:40,408 [CacheReplicationMonitor(172064044)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:23:40,408 [Listener at 0.0.0.0/43063] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:23:40,408 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:23:40,409 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:23:40,409 [Edit log tailer] WARN  ha.EditLogTailer (EditLogTailer.java:doWork(528)) - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.sleep(EditLogTailer.java:433)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:526)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:440)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:457)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:484)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:453)
2020-12-03 07:23:40,409 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:23:40,410 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:23:40,410 [Listener at 0.0.0.0/43063] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:23:40,410 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 42 msec
2020-12-03 07:23:40,412 [Listener at 0.0.0.0/43063] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-2-through-3/current
2020-12-03 07:23:40,413 [Listener at 0.0.0.0/43063] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/current
2020-12-03 07:23:40,413 [Listener at 0.0.0.0/43063] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6/current
2020-12-03 07:23:40,413 [Listener at 0.0.0.0/43063] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1233)) - Catching up to latest edits from old active before taking over writer role in edits logs
2020-12-03 07:23:40,415 [Listener at 0.0.0.0/43063] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:markAllDatanodesStale(1840)) - Marking all datanodes as stale
2020-12-03 07:23:40,429 [Listener at 0.0.0.0/43063] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1244)) - Reprocessing replication and invalidation queues
2020-12-03 07:23:40,430 [Listener at 0.0.0.0/43063] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:23:40,433 [Listener at 0.0.0.0/43063] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1255)) - Will take over writing edit logs at txnid 1
2020-12-03 07:23:40,433 [Listener at 0.0.0.0/43063] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 1
2020-12-03 07:23:40,446 [Listener at 0.0.0.0/43063] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:23:40,448 [Listener at 0.0.0.0/43063] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 1 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:23:40,453 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 0
2020-12-03 07:23:40,453 [CacheReplicationMonitor(1897241247)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:23:40,454 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:23:40,454 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:23:40,454 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:23:40,455 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:23:40,455 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 22 msec
2020-12-03 07:23:41,494 [Thread-488] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = webhdfs://0.0.0.0:38421 implemented by org.apache.hadoop.hdfs.web.WebHdfsFileSystem@269138d6
Dec 03, 2020 7:23:41 AM com.sun.jersey.api.core.PackagesResourceConfig init
INFO: Scanning for root resource and provider classes in the packages:
  org.apache.hadoop.hdfs.server.federation.router
  org.apache.hadoop.hdfs.web.resources
Dec 03, 2020 7:23:42 AM com.sun.jersey.api.core.ScanningResourceConfig logClasses
INFO: Root resource classes found:
  class org.apache.hadoop.hdfs.server.federation.router.RouterWebHdfsMethods
Dec 03, 2020 7:23:42 AM com.sun.jersey.api.core.ScanningResourceConfig logClasses
INFO: Provider classes found:
  class org.apache.hadoop.hdfs.web.resources.ExceptionHandler
  class org.apache.hadoop.hdfs.web.resources.UserProvider
Dec 03, 2020 7:23:42 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
2020-12-03 07:23:42,525 [BP-1199477258-172.17.0.8-1606980214994 heartbeating to localhost/127.0.0.1:39762] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-1199477258-172.17.0.8-1606980214994 (Datanode Uuid d23de78e-12d8-4e37-95c6-1061610640b4) service to localhost/127.0.0.1:39762 trying to claim ACTIVE state with txid=1
2020-12-03 07:23:42,526 [BP-1192165426-172.17.0.8-1606980210852 heartbeating to localhost/127.0.0.1:32986] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-1192165426-172.17.0.8-1606980210852 (Datanode Uuid 6474728c-8e98-4f1d-a1f7-e54d7a9024e5) service to localhost/127.0.0.1:32986 trying to claim ACTIVE state with txid=1
2020-12-03 07:23:42,526 [BP-1192165426-172.17.0.8-1606980210852 heartbeating to localhost/127.0.0.1:32986] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-1192165426-172.17.0.8-1606980210852 (Datanode Uuid d23de78e-12d8-4e37-95c6-1061610640b4) service to localhost/127.0.0.1:32986 trying to claim ACTIVE state with txid=1
2020-12-03 07:23:42,526 [BP-1199477258-172.17.0.8-1606980214994 heartbeating to localhost/127.0.0.1:39762] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-1199477258-172.17.0.8-1606980214994 (Datanode Uuid d23de78e-12d8-4e37-95c6-1061610640b4) service to localhost/127.0.0.1:39762
2020-12-03 07:23:42,531 [BP-1199477258-172.17.0.8-1606980214994 heartbeating to localhost/127.0.0.1:39762] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-1199477258-172.17.0.8-1606980214994 (Datanode Uuid 6474728c-8e98-4f1d-a1f7-e54d7a9024e5) service to localhost/127.0.0.1:39762 trying to claim ACTIVE state with txid=1
2020-12-03 07:23:42,527 [BP-1199477258-172.17.0.8-1606980214994 heartbeating to localhost/127.0.0.1:39762] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-1199477258-172.17.0.8-1606980214994 (Datanode Uuid 50567619-bc66-4185-aad7-ed7a22a9939e) service to localhost/127.0.0.1:39762 trying to claim ACTIVE state with txid=1
2020-12-03 07:23:42,527 [BP-1192165426-172.17.0.8-1606980210852 heartbeating to localhost/127.0.0.1:32986] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-1192165426-172.17.0.8-1606980210852 (Datanode Uuid d23de78e-12d8-4e37-95c6-1061610640b4) service to localhost/127.0.0.1:32986
2020-12-03 07:23:42,527 [BP-1192165426-172.17.0.8-1606980210852 heartbeating to localhost/127.0.0.1:32986] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-1192165426-172.17.0.8-1606980210852 (Datanode Uuid 50567619-bc66-4185-aad7-ed7a22a9939e) service to localhost/127.0.0.1:32986 trying to claim ACTIVE state with txid=1
2020-12-03 07:23:42,527 [BP-1192165426-172.17.0.8-1606980210852 heartbeating to localhost/127.0.0.1:32986] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-1192165426-172.17.0.8-1606980210852 (Datanode Uuid 6474728c-8e98-4f1d-a1f7-e54d7a9024e5) service to localhost/127.0.0.1:32986
2020-12-03 07:23:42,532 [BP-1192165426-172.17.0.8-1606980210852 heartbeating to localhost/127.0.0.1:32986] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-1192165426-172.17.0.8-1606980210852 (Datanode Uuid 50567619-bc66-4185-aad7-ed7a22a9939e) service to localhost/127.0.0.1:32986
2020-12-03 07:23:42,531 [BP-1199477258-172.17.0.8-1606980214994 heartbeating to localhost/127.0.0.1:39762] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-1199477258-172.17.0.8-1606980214994 (Datanode Uuid 50567619-bc66-4185-aad7-ed7a22a9939e) service to localhost/127.0.0.1:39762
2020-12-03 07:23:42,531 [BP-1199477258-172.17.0.8-1606980214994 heartbeating to localhost/127.0.0.1:39762] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-1199477258-172.17.0.8-1606980214994 (Datanode Uuid 6474728c-8e98-4f1d-a1f7-e54d7a9024e5) service to localhost/127.0.0.1:39762
2020-12-03 07:23:42,672 [BP-1192165426-172.17.0.8-1606980210852 heartbeating to localhost/127.0.0.1:32986] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-1192165426-172.17.0.8-1606980210852 (Datanode Uuid e1a5f8c8-f07f-476b-9f72-5bd254411763) service to localhost/127.0.0.1:32986 trying to claim ACTIVE state with txid=1
2020-12-03 07:23:42,673 [BP-1192165426-172.17.0.8-1606980210852 heartbeating to localhost/127.0.0.1:32986] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-1192165426-172.17.0.8-1606980210852 (Datanode Uuid e1a5f8c8-f07f-476b-9f72-5bd254411763) service to localhost/127.0.0.1:32986
2020-12-03 07:23:42,692 [BP-1199477258-172.17.0.8-1606980214994 heartbeating to localhost/127.0.0.1:39762] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-1199477258-172.17.0.8-1606980214994 (Datanode Uuid e1a5f8c8-f07f-476b-9f72-5bd254411763) service to localhost/127.0.0.1:39762 trying to claim ACTIVE state with txid=1
2020-12-03 07:23:42,692 [BP-1199477258-172.17.0.8-1606980214994 heartbeating to localhost/127.0.0.1:39762] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-1199477258-172.17.0.8-1606980214994 (Datanode Uuid e1a5f8c8-f07f-476b-9f72-5bd254411763) service to localhost/127.0.0.1:39762
Dec 03, 2020 7:23:43 AM com.sun.jersey.spi.inject.Errors processErrorMessages
WARNING: The following warnings have been detected with resource and/or provider classes:
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.putRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.PutOpParam,org.apache.hadoop.hdfs.web.resources.DestinationParam,org.apache.hadoop.hdfs.web.resources.OwnerParam,org.apache.hadoop.hdfs.web.resources.GroupParam,org.apache.hadoop.hdfs.web.resources.PermissionParam,org.apache.hadoop.hdfs.web.resources.UnmaskedPermissionParam,org.apache.hadoop.hdfs.web.resources.OverwriteParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,org.apache.hadoop.hdfs.web.resources.ReplicationParam,org.apache.hadoop.hdfs.web.resources.BlockSizeParam,org.apache.hadoop.hdfs.web.resources.ModificationTimeParam,org.apache.hadoop.hdfs.web.resources.AccessTimeParam,org.apache.hadoop.hdfs.web.resources.RenameOptionSetParam,org.apache.hadoop.hdfs.web.resources.CreateParentParam,org.apache.hadoop.hdfs.web.resources.TokenArgumentParam,org.apache.hadoop.hdfs.web.resources.AclPermissionParam,org.apache.hadoop.hdfs.web.resources.XAttrNameParam,org.apache.hadoop.hdfs.web.resources.XAttrValueParam,org.apache.hadoop.hdfs.web.resources.XAttrSetFlagParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam,org.apache.hadoop.hdfs.web.resources.OldSnapshotNameParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.CreateFlagParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam,org.apache.hadoop.hdfs.web.resources.StoragePolicyParam,org.apache.hadoop.hdfs.web.resources.ECPolicyParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.postRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.PostOpParam,org.apache.hadoop.hdfs.web.resources.ConcatSourcesParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.NewLengthParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.deleteRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.DeleteOpParam,org.apache.hadoop.hdfs.web.resources.RecursiveParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.getRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.GetOpParam,org.apache.hadoop.hdfs.web.resources.OffsetParam,org.apache.hadoop.hdfs.web.resources.LengthParam,org.apache.hadoop.hdfs.web.resources.RenewerParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,java.util.List,org.apache.hadoop.hdfs.web.resources.XAttrEncodingParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.FsActionParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam,org.apache.hadoop.hdfs.web.resources.OldSnapshotNameParam,org.apache.hadoop.hdfs.web.resources.TokenKindParam,org.apache.hadoop.hdfs.web.resources.TokenServiceParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam,org.apache.hadoop.hdfs.web.resources.StartAfterParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
2020-12-03 07:23:43,251 [IPC Server handler 0 on default port 32986] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
Dec 03, 2020 7:23:43 AM com.sun.jersey.api.core.PackagesResourceConfig init
INFO: Scanning for root resource and provider classes in the packages:
  org.apache.hadoop.hdfs.server.namenode.web.resources
  org.apache.hadoop.hdfs.web.resources
Dec 03, 2020 7:23:44 AM com.sun.jersey.api.core.ScanningResourceConfig logClasses
INFO: Root resource classes found:
  class org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods
Dec 03, 2020 7:23:44 AM com.sun.jersey.api.core.ScanningResourceConfig logClasses
INFO: Provider classes found:
  class org.apache.hadoop.hdfs.web.resources.ExceptionHandler
  class org.apache.hadoop.hdfs.web.resources.UserProvider
Dec 03, 2020 7:23:44 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
Dec 03, 2020 7:23:44 AM com.sun.jersey.spi.inject.Errors processErrorMessages
WARNING: The following warnings have been detected with resource and/or provider classes:
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.putRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.PutOpParam,org.apache.hadoop.hdfs.web.resources.DestinationParam,org.apache.hadoop.hdfs.web.resources.OwnerParam,org.apache.hadoop.hdfs.web.resources.GroupParam,org.apache.hadoop.hdfs.web.resources.PermissionParam,org.apache.hadoop.hdfs.web.resources.UnmaskedPermissionParam,org.apache.hadoop.hdfs.web.resources.OverwriteParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,org.apache.hadoop.hdfs.web.resources.ReplicationParam,org.apache.hadoop.hdfs.web.resources.BlockSizeParam,org.apache.hadoop.hdfs.web.resources.ModificationTimeParam,org.apache.hadoop.hdfs.web.resources.AccessTimeParam,org.apache.hadoop.hdfs.web.resources.RenameOptionSetParam,org.apache.hadoop.hdfs.web.resources.CreateParentParam,org.apache.hadoop.hdfs.web.resources.TokenArgumentParam,org.apache.hadoop.hdfs.web.resources.AclPermissionParam,org.apache.hadoop.hdfs.web.resources.XAttrNameParam,org.apache.hadoop.hdfs.web.resources.XAttrValueParam,org.apache.hadoop.hdfs.web.resources.XAttrSetFlagParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam,org.apache.hadoop.hdfs.web.resources.OldSnapshotNameParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.CreateFlagParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam,org.apache.hadoop.hdfs.web.resources.StoragePolicyParam,org.apache.hadoop.hdfs.web.resources.ECPolicyParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.postRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.PostOpParam,org.apache.hadoop.hdfs.web.resources.ConcatSourcesParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.NewLengthParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.deleteRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.DeleteOpParam,org.apache.hadoop.hdfs.web.resources.RecursiveParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.getRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.GetOpParam,org.apache.hadoop.hdfs.web.resources.OffsetParam,org.apache.hadoop.hdfs.web.resources.LengthParam,org.apache.hadoop.hdfs.web.resources.RenewerParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,java.util.List,org.apache.hadoop.hdfs.web.resources.XAttrEncodingParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.FsActionParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam,org.apache.hadoop.hdfs.web.resources.OldSnapshotNameParam,org.apache.hadoop.hdfs.web.resources.TokenKindParam,org.apache.hadoop.hdfs.web.resources.TokenServiceParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam,org.apache.hadoop.hdfs.web.resources.StartAfterParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
2020-12-03 07:23:45,026 [IPC Server handler 8 on default port 32986] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/test/seekfile.txt	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:23:45,057 [nioEventLoopGroup-7-1] INFO  datanode.webhdfs (WebHdfsHandler.java:run(147)) - 127.0.0.1 PUT /webhdfs/v1/test/seekfile.txt?op=CREATE&user.name=root&namenoderpcaddress=1c04ae08cdfc:43798&blocksize=134217728&buffersize=4096&createflag=&createparent=true&overwrite=true&permission=644&replication=3&unmaskedpermission=666 201
2020-12-03 07:23:45,079 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-12-03 07:23:45,103 [IPC Server handler 4 on default port 32986] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:41280, 127.0.0.1:33459, 127.0.0.1:43860 for /test/seekfile.txt
2020-12-03 07:23:45,108 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 1c04ae08cdfc:43798: State Store unavailable
2020-12-03 07:23:45,121 [Thread-492] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:45,125 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-12-03 07:23:45,148 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 1c04ae08cdfc:33397: State Store unavailable
2020-12-03 07:23:45,153 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-12-03 07:23:45,188 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 1c04ae08cdfc:46601: State Store unavailable
2020-12-03 07:23:45,196 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-12-03 07:23:45,220 [DataXceiver for client DFSClient_NONMAPREDUCE_-1831045193_699 at /127.0.0.1:57062 [Receiving block BP-1192165426-172.17.0.8-1606980210852:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1192165426-172.17.0.8-1606980210852:blk_1073741825_1001 src: /127.0.0.1:57062 dest: /127.0.0.1:41280
2020-12-03 07:23:45,253 [DataXceiver for client DFSClient_NONMAPREDUCE_-1831045193_699 at /127.0.0.1:57062 [Receiving block BP-1192165426-172.17.0.8-1606980210852:blk_1073741825_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:45,257 [DataXceiver for client DFSClient_NONMAPREDUCE_-1831045193_699 at /127.0.0.1:35596 [Receiving block BP-1192165426-172.17.0.8-1606980210852:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1192165426-172.17.0.8-1606980210852:blk_1073741825_1001 src: /127.0.0.1:35596 dest: /127.0.0.1:33459
2020-12-03 07:23:45,259 [DataXceiver for client DFSClient_NONMAPREDUCE_-1831045193_699 at /127.0.0.1:35596 [Receiving block BP-1192165426-172.17.0.8-1606980210852:blk_1073741825_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:45,261 [DataXceiver for client DFSClient_NONMAPREDUCE_-1831045193_699 at /127.0.0.1:42276 [Receiving block BP-1192165426-172.17.0.8-1606980210852:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1192165426-172.17.0.8-1606980210852:blk_1073741825_1001 src: /127.0.0.1:42276 dest: /127.0.0.1:43860
2020-12-03 07:23:45,296 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 1c04ae08cdfc:45719: State Store unavailable
2020-12-03 07:23:45,300 [PacketResponder: BP-1192165426-172.17.0.8-1606980210852:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:42276, dest: /127.0.0.1:43860, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1831045193_699, offset: 0, srvID: 6474728c-8e98-4f1d-a1f7-e54d7a9024e5, blockid: BP-1192165426-172.17.0.8-1606980210852:blk_1073741825_1001, duration(ns): 21377867
2020-12-03 07:23:45,300 [PacketResponder: BP-1192165426-172.17.0.8-1606980210852:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1192165426-172.17.0.8-1606980210852:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:23:45,324 [PacketResponder: BP-1192165426-172.17.0.8-1606980210852:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43860]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:35596, dest: /127.0.0.1:33459, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1831045193_699, offset: 0, srvID: e1a5f8c8-f07f-476b-9f72-5bd254411763, blockid: BP-1192165426-172.17.0.8-1606980210852:blk_1073741825_1001, duration(ns): 33118825
2020-12-03 07:23:45,326 [PacketResponder: BP-1192165426-172.17.0.8-1606980210852:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43860]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1192165426-172.17.0.8-1606980210852:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43860] terminating
2020-12-03 07:23:45,345 [PacketResponder: BP-1192165426-172.17.0.8-1606980210852:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:33459, 127.0.0.1:43860]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57062, dest: /127.0.0.1:41280, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1831045193_699, offset: 0, srvID: 50567619-bc66-4185-aad7-ed7a22a9939e, blockid: BP-1192165426-172.17.0.8-1606980210852:blk_1073741825_1001, duration(ns): 52553059
2020-12-03 07:23:45,346 [PacketResponder: BP-1192165426-172.17.0.8-1606980210852:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:33459, 127.0.0.1:43860]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1192165426-172.17.0.8-1606980210852:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:33459, 127.0.0.1:43860] terminating
2020-12-03 07:23:45,376 [IPC Server handler 3 on default port 32986] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /test/seekfile.txt is closed by DFSClient_NONMAPREDUCE_-1831045193_699
2020-12-03 07:23:45,412 [IPC Server handler 6 on default port 32986] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/test/zero.txt	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:23:45,415 [nioEventLoopGroup-9-1] INFO  datanode.webhdfs (WebHdfsHandler.java:run(147)) - 127.0.0.1 PUT /webhdfs/v1/test/zero.txt?op=CREATE&user.name=root&namenoderpcaddress=1c04ae08cdfc:43798&blocksize=134217728&buffersize=4096&createflag=&createparent=true&overwrite=true&permission=644&replication=3&unmaskedpermission=666 201
2020-12-03 07:23:45,419 [IPC Server handler 8 on default port 32986] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /test/zero.txt is closed by DFSClient_NONMAPREDUCE_-18726292_893
2020-12-03 07:23:45,422 [Thread-488] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - basic seek operations
2020-12-03 07:23:45,446 [IPC Server handler 4 on default port 32986] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:45,455 [IPC Server handler 8 on default port 39762] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:45,461 [IPC Server handler 0 on default port 32986] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/seekfile.txt	dst=null	perm=null	proto=rpc
2020-12-03 07:23:45,470 [IPC Server handler 9 on default port 32986] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/test/seekfile.txt	dst=null	perm=null	proto=rpc
2020-12-03 07:23:45,489 [IPC Server handler 1 on default port 32986] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/test/seekfile.txt	dst=null	perm=null	proto=rpc
2020-12-03 07:23:45,536 [nioEventLoopGroup-7-2] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:45,571 [nioEventLoopGroup-7-2] INFO  datanode.webhdfs (WebHdfsHandler.java:run(147)) - 127.0.0.1 GET /webhdfs/v1/test/seekfile.txt?op=OPEN&user.name=root&namenoderpcaddress=1c04ae08cdfc:43798&buffersize=4096&offset=0 200
2020-12-03 07:23:45,582 [IPC Server handler 6 on default port 32986] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/test/seekfile.txt	dst=null	perm=null	proto=rpc
2020-12-03 07:23:45,587 [nioEventLoopGroup-7-3] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:45,593 [nioEventLoopGroup-7-3] INFO  datanode.webhdfs (WebHdfsHandler.java:run(147)) - 127.0.0.1 GET /webhdfs/v1/test/seekfile.txt?op=OPEN&user.name=root&namenoderpcaddress=1c04ae08cdfc:43798&buffersize=4096&offset=128 200
2020-12-03 07:23:45,600 [IPC Server handler 4 on default port 32986] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/test/seekfile.txt	dst=null	perm=null	proto=rpc
2020-12-03 07:23:45,606 [nioEventLoopGroup-7-4] INFO  datanode.webhdfs (WebHdfsHandler.java:run(147)) - 127.0.0.1 GET /webhdfs/v1/test/seekfile.txt?op=OPEN&user.name=root&namenoderpcaddress=1c04ae08cdfc:43798&buffersize=4096&offset=63 200
2020-12-03 07:23:45,615 [IPC Server handler 0 on default port 32986] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test	dst=null	perm=null	proto=rpc
2020-12-03 07:23:45,653 [IPC Server handler 9 on default port 32986] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/test	dst=null	perm=null	proto=rpc
2020-12-03 07:23:45,659 [Listener at 0.0.0.0/43063] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:23:45,659 [Listener at 0.0.0.0/43063] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 3
2020-12-03 07:23:45,660 [Listener at 0.0.0.0/43063] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:23:45,660 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@488b50ec] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:45,662 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, DS-707a6798-cced-414e-becf-df59de1fd486) exiting.
2020-12-03 07:23:45,662 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, DS-78e24e72-4b84-4d28-a4dd-af91ad349ab5) exiting.
2020-12-03 07:23:45,666 [BP-1192165426-172.17.0.8-1606980210852 heartbeating to localhost/127.0.0.1:42813] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1192165426-172.17.0.8-1606980210852 (Datanode Uuid e1a5f8c8-f07f-476b-9f72-5bd254411763) service to localhost/127.0.0.1:42813
2020-12-03 07:23:45,669 [BP-1192165426-172.17.0.8-1606980210852 heartbeating to localhost/127.0.0.1:32986] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1192165426-172.17.0.8-1606980210852 (Datanode Uuid e1a5f8c8-f07f-476b-9f72-5bd254411763) service to localhost/127.0.0.1:32986
2020-12-03 07:23:45,670 [BP-1192165426-172.17.0.8-1606980210852 heartbeating to localhost/127.0.0.1:32986] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1192165426-172.17.0.8-1606980210852 (Datanode Uuid e1a5f8c8-f07f-476b-9f72-5bd254411763)
2020-12-03 07:23:45,670 [BP-1192165426-172.17.0.8-1606980210852 heartbeating to localhost/127.0.0.1:32986] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1192165426-172.17.0.8-1606980210852
2020-12-03 07:23:45,673 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-1192165426-172.17.0.8-1606980210852] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:45,673 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-1192165426-172.17.0.8-1606980210852] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:45,685 [BP-1199477258-172.17.0.8-1606980214994 heartbeating to localhost/127.0.0.1:39762] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1199477258-172.17.0.8-1606980214994 (Datanode Uuid e1a5f8c8-f07f-476b-9f72-5bd254411763) service to localhost/127.0.0.1:39762
2020-12-03 07:23:45,687 [BP-1199477258-172.17.0.8-1606980214994 heartbeating to localhost/127.0.0.1:40028] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1199477258-172.17.0.8-1606980214994 (Datanode Uuid e1a5f8c8-f07f-476b-9f72-5bd254411763) service to localhost/127.0.0.1:40028
2020-12-03 07:23:45,687 [Listener at 0.0.0.0/43063] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1440c311{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:45,687 [BP-1199477258-172.17.0.8-1606980214994 heartbeating to localhost/127.0.0.1:40028] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1199477258-172.17.0.8-1606980214994 (Datanode Uuid e1a5f8c8-f07f-476b-9f72-5bd254411763)
2020-12-03 07:23:45,688 [BP-1199477258-172.17.0.8-1606980214994 heartbeating to localhost/127.0.0.1:40028] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1199477258-172.17.0.8-1606980214994
2020-12-03 07:23:45,688 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-1199477258-172.17.0.8-1606980214994] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:45,688 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-1199477258-172.17.0.8-1606980214994] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:45,692 [Listener at 0.0.0.0/43063] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@189b5fb1{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:45,693 [Listener at 0.0.0.0/43063] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5e3a39cd{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:23:45,693 [Listener at 0.0.0.0/43063] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6d2d99fc{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:23:45,696 [Listener at 0.0.0.0/43063] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 37926
2020-12-03 07:23:45,707 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:45,707 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:45,712 [Listener at 0.0.0.0/43063] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:23:45,712 [Listener at 0.0.0.0/43063] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:23:45,713 [Listener at 0.0.0.0/43063] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:23:45,713 [Listener at 0.0.0.0/43063] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:23:45,716 [Listener at 0.0.0.0/43063] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:45,716 [Listener at 0.0.0.0/43063] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 2
2020-12-03 07:23:45,717 [Listener at 0.0.0.0/43063] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:23:45,717 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@cda0432] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:45,717 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, DS-191698f0-bb42-4b8c-af23-5c0b24e998b3) exiting.
2020-12-03 07:23:45,719 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, DS-d66a95d5-e758-44e2-aeb8-ddd60f895dee) exiting.
2020-12-03 07:23:45,782 [Listener at 0.0.0.0/43063] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5d39f2d8{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:45,783 [Listener at 0.0.0.0/43063] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6ad6fa53{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:45,784 [Listener at 0.0.0.0/43063] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@25d958c6{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:23:45,784 [Listener at 0.0.0.0/43063] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@baf1bb3{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:23:45,785 [Listener at 0.0.0.0/43063] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 37605
2020-12-03 07:23:45,793 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:45,802 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:45,805 [BP-1192165426-172.17.0.8-1606980210852 heartbeating to localhost/127.0.0.1:42813] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:45,806 [BP-1192165426-172.17.0.8-1606980210852 heartbeating to localhost/127.0.0.1:42813] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1192165426-172.17.0.8-1606980210852 (Datanode Uuid 6474728c-8e98-4f1d-a1f7-e54d7a9024e5) service to localhost/127.0.0.1:42813
2020-12-03 07:23:45,806 [BP-1192165426-172.17.0.8-1606980210852 heartbeating to localhost/127.0.0.1:32986] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:45,806 [BP-1199477258-172.17.0.8-1606980214994 heartbeating to localhost/127.0.0.1:39762] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:45,806 [BP-1199477258-172.17.0.8-1606980214994 heartbeating to localhost/127.0.0.1:40028] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:45,814 [BP-1199477258-172.17.0.8-1606980214994 heartbeating to localhost/127.0.0.1:39762] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1199477258-172.17.0.8-1606980214994 (Datanode Uuid 6474728c-8e98-4f1d-a1f7-e54d7a9024e5) service to localhost/127.0.0.1:39762
2020-12-03 07:23:45,814 [BP-1192165426-172.17.0.8-1606980210852 heartbeating to localhost/127.0.0.1:32986] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1192165426-172.17.0.8-1606980210852 (Datanode Uuid 6474728c-8e98-4f1d-a1f7-e54d7a9024e5) service to localhost/127.0.0.1:32986
2020-12-03 07:23:45,814 [BP-1199477258-172.17.0.8-1606980214994 heartbeating to localhost/127.0.0.1:40028] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1199477258-172.17.0.8-1606980214994 (Datanode Uuid 6474728c-8e98-4f1d-a1f7-e54d7a9024e5) service to localhost/127.0.0.1:40028
2020-12-03 07:23:45,814 [BP-1192165426-172.17.0.8-1606980210852 heartbeating to localhost/127.0.0.1:32986] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1192165426-172.17.0.8-1606980210852 (Datanode Uuid 6474728c-8e98-4f1d-a1f7-e54d7a9024e5)
2020-12-03 07:23:45,815 [BP-1199477258-172.17.0.8-1606980214994 heartbeating to localhost/127.0.0.1:40028] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1199477258-172.17.0.8-1606980214994 (Datanode Uuid 6474728c-8e98-4f1d-a1f7-e54d7a9024e5)
2020-12-03 07:23:45,815 [BP-1192165426-172.17.0.8-1606980210852 heartbeating to localhost/127.0.0.1:32986] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1192165426-172.17.0.8-1606980210852
2020-12-03 07:23:45,816 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-1192165426-172.17.0.8-1606980210852] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:45,816 [BP-1199477258-172.17.0.8-1606980214994 heartbeating to localhost/127.0.0.1:40028] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1199477258-172.17.0.8-1606980214994
2020-12-03 07:23:45,816 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-1192165426-172.17.0.8-1606980210852] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:45,826 [Listener at 0.0.0.0/43063] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:23:45,826 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-1199477258-172.17.0.8-1606980214994] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:45,826 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-1199477258-172.17.0.8-1606980214994] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:45,826 [Listener at 0.0.0.0/43063] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:23:45,828 [Listener at 0.0.0.0/43063] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:23:45,828 [Listener at 0.0.0.0/43063] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:23:45,832 [Listener at 0.0.0.0/43063] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:45,832 [Listener at 0.0.0.0/43063] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 1
2020-12-03 07:23:45,835 [Listener at 0.0.0.0/43063] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:23:45,835 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@6a74d228] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:45,836 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, DS-ed4e0c39-1e32-430e-b11d-10ea474dda16) exiting.
2020-12-03 07:23:45,836 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, DS-92e3d219-e1a4-4f3f-97a2-fca243ee2c69) exiting.
2020-12-03 07:23:45,867 [Listener at 0.0.0.0/43063] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6a84bc2a{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:45,868 [Listener at 0.0.0.0/43063] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@5183d589{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:45,868 [Listener at 0.0.0.0/43063] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@35c09b94{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:23:45,868 [Listener at 0.0.0.0/43063] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6ac97b84{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:23:45,869 [Listener at 0.0.0.0/43063] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 39821
2020-12-03 07:23:45,878 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:45,878 [BP-1192165426-172.17.0.8-1606980210852 heartbeating to localhost/127.0.0.1:32986] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:45,879 [BP-1192165426-172.17.0.8-1606980210852 heartbeating to localhost/127.0.0.1:32986] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1192165426-172.17.0.8-1606980210852 (Datanode Uuid 50567619-bc66-4185-aad7-ed7a22a9939e) service to localhost/127.0.0.1:32986
2020-12-03 07:23:45,878 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:45,878 [BP-1192165426-172.17.0.8-1606980210852 heartbeating to localhost/127.0.0.1:42813] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:45,878 [BP-1199477258-172.17.0.8-1606980214994 heartbeating to localhost/127.0.0.1:40028] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:45,882 [BP-1199477258-172.17.0.8-1606980214994 heartbeating to localhost/127.0.0.1:40028] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1199477258-172.17.0.8-1606980214994 (Datanode Uuid 50567619-bc66-4185-aad7-ed7a22a9939e) service to localhost/127.0.0.1:40028
2020-12-03 07:23:45,878 [BP-1199477258-172.17.0.8-1606980214994 heartbeating to localhost/127.0.0.1:39762] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:45,882 [BP-1192165426-172.17.0.8-1606980210852 heartbeating to localhost/127.0.0.1:42813] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1192165426-172.17.0.8-1606980210852 (Datanode Uuid 50567619-bc66-4185-aad7-ed7a22a9939e) service to localhost/127.0.0.1:42813
2020-12-03 07:23:45,883 [BP-1199477258-172.17.0.8-1606980214994 heartbeating to localhost/127.0.0.1:39762] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1199477258-172.17.0.8-1606980214994 (Datanode Uuid 50567619-bc66-4185-aad7-ed7a22a9939e) service to localhost/127.0.0.1:39762
2020-12-03 07:23:45,883 [BP-1192165426-172.17.0.8-1606980210852 heartbeating to localhost/127.0.0.1:42813] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1192165426-172.17.0.8-1606980210852 (Datanode Uuid 50567619-bc66-4185-aad7-ed7a22a9939e)
2020-12-03 07:23:45,883 [BP-1192165426-172.17.0.8-1606980210852 heartbeating to localhost/127.0.0.1:42813] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1192165426-172.17.0.8-1606980210852
2020-12-03 07:23:45,883 [BP-1199477258-172.17.0.8-1606980214994 heartbeating to localhost/127.0.0.1:39762] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1199477258-172.17.0.8-1606980214994 (Datanode Uuid 50567619-bc66-4185-aad7-ed7a22a9939e)
2020-12-03 07:23:45,884 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-1192165426-172.17.0.8-1606980210852] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:45,885 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-1192165426-172.17.0.8-1606980210852] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:45,888 [BP-1199477258-172.17.0.8-1606980214994 heartbeating to localhost/127.0.0.1:39762] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1199477258-172.17.0.8-1606980214994
2020-12-03 07:23:45,895 [Listener at 0.0.0.0/43063] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:23:45,895 [Listener at 0.0.0.0/43063] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:23:45,896 [Listener at 0.0.0.0/43063] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:23:45,897 [Listener at 0.0.0.0/43063] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:23:45,897 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-1199477258-172.17.0.8-1606980214994] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:45,897 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-1199477258-172.17.0.8-1606980214994] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:45,901 [Listener at 0.0.0.0/43063] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:45,901 [Listener at 0.0.0.0/43063] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:23:45,901 [Listener at 0.0.0.0/43063] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:23:45,902 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@273c947f] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:45,904 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, DS-d252d603-5c4f-4562-918f-2c3750f127c8) exiting.
2020-12-03 07:23:45,904 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, DS-2c8d6396-1620-4cc7-8cb0-a097b414b982) exiting.
2020-12-03 07:23:45,918 [IPC Server handler 8 on default port 42813] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:45,919 [IPC Server handler 6 on default port 42813] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:45,919 [IPC Server handler 7 on default port 40028] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:45,919 [IPC Server handler 8 on default port 40028] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:45,920 [IPC Server handler 0 on default port 42813] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:45,921 [IPC Server handler 4 on default port 42813] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:45,921 [IPC Server handler 1 on default port 40028] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:45,922 [IPC Server handler 6 on default port 40028] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:45,922 [IPC Server handler 2 on default port 32986] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:45,923 [IPC Server handler 6 on default port 32986] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:45,923 [IPC Server handler 9 on default port 39762] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:45,926 [IPC Server handler 8 on default port 32986] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:45,927 [IPC Server handler 4 on default port 32986] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:45,927 [IPC Server handler 2 on default port 39762] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:45,928 [IPC Server handler 2 on default port 39762] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:45,930 [Listener at 0.0.0.0/43063] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@38600b{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:45,931 [Listener at 0.0.0.0/43063] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@669d2b1b{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:45,931 [IPC Server handler 8 on default port 39762] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:45,932 [Listener at 0.0.0.0/43063] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@22175d4f{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:23:45,932 [Listener at 0.0.0.0/43063] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2472c7d8{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:23:45,968 [Listener at 0.0.0.0/43063] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 34886
2020-12-03 07:23:45,977 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:45,981 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:45,998 [BP-1192165426-172.17.0.8-1606980210852 heartbeating to localhost/127.0.0.1:32986] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:45,998 [BP-1192165426-172.17.0.8-1606980210852 heartbeating to localhost/127.0.0.1:32986] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1192165426-172.17.0.8-1606980210852 (Datanode Uuid d23de78e-12d8-4e37-95c6-1061610640b4) service to localhost/127.0.0.1:32986
2020-12-03 07:23:45,999 [BP-1192165426-172.17.0.8-1606980210852 heartbeating to localhost/127.0.0.1:42813] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:45,999 [BP-1192165426-172.17.0.8-1606980210852 heartbeating to localhost/127.0.0.1:42813] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1192165426-172.17.0.8-1606980210852 (Datanode Uuid d23de78e-12d8-4e37-95c6-1061610640b4) service to localhost/127.0.0.1:42813
2020-12-03 07:23:45,999 [BP-1192165426-172.17.0.8-1606980210852 heartbeating to localhost/127.0.0.1:42813] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1192165426-172.17.0.8-1606980210852 (Datanode Uuid d23de78e-12d8-4e37-95c6-1061610640b4)
2020-12-03 07:23:45,999 [BP-1192165426-172.17.0.8-1606980210852 heartbeating to localhost/127.0.0.1:42813] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1192165426-172.17.0.8-1606980210852
2020-12-03 07:23:46,000 [BP-1199477258-172.17.0.8-1606980214994 heartbeating to localhost/127.0.0.1:40028] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:46,000 [BP-1199477258-172.17.0.8-1606980214994 heartbeating to localhost/127.0.0.1:39762] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:46,000 [BP-1199477258-172.17.0.8-1606980214994 heartbeating to localhost/127.0.0.1:40028] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1199477258-172.17.0.8-1606980214994 (Datanode Uuid d23de78e-12d8-4e37-95c6-1061610640b4) service to localhost/127.0.0.1:40028
2020-12-03 07:23:46,000 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-1192165426-172.17.0.8-1606980210852] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:46,000 [BP-1199477258-172.17.0.8-1606980214994 heartbeating to localhost/127.0.0.1:39762] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1199477258-172.17.0.8-1606980214994 (Datanode Uuid d23de78e-12d8-4e37-95c6-1061610640b4) service to localhost/127.0.0.1:39762
2020-12-03 07:23:46,001 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-1192165426-172.17.0.8-1606980210852] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:46,001 [BP-1199477258-172.17.0.8-1606980214994 heartbeating to localhost/127.0.0.1:39762] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1199477258-172.17.0.8-1606980214994 (Datanode Uuid d23de78e-12d8-4e37-95c6-1061610640b4)
2020-12-03 07:23:46,002 [BP-1199477258-172.17.0.8-1606980214994 heartbeating to localhost/127.0.0.1:39762] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1199477258-172.17.0.8-1606980214994
2020-12-03 07:23:46,003 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-1199477258-172.17.0.8-1606980214994] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:46,003 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-1199477258-172.17.0.8-1606980214994] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:46,018 [Listener at 0.0.0.0/43063] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:23:46,019 [Listener at 0.0.0.0/43063] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:23:46,021 [Listener at 0.0.0.0/43063] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:23:46,022 [Listener at 0.0.0.0/43063] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:23:46,031 [Listener at 0.0.0.0/43063] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:46,032 [Listener at 0.0.0.0/43063] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:23:46,032 [Listener at 0.0.0.0/43063] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:46,033 [Listener at 0.0.0.0/43063] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 1, 10
2020-12-03 07:23:46,033 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@4b1a43d8] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:23:46,034 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@67d86804] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:23:46,034 [Listener at 0.0.0.0/43063] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 11 Total time for transactions(ms): 36 Number of transactions batched in Syncs: 0 Number of syncs: 12 SyncTimes(ms): 3 2 3 
2020-12-03 07:23:46,036 [Listener at 0.0.0.0/43063] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-0-through-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-0-through-1/current/edits_0000000000000000001-0000000000000000011
2020-12-03 07:23:46,037 [Listener at 0.0.0.0/43063] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000011
2020-12-03 07:23:46,038 [Listener at 0.0.0.0/43063] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000011
2020-12-03 07:23:46,038 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:23:46,038 [CacheReplicationMonitor(172064044)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:23:46,039 [Listener at 0.0.0.0/43063] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 32986
2020-12-03 07:23:46,042 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:46,043 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:46,048 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:23:46,048 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:23:46,127 [NamenodeHeartbeatService ns0 nn0-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:getNamenodeStatusReport(293)) - Cannot fetch HA status for ns0-nn0:127.0.0.1:32986: End of File Exception between local host is: "1c04ae08cdfc/172.17.0.8"; destination host is: "localhost":32986; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
java.io.EOFException: End of File Exception between local host is: "1c04ae08cdfc/172.17.0.8"; destination host is: "localhost":32986; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:791)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
	at com.sun.proxy.$Proxy34.getServiceStatus(Unknown Source)
	at org.apache.hadoop.ha.protocolPB.HAServiceProtocolClientSideTranslatorPB.getServiceStatus(HAServiceProtocolClientSideTranslatorPB.java:136)
	at org.apache.hadoop.hdfs.server.federation.router.NamenodeHeartbeatService.getNamenodeStatusReport(NamenodeHeartbeatService.java:285)
	at org.apache.hadoop.hdfs.server.federation.router.NamenodeHeartbeatService.updateState(NamenodeHeartbeatService.java:205)
	at org.apache.hadoop.hdfs.server.federation.router.NamenodeHeartbeatService.periodicInvoke(NamenodeHeartbeatService.java:159)
	at org.apache.hadoop.hdfs.server.federation.router.PeriodicService$1.run(PeriodicService.java:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
2020-12-03 07:23:46,150 [Listener at 0.0.0.0/43063] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:46,151 [Listener at 0.0.0.0/43063] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:23:46,155 [Listener at 0.0.0.0/43063] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@71529963{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:23:46,158 [Listener at 0.0.0.0/43063] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@41d426b5{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:46,158 [Listener at 0.0.0.0/43063] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@27216cd{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:23:46,158 [Listener at 0.0.0.0/43063] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@78d6692f{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:23:46,172 [Listener at 0.0.0.0/43063] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:23:46,173 [Listener at 0.0.0.0/43063] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:23:46,173 [Edit log tailer] WARN  ha.EditLogTailer (EditLogTailer.java:doWork(528)) - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.sleep(EditLogTailer.java:433)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:526)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:440)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:457)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:484)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:453)
2020-12-03 07:23:46,174 [Listener at 0.0.0.0/43063] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 42813
2020-12-03 07:23:46,178 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:46,181 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:23:46,182 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:23:46,183 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:46,194 [Listener at 0.0.0.0/43063] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:46,194 [Listener at 0.0.0.0/43063] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:23:46,199 [Listener at 0.0.0.0/43063] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@70e0accd{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:23:46,202 [Listener at 0.0.0.0/43063] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7957dc72{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:46,202 [Listener at 0.0.0.0/43063] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1a15b789{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:23:46,202 [Listener at 0.0.0.0/43063] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@69adf72c{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:23:46,207 [Listener at 0.0.0.0/43063] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:23:46,207 [Listener at 0.0.0.0/43063] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:46,207 [Listener at 0.0.0.0/43063] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 1, 1
2020-12-03 07:23:46,207 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@6d469831] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:23:46,207 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@74db12c2] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:23:46,245 [Listener at 0.0.0.0/43063] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 2 Total time for transactions(ms): 11 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 31 2 4 
2020-12-03 07:23:46,246 [Listener at 0.0.0.0/43063] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-2-through-3/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-2-through-3/current/edits_0000000000000000001-0000000000000000002
2020-12-03 07:23:46,317 [Listener at 0.0.0.0/43063] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/current/edits_0000000000000000001-0000000000000000002
2020-12-03 07:23:46,318 [Listener at 0.0.0.0/43063] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6/current/edits_0000000000000000001-0000000000000000002
2020-12-03 07:23:46,318 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:23:46,318 [CacheReplicationMonitor(1897241247)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:23:46,318 [Listener at 0.0.0.0/43063] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 39762
2020-12-03 07:23:46,322 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:46,322 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:46,324 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:23:46,324 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:23:46,333 [Listener at 0.0.0.0/43063] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:46,333 [Listener at 0.0.0.0/43063] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:23:46,335 [Listener at 0.0.0.0/43063] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@22db8f4{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:23:46,337 [Listener at 0.0.0.0/43063] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2b46a8c1{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:46,337 [Listener at 0.0.0.0/43063] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5305c37d{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:23:46,338 [Listener at 0.0.0.0/43063] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@f5c79a6{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:23:46,342 [Listener at 0.0.0.0/43063] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:23:46,342 [Listener at 0.0.0.0/43063] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:23:46,342 [Edit log tailer] WARN  ha.EditLogTailer (EditLogTailer.java:doWork(528)) - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.sleep(EditLogTailer.java:433)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:526)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:440)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:457)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:484)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:453)
2020-12-03 07:23:46,343 [Listener at 0.0.0.0/43063] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 40028
2020-12-03 07:23:46,346 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:46,346 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:46,348 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:23:46,348 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:23:46,357 [Listener at 0.0.0.0/43063] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:46,358 [Listener at 0.0.0.0/43063] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:23:46,362 [Listener at 0.0.0.0/43063] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@3c321bdb{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:23:46,373 [Listener at 0.0.0.0/43063] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@24855019{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:46,374 [Listener at 0.0.0.0/43063] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@50b8ae8d{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:23:46,374 [Listener at 0.0.0.0/43063] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3228d990{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:23:46,400 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 1c04ae08cdfc:43798: State Store unavailable
2020-12-03 07:23:46,409 [Thread-508] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - RouterHeartbeatService is shutting down
2020-12-03 07:23:46,411 [Thread-508] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service RouterHeartbeatService
2020-12-03 07:23:46,415 [Thread-508] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn1 is shutting down
2020-12-03 07:23:46,415 [Thread-508] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn1
2020-12-03 07:23:46,429 [Thread-508] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn1 is shutting down
2020-12-03 07:23:46,429 [Thread-508] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn1
2020-12-03 07:23:46,434 [Thread-508] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn0 is shutting down
2020-12-03 07:23:46,434 [Thread-508] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn0
2020-12-03 07:23:46,438 [Thread-508] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn0 is shutting down
2020-12-03 07:23:46,438 [Thread-508] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn0
2020-12-03 07:23:46,447 [Thread-508] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@68f32020{/,null,UNAVAILABLE}{/router}
2020-12-03 07:23:46,450 [Thread-508] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@409986fe{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2020-12-03 07:23:46,453 [Thread-508] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@504e1599{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:46,455 [Thread-508] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@f446158{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:23:46,462 [Thread-508] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 38326
2020-12-03 07:23:46,465 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:46,467 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:46,473 [Thread-508] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 43798
2020-12-03 07:23:46,476 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:46,485 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:46,493 [Thread-508] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreCacheUpdateService is shutting down
2020-12-03 07:23:46,493 [Thread-508] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreCacheUpdateService
2020-12-03 07:23:46,497 [Thread-508] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreConnectionMonitorService is shutting down
2020-12-03 07:23:46,497 [Thread-508] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreConnectionMonitorService
2020-12-03 07:23:47,151 [NamenodeHeartbeatService ns0 nn0-0] INFO  ipc.Client (Client.java:handleConnectionFailure(958)) - Retrying connect to server: localhost/127.0.0.1:32986. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=1, sleepTime=1000 MILLISECONDS)
2020-12-03 07:23:47,153 [NamenodeHeartbeatService ns0 nn0-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:getNamenodeStatusReport(293)) - Cannot fetch HA status for ns0-nn0:127.0.0.1:32986: Call From 1c04ae08cdfc/172.17.0.8 to localhost:32986 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
java.net.ConnectException: Call From 1c04ae08cdfc/172.17.0.8 to localhost:32986 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:757)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
	at com.sun.proxy.$Proxy34.getServiceStatus(Unknown Source)
	at org.apache.hadoop.ha.protocolPB.HAServiceProtocolClientSideTranslatorPB.getServiceStatus(HAServiceProtocolClientSideTranslatorPB.java:136)
	at org.apache.hadoop.hdfs.server.federation.router.NamenodeHeartbeatService.getNamenodeStatusReport(NamenodeHeartbeatService.java:285)
	at org.apache.hadoop.hdfs.server.federation.router.NamenodeHeartbeatService.updateState(NamenodeHeartbeatService.java:205)
	at org.apache.hadoop.hdfs.server.federation.router.NamenodeHeartbeatService.periodicInvoke(NamenodeHeartbeatService.java:159)
	at org.apache.hadoop.hdfs.server.federation.router.PeriodicService$1.run(PeriodicService.java:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:533)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:804)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:421)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1606)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	... 16 more
2020-12-03 07:23:47,156 [NamenodeHeartbeatService ns0 nn0-0] WARN  ipc.Client (Client.java:handleConnectionFailure(948)) - Interrupted while trying for connection
2020-12-03 07:23:47,158 [NamenodeHeartbeatService ns0 nn0-0] WARN  net.NetUtils (NetUtils.java:wrapWithMessage(836)) - Unable to wrap exception of type class java.nio.channels.ClosedByInterruptException: it has no (String) constructor
java.lang.NoSuchMethodException: java.nio.channels.ClosedByInterruptException.<init>(java.lang.String)
	at java.lang.Class.getConstructor0(Class.java:3082)
	at java.lang.Class.getConstructor(Class.java:1825)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:832)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:808)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
	at com.sun.proxy.$Proxy34.getServiceStatus(Unknown Source)
	at org.apache.hadoop.ha.protocolPB.HAServiceProtocolClientSideTranslatorPB.getServiceStatus(HAServiceProtocolClientSideTranslatorPB.java:136)
	at org.apache.hadoop.hdfs.server.federation.router.NamenodeHeartbeatService.getNamenodeStatusReport(NamenodeHeartbeatService.java:285)
	at org.apache.hadoop.hdfs.server.federation.router.NamenodeHeartbeatService.updateState(NamenodeHeartbeatService.java:205)
	at org.apache.hadoop.hdfs.server.federation.router.NamenodeHeartbeatService.periodicInvoke(NamenodeHeartbeatService.java:159)
	at org.apache.hadoop.hdfs.server.federation.router.PeriodicService$1.run(PeriodicService.java:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:23:47,158 [NamenodeHeartbeatService ns0 nn0-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:getNamenodeStatusReport(293)) - Cannot fetch HA status for ns0-nn0:127.0.0.1:32986: Failed on local exception: java.nio.channels.ClosedByInterruptException; Host Details : local host is: "1c04ae08cdfc/172.17.0.8"; destination host is: "localhost":32986; 
java.io.IOException: Failed on local exception: java.nio.channels.ClosedByInterruptException; Host Details : local host is: "1c04ae08cdfc/172.17.0.8"; destination host is: "localhost":32986; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:818)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
	at com.sun.proxy.$Proxy34.getServiceStatus(Unknown Source)
	at org.apache.hadoop.ha.protocolPB.HAServiceProtocolClientSideTranslatorPB.getServiceStatus(HAServiceProtocolClientSideTranslatorPB.java:136)
	at org.apache.hadoop.hdfs.server.federation.router.NamenodeHeartbeatService.getNamenodeStatusReport(NamenodeHeartbeatService.java:285)
	at org.apache.hadoop.hdfs.server.federation.router.NamenodeHeartbeatService.updateState(NamenodeHeartbeatService.java:205)
	at org.apache.hadoop.hdfs.server.federation.router.NamenodeHeartbeatService.periodicInvoke(NamenodeHeartbeatService.java:159)
	at org.apache.hadoop.hdfs.server.federation.router.PeriodicService$1.run(PeriodicService.java:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.nio.channels.ClosedByInterruptException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:202)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:656)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:533)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:804)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:421)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1606)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	... 16 more
2020-12-03 07:23:47,407 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 1c04ae08cdfc:33397: State Store unavailable
2020-12-03 07:23:47,415 [Thread-512] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - RouterHeartbeatService is shutting down
2020-12-03 07:23:47,415 [Thread-512] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service RouterHeartbeatService
2020-12-03 07:23:47,419 [Thread-512] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn1 is shutting down
2020-12-03 07:23:47,419 [Thread-512] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn1
2020-12-03 07:23:47,429 [Thread-512] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn1 is shutting down
2020-12-03 07:23:47,429 [Thread-512] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn1
2020-12-03 07:23:47,438 [Thread-512] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn0 is shutting down
2020-12-03 07:23:47,438 [Thread-512] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn0
2020-12-03 07:23:47,440 [Thread-512] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn0 is shutting down
2020-12-03 07:23:47,440 [Thread-512] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn0
2020-12-03 07:23:47,442 [NamenodeHeartbeatService ns0 nn0-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:getNamenodeStatusReport(293)) - Cannot fetch HA status for ns0-nn0:127.0.0.1:32986: DestHost:destPort localhost:32986 , LocalHost:localPort 1c04ae08cdfc/172.17.0.8:0. Failed on local exception: java.io.InterruptedIOException: Interrupted: action=RetryAction(action=RETRY, delayMillis=1000, reason=retries get failed due to exceeded maximum allowed retries number: 1), retry policy=RetryUpToMaximumCountWithFixedSleep(maxRetries=1, sleepTime=1000 MILLISECONDS)
java.io.InterruptedIOException: DestHost:destPort localhost:32986 , LocalHost:localPort 1c04ae08cdfc/172.17.0.8:0. Failed on local exception: java.io.InterruptedIOException: Interrupted: action=RetryAction(action=RETRY, delayMillis=1000, reason=retries get failed due to exceeded maximum allowed retries number: 1), retry policy=RetryUpToMaximumCountWithFixedSleep(maxRetries=1, sleepTime=1000 MILLISECONDS)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:808)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
	at com.sun.proxy.$Proxy34.getServiceStatus(Unknown Source)
	at org.apache.hadoop.ha.protocolPB.HAServiceProtocolClientSideTranslatorPB.getServiceStatus(HAServiceProtocolClientSideTranslatorPB.java:136)
	at org.apache.hadoop.hdfs.server.federation.router.NamenodeHeartbeatService.getNamenodeStatusReport(NamenodeHeartbeatService.java:285)
	at org.apache.hadoop.hdfs.server.federation.router.NamenodeHeartbeatService.updateState(NamenodeHeartbeatService.java:205)
	at org.apache.hadoop.hdfs.server.federation.router.NamenodeHeartbeatService.periodicInvoke(NamenodeHeartbeatService.java:159)
	at org.apache.hadoop.hdfs.server.federation.router.PeriodicService$1.run(PeriodicService.java:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.InterruptedIOException: Interrupted: action=RetryAction(action=RETRY, delayMillis=1000, reason=retries get failed due to exceeded maximum allowed retries number: 1), retry policy=RetryUpToMaximumCountWithFixedSleep(maxRetries=1, sleepTime=1000 MILLISECONDS)
	at org.apache.hadoop.ipc.Client$Connection.handleConnectionFailure(Client.java:955)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:716)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:804)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:421)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1606)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	... 16 more
Caused by: java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.ipc.Client$Connection.handleConnectionFailure(Client.java:953)
	... 21 more
2020-12-03 07:23:47,447 [Thread-512] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@43a51d00{/,null,UNAVAILABLE}{/router}
2020-12-03 07:23:47,448 [Thread-512] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2e23c180{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2020-12-03 07:23:47,450 [Thread-512] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@34fe326d{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:47,452 [Thread-512] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7dff6d05{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:23:47,455 [Thread-512] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 37989
2020-12-03 07:23:47,457 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:47,459 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:47,461 [Thread-512] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 33397
2020-12-03 07:23:47,465 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:47,465 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:47,474 [Thread-512] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping Router metrics system...
2020-12-03 07:23:47,478 [Thread-512] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - Router metrics system stopped.
2020-12-03 07:23:47,481 [Thread-512] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - Router metrics system shutdown complete.
2020-12-03 07:23:47,484 [Thread-512] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreCacheUpdateService is shutting down
2020-12-03 07:23:47,484 [Thread-512] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreCacheUpdateService
2020-12-03 07:23:47,486 [Thread-512] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreConnectionMonitorService is shutting down
2020-12-03 07:23:47,486 [Thread-512] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreConnectionMonitorService
2020-12-03 07:23:48,396 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 1c04ae08cdfc:46601: State Store unavailable
2020-12-03 07:23:48,397 [Thread-513] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - RouterHeartbeatService is shutting down
2020-12-03 07:23:48,397 [Thread-513] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service RouterHeartbeatService
2020-12-03 07:23:48,398 [Thread-513] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn1 is shutting down
2020-12-03 07:23:48,398 [Thread-513] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn1
2020-12-03 07:23:48,398 [Thread-513] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn1 is shutting down
2020-12-03 07:23:48,398 [Thread-513] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn1
2020-12-03 07:23:48,399 [Thread-513] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn0 is shutting down
2020-12-03 07:23:48,399 [Thread-513] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn0
2020-12-03 07:23:48,399 [Thread-513] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn0 is shutting down
2020-12-03 07:23:48,399 [Thread-513] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn0
2020-12-03 07:23:48,401 [Thread-513] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6ea04618{/,null,UNAVAILABLE}{/router}
2020-12-03 07:23:48,402 [Thread-513] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6dd82486{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2020-12-03 07:23:48,403 [Thread-513] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@74aa9c72{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:48,403 [Thread-513] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5ff90645{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:23:48,404 [Thread-513] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 45005
2020-12-03 07:23:48,405 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:48,406 [Thread-513] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 46601
2020-12-03 07:23:48,405 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:48,407 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:48,407 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:48,407 [Thread-513] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreCacheUpdateService is shutting down
2020-12-03 07:23:48,408 [Thread-513] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreCacheUpdateService
2020-12-03 07:23:48,408 [Thread-513] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreConnectionMonitorService is shutting down
2020-12-03 07:23:48,408 [Thread-513] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreConnectionMonitorService
2020-12-03 07:23:49,397 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 1c04ae08cdfc:45719: State Store unavailable
2020-12-03 07:23:49,397 [Thread-514] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - RouterHeartbeatService is shutting down
2020-12-03 07:23:49,397 [Thread-514] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service RouterHeartbeatService
2020-12-03 07:23:49,398 [Thread-514] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn1 is shutting down
2020-12-03 07:23:49,398 [Thread-514] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn1
2020-12-03 07:23:49,398 [Thread-514] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn0 is shutting down
2020-12-03 07:23:49,398 [Thread-514] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn0
2020-12-03 07:23:49,399 [Thread-514] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn1 is shutting down
2020-12-03 07:23:49,399 [Thread-514] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn1
2020-12-03 07:23:49,399 [Thread-514] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn0 is shutting down
2020-12-03 07:23:49,399 [Thread-514] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn0
2020-12-03 07:23:49,401 [Thread-514] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@86733{/,null,UNAVAILABLE}{/router}
2020-12-03 07:23:49,402 [Thread-514] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@186cb891{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2020-12-03 07:23:49,402 [Thread-514] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@62891fc8{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:49,403 [Thread-514] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@39c1fe0b{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:23:49,404 [Thread-514] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 43063
2020-12-03 07:23:49,404 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:49,405 [Thread-514] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 45719
2020-12-03 07:23:49,405 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:49,406 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:49,406 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:49,407 [Thread-514] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreCacheUpdateService is shutting down
2020-12-03 07:23:49,407 [Thread-514] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreCacheUpdateService
2020-12-03 07:23:49,407 [Thread-514] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreConnectionMonitorService is shutting down
2020-12-03 07:23:49,408 [Thread-514] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreConnectionMonitorService
msx-rc 0
