2020-12-03 07:20:12,063 [Thread-0] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=9
Formatting using clusterid: testClusterID
2020-12-03 07:20:13,071 [Thread-0] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:20:13,093 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:20:13,095 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:20:13,095 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:20:13,105 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:20:13,106 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:20:13,106 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:20:13,107 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:20:13,184 [Thread-0] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:13,191 [Thread-0] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2020-12-03 07:20:13,192 [Thread-0] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:20:13,192 [Thread-0] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:20:13,198 [Thread-0] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:20:13,199 [Thread-0] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:20:13
2020-12-03 07:20:13,202 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:20:13,204 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:13,207 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-12-03 07:20:13,208 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:20:13,234 [Thread-0] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:20:13,234 [Thread-0] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:20:13,242 [Thread-0] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:20:13,242 [Thread-0] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:20:13,242 [Thread-0] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:20:13,243 [Thread-0] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:20:13,243 [Thread-0] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:20:13,244 [Thread-0] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:20:13,244 [Thread-0] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:20:13,244 [Thread-0] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:20:13,244 [Thread-0] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:20:13,244 [Thread-0] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:20:13,245 [Thread-0] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:20:13,279 [Thread-0] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GLOBAL serial map: bits=29 maxEntries=536870911
2020-12-03 07:20:13,280 [Thread-0] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - USER serial map: bits=24 maxEntries=16777215
2020-12-03 07:20:13,280 [Thread-0] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GROUP serial map: bits=24 maxEntries=16777215
2020-12-03 07:20:13,280 [Thread-0] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - XATTR serial map: bits=24 maxEntries=16777215
2020-12-03 07:20:13,298 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:20:13,298 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:13,299 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-12-03 07:20:13,299 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:20:13,307 [Thread-0] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:20:13,308 [Thread-0] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:20:13,308 [Thread-0] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:20:13,309 [Thread-0] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:20:13,317 [Thread-0] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:20:13,321 [Thread-0] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:20:13,326 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:20:13,327 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:13,327 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-12-03 07:20:13,327 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:20:13,336 [Thread-0] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:20:13,337 [Thread-0] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:20:13,337 [Thread-0] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:20:13,343 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:20:13,343 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:20:13,346 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:20:13,346 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:13,347 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-12-03 07:20:13,348 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:20:13,410 [Thread-0] INFO  namenode.FSImage (FSImage.java:format(185)) - Allocated new BlockPoolId: BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:13,555 [Thread-0] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-12-03 07:20:13,628 [Thread-0] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-12-03 07:20:13,670 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:20:13,670 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:20:13,839 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 396 bytes saved in 0 seconds .
2020-12-03 07:20:13,840 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 396 bytes saved in 0 seconds .
2020-12-03 07:20:14,316 [Thread-0] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-12-03 07:20:14,319 [Thread-0] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:20:14,460 [Thread-0] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:20:14,894 [Thread-0] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:20:14,894 [Thread-0] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:20:14,929 [Thread-0] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-12-03 07:20:14,983 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@16614318] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:15,006 [Thread-0] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:20:15,012 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:15,032 [Thread-0] INFO  util.log (Log.java:initialized(192)) - Logging initialized @4320ms
2020-12-03 07:20:15,182 [Thread-0] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:15,186 [Thread-0] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:20:15,186 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:15,197 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:15,199 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:20:15,199 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:15,200 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:15,242 [Thread-0] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:20:15,242 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:20:15,253 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 33418
2020-12-03 07:20:15,255 [Thread-0] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:15,311 [Thread-0] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@50797eb1{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:15,313 [Thread-0] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@331ba624{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:15,360 [Thread-0] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@2adcde7{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:20:15,371 [Thread-0] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@18548501{HTTP/1.1,[http/1.1]}{localhost:33418}
2020-12-03 07:20:15,371 [Thread-0] INFO  server.Server (Server.java:doStart(419)) - Started @4660ms
2020-12-03 07:20:15,386 [Thread-0] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:20:15,387 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:20:15,387 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:20:15,387 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:20:15,388 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:20:15,388 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:20:15,388 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:20:15,389 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:20:15,389 [Thread-0] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:15,390 [Thread-0] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:20:15,390 [Thread-0] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:20:15,390 [Thread-0] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:20:15,391 [Thread-0] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:20:15
2020-12-03 07:20:15,391 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:20:15,391 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:15,392 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:20:15,392 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:20:15,402 [Thread-0] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:20:15,403 [Thread-0] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:20:15,403 [Thread-0] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:20:15,404 [Thread-0] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:20:15,404 [Thread-0] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:20:15,404 [Thread-0] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:20:15,405 [Thread-0] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:20:15,405 [Thread-0] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:20:15,405 [Thread-0] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:20:15,406 [Thread-0] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:20:15,406 [Thread-0] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:20:15,406 [Thread-0] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:20:15,407 [Thread-0] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:20:15,407 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:20:15,408 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:15,408 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:20:15,409 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:20:15,411 [Thread-0] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:20:15,411 [Thread-0] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:20:15,412 [Thread-0] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:20:15,412 [Thread-0] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:20:15,412 [Thread-0] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:20:15,412 [Thread-0] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:20:15,413 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:20:15,413 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:15,414 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:20:15,414 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:20:15,415 [Thread-0] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:20:15,415 [Thread-0] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:20:15,416 [Thread-0] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:20:15,416 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:20:15,416 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:20:15,416 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:20:15,417 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:15,417 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:20:15,418 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:20:15,472 [Thread-0] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 900@9c826977c5c0
2020-12-03 07:20:15,522 [Thread-0] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 900@9c826977c5c0
2020-12-03 07:20:15,527 [Thread-0] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-12-03 07:20:15,527 [Thread-0] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-12-03 07:20:15,528 [Thread-0] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:20:15,528 [Thread-0] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:20:15,571 [Thread-0] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:20:15,581 [Thread-0] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:20:15,582 [Thread-0] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-12-03 07:20:15,589 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:20:15,590 [Thread-0] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 1
2020-12-03 07:20:15,759 [Thread-0] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:20:15,760 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 339 msecs
2020-12-03 07:20:15,967 [Thread-0] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:20:16,032 [Thread-0] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:16,059 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:16,448 [Listener at localhost/44233] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:44233 to access this namenode/service.
2020-12-03 07:20:16,458 [Listener at localhost/44233] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:20:16,479 [Listener at localhost/44233] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:20:16,504 [Listener at localhost/44233] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:20:16,505 [Listener at localhost/44233] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:20:16,505 [Listener at localhost/44233] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:20:16,505 [Listener at localhost/44233] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:20:16,510 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 0
2020-12-03 07:20:16,511 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:20:16,511 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:20:16,511 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:20:16,512 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:20:16,512 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 7 msec
2020-12-03 07:20:16,560 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:16,560 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:16,565 [Listener at localhost/44233] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:44233
2020-12-03 07:20:16,570 [Listener at localhost/44233] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:20:16,570 [Listener at localhost/44233] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:20:16,579 [Listener at localhost/44233] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 8 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:20:16,585 [CacheReplicationMonitor(1045112527)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:20:16,596 [Listener at localhost/44233] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:20:16,687 [Listener at localhost/44233] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:20:16,710 [Listener at localhost/44233] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:20:16,745 [Listener at localhost/44233] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:16,752 [Listener at localhost/44233] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:16,756 [Listener at localhost/44233] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:16,762 [Listener at localhost/44233] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:16,763 [Listener at localhost/44233] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:16,770 [Listener at localhost/44233] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:16,779 [Listener at localhost/44233] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:37359
2020-12-03 07:20:16,781 [Listener at localhost/44233] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:16,781 [Listener at localhost/44233] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:16,809 [Listener at localhost/44233] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:16,811 [Listener at localhost/44233] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:16,811 [Listener at localhost/44233] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:16,812 [Listener at localhost/44233] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:16,818 [Listener at localhost/44233] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:16,820 [Listener at localhost/44233] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:16,820 [Listener at localhost/44233] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:16,820 [Listener at localhost/44233] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:16,827 [Listener at localhost/44233] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 45135
2020-12-03 07:20:16,828 [Listener at localhost/44233] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:16,830 [Listener at localhost/44233] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5abf2073{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:16,832 [Listener at localhost/44233] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7ffc1570{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:16,844 [Listener at localhost/44233] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@29e41834{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:20:16,846 [Listener at localhost/44233] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7fb7c1ea{HTTP/1.1,[http/1.1]}{localhost:45135}
2020-12-03 07:20:16,846 [Listener at localhost/44233] INFO  server.Server (Server.java:doStart(419)) - Started @6135ms
2020-12-03 07:20:17,221 [Listener at localhost/44233] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:38706
2020-12-03 07:20:17,222 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7ad850dd] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:17,223 [Listener at localhost/44233] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:17,223 [Listener at localhost/44233] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:17,545 [Listener at localhost/44233] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:17,547 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:17,576 [Listener at localhost/40783] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:40783
2020-12-03 07:20:17,622 [Listener at localhost/40783] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:20:17,624 [Listener at localhost/40783] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:20:17,636 [Thread-60] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44233 starting to offer service
2020-12-03 07:20:17,644 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:17,645 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:17,661 [Listener at localhost/40783] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:20:17,664 [Listener at localhost/40783] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:20:17,665 [Listener at localhost/40783] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:20:17,669 [Listener at localhost/40783] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:17,670 [Listener at localhost/40783] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:17,670 [Listener at localhost/40783] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:17,672 [Listener at localhost/40783] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:17,672 [Listener at localhost/40783] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:17,673 [Listener at localhost/40783] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:17,675 [Listener at localhost/40783] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:38140
2020-12-03 07:20:17,675 [Listener at localhost/40783] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:17,675 [Listener at localhost/40783] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:17,678 [Listener at localhost/40783] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:17,682 [Listener at localhost/40783] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:17,683 [Listener at localhost/40783] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:17,684 [Listener at localhost/40783] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:17,687 [Listener at localhost/40783] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:17,689 [Listener at localhost/40783] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:17,689 [Listener at localhost/40783] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:17,690 [Listener at localhost/40783] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:17,692 [Listener at localhost/40783] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 34147
2020-12-03 07:20:17,694 [Listener at localhost/40783] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:17,697 [Listener at localhost/40783] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@25caa7ef{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:17,698 [Listener at localhost/40783] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@11b29b7c{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:17,707 [Listener at localhost/40783] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3be9e39c{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:20:17,709 [Listener at localhost/40783] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@52333402{HTTP/1.1,[http/1.1]}{localhost:34147}
2020-12-03 07:20:17,709 [Listener at localhost/40783] INFO  server.Server (Server.java:doStart(419)) - Started @6998ms
2020-12-03 07:20:17,806 [Listener at localhost/40783] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:39750
2020-12-03 07:20:17,807 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@95e97c2] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:17,807 [Listener at localhost/40783] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:17,807 [Listener at localhost/40783] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:17,824 [Listener at localhost/40783] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:17,825 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:17,833 [Listener at localhost/39371] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:39371
2020-12-03 07:20:17,841 [Listener at localhost/39371] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:20:17,842 [Listener at localhost/39371] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:20:17,843 [Thread-84] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44233 starting to offer service
2020-12-03 07:20:17,852 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:17,852 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:17,856 [Listener at localhost/39371] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:20:17,859 [Listener at localhost/39371] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:20:17,860 [Listener at localhost/39371] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:20:17,862 [Listener at localhost/39371] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:17,863 [Listener at localhost/39371] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:17,864 [Listener at localhost/39371] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:17,864 [Listener at localhost/39371] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:17,865 [Listener at localhost/39371] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:17,865 [Listener at localhost/39371] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:17,866 [Listener at localhost/39371] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:38875
2020-12-03 07:20:17,866 [Listener at localhost/39371] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:17,866 [Listener at localhost/39371] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:17,868 [Listener at localhost/39371] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:17,871 [Listener at localhost/39371] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:17,872 [Listener at localhost/39371] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:17,873 [Listener at localhost/39371] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:17,878 [Listener at localhost/39371] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:17,879 [Listener at localhost/39371] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:17,880 [Listener at localhost/39371] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:17,880 [Listener at localhost/39371] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:17,881 [Listener at localhost/39371] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 46637
2020-12-03 07:20:17,881 [Listener at localhost/39371] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:17,885 [Listener at localhost/39371] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7b0ea794{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:17,886 [Listener at localhost/39371] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@55f83456{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:17,895 [Listener at localhost/39371] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@36ecea3{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:20:17,896 [Listener at localhost/39371] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@ef806db{HTTP/1.1,[http/1.1]}{localhost:46637}
2020-12-03 07:20:17,897 [Listener at localhost/39371] INFO  server.Server (Server.java:doStart(419)) - Started @7185ms
2020-12-03 07:20:17,937 [Listener at localhost/39371] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:35718
2020-12-03 07:20:17,938 [Listener at localhost/39371] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:17,938 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5a939cf8] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:17,938 [Listener at localhost/39371] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:17,939 [Listener at localhost/39371] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:17,944 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:17,956 [Listener at localhost/38382] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:38382
2020-12-03 07:20:17,967 [Listener at localhost/38382] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:20:17,978 [Listener at localhost/38382] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:20:17,985 [Thread-106] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44233 starting to offer service
2020-12-03 07:20:17,989 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:17,989 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:18,007 [Listener at localhost/38382] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 3 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:20:18,016 [Listener at localhost/38382] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:20:18,017 [Listener at localhost/38382] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:20:18,025 [Listener at localhost/38382] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:18,026 [Listener at localhost/38382] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:18,027 [Listener at localhost/38382] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:18,030 [Listener at localhost/38382] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:18,031 [Listener at localhost/38382] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:18,031 [Listener at localhost/38382] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:18,032 [Listener at localhost/38382] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:36016
2020-12-03 07:20:18,033 [Listener at localhost/38382] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:18,033 [Listener at localhost/38382] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:18,041 [Listener at localhost/38382] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:18,044 [Listener at localhost/38382] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:18,048 [Listener at localhost/38382] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:18,049 [Listener at localhost/38382] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:18,054 [Listener at localhost/38382] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:18,055 [Listener at localhost/38382] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:18,055 [Listener at localhost/38382] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:18,056 [Listener at localhost/38382] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:18,057 [Listener at localhost/38382] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 33309
2020-12-03 07:20:18,057 [Listener at localhost/38382] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:18,061 [Listener at localhost/38382] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6bdeff70{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:18,063 [Listener at localhost/38382] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4ac9d9a2{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:18,073 [Listener at localhost/38382] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1e3a15fd{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:20:18,075 [Listener at localhost/38382] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@67908616{HTTP/1.1,[http/1.1]}{localhost:33309}
2020-12-03 07:20:18,076 [Listener at localhost/38382] INFO  server.Server (Server.java:doStart(419)) - Started @7365ms
2020-12-03 07:20:18,161 [Listener at localhost/38382] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:37163
2020-12-03 07:20:18,161 [Listener at localhost/38382] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:18,161 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4108dc1f] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:18,162 [Listener at localhost/38382] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:18,163 [Listener at localhost/38382] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:18,164 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:18,172 [Listener at localhost/32843] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:32843
2020-12-03 07:20:18,176 [Listener at localhost/32843] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:20:18,177 [Listener at localhost/32843] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:20:18,177 [Thread-128] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44233 starting to offer service
2020-12-03 07:20:18,185 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:18,185 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:18,189 [Listener at localhost/32843] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 4 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:20:18,191 [Listener at localhost/32843] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:20:18,192 [Listener at localhost/32843] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:20:18,193 [Listener at localhost/32843] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:18,193 [Listener at localhost/32843] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:18,194 [Listener at localhost/32843] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:18,194 [Listener at localhost/32843] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:18,194 [Listener at localhost/32843] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:18,195 [Listener at localhost/32843] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:18,196 [Listener at localhost/32843] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:39670
2020-12-03 07:20:18,196 [Listener at localhost/32843] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:18,196 [Listener at localhost/32843] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:18,198 [Listener at localhost/32843] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:18,199 [Listener at localhost/32843] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:18,200 [Listener at localhost/32843] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:18,200 [Listener at localhost/32843] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:18,203 [Listener at localhost/32843] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:18,204 [Listener at localhost/32843] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:18,204 [Listener at localhost/32843] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:18,204 [Listener at localhost/32843] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:18,205 [Listener at localhost/32843] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 39703
2020-12-03 07:20:18,207 [Listener at localhost/32843] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:18,210 [Listener at localhost/32843] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@de066c{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:18,211 [Listener at localhost/32843] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@384491cb{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:18,218 [Thread-128] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44233
2020-12-03 07:20:18,218 [Thread-106] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44233
2020-12-03 07:20:18,218 [Thread-60] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44233
2020-12-03 07:20:18,218 [Thread-84] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44233
2020-12-03 07:20:18,222 [Thread-106] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:18,222 [Thread-128] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:18,222 [Thread-84] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:18,222 [Thread-60] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:18,224 [Listener at localhost/32843] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5c119a66{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:20:18,226 [Listener at localhost/32843] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@103f2cb1{HTTP/1.1,[http/1.1]}{localhost:39703}
2020-12-03 07:20:18,226 [Listener at localhost/32843] INFO  server.Server (Server.java:doStart(419)) - Started @7515ms
2020-12-03 07:20:18,242 [Listener at localhost/32843] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:41886
2020-12-03 07:20:18,243 [Listener at localhost/32843] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:18,243 [Listener at localhost/32843] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:18,243 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6c639b9a] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:18,243 [Listener at localhost/32843] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:18,244 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:18,248 [Listener at localhost/33533] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:33533
2020-12-03 07:20:18,252 [Listener at localhost/33533] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:20:18,253 [Listener at localhost/33533] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:20:18,253 [Thread-150] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44233 starting to offer service
2020-12-03 07:20:18,255 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:18,256 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:18,265 [Listener at localhost/33533] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 5 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:20:18,270 [Listener at localhost/33533] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:20:18,271 [Listener at localhost/33533] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:20:18,274 [Listener at localhost/33533] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:18,274 [Listener at localhost/33533] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:18,274 [Listener at localhost/33533] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:18,275 [Listener at localhost/33533] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:18,275 [Listener at localhost/33533] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:18,279 [Thread-150] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44233
2020-12-03 07:20:18,280 [Thread-150] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:18,280 [Listener at localhost/33533] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:18,281 [Listener at localhost/33533] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:38718
2020-12-03 07:20:18,281 [Listener at localhost/33533] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:18,282 [Listener at localhost/33533] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:18,283 [Listener at localhost/33533] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:18,284 [Listener at localhost/33533] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:18,285 [Listener at localhost/33533] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:18,285 [Listener at localhost/33533] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:18,287 [Listener at localhost/33533] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:18,288 [Listener at localhost/33533] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:18,288 [Listener at localhost/33533] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:18,288 [Listener at localhost/33533] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:18,289 [Listener at localhost/33533] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 43880
2020-12-03 07:20:18,289 [Listener at localhost/33533] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:18,292 [Listener at localhost/33533] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@20489d{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:18,292 [Listener at localhost/33533] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@61e479e4{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:18,300 [Listener at localhost/33533] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@172edb72{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:20:18,301 [Listener at localhost/33533] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@f0449e6{HTTP/1.1,[http/1.1]}{localhost:43880}
2020-12-03 07:20:18,302 [Listener at localhost/33533] INFO  server.Server (Server.java:doStart(419)) - Started @7590ms
2020-12-03 07:20:18,308 [Thread-128] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/in_use.lock acquired by nodename 900@9c826977c5c0
2020-12-03 07:20:18,308 [Thread-106] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 900@9c826977c5c0
2020-12-03 07:20:18,308 [Thread-60] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 900@9c826977c5c0
2020-12-03 07:20:18,308 [Thread-84] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 900@9c826977c5c0
2020-12-03 07:20:18,311 [Thread-60] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 267665338. Formatting...
2020-12-03 07:20:18,311 [Thread-128] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 is not formatted for namespace 267665338. Formatting...
2020-12-03 07:20:18,311 [Thread-84] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 is not formatted for namespace 267665338. Formatting...
2020-12-03 07:20:18,311 [Thread-106] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 is not formatted for namespace 267665338. Formatting...
2020-12-03 07:20:18,316 [Thread-84] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-9f3a827e-e2fe-44cb-bf3f-03dbde2b0b88 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 
2020-12-03 07:20:18,317 [Thread-106] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-e0706d8b-1d48-436b-a586-041594df8014 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 
2020-12-03 07:20:18,317 [Thread-128] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-53ebb263-a519-4e04-8516-6895b2684e49 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 
2020-12-03 07:20:18,318 [Thread-60] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-9637c4ad-4b9f-4743-85c8-8b3b2981aad6 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-12-03 07:20:18,323 [Listener at localhost/33533] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:45384
2020-12-03 07:20:18,324 [Listener at localhost/33533] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:18,324 [Listener at localhost/33533] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:18,325 [Listener at localhost/33533] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:18,326 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:18,328 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6b6a8fd6] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:18,340 [Listener at localhost/33442] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:33442
2020-12-03 07:20:18,346 [Listener at localhost/33442] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:20:18,347 [Listener at localhost/33442] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:20:18,348 [Thread-172] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44233 starting to offer service
2020-12-03 07:20:18,350 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:18,350 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:18,354 [Listener at localhost/33442] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 6 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:20:18,355 [Thread-172] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44233
2020-12-03 07:20:18,356 [Thread-172] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:18,357 [Listener at localhost/33442] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:20:18,357 [Listener at localhost/33442] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:20:18,359 [Listener at localhost/33442] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:18,360 [Listener at localhost/33442] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:18,360 [Listener at localhost/33442] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:18,361 [Listener at localhost/33442] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:18,365 [Listener at localhost/33442] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:18,366 [Listener at localhost/33442] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:18,367 [Listener at localhost/33442] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:37144
2020-12-03 07:20:18,367 [Listener at localhost/33442] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:18,367 [Listener at localhost/33442] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:18,369 [Listener at localhost/33442] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:18,371 [Listener at localhost/33442] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:18,372 [Listener at localhost/33442] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:18,372 [Listener at localhost/33442] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:18,374 [Listener at localhost/33442] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:18,375 [Thread-150] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/in_use.lock acquired by nodename 900@9c826977c5c0
2020-12-03 07:20:18,375 [Listener at localhost/33442] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:18,375 [Thread-150] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 is not formatted for namespace 267665338. Formatting...
2020-12-03 07:20:18,375 [Listener at localhost/33442] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:18,375 [Listener at localhost/33442] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:18,376 [Listener at localhost/33442] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 46432
2020-12-03 07:20:18,377 [Listener at localhost/33442] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:18,377 [Thread-150] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-424ba2c6-e1c2-4264-9ece-472b5fa767aa for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 
2020-12-03 07:20:18,379 [Listener at localhost/33442] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@14de1c31{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:18,380 [Listener at localhost/33442] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@63fd3e8c{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:18,388 [Listener at localhost/33442] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3416b965{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:20:18,389 [Listener at localhost/33442] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2a7cc383{HTTP/1.1,[http/1.1]}{localhost:46432}
2020-12-03 07:20:18,390 [Listener at localhost/33442] INFO  server.Server (Server.java:doStart(419)) - Started @7678ms
2020-12-03 07:20:18,407 [Listener at localhost/33442] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:36080
2020-12-03 07:20:18,408 [Listener at localhost/33442] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:18,408 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@48aadf1f] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:18,408 [Listener at localhost/33442] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:18,408 [Listener at localhost/33442] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:18,409 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:18,413 [Listener at localhost/37376] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:37376
2020-12-03 07:20:18,417 [Listener at localhost/37376] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:20:18,418 [Listener at localhost/37376] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:20:18,419 [Thread-194] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44233 starting to offer service
2020-12-03 07:20:18,420 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:18,421 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:18,425 [Listener at localhost/37376] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 7 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:20:18,427 [Listener at localhost/37376] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:20:18,427 [Listener at localhost/37376] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:20:18,427 [Thread-194] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44233
2020-12-03 07:20:18,428 [Thread-194] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:18,428 [Listener at localhost/37376] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:18,430 [Listener at localhost/37376] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:18,430 [Listener at localhost/37376] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:18,430 [Listener at localhost/37376] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:18,431 [Listener at localhost/37376] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:18,431 [Listener at localhost/37376] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:18,432 [Listener at localhost/37376] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:40206
2020-12-03 07:20:18,432 [Listener at localhost/37376] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:18,432 [Listener at localhost/37376] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:18,434 [Listener at localhost/37376] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:18,437 [Listener at localhost/37376] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:18,438 [Listener at localhost/37376] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:18,438 [Listener at localhost/37376] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:18,439 [Thread-172] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/in_use.lock acquired by nodename 900@9c826977c5c0
2020-12-03 07:20:18,439 [Thread-172] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 is not formatted for namespace 267665338. Formatting...
2020-12-03 07:20:18,441 [Listener at localhost/37376] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:18,443 [Thread-172] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-ba213c2e-7d56-49cf-8c5f-d363ac2f32c7 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 
2020-12-03 07:20:18,443 [Listener at localhost/37376] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:18,443 [Listener at localhost/37376] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:18,443 [Listener at localhost/37376] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:18,444 [Listener at localhost/37376] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 41655
2020-12-03 07:20:18,444 [Listener at localhost/37376] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:18,449 [Listener at localhost/37376] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@d0d3c7d{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:18,450 [Listener at localhost/37376] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@23820214{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:18,459 [Listener at localhost/37376] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1e6ec59e{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:20:18,464 [Listener at localhost/37376] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@251a4318{HTTP/1.1,[http/1.1]}{localhost:41655}
2020-12-03 07:20:18,465 [Listener at localhost/37376] INFO  server.Server (Server.java:doStart(419)) - Started @7753ms
2020-12-03 07:20:18,516 [Thread-194] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/in_use.lock acquired by nodename 900@9c826977c5c0
2020-12-03 07:20:18,517 [Thread-194] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 is not formatted for namespace 267665338. Formatting...
2020-12-03 07:20:18,518 [Thread-194] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-e0b4f24e-24cd-44f5-8116-b2ae227fd08c for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 
2020-12-03 07:20:18,526 [Listener at localhost/37376] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:45942
2020-12-03 07:20:18,526 [Listener at localhost/37376] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:18,526 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@43e73481] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:18,526 [Listener at localhost/37376] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:18,527 [Listener at localhost/37376] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:18,528 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:18,538 [Listener at localhost/43625] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:43625
2020-12-03 07:20:18,544 [Listener at localhost/43625] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:20:18,544 [Listener at localhost/43625] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:20:18,545 [Thread-216] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44233 starting to offer service
2020-12-03 07:20:18,548 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:18,549 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:18,556 [Thread-216] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44233
2020-12-03 07:20:18,557 [Thread-216] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:18,558 [Listener at localhost/43625] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 8 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:20:18,559 [Listener at localhost/43625] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:20:18,560 [Listener at localhost/43625] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:20:18,561 [Listener at localhost/43625] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:18,562 [Listener at localhost/43625] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:18,562 [Listener at localhost/43625] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:18,563 [Listener at localhost/43625] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:18,563 [Listener at localhost/43625] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:18,563 [Listener at localhost/43625] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:18,564 [Listener at localhost/43625] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:43228
2020-12-03 07:20:18,565 [Listener at localhost/43625] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:18,565 [Listener at localhost/43625] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:18,566 [Listener at localhost/43625] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:18,569 [Listener at localhost/43625] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:18,569 [Listener at localhost/43625] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:18,569 [Listener at localhost/43625] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:18,572 [Listener at localhost/43625] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:18,573 [Listener at localhost/43625] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:18,573 [Listener at localhost/43625] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:18,573 [Listener at localhost/43625] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:18,574 [Listener at localhost/43625] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 44378
2020-12-03 07:20:18,574 [Listener at localhost/43625] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:18,576 [Listener at localhost/43625] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@56a6d42a{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:18,577 [Listener at localhost/43625] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@47723f65{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:18,583 [Listener at localhost/43625] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@4a1b4671{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:20:18,585 [Listener at localhost/43625] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7961de36{HTTP/1.1,[http/1.1]}{localhost:44378}
2020-12-03 07:20:18,585 [Listener at localhost/43625] INFO  server.Server (Server.java:doStart(419)) - Started @7874ms
2020-12-03 07:20:18,606 [Listener at localhost/43625] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:39224
2020-12-03 07:20:18,606 [Listener at localhost/43625] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:18,606 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@be62034] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:18,606 [Listener at localhost/43625] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:18,607 [Listener at localhost/43625] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:18,608 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:18,613 [Listener at localhost/43660] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:43660
2020-12-03 07:20:18,620 [Listener at localhost/43660] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:20:18,620 [Listener at localhost/43660] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:20:18,621 [Thread-238] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44233 starting to offer service
2020-12-03 07:20:18,624 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:18,628 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:18,632 [Thread-238] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44233
2020-12-03 07:20:18,633 [Thread-238] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:18,660 [Thread-216] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/in_use.lock acquired by nodename 900@9c826977c5c0
2020-12-03 07:20:18,660 [Thread-216] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 is not formatted for namespace 267665338. Formatting...
2020-12-03 07:20:18,662 [Thread-216] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-fafaff18-4de2-4bc2-bceb-3b8e48cbd859 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 
2020-12-03 07:20:18,748 [Thread-84] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 900@9c826977c5c0
2020-12-03 07:20:18,748 [Thread-238] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/in_use.lock acquired by nodename 900@9c826977c5c0
2020-12-03 07:20:18,748 [Thread-84] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 is not formatted for namespace 267665338. Formatting...
2020-12-03 07:20:18,748 [Thread-60] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 900@9c826977c5c0
2020-12-03 07:20:18,749 [Thread-60] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 267665338. Formatting...
2020-12-03 07:20:18,748 [Thread-128] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/in_use.lock acquired by nodename 900@9c826977c5c0
2020-12-03 07:20:18,748 [Thread-238] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 is not formatted for namespace 267665338. Formatting...
2020-12-03 07:20:18,749 [Thread-128] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 is not formatted for namespace 267665338. Formatting...
2020-12-03 07:20:18,751 [Thread-238] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-05e88003-7d71-45e9-9eec-ae795adefff3 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 
2020-12-03 07:20:18,751 [Thread-60] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-89b6f46a-278e-49c3-b219-2a6fc902ef6b for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-12-03 07:20:18,751 [Thread-128] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-604aa382-053e-4d29-ae14-d8159a125483 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 
2020-12-03 07:20:18,751 [Thread-84] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-8888774b-8a84-448b-b3e5-a3adadd0d078 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 
2020-12-03 07:20:18,752 [Thread-106] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 900@9c826977c5c0
2020-12-03 07:20:18,752 [Thread-106] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 is not formatted for namespace 267665338. Formatting...
2020-12-03 07:20:18,752 [Thread-106] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-7c7a5fb3-6845-447a-a855-e677cf9028bc for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 
2020-12-03 07:20:18,842 [Thread-150] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/in_use.lock acquired by nodename 900@9c826977c5c0
2020-12-03 07:20:18,842 [Thread-150] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 is not formatted for namespace 267665338. Formatting...
2020-12-03 07:20:18,843 [Thread-150] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-75948b37-fc93-40b9-90df-eead8d830e52 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 
2020-12-03 07:20:18,918 [Thread-172] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/in_use.lock acquired by nodename 900@9c826977c5c0
2020-12-03 07:20:18,919 [Thread-172] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 is not formatted for namespace 267665338. Formatting...
2020-12-03 07:20:18,921 [Thread-172] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-a28f0b02-f8c5-4829-be0e-08394c72924d for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 
2020-12-03 07:20:19,037 [Thread-194] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/in_use.lock acquired by nodename 900@9c826977c5c0
2020-12-03 07:20:19,038 [Thread-194] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 is not formatted for namespace 267665338. Formatting...
2020-12-03 07:20:19,038 [Thread-194] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-ec353e10-93bc-4bc7-959e-05ad0de8bd77 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 
2020-12-03 07:20:19,219 [IPC Server handler 0 on default port 44233] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:19,227 [Listener at localhost/43660] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:19,227 [Listener at localhost/43660] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:19,331 [IPC Server handler 7 on default port 44233] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:19,332 [Listener at localhost/43660] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:19,332 [Listener at localhost/43660] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:19,435 [IPC Server handler 6 on default port 44233] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:19,436 [Listener at localhost/43660] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:19,436 [Listener at localhost/43660] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:19,539 [IPC Server handler 8 on default port 44233] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:19,540 [Listener at localhost/43660] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:19,540 [Listener at localhost/43660] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:19,613 [Thread-60] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:19,613 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:19,613 [Thread-60] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:19,613 [Thread-84] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:19,614 [Thread-60] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-1199088383-172.17.0.4-1606980013387 is not formatted. Formatting ...
2020-12-03 07:20:19,614 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 and block pool id BP-1199088383-172.17.0.4-1606980013387 is not formatted. Formatting ...
2020-12-03 07:20:19,614 [Thread-128] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:19,614 [Thread-60] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1199088383-172.17.0.4-1606980013387 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1199088383-172.17.0.4-1606980013387/current
2020-12-03 07:20:19,614 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1199088383-172.17.0.4-1606980013387 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1199088383-172.17.0.4-1606980013387/current
2020-12-03 07:20:19,615 [Thread-128] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:19,615 [Thread-128] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 and block pool id BP-1199088383-172.17.0.4-1606980013387 is not formatted. Formatting ...
2020-12-03 07:20:19,615 [Thread-106] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:19,615 [Thread-128] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1199088383-172.17.0.4-1606980013387 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1199088383-172.17.0.4-1606980013387/current
2020-12-03 07:20:19,615 [Thread-106] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:19,616 [Thread-106] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 and block pool id BP-1199088383-172.17.0.4-1606980013387 is not formatted. Formatting ...
2020-12-03 07:20:19,616 [Thread-106] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1199088383-172.17.0.4-1606980013387 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1199088383-172.17.0.4-1606980013387/current
2020-12-03 07:20:19,642 [IPC Server handler 3 on default port 44233] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:19,644 [Listener at localhost/43660] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:19,644 [Listener at localhost/43660] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:19,691 [Thread-216] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/in_use.lock acquired by nodename 900@9c826977c5c0
2020-12-03 07:20:19,692 [Thread-216] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 is not formatted for namespace 267665338. Formatting...
2020-12-03 07:20:19,692 [Thread-216] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-4b096592-2cf9-441a-91b8-89f8826a3f3a for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 
2020-12-03 07:20:19,704 [Thread-150] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:19,704 [Thread-150] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:19,705 [Thread-150] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 and block pool id BP-1199088383-172.17.0.4-1606980013387 is not formatted. Formatting ...
2020-12-03 07:20:19,705 [Thread-150] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1199088383-172.17.0.4-1606980013387 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1199088383-172.17.0.4-1606980013387/current
2020-12-03 07:20:19,746 [IPC Server handler 2 on default port 44233] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:19,747 [Listener at localhost/43660] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:19,748 [Listener at localhost/43660] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:19,775 [Thread-238] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/in_use.lock acquired by nodename 900@9c826977c5c0
2020-12-03 07:20:19,776 [Thread-238] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 is not formatted for namespace 267665338. Formatting...
2020-12-03 07:20:19,778 [Thread-238] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-c1a89502-e5b9-42b4-9665-585863fffe34 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 
2020-12-03 07:20:19,784 [Thread-172] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:19,784 [Thread-172] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:19,784 [Thread-172] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 and block pool id BP-1199088383-172.17.0.4-1606980013387 is not formatted. Formatting ...
2020-12-03 07:20:19,785 [Thread-172] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1199088383-172.17.0.4-1606980013387 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1199088383-172.17.0.4-1606980013387/current
2020-12-03 07:20:19,851 [IPC Server handler 0 on default port 44233] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:19,852 [Listener at localhost/43660] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:19,852 [Listener at localhost/43660] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:19,890 [Thread-194] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:19,890 [Thread-194] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:19,891 [Thread-194] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 and block pool id BP-1199088383-172.17.0.4-1606980013387 is not formatted. Formatting ...
2020-12-03 07:20:19,891 [Thread-194] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1199088383-172.17.0.4-1606980013387 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1199088383-172.17.0.4-1606980013387/current
2020-12-03 07:20:19,954 [IPC Server handler 5 on default port 44233] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:19,955 [Listener at localhost/43660] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:19,955 [Listener at localhost/43660] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:19,992 [Thread-60] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:19,992 [Thread-60] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:19,992 [Thread-60] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-1199088383-172.17.0.4-1606980013387 is not formatted. Formatting ...
2020-12-03 07:20:19,992 [Thread-60] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1199088383-172.17.0.4-1606980013387 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1199088383-172.17.0.4-1606980013387/current
2020-12-03 07:20:19,994 [Thread-128] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:19,994 [Thread-106] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:19,994 [Thread-128] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:19,994 [Thread-106] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:19,994 [Thread-128] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 and block pool id BP-1199088383-172.17.0.4-1606980013387 is not formatted. Formatting ...
2020-12-03 07:20:19,994 [Thread-128] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1199088383-172.17.0.4-1606980013387 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1199088383-172.17.0.4-1606980013387/current
2020-12-03 07:20:19,994 [Thread-106] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 and block pool id BP-1199088383-172.17.0.4-1606980013387 is not formatted. Formatting ...
2020-12-03 07:20:19,995 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:19,995 [Thread-106] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1199088383-172.17.0.4-1606980013387 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1199088383-172.17.0.4-1606980013387/current
2020-12-03 07:20:19,995 [Thread-84] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:19,995 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 and block pool id BP-1199088383-172.17.0.4-1606980013387 is not formatted. Formatting ...
2020-12-03 07:20:19,995 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1199088383-172.17.0.4-1606980013387 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1199088383-172.17.0.4-1606980013387/current
2020-12-03 07:20:20,059 [IPC Server handler 7 on default port 44233] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:20,060 [Listener at localhost/43660] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:20,060 [Listener at localhost/43660] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:20,091 [Thread-216] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:20,092 [Thread-216] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:20,092 [Thread-216] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 and block pool id BP-1199088383-172.17.0.4-1606980013387 is not formatted. Formatting ...
2020-12-03 07:20:20,092 [Thread-216] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1199088383-172.17.0.4-1606980013387 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1199088383-172.17.0.4-1606980013387/current
2020-12-03 07:20:20,092 [Thread-150] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:20,093 [Thread-150] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:20,093 [Thread-150] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 and block pool id BP-1199088383-172.17.0.4-1606980013387 is not formatted. Formatting ...
2020-12-03 07:20:20,093 [Thread-150] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1199088383-172.17.0.4-1606980013387 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1199088383-172.17.0.4-1606980013387/current
2020-12-03 07:20:20,163 [IPC Server handler 4 on default port 44233] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:20,167 [Listener at localhost/43660] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:20,167 [Listener at localhost/43660] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:20,225 [Thread-238] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:20,225 [Thread-238] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:20,225 [Thread-238] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 and block pool id BP-1199088383-172.17.0.4-1606980013387 is not formatted. Formatting ...
2020-12-03 07:20:20,225 [Thread-238] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1199088383-172.17.0.4-1606980013387 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1199088383-172.17.0.4-1606980013387/current
2020-12-03 07:20:20,228 [Thread-172] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:20,228 [Thread-172] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:20,229 [Thread-172] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 and block pool id BP-1199088383-172.17.0.4-1606980013387 is not formatted. Formatting ...
2020-12-03 07:20:20,229 [Thread-172] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1199088383-172.17.0.4-1606980013387 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1199088383-172.17.0.4-1606980013387/current
2020-12-03 07:20:20,271 [IPC Server handler 6 on default port 44233] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:20,272 [Listener at localhost/43660] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:20,272 [Listener at localhost/43660] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:20,344 [Thread-194] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:20,344 [Thread-194] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:20,345 [Thread-194] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 and block pool id BP-1199088383-172.17.0.4-1606980013387 is not formatted. Formatting ...
2020-12-03 07:20:20,345 [Thread-194] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1199088383-172.17.0.4-1606980013387 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1199088383-172.17.0.4-1606980013387/current
2020-12-03 07:20:20,375 [IPC Server handler 8 on default port 44233] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:20,376 [Listener at localhost/43660] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:20,376 [Listener at localhost/43660] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:20,448 [Thread-84] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=267665338;bpid=BP-1199088383-172.17.0.4-1606980013387;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=267665338;c=1606980013387;bpid=BP-1199088383-172.17.0.4-1606980013387;dnuuid=null
2020-12-03 07:20:20,448 [Thread-106] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=267665338;bpid=BP-1199088383-172.17.0.4-1606980013387;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=267665338;c=1606980013387;bpid=BP-1199088383-172.17.0.4-1606980013387;dnuuid=null
2020-12-03 07:20:20,448 [Thread-128] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=267665338;bpid=BP-1199088383-172.17.0.4-1606980013387;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=267665338;c=1606980013387;bpid=BP-1199088383-172.17.0.4-1606980013387;dnuuid=null
2020-12-03 07:20:20,448 [Thread-60] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=267665338;bpid=BP-1199088383-172.17.0.4-1606980013387;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=267665338;c=1606980013387;bpid=BP-1199088383-172.17.0.4-1606980013387;dnuuid=null
2020-12-03 07:20:20,478 [IPC Server handler 9 on default port 44233] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:20,479 [Listener at localhost/43660] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:20,479 [Listener at localhost/43660] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:20,540 [Thread-150] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=267665338;bpid=BP-1199088383-172.17.0.4-1606980013387;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=267665338;c=1606980013387;bpid=BP-1199088383-172.17.0.4-1606980013387;dnuuid=null
2020-12-03 07:20:20,549 [Thread-216] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:20,550 [Thread-216] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:20,550 [Thread-216] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 and block pool id BP-1199088383-172.17.0.4-1606980013387 is not formatted. Formatting ...
2020-12-03 07:20:20,550 [Thread-216] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1199088383-172.17.0.4-1606980013387 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1199088383-172.17.0.4-1606980013387/current
2020-12-03 07:20:20,581 [IPC Server handler 1 on default port 44233] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:20,582 [Listener at localhost/43660] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:20,583 [Listener at localhost/43660] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:20,685 [IPC Server handler 2 on default port 44233] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:20,686 [Listener at localhost/43660] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:20,686 [Listener at localhost/43660] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:20,699 [Thread-172] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=267665338;bpid=BP-1199088383-172.17.0.4-1606980013387;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=267665338;c=1606980013387;bpid=BP-1199088383-172.17.0.4-1606980013387;dnuuid=null
2020-12-03 07:20:20,713 [Thread-238] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:20,714 [Thread-238] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:20,714 [Thread-238] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 and block pool id BP-1199088383-172.17.0.4-1606980013387 is not formatted. Formatting ...
2020-12-03 07:20:20,714 [Thread-238] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1199088383-172.17.0.4-1606980013387 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1199088383-172.17.0.4-1606980013387/current
2020-12-03 07:20:20,789 [IPC Server handler 0 on default port 44233] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:20,790 [Listener at localhost/43660] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:20,790 [Listener at localhost/43660] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:20,832 [Thread-194] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=267665338;bpid=BP-1199088383-172.17.0.4-1606980013387;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=267665338;c=1606980013387;bpid=BP-1199088383-172.17.0.4-1606980013387;dnuuid=null
2020-12-03 07:20:20,892 [IPC Server handler 5 on default port 44233] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:20,893 [Listener at localhost/43660] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:20,893 [Listener at localhost/43660] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:20,995 [IPC Server handler 7 on default port 44233] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:20,996 [Listener at localhost/43660] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:20,996 [Listener at localhost/43660] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:21,058 [Thread-128] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 2c0b9200-a808-454b-aeae-39910540cca5
2020-12-03 07:20:21,058 [Thread-84] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID aae714b7-affe-4899-8582-7db48868bdef
2020-12-03 07:20:21,059 [Thread-60] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 3c6cb142-24b8-4ba9-8bce-390f3aeb2056
2020-12-03 07:20:21,058 [Thread-106] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID aa46699a-faf3-419b-9673-7b32209adbf8
2020-12-03 07:20:21,098 [IPC Server handler 4 on default port 44233] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:21,099 [Listener at localhost/43660] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:21,099 [Listener at localhost/43660] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:21,247 [Thread-128] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-53ebb263-a519-4e04-8516-6895b2684e49
2020-12-03 07:20:21,248 [Thread-84] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-9f3a827e-e2fe-44cb-bf3f-03dbde2b0b88
2020-12-03 07:20:21,248 [Thread-60] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-9637c4ad-4b9f-4743-85c8-8b3b2981aad6
2020-12-03 07:20:21,249 [Thread-84] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: DISK
2020-12-03 07:20:21,249 [Thread-128] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, StorageType: DISK
2020-12-03 07:20:21,248 [Thread-106] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-e0706d8b-1d48-436b-a586-041594df8014
2020-12-03 07:20:21,250 [IPC Server handler 6 on default port 44233] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:21,250 [Thread-60] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-12-03 07:20:21,251 [Thread-106] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, StorageType: DISK
2020-12-03 07:20:21,251 [Listener at localhost/43660] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:21,251 [Listener at localhost/43660] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:21,252 [Thread-128] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-604aa382-053e-4d29-ae14-d8159a125483
2020-12-03 07:20:21,252 [Thread-128] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, StorageType: DISK
2020-12-03 07:20:21,254 [Thread-106] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-7c7a5fb3-6845-447a-a855-e677cf9028bc
2020-12-03 07:20:21,254 [Thread-106] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, StorageType: DISK
2020-12-03 07:20:21,255 [Thread-60] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-89b6f46a-278e-49c3-b219-2a6fc902ef6b
2020-12-03 07:20:21,255 [Thread-60] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-12-03 07:20:21,257 [Thread-84] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-8888774b-8a84-448b-b3e5-a3adadd0d078
2020-12-03 07:20:21,257 [Thread-84] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: DISK
2020-12-03 07:20:21,259 [Thread-128] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:21,259 [Thread-84] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:21,259 [Thread-106] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:21,259 [Thread-60] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:21,260 [Thread-150] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID ac43fde1-9305-4657-806e-9582c003dbfc
2020-12-03 07:20:21,260 [Thread-216] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=267665338;bpid=BP-1199088383-172.17.0.4-1606980013387;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=267665338;c=1606980013387;bpid=BP-1199088383-172.17.0.4-1606980013387;dnuuid=null
2020-12-03 07:20:21,265 [Thread-128] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:20:21,266 [Thread-150] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-424ba2c6-e1c2-4264-9ece-472b5fa767aa
2020-12-03 07:20:21,267 [Thread-150] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, StorageType: DISK
2020-12-03 07:20:21,268 [Thread-60] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:20:21,269 [Thread-106] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:20:21,270 [Thread-84] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:20:21,271 [Thread-150] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-75948b37-fc93-40b9-90df-eead8d830e52
2020-12-03 07:20:21,272 [Thread-150] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, StorageType: DISK
2020-12-03 07:20:21,273 [Thread-150] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:21,274 [Thread-150] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:20:21,275 [Thread-150] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:20:21,275 [Thread-106] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:20:21,275 [Thread-84] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:20:21,275 [Thread-128] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:20:21,275 [Thread-60] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:20:21,277 [Thread-128] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:20:21,277 [Thread-150] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:20:21,277 [Thread-60] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:20:21,277 [Thread-84] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:20:21,277 [Thread-106] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:20:21,278 [Thread-84] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:20:21,278 [Thread-60] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:20:21,277 [Thread-150] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:20:21,277 [Thread-128] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:20:21,280 [Thread-150] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:21,280 [Thread-84] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:21,280 [Thread-60] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:21,279 [Thread-106] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:20:21,280 [Thread-128] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:21,280 [Thread-106] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:21,280 [Thread-262] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1199088383-172.17.0.4-1606980013387 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-12-03 07:20:21,281 [Thread-265] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1199088383-172.17.0.4-1606980013387 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-12-03 07:20:21,281 [Thread-264] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1199088383-172.17.0.4-1606980013387 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:20:21,281 [Thread-268] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1199088383-172.17.0.4-1606980013387 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-12-03 07:20:21,282 [Thread-263] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1199088383-172.17.0.4-1606980013387 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:20:21,282 [Thread-266] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1199088383-172.17.0.4-1606980013387 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:20:21,283 [Thread-267] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1199088383-172.17.0.4-1606980013387 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-12-03 07:20:21,283 [Thread-269] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1199088383-172.17.0.4-1606980013387 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:20:21,283 [Thread-271] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1199088383-172.17.0.4-1606980013387 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:20:21,283 [Thread-270] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1199088383-172.17.0.4-1606980013387 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:20:21,353 [IPC Server handler 8 on default port 44233] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:21,354 [Listener at localhost/43660] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:21,354 [Listener at localhost/43660] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:21,407 [Thread-264] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1199088383-172.17.0.4-1606980013387 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 127ms
2020-12-03 07:20:21,407 [Thread-269] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1199088383-172.17.0.4-1606980013387 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 125ms
2020-12-03 07:20:21,407 [Thread-267] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1199088383-172.17.0.4-1606980013387 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 125ms
2020-12-03 07:20:21,408 [Thread-84] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1199088383-172.17.0.4-1606980013387: 128ms
2020-12-03 07:20:21,417 [Thread-282] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1199088383-172.17.0.4-1606980013387 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:20:21,417 [Thread-283] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1199088383-172.17.0.4-1606980013387 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:20:21,417 [Thread-282] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1199088383-172.17.0.4-1606980013387/current/replicas doesn't exist 
2020-12-03 07:20:21,420 [Thread-283] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1199088383-172.17.0.4-1606980013387/current/replicas doesn't exist 
2020-12-03 07:20:21,422 [Thread-283] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1199088383-172.17.0.4-1606980013387 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 3ms
2020-12-03 07:20:21,422 [Thread-282] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1199088383-172.17.0.4-1606980013387 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 5ms
2020-12-03 07:20:21,423 [Thread-84] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1199088383-172.17.0.4-1606980013387: 12ms
2020-12-03 07:20:21,425 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1199088383-172.17.0.4-1606980013387 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:20:21,425 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1199088383-172.17.0.4-1606980013387 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:20:21,427 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-9f3a827e-e2fe-44cb-bf3f-03dbde2b0b88): finished scanning block pool BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:21,427 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-8888774b-8a84-448b-b3e5-a3adadd0d078): finished scanning block pool BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:21,430 [Thread-271] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1199088383-172.17.0.4-1606980013387 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 147ms
2020-12-03 07:20:21,430 [Thread-268] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1199088383-172.17.0.4-1606980013387 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 150ms
2020-12-03 07:20:21,432 [Thread-263] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1199088383-172.17.0.4-1606980013387 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 149ms
2020-12-03 07:20:21,432 [Thread-262] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1199088383-172.17.0.4-1606980013387 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 151ms
2020-12-03 07:20:21,432 [Thread-150] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1199088383-172.17.0.4-1606980013387: 152ms
2020-12-03 07:20:21,432 [Thread-265] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1199088383-172.17.0.4-1606980013387 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 151ms
2020-12-03 07:20:21,432 [Thread-286] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1199088383-172.17.0.4-1606980013387 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-12-03 07:20:21,432 [Thread-287] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1199088383-172.17.0.4-1606980013387 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-12-03 07:20:21,432 [Thread-266] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1199088383-172.17.0.4-1606980013387 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 150ms
2020-12-03 07:20:21,433 [Thread-287] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1199088383-172.17.0.4-1606980013387/current/replicas doesn't exist 
2020-12-03 07:20:21,432 [Thread-128] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1199088383-172.17.0.4-1606980013387: 153ms
2020-12-03 07:20:21,433 [Thread-106] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1199088383-172.17.0.4-1606980013387: 152ms
2020-12-03 07:20:21,433 [Thread-286] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1199088383-172.17.0.4-1606980013387/current/replicas doesn't exist 
2020-12-03 07:20:21,433 [Thread-270] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1199088383-172.17.0.4-1606980013387 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 150ms
2020-12-03 07:20:21,433 [Thread-288] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1199088383-172.17.0.4-1606980013387 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-12-03 07:20:21,433 [Thread-60] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1199088383-172.17.0.4-1606980013387: 154ms
2020-12-03 07:20:21,433 [Thread-287] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1199088383-172.17.0.4-1606980013387 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 0ms
2020-12-03 07:20:21,434 [Thread-291] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1199088383-172.17.0.4-1606980013387 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:20:21,434 [Thread-290] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1199088383-172.17.0.4-1606980013387 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-12-03 07:20:21,434 [Thread-292] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1199088383-172.17.0.4-1606980013387 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:20:21,434 [Thread-290] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1199088383-172.17.0.4-1606980013387/current/replicas doesn't exist 
2020-12-03 07:20:21,433 [Thread-288] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1199088383-172.17.0.4-1606980013387/current/replicas doesn't exist 
2020-12-03 07:20:21,433 [Thread-286] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1199088383-172.17.0.4-1606980013387 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 1ms
2020-12-03 07:20:21,433 [Thread-289] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1199088383-172.17.0.4-1606980013387 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:20:21,435 [Thread-150] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1199088383-172.17.0.4-1606980013387: 3ms
2020-12-03 07:20:21,435 [Thread-290] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1199088383-172.17.0.4-1606980013387 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 0ms
2020-12-03 07:20:21,435 [Thread-293] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1199088383-172.17.0.4-1606980013387 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:20:21,436 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1199088383-172.17.0.4-1606980013387 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:20:21,436 [Thread-293] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1199088383-172.17.0.4-1606980013387/current/replicas doesn't exist 
2020-12-03 07:20:21,435 [Thread-292] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1199088383-172.17.0.4-1606980013387/current/replicas doesn't exist 
2020-12-03 07:20:21,434 [Thread-291] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1199088383-172.17.0.4-1606980013387/current/replicas doesn't exist 
2020-12-03 07:20:21,436 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1199088383-172.17.0.4-1606980013387 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:20:21,435 [Thread-289] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1199088383-172.17.0.4-1606980013387/current/replicas doesn't exist 
2020-12-03 07:20:21,435 [Thread-288] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1199088383-172.17.0.4-1606980013387 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 1ms
2020-12-03 07:20:21,436 [Thread-291] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1199088383-172.17.0.4-1606980013387 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 2ms
2020-12-03 07:20:21,436 [Thread-128] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1199088383-172.17.0.4-1606980013387: 4ms
2020-12-03 07:20:21,436 [Thread-292] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1199088383-172.17.0.4-1606980013387 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 1ms
2020-12-03 07:20:21,436 [Thread-293] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1199088383-172.17.0.4-1606980013387 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 0ms
2020-12-03 07:20:21,436 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-424ba2c6-e1c2-4264-9ece-472b5fa767aa): finished scanning block pool BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:21,437 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1199088383-172.17.0.4-1606980013387 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:20:21,437 [Thread-60] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1199088383-172.17.0.4-1606980013387: 4ms
2020-12-03 07:20:21,436 [Thread-289] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1199088383-172.17.0.4-1606980013387 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 2ms
2020-12-03 07:20:21,436 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-75948b37-fc93-40b9-90df-eead8d830e52): finished scanning block pool BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:21,438 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-53ebb263-a519-4e04-8516-6895b2684e49): finished scanning block pool BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:21,438 [Thread-106] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1199088383-172.17.0.4-1606980013387: 5ms
2020-12-03 07:20:21,437 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1199088383-172.17.0.4-1606980013387 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:20:21,438 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1199088383-172.17.0.4-1606980013387 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:20:21,438 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1199088383-172.17.0.4-1606980013387 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:20:21,438 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1199088383-172.17.0.4-1606980013387 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:20:21,438 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-9637c4ad-4b9f-4743-85c8-8b3b2981aad6): finished scanning block pool BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:21,438 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-604aa382-053e-4d29-ae14-d8159a125483): finished scanning block pool BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:21,438 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1199088383-172.17.0.4-1606980013387 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:20:21,439 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-7c7a5fb3-6845-447a-a855-e677cf9028bc): finished scanning block pool BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:21,438 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-89b6f46a-278e-49c3-b219-2a6fc902ef6b): finished scanning block pool BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:21,439 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-e0706d8b-1d48-436b-a586-041594df8014): finished scanning block pool BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:21,456 [IPC Server handler 9 on default port 44233] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:21,457 [Listener at localhost/43660] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:21,457 [Listener at localhost/43660] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:21,472 [Thread-172] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 13dd0217-9dd1-4416-9b7c-bf07e67f055d
2020-12-03 07:20:21,472 [Thread-238] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=267665338;bpid=BP-1199088383-172.17.0.4-1606980013387;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=267665338;c=1606980013387;bpid=BP-1199088383-172.17.0.4-1606980013387;dnuuid=null
2020-12-03 07:20:21,475 [Thread-172] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-ba213c2e-7d56-49cf-8c5f-d363ac2f32c7
2020-12-03 07:20:21,476 [Thread-172] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, StorageType: DISK
2020-12-03 07:20:21,477 [Thread-172] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-a28f0b02-f8c5-4829-be0e-08394c72924d
2020-12-03 07:20:21,477 [Thread-172] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, StorageType: DISK
2020-12-03 07:20:21,478 [Thread-172] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:21,480 [Thread-172] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:20:21,481 [Thread-172] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:20:21,481 [Thread-172] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:20:21,481 [Thread-172] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:20:21,482 [Thread-172] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:21,482 [Thread-304] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1199088383-172.17.0.4-1606980013387 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11...
2020-12-03 07:20:21,482 [Thread-305] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1199088383-172.17.0.4-1606980013387 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12...
2020-12-03 07:20:21,559 [IPC Server handler 1 on default port 44233] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:21,560 [Listener at localhost/43660] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:21,560 [Listener at localhost/43660] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:21,671 [IPC Server handler 2 on default port 44233] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:21,672 [Listener at localhost/43660] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:21,672 [Listener at localhost/43660] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:21,744 [Thread-304] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1199088383-172.17.0.4-1606980013387 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11: 262ms
2020-12-03 07:20:21,744 [Thread-305] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1199088383-172.17.0.4-1606980013387 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12: 261ms
2020-12-03 07:20:21,746 [Thread-172] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1199088383-172.17.0.4-1606980013387: 264ms
2020-12-03 07:20:21,746 [Thread-308] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1199088383-172.17.0.4-1606980013387 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11...
2020-12-03 07:20:21,746 [Thread-308] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1199088383-172.17.0.4-1606980013387/current/replicas doesn't exist 
2020-12-03 07:20:21,746 [Thread-309] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1199088383-172.17.0.4-1606980013387 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12...
2020-12-03 07:20:21,747 [Thread-309] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1199088383-172.17.0.4-1606980013387/current/replicas doesn't exist 
2020-12-03 07:20:21,747 [Thread-308] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1199088383-172.17.0.4-1606980013387 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11: 0ms
2020-12-03 07:20:21,747 [Thread-309] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1199088383-172.17.0.4-1606980013387 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12: 0ms
2020-12-03 07:20:21,747 [Thread-172] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1199088383-172.17.0.4-1606980013387: 1ms
2020-12-03 07:20:21,747 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1199088383-172.17.0.4-1606980013387 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:20:21,747 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1199088383-172.17.0.4-1606980013387 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:20:21,748 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-ba213c2e-7d56-49cf-8c5f-d363ac2f32c7): finished scanning block pool BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:21,748 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-a28f0b02-f8c5-4829-be0e-08394c72924d): finished scanning block pool BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:21,774 [IPC Server handler 0 on default port 44233] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:21,775 [Listener at localhost/43660] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:21,775 [Listener at localhost/43660] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:21,877 [IPC Server handler 5 on default port 44233] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:21,878 [Listener at localhost/43660] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:21,878 [Listener at localhost/43660] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:21,887 [Thread-194] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 90214f51-5a35-447c-80e4-0159b8394987
2020-12-03 07:20:21,890 [Thread-194] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-e0b4f24e-24cd-44f5-8116-b2ae227fd08c
2020-12-03 07:20:21,891 [Thread-194] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, StorageType: DISK
2020-12-03 07:20:21,892 [Thread-194] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-ec353e10-93bc-4bc7-959e-05ad0de8bd77
2020-12-03 07:20:21,893 [Thread-194] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, StorageType: DISK
2020-12-03 07:20:21,894 [Thread-194] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:21,895 [Thread-194] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:20:21,896 [Thread-194] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:20:21,896 [Thread-194] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:20:21,896 [Thread-194] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:20:21,897 [Thread-194] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:21,897 [Thread-314] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1199088383-172.17.0.4-1606980013387 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13...
2020-12-03 07:20:21,897 [Thread-315] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1199088383-172.17.0.4-1606980013387 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14...
2020-12-03 07:20:21,913 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-9f3a827e-e2fe-44cb-bf3f-03dbde2b0b88): no suitable block pools found to scan.  Waiting 1814399513 ms.
2020-12-03 07:20:21,913 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-ba213c2e-7d56-49cf-8c5f-d363ac2f32c7): no suitable block pools found to scan.  Waiting 1814399834 ms.
2020-12-03 07:20:21,913 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-75948b37-fc93-40b9-90df-eead8d830e52): no suitable block pools found to scan.  Waiting 1814399523 ms.
2020-12-03 07:20:21,913 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-9637c4ad-4b9f-4743-85c8-8b3b2981aad6): no suitable block pools found to scan.  Waiting 1814399525 ms.
2020-12-03 07:20:21,913 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-a28f0b02-f8c5-4829-be0e-08394c72924d): no suitable block pools found to scan.  Waiting 1814399834 ms.
2020-12-03 07:20:21,913 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-424ba2c6-e1c2-4264-9ece-472b5fa767aa): no suitable block pools found to scan.  Waiting 1814399523 ms.
2020-12-03 07:20:21,913 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-8888774b-8a84-448b-b3e5-a3adadd0d078): no suitable block pools found to scan.  Waiting 1814399512 ms.
2020-12-03 07:20:21,913 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-53ebb263-a519-4e04-8516-6895b2684e49): no suitable block pools found to scan.  Waiting 1814399524 ms.
2020-12-03 07:20:21,913 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-89b6f46a-278e-49c3-b219-2a6fc902ef6b): no suitable block pools found to scan.  Waiting 1814399525 ms.
2020-12-03 07:20:21,913 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-7c7a5fb3-6845-447a-a855-e677cf9028bc): no suitable block pools found to scan.  Waiting 1814399525 ms.
2020-12-03 07:20:21,913 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-604aa382-053e-4d29-ae14-d8159a125483): no suitable block pools found to scan.  Waiting 1814399524 ms.
2020-12-03 07:20:21,913 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-e0706d8b-1d48-436b-a586-041594df8014): no suitable block pools found to scan.  Waiting 1814399525 ms.
2020-12-03 07:20:21,920 [Thread-128] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 12:21 PM with interval of 21600000ms
2020-12-03 07:20:21,921 [Thread-84] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:51 AM with interval of 21600000ms
2020-12-03 07:20:21,921 [Thread-172] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 10:55 AM with interval of 21600000ms
2020-12-03 07:20:21,921 [Thread-60] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 8:09 AM with interval of 21600000ms
2020-12-03 07:20:21,921 [Thread-150] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 10:21 AM with interval of 21600000ms
2020-12-03 07:20:21,921 [Thread-106] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 10:46 AM with interval of 21600000ms
2020-12-03 07:20:21,928 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1199088383-172.17.0.4-1606980013387 (Datanode Uuid 2c0b9200-a808-454b-aeae-39910540cca5) service to localhost/127.0.0.1:44233 beginning handshake with NN
2020-12-03 07:20:21,928 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1199088383-172.17.0.4-1606980013387 (Datanode Uuid 3c6cb142-24b8-4ba9-8bce-390f3aeb2056) service to localhost/127.0.0.1:44233 beginning handshake with NN
2020-12-03 07:20:21,928 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1199088383-172.17.0.4-1606980013387 (Datanode Uuid aa46699a-faf3-419b-9673-7b32209adbf8) service to localhost/127.0.0.1:44233 beginning handshake with NN
2020-12-03 07:20:21,928 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1199088383-172.17.0.4-1606980013387 (Datanode Uuid aae714b7-affe-4899-8582-7db48868bdef) service to localhost/127.0.0.1:44233 beginning handshake with NN
2020-12-03 07:20:21,928 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1199088383-172.17.0.4-1606980013387 (Datanode Uuid 13dd0217-9dd1-4416-9b7c-bf07e67f055d) service to localhost/127.0.0.1:44233 beginning handshake with NN
2020-12-03 07:20:21,928 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1199088383-172.17.0.4-1606980013387 (Datanode Uuid ac43fde1-9305-4657-806e-9582c003dbfc) service to localhost/127.0.0.1:44233 beginning handshake with NN
2020-12-03 07:20:21,929 [Thread-314] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1199088383-172.17.0.4-1606980013387 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13: 33ms
2020-12-03 07:20:21,930 [Thread-315] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1199088383-172.17.0.4-1606980013387 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14: 32ms
2020-12-03 07:20:21,930 [Thread-194] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1199088383-172.17.0.4-1606980013387: 33ms
2020-12-03 07:20:21,930 [Thread-324] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1199088383-172.17.0.4-1606980013387 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13...
2020-12-03 07:20:21,931 [Thread-325] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1199088383-172.17.0.4-1606980013387 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14...
2020-12-03 07:20:21,931 [Thread-324] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1199088383-172.17.0.4-1606980013387/current/replicas doesn't exist 
2020-12-03 07:20:21,931 [Thread-325] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1199088383-172.17.0.4-1606980013387/current/replicas doesn't exist 
2020-12-03 07:20:21,931 [Thread-324] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1199088383-172.17.0.4-1606980013387 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13: 0ms
2020-12-03 07:20:21,931 [Thread-325] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1199088383-172.17.0.4-1606980013387 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14: 0ms
2020-12-03 07:20:21,931 [Thread-194] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1199088383-172.17.0.4-1606980013387: 2ms
2020-12-03 07:20:21,932 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1199088383-172.17.0.4-1606980013387 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:20:21,932 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1199088383-172.17.0.4-1606980013387 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:20:21,932 [Thread-194] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 9:07 AM with interval of 21600000ms
2020-12-03 07:20:21,932 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-e0b4f24e-24cd-44f5-8116-b2ae227fd08c): finished scanning block pool BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:21,932 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-ec353e10-93bc-4bc7-959e-05ad0de8bd77): finished scanning block pool BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:21,933 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1199088383-172.17.0.4-1606980013387 (Datanode Uuid 90214f51-5a35-447c-80e4-0159b8394987) service to localhost/127.0.0.1:44233 beginning handshake with NN
2020-12-03 07:20:21,934 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-e0b4f24e-24cd-44f5-8116-b2ae227fd08c): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-12-03 07:20:21,934 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-ec353e10-93bc-4bc7-959e-05ad0de8bd77): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-12-03 07:20:21,944 [IPC Server handler 7 on default port 44233] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:38140, datanodeUuid=aae714b7-affe-4899-8582-7db48868bdef, infoPort=39750, infoSecurePort=0, ipcPort=39371, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387) storage aae714b7-affe-4899-8582-7db48868bdef
2020-12-03 07:20:21,945 [IPC Server handler 7 on default port 44233] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38140
2020-12-03 07:20:21,946 [IPC Server handler 7 on default port 44233] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN aae714b7-affe-4899-8582-7db48868bdef (127.0.0.1:38140).
2020-12-03 07:20:21,948 [IPC Server handler 6 on default port 44233] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:39670, datanodeUuid=ac43fde1-9305-4657-806e-9582c003dbfc, infoPort=41886, infoSecurePort=0, ipcPort=33533, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387) storage ac43fde1-9305-4657-806e-9582c003dbfc
2020-12-03 07:20:21,948 [IPC Server handler 6 on default port 44233] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:39670
2020-12-03 07:20:21,949 [IPC Server handler 6 on default port 44233] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN ac43fde1-9305-4657-806e-9582c003dbfc (127.0.0.1:39670).
2020-12-03 07:20:21,949 [IPC Server handler 4 on default port 44233] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:36016, datanodeUuid=2c0b9200-a808-454b-aeae-39910540cca5, infoPort=37163, infoSecurePort=0, ipcPort=32843, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387) storage 2c0b9200-a808-454b-aeae-39910540cca5
2020-12-03 07:20:21,949 [IPC Server handler 4 on default port 44233] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36016
2020-12-03 07:20:21,950 [IPC Server handler 4 on default port 44233] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 2c0b9200-a808-454b-aeae-39910540cca5 (127.0.0.1:36016).
2020-12-03 07:20:21,950 [IPC Server handler 8 on default port 44233] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:38875, datanodeUuid=aa46699a-faf3-419b-9673-7b32209adbf8, infoPort=35718, infoSecurePort=0, ipcPort=38382, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387) storage aa46699a-faf3-419b-9673-7b32209adbf8
2020-12-03 07:20:21,950 [IPC Server handler 8 on default port 44233] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38875
2020-12-03 07:20:21,950 [IPC Server handler 8 on default port 44233] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN aa46699a-faf3-419b-9673-7b32209adbf8 (127.0.0.1:38875).
2020-12-03 07:20:21,951 [IPC Server handler 9 on default port 44233] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:37359, datanodeUuid=3c6cb142-24b8-4ba9-8bce-390f3aeb2056, infoPort=38706, infoSecurePort=0, ipcPort=40783, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387) storage 3c6cb142-24b8-4ba9-8bce-390f3aeb2056
2020-12-03 07:20:21,951 [IPC Server handler 9 on default port 44233] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:37359
2020-12-03 07:20:21,951 [IPC Server handler 9 on default port 44233] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 3c6cb142-24b8-4ba9-8bce-390f3aeb2056 (127.0.0.1:37359).
2020-12-03 07:20:21,951 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1199088383-172.17.0.4-1606980013387 (Datanode Uuid aa46699a-faf3-419b-9673-7b32209adbf8) service to localhost/127.0.0.1:44233 successfully registered with NN
2020-12-03 07:20:21,951 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1199088383-172.17.0.4-1606980013387 (Datanode Uuid aae714b7-affe-4899-8582-7db48868bdef) service to localhost/127.0.0.1:44233 successfully registered with NN
2020-12-03 07:20:21,951 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1199088383-172.17.0.4-1606980013387 (Datanode Uuid 2c0b9200-a808-454b-aeae-39910540cca5) service to localhost/127.0.0.1:44233 successfully registered with NN
2020-12-03 07:20:21,951 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1199088383-172.17.0.4-1606980013387 (Datanode Uuid ac43fde1-9305-4657-806e-9582c003dbfc) service to localhost/127.0.0.1:44233 successfully registered with NN
2020-12-03 07:20:21,951 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:44233 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:21,951 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:44233 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:21,951 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:44233 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:21,951 [IPC Server handler 1 on default port 44233] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:37144, datanodeUuid=90214f51-5a35-447c-80e4-0159b8394987, infoPort=36080, infoSecurePort=0, ipcPort=37376, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387) storage 90214f51-5a35-447c-80e4-0159b8394987
2020-12-03 07:20:21,952 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1199088383-172.17.0.4-1606980013387 (Datanode Uuid 3c6cb142-24b8-4ba9-8bce-390f3aeb2056) service to localhost/127.0.0.1:44233 successfully registered with NN
2020-12-03 07:20:21,952 [IPC Server handler 1 on default port 44233] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:37144
2020-12-03 07:20:21,952 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:44233 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:21,952 [IPC Server handler 1 on default port 44233] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 90214f51-5a35-447c-80e4-0159b8394987 (127.0.0.1:37144).
2020-12-03 07:20:21,952 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:44233 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:21,953 [IPC Server handler 3 on default port 44233] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:38718, datanodeUuid=13dd0217-9dd1-4416-9b7c-bf07e67f055d, infoPort=45384, infoSecurePort=0, ipcPort=33442, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387) storage 13dd0217-9dd1-4416-9b7c-bf07e67f055d
2020-12-03 07:20:21,953 [IPC Server handler 3 on default port 44233] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38718
2020-12-03 07:20:21,953 [IPC Server handler 3 on default port 44233] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 13dd0217-9dd1-4416-9b7c-bf07e67f055d (127.0.0.1:38718).
2020-12-03 07:20:21,953 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1199088383-172.17.0.4-1606980013387 (Datanode Uuid 90214f51-5a35-447c-80e4-0159b8394987) service to localhost/127.0.0.1:44233 successfully registered with NN
2020-12-03 07:20:21,953 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:44233 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:21,955 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1199088383-172.17.0.4-1606980013387 (Datanode Uuid 13dd0217-9dd1-4416-9b7c-bf07e67f055d) service to localhost/127.0.0.1:44233 successfully registered with NN
2020-12-03 07:20:21,955 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:44233 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:21,972 [IPC Server handler 6 on default port 44233] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-e0b4f24e-24cd-44f5-8116-b2ae227fd08c for DN 127.0.0.1:37144
2020-12-03 07:20:21,973 [IPC Server handler 6 on default port 44233] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-ec353e10-93bc-4bc7-959e-05ad0de8bd77 for DN 127.0.0.1:37144
2020-12-03 07:20:21,974 [IPC Server handler 7 on default port 44233] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-9637c4ad-4b9f-4743-85c8-8b3b2981aad6 for DN 127.0.0.1:37359
2020-12-03 07:20:21,976 [IPC Server handler 7 on default port 44233] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-89b6f46a-278e-49c3-b219-2a6fc902ef6b for DN 127.0.0.1:37359
2020-12-03 07:20:21,976 [IPC Server handler 4 on default port 44233] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-53ebb263-a519-4e04-8516-6895b2684e49 for DN 127.0.0.1:36016
2020-12-03 07:20:21,976 [IPC Server handler 4 on default port 44233] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-604aa382-053e-4d29-ae14-d8159a125483 for DN 127.0.0.1:36016
2020-12-03 07:20:21,977 [IPC Server handler 2 on default port 44233] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-ba213c2e-7d56-49cf-8c5f-d363ac2f32c7 for DN 127.0.0.1:38718
2020-12-03 07:20:21,977 [IPC Server handler 2 on default port 44233] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-a28f0b02-f8c5-4829-be0e-08394c72924d for DN 127.0.0.1:38718
2020-12-03 07:20:21,977 [IPC Server handler 5 on default port 44233] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-e0706d8b-1d48-436b-a586-041594df8014 for DN 127.0.0.1:38875
2020-12-03 07:20:21,978 [IPC Server handler 5 on default port 44233] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-7c7a5fb3-6845-447a-a855-e677cf9028bc for DN 127.0.0.1:38875
2020-12-03 07:20:21,978 [IPC Server handler 0 on default port 44233] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-424ba2c6-e1c2-4264-9ece-472b5fa767aa for DN 127.0.0.1:39670
2020-12-03 07:20:21,978 [IPC Server handler 0 on default port 44233] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-75948b37-fc93-40b9-90df-eead8d830e52 for DN 127.0.0.1:39670
2020-12-03 07:20:21,979 [IPC Server handler 8 on default port 44233] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-9f3a827e-e2fe-44cb-bf3f-03dbde2b0b88 for DN 127.0.0.1:38140
2020-12-03 07:20:21,980 [IPC Server handler 8 on default port 44233] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-8888774b-8a84-448b-b3e5-a3adadd0d078 for DN 127.0.0.1:38140
2020-12-03 07:20:21,982 [IPC Server handler 9 on default port 44233] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:22,003 [Listener at localhost/43660] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:22,003 [Listener at localhost/43660] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:22,104 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xb9c4b4badfe23286: Processing first storage report for DS-ec353e10-93bc-4bc7-959e-05ad0de8bd77 from datanode 90214f51-5a35-447c-80e4-0159b8394987
2020-12-03 07:20:22,107 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xb9c4b4badfe23286: from storage DS-ec353e10-93bc-4bc7-959e-05ad0de8bd77 node DatanodeRegistration(127.0.0.1:37144, datanodeUuid=90214f51-5a35-447c-80e4-0159b8394987, infoPort=36080, infoSecurePort=0, ipcPort=37376, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387), blocks: 0, hasStaleStorage: true, processing time: 3 msecs, invalidatedBlocks: 0
2020-12-03 07:20:22,107 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xa4fa3b562d6224b8: Processing first storage report for DS-424ba2c6-e1c2-4264-9ece-472b5fa767aa from datanode ac43fde1-9305-4657-806e-9582c003dbfc
2020-12-03 07:20:22,108 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xa4fa3b562d6224b8: from storage DS-424ba2c6-e1c2-4264-9ece-472b5fa767aa node DatanodeRegistration(127.0.0.1:39670, datanodeUuid=ac43fde1-9305-4657-806e-9582c003dbfc, infoPort=41886, infoSecurePort=0, ipcPort=33533, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:22,108 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xff4a5452b3f8a414: Processing first storage report for DS-53ebb263-a519-4e04-8516-6895b2684e49 from datanode 2c0b9200-a808-454b-aeae-39910540cca5
2020-12-03 07:20:22,108 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xff4a5452b3f8a414: from storage DS-53ebb263-a519-4e04-8516-6895b2684e49 node DatanodeRegistration(127.0.0.1:36016, datanodeUuid=2c0b9200-a808-454b-aeae-39910540cca5, infoPort=37163, infoSecurePort=0, ipcPort=32843, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:22,108 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xc76442dff4df8036: Processing first storage report for DS-ba213c2e-7d56-49cf-8c5f-d363ac2f32c7 from datanode 13dd0217-9dd1-4416-9b7c-bf07e67f055d
2020-12-03 07:20:22,108 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xc76442dff4df8036: from storage DS-ba213c2e-7d56-49cf-8c5f-d363ac2f32c7 node DatanodeRegistration(127.0.0.1:38718, datanodeUuid=13dd0217-9dd1-4416-9b7c-bf07e67f055d, infoPort=45384, infoSecurePort=0, ipcPort=33442, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:20:22,109 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x37422f3f95ee8261: Processing first storage report for DS-7c7a5fb3-6845-447a-a855-e677cf9028bc from datanode aa46699a-faf3-419b-9673-7b32209adbf8
2020-12-03 07:20:22,109 [IPC Server handler 2 on default port 44233] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:22,109 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x37422f3f95ee8261: from storage DS-7c7a5fb3-6845-447a-a855-e677cf9028bc node DatanodeRegistration(127.0.0.1:38875, datanodeUuid=aa46699a-faf3-419b-9673-7b32209adbf8, infoPort=35718, infoSecurePort=0, ipcPort=38382, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:22,109 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x74e17781f4d118a: Processing first storage report for DS-89b6f46a-278e-49c3-b219-2a6fc902ef6b from datanode 3c6cb142-24b8-4ba9-8bce-390f3aeb2056
2020-12-03 07:20:22,110 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x74e17781f4d118a: from storage DS-89b6f46a-278e-49c3-b219-2a6fc902ef6b node DatanodeRegistration(127.0.0.1:37359, datanodeUuid=3c6cb142-24b8-4ba9-8bce-390f3aeb2056, infoPort=38706, infoSecurePort=0, ipcPort=40783, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:22,110 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xb9c4b4badfe23286: Processing first storage report for DS-e0b4f24e-24cd-44f5-8116-b2ae227fd08c from datanode 90214f51-5a35-447c-80e4-0159b8394987
2020-12-03 07:20:22,110 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xb9c4b4badfe23286: from storage DS-e0b4f24e-24cd-44f5-8116-b2ae227fd08c node DatanodeRegistration(127.0.0.1:37144, datanodeUuid=90214f51-5a35-447c-80e4-0159b8394987, infoPort=36080, infoSecurePort=0, ipcPort=37376, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:22,110 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xa4fa3b562d6224b8: Processing first storage report for DS-75948b37-fc93-40b9-90df-eead8d830e52 from datanode ac43fde1-9305-4657-806e-9582c003dbfc
2020-12-03 07:20:22,110 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xa4fa3b562d6224b8: from storage DS-75948b37-fc93-40b9-90df-eead8d830e52 node DatanodeRegistration(127.0.0.1:39670, datanodeUuid=ac43fde1-9305-4657-806e-9582c003dbfc, infoPort=41886, infoSecurePort=0, ipcPort=33533, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:22,110 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xff4a5452b3f8a414: Processing first storage report for DS-604aa382-053e-4d29-ae14-d8159a125483 from datanode 2c0b9200-a808-454b-aeae-39910540cca5
2020-12-03 07:20:22,110 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xff4a5452b3f8a414: from storage DS-604aa382-053e-4d29-ae14-d8159a125483 node DatanodeRegistration(127.0.0.1:36016, datanodeUuid=2c0b9200-a808-454b-aeae-39910540cca5, infoPort=37163, infoSecurePort=0, ipcPort=32843, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:22,111 [Listener at localhost/43660] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:22,111 [Listener at localhost/43660] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:22,111 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xc76442dff4df8036: Processing first storage report for DS-a28f0b02-f8c5-4829-be0e-08394c72924d from datanode 13dd0217-9dd1-4416-9b7c-bf07e67f055d
2020-12-03 07:20:22,111 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xc76442dff4df8036: from storage DS-a28f0b02-f8c5-4829-be0e-08394c72924d node DatanodeRegistration(127.0.0.1:38718, datanodeUuid=13dd0217-9dd1-4416-9b7c-bf07e67f055d, infoPort=45384, infoSecurePort=0, ipcPort=33442, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:22,111 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x37422f3f95ee8261: Processing first storage report for DS-e0706d8b-1d48-436b-a586-041594df8014 from datanode aa46699a-faf3-419b-9673-7b32209adbf8
2020-12-03 07:20:22,111 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x37422f3f95ee8261: from storage DS-e0706d8b-1d48-436b-a586-041594df8014 node DatanodeRegistration(127.0.0.1:38875, datanodeUuid=aa46699a-faf3-419b-9673-7b32209adbf8, infoPort=35718, infoSecurePort=0, ipcPort=38382, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:20:22,112 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x74e17781f4d118a: Processing first storage report for DS-9637c4ad-4b9f-4743-85c8-8b3b2981aad6 from datanode 3c6cb142-24b8-4ba9-8bce-390f3aeb2056
2020-12-03 07:20:22,112 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x74e17781f4d118a: from storage DS-9637c4ad-4b9f-4743-85c8-8b3b2981aad6 node DatanodeRegistration(127.0.0.1:37359, datanodeUuid=3c6cb142-24b8-4ba9-8bce-390f3aeb2056, infoPort=38706, infoSecurePort=0, ipcPort=40783, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:22,134 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x74e17781f4d118a,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 98 msec to generate and 43 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:22,134 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xff4a5452b3f8a414,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 98 msec to generate and 43 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:22,134 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xa4fa3b562d6224b8,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 98 msec to generate and 43 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:22,134 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:22,134 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x37422f3f95ee8261,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 98 msec to generate and 43 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:22,134 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xc76442dff4df8036,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 98 msec to generate and 43 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:22,134 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xb9c4b4badfe23286,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 98 msec to generate and 43 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:22,135 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:22,134 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:22,134 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:22,134 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:22,135 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:22,212 [IPC Server handler 4 on default port 44233] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:22,214 [Listener at localhost/43660] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:22,214 [Listener at localhost/43660] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:22,316 [IPC Server handler 7 on default port 44233] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:22,318 [Listener at localhost/43660] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:22,318 [Listener at localhost/43660] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:22,331 [Thread-216] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 3029aacb-7eaa-447f-9e36-1d53750951b1
2020-12-03 07:20:22,334 [Thread-216] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-fafaff18-4de2-4bc2-bceb-3b8e48cbd859
2020-12-03 07:20:22,335 [Thread-216] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, StorageType: DISK
2020-12-03 07:20:22,338 [Thread-216] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-4b096592-2cf9-441a-91b8-89f8826a3f3a
2020-12-03 07:20:22,338 [Thread-216] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, StorageType: DISK
2020-12-03 07:20:22,339 [Thread-216] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:22,340 [Thread-216] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:20:22,341 [Thread-216] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:20:22,341 [Thread-216] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:20:22,341 [Thread-216] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:20:22,342 [Thread-216] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:22,342 [Thread-331] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1199088383-172.17.0.4-1606980013387 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15...
2020-12-03 07:20:22,342 [Thread-332] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1199088383-172.17.0.4-1606980013387 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16...
2020-12-03 07:20:22,419 [IPC Server handler 9 on default port 44233] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:22,421 [Listener at localhost/43660] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:22,421 [Listener at localhost/43660] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:22,479 [Thread-332] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1199088383-172.17.0.4-1606980013387 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16: 138ms
2020-12-03 07:20:22,479 [Thread-331] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1199088383-172.17.0.4-1606980013387 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15: 138ms
2020-12-03 07:20:22,480 [Thread-216] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1199088383-172.17.0.4-1606980013387: 138ms
2020-12-03 07:20:22,481 [Thread-335] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1199088383-172.17.0.4-1606980013387 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15...
2020-12-03 07:20:22,481 [Thread-335] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1199088383-172.17.0.4-1606980013387/current/replicas doesn't exist 
2020-12-03 07:20:22,481 [Thread-336] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1199088383-172.17.0.4-1606980013387 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16...
2020-12-03 07:20:22,481 [Thread-336] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1199088383-172.17.0.4-1606980013387/current/replicas doesn't exist 
2020-12-03 07:20:22,481 [Thread-335] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1199088383-172.17.0.4-1606980013387 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15: 0ms
2020-12-03 07:20:22,481 [Thread-336] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1199088383-172.17.0.4-1606980013387 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16: 1ms
2020-12-03 07:20:22,482 [Thread-216] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1199088383-172.17.0.4-1606980013387: 1ms
2020-12-03 07:20:22,482 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1199088383-172.17.0.4-1606980013387 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:20:22,482 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1199088383-172.17.0.4-1606980013387 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:20:22,482 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-fafaff18-4de2-4bc2-bceb-3b8e48cbd859): finished scanning block pool BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:22,482 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-4b096592-2cf9-441a-91b8-89f8826a3f3a): finished scanning block pool BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:22,483 [Thread-216] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 12:36 PM with interval of 21600000ms
2020-12-03 07:20:22,483 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-fafaff18-4de2-4bc2-bceb-3b8e48cbd859): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:20:22,483 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-4b096592-2cf9-441a-91b8-89f8826a3f3a): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:20:22,484 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1199088383-172.17.0.4-1606980013387 (Datanode Uuid 3029aacb-7eaa-447f-9e36-1d53750951b1) service to localhost/127.0.0.1:44233 beginning handshake with NN
2020-12-03 07:20:22,485 [IPC Server handler 2 on default port 44233] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:40206, datanodeUuid=3029aacb-7eaa-447f-9e36-1d53750951b1, infoPort=45942, infoSecurePort=0, ipcPort=43625, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387) storage 3029aacb-7eaa-447f-9e36-1d53750951b1
2020-12-03 07:20:22,485 [IPC Server handler 2 on default port 44233] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:40206
2020-12-03 07:20:22,486 [IPC Server handler 2 on default port 44233] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 3029aacb-7eaa-447f-9e36-1d53750951b1 (127.0.0.1:40206).
2020-12-03 07:20:22,486 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1199088383-172.17.0.4-1606980013387 (Datanode Uuid 3029aacb-7eaa-447f-9e36-1d53750951b1) service to localhost/127.0.0.1:44233 successfully registered with NN
2020-12-03 07:20:22,487 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:44233 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:22,490 [IPC Server handler 0 on default port 44233] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-fafaff18-4de2-4bc2-bceb-3b8e48cbd859 for DN 127.0.0.1:40206
2020-12-03 07:20:22,490 [IPC Server handler 0 on default port 44233] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-4b096592-2cf9-441a-91b8-89f8826a3f3a for DN 127.0.0.1:40206
2020-12-03 07:20:22,492 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x2a2f48ede4d44567: Processing first storage report for DS-4b096592-2cf9-441a-91b8-89f8826a3f3a from datanode 3029aacb-7eaa-447f-9e36-1d53750951b1
2020-12-03 07:20:22,493 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x2a2f48ede4d44567: from storage DS-4b096592-2cf9-441a-91b8-89f8826a3f3a node DatanodeRegistration(127.0.0.1:40206, datanodeUuid=3029aacb-7eaa-447f-9e36-1d53750951b1, infoPort=45942, infoSecurePort=0, ipcPort=43625, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:22,493 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x2a2f48ede4d44567: Processing first storage report for DS-fafaff18-4de2-4bc2-bceb-3b8e48cbd859 from datanode 3029aacb-7eaa-447f-9e36-1d53750951b1
2020-12-03 07:20:22,493 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x2a2f48ede4d44567: from storage DS-fafaff18-4de2-4bc2-bceb-3b8e48cbd859 node DatanodeRegistration(127.0.0.1:40206, datanodeUuid=3029aacb-7eaa-447f-9e36-1d53750951b1, infoPort=45942, infoSecurePort=0, ipcPort=43625, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:22,493 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x2a2f48ede4d44567,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:22,494 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:22,523 [IPC Server handler 6 on default port 44233] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:22,525 [Listener at localhost/43660] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:22,525 [Listener at localhost/43660] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:22,564 [Thread-238] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 785f49e4-7600-4544-bff9-d9be9a31becb
2020-12-03 07:20:22,567 [Thread-238] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-05e88003-7d71-45e9-9eec-ae795adefff3
2020-12-03 07:20:22,568 [Thread-238] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, StorageType: DISK
2020-12-03 07:20:22,570 [Thread-238] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-c1a89502-e5b9-42b4-9665-585863fffe34
2020-12-03 07:20:22,570 [Thread-238] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, StorageType: DISK
2020-12-03 07:20:22,571 [Thread-238] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:22,572 [Thread-238] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:20:22,573 [Thread-238] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:20:22,573 [Thread-238] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:20:22,573 [Thread-238] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:20:22,574 [Thread-238] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:22,574 [Thread-342] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1199088383-172.17.0.4-1606980013387 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17...
2020-12-03 07:20:22,576 [Thread-343] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1199088383-172.17.0.4-1606980013387 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18...
2020-12-03 07:20:22,605 [Thread-343] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1199088383-172.17.0.4-1606980013387 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18: 29ms
2020-12-03 07:20:22,605 [Thread-342] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1199088383-172.17.0.4-1606980013387 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17: 30ms
2020-12-03 07:20:22,606 [Thread-238] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1199088383-172.17.0.4-1606980013387: 33ms
2020-12-03 07:20:22,607 [Thread-346] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1199088383-172.17.0.4-1606980013387 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17...
2020-12-03 07:20:22,607 [Thread-347] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1199088383-172.17.0.4-1606980013387 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18...
2020-12-03 07:20:22,607 [Thread-346] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1199088383-172.17.0.4-1606980013387/current/replicas doesn't exist 
2020-12-03 07:20:22,607 [Thread-347] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1199088383-172.17.0.4-1606980013387/current/replicas doesn't exist 
2020-12-03 07:20:22,607 [Thread-347] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1199088383-172.17.0.4-1606980013387 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18: 1ms
2020-12-03 07:20:22,607 [Thread-346] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1199088383-172.17.0.4-1606980013387 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17: 1ms
2020-12-03 07:20:22,608 [Thread-238] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1199088383-172.17.0.4-1606980013387: 1ms
2020-12-03 07:20:22,609 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1199088383-172.17.0.4-1606980013387 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:20:22,609 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1199088383-172.17.0.4-1606980013387 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:20:22,609 [Thread-238] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 8:09 AM with interval of 21600000ms
2020-12-03 07:20:22,609 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-c1a89502-e5b9-42b4-9665-585863fffe34): finished scanning block pool BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:22,609 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-05e88003-7d71-45e9-9eec-ae795adefff3): finished scanning block pool BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:22,610 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1199088383-172.17.0.4-1606980013387 (Datanode Uuid 785f49e4-7600-4544-bff9-d9be9a31becb) service to localhost/127.0.0.1:44233 beginning handshake with NN
2020-12-03 07:20:22,610 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-05e88003-7d71-45e9-9eec-ae795adefff3): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-12-03 07:20:22,610 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-c1a89502-e5b9-42b4-9665-585863fffe34): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:20:22,611 [IPC Server handler 3 on default port 44233] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:43228, datanodeUuid=785f49e4-7600-4544-bff9-d9be9a31becb, infoPort=39224, infoSecurePort=0, ipcPort=43660, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387) storage 785f49e4-7600-4544-bff9-d9be9a31becb
2020-12-03 07:20:22,612 [IPC Server handler 3 on default port 44233] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:43228
2020-12-03 07:20:22,612 [IPC Server handler 3 on default port 44233] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 785f49e4-7600-4544-bff9-d9be9a31becb (127.0.0.1:43228).
2020-12-03 07:20:22,613 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1199088383-172.17.0.4-1606980013387 (Datanode Uuid 785f49e4-7600-4544-bff9-d9be9a31becb) service to localhost/127.0.0.1:44233 successfully registered with NN
2020-12-03 07:20:22,613 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:44233 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:22,615 [IPC Server handler 5 on default port 44233] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-05e88003-7d71-45e9-9eec-ae795adefff3 for DN 127.0.0.1:43228
2020-12-03 07:20:22,615 [IPC Server handler 5 on default port 44233] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c1a89502-e5b9-42b4-9665-585863fffe34 for DN 127.0.0.1:43228
2020-12-03 07:20:22,617 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xa88f9fb9c8fc2c10: Processing first storage report for DS-c1a89502-e5b9-42b4-9665-585863fffe34 from datanode 785f49e4-7600-4544-bff9-d9be9a31becb
2020-12-03 07:20:22,617 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xa88f9fb9c8fc2c10: from storage DS-c1a89502-e5b9-42b4-9665-585863fffe34 node DatanodeRegistration(127.0.0.1:43228, datanodeUuid=785f49e4-7600-4544-bff9-d9be9a31becb, infoPort=39224, infoSecurePort=0, ipcPort=43660, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:22,617 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xa88f9fb9c8fc2c10: Processing first storage report for DS-05e88003-7d71-45e9-9eec-ae795adefff3 from datanode 785f49e4-7600-4544-bff9-d9be9a31becb
2020-12-03 07:20:22,617 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xa88f9fb9c8fc2c10: from storage DS-05e88003-7d71-45e9-9eec-ae795adefff3 node DatanodeRegistration(127.0.0.1:43228, datanodeUuid=785f49e4-7600-4544-bff9-d9be9a31becb, infoPort=39224, infoSecurePort=0, ipcPort=43660, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:20:22,618 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xa88f9fb9c8fc2c10,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:22,618 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:22,626 [IPC Server handler 4 on default port 44233] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:22,629 [Listener at localhost/43660] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:20:22,636 [IPC Server handler 7 on default port 44233] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:22,638 [Listener at localhost/43660] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:20:22,649 [IPC Server handler 9 on default port 44233] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=enableErasureCodingPolicy	src=RS-6-3-1024k	dst=null	perm=null	proto=rpc
2020-12-03 07:20:22,745 [IPC Server handler 2 on default port 44233] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setErasureCodingPolicy	src=/	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:20:23,205 [IPC Server handler 0 on default port 44233] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/file1	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:20:23,438 [IPC Server handler 8 on default port 44233] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_-9223372036854775792_1001, replicas=127.0.0.1:40206, 127.0.0.1:43228, 127.0.0.1:38140, 127.0.0.1:38718, 127.0.0.1:39670, 127.0.0.1:37359, 127.0.0.1:36016, 127.0.0.1:38875, 127.0.0.1:37144 for /file1
2020-12-03 07:20:23,460 [Thread-352] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:23,519 [DataXceiver for client DFSClient_NONMAPREDUCE_1275747404_24 at /127.0.0.1:36202 [Receiving block BP-1199088383-172.17.0.4-1606980013387:blk_-9223372036854775792_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1199088383-172.17.0.4-1606980013387:blk_-9223372036854775792_1001 src: /127.0.0.1:36202 dest: /127.0.0.1:40206
2020-12-03 07:20:23,713 [Thread-351] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:20:23,713 [Thread-351] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:20:23,714 [Thread-351] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 1, 7
2020-12-03 07:20:23,714 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@16eb6714] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:20:23,715 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@5420319b] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:20:23,716 [Thread-351] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 8 Total time for transactions(ms): 21 Number of transactions batched in Syncs: 0 Number of syncs: 9 SyncTimes(ms): 2 2 
2020-12-03 07:20:23,718 [Thread-351] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000008
2020-12-03 07:20:23,719 [Thread-351] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000008
2020-12-03 07:20:23,720 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:20:23,724 [CacheReplicationMonitor(1045112527)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:20:23,739 [Thread-351] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 44233
2020-12-03 07:20:23,745 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:23,745 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:23,747 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:20:23,747 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:20:23,790 [Thread-351] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:20:23,791 [Thread-351] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:20:23,887 [Thread-351] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@2adcde7{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:20:23,894 [Thread-351] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@18548501{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:23,897 [Thread-351] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@331ba624{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:23,898 [Thread-351] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@50797eb1{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:23,905 [Thread-351] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:20:23,906 [Thread-351] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-12-03 07:20:23,906 [Thread-351] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://localhost:44233
2020-12-03 07:20:23,906 [Thread-351] INFO  namenode.NameNode (NameNode.java:<init>(944)) - Clients should use localhost:44233 to access this namenode/service.
2020-12-03 07:20:23,914 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@23a2c28] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:23,914 [Thread-351] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:33418
2020-12-03 07:20:23,914 [Thread-351] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:24,029 [Thread-351] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:24,030 [Thread-351] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:20:24,030 [Thread-351] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:24,033 [Thread-351] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:24,034 [Thread-351] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:20:24,034 [Thread-351] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:24,034 [Thread-351] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:24,037 [Thread-351] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:20:24,037 [Thread-351] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:20:24,038 [Thread-351] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 33418
2020-12-03 07:20:24,038 [Thread-351] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:24,040 [Thread-351] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5bb8d3fc{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:24,040 [Thread-351] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@495259fd{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:24,047 [Thread-351] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@18d348c3{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:20:24,048 [Thread-351] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@511fa459{HTTP/1.1,[http/1.1]}{localhost:33418}
2020-12-03 07:20:24,049 [Thread-351] INFO  server.Server (Server.java:doStart(419)) - Started @13337ms
2020-12-03 07:20:24,051 [Thread-351] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:20:24,052 [Thread-351] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:20:24,052 [Thread-351] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:20:24,052 [Thread-351] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:20:24,052 [Thread-351] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:20:24,052 [Thread-351] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:20:24,053 [Thread-351] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:20:24,053 [Thread-351] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:20:24,053 [Thread-351] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:24,054 [Thread-351] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:20:24,054 [Thread-351] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:20:24,054 [Thread-351] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:20:24,054 [Thread-351] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:20:24
2020-12-03 07:20:24,054 [Thread-351] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:20:24,054 [Thread-351] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:24,055 [Thread-351] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:20:24,055 [Thread-351] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:20:24,063 [Thread-351] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:20:24,063 [Thread-351] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:20:24,064 [Thread-351] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:20:24,064 [Thread-351] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:20:24,064 [Thread-351] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:20:24,064 [Thread-351] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:20:24,064 [Thread-351] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:20:24,064 [Thread-351] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:20:24,064 [Thread-351] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:20:24,064 [Thread-351] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:20:24,064 [Thread-351] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:20:24,065 [Thread-351] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:20:24,065 [Thread-351] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:20:24,065 [Thread-351] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:20:24,065 [Thread-351] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:24,065 [Thread-351] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:20:24,066 [Thread-351] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:20:24,067 [Thread-351] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:20:24,068 [Thread-351] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:20:24,068 [Thread-351] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:20:24,068 [Thread-351] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:20:24,068 [Thread-351] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:20:24,068 [Thread-351] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:20:24,068 [Thread-351] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:20:24,068 [Thread-351] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:24,069 [Thread-351] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:20:24,069 [Thread-351] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:20:24,069 [Thread-351] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:20:24,070 [Thread-351] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:20:24,070 [Thread-351] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:20:24,070 [Thread-351] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:20:24,070 [Thread-351] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:20:24,070 [Thread-351] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:20:24,070 [Thread-351] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:24,070 [Thread-351] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:20:24,070 [Thread-351] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:20:24,492 [Thread-351] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 900@9c826977c5c0
2020-12-03 07:20:25,005 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] WARN  datanode.DataNode (BPServiceActor.java:offerService(731)) - IOException in offerService
java.io.EOFException: End of File Exception between local host is: "9c826977c5c0/172.17.0.4"; destination host is: "localhost":44233; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:791)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
	at com.sun.proxy.$Proxy25.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:168)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:517)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:648)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:849)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
2020-12-03 07:20:25,058 [Thread-351] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 900@9c826977c5c0
2020-12-03 07:20:25,005 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] WARN  datanode.DataNode (BPServiceActor.java:offerService(731)) - IOException in offerService
java.io.EOFException: End of File Exception between local host is: "9c826977c5c0/172.17.0.4"; destination host is: "localhost":44233; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:791)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
	at com.sun.proxy.$Proxy25.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:168)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:517)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:648)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:849)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
2020-12-03 07:20:25,325 [Thread-351] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-12-03 07:20:25,326 [Thread-351] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-12-03 07:20:25,391 [Thread-351] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:20:25,396 [Thread-351] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:20:25,398 [Thread-351] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:20:25,398 [Thread-351] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-12-03 07:20:25,921 [Thread-351] INFO  namenode.FSImage (FSImage.java:loadEdits(910)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@7822f44f expecting start txid #1
2020-12-03 07:20:25,922 [Thread-351] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000008, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000008 maxTxnsToRead = 9223372036854775807
2020-12-03 07:20:25,923 [Thread-351] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000008' to transaction ID 1
2020-12-03 07:20:25,956 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  ipc.Client (Client.java:handleConnectionFailure(958)) - Retrying connect to server: localhost/127.0.0.1:44233. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-03 07:20:26,078 [Thread-351] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(188)) - Loaded 1 edits file(s) (the last named /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000008, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000008) of total size 441.0, total edits 8.0, total load time 15.0 ms
2020-12-03 07:20:26,079 [Thread-351] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:20:26,080 [Thread-351] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 9
2020-12-03 07:20:26,939 [Thread-351] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:20:26,939 [Thread-351] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 2867 msecs
2020-12-03 07:20:26,939 [Thread-351] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:44233
2020-12-03 07:20:26,940 [Thread-351] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:26,941 [Socket Reader #1 for port 44233] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 44233
2020-12-03 07:20:26,949 [Listener at localhost/44233] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:20:26,957 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  ipc.Client (Client.java:handleConnectionFailure(958)) - Retrying connect to server: localhost/127.0.0.1:44233. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-12-03 07:20:27,134 [Listener at localhost/44233] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 1
2020-12-03 07:20:27,136 [Listener at localhost/44233] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:20:27,136 [Listener at localhost/44233] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:20:27,136 [Listener at localhost/44233] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:20:27,137 [Listener at localhost/44233] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:20:27,141 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:27,141 [IPC Server listener on 44233] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 44233: starting
2020-12-03 07:20:27,144 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 1
2020-12-03 07:20:27,145 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:20:27,146 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:20:27,146 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:20:27,146 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 1
2020-12-03 07:20:27,146 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 9 msec
2020-12-03 07:20:27,146 [Listener at localhost/44233] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:44233
2020-12-03 07:20:27,146 [Listener at localhost/44233] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:20:27,146 [Listener at localhost/44233] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:20:27,147 [IPC Server handler 0 on default port 44233] INFO  ipc.Server (Server.java:logException(2976)) - IPC Server handler 0 on default port 44233, call Call#78 Retry#0 org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol.sendHeartbeat from 127.0.0.1:52032
org.apache.hadoop.ipc.RetriableException: NameNode still not started
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.checkNNStartup(NameNodeRpcServer.java:2282)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.sendHeartbeat(NameNodeRpcServer.java:1551)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolServerSideTranslatorPB.sendHeartbeat(DatanodeProtocolServerSideTranslatorPB.java:119)
	at org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$DatanodeProtocolService$2.callBlockingMethod(DatanodeProtocolProtos.java:31662)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
2020-12-03 07:20:27,148 [IPC Server handler 5 on default port 44233] INFO  ipc.Server (Server.java:logException(2976)) - IPC Server handler 5 on default port 44233, call Call#76 Retry#0 org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol.sendHeartbeat from 127.0.0.1:52032
org.apache.hadoop.ipc.RetriableException: NameNode still not started
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.checkNNStartup(NameNodeRpcServer.java:2282)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.sendHeartbeat(NameNodeRpcServer.java:1551)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolServerSideTranslatorPB.sendHeartbeat(DatanodeProtocolServerSideTranslatorPB.java:119)
	at org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$DatanodeProtocolService$2.callBlockingMethod(DatanodeProtocolProtos.java:31662)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
2020-12-03 07:20:27,147 [IPC Server handler 4 on default port 44233] INFO  ipc.Server (Server.java:logException(2976)) - IPC Server handler 4 on default port 44233, call Call#81 Retry#0 org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol.sendHeartbeat from 127.0.0.1:52032
org.apache.hadoop.ipc.RetriableException: NameNode still not started
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.checkNNStartup(NameNodeRpcServer.java:2282)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.sendHeartbeat(NameNodeRpcServer.java:1551)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolServerSideTranslatorPB.sendHeartbeat(DatanodeProtocolServerSideTranslatorPB.java:119)
	at org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$DatanodeProtocolService$2.callBlockingMethod(DatanodeProtocolProtos.java:31662)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
2020-12-03 07:20:27,147 [IPC Server handler 2 on default port 44233] INFO  ipc.Server (Server.java:logException(2976)) - IPC Server handler 2 on default port 44233, call Call#82 Retry#0 org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol.sendHeartbeat from 127.0.0.1:52032
org.apache.hadoop.ipc.RetriableException: NameNode still not started
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.checkNNStartup(NameNodeRpcServer.java:2282)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.sendHeartbeat(NameNodeRpcServer.java:1551)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolServerSideTranslatorPB.sendHeartbeat(DatanodeProtocolServerSideTranslatorPB.java:119)
	at org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$DatanodeProtocolService$2.callBlockingMethod(DatanodeProtocolProtos.java:31662)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
2020-12-03 07:20:27,147 [IPC Server handler 3 on default port 44233] INFO  ipc.Server (Server.java:logException(2976)) - IPC Server handler 3 on default port 44233, call Call#79 Retry#0 org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol.sendHeartbeat from 127.0.0.1:52032
org.apache.hadoop.ipc.RetriableException: NameNode still not started
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.checkNNStartup(NameNodeRpcServer.java:2282)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.sendHeartbeat(NameNodeRpcServer.java:1551)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolServerSideTranslatorPB.sendHeartbeat(DatanodeProtocolServerSideTranslatorPB.java:119)
	at org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$DatanodeProtocolService$2.callBlockingMethod(DatanodeProtocolProtos.java:31662)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
2020-12-03 07:20:27,147 [IPC Server handler 1 on default port 44233] INFO  ipc.Server (Server.java:logException(2976)) - IPC Server handler 1 on default port 44233, call Call#77 Retry#0 org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol.sendHeartbeat from 127.0.0.1:52032
org.apache.hadoop.ipc.RetriableException: NameNode still not started
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.checkNNStartup(NameNodeRpcServer.java:2282)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.sendHeartbeat(NameNodeRpcServer.java:1551)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolServerSideTranslatorPB.sendHeartbeat(DatanodeProtocolServerSideTranslatorPB.java:119)
	at org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$DatanodeProtocolService$2.callBlockingMethod(DatanodeProtocolProtos.java:31662)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
2020-12-03 07:20:27,154 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] WARN  datanode.DataNode (BPServiceActor.java:offerService(728)) - RemoteException in offerService
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.RetriableException): NameNode still not started
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.checkNNStartup(NameNodeRpcServer.java:2282)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.sendHeartbeat(NameNodeRpcServer.java:1551)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolServerSideTranslatorPB.sendHeartbeat(DatanodeProtocolServerSideTranslatorPB.java:119)
	at org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$DatanodeProtocolService$2.callBlockingMethod(DatanodeProtocolProtos.java:31662)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1545)
	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
	at com.sun.proxy.$Proxy25.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:168)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:517)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:648)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:849)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:20:27,153 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] WARN  datanode.DataNode (BPServiceActor.java:offerService(728)) - RemoteException in offerService
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.RetriableException): NameNode still not started
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.checkNNStartup(NameNodeRpcServer.java:2282)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.sendHeartbeat(NameNodeRpcServer.java:1551)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolServerSideTranslatorPB.sendHeartbeat(DatanodeProtocolServerSideTranslatorPB.java:119)
	at org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$DatanodeProtocolService$2.callBlockingMethod(DatanodeProtocolProtos.java:31662)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1545)
	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
	at com.sun.proxy.$Proxy25.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:168)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:517)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:648)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:849)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:20:27,152 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] WARN  datanode.DataNode (BPServiceActor.java:offerService(728)) - RemoteException in offerService
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.RetriableException): NameNode still not started
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.checkNNStartup(NameNodeRpcServer.java:2282)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.sendHeartbeat(NameNodeRpcServer.java:1551)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolServerSideTranslatorPB.sendHeartbeat(DatanodeProtocolServerSideTranslatorPB.java:119)
	at org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$DatanodeProtocolService$2.callBlockingMethod(DatanodeProtocolProtos.java:31662)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1545)
	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
	at com.sun.proxy.$Proxy25.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:168)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:517)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:648)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:849)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:20:27,152 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] WARN  datanode.DataNode (BPServiceActor.java:offerService(728)) - RemoteException in offerService
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.RetriableException): NameNode still not started
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.checkNNStartup(NameNodeRpcServer.java:2282)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.sendHeartbeat(NameNodeRpcServer.java:1551)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolServerSideTranslatorPB.sendHeartbeat(DatanodeProtocolServerSideTranslatorPB.java:119)
	at org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$DatanodeProtocolService$2.callBlockingMethod(DatanodeProtocolProtos.java:31662)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1545)
	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
	at com.sun.proxy.$Proxy25.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:168)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:517)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:648)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:849)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:20:27,148 [Listener at localhost/44233] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 1 milliseconds
name space=2
storage space=1207959552
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:20:27,148 [IPC Server handler 6 on default port 44233] INFO  ipc.Server (Server.java:logException(2976)) - IPC Server handler 6 on default port 44233, call Call#80 Retry#0 org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol.sendHeartbeat from 127.0.0.1:52032
org.apache.hadoop.ipc.RetriableException: NameNode still not started
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.checkNNStartup(NameNodeRpcServer.java:2282)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.sendHeartbeat(NameNodeRpcServer.java:1551)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolServerSideTranslatorPB.sendHeartbeat(DatanodeProtocolServerSideTranslatorPB.java:119)
	at org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$DatanodeProtocolService$2.callBlockingMethod(DatanodeProtocolProtos.java:31662)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
2020-12-03 07:20:27,155 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] WARN  datanode.DataNode (BPServiceActor.java:offerService(728)) - RemoteException in offerService
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.RetriableException): NameNode still not started
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.checkNNStartup(NameNodeRpcServer.java:2282)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.sendHeartbeat(NameNodeRpcServer.java:1551)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolServerSideTranslatorPB.sendHeartbeat(DatanodeProtocolServerSideTranslatorPB.java:119)
	at org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$DatanodeProtocolService$2.callBlockingMethod(DatanodeProtocolProtos.java:31662)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1545)
	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
	at com.sun.proxy.$Proxy25.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:168)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:517)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:648)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:849)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:20:27,155 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] WARN  datanode.DataNode (BPServiceActor.java:offerService(728)) - RemoteException in offerService
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.RetriableException): NameNode still not started
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.checkNNStartup(NameNodeRpcServer.java:2282)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.sendHeartbeat(NameNodeRpcServer.java:1551)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolServerSideTranslatorPB.sendHeartbeat(DatanodeProtocolServerSideTranslatorPB.java:119)
	at org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$DatanodeProtocolService$2.callBlockingMethod(DatanodeProtocolProtos.java:31662)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1545)
	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
	at com.sun.proxy.$Proxy25.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:168)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:517)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:648)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:849)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:20:27,160 [CacheReplicationMonitor(573879951)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:20:27,160 [Listener at localhost/44233] WARN  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitClusterUp(1436)) - Waiting for the Mini HDFS Cluster to start...
2020-12-03 07:20:27,159 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] WARN  datanode.DataNode (BPServiceActor.java:offerService(728)) - RemoteException in offerService
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.RetriableException): NameNode still not started
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.checkNNStartup(NameNodeRpcServer.java:2282)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.sendHeartbeat(NameNodeRpcServer.java:1551)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolServerSideTranslatorPB.sendHeartbeat(DatanodeProtocolServerSideTranslatorPB.java:119)
	at org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$DatanodeProtocolService$2.callBlockingMethod(DatanodeProtocolProtos.java:31662)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1545)
	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
	at com.sun.proxy.$Proxy25.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:168)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:517)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:648)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:849)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:20:27,956 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActor(672)) - DatanodeCommand action : DNA_REGISTER from localhost/127.0.0.1:44233 with active state
2020-12-03 07:20:27,956 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActor(672)) - DatanodeCommand action : DNA_REGISTER from localhost/127.0.0.1:44233 with active state
2020-12-03 07:20:27,957 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1199088383-172.17.0.4-1606980013387 (Datanode Uuid 2c0b9200-a808-454b-aeae-39910540cca5) service to localhost/127.0.0.1:44233 beginning handshake with NN
2020-12-03 07:20:27,957 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1199088383-172.17.0.4-1606980013387 (Datanode Uuid 3c6cb142-24b8-4ba9-8bce-390f3aeb2056) service to localhost/127.0.0.1:44233 beginning handshake with NN
2020-12-03 07:20:27,959 [IPC Server handler 5 on default port 44233] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:36016, datanodeUuid=2c0b9200-a808-454b-aeae-39910540cca5, infoPort=37163, infoSecurePort=0, ipcPort=32843, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387) storage 2c0b9200-a808-454b-aeae-39910540cca5
2020-12-03 07:20:27,959 [IPC Server handler 5 on default port 44233] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36016
2020-12-03 07:20:27,959 [IPC Server handler 5 on default port 44233] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 2c0b9200-a808-454b-aeae-39910540cca5 (127.0.0.1:36016).
2020-12-03 07:20:27,960 [IPC Server handler 4 on default port 44233] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:37359, datanodeUuid=3c6cb142-24b8-4ba9-8bce-390f3aeb2056, infoPort=38706, infoSecurePort=0, ipcPort=40783, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387) storage 3c6cb142-24b8-4ba9-8bce-390f3aeb2056
2020-12-03 07:20:27,960 [IPC Server handler 4 on default port 44233] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:37359
2020-12-03 07:20:27,961 [IPC Server handler 4 on default port 44233] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 3c6cb142-24b8-4ba9-8bce-390f3aeb2056 (127.0.0.1:37359).
2020-12-03 07:20:27,961 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1199088383-172.17.0.4-1606980013387 (Datanode Uuid 2c0b9200-a808-454b-aeae-39910540cca5) service to localhost/127.0.0.1:44233 successfully registered with NN
2020-12-03 07:20:27,962 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1199088383-172.17.0.4-1606980013387 (Datanode Uuid 3c6cb142-24b8-4ba9-8bce-390f3aeb2056) service to localhost/127.0.0.1:44233 successfully registered with NN
2020-12-03 07:20:27,963 [IPC Server handler 2 on default port 44233] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-53ebb263-a519-4e04-8516-6895b2684e49 for DN 127.0.0.1:36016
2020-12-03 07:20:27,963 [IPC Server handler 2 on default port 44233] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-604aa382-053e-4d29-ae14-d8159a125483 for DN 127.0.0.1:36016
2020-12-03 07:20:27,964 [IPC Server handler 3 on default port 44233] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-9637c4ad-4b9f-4743-85c8-8b3b2981aad6 for DN 127.0.0.1:37359
2020-12-03 07:20:27,965 [IPC Server handler 3 on default port 44233] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-89b6f46a-278e-49c3-b219-2a6fc902ef6b for DN 127.0.0.1:37359
2020-12-03 07:20:27,966 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xff4a5452b3f8a415: Processing first storage report for DS-53ebb263-a519-4e04-8516-6895b2684e49 from datanode 2c0b9200-a808-454b-aeae-39910540cca5
2020-12-03 07:20:27,967 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xff4a5452b3f8a415: from storage DS-53ebb263-a519-4e04-8516-6895b2684e49 node DatanodeRegistration(127.0.0.1:36016, datanodeUuid=2c0b9200-a808-454b-aeae-39910540cca5, infoPort=37163, infoSecurePort=0, ipcPort=32843, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:20:27,967 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x74e17781f4d118b: Processing first storage report for DS-89b6f46a-278e-49c3-b219-2a6fc902ef6b from datanode 3c6cb142-24b8-4ba9-8bce-390f3aeb2056
2020-12-03 07:20:27,967 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x74e17781f4d118b: from storage DS-89b6f46a-278e-49c3-b219-2a6fc902ef6b node DatanodeRegistration(127.0.0.1:37359, datanodeUuid=3c6cb142-24b8-4ba9-8bce-390f3aeb2056, infoPort=38706, infoSecurePort=0, ipcPort=40783, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:27,967 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xff4a5452b3f8a415: Processing first storage report for DS-604aa382-053e-4d29-ae14-d8159a125483 from datanode 2c0b9200-a808-454b-aeae-39910540cca5
2020-12-03 07:20:27,968 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xff4a5452b3f8a415: from storage DS-604aa382-053e-4d29-ae14-d8159a125483 node DatanodeRegistration(127.0.0.1:36016, datanodeUuid=2c0b9200-a808-454b-aeae-39910540cca5, infoPort=37163, infoSecurePort=0, ipcPort=32843, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:27,968 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x74e17781f4d118b: Processing first storage report for DS-9637c4ad-4b9f-4743-85c8-8b3b2981aad6 from datanode 3c6cb142-24b8-4ba9-8bce-390f3aeb2056
2020-12-03 07:20:27,968 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x74e17781f4d118b: from storage DS-9637c4ad-4b9f-4743-85c8-8b3b2981aad6 node DatanodeRegistration(127.0.0.1:37359, datanodeUuid=3c6cb142-24b8-4ba9-8bce-390f3aeb2056, infoPort=38706, infoSecurePort=0, ipcPort=40783, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:27,968 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xff4a5452b3f8a415,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 4 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:27,968 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x74e17781f4d118b,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:27,969 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:27,969 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:28,158 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActor(672)) - DatanodeCommand action : DNA_REGISTER from localhost/127.0.0.1:44233 with active state
2020-12-03 07:20:28,158 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActor(672)) - DatanodeCommand action : DNA_REGISTER from localhost/127.0.0.1:44233 with active state
2020-12-03 07:20:28,160 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1199088383-172.17.0.4-1606980013387 (Datanode Uuid 90214f51-5a35-447c-80e4-0159b8394987) service to localhost/127.0.0.1:44233 beginning handshake with NN
2020-12-03 07:20:28,160 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1199088383-172.17.0.4-1606980013387 (Datanode Uuid aa46699a-faf3-419b-9673-7b32209adbf8) service to localhost/127.0.0.1:44233 beginning handshake with NN
2020-12-03 07:20:28,161 [IPC Server handler 4 on default port 44233] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:37144, datanodeUuid=90214f51-5a35-447c-80e4-0159b8394987, infoPort=36080, infoSecurePort=0, ipcPort=37376, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387) storage 90214f51-5a35-447c-80e4-0159b8394987
2020-12-03 07:20:28,161 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActor(672)) - DatanodeCommand action : DNA_REGISTER from localhost/127.0.0.1:44233 with active state
2020-12-03 07:20:28,161 [IPC Server handler 4 on default port 44233] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:37144
2020-12-03 07:20:28,161 [Listener at localhost/44233] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:restartNameNode(2191)) - Restarted the namenode
2020-12-03 07:20:28,162 [IPC Server handler 4 on default port 44233] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 90214f51-5a35-447c-80e4-0159b8394987 (127.0.0.1:37144).
2020-12-03 07:20:28,163 [IPC Server handler 2 on default port 44233] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:38875, datanodeUuid=aa46699a-faf3-419b-9673-7b32209adbf8, infoPort=35718, infoSecurePort=0, ipcPort=38382, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387) storage aa46699a-faf3-419b-9673-7b32209adbf8
2020-12-03 07:20:28,164 [IPC Server handler 2 on default port 44233] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38875
2020-12-03 07:20:28,164 [IPC Server handler 2 on default port 44233] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN aa46699a-faf3-419b-9673-7b32209adbf8 (127.0.0.1:38875).
2020-12-03 07:20:28,165 [IPC Server handler 3 on default port 44233] WARN  blockmanagement.BlockManager (BlockManager.java:requestBlockReportLeaseId(2438)) - Failed to find datanode DatanodeRegistration(127.0.0.1:38140, datanodeUuid=aae714b7-affe-4899-8582-7db48868bdef, infoPort=39750, infoSecurePort=0, ipcPort=39371, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387)
2020-12-03 07:20:28,165 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1199088383-172.17.0.4-1606980013387 (Datanode Uuid 90214f51-5a35-447c-80e4-0159b8394987) service to localhost/127.0.0.1:44233 successfully registered with NN
2020-12-03 07:20:28,166 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1199088383-172.17.0.4-1606980013387 (Datanode Uuid aa46699a-faf3-419b-9673-7b32209adbf8) service to localhost/127.0.0.1:44233 successfully registered with NN
2020-12-03 07:20:28,166 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActor(672)) - DatanodeCommand action : DNA_REGISTER from localhost/127.0.0.1:44233 with active state
2020-12-03 07:20:28,166 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActor(672)) - DatanodeCommand action : DNA_REGISTER from localhost/127.0.0.1:44233 with active state
2020-12-03 07:20:28,166 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1199088383-172.17.0.4-1606980013387 (Datanode Uuid ac43fde1-9305-4657-806e-9582c003dbfc) service to localhost/127.0.0.1:44233 beginning handshake with NN
2020-12-03 07:20:28,167 [IPC Server handler 9 on default port 44233] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-e0b4f24e-24cd-44f5-8116-b2ae227fd08c for DN 127.0.0.1:37144
2020-12-03 07:20:28,168 [IPC Server handler 9 on default port 44233] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-ec353e10-93bc-4bc7-959e-05ad0de8bd77 for DN 127.0.0.1:37144
2020-12-03 07:20:28,168 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1199088383-172.17.0.4-1606980013387 (Datanode Uuid 13dd0217-9dd1-4416-9b7c-bf07e67f055d) service to localhost/127.0.0.1:44233 beginning handshake with NN
2020-12-03 07:20:28,168 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1199088383-172.17.0.4-1606980013387 (Datanode Uuid aae714b7-affe-4899-8582-7db48868bdef) service to localhost/127.0.0.1:44233 beginning handshake with NN
2020-12-03 07:20:28,168 [IPC Server handler 0 on default port 44233] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-e0706d8b-1d48-436b-a586-041594df8014 for DN 127.0.0.1:38875
2020-12-03 07:20:28,169 [IPC Server handler 0 on default port 44233] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-7c7a5fb3-6845-447a-a855-e677cf9028bc for DN 127.0.0.1:38875
2020-12-03 07:20:28,169 [IPC Server handler 5 on default port 44233] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:39670, datanodeUuid=ac43fde1-9305-4657-806e-9582c003dbfc, infoPort=41886, infoSecurePort=0, ipcPort=33533, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387) storage ac43fde1-9305-4657-806e-9582c003dbfc
2020-12-03 07:20:28,169 [IPC Server handler 5 on default port 44233] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:39670
2020-12-03 07:20:28,170 [IPC Server handler 5 on default port 44233] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN ac43fde1-9305-4657-806e-9582c003dbfc (127.0.0.1:39670).
2020-12-03 07:20:28,170 [IPC Server handler 0 on default port 44233] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:38140, datanodeUuid=aae714b7-affe-4899-8582-7db48868bdef, infoPort=39750, infoSecurePort=0, ipcPort=39371, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387) storage aae714b7-affe-4899-8582-7db48868bdef
2020-12-03 07:20:28,170 [IPC Server handler 0 on default port 44233] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38140
2020-12-03 07:20:28,172 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1199088383-172.17.0.4-1606980013387 (Datanode Uuid ac43fde1-9305-4657-806e-9582c003dbfc) service to localhost/127.0.0.1:44233 successfully registered with NN
2020-12-03 07:20:28,172 [IPC Server handler 0 on default port 44233] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN aae714b7-affe-4899-8582-7db48868bdef (127.0.0.1:38140).
2020-12-03 07:20:28,174 [IPC Server handler 4 on default port 44233] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:38718, datanodeUuid=13dd0217-9dd1-4416-9b7c-bf07e67f055d, infoPort=45384, infoSecurePort=0, ipcPort=33442, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387) storage 13dd0217-9dd1-4416-9b7c-bf07e67f055d
2020-12-03 07:20:28,174 [IPC Server handler 4 on default port 44233] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38718
2020-12-03 07:20:28,174 [IPC Server handler 4 on default port 44233] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 13dd0217-9dd1-4416-9b7c-bf07e67f055d (127.0.0.1:38718).
2020-12-03 07:20:28,174 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1199088383-172.17.0.4-1606980013387 (Datanode Uuid aae714b7-affe-4899-8582-7db48868bdef) service to localhost/127.0.0.1:44233 successfully registered with NN
2020-12-03 07:20:28,174 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xb9c4b4badfe23287: Processing first storage report for DS-ec353e10-93bc-4bc7-959e-05ad0de8bd77 from datanode 90214f51-5a35-447c-80e4-0159b8394987
2020-12-03 07:20:28,175 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xb9c4b4badfe23287: from storage DS-ec353e10-93bc-4bc7-959e-05ad0de8bd77 node DatanodeRegistration(127.0.0.1:37144, datanodeUuid=90214f51-5a35-447c-80e4-0159b8394987, infoPort=36080, infoSecurePort=0, ipcPort=37376, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:28,175 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1199088383-172.17.0.4-1606980013387 (Datanode Uuid 13dd0217-9dd1-4416-9b7c-bf07e67f055d) service to localhost/127.0.0.1:44233 successfully registered with NN
2020-12-03 07:20:28,175 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x37422f3f95ee8262: Processing first storage report for DS-7c7a5fb3-6845-447a-a855-e677cf9028bc from datanode aa46699a-faf3-419b-9673-7b32209adbf8
2020-12-03 07:20:28,175 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x37422f3f95ee8262: from storage DS-7c7a5fb3-6845-447a-a855-e677cf9028bc node DatanodeRegistration(127.0.0.1:38875, datanodeUuid=aa46699a-faf3-419b-9673-7b32209adbf8, infoPort=35718, infoSecurePort=0, ipcPort=38382, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:28,175 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xb9c4b4badfe23287: Processing first storage report for DS-e0b4f24e-24cd-44f5-8116-b2ae227fd08c from datanode 90214f51-5a35-447c-80e4-0159b8394987
2020-12-03 07:20:28,175 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xb9c4b4badfe23287: from storage DS-e0b4f24e-24cd-44f5-8116-b2ae227fd08c node DatanodeRegistration(127.0.0.1:37144, datanodeUuid=90214f51-5a35-447c-80e4-0159b8394987, infoPort=36080, infoSecurePort=0, ipcPort=37376, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:20:28,176 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x37422f3f95ee8262: Processing first storage report for DS-e0706d8b-1d48-436b-a586-041594df8014 from datanode aa46699a-faf3-419b-9673-7b32209adbf8
2020-12-03 07:20:28,176 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x37422f3f95ee8262: from storage DS-e0706d8b-1d48-436b-a586-041594df8014 node DatanodeRegistration(127.0.0.1:38875, datanodeUuid=aa46699a-faf3-419b-9673-7b32209adbf8, infoPort=35718, infoSecurePort=0, ipcPort=38382, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:28,177 [IPC Server handler 7 on default port 44233] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-9f3a827e-e2fe-44cb-bf3f-03dbde2b0b88 for DN 127.0.0.1:38140
2020-12-03 07:20:28,177 [IPC Server handler 7 on default port 44233] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-8888774b-8a84-448b-b3e5-a3adadd0d078 for DN 127.0.0.1:38140
2020-12-03 07:20:28,179 [IPC Server handler 8 on default port 44233] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-424ba2c6-e1c2-4264-9ece-472b5fa767aa for DN 127.0.0.1:39670
2020-12-03 07:20:28,179 [IPC Server handler 6 on default port 44233] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:28,179 [IPC Server handler 8 on default port 44233] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-75948b37-fc93-40b9-90df-eead8d830e52 for DN 127.0.0.1:39670
2020-12-03 07:20:28,180 [IPC Server handler 1 on default port 44233] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-ba213c2e-7d56-49cf-8c5f-d363ac2f32c7 for DN 127.0.0.1:38718
2020-12-03 07:20:28,180 [IPC Server handler 1 on default port 44233] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-a28f0b02-f8c5-4829-be0e-08394c72924d for DN 127.0.0.1:38718
2020-12-03 07:20:28,180 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xb9c4b4badfe23287,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 11 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:28,180 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:28,180 [Block report processor] WARN  BlockStateChange (BlockManager.java:processIncrementalBlockReport(4097)) - BLOCK* processIncrementalBlockReport is received from dead or unregistered node DatanodeRegistration(127.0.0.1:40206, datanodeUuid=3029aacb-7eaa-447f-9e36-1d53750951b1, infoPort=45942, infoSecurePort=0, ipcPort=43625, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387)
2020-12-03 07:20:28,180 [Listener at localhost/44233] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:28,181 [Listener at localhost/44233] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:28,181 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x37422f3f95ee8262,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 11 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:28,181 [Block report processor] ERROR BlockStateChange (NameNodeRpcServer.java:run(1641)) - *BLOCK* NameNode.blockReceivedAndDeleted: failed from DatanodeRegistration(127.0.0.1:40206, datanodeUuid=3029aacb-7eaa-447f-9e36-1d53750951b1, infoPort=45942, infoSecurePort=0, ipcPort=43625, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387): Got incremental block report from unregistered or dead node
2020-12-03 07:20:28,181 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:28,181 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x95c7948b55e994fd: Processing first storage report for DS-8888774b-8a84-448b-b3e5-a3adadd0d078 from datanode aae714b7-affe-4899-8582-7db48868bdef
2020-12-03 07:20:28,181 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x95c7948b55e994fd: from storage DS-8888774b-8a84-448b-b3e5-a3adadd0d078 node DatanodeRegistration(127.0.0.1:38140, datanodeUuid=aae714b7-affe-4899-8582-7db48868bdef, infoPort=39750, infoSecurePort=0, ipcPort=39371, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:28,181 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xa4fa3b562d6224b9: Processing first storage report for DS-424ba2c6-e1c2-4264-9ece-472b5fa767aa from datanode ac43fde1-9305-4657-806e-9582c003dbfc
2020-12-03 07:20:28,182 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xa4fa3b562d6224b9: from storage DS-424ba2c6-e1c2-4264-9ece-472b5fa767aa node DatanodeRegistration(127.0.0.1:39670, datanodeUuid=ac43fde1-9305-4657-806e-9582c003dbfc, infoPort=41886, infoSecurePort=0, ipcPort=33533, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:28,182 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xc76442dff4df8037: Processing first storage report for DS-ba213c2e-7d56-49cf-8c5f-d363ac2f32c7 from datanode 13dd0217-9dd1-4416-9b7c-bf07e67f055d
2020-12-03 07:20:28,182 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xc76442dff4df8037: from storage DS-ba213c2e-7d56-49cf-8c5f-d363ac2f32c7 node DatanodeRegistration(127.0.0.1:38718, datanodeUuid=13dd0217-9dd1-4416-9b7c-bf07e67f055d, infoPort=45384, infoSecurePort=0, ipcPort=33442, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:28,182 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x95c7948b55e994fd: Processing first storage report for DS-9f3a827e-e2fe-44cb-bf3f-03dbde2b0b88 from datanode aae714b7-affe-4899-8582-7db48868bdef
2020-12-03 07:20:28,182 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x95c7948b55e994fd: from storage DS-9f3a827e-e2fe-44cb-bf3f-03dbde2b0b88 node DatanodeRegistration(127.0.0.1:38140, datanodeUuid=aae714b7-affe-4899-8582-7db48868bdef, infoPort=39750, infoSecurePort=0, ipcPort=39371, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:28,182 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xa4fa3b562d6224b9: Processing first storage report for DS-75948b37-fc93-40b9-90df-eead8d830e52 from datanode ac43fde1-9305-4657-806e-9582c003dbfc
2020-12-03 07:20:28,182 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xa4fa3b562d6224b9: from storage DS-75948b37-fc93-40b9-90df-eead8d830e52 node DatanodeRegistration(127.0.0.1:39670, datanodeUuid=ac43fde1-9305-4657-806e-9582c003dbfc, infoPort=41886, infoSecurePort=0, ipcPort=33533, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:28,182 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xc76442dff4df8037: Processing first storage report for DS-a28f0b02-f8c5-4829-be0e-08394c72924d from datanode 13dd0217-9dd1-4416-9b7c-bf07e67f055d
2020-12-03 07:20:28,182 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xc76442dff4df8037: from storage DS-a28f0b02-f8c5-4829-be0e-08394c72924d node DatanodeRegistration(127.0.0.1:38718, datanodeUuid=13dd0217-9dd1-4416-9b7c-bf07e67f055d, infoPort=45384, infoSecurePort=0, ipcPort=33442, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:28,183 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xa4fa3b562d6224b9,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:28,183 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xc76442dff4df8037,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:28,183 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x95c7948b55e994fd,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:28,183 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:28,183 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:28,183 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:28,287 [IPC Server handler 9 on default port 44233] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:28,290 [Listener at localhost/44233] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:28,290 [Listener at localhost/44233] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:28,392 [IPC Server handler 7 on default port 44233] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:28,393 [Listener at localhost/44233] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:28,394 [Listener at localhost/44233] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:28,489 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActor(672)) - DatanodeCommand action : DNA_REGISTER from localhost/127.0.0.1:44233 with active state
2020-12-03 07:20:28,490 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1199088383-172.17.0.4-1606980013387 (Datanode Uuid 3029aacb-7eaa-447f-9e36-1d53750951b1) service to localhost/127.0.0.1:44233 beginning handshake with NN
2020-12-03 07:20:28,491 [IPC Server handler 6 on default port 44233] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:40206, datanodeUuid=3029aacb-7eaa-447f-9e36-1d53750951b1, infoPort=45942, infoSecurePort=0, ipcPort=43625, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387) storage 3029aacb-7eaa-447f-9e36-1d53750951b1
2020-12-03 07:20:28,491 [IPC Server handler 6 on default port 44233] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:40206
2020-12-03 07:20:28,491 [IPC Server handler 6 on default port 44233] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 3029aacb-7eaa-447f-9e36-1d53750951b1 (127.0.0.1:40206).
2020-12-03 07:20:28,492 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1199088383-172.17.0.4-1606980013387 (Datanode Uuid 3029aacb-7eaa-447f-9e36-1d53750951b1) service to localhost/127.0.0.1:44233 successfully registered with NN
2020-12-03 07:20:28,496 [IPC Server handler 1 on default port 44233] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-fafaff18-4de2-4bc2-bceb-3b8e48cbd859 for DN 127.0.0.1:40206
2020-12-03 07:20:28,496 [IPC Server handler 1 on default port 44233] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-4b096592-2cf9-441a-91b8-89f8826a3f3a for DN 127.0.0.1:40206
2020-12-03 07:20:28,499 [IPC Server handler 3 on default port 44233] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:28,500 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x2a2f48ede4d44568: Processing first storage report for DS-4b096592-2cf9-441a-91b8-89f8826a3f3a from datanode 3029aacb-7eaa-447f-9e36-1d53750951b1
2020-12-03 07:20:28,500 [Listener at localhost/44233] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:28,500 [Listener at localhost/44233] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:28,500 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x2a2f48ede4d44568: from storage DS-4b096592-2cf9-441a-91b8-89f8826a3f3a node DatanodeRegistration(127.0.0.1:40206, datanodeUuid=3029aacb-7eaa-447f-9e36-1d53750951b1, infoPort=45942, infoSecurePort=0, ipcPort=43625, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:28,500 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x2a2f48ede4d44568: Processing first storage report for DS-fafaff18-4de2-4bc2-bceb-3b8e48cbd859 from datanode 3029aacb-7eaa-447f-9e36-1d53750951b1
2020-12-03 07:20:28,501 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x2a2f48ede4d44568: from storage DS-fafaff18-4de2-4bc2-bceb-3b8e48cbd859 node DatanodeRegistration(127.0.0.1:40206, datanodeUuid=3029aacb-7eaa-447f-9e36-1d53750951b1, infoPort=45942, infoSecurePort=0, ipcPort=43625, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:28,501 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x2a2f48ede4d44568,  containing 2 storage report(s), of which we sent 2. The reports had 1 total blocks and used 1 RPC(s). This took 2 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:28,502 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:28,602 [IPC Server handler 0 on default port 44233] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:28,603 [Listener at localhost/44233] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:28,603 [Listener at localhost/44233] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:28,615 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActor(672)) - DatanodeCommand action : DNA_REGISTER from localhost/127.0.0.1:44233 with active state
2020-12-03 07:20:28,616 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1199088383-172.17.0.4-1606980013387 (Datanode Uuid 785f49e4-7600-4544-bff9-d9be9a31becb) service to localhost/127.0.0.1:44233 beginning handshake with NN
2020-12-03 07:20:28,617 [IPC Server handler 7 on default port 44233] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:43228, datanodeUuid=785f49e4-7600-4544-bff9-d9be9a31becb, infoPort=39224, infoSecurePort=0, ipcPort=43660, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387) storage 785f49e4-7600-4544-bff9-d9be9a31becb
2020-12-03 07:20:28,617 [IPC Server handler 7 on default port 44233] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:43228
2020-12-03 07:20:28,618 [IPC Server handler 7 on default port 44233] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 785f49e4-7600-4544-bff9-d9be9a31becb (127.0.0.1:43228).
2020-12-03 07:20:28,618 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1199088383-172.17.0.4-1606980013387 (Datanode Uuid 785f49e4-7600-4544-bff9-d9be9a31becb) service to localhost/127.0.0.1:44233 successfully registered with NN
2020-12-03 07:20:28,620 [IPC Server handler 8 on default port 44233] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-05e88003-7d71-45e9-9eec-ae795adefff3 for DN 127.0.0.1:43228
2020-12-03 07:20:28,620 [IPC Server handler 8 on default port 44233] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c1a89502-e5b9-42b4-9665-585863fffe34 for DN 127.0.0.1:43228
2020-12-03 07:20:28,622 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xa88f9fb9c8fc2c11: Processing first storage report for DS-c1a89502-e5b9-42b4-9665-585863fffe34 from datanode 785f49e4-7600-4544-bff9-d9be9a31becb
2020-12-03 07:20:28,622 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xa88f9fb9c8fc2c11: from storage DS-c1a89502-e5b9-42b4-9665-585863fffe34 node DatanodeRegistration(127.0.0.1:43228, datanodeUuid=785f49e4-7600-4544-bff9-d9be9a31becb, infoPort=39224, infoSecurePort=0, ipcPort=43660, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:28,622 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xa88f9fb9c8fc2c11: Processing first storage report for DS-05e88003-7d71-45e9-9eec-ae795adefff3 from datanode 785f49e4-7600-4544-bff9-d9be9a31becb
2020-12-03 07:20:28,622 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xa88f9fb9c8fc2c11: from storage DS-05e88003-7d71-45e9-9eec-ae795adefff3 node DatanodeRegistration(127.0.0.1:43228, datanodeUuid=785f49e4-7600-4544-bff9-d9be9a31becb, infoPort=39224, infoSecurePort=0, ipcPort=43660, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:28,623 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xa88f9fb9c8fc2c11,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:28,623 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:28,705 [IPC Server handler 6 on default port 44233] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:28,706 [Listener at localhost/44233] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:20:28,709 [IPC Server handler 1 on default port 44233] INFO  hdfs.StateChange (FSNamesystem.java:enterSafeMode(4674)) - STATE* Safe mode is ON.
It was turned on manually. Use "hdfs dfsadmin -safemode leave" to turn safe mode off.
2020-12-03 07:20:28,710 [IPC Server handler 1 on default port 44233] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_enter	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:28,714 [IPC Server handler 5 on default port 44233] INFO  namenode.FSImage (FSImage.java:saveNamespace(1147)) - Save namespace ...
2020-12-03 07:20:28,714 [IPC Server handler 5 on default port 44233] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 9, 9
2020-12-03 07:20:28,716 [IPC Server handler 5 on default port 44233] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 2 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 8 Number of syncs: 3 SyncTimes(ms): 1 2 
2020-12-03 07:20:28,717 [IPC Server handler 5 on default port 44233] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000009 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000009-0000000000000000010
2020-12-03 07:20:28,718 [IPC Server handler 5 on default port 44233] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000009 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000009-0000000000000000010
2020-12-03 07:20:28,728 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000010 using no compression
2020-12-03 07:20:28,728 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000010 using no compression
2020-12-03 07:20:28,744 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000010 of size 628 bytes saved in 0 seconds .
2020-12-03 07:20:28,744 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000010 of size 628 bytes saved in 0 seconds .
2020-12-03 07:20:28,876 [IPC Server handler 5 on default port 44233] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 2 images with txid >= 0
2020-12-03 07:20:29,084 [IPC Server handler 5 on default port 44233] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 11
2020-12-03 07:20:29,364 [IPC Server handler 5 on default port 44233] INFO  namenode.FSNamesystem (FSNamesystem.java:saveNamespace(4500)) - New namespace image has been created
2020-12-03 07:20:29,365 [IPC Server handler 5 on default port 44233] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=saveNamespace	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:29,369 [IPC Server handler 3 on default port 44233] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 2 secs
2020-12-03 07:20:29,369 [IPC Server handler 3 on default port 44233] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 1 racks and 9 datanodes
2020-12-03 07:20:29,369 [IPC Server handler 3 on default port 44233] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:20:29,369 [IPC Server handler 3 on default port 44233] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_leave	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:29,370 [Listener at localhost/44233] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:20:29,370 [Listener at localhost/44233] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:20:29,370 [Listener at localhost/44233] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 11, 11
2020-12-03 07:20:29,371 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@791d0edd] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:20:29,370 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@22aad006] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:20:29,374 [Listener at localhost/44233] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 2 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 1 1 
2020-12-03 07:20:29,375 [Listener at localhost/44233] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000011 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000011-0000000000000000012
2020-12-03 07:20:29,375 [Listener at localhost/44233] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000011 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000011-0000000000000000012
2020-12-03 07:20:29,376 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:20:29,376 [CacheReplicationMonitor(573879951)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:20:29,390 [Listener at localhost/44233] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 44233
2020-12-03 07:20:29,394 [IPC Server listener on 44233] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 44233
2020-12-03 07:20:29,394 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:29,397 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:20:29,397 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:20:29,405 [Listener at localhost/44233] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:20:29,406 [Listener at localhost/44233] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:20:29,409 [Listener at localhost/44233] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@18d348c3{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:20:29,411 [Listener at localhost/44233] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@511fa459{HTTP/1.1,[http/1.1]}{localhost:33418}
2020-12-03 07:20:29,411 [Listener at localhost/44233] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@495259fd{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:29,411 [Listener at localhost/44233] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5bb8d3fc{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:29,416 [Listener at localhost/44233] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:20:29,417 [Listener at localhost/44233] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-12-03 07:20:29,417 [Listener at localhost/44233] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://localhost:44233
2020-12-03 07:20:29,417 [Listener at localhost/44233] INFO  namenode.NameNode (NameNode.java:<init>(944)) - Clients should use localhost:44233 to access this namenode/service.
2020-12-03 07:20:29,521 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5f2cf35b] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:29,521 [Listener at localhost/44233] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:33418
2020-12-03 07:20:29,521 [Listener at localhost/44233] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:29,523 [Listener at localhost/44233] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:29,524 [Listener at localhost/44233] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:20:29,524 [Listener at localhost/44233] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:29,525 [Listener at localhost/44233] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:29,526 [Listener at localhost/44233] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:20:29,526 [Listener at localhost/44233] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:29,526 [Listener at localhost/44233] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:29,529 [Listener at localhost/44233] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:20:29,529 [Listener at localhost/44233] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:20:29,530 [Listener at localhost/44233] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 33418
2020-12-03 07:20:29,530 [Listener at localhost/44233] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:29,532 [Listener at localhost/44233] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@594e2f82{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:29,532 [Listener at localhost/44233] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@158171f9{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:29,538 [Listener at localhost/44233] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@d2141be{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:20:29,539 [Listener at localhost/44233] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6d2bca61{HTTP/1.1,[http/1.1]}{localhost:33418}
2020-12-03 07:20:29,540 [Listener at localhost/44233] INFO  server.Server (Server.java:doStart(419)) - Started @18828ms
2020-12-03 07:20:29,541 [Listener at localhost/44233] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:20:29,542 [Listener at localhost/44233] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:20:29,542 [Listener at localhost/44233] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:20:29,542 [Listener at localhost/44233] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:20:29,542 [Listener at localhost/44233] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:20:29,542 [Listener at localhost/44233] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:20:29,542 [Listener at localhost/44233] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:20:29,543 [Listener at localhost/44233] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:20:29,543 [Listener at localhost/44233] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:29,543 [Listener at localhost/44233] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:20:29,543 [Listener at localhost/44233] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:20:29,544 [Listener at localhost/44233] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:20:29,544 [Listener at localhost/44233] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:20:29
2020-12-03 07:20:29,544 [Listener at localhost/44233] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:20:29,544 [Listener at localhost/44233] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:29,544 [Listener at localhost/44233] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:20:29,544 [Listener at localhost/44233] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:20:29,548 [Listener at localhost/44233] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:20:29,548 [Listener at localhost/44233] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:20:29,548 [Listener at localhost/44233] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:20:29,548 [Listener at localhost/44233] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:20:29,548 [Listener at localhost/44233] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:20:29,549 [Listener at localhost/44233] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:20:29,549 [Listener at localhost/44233] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:20:29,549 [Listener at localhost/44233] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:20:29,549 [Listener at localhost/44233] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:20:29,549 [Listener at localhost/44233] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:20:29,549 [Listener at localhost/44233] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:20:29,549 [Listener at localhost/44233] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:20:29,549 [Listener at localhost/44233] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:20:29,550 [Listener at localhost/44233] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:20:29,550 [Listener at localhost/44233] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:29,550 [Listener at localhost/44233] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:20:29,550 [Listener at localhost/44233] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:20:29,552 [Listener at localhost/44233] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:20:29,552 [Listener at localhost/44233] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:20:29,552 [Listener at localhost/44233] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:20:29,552 [Listener at localhost/44233] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:20:29,552 [Listener at localhost/44233] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:20:29,552 [Listener at localhost/44233] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:20:29,552 [Listener at localhost/44233] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:20:29,552 [Listener at localhost/44233] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:29,553 [Listener at localhost/44233] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:20:29,553 [Listener at localhost/44233] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:20:29,553 [Listener at localhost/44233] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:20:29,553 [Listener at localhost/44233] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:20:29,554 [Listener at localhost/44233] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:20:29,554 [Listener at localhost/44233] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:20:29,554 [Listener at localhost/44233] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:20:29,554 [Listener at localhost/44233] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:20:29,554 [Listener at localhost/44233] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:29,554 [Listener at localhost/44233] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:20:29,554 [Listener at localhost/44233] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:20:29,631 [Listener at localhost/44233] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 900@9c826977c5c0
2020-12-03 07:20:29,715 [Listener at localhost/44233] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 900@9c826977c5c0
2020-12-03 07:20:29,717 [Listener at localhost/44233] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-12-03 07:20:29,717 [Listener at localhost/44233] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-12-03 07:20:29,718 [Listener at localhost/44233] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000010, cpktTxId=0000000000000000010)
2020-12-03 07:20:29,720 [Listener at localhost/44233] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 2 INodes.
2020-12-03 07:20:29,723 [Listener at localhost/44233] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:20:29,723 [Listener at localhost/44233] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 10 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000010
2020-12-03 07:20:29,723 [Listener at localhost/44233] INFO  namenode.FSImage (FSImage.java:loadEdits(910)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@23581e8d expecting start txid #11
2020-12-03 07:20:29,723 [Listener at localhost/44233] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000011-0000000000000000012, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000011-0000000000000000012 maxTxnsToRead = 9223372036854775807
2020-12-03 07:20:29,724 [Listener at localhost/44233] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000011-0000000000000000012' to transaction ID 11
2020-12-03 07:20:29,724 [Listener at localhost/44233] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(188)) - Loaded 1 edits file(s) (the last named /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000011-0000000000000000012, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000011-0000000000000000012) of total size 42.0, total edits 2.0, total load time 0.0 ms
2020-12-03 07:20:29,725 [Listener at localhost/44233] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:20:29,725 [Listener at localhost/44233] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 13
2020-12-03 07:20:30,005 [Listener at localhost/44233] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:20:30,005 [Listener at localhost/44233] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 449 msecs
2020-12-03 07:20:30,005 [Listener at localhost/44233] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:44233
2020-12-03 07:20:30,006 [Listener at localhost/44233] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:30,007 [Socket Reader #1 for port 44233] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 44233
2020-12-03 07:20:30,013 [Listener at localhost/44233] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:20:30,051 [Listener at localhost/44233] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 1
2020-12-03 07:20:30,052 [Listener at localhost/44233] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:20:30,053 [Listener at localhost/44233] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:20:30,053 [Listener at localhost/44233] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:20:30,053 [Listener at localhost/44233] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:20:30,057 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 1
2020-12-03 07:20:30,057 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:20:30,057 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:20:30,057 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:20:30,057 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 1
2020-12-03 07:20:30,057 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 4 msec
2020-12-03 07:20:30,060 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:30,060 [IPC Server listener on 44233] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 44233: starting
2020-12-03 07:20:30,062 [Listener at localhost/44233] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:44233
2020-12-03 07:20:30,062 [Listener at localhost/44233] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:20:30,062 [Listener at localhost/44233] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:20:30,063 [Listener at localhost/44233] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 0 milliseconds
name space=2
storage space=1207959552
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:20:30,066 [Listener at localhost/44233] WARN  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitClusterUp(1436)) - Waiting for the Mini HDFS Cluster to start...
2020-12-03 07:20:30,066 [CacheReplicationMonitor(1695538199)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:20:30,963 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] WARN  datanode.DataNode (BPServiceActor.java:offerService(731)) - IOException in offerService
java.io.EOFException: End of File Exception between local host is: "9c826977c5c0/172.17.0.4"; destination host is: "localhost":44233; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:791)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
	at com.sun.proxy.$Proxy25.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:168)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:517)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:648)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:849)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
2020-12-03 07:20:30,964 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] WARN  datanode.DataNode (BPServiceActor.java:offerService(731)) - IOException in offerService
java.io.EOFException: End of File Exception between local host is: "9c826977c5c0/172.17.0.4"; destination host is: "localhost":44233; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:791)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
	at com.sun.proxy.$Proxy25.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:168)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:517)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:648)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:849)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
2020-12-03 07:20:31,066 [Listener at localhost/44233] WARN  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitClusterUp(1436)) - Waiting for the Mini HDFS Cluster to start...
2020-12-03 07:20:31,173 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActor(672)) - DatanodeCommand action : DNA_REGISTER from localhost/127.0.0.1:44233 with active state
2020-12-03 07:20:31,173 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActor(672)) - DatanodeCommand action : DNA_REGISTER from localhost/127.0.0.1:44233 with active state
2020-12-03 07:20:31,174 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActor(672)) - DatanodeCommand action : DNA_REGISTER from localhost/127.0.0.1:44233 with active state
2020-12-03 07:20:31,175 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1199088383-172.17.0.4-1606980013387 (Datanode Uuid 90214f51-5a35-447c-80e4-0159b8394987) service to localhost/127.0.0.1:44233 beginning handshake with NN
2020-12-03 07:20:31,175 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1199088383-172.17.0.4-1606980013387 (Datanode Uuid aa46699a-faf3-419b-9673-7b32209adbf8) service to localhost/127.0.0.1:44233 beginning handshake with NN
2020-12-03 07:20:31,176 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActor(672)) - DatanodeCommand action : DNA_REGISTER from localhost/127.0.0.1:44233 with active state
2020-12-03 07:20:31,177 [IPC Server handler 7 on default port 44233] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:37144, datanodeUuid=90214f51-5a35-447c-80e4-0159b8394987, infoPort=36080, infoSecurePort=0, ipcPort=37376, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387) storage 90214f51-5a35-447c-80e4-0159b8394987
2020-12-03 07:20:31,177 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1199088383-172.17.0.4-1606980013387 (Datanode Uuid ac43fde1-9305-4657-806e-9582c003dbfc) service to localhost/127.0.0.1:44233 beginning handshake with NN
2020-12-03 07:20:31,177 [IPC Server handler 7 on default port 44233] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:37144
2020-12-03 07:20:31,177 [IPC Server handler 7 on default port 44233] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 90214f51-5a35-447c-80e4-0159b8394987 (127.0.0.1:37144).
2020-12-03 07:20:31,178 [IPC Server handler 9 on default port 44233] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:38875, datanodeUuid=aa46699a-faf3-419b-9673-7b32209adbf8, infoPort=35718, infoSecurePort=0, ipcPort=38382, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387) storage aa46699a-faf3-419b-9673-7b32209adbf8
2020-12-03 07:20:31,178 [IPC Server handler 9 on default port 44233] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38875
2020-12-03 07:20:31,179 [IPC Server handler 9 on default port 44233] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN aa46699a-faf3-419b-9673-7b32209adbf8 (127.0.0.1:38875).
2020-12-03 07:20:31,179 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1199088383-172.17.0.4-1606980013387 (Datanode Uuid 90214f51-5a35-447c-80e4-0159b8394987) service to localhost/127.0.0.1:44233 successfully registered with NN
2020-12-03 07:20:31,179 [IPC Server handler 0 on default port 44233] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:39670, datanodeUuid=ac43fde1-9305-4657-806e-9582c003dbfc, infoPort=41886, infoSecurePort=0, ipcPort=33533, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387) storage ac43fde1-9305-4657-806e-9582c003dbfc
2020-12-03 07:20:31,179 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1199088383-172.17.0.4-1606980013387 (Datanode Uuid aa46699a-faf3-419b-9673-7b32209adbf8) service to localhost/127.0.0.1:44233 successfully registered with NN
2020-12-03 07:20:31,179 [IPC Server handler 0 on default port 44233] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:39670
2020-12-03 07:20:31,179 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActor(672)) - DatanodeCommand action : DNA_REGISTER from localhost/127.0.0.1:44233 with active state
2020-12-03 07:20:31,179 [IPC Server handler 0 on default port 44233] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN ac43fde1-9305-4657-806e-9582c003dbfc (127.0.0.1:39670).
2020-12-03 07:20:31,179 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1199088383-172.17.0.4-1606980013387 (Datanode Uuid 13dd0217-9dd1-4416-9b7c-bf07e67f055d) service to localhost/127.0.0.1:44233 beginning handshake with NN
2020-12-03 07:20:31,180 [IPC Server handler 2 on default port 44233] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-e0b4f24e-24cd-44f5-8116-b2ae227fd08c for DN 127.0.0.1:37144
2020-12-03 07:20:31,180 [IPC Server handler 2 on default port 44233] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-ec353e10-93bc-4bc7-959e-05ad0de8bd77 for DN 127.0.0.1:37144
2020-12-03 07:20:31,181 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1199088383-172.17.0.4-1606980013387 (Datanode Uuid ac43fde1-9305-4657-806e-9582c003dbfc) service to localhost/127.0.0.1:44233 successfully registered with NN
2020-12-03 07:20:31,181 [IPC Server handler 6 on default port 44233] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:38718, datanodeUuid=13dd0217-9dd1-4416-9b7c-bf07e67f055d, infoPort=45384, infoSecurePort=0, ipcPort=33442, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387) storage 13dd0217-9dd1-4416-9b7c-bf07e67f055d
2020-12-03 07:20:31,181 [IPC Server handler 6 on default port 44233] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38718
2020-12-03 07:20:31,181 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1199088383-172.17.0.4-1606980013387 (Datanode Uuid aae714b7-affe-4899-8582-7db48868bdef) service to localhost/127.0.0.1:44233 beginning handshake with NN
2020-12-03 07:20:31,181 [IPC Server handler 6 on default port 44233] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 13dd0217-9dd1-4416-9b7c-bf07e67f055d (127.0.0.1:38718).
2020-12-03 07:20:31,182 [IPC Server handler 3 on default port 44233] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-e0706d8b-1d48-436b-a586-041594df8014 for DN 127.0.0.1:38875
2020-12-03 07:20:31,183 [IPC Server handler 3 on default port 44233] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-7c7a5fb3-6845-447a-a855-e677cf9028bc for DN 127.0.0.1:38875
2020-12-03 07:20:31,184 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1199088383-172.17.0.4-1606980013387 (Datanode Uuid 13dd0217-9dd1-4416-9b7c-bf07e67f055d) service to localhost/127.0.0.1:44233 successfully registered with NN
2020-12-03 07:20:31,184 [IPC Server handler 5 on default port 44233] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-424ba2c6-e1c2-4264-9ece-472b5fa767aa for DN 127.0.0.1:39670
2020-12-03 07:20:31,185 [IPC Server handler 5 on default port 44233] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-75948b37-fc93-40b9-90df-eead8d830e52 for DN 127.0.0.1:39670
2020-12-03 07:20:31,185 [IPC Server handler 7 on default port 44233] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:38140, datanodeUuid=aae714b7-affe-4899-8582-7db48868bdef, infoPort=39750, infoSecurePort=0, ipcPort=39371, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387) storage aae714b7-affe-4899-8582-7db48868bdef
2020-12-03 07:20:31,185 [IPC Server handler 7 on default port 44233] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38140
2020-12-03 07:20:31,185 [IPC Server handler 7 on default port 44233] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN aae714b7-affe-4899-8582-7db48868bdef (127.0.0.1:38140).
2020-12-03 07:20:31,185 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xb9c4b4badfe23288: Processing first storage report for DS-ec353e10-93bc-4bc7-959e-05ad0de8bd77 from datanode 90214f51-5a35-447c-80e4-0159b8394987
2020-12-03 07:20:31,186 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xb9c4b4badfe23288: from storage DS-ec353e10-93bc-4bc7-959e-05ad0de8bd77 node DatanodeRegistration(127.0.0.1:37144, datanodeUuid=90214f51-5a35-447c-80e4-0159b8394987, infoPort=36080, infoSecurePort=0, ipcPort=37376, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:31,186 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x37422f3f95ee8263: Processing first storage report for DS-7c7a5fb3-6845-447a-a855-e677cf9028bc from datanode aa46699a-faf3-419b-9673-7b32209adbf8
2020-12-03 07:20:31,186 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1199088383-172.17.0.4-1606980013387 (Datanode Uuid aae714b7-affe-4899-8582-7db48868bdef) service to localhost/127.0.0.1:44233 successfully registered with NN
2020-12-03 07:20:31,186 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x37422f3f95ee8263: from storage DS-7c7a5fb3-6845-447a-a855-e677cf9028bc node DatanodeRegistration(127.0.0.1:38875, datanodeUuid=aa46699a-faf3-419b-9673-7b32209adbf8, infoPort=35718, infoSecurePort=0, ipcPort=38382, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:20:31,187 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xb9c4b4badfe23288: Processing first storage report for DS-e0b4f24e-24cd-44f5-8116-b2ae227fd08c from datanode 90214f51-5a35-447c-80e4-0159b8394987
2020-12-03 07:20:31,187 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xb9c4b4badfe23288: from storage DS-e0b4f24e-24cd-44f5-8116-b2ae227fd08c node DatanodeRegistration(127.0.0.1:37144, datanodeUuid=90214f51-5a35-447c-80e4-0159b8394987, infoPort=36080, infoSecurePort=0, ipcPort=37376, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:31,187 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xa4fa3b562d6224ba: Processing first storage report for DS-424ba2c6-e1c2-4264-9ece-472b5fa767aa from datanode ac43fde1-9305-4657-806e-9582c003dbfc
2020-12-03 07:20:31,187 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xa4fa3b562d6224ba: from storage DS-424ba2c6-e1c2-4264-9ece-472b5fa767aa node DatanodeRegistration(127.0.0.1:39670, datanodeUuid=ac43fde1-9305-4657-806e-9582c003dbfc, infoPort=41886, infoSecurePort=0, ipcPort=33533, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:31,187 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x37422f3f95ee8263: Processing first storage report for DS-e0706d8b-1d48-436b-a586-041594df8014 from datanode aa46699a-faf3-419b-9673-7b32209adbf8
2020-12-03 07:20:31,187 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x37422f3f95ee8263: from storage DS-e0706d8b-1d48-436b-a586-041594df8014 node DatanodeRegistration(127.0.0.1:38875, datanodeUuid=aa46699a-faf3-419b-9673-7b32209adbf8, infoPort=35718, infoSecurePort=0, ipcPort=38382, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:31,187 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xa4fa3b562d6224ba: Processing first storage report for DS-75948b37-fc93-40b9-90df-eead8d830e52 from datanode ac43fde1-9305-4657-806e-9582c003dbfc
2020-12-03 07:20:31,187 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xa4fa3b562d6224ba: from storage DS-75948b37-fc93-40b9-90df-eead8d830e52 node DatanodeRegistration(127.0.0.1:39670, datanodeUuid=ac43fde1-9305-4657-806e-9582c003dbfc, infoPort=41886, infoSecurePort=0, ipcPort=33533, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:20:31,189 [IPC Server handler 8 on default port 44233] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-ba213c2e-7d56-49cf-8c5f-d363ac2f32c7 for DN 127.0.0.1:38718
2020-12-03 07:20:31,189 [IPC Server handler 8 on default port 44233] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-a28f0b02-f8c5-4829-be0e-08394c72924d for DN 127.0.0.1:38718
2020-12-03 07:20:31,190 [IPC Server handler 4 on default port 44233] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-9f3a827e-e2fe-44cb-bf3f-03dbde2b0b88 for DN 127.0.0.1:38140
2020-12-03 07:20:31,190 [IPC Server handler 4 on default port 44233] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-8888774b-8a84-448b-b3e5-a3adadd0d078 for DN 127.0.0.1:38140
2020-12-03 07:20:31,190 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xb9c4b4badfe23288,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 8 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:31,190 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xa4fa3b562d6224ba,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 5 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:31,190 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:31,190 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x37422f3f95ee8263,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 5 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:31,190 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:31,191 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:31,191 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xc76442dff4df8038: Processing first storage report for DS-ba213c2e-7d56-49cf-8c5f-d363ac2f32c7 from datanode 13dd0217-9dd1-4416-9b7c-bf07e67f055d
2020-12-03 07:20:31,191 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xc76442dff4df8038: from storage DS-ba213c2e-7d56-49cf-8c5f-d363ac2f32c7 node DatanodeRegistration(127.0.0.1:38718, datanodeUuid=13dd0217-9dd1-4416-9b7c-bf07e67f055d, infoPort=45384, infoSecurePort=0, ipcPort=33442, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:31,191 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xc76442dff4df8038: Processing first storage report for DS-a28f0b02-f8c5-4829-be0e-08394c72924d from datanode 13dd0217-9dd1-4416-9b7c-bf07e67f055d
2020-12-03 07:20:31,191 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xc76442dff4df8038: from storage DS-a28f0b02-f8c5-4829-be0e-08394c72924d node DatanodeRegistration(127.0.0.1:38718, datanodeUuid=13dd0217-9dd1-4416-9b7c-bf07e67f055d, infoPort=45384, infoSecurePort=0, ipcPort=33442, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:31,192 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x95c7948b55e994fe: Processing first storage report for DS-8888774b-8a84-448b-b3e5-a3adadd0d078 from datanode aae714b7-affe-4899-8582-7db48868bdef
2020-12-03 07:20:31,192 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x95c7948b55e994fe: from storage DS-8888774b-8a84-448b-b3e5-a3adadd0d078 node DatanodeRegistration(127.0.0.1:38140, datanodeUuid=aae714b7-affe-4899-8582-7db48868bdef, infoPort=39750, infoSecurePort=0, ipcPort=39371, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:31,192 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x95c7948b55e994fe: Processing first storage report for DS-9f3a827e-e2fe-44cb-bf3f-03dbde2b0b88 from datanode aae714b7-affe-4899-8582-7db48868bdef
2020-12-03 07:20:31,192 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x95c7948b55e994fe: from storage DS-9f3a827e-e2fe-44cb-bf3f-03dbde2b0b88 node DatanodeRegistration(127.0.0.1:38140, datanodeUuid=aae714b7-affe-4899-8582-7db48868bdef, infoPort=39750, infoSecurePort=0, ipcPort=39371, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:31,192 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xc76442dff4df8038,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:31,192 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:31,193 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x95c7948b55e994fe,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:31,193 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:31,494 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActor(672)) - DatanodeCommand action : DNA_REGISTER from localhost/127.0.0.1:44233 with active state
2020-12-03 07:20:31,495 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1199088383-172.17.0.4-1606980013387 (Datanode Uuid 3029aacb-7eaa-447f-9e36-1d53750951b1) service to localhost/127.0.0.1:44233 beginning handshake with NN
2020-12-03 07:20:31,496 [IPC Server handler 7 on default port 44233] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:40206, datanodeUuid=3029aacb-7eaa-447f-9e36-1d53750951b1, infoPort=45942, infoSecurePort=0, ipcPort=43625, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387) storage 3029aacb-7eaa-447f-9e36-1d53750951b1
2020-12-03 07:20:31,497 [IPC Server handler 7 on default port 44233] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:40206
2020-12-03 07:20:31,497 [IPC Server handler 7 on default port 44233] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 3029aacb-7eaa-447f-9e36-1d53750951b1 (127.0.0.1:40206).
2020-12-03 07:20:31,498 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1199088383-172.17.0.4-1606980013387 (Datanode Uuid 3029aacb-7eaa-447f-9e36-1d53750951b1) service to localhost/127.0.0.1:44233 successfully registered with NN
2020-12-03 07:20:31,500 [IPC Server handler 8 on default port 44233] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-fafaff18-4de2-4bc2-bceb-3b8e48cbd859 for DN 127.0.0.1:40206
2020-12-03 07:20:31,500 [IPC Server handler 8 on default port 44233] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-4b096592-2cf9-441a-91b8-89f8826a3f3a for DN 127.0.0.1:40206
2020-12-03 07:20:31,502 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x2a2f48ede4d44569: Processing first storage report for DS-4b096592-2cf9-441a-91b8-89f8826a3f3a from datanode 3029aacb-7eaa-447f-9e36-1d53750951b1
2020-12-03 07:20:31,502 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x2a2f48ede4d44569: from storage DS-4b096592-2cf9-441a-91b8-89f8826a3f3a node DatanodeRegistration(127.0.0.1:40206, datanodeUuid=3029aacb-7eaa-447f-9e36-1d53750951b1, infoPort=45942, infoSecurePort=0, ipcPort=43625, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:31,502 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x2a2f48ede4d44569: Processing first storage report for DS-fafaff18-4de2-4bc2-bceb-3b8e48cbd859 from datanode 3029aacb-7eaa-447f-9e36-1d53750951b1
2020-12-03 07:20:31,503 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x2a2f48ede4d44569: from storage DS-fafaff18-4de2-4bc2-bceb-3b8e48cbd859 node DatanodeRegistration(127.0.0.1:40206, datanodeUuid=3029aacb-7eaa-447f-9e36-1d53750951b1, infoPort=45942, infoSecurePort=0, ipcPort=43625, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:31,503 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x2a2f48ede4d44569,  containing 2 storage report(s), of which we sent 2. The reports had 1 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:31,503 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:31,621 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActor(672)) - DatanodeCommand action : DNA_REGISTER from localhost/127.0.0.1:44233 with active state
2020-12-03 07:20:31,622 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1199088383-172.17.0.4-1606980013387 (Datanode Uuid 785f49e4-7600-4544-bff9-d9be9a31becb) service to localhost/127.0.0.1:44233 beginning handshake with NN
2020-12-03 07:20:31,623 [IPC Server handler 4 on default port 44233] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:43228, datanodeUuid=785f49e4-7600-4544-bff9-d9be9a31becb, infoPort=39224, infoSecurePort=0, ipcPort=43660, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387) storage 785f49e4-7600-4544-bff9-d9be9a31becb
2020-12-03 07:20:31,623 [IPC Server handler 4 on default port 44233] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:43228
2020-12-03 07:20:31,624 [IPC Server handler 4 on default port 44233] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 785f49e4-7600-4544-bff9-d9be9a31becb (127.0.0.1:43228).
2020-12-03 07:20:31,624 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1199088383-172.17.0.4-1606980013387 (Datanode Uuid 785f49e4-7600-4544-bff9-d9be9a31becb) service to localhost/127.0.0.1:44233 successfully registered with NN
2020-12-03 07:20:31,626 [IPC Server handler 2 on default port 44233] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-05e88003-7d71-45e9-9eec-ae795adefff3 for DN 127.0.0.1:43228
2020-12-03 07:20:31,626 [IPC Server handler 2 on default port 44233] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c1a89502-e5b9-42b4-9665-585863fffe34 for DN 127.0.0.1:43228
2020-12-03 07:20:31,628 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xa88f9fb9c8fc2c12: Processing first storage report for DS-c1a89502-e5b9-42b4-9665-585863fffe34 from datanode 785f49e4-7600-4544-bff9-d9be9a31becb
2020-12-03 07:20:31,628 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xa88f9fb9c8fc2c12: from storage DS-c1a89502-e5b9-42b4-9665-585863fffe34 node DatanodeRegistration(127.0.0.1:43228, datanodeUuid=785f49e4-7600-4544-bff9-d9be9a31becb, infoPort=39224, infoSecurePort=0, ipcPort=43660, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:31,628 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xa88f9fb9c8fc2c12: Processing first storage report for DS-05e88003-7d71-45e9-9eec-ae795adefff3 from datanode 785f49e4-7600-4544-bff9-d9be9a31becb
2020-12-03 07:20:31,628 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xa88f9fb9c8fc2c12: from storage DS-05e88003-7d71-45e9-9eec-ae795adefff3 node DatanodeRegistration(127.0.0.1:43228, datanodeUuid=785f49e4-7600-4544-bff9-d9be9a31becb, infoPort=39224, infoSecurePort=0, ipcPort=43660, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:20:31,629 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xa88f9fb9c8fc2c12,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:31,629 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:32,067 [Listener at localhost/44233] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:restartNameNode(2191)) - Restarted the namenode
2020-12-03 07:20:32,074 [IPC Server handler 3 on default port 44233] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:32,076 [Listener at localhost/44233] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:32,076 [Listener at localhost/44233] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:32,178 [IPC Server handler 5 on default port 44233] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:32,182 [Listener at localhost/44233] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:32,182 [Listener at localhost/44233] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:32,283 [IPC Server handler 7 on default port 44233] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:32,285 [Listener at localhost/44233] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:32,285 [Listener at localhost/44233] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:32,387 [IPC Server handler 8 on default port 44233] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:32,388 [Listener at localhost/44233] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:32,388 [Listener at localhost/44233] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:32,489 [IPC Server handler 9 on default port 44233] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:32,490 [Listener at localhost/44233] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:32,491 [Listener at localhost/44233] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:32,592 [IPC Server handler 1 on default port 44233] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:32,593 [Listener at localhost/44233] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:32,593 [Listener at localhost/44233] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:32,695 [IPC Server handler 3 on default port 44233] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:32,696 [Listener at localhost/44233] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:32,696 [Listener at localhost/44233] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:32,797 [IPC Server handler 5 on default port 44233] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:32,798 [Listener at localhost/44233] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:32,798 [Listener at localhost/44233] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:32,900 [IPC Server handler 7 on default port 44233] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:32,901 [Listener at localhost/44233] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:32,901 [Listener at localhost/44233] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:33,002 [IPC Server handler 8 on default port 44233] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:33,003 [Listener at localhost/44233] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:33,004 [Listener at localhost/44233] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:33,105 [IPC Server handler 9 on default port 44233] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:33,107 [Listener at localhost/44233] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:33,107 [Listener at localhost/44233] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:33,208 [IPC Server handler 1 on default port 44233] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:33,209 [Listener at localhost/44233] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:33,210 [Listener at localhost/44233] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:33,311 [IPC Server handler 0 on default port 44233] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:33,312 [Listener at localhost/44233] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:33,312 [Listener at localhost/44233] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:33,414 [IPC Server handler 4 on default port 44233] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:33,415 [Listener at localhost/44233] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:33,415 [Listener at localhost/44233] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:33,516 [IPC Server handler 2 on default port 44233] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:33,517 [Listener at localhost/44233] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:33,517 [Listener at localhost/44233] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:33,618 [IPC Server handler 6 on default port 44233] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:33,619 [Listener at localhost/44233] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:33,619 [Listener at localhost/44233] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:33,721 [IPC Server handler 5 on default port 44233] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:33,722 [Listener at localhost/44233] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:33,722 [Listener at localhost/44233] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:33,823 [IPC Server handler 7 on default port 44233] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:33,824 [Listener at localhost/44233] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:33,824 [Listener at localhost/44233] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:33,925 [IPC Server handler 8 on default port 44233] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:33,926 [Listener at localhost/44233] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:33,926 [Listener at localhost/44233] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:33,963 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActor(672)) - DatanodeCommand action : DNA_REGISTER from localhost/127.0.0.1:44233 with active state
2020-12-03 07:20:33,963 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActor(672)) - DatanodeCommand action : DNA_REGISTER from localhost/127.0.0.1:44233 with active state
2020-12-03 07:20:33,964 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1199088383-172.17.0.4-1606980013387 (Datanode Uuid 2c0b9200-a808-454b-aeae-39910540cca5) service to localhost/127.0.0.1:44233 beginning handshake with NN
2020-12-03 07:20:33,964 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1199088383-172.17.0.4-1606980013387 (Datanode Uuid 3c6cb142-24b8-4ba9-8bce-390f3aeb2056) service to localhost/127.0.0.1:44233 beginning handshake with NN
2020-12-03 07:20:33,965 [IPC Server handler 2 on default port 44233] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:36016, datanodeUuid=2c0b9200-a808-454b-aeae-39910540cca5, infoPort=37163, infoSecurePort=0, ipcPort=32843, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387) storage 2c0b9200-a808-454b-aeae-39910540cca5
2020-12-03 07:20:33,966 [IPC Server handler 2 on default port 44233] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36016
2020-12-03 07:20:33,966 [IPC Server handler 2 on default port 44233] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 2c0b9200-a808-454b-aeae-39910540cca5 (127.0.0.1:36016).
2020-12-03 07:20:33,966 [IPC Server handler 6 on default port 44233] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:37359, datanodeUuid=3c6cb142-24b8-4ba9-8bce-390f3aeb2056, infoPort=38706, infoSecurePort=0, ipcPort=40783, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387) storage 3c6cb142-24b8-4ba9-8bce-390f3aeb2056
2020-12-03 07:20:33,966 [IPC Server handler 6 on default port 44233] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:37359
2020-12-03 07:20:33,966 [IPC Server handler 6 on default port 44233] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 3c6cb142-24b8-4ba9-8bce-390f3aeb2056 (127.0.0.1:37359).
2020-12-03 07:20:33,966 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1199088383-172.17.0.4-1606980013387 (Datanode Uuid 2c0b9200-a808-454b-aeae-39910540cca5) service to localhost/127.0.0.1:44233 successfully registered with NN
2020-12-03 07:20:33,967 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1199088383-172.17.0.4-1606980013387 (Datanode Uuid 3c6cb142-24b8-4ba9-8bce-390f3aeb2056) service to localhost/127.0.0.1:44233 successfully registered with NN
2020-12-03 07:20:33,969 [IPC Server handler 3 on default port 44233] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-53ebb263-a519-4e04-8516-6895b2684e49 for DN 127.0.0.1:36016
2020-12-03 07:20:33,969 [IPC Server handler 3 on default port 44233] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-604aa382-053e-4d29-ae14-d8159a125483 for DN 127.0.0.1:36016
2020-12-03 07:20:33,969 [IPC Server handler 5 on default port 44233] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-9637c4ad-4b9f-4743-85c8-8b3b2981aad6 for DN 127.0.0.1:37359
2020-12-03 07:20:33,970 [IPC Server handler 5 on default port 44233] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-89b6f46a-278e-49c3-b219-2a6fc902ef6b for DN 127.0.0.1:37359
2020-12-03 07:20:33,971 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xff4a5452b3f8a416: Processing first storage report for DS-53ebb263-a519-4e04-8516-6895b2684e49 from datanode 2c0b9200-a808-454b-aeae-39910540cca5
2020-12-03 07:20:33,971 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xff4a5452b3f8a416: from storage DS-53ebb263-a519-4e04-8516-6895b2684e49 node DatanodeRegistration(127.0.0.1:36016, datanodeUuid=2c0b9200-a808-454b-aeae-39910540cca5, infoPort=37163, infoSecurePort=0, ipcPort=32843, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:33,971 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x74e17781f4d118c: Processing first storage report for DS-89b6f46a-278e-49c3-b219-2a6fc902ef6b from datanode 3c6cb142-24b8-4ba9-8bce-390f3aeb2056
2020-12-03 07:20:33,971 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x74e17781f4d118c: from storage DS-89b6f46a-278e-49c3-b219-2a6fc902ef6b node DatanodeRegistration(127.0.0.1:37359, datanodeUuid=3c6cb142-24b8-4ba9-8bce-390f3aeb2056, infoPort=38706, infoSecurePort=0, ipcPort=40783, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:33,971 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xff4a5452b3f8a416: Processing first storage report for DS-604aa382-053e-4d29-ae14-d8159a125483 from datanode 2c0b9200-a808-454b-aeae-39910540cca5
2020-12-03 07:20:33,971 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xff4a5452b3f8a416: from storage DS-604aa382-053e-4d29-ae14-d8159a125483 node DatanodeRegistration(127.0.0.1:36016, datanodeUuid=2c0b9200-a808-454b-aeae-39910540cca5, infoPort=37163, infoSecurePort=0, ipcPort=32843, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:33,971 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x74e17781f4d118c: Processing first storage report for DS-9637c4ad-4b9f-4743-85c8-8b3b2981aad6 from datanode 3c6cb142-24b8-4ba9-8bce-390f3aeb2056
2020-12-03 07:20:33,971 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x74e17781f4d118c: from storage DS-9637c4ad-4b9f-4743-85c8-8b3b2981aad6 node DatanodeRegistration(127.0.0.1:37359, datanodeUuid=3c6cb142-24b8-4ba9-8bce-390f3aeb2056, infoPort=38706, infoSecurePort=0, ipcPort=40783, storageInfo=lv=-57;cid=testClusterID;nsid=267665338;c=1606980013387), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:33,972 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xff4a5452b3f8a416,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:33,972 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x74e17781f4d118c,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:20:33,972 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:33,972 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:34,038 [IPC Server handler 9 on default port 44233] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:34,040 [Listener at localhost/44233] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:20:34,053 [Thread-359] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:34,053 [Thread-358] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:34,053 [Thread-360] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:34,056 [DataXceiver for client DFSClient_NONMAPREDUCE_1275747404_24 at /127.0.0.1:55344 [Receiving block BP-1199088383-172.17.0.4-1606980013387:blk_-9223372036854775785_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1199088383-172.17.0.4-1606980013387:blk_-9223372036854775785_1001 src: /127.0.0.1:55344 dest: /127.0.0.1:38875
2020-12-03 07:20:34,056 [DataXceiver for client DFSClient_NONMAPREDUCE_1275747404_24 at /127.0.0.1:41796 [Receiving block BP-1199088383-172.17.0.4-1606980013387:blk_-9223372036854775786_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1199088383-172.17.0.4-1606980013387:blk_-9223372036854775786_1001 src: /127.0.0.1:41796 dest: /127.0.0.1:36016
2020-12-03 07:20:34,056 [DataXceiver for client DFSClient_NONMAPREDUCE_1275747404_24 at /127.0.0.1:58606 [Receiving block BP-1199088383-172.17.0.4-1606980013387:blk_-9223372036854775784_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1199088383-172.17.0.4-1606980013387:blk_-9223372036854775784_1001 src: /127.0.0.1:58606 dest: /127.0.0.1:37144
2020-12-03 07:20:34,555 [PacketResponder: BP-1199088383-172.17.0.4-1606980013387:blk_-9223372036854775792_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:36202, dest: /127.0.0.1:40206, bytes: 4609, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1275747404_24, offset: 0, srvID: 3029aacb-7eaa-447f-9e36-1d53750951b1, blockid: BP-1199088383-172.17.0.4-1606980013387:blk_-9223372036854775792_1001, duration(ns): 10739422332
2020-12-03 07:20:34,555 [PacketResponder: BP-1199088383-172.17.0.4-1606980013387:blk_-9223372036854775792_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1199088383-172.17.0.4-1606980013387:blk_-9223372036854775792_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:20:34,560 [PacketResponder: BP-1199088383-172.17.0.4-1606980013387:blk_-9223372036854775786_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41796, dest: /127.0.0.1:36016, bytes: 4609, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1275747404_24, offset: 0, srvID: 2c0b9200-a808-454b-aeae-39910540cca5, blockid: BP-1199088383-172.17.0.4-1606980013387:blk_-9223372036854775786_1001, duration(ns): 288742059
2020-12-03 07:20:34,561 [PacketResponder: BP-1199088383-172.17.0.4-1606980013387:blk_-9223372036854775786_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1199088383-172.17.0.4-1606980013387:blk_-9223372036854775786_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:20:34,564 [PacketResponder: BP-1199088383-172.17.0.4-1606980013387:blk_-9223372036854775785_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55344, dest: /127.0.0.1:38875, bytes: 4609, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1275747404_24, offset: 0, srvID: aa46699a-faf3-419b-9673-7b32209adbf8, blockid: BP-1199088383-172.17.0.4-1606980013387:blk_-9223372036854775785_1001, duration(ns): 292193835
2020-12-03 07:20:34,565 [PacketResponder: BP-1199088383-172.17.0.4-1606980013387:blk_-9223372036854775785_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1199088383-172.17.0.4-1606980013387:blk_-9223372036854775785_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:20:34,622 [PacketResponder: BP-1199088383-172.17.0.4-1606980013387:blk_-9223372036854775784_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58606, dest: /127.0.0.1:37144, bytes: 4609, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1275747404_24, offset: 0, srvID: 90214f51-5a35-447c-80e4-0159b8394987, blockid: BP-1199088383-172.17.0.4-1606980013387:blk_-9223372036854775784_1001, duration(ns): 293788161
2020-12-03 07:20:34,622 [PacketResponder: BP-1199088383-172.17.0.4-1606980013387:blk_-9223372036854775784_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1199088383-172.17.0.4-1606980013387:blk_-9223372036854775784_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:20:34,632 [IPC Server handler 4 on default port 44233] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /file1 is closed by DFSClient_NONMAPREDUCE_1275747404_24
2020-12-03 07:20:34,636 [Listener at localhost/43660] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:20:34,637 [Listener at localhost/43660] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 8
2020-12-03 07:20:34,637 [Listener at localhost/43660] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:34,637 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@3889f955] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:34,638 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-c1a89502-e5b9-42b4-9665-585863fffe34) exiting.
2020-12-03 07:20:34,638 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-05e88003-7d71-45e9-9eec-ae795adefff3) exiting.
2020-12-03 07:20:34,661 [Listener at localhost/43660] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@4a1b4671{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:34,661 [Listener at localhost/43660] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7961de36{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:34,663 [Listener at localhost/43660] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@47723f65{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:34,663 [Listener at localhost/43660] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@56a6d42a{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:34,664 [Listener at localhost/43660] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 43660
2020-12-03 07:20:34,666 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:34,666 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:34,667 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:34,667 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1199088383-172.17.0.4-1606980013387 (Datanode Uuid 785f49e4-7600-4544-bff9-d9be9a31becb) service to localhost/127.0.0.1:44233
2020-12-03 07:20:34,668 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1199088383-172.17.0.4-1606980013387 (Datanode Uuid 785f49e4-7600-4544-bff9-d9be9a31becb)
2020-12-03 07:20:34,668 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:34,668 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1199088383-172.17.0.4-1606980013387] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:34,669 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1199088383-172.17.0.4-1606980013387] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:34,672 [Listener at localhost/43660] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:34,672 [Listener at localhost/43660] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:34,672 [Listener at localhost/43660] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:34,672 [Listener at localhost/43660] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:34,675 [Listener at localhost/43660] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:34,675 [Listener at localhost/43660] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 7
2020-12-03 07:20:34,675 [Listener at localhost/43660] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:34,675 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@76185e29] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:34,676 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-4b096592-2cf9-441a-91b8-89f8826a3f3a) exiting.
2020-12-03 07:20:34,676 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-fafaff18-4de2-4bc2-bceb-3b8e48cbd859) exiting.
2020-12-03 07:20:34,700 [Listener at localhost/43660] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1e6ec59e{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:34,700 [Listener at localhost/43660] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@251a4318{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:34,701 [Listener at localhost/43660] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@23820214{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:34,701 [Listener at localhost/43660] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@d0d3c7d{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:34,702 [Listener at localhost/43660] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 43625
2020-12-03 07:20:34,704 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:34,704 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:34,704 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:34,706 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1199088383-172.17.0.4-1606980013387 (Datanode Uuid 3029aacb-7eaa-447f-9e36-1d53750951b1) service to localhost/127.0.0.1:44233
2020-12-03 07:20:34,706 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1199088383-172.17.0.4-1606980013387 (Datanode Uuid 3029aacb-7eaa-447f-9e36-1d53750951b1)
2020-12-03 07:20:34,706 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:34,707 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1199088383-172.17.0.4-1606980013387] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:34,707 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1199088383-172.17.0.4-1606980013387] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:34,711 [Listener at localhost/43660] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:34,711 [Listener at localhost/43660] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:34,712 [Listener at localhost/43660] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:34,712 [Listener at localhost/43660] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:34,714 [Listener at localhost/43660] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:34,714 [Listener at localhost/43660] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 6
2020-12-03 07:20:34,714 [Listener at localhost/43660] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:34,714 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@4ed97ea2] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:34,715 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-e0b4f24e-24cd-44f5-8116-b2ae227fd08c) exiting.
2020-12-03 07:20:34,715 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-ec353e10-93bc-4bc7-959e-05ad0de8bd77) exiting.
2020-12-03 07:20:34,737 [Listener at localhost/43660] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@3416b965{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:34,738 [Listener at localhost/43660] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2a7cc383{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:34,739 [Listener at localhost/43660] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@63fd3e8c{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:34,739 [Listener at localhost/43660] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@14de1c31{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:34,740 [Listener at localhost/43660] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 37376
2020-12-03 07:20:34,742 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:34,742 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:34,744 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:34,744 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1199088383-172.17.0.4-1606980013387 (Datanode Uuid 90214f51-5a35-447c-80e4-0159b8394987) service to localhost/127.0.0.1:44233
2020-12-03 07:20:34,744 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1199088383-172.17.0.4-1606980013387 (Datanode Uuid 90214f51-5a35-447c-80e4-0159b8394987)
2020-12-03 07:20:34,744 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:34,745 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1199088383-172.17.0.4-1606980013387] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:34,750 [Listener at localhost/43660] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:34,750 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1199088383-172.17.0.4-1606980013387] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:34,750 [Listener at localhost/43660] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:34,751 [Listener at localhost/43660] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:34,751 [Listener at localhost/43660] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:34,754 [Listener at localhost/43660] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:34,754 [Listener at localhost/43660] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 5
2020-12-03 07:20:34,754 [Listener at localhost/43660] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:34,754 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@20787214] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:34,755 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-a28f0b02-f8c5-4829-be0e-08394c72924d) exiting.
2020-12-03 07:20:34,755 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-ba213c2e-7d56-49cf-8c5f-d363ac2f32c7) exiting.
2020-12-03 07:20:34,780 [Listener at localhost/43660] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@172edb72{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:34,781 [Listener at localhost/43660] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@f0449e6{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:34,781 [Listener at localhost/43660] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@61e479e4{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:34,782 [Listener at localhost/43660] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@20489d{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:34,783 [Listener at localhost/43660] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 33442
2020-12-03 07:20:34,786 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:34,789 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:34,789 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:34,789 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1199088383-172.17.0.4-1606980013387 (Datanode Uuid 13dd0217-9dd1-4416-9b7c-bf07e67f055d) service to localhost/127.0.0.1:44233
2020-12-03 07:20:34,789 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1199088383-172.17.0.4-1606980013387 (Datanode Uuid 13dd0217-9dd1-4416-9b7c-bf07e67f055d)
2020-12-03 07:20:34,789 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:34,790 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1199088383-172.17.0.4-1606980013387] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:34,790 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1199088383-172.17.0.4-1606980013387] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:34,797 [Listener at localhost/43660] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:34,797 [Listener at localhost/43660] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:34,799 [Listener at localhost/43660] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:34,799 [Listener at localhost/43660] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:34,803 [Listener at localhost/43660] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:34,803 [Listener at localhost/43660] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 4
2020-12-03 07:20:34,803 [Listener at localhost/43660] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:34,803 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@40815757] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:34,805 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-424ba2c6-e1c2-4264-9ece-472b5fa767aa) exiting.
2020-12-03 07:20:34,805 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-75948b37-fc93-40b9-90df-eead8d830e52) exiting.
2020-12-03 07:20:34,823 [Listener at localhost/43660] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5c119a66{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:34,823 [Listener at localhost/43660] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@103f2cb1{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:34,824 [Listener at localhost/43660] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@384491cb{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:34,824 [Listener at localhost/43660] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@de066c{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:34,825 [Listener at localhost/43660] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 33533
2020-12-03 07:20:34,829 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:34,829 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:34,829 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:34,829 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1199088383-172.17.0.4-1606980013387 (Datanode Uuid ac43fde1-9305-4657-806e-9582c003dbfc) service to localhost/127.0.0.1:44233
2020-12-03 07:20:34,831 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1199088383-172.17.0.4-1606980013387 (Datanode Uuid ac43fde1-9305-4657-806e-9582c003dbfc)
2020-12-03 07:20:34,831 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:34,832 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1199088383-172.17.0.4-1606980013387] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:34,832 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1199088383-172.17.0.4-1606980013387] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:34,855 [Listener at localhost/43660] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:34,855 [Listener at localhost/43660] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:34,857 [Listener at localhost/43660] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:34,857 [Listener at localhost/43660] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:34,860 [Listener at localhost/43660] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:34,860 [Listener at localhost/43660] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 3
2020-12-03 07:20:34,861 [Listener at localhost/43660] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:34,861 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@739c5f9a] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:34,863 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-53ebb263-a519-4e04-8516-6895b2684e49) exiting.
2020-12-03 07:20:34,863 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-604aa382-053e-4d29-ae14-d8159a125483) exiting.
2020-12-03 07:20:35,030 [Listener at localhost/43660] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1e3a15fd{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:35,031 [Listener at localhost/43660] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@67908616{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:35,031 [Listener at localhost/43660] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4ac9d9a2{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:35,032 [Listener at localhost/43660] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6bdeff70{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:35,033 [Listener at localhost/43660] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 32843
2020-12-03 07:20:35,036 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:35,037 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:35,039 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:35,039 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1199088383-172.17.0.4-1606980013387 (Datanode Uuid 2c0b9200-a808-454b-aeae-39910540cca5) service to localhost/127.0.0.1:44233
2020-12-03 07:20:35,039 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1199088383-172.17.0.4-1606980013387 (Datanode Uuid 2c0b9200-a808-454b-aeae-39910540cca5)
2020-12-03 07:20:35,039 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:35,040 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1199088383-172.17.0.4-1606980013387] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:35,040 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1199088383-172.17.0.4-1606980013387] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:35,045 [Listener at localhost/43660] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:35,045 [Listener at localhost/43660] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:35,048 [Listener at localhost/43660] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:35,048 [Listener at localhost/43660] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:35,052 [Listener at localhost/43660] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:35,052 [Listener at localhost/43660] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 2
2020-12-03 07:20:35,052 [Listener at localhost/43660] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:35,052 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@55cc7716] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:35,055 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-7c7a5fb3-6845-447a-a855-e677cf9028bc) exiting.
2020-12-03 07:20:35,055 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-e0706d8b-1d48-436b-a586-041594df8014) exiting.
2020-12-03 07:20:35,073 [Listener at localhost/43660] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@36ecea3{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:35,073 [Listener at localhost/43660] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@ef806db{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:35,074 [Listener at localhost/43660] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@55f83456{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:35,074 [Listener at localhost/43660] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7b0ea794{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:35,075 [Listener at localhost/43660] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 38382
2020-12-03 07:20:35,080 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:35,080 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:35,083 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:35,083 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1199088383-172.17.0.4-1606980013387 (Datanode Uuid aa46699a-faf3-419b-9673-7b32209adbf8) service to localhost/127.0.0.1:44233
2020-12-03 07:20:35,084 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1199088383-172.17.0.4-1606980013387 (Datanode Uuid aa46699a-faf3-419b-9673-7b32209adbf8)
2020-12-03 07:20:35,084 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:35,085 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1199088383-172.17.0.4-1606980013387] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:35,085 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1199088383-172.17.0.4-1606980013387] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:35,088 [Listener at localhost/43660] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:35,088 [Listener at localhost/43660] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:35,091 [Listener at localhost/43660] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:35,091 [Listener at localhost/43660] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:35,095 [Listener at localhost/43660] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:35,095 [Listener at localhost/43660] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 1
2020-12-03 07:20:35,096 [Listener at localhost/43660] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:35,096 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@b50770] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:35,099 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-8888774b-8a84-448b-b3e5-a3adadd0d078) exiting.
2020-12-03 07:20:35,099 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-9f3a827e-e2fe-44cb-bf3f-03dbde2b0b88) exiting.
2020-12-03 07:20:35,229 [Listener at localhost/43660] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@3be9e39c{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:35,230 [Listener at localhost/43660] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@52333402{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:35,230 [Listener at localhost/43660] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@11b29b7c{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:35,231 [Listener at localhost/43660] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@25caa7ef{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:35,232 [Listener at localhost/43660] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 39371
2020-12-03 07:20:35,238 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:35,239 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:35,244 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:35,244 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1199088383-172.17.0.4-1606980013387 (Datanode Uuid aae714b7-affe-4899-8582-7db48868bdef) service to localhost/127.0.0.1:44233
2020-12-03 07:20:35,244 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1199088383-172.17.0.4-1606980013387 (Datanode Uuid aae714b7-affe-4899-8582-7db48868bdef)
2020-12-03 07:20:35,244 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:35,245 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1199088383-172.17.0.4-1606980013387] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:35,245 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1199088383-172.17.0.4-1606980013387] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:35,251 [Listener at localhost/43660] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:35,251 [Listener at localhost/43660] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:35,255 [Listener at localhost/43660] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:35,255 [Listener at localhost/43660] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:35,265 [Listener at localhost/43660] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:35,265 [Listener at localhost/43660] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:20:35,265 [Listener at localhost/43660] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:35,266 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@315c928d] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:35,270 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-9637c4ad-4b9f-4743-85c8-8b3b2981aad6) exiting.
2020-12-03 07:20:35,271 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-89b6f46a-278e-49c3-b219-2a6fc902ef6b) exiting.
2020-12-03 07:20:35,301 [Listener at localhost/43660] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@29e41834{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:35,302 [Listener at localhost/43660] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7fb7c1ea{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:35,302 [Listener at localhost/43660] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7ffc1570{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:35,302 [Listener at localhost/43660] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5abf2073{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:35,304 [Listener at localhost/43660] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 40783
2020-12-03 07:20:35,309 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:35,310 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:35,313 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:35,313 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1199088383-172.17.0.4-1606980013387 (Datanode Uuid 3c6cb142-24b8-4ba9-8bce-390f3aeb2056) service to localhost/127.0.0.1:44233
2020-12-03 07:20:35,313 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1199088383-172.17.0.4-1606980013387 (Datanode Uuid 3c6cb142-24b8-4ba9-8bce-390f3aeb2056)
2020-12-03 07:20:35,313 [BP-1199088383-172.17.0.4-1606980013387 heartbeating to localhost/127.0.0.1:44233] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1199088383-172.17.0.4-1606980013387
2020-12-03 07:20:35,314 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1199088383-172.17.0.4-1606980013387] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:35,314 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1199088383-172.17.0.4-1606980013387] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:35,319 [Listener at localhost/43660] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:35,320 [Listener at localhost/43660] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:35,325 [Listener at localhost/43660] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:35,325 [Listener at localhost/43660] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:35,351 [Listener at localhost/43660] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:35,352 [Listener at localhost/43660] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:20:35,352 [Listener at localhost/43660] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:20:35,356 [Listener at localhost/43660] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 13, 14
2020-12-03 07:20:35,360 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@6e1333a] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:20:35,360 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@4bc72edc] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:20:35,382 [Listener at localhost/43660] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 3 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 12 Number of syncs: 4 SyncTimes(ms): 26 2 
2020-12-03 07:20:35,387 [Listener at localhost/43660] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000013 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000013-0000000000000000015
2020-12-03 07:20:35,391 [Listener at localhost/43660] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000013 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000013-0000000000000000015
2020-12-03 07:20:35,391 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:20:35,392 [CacheReplicationMonitor(1695538199)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:20:35,409 [Listener at localhost/43660] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 44233
2020-12-03 07:20:35,420 [IPC Server listener on 44233] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 44233
2020-12-03 07:20:35,424 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:35,438 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:20:35,443 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:20:35,455 [Listener at localhost/43660] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:20:35,456 [Listener at localhost/43660] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:20:35,475 [Listener at localhost/43660] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@d2141be{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:20:35,477 [Listener at localhost/43660] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6d2bca61{HTTP/1.1,[http/1.1]}{localhost:33418}
2020-12-03 07:20:35,480 [Listener at localhost/43660] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@158171f9{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:35,483 [Listener at localhost/43660] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@594e2f82{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:35,484 [Listener at localhost/43660] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping NameNode metrics system...
2020-12-03 07:20:35,488 [Listener at localhost/43660] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - NameNode metrics system stopped.
2020-12-03 07:20:35,489 [Listener at localhost/43660] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - NameNode metrics system shutdown complete.
msx-rc 0
