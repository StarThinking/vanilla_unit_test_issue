2020-12-03 07:22:35,847 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=11
Formatting using clusterid: testClusterID
2020-12-03 07:22:36,589 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:22:36,604 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:22:36,605 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:22:36,606 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:22:36,614 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:22:36,614 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:22:36,614 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:22:36,615 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:22:36,654 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:36,659 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2020-12-03 07:22:36,660 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:22:36,660 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:22:36,666 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:22:36,667 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:22:36
2020-12-03 07:22:36,669 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:22:36,671 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:36,673 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-12-03 07:22:36,673 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:22:36,695 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:22:36,696 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:22:36,699 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.redundancy.interval.seconds(1) assuming SECONDS
2020-12-03 07:22:36,704 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:22:36,704 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:22:36,704 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:22:36,705 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:22:36,706 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:22:36,706 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:22:36,706 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:22:36,706 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:22:36,707 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 1000ms
2020-12-03 07:22:36,707 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:22:36,707 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:22:36,742 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GLOBAL serial map: bits=29 maxEntries=536870911
2020-12-03 07:22:36,742 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - USER serial map: bits=24 maxEntries=16777215
2020-12-03 07:22:36,742 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GROUP serial map: bits=24 maxEntries=16777215
2020-12-03 07:22:36,743 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - XATTR serial map: bits=24 maxEntries=16777215
2020-12-03 07:22:36,759 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:22:36,759 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:36,760 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-12-03 07:22:36,760 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:22:36,767 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:22:36,768 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:22:36,768 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:22:36,769 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:22:36,775 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:22:36,777 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:22:36,783 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:22:36,783 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:36,784 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-12-03 07:22:36,784 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:22:36,792 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:22:36,793 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:22:36,793 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:22:36,797 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:22:36,798 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:22:36,800 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:22:36,801 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:36,801 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-12-03 07:22:36,802 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:22:36,839 [main] INFO  namenode.FSImage (FSImage.java:format(185)) - Allocated new BlockPoolId: BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:37,098 [main] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-12-03 07:22:37,344 [main] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-12-03 07:22:37,377 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:22:37,377 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:22:37,517 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:22:37,517 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:22:37,623 [main] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-12-03 07:22:37,629 [main] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:22:37,747 [main] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:22:38,015 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:22:38,015 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:22:38,047 [main] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-12-03 07:22:38,091 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2ed2d9cb] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:38,107 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:22:38,113 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:38,128 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @3329ms
2020-12-03 07:22:38,271 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:38,276 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:22:38,276 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:38,287 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:38,290 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:22:38,291 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:38,291 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:38,330 [main] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:22:38,330 [main] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:22:38,343 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 45850
2020-12-03 07:22:38,346 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:38,402 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@28cda624{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:38,403 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7eecb5b8{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:38,451 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3e44f2a5{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:22:38,469 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@589da3f3{HTTP/1.1,[http/1.1]}{localhost:45850}
2020-12-03 07:22:38,470 [main] INFO  server.Server (Server.java:doStart(419)) - Started @3671ms
2020-12-03 07:22:38,483 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:22:38,484 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:22:38,484 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:22:38,484 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:22:38,485 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:22:38,485 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:22:38,485 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:22:38,486 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:22:38,487 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:38,488 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:22:38,488 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:22:38,489 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:22:38,489 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:22:38
2020-12-03 07:22:38,490 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:22:38,490 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:38,490 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:22:38,490 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:22:38,496 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:22:38,497 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:22:38,497 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.redundancy.interval.seconds(1) assuming SECONDS
2020-12-03 07:22:38,498 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:22:38,498 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:22:38,499 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:22:38,499 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:22:38,500 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:22:38,500 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:22:38,501 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:22:38,501 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:22:38,501 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 1000ms
2020-12-03 07:22:38,502 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:22:38,502 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:22:38,503 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:22:38,503 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:38,504 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:22:38,505 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:22:38,508 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:22:38,508 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:22:38,508 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:22:38,509 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:22:38,509 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:22:38,509 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:22:38,510 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:22:38,510 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:38,511 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:22:38,511 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:22:38,512 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:22:38,513 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:22:38,513 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:22:38,513 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:22:38,514 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:22:38,514 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:22:38,514 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:38,515 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:22:38,515 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:22:38,589 [main] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 5029@5a8b1b2f5494
2020-12-03 07:22:38,697 [main] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 5029@5a8b1b2f5494
2020-12-03 07:22:38,701 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-12-03 07:22:38,702 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-12-03 07:22:38,703 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:22:38,703 [main] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:22:38,738 [main] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:22:38,744 [main] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:22:38,745 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-12-03 07:22:38,750 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:22:38,751 [main] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 1
2020-12-03 07:22:38,837 [main] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:22:38,837 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 319 msecs
2020-12-03 07:22:39,046 [main] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:22:39,096 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:39,171 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:39,474 [Listener at localhost/46381] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:46381 to access this namenode/service.
2020-12-03 07:22:39,477 [Listener at localhost/46381] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:22:39,498 [Listener at localhost/46381] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:22:39,511 [org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor@47db5fa5] DEBUG blockmanagement.BlockManager (PendingReconstructionBlocks.java:pendingReconstructionCheck(261)) - PendingReconstructionMonitor checking Q
2020-12-03 07:22:39,527 [Listener at localhost/46381] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:22:39,528 [Listener at localhost/46381] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:22:39,536 [Listener at localhost/46381] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:22:39,536 [Listener at localhost/46381] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:22:39,540 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 0
2020-12-03 07:22:39,540 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:22:39,540 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:22:39,541 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:22:39,541 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:22:39,541 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 12 msec
2020-12-03 07:22:39,580 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:39,580 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:39,585 [Listener at localhost/46381] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:46381
2020-12-03 07:22:39,590 [Listener at localhost/46381] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:22:39,590 [Listener at localhost/46381] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:22:39,612 [Listener at localhost/46381] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 21 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:22:39,617 [CacheReplicationMonitor(457603143)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:22:39,621 [Listener at localhost/46381] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:22:39,621 [Listener at localhost/46381] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1664)) - Starting DataNode 0 with hostname set to: host1
2020-12-03 07:22:39,621 [Listener at localhost/46381] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1669)) - Adding node with hostname : host1 to rack /r1
2020-12-03 07:22:39,722 [Listener at localhost/46381] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:22:39,744 [Listener at localhost/46381] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:22:39,775 [Listener at localhost/46381] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:22:39,782 [Listener at localhost/46381] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:39,786 [Listener at localhost/46381] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:22:39,792 [Listener at localhost/46381] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is host1
2020-12-03 07:22:39,794 [Listener at localhost/46381] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:39,801 [Listener at localhost/46381] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:22:39,811 [Listener at localhost/46381] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:36853
2020-12-03 07:22:39,817 [Listener at localhost/46381] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:22:39,817 [Listener at localhost/46381] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:22:39,841 [Listener at localhost/46381] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:39,843 [Listener at localhost/46381] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:39,844 [Listener at localhost/46381] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:22:39,844 [Listener at localhost/46381] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:39,853 [Listener at localhost/46381] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:39,855 [Listener at localhost/46381] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:22:39,855 [Listener at localhost/46381] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:39,855 [Listener at localhost/46381] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:39,860 [Listener at localhost/46381] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 43180
2020-12-03 07:22:39,860 [Listener at localhost/46381] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:39,863 [Listener at localhost/46381] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@107ed6fc{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:39,864 [Listener at localhost/46381] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@186978a6{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:39,872 [Listener at localhost/46381] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@64beebb7{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:22:39,873 [Listener at localhost/46381] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7813cb11{HTTP/1.1,[http/1.1]}{localhost:43180}
2020-12-03 07:22:39,874 [Listener at localhost/46381] INFO  server.Server (Server.java:doStart(419)) - Started @5075ms
2020-12-03 07:22:40,205 [Listener at localhost/46381] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:43296
2020-12-03 07:22:40,206 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7889a1ac] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:40,208 [Listener at localhost/46381] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:22:40,208 [Listener at localhost/46381] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:22:40,235 [Listener at localhost/46381] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:40,236 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:40,249 [Listener at localhost/34080] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:34080
2020-12-03 07:22:40,473 [Listener at localhost/34080] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:22:40,475 [Listener at localhost/34080] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:22:40,486 [Thread-59] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46381 starting to offer service
2020-12-03 07:22:40,492 [Listener at localhost/34080] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1724)) - Adding node with service : 127.0.0.1:36853 to rack /r1
2020-12-03 07:22:40,493 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:40,493 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:40,498 [Listener at localhost/34080] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:22:40,499 [Listener at localhost/34080] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1664)) - Starting DataNode 1 with hostname set to: host2
2020-12-03 07:22:40,499 [Listener at localhost/34080] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1669)) - Adding node with hostname : host2 to rack /r1
2020-12-03 07:22:40,501 [Listener at localhost/34080] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:22:40,502 [Listener at localhost/34080] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:22:40,503 [Listener at localhost/34080] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:22:40,505 [Listener at localhost/34080] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:40,505 [Listener at localhost/34080] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:22:40,506 [Listener at localhost/34080] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is host2
2020-12-03 07:22:40,506 [Listener at localhost/34080] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:40,507 [Listener at localhost/34080] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:22:40,508 [Listener at localhost/34080] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:43893
2020-12-03 07:22:40,508 [Listener at localhost/34080] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:22:40,508 [Listener at localhost/34080] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:22:40,510 [Listener at localhost/34080] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:40,511 [Listener at localhost/34080] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:40,512 [Listener at localhost/34080] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:22:40,512 [Listener at localhost/34080] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:40,515 [Listener at localhost/34080] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:40,516 [Listener at localhost/34080] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:22:40,516 [Listener at localhost/34080] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:40,516 [Listener at localhost/34080] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:40,517 [Listener at localhost/34080] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 44054
2020-12-03 07:22:40,517 [Listener at localhost/34080] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:40,524 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1998)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-12-03 07:22:40,526 [Listener at localhost/34080] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2970a5bc{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:40,527 [Listener at localhost/34080] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@72efb5c1{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:40,536 [Listener at localhost/34080] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@40bffbca{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:22:40,538 [Listener at localhost/34080] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2449cff7{HTTP/1.1,[http/1.1]}{localhost:44054}
2020-12-03 07:22:40,540 [Listener at localhost/34080] INFO  server.Server (Server.java:doStart(419)) - Started @5741ms
2020-12-03 07:22:40,620 [Listener at localhost/34080] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:37668
2020-12-03 07:22:40,621 [Listener at localhost/34080] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:22:40,621 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@62da83ed] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:40,621 [Listener at localhost/34080] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:22:40,622 [Listener at localhost/34080] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:40,623 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:40,628 [Listener at localhost/46185] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:46185
2020-12-03 07:22:40,635 [Listener at localhost/46185] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:22:40,636 [Listener at localhost/46185] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:22:40,636 [Thread-83] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46381 starting to offer service
2020-12-03 07:22:40,637 [Listener at localhost/46185] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1724)) - Adding node with service : 127.0.0.1:43893 to rack /r1
2020-12-03 07:22:40,638 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:40,638 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:40,642 [Listener at localhost/46185] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:22:40,643 [Listener at localhost/46185] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1664)) - Starting DataNode 2 with hostname set to: host3
2020-12-03 07:22:40,643 [Listener at localhost/46185] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1669)) - Adding node with hostname : host3 to rack /r2
2020-12-03 07:22:40,645 [Listener at localhost/46185] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:22:40,645 [Listener at localhost/46185] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:22:40,648 [Listener at localhost/46185] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:22:40,649 [Listener at localhost/46185] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:40,649 [Listener at localhost/46185] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:22:40,650 [Listener at localhost/46185] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is host3
2020-12-03 07:22:40,650 [Listener at localhost/46185] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:40,650 [Listener at localhost/46185] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:22:40,651 [Listener at localhost/46185] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:35093
2020-12-03 07:22:40,651 [Listener at localhost/46185] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:22:40,651 [Listener at localhost/46185] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:22:40,653 [Listener at localhost/46185] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:40,654 [Listener at localhost/46185] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:40,656 [Listener at localhost/46185] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:22:40,656 [Listener at localhost/46185] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:40,659 [Listener at localhost/46185] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:40,660 [Listener at localhost/46185] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:22:40,660 [Listener at localhost/46185] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:40,660 [Listener at localhost/46185] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:40,661 [Listener at localhost/46185] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 44888
2020-12-03 07:22:40,661 [Listener at localhost/46185] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:40,668 [Listener at localhost/46185] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1827a871{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:40,669 [Listener at localhost/46185] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7249dadf{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:40,677 [Listener at localhost/46185] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@443dbe42{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:22:40,678 [Listener at localhost/46185] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@473b3b7a{HTTP/1.1,[http/1.1]}{localhost:44888}
2020-12-03 07:22:40,679 [Listener at localhost/46185] INFO  server.Server (Server.java:doStart(419)) - Started @5880ms
2020-12-03 07:22:40,718 [Listener at localhost/46185] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:44155
2020-12-03 07:22:40,719 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@77b7ffa4] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:40,720 [Listener at localhost/46185] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:22:40,720 [Listener at localhost/46185] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:22:40,721 [Listener at localhost/46185] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:40,723 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:40,731 [Listener at localhost/36965] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:36965
2020-12-03 07:22:40,736 [Listener at localhost/36965] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:22:40,737 [Listener at localhost/36965] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:22:40,739 [Thread-105] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46381 starting to offer service
2020-12-03 07:22:40,741 [Listener at localhost/36965] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1724)) - Adding node with service : 127.0.0.1:35093 to rack /r2
2020-12-03 07:22:40,742 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:40,742 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:40,747 [Listener at localhost/36965] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 3 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:22:40,747 [Listener at localhost/36965] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1664)) - Starting DataNode 3 with hostname set to: host4
2020-12-03 07:22:40,747 [Listener at localhost/36965] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1669)) - Adding node with hostname : host4 to rack /r2
2020-12-03 07:22:40,750 [Listener at localhost/36965] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:22:40,750 [Listener at localhost/36965] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:22:40,755 [Listener at localhost/36965] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:22:40,756 [Listener at localhost/36965] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:40,756 [Listener at localhost/36965] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:22:40,756 [Listener at localhost/36965] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is host4
2020-12-03 07:22:40,757 [Listener at localhost/36965] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:40,757 [Listener at localhost/36965] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:22:40,758 [Listener at localhost/36965] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:34171
2020-12-03 07:22:40,758 [Listener at localhost/36965] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:22:40,758 [Listener at localhost/36965] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:22:40,760 [Listener at localhost/36965] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:40,762 [Listener at localhost/36965] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:40,763 [Listener at localhost/36965] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:22:40,764 [Listener at localhost/36965] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:40,766 [Listener at localhost/36965] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:40,767 [Listener at localhost/36965] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:22:40,767 [Listener at localhost/36965] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:40,767 [Listener at localhost/36965] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:40,769 [Listener at localhost/36965] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 41892
2020-12-03 07:22:40,769 [Listener at localhost/36965] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:40,779 [Listener at localhost/36965] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1edb61b1{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:40,780 [Listener at localhost/36965] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@cc62a3b{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:40,788 [Listener at localhost/36965] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@324dcd31{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:22:40,790 [Listener at localhost/36965] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@503d56b5{HTTP/1.1,[http/1.1]}{localhost:41892}
2020-12-03 07:22:40,790 [Listener at localhost/36965] INFO  server.Server (Server.java:doStart(419)) - Started @5991ms
2020-12-03 07:22:40,895 [Listener at localhost/36965] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:40452
2020-12-03 07:22:40,896 [Listener at localhost/36965] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:22:40,896 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@433ffad1] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:40,896 [Listener at localhost/36965] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:22:40,897 [Listener at localhost/36965] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:40,898 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:40,903 [Listener at localhost/35388] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:35388
2020-12-03 07:22:40,909 [Listener at localhost/35388] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:22:40,909 [Listener at localhost/35388] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:22:40,910 [Thread-127] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46381 starting to offer service
2020-12-03 07:22:40,911 [Listener at localhost/35388] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1724)) - Adding node with service : 127.0.0.1:34171 to rack /r2
2020-12-03 07:22:40,912 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:40,914 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:40,917 [Listener at localhost/35388] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 4 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:22:40,918 [Listener at localhost/35388] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1664)) - Starting DataNode 4 with hostname set to: host5
2020-12-03 07:22:40,918 [Listener at localhost/35388] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1669)) - Adding node with hostname : host5 to rack /r3
2020-12-03 07:22:40,919 [Listener at localhost/35388] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:22:40,920 [Listener at localhost/35388] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:22:40,921 [Listener at localhost/35388] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:22:40,922 [Listener at localhost/35388] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:40,923 [Listener at localhost/35388] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:22:40,924 [Listener at localhost/35388] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is host5
2020-12-03 07:22:40,925 [Listener at localhost/35388] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:40,925 [Listener at localhost/35388] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:22:40,927 [Listener at localhost/35388] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:43254
2020-12-03 07:22:40,927 [Listener at localhost/35388] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:22:40,927 [Listener at localhost/35388] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:22:40,929 [Listener at localhost/35388] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:40,931 [Listener at localhost/35388] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:40,933 [Listener at localhost/35388] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:22:40,934 [Listener at localhost/35388] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:40,934 [Thread-105] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46381
2020-12-03 07:22:40,934 [Thread-59] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46381
2020-12-03 07:22:40,934 [Thread-127] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46381
2020-12-03 07:22:40,934 [Thread-83] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46381
2020-12-03 07:22:40,937 [Thread-127] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:40,937 [Thread-105] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:40,937 [Thread-83] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:40,938 [Listener at localhost/35388] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:40,938 [Thread-59] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:40,939 [Listener at localhost/35388] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:22:40,939 [Listener at localhost/35388] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:40,939 [Listener at localhost/35388] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:40,941 [Listener at localhost/35388] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 39101
2020-12-03 07:22:40,941 [Listener at localhost/35388] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:40,956 [Listener at localhost/35388] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2024293c{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:40,958 [Listener at localhost/35388] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@c074c0c{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:40,968 [Listener at localhost/35388] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@50b8ae8d{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:22:40,969 [Listener at localhost/35388] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@255990cc{HTTP/1.1,[http/1.1]}{localhost:39101}
2020-12-03 07:22:40,970 [Listener at localhost/35388] INFO  server.Server (Server.java:doStart(419)) - Started @6171ms
2020-12-03 07:22:40,988 [Listener at localhost/35388] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:35472
2020-12-03 07:22:40,989 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3c8bdd5b] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:40,989 [Listener at localhost/35388] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:22:40,989 [Listener at localhost/35388] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:22:40,990 [Listener at localhost/35388] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:40,991 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:40,994 [Listener at localhost/37876] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:37876
2020-12-03 07:22:40,998 [Listener at localhost/37876] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:22:40,998 [Listener at localhost/37876] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:22:40,999 [Thread-149] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46381 starting to offer service
2020-12-03 07:22:41,000 [Listener at localhost/37876] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1724)) - Adding node with service : 127.0.0.1:43254 to rack /r3
2020-12-03 07:22:41,001 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:41,001 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:41,003 [Listener at localhost/37876] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 5 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:22:41,004 [Listener at localhost/37876] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1664)) - Starting DataNode 5 with hostname set to: host6
2020-12-03 07:22:41,004 [Listener at localhost/37876] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1669)) - Adding node with hostname : host6 to rack /r3
2020-12-03 07:22:41,004 [Thread-149] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46381
2020-12-03 07:22:41,005 [Thread-149] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:41,005 [Listener at localhost/37876] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:22:41,006 [Listener at localhost/37876] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:22:41,006 [Listener at localhost/37876] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:22:41,007 [Listener at localhost/37876] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:41,007 [Listener at localhost/37876] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:22:41,008 [Listener at localhost/37876] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is host6
2020-12-03 07:22:41,008 [Listener at localhost/37876] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:41,008 [Listener at localhost/37876] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:22:41,009 [Listener at localhost/37876] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:46621
2020-12-03 07:22:41,009 [Listener at localhost/37876] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:22:41,009 [Listener at localhost/37876] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:22:41,011 [Listener at localhost/37876] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:41,012 [Listener at localhost/37876] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:41,013 [Listener at localhost/37876] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:22:41,013 [Listener at localhost/37876] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:41,015 [Listener at localhost/37876] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:41,016 [Listener at localhost/37876] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:22:41,016 [Listener at localhost/37876] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:41,016 [Listener at localhost/37876] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:41,017 [Listener at localhost/37876] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 45875
2020-12-03 07:22:41,017 [Listener at localhost/37876] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:41,019 [Listener at localhost/37876] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@610db97e{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:41,019 [Listener at localhost/37876] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3fabf088{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:41,025 [Listener at localhost/37876] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6f6a7463{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:22:41,027 [Listener at localhost/37876] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1bdaa23d{HTTP/1.1,[http/1.1]}{localhost:45875}
2020-12-03 07:22:41,027 [Listener at localhost/37876] INFO  server.Server (Server.java:doStart(419)) - Started @6228ms
2020-12-03 07:22:41,035 [Thread-105] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 5029@5a8b1b2f5494
2020-12-03 07:22:41,035 [Thread-83] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 5029@5a8b1b2f5494
2020-12-03 07:22:41,035 [Thread-127] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/in_use.lock acquired by nodename 5029@5a8b1b2f5494
2020-12-03 07:22:41,036 [Thread-59] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 5029@5a8b1b2f5494
2020-12-03 07:22:41,037 [Thread-105] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 is not formatted for namespace 1340213695. Formatting...
2020-12-03 07:22:41,037 [Thread-127] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 is not formatted for namespace 1340213695. Formatting...
2020-12-03 07:22:41,037 [Thread-83] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 is not formatted for namespace 1340213695. Formatting...
2020-12-03 07:22:41,037 [Thread-59] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 1340213695. Formatting...
2020-12-03 07:22:41,038 [Thread-83] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-7d23030f-e4b7-41c3-86d6-2f213d105c85 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 
2020-12-03 07:22:41,038 [Thread-105] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-529740d6-cc36-46d6-8bf0-550bd7bc3681 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 
2020-12-03 07:22:41,038 [Thread-59] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-d2a4899e-ef3e-4caa-92a7-edff2cf40784 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-12-03 07:22:41,038 [Thread-127] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-9858e8d6-2e19-4c6d-b267-646ed6d48c33 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 
2020-12-03 07:22:41,043 [Listener at localhost/37876] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:39992
2020-12-03 07:22:41,043 [Listener at localhost/37876] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:22:41,043 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6ca320ab] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:41,043 [Listener at localhost/37876] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:22:41,044 [Listener at localhost/37876] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:41,045 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:41,048 [Listener at localhost/41711] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:41711
2020-12-03 07:22:41,052 [Listener at localhost/41711] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:22:41,052 [Listener at localhost/41711] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:22:41,053 [Thread-171] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46381 starting to offer service
2020-12-03 07:22:41,055 [Listener at localhost/41711] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1724)) - Adding node with service : 127.0.0.1:46621 to rack /r3
2020-12-03 07:22:41,056 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:41,056 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:41,059 [Thread-171] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46381
2020-12-03 07:22:41,060 [Thread-171] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:41,061 [Listener at localhost/41711] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 6 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:22:41,061 [Listener at localhost/41711] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1664)) - Starting DataNode 6 with hostname set to: host7
2020-12-03 07:22:41,061 [Listener at localhost/41711] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1669)) - Adding node with hostname : host7 to rack /r4
2020-12-03 07:22:41,063 [Listener at localhost/41711] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:22:41,064 [Listener at localhost/41711] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:22:41,065 [Listener at localhost/41711] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:22:41,066 [Listener at localhost/41711] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:41,066 [Listener at localhost/41711] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:22:41,066 [Listener at localhost/41711] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is host7
2020-12-03 07:22:41,067 [Listener at localhost/41711] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:41,067 [Listener at localhost/41711] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:22:41,068 [Listener at localhost/41711] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:46575
2020-12-03 07:22:41,068 [Listener at localhost/41711] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:22:41,068 [Listener at localhost/41711] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:22:41,070 [Listener at localhost/41711] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:41,071 [Listener at localhost/41711] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:41,072 [Listener at localhost/41711] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:22:41,072 [Listener at localhost/41711] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:41,074 [Listener at localhost/41711] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:41,074 [Listener at localhost/41711] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:22:41,075 [Listener at localhost/41711] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:41,075 [Listener at localhost/41711] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:41,076 [Listener at localhost/41711] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 43151
2020-12-03 07:22:41,076 [Listener at localhost/41711] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:41,077 [Listener at localhost/41711] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7bfc3126{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:41,078 [Listener at localhost/41711] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@53bc1328{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:41,084 [Listener at localhost/41711] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@4102b1b1{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:22:41,085 [Listener at localhost/41711] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@61a5b4ae{HTTP/1.1,[http/1.1]}{localhost:43151}
2020-12-03 07:22:41,085 [Listener at localhost/41711] INFO  server.Server (Server.java:doStart(419)) - Started @6286ms
2020-12-03 07:22:41,097 [Thread-149] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/in_use.lock acquired by nodename 5029@5a8b1b2f5494
2020-12-03 07:22:41,097 [Thread-149] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 is not formatted for namespace 1340213695. Formatting...
2020-12-03 07:22:41,098 [Thread-149] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-1065d737-6687-4441-a64b-8cff8d91e6c0 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 
2020-12-03 07:22:41,101 [Listener at localhost/41711] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:33546
2020-12-03 07:22:41,101 [Listener at localhost/41711] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:22:41,101 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5b69fd74] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:41,101 [Listener at localhost/41711] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:22:41,102 [Listener at localhost/41711] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:41,103 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:41,106 [Listener at localhost/44771] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:44771
2020-12-03 07:22:41,110 [Listener at localhost/44771] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:22:41,110 [Listener at localhost/44771] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:22:41,111 [Thread-193] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46381 starting to offer service
2020-12-03 07:22:41,112 [Listener at localhost/44771] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1724)) - Adding node with service : 127.0.0.1:46575 to rack /r4
2020-12-03 07:22:41,113 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:41,113 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:41,116 [Thread-193] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46381
2020-12-03 07:22:41,117 [Thread-193] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:41,117 [Listener at localhost/44771] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 7 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:22:41,117 [Listener at localhost/44771] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1664)) - Starting DataNode 7 with hostname set to: host8
2020-12-03 07:22:41,117 [Listener at localhost/44771] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1669)) - Adding node with hostname : host8 to rack /r4
2020-12-03 07:22:41,119 [Listener at localhost/44771] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:22:41,119 [Listener at localhost/44771] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:22:41,120 [Listener at localhost/44771] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:22:41,121 [Listener at localhost/44771] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:41,121 [Listener at localhost/44771] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:22:41,121 [Listener at localhost/44771] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is host8
2020-12-03 07:22:41,122 [Listener at localhost/44771] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:41,122 [Listener at localhost/44771] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:22:41,123 [Listener at localhost/44771] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:39297
2020-12-03 07:22:41,123 [Listener at localhost/44771] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:22:41,123 [Listener at localhost/44771] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:22:41,124 [Listener at localhost/44771] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:41,125 [Listener at localhost/44771] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:41,126 [Listener at localhost/44771] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:22:41,126 [Listener at localhost/44771] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:41,128 [Listener at localhost/44771] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:41,128 [Listener at localhost/44771] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:22:41,128 [Listener at localhost/44771] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:41,128 [Listener at localhost/44771] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:41,129 [Listener at localhost/44771] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 34596
2020-12-03 07:22:41,129 [Listener at localhost/44771] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:41,131 [Listener at localhost/44771] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@bae47a0{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:41,131 [Listener at localhost/44771] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@85ec632{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:41,137 [Listener at localhost/44771] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@71652c98{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:22:41,138 [Listener at localhost/44771] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@51bde877{HTTP/1.1,[http/1.1]}{localhost:34596}
2020-12-03 07:22:41,138 [Listener at localhost/44771] INFO  server.Server (Server.java:doStart(419)) - Started @6339ms
2020-12-03 07:22:41,140 [Thread-171] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/in_use.lock acquired by nodename 5029@5a8b1b2f5494
2020-12-03 07:22:41,141 [Thread-171] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 is not formatted for namespace 1340213695. Formatting...
2020-12-03 07:22:41,142 [Thread-171] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-e0eebb59-dd2d-433a-93fb-dc405cc68a0e for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 
2020-12-03 07:22:41,193 [Listener at localhost/44771] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:33597
2020-12-03 07:22:41,193 [Listener at localhost/44771] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:22:41,193 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@492fc69e] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:41,193 [Listener at localhost/44771] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:22:41,194 [Listener at localhost/44771] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:41,195 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:41,197 [Thread-193] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/in_use.lock acquired by nodename 5029@5a8b1b2f5494
2020-12-03 07:22:41,197 [Thread-193] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 is not formatted for namespace 1340213695. Formatting...
2020-12-03 07:22:41,198 [Thread-193] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-d776ca84-07fa-451c-9d5c-5823f2a9c283 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 
2020-12-03 07:22:41,198 [Listener at localhost/41006] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:41006
2020-12-03 07:22:41,203 [Listener at localhost/41006] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:22:41,204 [Listener at localhost/41006] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:22:41,204 [Thread-215] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46381 starting to offer service
2020-12-03 07:22:41,206 [Listener at localhost/41006] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1724)) - Adding node with service : 127.0.0.1:39297 to rack /r4
2020-12-03 07:22:41,206 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:41,206 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:41,210 [Listener at localhost/41006] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 8 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:22:41,211 [Listener at localhost/41006] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1664)) - Starting DataNode 8 with hostname set to: host9
2020-12-03 07:22:41,211 [Listener at localhost/41006] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1669)) - Adding node with hostname : host9 to rack /r5
2020-12-03 07:22:41,211 [Thread-215] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46381
2020-12-03 07:22:41,212 [Thread-215] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:41,213 [Listener at localhost/41006] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:22:41,214 [Listener at localhost/41006] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:22:41,215 [Listener at localhost/41006] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:22:41,216 [Listener at localhost/41006] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:41,216 [Listener at localhost/41006] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:22:41,217 [Listener at localhost/41006] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is host9
2020-12-03 07:22:41,217 [Listener at localhost/41006] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:41,217 [Listener at localhost/41006] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:22:41,218 [Listener at localhost/41006] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:44873
2020-12-03 07:22:41,219 [Listener at localhost/41006] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:22:41,220 [Listener at localhost/41006] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:22:41,222 [Listener at localhost/41006] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:41,224 [Listener at localhost/41006] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:41,224 [Listener at localhost/41006] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:22:41,225 [Listener at localhost/41006] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:41,228 [Listener at localhost/41006] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:41,229 [Listener at localhost/41006] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:22:41,229 [Listener at localhost/41006] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:41,229 [Listener at localhost/41006] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:41,231 [Listener at localhost/41006] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 40459
2020-12-03 07:22:41,231 [Listener at localhost/41006] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:41,233 [Listener at localhost/41006] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6c44052e{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:41,234 [Listener at localhost/41006] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@530a8454{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:41,243 [Listener at localhost/41006] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@54f5f647{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:22:41,244 [Listener at localhost/41006] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6979efad{HTTP/1.1,[http/1.1]}{localhost:40459}
2020-12-03 07:22:41,245 [Listener at localhost/41006] INFO  server.Server (Server.java:doStart(419)) - Started @6446ms
2020-12-03 07:22:41,293 [Listener at localhost/41006] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:43336
2020-12-03 07:22:41,294 [Listener at localhost/41006] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:22:41,294 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4a67318f] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:41,294 [Listener at localhost/41006] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:22:41,295 [Listener at localhost/41006] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:41,295 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:41,296 [Thread-215] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/in_use.lock acquired by nodename 5029@5a8b1b2f5494
2020-12-03 07:22:41,296 [Thread-215] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 is not formatted for namespace 1340213695. Formatting...
2020-12-03 07:22:41,298 [Thread-215] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-989ab400-edd5-4c26-8129-27b187f55bea for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 
2020-12-03 07:22:41,299 [Listener at localhost/41578] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:41578
2020-12-03 07:22:41,304 [Listener at localhost/41578] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:22:41,304 [Listener at localhost/41578] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:22:41,305 [Thread-237] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46381 starting to offer service
2020-12-03 07:22:41,308 [Listener at localhost/41578] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1724)) - Adding node with service : 127.0.0.1:44873 to rack /r5
2020-12-03 07:22:41,309 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:41,309 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:41,313 [Thread-237] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46381
2020-12-03 07:22:41,314 [Listener at localhost/41578] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 9 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20
2020-12-03 07:22:41,314 [Thread-237] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:41,314 [Listener at localhost/41578] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1664)) - Starting DataNode 9 with hostname set to: host10
2020-12-03 07:22:41,314 [Listener at localhost/41578] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1669)) - Adding node with hostname : host10 to rack /r5
2020-12-03 07:22:41,315 [Listener at localhost/41578] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19
2020-12-03 07:22:41,316 [Listener at localhost/41578] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20
2020-12-03 07:22:41,318 [Listener at localhost/41578] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:22:41,319 [Listener at localhost/41578] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:41,319 [Listener at localhost/41578] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:22:41,320 [Listener at localhost/41578] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is host10
2020-12-03 07:22:41,320 [Listener at localhost/41578] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:41,320 [Listener at localhost/41578] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:22:41,321 [Listener at localhost/41578] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:45934
2020-12-03 07:22:41,321 [Listener at localhost/41578] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:22:41,321 [Listener at localhost/41578] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:22:41,323 [Listener at localhost/41578] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:41,324 [Listener at localhost/41578] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:41,325 [Listener at localhost/41578] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:22:41,325 [Listener at localhost/41578] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:41,327 [Listener at localhost/41578] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:41,327 [Listener at localhost/41578] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:22:41,327 [Listener at localhost/41578] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:41,327 [Listener at localhost/41578] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:41,328 [Listener at localhost/41578] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 35506
2020-12-03 07:22:41,328 [Listener at localhost/41578] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:41,333 [Listener at localhost/41578] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5bf61e67{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:41,334 [Listener at localhost/41578] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@b273a59{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:41,341 [Listener at localhost/41578] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@71b1a49c{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:22:41,343 [Listener at localhost/41578] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@73e132e0{HTTP/1.1,[http/1.1]}{localhost:35506}
2020-12-03 07:22:41,343 [Listener at localhost/41578] INFO  server.Server (Server.java:doStart(419)) - Started @6544ms
2020-12-03 07:22:41,359 [Listener at localhost/41578] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:45288
2020-12-03 07:22:41,359 [Listener at localhost/41578] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:22:41,359 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2472c7d8] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:41,359 [Listener at localhost/41578] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:22:41,360 [Listener at localhost/41578] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:41,361 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:41,364 [Listener at localhost/45396] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:45396
2020-12-03 07:22:41,369 [Listener at localhost/45396] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:22:41,370 [Listener at localhost/45396] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:22:41,371 [Thread-259] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46381 starting to offer service
2020-12-03 07:22:41,372 [Listener at localhost/45396] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1724)) - Adding node with service : 127.0.0.1:45934 to rack /r5
2020-12-03 07:22:41,374 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:41,374 [Thread-127] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/in_use.lock acquired by nodename 5029@5a8b1b2f5494
2020-12-03 07:22:41,374 [Thread-59] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 5029@5a8b1b2f5494
2020-12-03 07:22:41,374 [Thread-127] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 is not formatted for namespace 1340213695. Formatting...
2020-12-03 07:22:41,374 [Thread-105] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 5029@5a8b1b2f5494
2020-12-03 07:22:41,374 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:41,375 [Thread-83] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 5029@5a8b1b2f5494
2020-12-03 07:22:41,375 [Thread-127] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-88f48494-4b0c-4d6a-8850-141d185c4b08 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 
2020-12-03 07:22:41,375 [Thread-59] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 1340213695. Formatting...
2020-12-03 07:22:41,376 [Thread-83] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 is not formatted for namespace 1340213695. Formatting...
2020-12-03 07:22:41,376 [Thread-59] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-30d9c94d-ca53-4e48-9d49-19bd923387f8 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-12-03 07:22:41,377 [Thread-83] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-dee073db-38dc-4e86-b76e-620390a0797a for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 
2020-12-03 07:22:41,375 [Thread-105] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 is not formatted for namespace 1340213695. Formatting...
2020-12-03 07:22:41,377 [Thread-105] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-9c05daf8-c5f6-400f-9196-df42ff74880a for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 
2020-12-03 07:22:41,377 [Listener at localhost/45396] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 10 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22
2020-12-03 07:22:41,378 [Listener at localhost/45396] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1664)) - Starting DataNode 10 with hostname set to: host11
2020-12-03 07:22:41,378 [Listener at localhost/45396] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1669)) - Adding node with hostname : host11 to rack /r6
2020-12-03 07:22:41,378 [Thread-259] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46381
2020-12-03 07:22:41,379 [Thread-259] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:41,379 [Listener at localhost/45396] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21
2020-12-03 07:22:41,380 [Listener at localhost/45396] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22
2020-12-03 07:22:41,381 [Listener at localhost/45396] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:22:41,382 [Listener at localhost/45396] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:41,382 [Listener at localhost/45396] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:22:41,382 [Listener at localhost/45396] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is host11
2020-12-03 07:22:41,383 [Listener at localhost/45396] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:41,383 [Listener at localhost/45396] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:22:41,384 [Listener at localhost/45396] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:34223
2020-12-03 07:22:41,384 [Listener at localhost/45396] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:22:41,384 [Listener at localhost/45396] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:22:41,385 [Listener at localhost/45396] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:41,386 [Listener at localhost/45396] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:41,387 [Listener at localhost/45396] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:22:41,387 [Listener at localhost/45396] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:41,389 [Listener at localhost/45396] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:41,390 [Listener at localhost/45396] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:22:41,390 [Listener at localhost/45396] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:41,390 [Listener at localhost/45396] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:41,391 [Listener at localhost/45396] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 36859
2020-12-03 07:22:41,391 [Listener at localhost/45396] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:41,392 [Listener at localhost/45396] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@38600b{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:41,393 [Listener at localhost/45396] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@721eb7df{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:41,399 [Listener at localhost/45396] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6aa648b9{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:22:41,400 [Listener at localhost/45396] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@23c650a3{HTTP/1.1,[http/1.1]}{localhost:36859}
2020-12-03 07:22:41,400 [Listener at localhost/45396] INFO  server.Server (Server.java:doStart(419)) - Started @6602ms
2020-12-03 07:22:41,416 [Listener at localhost/45396] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:39510
2020-12-03 07:22:41,417 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@88a8218] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:41,417 [Listener at localhost/45396] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:22:41,417 [Listener at localhost/45396] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:22:41,418 [Listener at localhost/45396] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:41,418 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:41,422 [Listener at localhost/42513] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:42513
2020-12-03 07:22:41,429 [Listener at localhost/42513] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:22:41,429 [Listener at localhost/42513] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:22:41,430 [Thread-281] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46381 starting to offer service
2020-12-03 07:22:41,431 [Listener at localhost/42513] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1724)) - Adding node with service : 127.0.0.1:34223 to rack /r6
2020-12-03 07:22:41,433 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:41,434 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:41,437 [Thread-281] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46381
2020-12-03 07:22:41,437 [Thread-281] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:41,446 [Thread-237] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/in_use.lock acquired by nodename 5029@5a8b1b2f5494
2020-12-03 07:22:41,446 [Thread-149] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/in_use.lock acquired by nodename 5029@5a8b1b2f5494
2020-12-03 07:22:41,446 [Thread-237] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 is not formatted for namespace 1340213695. Formatting...
2020-12-03 07:22:41,446 [Thread-149] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 is not formatted for namespace 1340213695. Formatting...
2020-12-03 07:22:41,447 [Thread-237] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-61b82fc7-0cf4-4863-914d-b8b5d6ea1bdf for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 
2020-12-03 07:22:41,447 [Thread-149] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-969ad042-8fa6-4020-a93e-a04cbcb9ee38 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 
2020-12-03 07:22:41,509 [Thread-259] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19/in_use.lock acquired by nodename 5029@5a8b1b2f5494
2020-12-03 07:22:41,509 [Thread-281] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21/in_use.lock acquired by nodename 5029@5a8b1b2f5494
2020-12-03 07:22:41,509 [Thread-259] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19 is not formatted for namespace 1340213695. Formatting...
2020-12-03 07:22:41,509 [Thread-281] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21 is not formatted for namespace 1340213695. Formatting...
2020-12-03 07:22:41,509 [Thread-171] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/in_use.lock acquired by nodename 5029@5a8b1b2f5494
2020-12-03 07:22:41,510 [Thread-171] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 is not formatted for namespace 1340213695. Formatting...
2020-12-03 07:22:41,510 [Thread-171] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-d592cf78-a277-4a6c-8bcb-f07e7ab49315 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 
2020-12-03 07:22:41,510 [Thread-281] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-38ba94e2-2ce4-49bf-99db-685a54d217e4 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21 
2020-12-03 07:22:41,510 [Thread-259] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-7daa0dcb-00a1-4340-9cd9-d4a965f46cca for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19 
2020-12-03 07:22:41,525 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1998)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-12-03 07:22:41,579 [Thread-193] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/in_use.lock acquired by nodename 5029@5a8b1b2f5494
2020-12-03 07:22:41,579 [Thread-193] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 is not formatted for namespace 1340213695. Formatting...
2020-12-03 07:22:41,580 [Thread-193] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-0a405c40-4d26-4ad5-858e-e8b6d4387025 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 
2020-12-03 07:22:41,648 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:41,648 [Thread-127] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:41,648 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:41,648 [Thread-127] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:41,648 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:41,648 [Thread-83] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:41,648 [Thread-105] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:41,648 [Thread-59] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:41,649 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 and block pool id BP-553029280-172.17.0.10-1606980156826 is not formatted. Formatting ...
2020-12-03 07:22:41,649 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 and block pool id BP-553029280-172.17.0.10-1606980156826 is not formatted. Formatting ...
2020-12-03 07:22:41,649 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-553029280-172.17.0.10-1606980156826 is not formatted. Formatting ...
2020-12-03 07:22:41,649 [Thread-127] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 and block pool id BP-553029280-172.17.0.10-1606980156826 is not formatted. Formatting ...
2020-12-03 07:22:41,649 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-553029280-172.17.0.10-1606980156826 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-553029280-172.17.0.10-1606980156826/current
2020-12-03 07:22:41,649 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-553029280-172.17.0.10-1606980156826 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-553029280-172.17.0.10-1606980156826/current
2020-12-03 07:22:41,649 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-553029280-172.17.0.10-1606980156826 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-553029280-172.17.0.10-1606980156826/current
2020-12-03 07:22:41,649 [Thread-127] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-553029280-172.17.0.10-1606980156826 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-553029280-172.17.0.10-1606980156826/current
2020-12-03 07:22:41,704 [Thread-215] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/in_use.lock acquired by nodename 5029@5a8b1b2f5494
2020-12-03 07:22:41,705 [Thread-215] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 is not formatted for namespace 1340213695. Formatting...
2020-12-03 07:22:41,706 [Thread-215] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-0bcac960-967a-40ed-b8c5-387870c04d08 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 
2020-12-03 07:22:41,714 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:41,714 [Thread-149] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:41,714 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 and block pool id BP-553029280-172.17.0.10-1606980156826 is not formatted. Formatting ...
2020-12-03 07:22:41,714 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-553029280-172.17.0.10-1606980156826 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-553029280-172.17.0.10-1606980156826/current
2020-12-03 07:22:41,786 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:41,786 [Thread-171] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:41,787 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 and block pool id BP-553029280-172.17.0.10-1606980156826 is not formatted. Formatting ...
2020-12-03 07:22:41,787 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-553029280-172.17.0.10-1606980156826 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-553029280-172.17.0.10-1606980156826/current
2020-12-03 07:22:41,855 [Thread-237] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/in_use.lock acquired by nodename 5029@5a8b1b2f5494
2020-12-03 07:22:41,855 [Thread-237] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 is not formatted for namespace 1340213695. Formatting...
2020-12-03 07:22:41,857 [Thread-237] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-f4dbfb9b-555a-4059-9031-6a9fbc4e3745 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 
2020-12-03 07:22:41,866 [Thread-193] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:41,867 [Thread-193] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:41,867 [Thread-193] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 and block pool id BP-553029280-172.17.0.10-1606980156826 is not formatted. Formatting ...
2020-12-03 07:22:41,867 [Thread-193] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-553029280-172.17.0.10-1606980156826 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-553029280-172.17.0.10-1606980156826/current
2020-12-03 07:22:41,915 [Thread-259] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20/in_use.lock acquired by nodename 5029@5a8b1b2f5494
2020-12-03 07:22:41,915 [Thread-281] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22/in_use.lock acquired by nodename 5029@5a8b1b2f5494
2020-12-03 07:22:41,916 [Thread-259] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20 is not formatted for namespace 1340213695. Formatting...
2020-12-03 07:22:41,916 [Thread-281] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22 is not formatted for namespace 1340213695. Formatting...
2020-12-03 07:22:41,916 [Thread-281] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-53377210-e960-4ec0-ab7e-bfaeb689ad6d for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22 
2020-12-03 07:22:41,916 [Thread-259] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-c2d06ce4-d7fc-4f12-8985-fe5ab0cb5910 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20 
2020-12-03 07:22:41,926 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:41,926 [Thread-59] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:41,926 [IPC Server handler 1 on default port 46381] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:41,926 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-553029280-172.17.0.10-1606980156826 is not formatted. Formatting ...
2020-12-03 07:22:41,927 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:41,927 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-553029280-172.17.0.10-1606980156826 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-553029280-172.17.0.10-1606980156826/current
2020-12-03 07:22:41,929 [Thread-105] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:41,929 [Thread-127] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:41,929 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 and block pool id BP-553029280-172.17.0.10-1606980156826 is not formatted. Formatting ...
2020-12-03 07:22:41,929 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-553029280-172.17.0.10-1606980156826 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-553029280-172.17.0.10-1606980156826/current
2020-12-03 07:22:41,929 [Thread-127] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:41,930 [Thread-127] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 and block pool id BP-553029280-172.17.0.10-1606980156826 is not formatted. Formatting ...
2020-12-03 07:22:41,930 [Thread-127] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-553029280-172.17.0.10-1606980156826 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-553029280-172.17.0.10-1606980156826/current
2020-12-03 07:22:41,930 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:41,931 [Thread-83] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:41,931 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 and block pool id BP-553029280-172.17.0.10-1606980156826 is not formatted. Formatting ...
2020-12-03 07:22:41,931 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-553029280-172.17.0.10-1606980156826 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-553029280-172.17.0.10-1606980156826/current
2020-12-03 07:22:41,937 [Listener at localhost/42513] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:41,937 [Listener at localhost/42513] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:41,989 [Thread-215] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:41,989 [Thread-215] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:41,990 [Thread-215] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 and block pool id BP-553029280-172.17.0.10-1606980156826 is not formatted. Formatting ...
2020-12-03 07:22:41,990 [Thread-215] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-553029280-172.17.0.10-1606980156826 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-553029280-172.17.0.10-1606980156826/current
2020-12-03 07:22:41,990 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:41,990 [Thread-149] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:41,990 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 and block pool id BP-553029280-172.17.0.10-1606980156826 is not formatted. Formatting ...
2020-12-03 07:22:41,990 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-553029280-172.17.0.10-1606980156826 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-553029280-172.17.0.10-1606980156826/current
2020-12-03 07:22:42,040 [IPC Server handler 5 on default port 46381] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:42,042 [Listener at localhost/42513] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:42,042 [Listener at localhost/42513] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:42,070 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:42,070 [Thread-171] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:42,070 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 and block pool id BP-553029280-172.17.0.10-1606980156826 is not formatted. Formatting ...
2020-12-03 07:22:42,070 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-553029280-172.17.0.10-1606980156826 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-553029280-172.17.0.10-1606980156826/current
2020-12-03 07:22:42,136 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:42,136 [Thread-237] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:42,136 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 and block pool id BP-553029280-172.17.0.10-1606980156826 is not formatted. Formatting ...
2020-12-03 07:22:42,136 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-553029280-172.17.0.10-1606980156826 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-553029280-172.17.0.10-1606980156826/current
2020-12-03 07:22:42,137 [Thread-193] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:42,137 [Thread-193] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:42,138 [Thread-193] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 and block pool id BP-553029280-172.17.0.10-1606980156826 is not formatted. Formatting ...
2020-12-03 07:22:42,138 [Thread-193] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-553029280-172.17.0.10-1606980156826 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-553029280-172.17.0.10-1606980156826/current
2020-12-03 07:22:42,144 [IPC Server handler 7 on default port 46381] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:42,145 [Listener at localhost/42513] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:42,145 [Listener at localhost/42513] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:42,189 [Thread-127] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1340213695;bpid=BP-553029280-172.17.0.10-1606980156826;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1340213695;c=1606980156826;bpid=BP-553029280-172.17.0.10-1606980156826;dnuuid=null
2020-12-03 07:22:42,189 [Thread-83] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1340213695;bpid=BP-553029280-172.17.0.10-1606980156826;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1340213695;c=1606980156826;bpid=BP-553029280-172.17.0.10-1606980156826;dnuuid=null
2020-12-03 07:22:42,190 [Thread-59] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1340213695;bpid=BP-553029280-172.17.0.10-1606980156826;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1340213695;c=1606980156826;bpid=BP-553029280-172.17.0.10-1606980156826;dnuuid=null
2020-12-03 07:22:42,190 [Thread-105] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1340213695;bpid=BP-553029280-172.17.0.10-1606980156826;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1340213695;c=1606980156826;bpid=BP-553029280-172.17.0.10-1606980156826;dnuuid=null
2020-12-03 07:22:42,201 [Thread-259] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:42,202 [Thread-259] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19/current/BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:42,202 [Thread-259] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19 and block pool id BP-553029280-172.17.0.10-1606980156826 is not formatted. Formatting ...
2020-12-03 07:22:42,202 [Thread-259] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-553029280-172.17.0.10-1606980156826 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19/current/BP-553029280-172.17.0.10-1606980156826/current
2020-12-03 07:22:42,204 [Thread-281] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:42,205 [Thread-281] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21/current/BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:42,205 [Thread-281] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21 and block pool id BP-553029280-172.17.0.10-1606980156826 is not formatted. Formatting ...
2020-12-03 07:22:42,205 [Thread-281] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-553029280-172.17.0.10-1606980156826 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21/current/BP-553029280-172.17.0.10-1606980156826/current
2020-12-03 07:22:42,248 [IPC Server handler 8 on default port 46381] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:42,249 [Listener at localhost/42513] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:42,249 [Listener at localhost/42513] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:42,259 [Thread-149] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1340213695;bpid=BP-553029280-172.17.0.10-1606980156826;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1340213695;c=1606980156826;bpid=BP-553029280-172.17.0.10-1606980156826;dnuuid=null
2020-12-03 07:22:42,268 [Thread-215] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:42,268 [Thread-215] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:42,268 [Thread-215] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 and block pool id BP-553029280-172.17.0.10-1606980156826 is not formatted. Formatting ...
2020-12-03 07:22:42,269 [Thread-215] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-553029280-172.17.0.10-1606980156826 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-553029280-172.17.0.10-1606980156826/current
2020-12-03 07:22:42,352 [IPC Server handler 9 on default port 46381] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:42,353 [Listener at localhost/42513] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:42,354 [Listener at localhost/42513] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:42,358 [Thread-171] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1340213695;bpid=BP-553029280-172.17.0.10-1606980156826;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1340213695;c=1606980156826;bpid=BP-553029280-172.17.0.10-1606980156826;dnuuid=null
2020-12-03 07:22:42,421 [Thread-193] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1340213695;bpid=BP-553029280-172.17.0.10-1606980156826;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1340213695;c=1606980156826;bpid=BP-553029280-172.17.0.10-1606980156826;dnuuid=null
2020-12-03 07:22:42,433 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:42,433 [Thread-237] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:42,434 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 and block pool id BP-553029280-172.17.0.10-1606980156826 is not formatted. Formatting ...
2020-12-03 07:22:42,434 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-553029280-172.17.0.10-1606980156826 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-553029280-172.17.0.10-1606980156826/current
2020-12-03 07:22:42,457 [IPC Server handler 0 on default port 46381] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:42,458 [Listener at localhost/42513] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:42,458 [Listener at localhost/42513] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:42,493 [Thread-59] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID bb55c2ab-550b-47a9-aef1-bbeebaea4626
2020-12-03 07:22:42,493 [Thread-83] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID e49ebb27-c895-49e4-980b-5953315ee3da
2020-12-03 07:22:42,493 [Thread-105] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 0fb937fa-2aba-45e3-8780-b03d3f5859b2
2020-12-03 07:22:42,493 [Thread-127] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID ac2c185f-8b0e-4e4f-b0c8-58495b79d4f5
2020-12-03 07:22:42,502 [Thread-259] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:42,502 [Thread-281] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:42,502 [Thread-259] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20/current/BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:42,503 [Thread-281] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22/current/BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:42,503 [Thread-259] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20 and block pool id BP-553029280-172.17.0.10-1606980156826 is not formatted. Formatting ...
2020-12-03 07:22:42,503 [Thread-281] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22 and block pool id BP-553029280-172.17.0.10-1606980156826 is not formatted. Formatting ...
2020-12-03 07:22:42,503 [Thread-259] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-553029280-172.17.0.10-1606980156826 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20/current/BP-553029280-172.17.0.10-1606980156826/current
2020-12-03 07:22:42,503 [Thread-281] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-553029280-172.17.0.10-1606980156826 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22/current/BP-553029280-172.17.0.10-1606980156826/current
2020-12-03 07:22:42,527 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1998)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-12-03 07:22:42,557 [Thread-149] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 7e66e6f2-77d4-4df8-8ba0-4db0382c661e
2020-12-03 07:22:42,561 [IPC Server handler 3 on default port 46381] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:42,561 [Listener at localhost/42513] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:42,562 [Listener at localhost/42513] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:42,564 [Thread-215] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1340213695;bpid=BP-553029280-172.17.0.10-1606980156826;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1340213695;c=1606980156826;bpid=BP-553029280-172.17.0.10-1606980156826;dnuuid=null
2020-12-03 07:22:42,622 [Thread-171] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID adab20bb-214b-4a74-bb76-b832f6e8c8d9
2020-12-03 07:22:42,652 [Thread-171] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-e0eebb59-dd2d-433a-93fb-dc405cc68a0e
2020-12-03 07:22:42,653 [Thread-127] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-9858e8d6-2e19-4c6d-b267-646ed6d48c33
2020-12-03 07:22:42,674 [Thread-171] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, StorageType: DISK
2020-12-03 07:22:42,654 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-d2a4899e-ef3e-4caa-92a7-edff2cf40784
2020-12-03 07:22:42,653 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-7d23030f-e4b7-41c3-86d6-2f213d105c85
2020-12-03 07:22:42,675 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-12-03 07:22:42,674 [Thread-127] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, StorageType: DISK
2020-12-03 07:22:42,675 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: DISK
2020-12-03 07:22:42,675 [IPC Server handler 1 on default port 46381] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:42,675 [Thread-105] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-529740d6-cc36-46d6-8bf0-550bd7bc3681
2020-12-03 07:22:42,676 [Thread-105] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, StorageType: DISK
2020-12-03 07:22:42,677 [Thread-193] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 2b735e97-c043-4614-a472-ecf3212bd218
2020-12-03 07:22:42,677 [Listener at localhost/42513] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:42,678 [Listener at localhost/42513] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:42,677 [Thread-149] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-1065d737-6687-4441-a64b-8cff8d91e6c0
2020-12-03 07:22:42,678 [Thread-237] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1340213695;bpid=BP-553029280-172.17.0.10-1606980156826;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1340213695;c=1606980156826;bpid=BP-553029280-172.17.0.10-1606980156826;dnuuid=null
2020-12-03 07:22:42,679 [Thread-149] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, StorageType: DISK
2020-12-03 07:22:42,679 [Thread-105] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-9c05daf8-c5f6-400f-9196-df42ff74880a
2020-12-03 07:22:42,679 [Thread-105] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, StorageType: DISK
2020-12-03 07:22:42,681 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-dee073db-38dc-4e86-b76e-620390a0797a
2020-12-03 07:22:42,681 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: DISK
2020-12-03 07:22:42,681 [Thread-127] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-88f48494-4b0c-4d6a-8850-141d185c4b08
2020-12-03 07:22:42,682 [Thread-127] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, StorageType: DISK
2020-12-03 07:22:42,682 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-30d9c94d-ca53-4e48-9d49-19bd923387f8
2020-12-03 07:22:42,682 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-12-03 07:22:42,685 [Thread-171] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-d592cf78-a277-4a6c-8bcb-f07e7ab49315
2020-12-03 07:22:42,686 [Thread-171] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, StorageType: DISK
2020-12-03 07:22:42,687 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:22:42,687 [Thread-127] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:22:42,687 [Thread-171] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:22:42,687 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:22:42,687 [Thread-149] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-969ad042-8fa6-4020-a93e-a04cbcb9ee38
2020-12-03 07:22:42,688 [Thread-149] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, StorageType: DISK
2020-12-03 07:22:42,688 [Thread-149] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:22:42,689 [Thread-193] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-d776ca84-07fa-451c-9d5c-5823f2a9c283
2020-12-03 07:22:42,689 [Thread-105] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:22:42,689 [Thread-193] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, StorageType: DISK
2020-12-03 07:22:42,694 [Thread-149] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:22:42,696 [Thread-83] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:22:42,696 [Thread-171] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:22:42,697 [Thread-127] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:22:42,698 [Thread-59] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:22:42,699 [Thread-193] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-0a405c40-4d26-4ad5-858e-e8b6d4387025
2020-12-03 07:22:42,699 [Thread-193] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, StorageType: DISK
2020-12-03 07:22:42,701 [Thread-105] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:22:42,701 [Thread-193] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:22:42,703 [Thread-193] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:22:42,706 [Thread-105] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:22:42,707 [Thread-105] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:22:42,708 [Thread-105] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:22:42,711 [Thread-127] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:22:42,707 [Thread-149] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:22:42,706 [Thread-59] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:22:42,710 [Thread-83] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:22:42,709 [Thread-193] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:22:42,706 [Thread-171] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:22:42,712 [Thread-193] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:22:42,711 [Thread-83] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:22:42,711 [Thread-59] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:22:42,711 [Thread-149] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:22:42,711 [Thread-127] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:22:42,714 [Thread-127] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:22:42,711 [Thread-105] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:42,714 [Thread-127] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:42,713 [Thread-149] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:22:42,712 [Thread-59] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:22:42,712 [Thread-83] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:22:42,712 [Thread-193] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:22:42,712 [Thread-171] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:22:42,715 [Thread-193] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:42,715 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:42,715 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:42,716 [Thread-312] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:22:42,716 [Thread-314] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:22:42,716 [Thread-315] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14...
2020-12-03 07:22:42,717 [Thread-317] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:22:42,717 [Thread-316] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:22:42,717 [Thread-318] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:22:42,715 [Thread-149] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:42,716 [Thread-313] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13...
2020-12-03 07:22:42,715 [Thread-309] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-12-03 07:22:42,715 [Thread-311] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-12-03 07:22:42,715 [Thread-310] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:22:42,715 [Thread-171] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:22:42,718 [Thread-319] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-12-03 07:22:42,718 [Thread-171] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:42,718 [Thread-320] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-12-03 07:22:42,718 [Thread-321] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11...
2020-12-03 07:22:42,719 [Thread-322] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12...
2020-12-03 07:22:42,728 [Thread-259] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1340213695;bpid=BP-553029280-172.17.0.10-1606980156826;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1340213695;c=1606980156826;bpid=BP-553029280-172.17.0.10-1606980156826;dnuuid=null
2020-12-03 07:22:42,728 [Thread-281] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1340213695;bpid=BP-553029280-172.17.0.10-1606980156826;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1340213695;c=1606980156826;bpid=BP-553029280-172.17.0.10-1606980156826;dnuuid=null
2020-12-03 07:22:42,791 [IPC Server handler 4 on default port 46381] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:42,792 [Thread-215] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 4e9c8f7c-7ed9-464f-af37-72d5c79cf464
2020-12-03 07:22:42,796 [Listener at localhost/42513] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:42,796 [Listener at localhost/42513] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:42,824 [Thread-215] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-989ab400-edd5-4c26-8129-27b187f55bea
2020-12-03 07:22:42,825 [Thread-215] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, StorageType: DISK
2020-12-03 07:22:42,827 [Thread-215] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-0bcac960-967a-40ed-b8c5-387870c04d08
2020-12-03 07:22:42,827 [Thread-215] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, StorageType: DISK
2020-12-03 07:22:42,828 [Thread-215] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:22:42,829 [Thread-215] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:22:42,830 [Thread-215] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:22:42,830 [Thread-215] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:22:42,830 [Thread-215] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:22:42,838 [Thread-215] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:42,838 [Thread-339] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15...
2020-12-03 07:22:42,839 [Thread-340] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16...
2020-12-03 07:22:42,849 [Thread-317] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-553029280-172.17.0.10-1606980156826 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 132ms
2020-12-03 07:22:42,857 [Thread-313] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-553029280-172.17.0.10-1606980156826 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13: 140ms
2020-12-03 07:22:42,859 [Thread-319] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-553029280-172.17.0.10-1606980156826 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 141ms
2020-12-03 07:22:42,859 [Thread-311] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-553029280-172.17.0.10-1606980156826 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 141ms
2020-12-03 07:22:42,871 [Thread-316] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-553029280-172.17.0.10-1606980156826 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 154ms
2020-12-03 07:22:42,873 [Thread-310] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-553029280-172.17.0.10-1606980156826 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 155ms
2020-12-03 07:22:42,873 [Thread-309] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-553029280-172.17.0.10-1606980156826 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 155ms
2020-12-03 07:22:42,875 [Thread-127] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-553029280-172.17.0.10-1606980156826: 160ms
2020-12-03 07:22:42,882 [Thread-343] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-12-03 07:22:42,882 [Thread-344] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-12-03 07:22:42,882 [Thread-343] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-553029280-172.17.0.10-1606980156826/current/replicas doesn't exist 
2020-12-03 07:22:42,882 [Thread-344] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-553029280-172.17.0.10-1606980156826/current/replicas doesn't exist 
2020-12-03 07:22:42,885 [Thread-321] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-553029280-172.17.0.10-1606980156826 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11: 166ms
2020-12-03 07:22:42,887 [Thread-344] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 5ms
2020-12-03 07:22:42,887 [Thread-343] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 5ms
2020-12-03 07:22:42,888 [Thread-320] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-553029280-172.17.0.10-1606980156826 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 170ms
2020-12-03 07:22:42,888 [Thread-149] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-553029280-172.17.0.10-1606980156826: 170ms
2020-12-03 07:22:42,888 [Thread-127] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-553029280-172.17.0.10-1606980156826: 10ms
2020-12-03 07:22:42,892 [Thread-237] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID b67852ef-41de-4129-852b-cdf1aa436090
2020-12-03 07:22:42,892 [Thread-346] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-12-03 07:22:42,892 [Thread-345] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-12-03 07:22:42,892 [Thread-314] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-553029280-172.17.0.10-1606980156826 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 176ms
2020-12-03 07:22:42,892 [Thread-346] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-553029280-172.17.0.10-1606980156826/current/replicas doesn't exist 
2020-12-03 07:22:42,893 [Thread-345] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-553029280-172.17.0.10-1606980156826/current/replicas doesn't exist 
2020-12-03 07:22:42,893 [Thread-315] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-553029280-172.17.0.10-1606980156826 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14: 176ms
2020-12-03 07:22:42,894 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-553029280-172.17.0.10-1606980156826: 179ms
2020-12-03 07:22:42,894 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:22:42,894 [Thread-345] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 1ms
2020-12-03 07:22:42,966 [Thread-259] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 2f03b26a-3875-4a82-b77d-a44b653d6091
2020-12-03 07:22:42,965 [Thread-281] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 2eee4d7d-a7de-413d-86d9-9bf7d9a28d3e
2020-12-03 07:22:42,965 [Thread-347] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:22:42,894 [Thread-193] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-553029280-172.17.0.10-1606980156826: 179ms
2020-12-03 07:22:42,894 [Thread-346] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 2ms
2020-12-03 07:22:42,894 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:22:42,969 [Thread-149] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-553029280-172.17.0.10-1606980156826: 81ms
2020-12-03 07:22:42,969 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-88f48494-4b0c-4d6a-8850-141d185c4b08): finished scanning block pool BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:42,969 [Thread-348] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:22:42,969 [IPC Server handler 5 on default port 46381] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:42,970 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:22:42,970 [Thread-348] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-553029280-172.17.0.10-1606980156826/current/replicas doesn't exist 
2020-12-03 07:22:42,970 [Thread-347] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-553029280-172.17.0.10-1606980156826/current/replicas doesn't exist 
2020-12-03 07:22:42,969 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-9858e8d6-2e19-4c6d-b267-646ed6d48c33): finished scanning block pool BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:42,969 [Thread-349] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13...
2020-12-03 07:22:42,969 [Thread-322] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-553029280-172.17.0.10-1606980156826 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12: 250ms
2020-12-03 07:22:42,975 [Thread-347] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 6ms
2020-12-03 07:22:42,972 [Thread-312] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-553029280-172.17.0.10-1606980156826 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 256ms
2020-12-03 07:22:42,972 [Listener at localhost/42513] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:42,987 [Listener at localhost/42513] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:42,972 [Thread-350] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14...
2020-12-03 07:22:42,972 [Thread-237] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-61b82fc7-0cf4-4863-914d-b8b5d6ea1bdf
2020-12-03 07:22:42,971 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-1065d737-6687-4441-a64b-8cff8d91e6c0): finished scanning block pool BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:42,989 [Thread-259] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-7daa0dcb-00a1-4340-9cd9-d4a965f46cca
2020-12-03 07:22:42,989 [Thread-259] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19, StorageType: DISK
2020-12-03 07:22:42,971 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:22:42,989 [Thread-237] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, StorageType: DISK
2020-12-03 07:22:42,989 [Thread-350] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-553029280-172.17.0.10-1606980156826/current/replicas doesn't exist 
2020-12-03 07:22:42,987 [Thread-318] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-553029280-172.17.0.10-1606980156826 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 270ms
2020-12-03 07:22:42,983 [Thread-339] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-553029280-172.17.0.10-1606980156826 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15: 145ms
2020-12-03 07:22:42,991 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-553029280-172.17.0.10-1606980156826: 275ms
2020-12-03 07:22:42,981 [Thread-105] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-553029280-172.17.0.10-1606980156826: 265ms
2020-12-03 07:22:42,991 [Thread-340] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-553029280-172.17.0.10-1606980156826 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16: 150ms
2020-12-03 07:22:42,978 [Thread-171] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-553029280-172.17.0.10-1606980156826: 258ms
2020-12-03 07:22:42,976 [Thread-281] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-38ba94e2-2ce4-49bf-99db-685a54d217e4
2020-12-03 07:22:42,976 [Thread-348] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 6ms
2020-12-03 07:22:42,992 [Thread-360] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:22:42,976 [Thread-349] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-553029280-172.17.0.10-1606980156826/current/replicas doesn't exist 
2020-12-03 07:22:42,992 [Thread-360] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-553029280-172.17.0.10-1606980156826/current/replicas doesn't exist 
2020-12-03 07:22:42,992 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-553029280-172.17.0.10-1606980156826: 98ms
2020-12-03 07:22:42,992 [Thread-281] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21, StorageType: DISK
2020-12-03 07:22:42,992 [Thread-359] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:22:42,992 [Thread-358] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:22:42,991 [Thread-215] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-553029280-172.17.0.10-1606980156826: 153ms
2020-12-03 07:22:42,991 [Thread-350] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14: 2ms
2020-12-03 07:22:42,991 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-969ad042-8fa6-4020-a93e-a04cbcb9ee38): finished scanning block pool BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:42,996 [Thread-237] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-f4dbfb9b-555a-4059-9031-6a9fbc4e3745
2020-12-03 07:22:42,996 [Thread-358] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-553029280-172.17.0.10-1606980156826/current/replicas doesn't exist 
2020-12-03 07:22:42,996 [Thread-359] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-553029280-172.17.0.10-1606980156826/current/replicas doesn't exist 
2020-12-03 07:22:42,996 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:22:42,996 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:22:42,999 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-dee073db-38dc-4e86-b76e-620390a0797a): finished scanning block pool BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:42,996 [Thread-349] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13: 21ms
2020-12-03 07:22:42,996 [Thread-360] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 4ms
2020-12-03 07:22:42,992 [Thread-259] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-c2d06ce4-d7fc-4f12-8985-fe5ab0cb5910
2020-12-03 07:22:42,992 [Thread-361] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:22:42,992 [Thread-364] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12...
2020-12-03 07:22:43,002 [Thread-364] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-553029280-172.17.0.10-1606980156826/current/replicas doesn't exist 
2020-12-03 07:22:42,992 [Thread-362] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11...
2020-12-03 07:22:43,002 [Thread-361] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-553029280-172.17.0.10-1606980156826/current/replicas doesn't exist 
2020-12-03 07:22:43,002 [Thread-259] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20, StorageType: DISK
2020-12-03 07:22:43,001 [Thread-193] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-553029280-172.17.0.10-1606980156826: 32ms
2020-12-03 07:22:43,003 [Thread-361] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 1ms
2020-12-03 07:22:43,000 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-7d23030f-e4b7-41c3-86d6-2f213d105c85): finished scanning block pool BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:43,004 [Thread-259] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:22:42,999 [Thread-281] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-53377210-e960-4ec0-ab7e-bfaeb689ad6d
2020-12-03 07:22:43,005 [Thread-281] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22, StorageType: DISK
2020-12-03 07:22:43,005 [Thread-281] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:22:42,999 [Thread-359] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 3ms
2020-12-03 07:22:42,999 [Thread-369] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16...
2020-12-03 07:22:42,999 [Thread-358] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 3ms
2020-12-03 07:22:43,006 [Thread-369] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-553029280-172.17.0.10-1606980156826/current/replicas doesn't exist 
2020-12-03 07:22:42,998 [Thread-368] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15...
2020-12-03 07:22:42,998 [Thread-237] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, StorageType: DISK
2020-12-03 07:22:43,009 [Thread-368] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-553029280-172.17.0.10-1606980156826/current/replicas doesn't exist 
2020-12-03 07:22:43,009 [Thread-369] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16: 3ms
2020-12-03 07:22:43,006 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-553029280-172.17.0.10-1606980156826: 15ms
2020-12-03 07:22:43,006 [Thread-259] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19
2020-12-03 07:22:43,006 [Thread-105] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-553029280-172.17.0.10-1606980156826: 15ms
2020-12-03 07:22:43,004 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:22:43,004 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:22:43,003 [Thread-362] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-553029280-172.17.0.10-1606980156826/current/replicas doesn't exist 
2020-12-03 07:22:43,003 [Thread-364] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12: 1ms
2020-12-03 07:22:43,012 [Thread-259] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19
2020-12-03 07:22:43,012 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-0a405c40-4d26-4ad5-858e-e8b6d4387025): finished scanning block pool BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:43,012 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-d776ca84-07fa-451c-9d5c-5823f2a9c283): finished scanning block pool BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:43,011 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:22:43,011 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:22:43,011 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:22:43,013 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-9c05daf8-c5f6-400f-9196-df42ff74880a): finished scanning block pool BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:43,011 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:22:43,013 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-529740d6-cc36-46d6-8bf0-550bd7bc3681): finished scanning block pool BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:43,011 [Thread-237] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:22:43,013 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-30d9c94d-ca53-4e48-9d49-19bd923387f8): finished scanning block pool BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:43,011 [Thread-368] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15: 1ms
2020-12-03 07:22:43,010 [Thread-281] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21
2020-12-03 07:22:43,014 [Thread-215] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-553029280-172.17.0.10-1606980156826: 18ms
2020-12-03 07:22:43,013 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-d2a4899e-ef3e-4caa-92a7-edff2cf40784): finished scanning block pool BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:43,013 [Thread-259] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20
2020-12-03 07:22:43,012 [Thread-362] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11: 9ms
2020-12-03 07:22:43,014 [Thread-237] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:22:43,014 [Thread-171] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-553029280-172.17.0.10-1606980156826: 23ms
2020-12-03 07:22:43,014 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:22:43,015 [Thread-237] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:22:43,014 [Thread-281] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21
2020-12-03 07:22:43,014 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:22:43,015 [Thread-281] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22
2020-12-03 07:22:43,015 [Thread-237] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:22:43,015 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:22:43,015 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-0bcac960-967a-40ed-b8c5-387870c04d08): finished scanning block pool BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:43,015 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:22:43,014 [Thread-259] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20
2020-12-03 07:22:43,016 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-e0eebb59-dd2d-433a-93fb-dc405cc68a0e): finished scanning block pool BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:43,016 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-d592cf78-a277-4a6c-8bcb-f07e7ab49315): finished scanning block pool BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:43,016 [Thread-237] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:22:43,017 [Thread-237] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:43,016 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-989ab400-edd5-4c26-8129-27b187f55bea): finished scanning block pool BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:43,016 [Thread-281] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22
2020-12-03 07:22:43,016 [Thread-259] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:43,017 [Thread-281] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:43,018 [Thread-381] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17...
2020-12-03 07:22:43,018 [Thread-382] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19...
2020-12-03 07:22:43,018 [Thread-384] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18...
2020-12-03 07:22:43,018 [Thread-383] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21...
2020-12-03 07:22:43,018 [Thread-385] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20...
2020-12-03 07:22:43,018 [Thread-386] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22...
2020-12-03 07:22:43,021 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-d2a4899e-ef3e-4caa-92a7-edff2cf40784): no suitable block pools found to scan.  Waiting 1814399990 ms.
2020-12-03 07:22:43,022 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-1065d737-6687-4441-a64b-8cff8d91e6c0): no suitable block pools found to scan.  Waiting 1814399948 ms.
2020-12-03 07:22:43,022 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-e0eebb59-dd2d-433a-93fb-dc405cc68a0e): no suitable block pools found to scan.  Waiting 1814399993 ms.
2020-12-03 07:22:43,022 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-969ad042-8fa6-4020-a93e-a04cbcb9ee38): no suitable block pools found to scan.  Waiting 1814399948 ms.
2020-12-03 07:22:43,022 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-9858e8d6-2e19-4c6d-b267-646ed6d48c33): no suitable block pools found to scan.  Waiting 1814399873 ms.
2020-12-03 07:22:43,022 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-7d23030f-e4b7-41c3-86d6-2f213d105c85): no suitable block pools found to scan.  Waiting 1814399974 ms.
2020-12-03 07:22:43,022 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-d776ca84-07fa-451c-9d5c-5823f2a9c283): no suitable block pools found to scan.  Waiting 1814399982 ms.
2020-12-03 07:22:43,022 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-9c05daf8-c5f6-400f-9196-df42ff74880a): no suitable block pools found to scan.  Waiting 1814399989 ms.
2020-12-03 07:22:43,022 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-0bcac960-967a-40ed-b8c5-387870c04d08): no suitable block pools found to scan.  Waiting 1814399992 ms.
2020-12-03 07:22:43,022 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-989ab400-edd5-4c26-8129-27b187f55bea): no suitable block pools found to scan.  Waiting 1814399992 ms.
2020-12-03 07:22:43,022 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-30d9c94d-ca53-4e48-9d49-19bd923387f8): no suitable block pools found to scan.  Waiting 1814399989 ms.
2020-12-03 07:22:43,022 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-dee073db-38dc-4e86-b76e-620390a0797a): no suitable block pools found to scan.  Waiting 1814399974 ms.
2020-12-03 07:22:43,024 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-529740d6-cc36-46d6-8bf0-550bd7bc3681): no suitable block pools found to scan.  Waiting 1814399987 ms.
2020-12-03 07:22:43,024 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-0a405c40-4d26-4ad5-858e-e8b6d4387025): no suitable block pools found to scan.  Waiting 1814399979 ms.
2020-12-03 07:22:43,024 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-d592cf78-a277-4a6c-8bcb-f07e7ab49315): no suitable block pools found to scan.  Waiting 1814399991 ms.
2020-12-03 07:22:43,024 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-88f48494-4b0c-4d6a-8850-141d185c4b08): no suitable block pools found to scan.  Waiting 1814399870 ms.
2020-12-03 07:22:43,027 [Thread-105] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 12:22 PM with interval of 21600000ms
2020-12-03 07:22:43,027 [Thread-83] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 9:13 AM with interval of 21600000ms
2020-12-03 07:22:43,028 [Thread-59] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 9:09 AM with interval of 21600000ms
2020-12-03 07:22:43,027 [Thread-215] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 10:02 AM with interval of 21600000ms
2020-12-03 07:22:43,029 [Thread-127] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:27 AM with interval of 21600000ms
2020-12-03 07:22:43,029 [Thread-193] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 9:56 AM with interval of 21600000ms
2020-12-03 07:22:43,029 [Thread-171] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 9:33 AM with interval of 21600000ms
2020-12-03 07:22:43,029 [Thread-149] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:54 AM with interval of 21600000ms
2020-12-03 07:22:43,037 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-553029280-172.17.0.10-1606980156826 (Datanode Uuid 7e66e6f2-77d4-4df8-8ba0-4db0382c661e) service to localhost/127.0.0.1:46381 beginning handshake with NN
2020-12-03 07:22:43,037 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-553029280-172.17.0.10-1606980156826 (Datanode Uuid e49ebb27-c895-49e4-980b-5953315ee3da) service to localhost/127.0.0.1:46381 beginning handshake with NN
2020-12-03 07:22:43,037 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-553029280-172.17.0.10-1606980156826 (Datanode Uuid ac2c185f-8b0e-4e4f-b0c8-58495b79d4f5) service to localhost/127.0.0.1:46381 beginning handshake with NN
2020-12-03 07:22:43,037 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-553029280-172.17.0.10-1606980156826 (Datanode Uuid 4e9c8f7c-7ed9-464f-af37-72d5c79cf464) service to localhost/127.0.0.1:46381 beginning handshake with NN
2020-12-03 07:22:43,037 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-553029280-172.17.0.10-1606980156826 (Datanode Uuid bb55c2ab-550b-47a9-aef1-bbeebaea4626) service to localhost/127.0.0.1:46381 beginning handshake with NN
2020-12-03 07:22:43,037 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-553029280-172.17.0.10-1606980156826 (Datanode Uuid 0fb937fa-2aba-45e3-8780-b03d3f5859b2) service to localhost/127.0.0.1:46381 beginning handshake with NN
2020-12-03 07:22:43,037 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-553029280-172.17.0.10-1606980156826 (Datanode Uuid adab20bb-214b-4a74-bb76-b832f6e8c8d9) service to localhost/127.0.0.1:46381 beginning handshake with NN
2020-12-03 07:22:43,037 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-553029280-172.17.0.10-1606980156826 (Datanode Uuid 2b735e97-c043-4614-a472-ecf3212bd218) service to localhost/127.0.0.1:46381 beginning handshake with NN
2020-12-03 07:22:43,050 [IPC Server handler 6 on default port 46381] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35093, datanodeUuid=0fb937fa-2aba-45e3-8780-b03d3f5859b2, infoPort=44155, infoSecurePort=0, ipcPort=36965, storageInfo=lv=-57;cid=testClusterID;nsid=1340213695;c=1606980156826) storage 0fb937fa-2aba-45e3-8780-b03d3f5859b2
2020-12-03 07:22:43,057 [IPC Server handler 6 on default port 46381] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /r2/127.0.0.1:35093
2020-12-03 07:22:43,059 [IPC Server handler 6 on default port 46381] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 0fb937fa-2aba-45e3-8780-b03d3f5859b2 (127.0.0.1:35093).
2020-12-03 07:22:43,071 [IPC Server handler 8 on default port 46381] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:39297, datanodeUuid=4e9c8f7c-7ed9-464f-af37-72d5c79cf464, infoPort=33597, infoSecurePort=0, ipcPort=41006, storageInfo=lv=-57;cid=testClusterID;nsid=1340213695;c=1606980156826) storage 4e9c8f7c-7ed9-464f-af37-72d5c79cf464
2020-12-03 07:22:43,072 [IPC Server handler 8 on default port 46381] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /r4/127.0.0.1:39297
2020-12-03 07:22:43,072 [IPC Server handler 8 on default port 46381] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:checkIfClusterIsNowMultiRack(1387)) - DN 127.0.0.1:39297 joining cluster has expanded a formerly single-rack cluster to be multi-rack. Re-checking all blocks for replication, since they should now be replicated cross-rack
2020-12-03 07:22:43,075 [IPC Server handler 8 on default port 46381] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 4e9c8f7c-7ed9-464f-af37-72d5c79cf464 (127.0.0.1:39297).
2020-12-03 07:22:43,076 [IPC Server handler 9 on default port 46381] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:43254, datanodeUuid=7e66e6f2-77d4-4df8-8ba0-4db0382c661e, infoPort=35472, infoSecurePort=0, ipcPort=37876, storageInfo=lv=-57;cid=testClusterID;nsid=1340213695;c=1606980156826) storage 7e66e6f2-77d4-4df8-8ba0-4db0382c661e
2020-12-03 07:22:43,076 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-553029280-172.17.0.10-1606980156826 (Datanode Uuid 4e9c8f7c-7ed9-464f-af37-72d5c79cf464) service to localhost/127.0.0.1:46381 successfully registered with NN
2020-12-03 07:22:43,076 [IPC Server handler 9 on default port 46381] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /r3/127.0.0.1:43254
2020-12-03 07:22:43,076 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:46381 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:22:43,076 [IPC Server handler 9 on default port 46381] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 7e66e6f2-77d4-4df8-8ba0-4db0382c661e (127.0.0.1:43254).
2020-12-03 07:22:43,076 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-553029280-172.17.0.10-1606980156826 (Datanode Uuid 0fb937fa-2aba-45e3-8780-b03d3f5859b2) service to localhost/127.0.0.1:46381 successfully registered with NN
2020-12-03 07:22:43,077 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:46381 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:22:43,077 [IPC Server handler 7 on default port 46381] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:43893, datanodeUuid=e49ebb27-c895-49e4-980b-5953315ee3da, infoPort=37668, infoSecurePort=0, ipcPort=46185, storageInfo=lv=-57;cid=testClusterID;nsid=1340213695;c=1606980156826) storage e49ebb27-c895-49e4-980b-5953315ee3da
2020-12-03 07:22:43,077 [IPC Server handler 7 on default port 46381] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /r1/127.0.0.1:43893
2020-12-03 07:22:43,077 [IPC Server handler 7 on default port 46381] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN e49ebb27-c895-49e4-980b-5953315ee3da (127.0.0.1:43893).
2020-12-03 07:22:43,078 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-553029280-172.17.0.10-1606980156826 (Datanode Uuid 7e66e6f2-77d4-4df8-8ba0-4db0382c661e) service to localhost/127.0.0.1:46381 successfully registered with NN
2020-12-03 07:22:43,078 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:46381 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:22:43,082 [IPC Server handler 2 on default port 46381] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:36853, datanodeUuid=bb55c2ab-550b-47a9-aef1-bbeebaea4626, infoPort=43296, infoSecurePort=0, ipcPort=34080, storageInfo=lv=-57;cid=testClusterID;nsid=1340213695;c=1606980156826) storage bb55c2ab-550b-47a9-aef1-bbeebaea4626
2020-12-03 07:22:43,083 [IPC Server handler 2 on default port 46381] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /r1/127.0.0.1:36853
2020-12-03 07:22:43,083 [IPC Server handler 2 on default port 46381] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN bb55c2ab-550b-47a9-aef1-bbeebaea4626 (127.0.0.1:36853).
2020-12-03 07:22:43,084 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-553029280-172.17.0.10-1606980156826 (Datanode Uuid e49ebb27-c895-49e4-980b-5953315ee3da) service to localhost/127.0.0.1:46381 successfully registered with NN
2020-12-03 07:22:43,084 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:46381 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:22:43,086 [IPC Server handler 0 on default port 46381] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:46575, datanodeUuid=2b735e97-c043-4614-a472-ecf3212bd218, infoPort=33546, infoSecurePort=0, ipcPort=44771, storageInfo=lv=-57;cid=testClusterID;nsid=1340213695;c=1606980156826) storage 2b735e97-c043-4614-a472-ecf3212bd218
2020-12-03 07:22:43,087 [IPC Server handler 0 on default port 46381] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /r4/127.0.0.1:46575
2020-12-03 07:22:43,087 [IPC Server handler 0 on default port 46381] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 2b735e97-c043-4614-a472-ecf3212bd218 (127.0.0.1:46575).
2020-12-03 07:22:43,087 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-553029280-172.17.0.10-1606980156826 (Datanode Uuid bb55c2ab-550b-47a9-aef1-bbeebaea4626) service to localhost/127.0.0.1:46381 successfully registered with NN
2020-12-03 07:22:43,087 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:46381 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:22:43,087 [Thread-385] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-553029280-172.17.0.10-1606980156826 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20: 69ms
2020-12-03 07:22:43,088 [IPC Server handler 3 on default port 46381] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34171, datanodeUuid=ac2c185f-8b0e-4e4f-b0c8-58495b79d4f5, infoPort=40452, infoSecurePort=0, ipcPort=35388, storageInfo=lv=-57;cid=testClusterID;nsid=1340213695;c=1606980156826) storage ac2c185f-8b0e-4e4f-b0c8-58495b79d4f5
2020-12-03 07:22:43,093 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-553029280-172.17.0.10-1606980156826 (Datanode Uuid 2b735e97-c043-4614-a472-ecf3212bd218) service to localhost/127.0.0.1:46381 successfully registered with NN
2020-12-03 07:22:43,093 [IPC Server handler 3 on default port 46381] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /r2/127.0.0.1:34171
2020-12-03 07:22:43,094 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:46381 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:22:43,095 [IPC Server handler 3 on default port 46381] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN ac2c185f-8b0e-4e4f-b0c8-58495b79d4f5 (127.0.0.1:34171).
2020-12-03 07:22:43,095 [Thread-381] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-553029280-172.17.0.10-1606980156826 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17: 77ms
2020-12-03 07:22:43,097 [IPC Server handler 1 on default port 46381] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:46621, datanodeUuid=adab20bb-214b-4a74-bb76-b832f6e8c8d9, infoPort=39992, infoSecurePort=0, ipcPort=41711, storageInfo=lv=-57;cid=testClusterID;nsid=1340213695;c=1606980156826) storage adab20bb-214b-4a74-bb76-b832f6e8c8d9
2020-12-03 07:22:43,097 [IPC Server handler 1 on default port 46381] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /r3/127.0.0.1:46621
2020-12-03 07:22:43,097 [IPC Server handler 1 on default port 46381] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN adab20bb-214b-4a74-bb76-b832f6e8c8d9 (127.0.0.1:46621).
2020-12-03 07:22:43,097 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-553029280-172.17.0.10-1606980156826 (Datanode Uuid ac2c185f-8b0e-4e4f-b0c8-58495b79d4f5) service to localhost/127.0.0.1:46381 successfully registered with NN
2020-12-03 07:22:43,097 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:46381 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:22:43,098 [Thread-383] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-553029280-172.17.0.10-1606980156826 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21: 80ms
2020-12-03 07:22:43,097 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 0
2020-12-03 07:22:43,098 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:22:43,098 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:22:43,098 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-553029280-172.17.0.10-1606980156826 (Datanode Uuid adab20bb-214b-4a74-bb76-b832f6e8c8d9) service to localhost/127.0.0.1:46381 successfully registered with NN
2020-12-03 07:22:43,098 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:22:43,098 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:22:43,099 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 24 msec
2020-12-03 07:22:43,099 [Thread-386] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-553029280-172.17.0.10-1606980156826 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22: 80ms
2020-12-03 07:22:43,098 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:46381 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:22:43,100 [Thread-281] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-553029280-172.17.0.10-1606980156826: 82ms
2020-12-03 07:22:43,101 [Thread-382] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-553029280-172.17.0.10-1606980156826 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19: 83ms
2020-12-03 07:22:43,102 [Thread-402] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21...
2020-12-03 07:22:43,102 [Thread-259] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-553029280-172.17.0.10-1606980156826: 84ms
2020-12-03 07:22:43,102 [Thread-402] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21/current/BP-553029280-172.17.0.10-1606980156826/current/replicas doesn't exist 
2020-12-03 07:22:43,102 [Thread-403] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22...
2020-12-03 07:22:43,102 [Thread-402] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21: 0ms
2020-12-03 07:22:43,102 [Thread-404] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19...
2020-12-03 07:22:43,102 [Thread-403] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22/current/BP-553029280-172.17.0.10-1606980156826/current/replicas doesn't exist 
2020-12-03 07:22:43,102 [Thread-405] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20...
2020-12-03 07:22:43,103 [Thread-404] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19/current/BP-553029280-172.17.0.10-1606980156826/current/replicas doesn't exist 
2020-12-03 07:22:43,103 [Thread-405] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20/current/BP-553029280-172.17.0.10-1606980156826/current/replicas doesn't exist 
2020-12-03 07:22:43,107 [IPC Server handler 4 on default port 46381] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:43,107 [Thread-403] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22: 6ms
2020-12-03 07:22:43,108 [Thread-405] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20: 5ms
2020-12-03 07:22:43,108 [Thread-281] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-553029280-172.17.0.10-1606980156826: 7ms
2020-12-03 07:22:43,108 [Thread-404] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19: 5ms
2020-12-03 07:22:43,113 [Thread-259] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-553029280-172.17.0.10-1606980156826: 11ms
2020-12-03 07:22:43,113 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21
2020-12-03 07:22:43,113 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22
2020-12-03 07:22:43,113 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20
2020-12-03 07:22:43,113 [Thread-281] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 12:08 PM with interval of 21600000ms
2020-12-03 07:22:43,113 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20, DS-c2d06ce4-d7fc-4f12-8985-fe5ab0cb5910): finished scanning block pool BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:43,113 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19
2020-12-03 07:22:43,115 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-553029280-172.17.0.10-1606980156826 (Datanode Uuid 2eee4d7d-a7de-413d-86d9-9bf7d9a28d3e) service to localhost/127.0.0.1:46381 beginning handshake with NN
2020-12-03 07:22:43,115 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22, DS-53377210-e960-4ec0-ab7e-bfaeb689ad6d): finished scanning block pool BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:43,115 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19, DS-7daa0dcb-00a1-4340-9cd9-d4a965f46cca): finished scanning block pool BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:43,113 [Thread-259] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 10:34 AM with interval of 21600000ms
2020-12-03 07:22:43,113 [Thread-384] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-553029280-172.17.0.10-1606980156826 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18: 95ms
2020-12-03 07:22:43,116 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19, DS-7daa0dcb-00a1-4340-9cd9-d4a965f46cca): no suitable block pools found to scan.  Waiting 1814399997 ms.
2020-12-03 07:22:43,113 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21, DS-38ba94e2-2ce4-49bf-99db-685a54d217e4): finished scanning block pool BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:43,116 [Thread-237] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-553029280-172.17.0.10-1606980156826: 99ms
2020-12-03 07:22:43,117 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-553029280-172.17.0.10-1606980156826 (Datanode Uuid 2f03b26a-3875-4a82-b77d-a44b653d6091) service to localhost/127.0.0.1:46381 beginning handshake with NN
2020-12-03 07:22:43,116 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22, DS-53377210-e960-4ec0-ab7e-bfaeb689ad6d): no suitable block pools found to scan.  Waiting 1814399997 ms.
2020-12-03 07:22:43,115 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20, DS-c2d06ce4-d7fc-4f12-8985-fe5ab0cb5910): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-12-03 07:22:43,118 [Thread-412] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17...
2020-12-03 07:22:43,118 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21, DS-38ba94e2-2ce4-49bf-99db-685a54d217e4): no suitable block pools found to scan.  Waiting 1814399994 ms.
2020-12-03 07:22:43,118 [IPC Server handler 5 on default port 46381] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34223, datanodeUuid=2eee4d7d-a7de-413d-86d9-9bf7d9a28d3e, infoPort=39510, infoSecurePort=0, ipcPort=42513, storageInfo=lv=-57;cid=testClusterID;nsid=1340213695;c=1606980156826) storage 2eee4d7d-a7de-413d-86d9-9bf7d9a28d3e
2020-12-03 07:22:43,119 [Thread-413] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18...
2020-12-03 07:22:43,119 [Thread-412] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-553029280-172.17.0.10-1606980156826/current/replicas doesn't exist 
2020-12-03 07:22:43,119 [Thread-413] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-553029280-172.17.0.10-1606980156826/current/replicas doesn't exist 
2020-12-03 07:22:43,120 [Thread-412] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17: 2ms
2020-12-03 07:22:43,120 [Thread-413] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18: 1ms
2020-12-03 07:22:43,120 [IPC Server handler 5 on default port 46381] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /r6/127.0.0.1:34223
2020-12-03 07:22:43,120 [IPC Server handler 5 on default port 46381] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 2eee4d7d-a7de-413d-86d9-9bf7d9a28d3e (127.0.0.1:34223).
2020-12-03 07:22:43,120 [Thread-237] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-553029280-172.17.0.10-1606980156826: 2ms
2020-12-03 07:22:43,121 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:22:43,121 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:22:43,121 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-61b82fc7-0cf4-4863-914d-b8b5d6ea1bdf): finished scanning block pool BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:43,121 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-f4dbfb9b-555a-4059-9031-6a9fbc4e3745): finished scanning block pool BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:43,121 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-553029280-172.17.0.10-1606980156826 (Datanode Uuid 2eee4d7d-a7de-413d-86d9-9bf7d9a28d3e) service to localhost/127.0.0.1:46381 successfully registered with NN
2020-12-03 07:22:43,125 [Thread-237] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 12:45 PM with interval of 21600000ms
2020-12-03 07:22:43,125 [IPC Server handler 6 on default port 46381] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:45934, datanodeUuid=2f03b26a-3875-4a82-b77d-a44b653d6091, infoPort=45288, infoSecurePort=0, ipcPort=45396, storageInfo=lv=-57;cid=testClusterID;nsid=1340213695;c=1606980156826) storage 2f03b26a-3875-4a82-b77d-a44b653d6091
2020-12-03 07:22:43,127 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-f4dbfb9b-555a-4059-9031-6a9fbc4e3745): no suitable block pools found to scan.  Waiting 1814399994 ms.
2020-12-03 07:22:43,127 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-61b82fc7-0cf4-4863-914d-b8b5d6ea1bdf): no suitable block pools found to scan.  Waiting 1814399995 ms.
2020-12-03 07:22:43,126 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:46381 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:22:43,127 [Listener at localhost/42513] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:43,128 [Listener at localhost/42513] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:43,127 [IPC Server handler 6 on default port 46381] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /r5/127.0.0.1:45934
2020-12-03 07:22:43,128 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-553029280-172.17.0.10-1606980156826 (Datanode Uuid b67852ef-41de-4129-852b-cdf1aa436090) service to localhost/127.0.0.1:46381 beginning handshake with NN
2020-12-03 07:22:43,132 [IPC Server handler 6 on default port 46381] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 2f03b26a-3875-4a82-b77d-a44b653d6091 (127.0.0.1:45934).
2020-12-03 07:22:43,133 [IPC Server handler 8 on default port 46381] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-7d23030f-e4b7-41c3-86d6-2f213d105c85 for DN 127.0.0.1:43893
2020-12-03 07:22:43,137 [IPC Server handler 8 on default port 46381] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-dee073db-38dc-4e86-b76e-620390a0797a for DN 127.0.0.1:43893
2020-12-03 07:22:43,137 [IPC Server handler 5 on default port 46381] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-1065d737-6687-4441-a64b-8cff8d91e6c0 for DN 127.0.0.1:43254
2020-12-03 07:22:43,138 [IPC Server handler 5 on default port 46381] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-969ad042-8fa6-4020-a93e-a04cbcb9ee38 for DN 127.0.0.1:43254
2020-12-03 07:22:43,139 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-553029280-172.17.0.10-1606980156826 (Datanode Uuid 2f03b26a-3875-4a82-b77d-a44b653d6091) service to localhost/127.0.0.1:46381 successfully registered with NN
2020-12-03 07:22:43,139 [IPC Server handler 2 on default port 46381] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d776ca84-07fa-451c-9d5c-5823f2a9c283 for DN 127.0.0.1:46575
2020-12-03 07:22:43,139 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:46381 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:22:43,139 [IPC Server handler 2 on default port 46381] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-0a405c40-4d26-4ad5-858e-e8b6d4387025 for DN 127.0.0.1:46575
2020-12-03 07:22:43,140 [IPC Server handler 1 on default port 46381] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-9858e8d6-2e19-4c6d-b267-646ed6d48c33 for DN 127.0.0.1:34171
2020-12-03 07:22:43,140 [IPC Server handler 1 on default port 46381] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-88f48494-4b0c-4d6a-8850-141d185c4b08 for DN 127.0.0.1:34171
2020-12-03 07:22:43,140 [IPC Server handler 3 on default port 46381] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d2a4899e-ef3e-4caa-92a7-edff2cf40784 for DN 127.0.0.1:36853
2020-12-03 07:22:43,144 [IPC Server handler 3 on default port 46381] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-30d9c94d-ca53-4e48-9d49-19bd923387f8 for DN 127.0.0.1:36853
2020-12-03 07:22:43,144 [IPC Server handler 0 on default port 46381] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-989ab400-edd5-4c26-8129-27b187f55bea for DN 127.0.0.1:39297
2020-12-03 07:22:43,145 [IPC Server handler 0 on default port 46381] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-0bcac960-967a-40ed-b8c5-387870c04d08 for DN 127.0.0.1:39297
2020-12-03 07:22:43,145 [IPC Server handler 7 on default port 46381] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-e0eebb59-dd2d-433a-93fb-dc405cc68a0e for DN 127.0.0.1:46621
2020-12-03 07:22:43,147 [IPC Server handler 7 on default port 46381] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d592cf78-a277-4a6c-8bcb-f07e7ab49315 for DN 127.0.0.1:46621
2020-12-03 07:22:43,147 [IPC Server handler 9 on default port 46381] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-529740d6-cc36-46d6-8bf0-550bd7bc3681 for DN 127.0.0.1:35093
2020-12-03 07:22:43,148 [IPC Server handler 9 on default port 46381] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-9c05daf8-c5f6-400f-9196-df42ff74880a for DN 127.0.0.1:35093
2020-12-03 07:22:43,148 [IPC Server handler 4 on default port 46381] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:44873, datanodeUuid=b67852ef-41de-4129-852b-cdf1aa436090, infoPort=43336, infoSecurePort=0, ipcPort=41578, storageInfo=lv=-57;cid=testClusterID;nsid=1340213695;c=1606980156826) storage b67852ef-41de-4129-852b-cdf1aa436090
2020-12-03 07:22:43,148 [IPC Server handler 4 on default port 46381] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /r5/127.0.0.1:44873
2020-12-03 07:22:43,148 [IPC Server handler 4 on default port 46381] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN b67852ef-41de-4129-852b-cdf1aa436090 (127.0.0.1:44873).
2020-12-03 07:22:43,149 [IPC Server handler 6 on default port 46381] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-38ba94e2-2ce4-49bf-99db-685a54d217e4 for DN 127.0.0.1:34223
2020-12-03 07:22:43,150 [IPC Server handler 6 on default port 46381] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-53377210-e960-4ec0-ab7e-bfaeb689ad6d for DN 127.0.0.1:34223
2020-12-03 07:22:43,150 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-553029280-172.17.0.10-1606980156826 (Datanode Uuid b67852ef-41de-4129-852b-cdf1aa436090) service to localhost/127.0.0.1:46381 successfully registered with NN
2020-12-03 07:22:43,151 [IPC Server handler 4 on default port 46381] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-7daa0dcb-00a1-4340-9cd9-d4a965f46cca for DN 127.0.0.1:45934
2020-12-03 07:22:43,151 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:46381 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:22:43,151 [IPC Server handler 4 on default port 46381] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c2d06ce4-d7fc-4f12-8985-fe5ab0cb5910 for DN 127.0.0.1:45934
2020-12-03 07:22:43,158 [IPC Server handler 7 on default port 46381] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-61b82fc7-0cf4-4863-914d-b8b5d6ea1bdf for DN 127.0.0.1:44873
2020-12-03 07:22:43,159 [IPC Server handler 7 on default port 46381] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-f4dbfb9b-555a-4059-9031-6a9fbc4e3745 for DN 127.0.0.1:44873
2020-12-03 07:22:43,182 [IPC Server handler 4 on default port 46381] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1566)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:43254, datanodeUuid=7e66e6f2-77d4-4df8-8ba0-4db0382c661e, infoPort=35472, infoSecurePort=0, ipcPort=37876, storageInfo=lv=-57;cid=testClusterID;nsid=1340213695;c=1606980156826), reports.length=2
2020-12-03 07:22:43,182 [IPC Server handler 5 on default port 46381] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1566)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:39297, datanodeUuid=4e9c8f7c-7ed9-464f-af37-72d5c79cf464, infoPort=33597, infoSecurePort=0, ipcPort=41006, storageInfo=lv=-57;cid=testClusterID;nsid=1340213695;c=1606980156826), reports.length=2
2020-12-03 07:22:43,182 [IPC Server handler 1 on default port 46381] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1566)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:46575, datanodeUuid=2b735e97-c043-4614-a472-ecf3212bd218, infoPort=33546, infoSecurePort=0, ipcPort=44771, storageInfo=lv=-57;cid=testClusterID;nsid=1340213695;c=1606980156826), reports.length=2
2020-12-03 07:22:43,182 [IPC Server handler 0 on default port 46381] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1566)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:36853, datanodeUuid=bb55c2ab-550b-47a9-aef1-bbeebaea4626, infoPort=43296, infoSecurePort=0, ipcPort=34080, storageInfo=lv=-57;cid=testClusterID;nsid=1340213695;c=1606980156826), reports.length=2
2020-12-03 07:22:43,182 [IPC Server handler 9 on default port 46381] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1566)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:34171, datanodeUuid=ac2c185f-8b0e-4e4f-b0c8-58495b79d4f5, infoPort=40452, infoSecurePort=0, ipcPort=35388, storageInfo=lv=-57;cid=testClusterID;nsid=1340213695;c=1606980156826), reports.length=2
2020-12-03 07:22:43,182 [IPC Server handler 3 on default port 46381] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1566)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:43893, datanodeUuid=e49ebb27-c895-49e4-980b-5953315ee3da, infoPort=37668, infoSecurePort=0, ipcPort=46185, storageInfo=lv=-57;cid=testClusterID;nsid=1340213695;c=1606980156826), reports.length=2
2020-12-03 07:22:43,188 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x7a381785c383425a: Processing first storage report for DS-88f48494-4b0c-4d6a-8850-141d185c4b08 from datanode ac2c185f-8b0e-4e4f-b0c8-58495b79d4f5
2020-12-03 07:22:43,191 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x7a381785c383425a: from storage DS-88f48494-4b0c-4d6a-8850-141d185c4b08 node DatanodeRegistration(127.0.0.1:34171, datanodeUuid=ac2c185f-8b0e-4e4f-b0c8-58495b79d4f5, infoPort=40452, infoSecurePort=0, ipcPort=35388, storageInfo=lv=-57;cid=testClusterID;nsid=1340213695;c=1606980156826), blocks: 0, hasStaleStorage: true, processing time: 3 msecs, invalidatedBlocks: 0
2020-12-03 07:22:43,191 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x2c4208464882acb8: Processing first storage report for DS-dee073db-38dc-4e86-b76e-620390a0797a from datanode e49ebb27-c895-49e4-980b-5953315ee3da
2020-12-03 07:22:43,191 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x2c4208464882acb8: from storage DS-dee073db-38dc-4e86-b76e-620390a0797a node DatanodeRegistration(127.0.0.1:43893, datanodeUuid=e49ebb27-c895-49e4-980b-5953315ee3da, infoPort=37668, infoSecurePort=0, ipcPort=46185, storageInfo=lv=-57;cid=testClusterID;nsid=1340213695;c=1606980156826), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:43,191 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x370f7ce40b1c87f3: Processing first storage report for DS-d776ca84-07fa-451c-9d5c-5823f2a9c283 from datanode 2b735e97-c043-4614-a472-ecf3212bd218
2020-12-03 07:22:43,191 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x370f7ce40b1c87f3: from storage DS-d776ca84-07fa-451c-9d5c-5823f2a9c283 node DatanodeRegistration(127.0.0.1:46575, datanodeUuid=2b735e97-c043-4614-a472-ecf3212bd218, infoPort=33546, infoSecurePort=0, ipcPort=44771, storageInfo=lv=-57;cid=testClusterID;nsid=1340213695;c=1606980156826), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:43,192 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x31122dab8ffde1e1: Processing first storage report for DS-d2a4899e-ef3e-4caa-92a7-edff2cf40784 from datanode bb55c2ab-550b-47a9-aef1-bbeebaea4626
2020-12-03 07:22:43,192 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x31122dab8ffde1e1: from storage DS-d2a4899e-ef3e-4caa-92a7-edff2cf40784 node DatanodeRegistration(127.0.0.1:36853, datanodeUuid=bb55c2ab-550b-47a9-aef1-bbeebaea4626, infoPort=43296, infoSecurePort=0, ipcPort=34080, storageInfo=lv=-57;cid=testClusterID;nsid=1340213695;c=1606980156826), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:43,192 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x5f0b7a3eabcac306: Processing first storage report for DS-989ab400-edd5-4c26-8129-27b187f55bea from datanode 4e9c8f7c-7ed9-464f-af37-72d5c79cf464
2020-12-03 07:22:43,192 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x5f0b7a3eabcac306: from storage DS-989ab400-edd5-4c26-8129-27b187f55bea node DatanodeRegistration(127.0.0.1:39297, datanodeUuid=4e9c8f7c-7ed9-464f-af37-72d5c79cf464, infoPort=33597, infoSecurePort=0, ipcPort=41006, storageInfo=lv=-57;cid=testClusterID;nsid=1340213695;c=1606980156826), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:43,192 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xacd94863aac5826d: Processing first storage report for DS-1065d737-6687-4441-a64b-8cff8d91e6c0 from datanode 7e66e6f2-77d4-4df8-8ba0-4db0382c661e
2020-12-03 07:22:43,192 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xacd94863aac5826d: from storage DS-1065d737-6687-4441-a64b-8cff8d91e6c0 node DatanodeRegistration(127.0.0.1:43254, datanodeUuid=7e66e6f2-77d4-4df8-8ba0-4db0382c661e, infoPort=35472, infoSecurePort=0, ipcPort=37876, storageInfo=lv=-57;cid=testClusterID;nsid=1340213695;c=1606980156826), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:43,193 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x7a381785c383425a: Processing first storage report for DS-9858e8d6-2e19-4c6d-b267-646ed6d48c33 from datanode ac2c185f-8b0e-4e4f-b0c8-58495b79d4f5
2020-12-03 07:22:43,193 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x7a381785c383425a: from storage DS-9858e8d6-2e19-4c6d-b267-646ed6d48c33 node DatanodeRegistration(127.0.0.1:34171, datanodeUuid=ac2c185f-8b0e-4e4f-b0c8-58495b79d4f5, infoPort=40452, infoSecurePort=0, ipcPort=35388, storageInfo=lv=-57;cid=testClusterID;nsid=1340213695;c=1606980156826), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:43,193 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x2c4208464882acb8: Processing first storage report for DS-7d23030f-e4b7-41c3-86d6-2f213d105c85 from datanode e49ebb27-c895-49e4-980b-5953315ee3da
2020-12-03 07:22:43,193 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x2c4208464882acb8: from storage DS-7d23030f-e4b7-41c3-86d6-2f213d105c85 node DatanodeRegistration(127.0.0.1:43893, datanodeUuid=e49ebb27-c895-49e4-980b-5953315ee3da, infoPort=37668, infoSecurePort=0, ipcPort=46185, storageInfo=lv=-57;cid=testClusterID;nsid=1340213695;c=1606980156826), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:43,193 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x370f7ce40b1c87f3: Processing first storage report for DS-0a405c40-4d26-4ad5-858e-e8b6d4387025 from datanode 2b735e97-c043-4614-a472-ecf3212bd218
2020-12-03 07:22:43,193 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x370f7ce40b1c87f3: from storage DS-0a405c40-4d26-4ad5-858e-e8b6d4387025 node DatanodeRegistration(127.0.0.1:46575, datanodeUuid=2b735e97-c043-4614-a472-ecf3212bd218, infoPort=33546, infoSecurePort=0, ipcPort=44771, storageInfo=lv=-57;cid=testClusterID;nsid=1340213695;c=1606980156826), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:43,194 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x31122dab8ffde1e1: Processing first storage report for DS-30d9c94d-ca53-4e48-9d49-19bd923387f8 from datanode bb55c2ab-550b-47a9-aef1-bbeebaea4626
2020-12-03 07:22:43,194 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x31122dab8ffde1e1: from storage DS-30d9c94d-ca53-4e48-9d49-19bd923387f8 node DatanodeRegistration(127.0.0.1:36853, datanodeUuid=bb55c2ab-550b-47a9-aef1-bbeebaea4626, infoPort=43296, infoSecurePort=0, ipcPort=34080, storageInfo=lv=-57;cid=testClusterID;nsid=1340213695;c=1606980156826), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:43,194 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x5f0b7a3eabcac306: Processing first storage report for DS-0bcac960-967a-40ed-b8c5-387870c04d08 from datanode 4e9c8f7c-7ed9-464f-af37-72d5c79cf464
2020-12-03 07:22:43,194 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x5f0b7a3eabcac306: from storage DS-0bcac960-967a-40ed-b8c5-387870c04d08 node DatanodeRegistration(127.0.0.1:39297, datanodeUuid=4e9c8f7c-7ed9-464f-af37-72d5c79cf464, infoPort=33597, infoSecurePort=0, ipcPort=41006, storageInfo=lv=-57;cid=testClusterID;nsid=1340213695;c=1606980156826), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:43,194 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xacd94863aac5826d: Processing first storage report for DS-969ad042-8fa6-4020-a93e-a04cbcb9ee38 from datanode 7e66e6f2-77d4-4df8-8ba0-4db0382c661e
2020-12-03 07:22:43,194 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xacd94863aac5826d: from storage DS-969ad042-8fa6-4020-a93e-a04cbcb9ee38 node DatanodeRegistration(127.0.0.1:43254, datanodeUuid=7e66e6f2-77d4-4df8-8ba0-4db0382c661e, infoPort=35472, infoSecurePort=0, ipcPort=37876, storageInfo=lv=-57;cid=testClusterID;nsid=1340213695;c=1606980156826), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:43,195 [IPC Server handler 9 on default port 46381] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2700)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x7a381785c383425a
2020-12-03 07:22:43,195 [IPC Server handler 3 on default port 46381] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2700)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x2c4208464882acb8
2020-12-03 07:22:43,195 [IPC Server handler 1 on default port 46381] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2700)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x370f7ce40b1c87f3
2020-12-03 07:22:43,195 [IPC Server handler 0 on default port 46381] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2700)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x31122dab8ffde1e1
2020-12-03 07:22:43,195 [IPC Server handler 5 on default port 46381] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2700)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x5f0b7a3eabcac306
2020-12-03 07:22:43,196 [IPC Server handler 4 on default port 46381] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2700)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xacd94863aac5826d
2020-12-03 07:22:43,228 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x5f0b7a3eabcac306,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 11 msec to generate and 52 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:43,228 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x7a381785c383425a,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 11 msec to generate and 52 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:43,228 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x370f7ce40b1c87f3,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 6 msec to generate and 52 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:43,228 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x2c4208464882acb8,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 52 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:43,228 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xacd94863aac5826d,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 9 msec to generate and 52 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:43,228 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x31122dab8ffde1e1,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 7 msec to generate and 52 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:43,229 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:43,229 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:43,228 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:43,228 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:43,228 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:43,229 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:43,234 [IPC Server handler 2 on default port 46381] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:43,237 [Listener at localhost/42513] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:22:43,245 [IPC Server handler 6 on default port 46381] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:43,248 [Listener at localhost/42513] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:22:43,262 [IPC Server handler 7 on default port 46381] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=enableErasureCodingPolicy	src=RS-6-3-1024k	dst=null	perm=null	proto=rpc
2020-12-03 07:22:43,290 [IPC Server handler 8 on default port 46381] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setErasureCodingPolicy	src=/	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:22:43,298 [Listener at localhost/42513] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopDataNode(2331)) - MiniDFSCluster Stopping DataNode host9:44873 from a total of 11 datanodes.
2020-12-03 07:22:43,298 [Listener at localhost/42513] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:22:43,298 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@1f2d2181] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:22:43,300 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-61b82fc7-0cf4-4863-914d-b8b5d6ea1bdf) exiting.
2020-12-03 07:22:43,300 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-f4dbfb9b-555a-4059-9031-6a9fbc4e3745) exiting.
2020-12-03 07:22:43,325 [Listener at localhost/42513] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@54f5f647{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:22:43,330 [Listener at localhost/42513] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6979efad{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:43,330 [Listener at localhost/42513] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@530a8454{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:43,331 [Listener at localhost/42513] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6c44052e{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:43,333 [Listener at localhost/42513] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 41578
2020-12-03 07:22:43,336 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:43,336 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:43,341 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:43,343 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-553029280-172.17.0.10-1606980156826 (Datanode Uuid b67852ef-41de-4129-852b-cdf1aa436090) service to localhost/127.0.0.1:46381
2020-12-03 07:22:43,344 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-553029280-172.17.0.10-1606980156826 (Datanode Uuid b67852ef-41de-4129-852b-cdf1aa436090)
2020-12-03 07:22:43,344 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:43,344 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-553029280-172.17.0.10-1606980156826] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:43,345 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-553029280-172.17.0.10-1606980156826] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:43,350 [Listener at localhost/42513] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:22:43,350 [Listener at localhost/42513] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:22:43,351 [Listener at localhost/42513] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:22:43,351 [Listener at localhost/42513] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:22:43,358 [Listener at localhost/42513] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:22:43,360 [Listener at localhost/42513] INFO  hdfs.StateChange (DatanodeManager.java:removeDeadDatanode(754)) - BLOCK* removeDeadDatanode: lost heartbeat from 127.0.0.1:44873, removeBlocksFromBlockMap true
2020-12-03 07:22:43,361 [Listener at localhost/42513] INFO  net.NetworkTopology (NetworkTopology.java:remove(219)) - Removing a node: /r5/127.0.0.1:44873
2020-12-03 07:22:43,361 [Listener at localhost/42513] INFO  blockmanagement.TestReconstructStripedBlocksWithRackAwareness (TestReconstructStripedBlocksWithRackAwareness.java:stopDataNode(120)) - stop datanode host9
2020-12-03 07:22:43,361 [Listener at localhost/42513] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopDataNode(2331)) - MiniDFSCluster Stopping DataNode host10:45934 from a total of 10 datanodes.
2020-12-03 07:22:43,362 [Listener at localhost/42513] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:22:43,362 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@77e2a6e2] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:22:43,365 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19, DS-7daa0dcb-00a1-4340-9cd9-d4a965f46cca) exiting.
2020-12-03 07:22:43,365 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20, DS-c2d06ce4-d7fc-4f12-8985-fe5ab0cb5910) exiting.
2020-12-03 07:22:43,389 [Listener at localhost/42513] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@71b1a49c{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:22:43,390 [Listener at localhost/42513] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@73e132e0{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:43,390 [Listener at localhost/42513] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@b273a59{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:43,391 [Listener at localhost/42513] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5bf61e67{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:43,392 [Listener at localhost/42513] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 45396
2020-12-03 07:22:43,397 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:43,397 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:43,398 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:43,403 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-553029280-172.17.0.10-1606980156826 (Datanode Uuid 2f03b26a-3875-4a82-b77d-a44b653d6091) service to localhost/127.0.0.1:46381
2020-12-03 07:22:43,404 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-553029280-172.17.0.10-1606980156826 (Datanode Uuid 2f03b26a-3875-4a82-b77d-a44b653d6091)
2020-12-03 07:22:43,404 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:43,404 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19/current/BP-553029280-172.17.0.10-1606980156826] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:43,404 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20/current/BP-553029280-172.17.0.10-1606980156826] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:43,411 [Listener at localhost/42513] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:22:43,411 [Listener at localhost/42513] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:22:43,413 [Listener at localhost/42513] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:22:43,413 [Listener at localhost/42513] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:22:43,415 [Listener at localhost/42513] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:22:43,416 [Listener at localhost/42513] INFO  hdfs.StateChange (DatanodeManager.java:removeDeadDatanode(754)) - BLOCK* removeDeadDatanode: lost heartbeat from 127.0.0.1:45934, removeBlocksFromBlockMap true
2020-12-03 07:22:43,416 [Listener at localhost/42513] INFO  net.NetworkTopology (NetworkTopology.java:remove(219)) - Removing a node: /r5/127.0.0.1:45934
2020-12-03 07:22:43,416 [Listener at localhost/42513] INFO  blockmanagement.TestReconstructStripedBlocksWithRackAwareness (TestReconstructStripedBlocksWithRackAwareness.java:stopDataNode(120)) - stop datanode host10
2020-12-03 07:22:43,423 [IPC Server handler 0 on default port 46381] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:22:43,462 [IPC Server handler 3 on default port 46381] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/foo	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:22:43,528 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1998)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-12-03 07:22:43,598 [IPC Server handler 9 on default port 46381] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(427)) - storageTypes={DISK=9}
2020-12-03 07:22:43,601 [IPC Server handler 9 on default port 46381] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyRackFaultTolerant.java:chooseTargetInOrder(135)) - Chosen nodes: [[DISK]DS-989ab400-edd5-4c26-8129-27b187f55bea:NORMAL:127.0.0.1:39297, [DISK]DS-9c05daf8-c5f6-400f-9196-df42ff74880a:NORMAL:127.0.0.1:35093, [DISK]DS-dee073db-38dc-4e86-b76e-620390a0797a:NORMAL:127.0.0.1:43893, [DISK]DS-d592cf78-a277-4a6c-8bcb-f07e7ab49315:NORMAL:127.0.0.1:46621, [DISK]DS-38ba94e2-2ce4-49bf-99db-685a54d217e4:NORMAL:127.0.0.1:34223]
2020-12-03 07:22:43,601 [IPC Server handler 9 on default port 46381] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyRackFaultTolerant.java:chooseTargetInOrder(136)) - Excluded nodes: [127.0.0.1:35093, 127.0.0.1:39297, 127.0.0.1:43893, 127.0.0.1:46621, 127.0.0.1:34223]
2020-12-03 07:22:43,608 [IPC Server handler 9 on default port 46381] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_-9223372036854775792_1001, replicas=127.0.0.1:39297, 127.0.0.1:46575, 127.0.0.1:43893, 127.0.0.1:36853, 127.0.0.1:34223, 127.0.0.1:35093, 127.0.0.1:34171, 127.0.0.1:46621, 127.0.0.1:43254 for /foo
2020-12-03 07:22:43,657 [Thread-417] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:43,703 [Thread-418] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:43,718 [Thread-419] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:43,741 [Thread-420] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:43,760 [Thread-421] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:43,779 [Thread-422] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:43,798 [DataXceiver for client DFSClient_NONMAPREDUCE_-2086109447_1 at /127.0.0.1:36092 [Receiving block BP-553029280-172.17.0.10-1606980156826:blk_-9223372036854775792_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-553029280-172.17.0.10-1606980156826:blk_-9223372036854775792_1001 src: /127.0.0.1:36092 dest: /127.0.0.1:39297
2020-12-03 07:22:43,798 [DataXceiver for client DFSClient_NONMAPREDUCE_-2086109447_1 at /127.0.0.1:53228 [Receiving block BP-553029280-172.17.0.10-1606980156826:blk_-9223372036854775789_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-553029280-172.17.0.10-1606980156826:blk_-9223372036854775789_1001 src: /127.0.0.1:53228 dest: /127.0.0.1:36853
2020-12-03 07:22:43,798 [DataXceiver for client DFSClient_NONMAPREDUCE_-2086109447_1 at /127.0.0.1:40498 [Receiving block BP-553029280-172.17.0.10-1606980156826:blk_-9223372036854775788_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-553029280-172.17.0.10-1606980156826:blk_-9223372036854775788_1001 src: /127.0.0.1:40498 dest: /127.0.0.1:34223
2020-12-03 07:22:43,798 [DataXceiver for client DFSClient_NONMAPREDUCE_-2086109447_1 at /127.0.0.1:53048 [Receiving block BP-553029280-172.17.0.10-1606980156826:blk_-9223372036854775787_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-553029280-172.17.0.10-1606980156826:blk_-9223372036854775787_1001 src: /127.0.0.1:53048 dest: /127.0.0.1:35093
2020-12-03 07:22:43,798 [DataXceiver for client DFSClient_NONMAPREDUCE_-2086109447_1 at /127.0.0.1:39628 [Receiving block BP-553029280-172.17.0.10-1606980156826:blk_-9223372036854775791_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-553029280-172.17.0.10-1606980156826:blk_-9223372036854775791_1001 src: /127.0.0.1:39628 dest: /127.0.0.1:46575
2020-12-03 07:22:43,799 [DataXceiver for client DFSClient_NONMAPREDUCE_-2086109447_1 at /127.0.0.1:56758 [Receiving block BP-553029280-172.17.0.10-1606980156826:blk_-9223372036854775790_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-553029280-172.17.0.10-1606980156826:blk_-9223372036854775790_1001 src: /127.0.0.1:56758 dest: /127.0.0.1:43893
2020-12-03 07:22:43,824 [Thread-423] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:43,833 [DataXceiver for client DFSClient_NONMAPREDUCE_-2086109447_1 at /127.0.0.1:56590 [Receiving block BP-553029280-172.17.0.10-1606980156826:blk_-9223372036854775786_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-553029280-172.17.0.10-1606980156826:blk_-9223372036854775786_1001 src: /127.0.0.1:56590 dest: /127.0.0.1:34171
2020-12-03 07:22:43,908 [Thread-424] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:43,910 [Thread-425] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:43,915 [DataXceiver for client DFSClient_NONMAPREDUCE_-2086109447_1 at /127.0.0.1:52428 [Receiving block BP-553029280-172.17.0.10-1606980156826:blk_-9223372036854775785_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-553029280-172.17.0.10-1606980156826:blk_-9223372036854775785_1001 src: /127.0.0.1:52428 dest: /127.0.0.1:46621
2020-12-03 07:22:43,932 [DataXceiver for client DFSClient_NONMAPREDUCE_-2086109447_1 at /127.0.0.1:38190 [Receiving block BP-553029280-172.17.0.10-1606980156826:blk_-9223372036854775784_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-553029280-172.17.0.10-1606980156826:blk_-9223372036854775784_1001 src: /127.0.0.1:38190 dest: /127.0.0.1:43254
2020-12-03 07:22:44,205 [PacketResponder: BP-553029280-172.17.0.10-1606980156826:blk_-9223372036854775792_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:36092, dest: /127.0.0.1:39297, bytes: 2097152, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2086109447_1, offset: 0, srvID: 4e9c8f7c-7ed9-464f-af37-72d5c79cf464, blockid: BP-553029280-172.17.0.10-1606980156826:blk_-9223372036854775792_1001, duration(ns): 331780655
2020-12-03 07:22:44,206 [PacketResponder: BP-553029280-172.17.0.10-1606980156826:blk_-9223372036854775792_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-553029280-172.17.0.10-1606980156826:blk_-9223372036854775792_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:22:44,249 [PacketResponder: BP-553029280-172.17.0.10-1606980156826:blk_-9223372036854775791_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39628, dest: /127.0.0.1:46575, bytes: 2097152, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2086109447_1, offset: 0, srvID: 2b735e97-c043-4614-a472-ecf3212bd218, blockid: BP-553029280-172.17.0.10-1606980156826:blk_-9223372036854775791_1001, duration(ns): 357542027
2020-12-03 07:22:44,251 [PacketResponder: BP-553029280-172.17.0.10-1606980156826:blk_-9223372036854775791_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-553029280-172.17.0.10-1606980156826:blk_-9223372036854775791_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:22:44,279 [PacketResponder: BP-553029280-172.17.0.10-1606980156826:blk_-9223372036854775790_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56758, dest: /127.0.0.1:43893, bytes: 2097152, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2086109447_1, offset: 0, srvID: e49ebb27-c895-49e4-980b-5953315ee3da, blockid: BP-553029280-172.17.0.10-1606980156826:blk_-9223372036854775790_1001, duration(ns): 415563067
2020-12-03 07:22:44,280 [PacketResponder: BP-553029280-172.17.0.10-1606980156826:blk_-9223372036854775790_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-553029280-172.17.0.10-1606980156826:blk_-9223372036854775790_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:22:44,284 [IPC Server handler 0 on default port 46381] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1627)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:46575, datanodeUuid=2b735e97-c043-4614-a472-ecf3212bd218, infoPort=33546, infoSecurePort=0, ipcPort=44771, storageInfo=lv=-57;cid=testClusterID;nsid=1340213695;c=1606980156826) 1 blocks.
2020-12-03 07:22:44,284 [IPC Server handler 8 on default port 46381] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1627)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:39297, datanodeUuid=4e9c8f7c-7ed9-464f-af37-72d5c79cf464, infoPort=33597, infoSecurePort=0, ipcPort=41006, storageInfo=lv=-57;cid=testClusterID;nsid=1340213695;c=1606980156826) 1 blocks.
2020-12-03 07:22:44,290 [PacketResponder: BP-553029280-172.17.0.10-1606980156826:blk_-9223372036854775789_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:53228, dest: /127.0.0.1:36853, bytes: 2097152, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2086109447_1, offset: 0, srvID: bb55c2ab-550b-47a9-aef1-bbeebaea4626, blockid: BP-553029280-172.17.0.10-1606980156826:blk_-9223372036854775789_1001, duration(ns): 401409584
2020-12-03 07:22:44,290 [PacketResponder: BP-553029280-172.17.0.10-1606980156826:blk_-9223372036854775789_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-553029280-172.17.0.10-1606980156826:blk_-9223372036854775789_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:22:44,294 [IPC Server handler 9 on default port 46381] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1627)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:43893, datanodeUuid=e49ebb27-c895-49e4-980b-5953315ee3da, infoPort=37668, infoSecurePort=0, ipcPort=46185, storageInfo=lv=-57;cid=testClusterID;nsid=1340213695;c=1606980156826) 1 blocks.
2020-12-03 07:22:44,296 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4021)) - Reported block blk_-9223372036854775791_1001 on 127.0.0.1:46575 size 2097152 replicaState = FINALIZED
2020-12-03 07:22:44,294 [IPC Server handler 3 on default port 46381] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1627)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:36853, datanodeUuid=bb55c2ab-550b-47a9-aef1-bbeebaea4626, infoPort=43296, infoSecurePort=0, ipcPort=34080, storageInfo=lv=-57;cid=testClusterID;nsid=1340213695;c=1606980156826) 1 blocks.
2020-12-03 07:22:44,296 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4044)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-12-03 07:22:44,298 [PacketResponder: BP-553029280-172.17.0.10-1606980156826:blk_-9223372036854775788_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40498, dest: /127.0.0.1:34223, bytes: 2097152, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2086109447_1, offset: 0, srvID: 2eee4d7d-a7de-413d-86d9-9bf7d9a28d3e, blockid: BP-553029280-172.17.0.10-1606980156826:blk_-9223372036854775788_1001, duration(ns): 410672461
2020-12-03 07:22:44,299 [PacketResponder: BP-553029280-172.17.0.10-1606980156826:blk_-9223372036854775788_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-553029280-172.17.0.10-1606980156826:blk_-9223372036854775788_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:22:44,307 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3351)) - BLOCK* addStoredBlock: 127.0.0.1:46575 is added to blk_-9223372036854775792_1001 (size=0)
2020-12-03 07:22:44,307 [IPC Server handler 4 on default port 46381] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1627)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34223, datanodeUuid=2eee4d7d-a7de-413d-86d9-9bf7d9a28d3e, infoPort=39510, infoSecurePort=0, ipcPort=42513, storageInfo=lv=-57;cid=testClusterID;nsid=1340213695;c=1606980156826) 1 blocks.
2020-12-03 07:22:44,316 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4154)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775791_1001 is received from 127.0.0.1:46575
2020-12-03 07:22:44,316 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4157)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:46575 receiving: 0, received: 1, deleted: 0
2020-12-03 07:22:44,317 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4021)) - Reported block blk_-9223372036854775792_1001 on 127.0.0.1:39297 size 2097152 replicaState = FINALIZED
2020-12-03 07:22:44,317 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4044)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-12-03 07:22:44,317 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3351)) - BLOCK* addStoredBlock: 127.0.0.1:39297 is added to blk_-9223372036854775792_1001 (size=0)
2020-12-03 07:22:44,317 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4154)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775792_1001 is received from 127.0.0.1:39297
2020-12-03 07:22:44,317 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4157)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:39297 receiving: 0, received: 1, deleted: 0
2020-12-03 07:22:44,317 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4021)) - Reported block blk_-9223372036854775790_1001 on 127.0.0.1:43893 size 2097152 replicaState = FINALIZED
2020-12-03 07:22:44,317 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4044)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-12-03 07:22:44,318 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3351)) - BLOCK* addStoredBlock: 127.0.0.1:43893 is added to blk_-9223372036854775792_1001 (size=0)
2020-12-03 07:22:44,318 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4154)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775790_1001 is received from 127.0.0.1:43893
2020-12-03 07:22:44,318 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4157)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:43893 receiving: 0, received: 1, deleted: 0
2020-12-03 07:22:44,318 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4021)) - Reported block blk_-9223372036854775789_1001 on 127.0.0.1:36853 size 2097152 replicaState = FINALIZED
2020-12-03 07:22:44,318 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4044)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-12-03 07:22:44,318 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3351)) - BLOCK* addStoredBlock: 127.0.0.1:36853 is added to blk_-9223372036854775792_1001 (size=0)
2020-12-03 07:22:44,318 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4154)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775789_1001 is received from 127.0.0.1:36853
2020-12-03 07:22:44,319 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4157)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:36853 receiving: 0, received: 1, deleted: 0
2020-12-03 07:22:44,319 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4021)) - Reported block blk_-9223372036854775788_1001 on 127.0.0.1:34223 size 2097152 replicaState = FINALIZED
2020-12-03 07:22:44,319 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4044)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-12-03 07:22:44,319 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3351)) - BLOCK* addStoredBlock: 127.0.0.1:34223 is added to blk_-9223372036854775792_1001 (size=0)
2020-12-03 07:22:44,319 [PacketResponder: BP-553029280-172.17.0.10-1606980156826:blk_-9223372036854775787_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:53048, dest: /127.0.0.1:35093, bytes: 2097152, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2086109447_1, offset: 0, srvID: 0fb937fa-2aba-45e3-8780-b03d3f5859b2, blockid: BP-553029280-172.17.0.10-1606980156826:blk_-9223372036854775787_1001, duration(ns): 451484931
2020-12-03 07:22:44,319 [PacketResponder: BP-553029280-172.17.0.10-1606980156826:blk_-9223372036854775787_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-553029280-172.17.0.10-1606980156826:blk_-9223372036854775787_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:22:44,319 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4154)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775788_1001 is received from 127.0.0.1:34223
2020-12-03 07:22:44,320 [IPC Server handler 1 on default port 46381] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1627)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:35093, datanodeUuid=0fb937fa-2aba-45e3-8780-b03d3f5859b2, infoPort=44155, infoSecurePort=0, ipcPort=36965, storageInfo=lv=-57;cid=testClusterID;nsid=1340213695;c=1606980156826) 1 blocks.
2020-12-03 07:22:44,320 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4157)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34223 receiving: 0, received: 1, deleted: 0
2020-12-03 07:22:44,321 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4021)) - Reported block blk_-9223372036854775787_1001 on 127.0.0.1:35093 size 2097152 replicaState = FINALIZED
2020-12-03 07:22:44,321 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4044)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-12-03 07:22:44,321 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3351)) - BLOCK* addStoredBlock: 127.0.0.1:35093 is added to blk_-9223372036854775792_1001 (size=0)
2020-12-03 07:22:44,321 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4154)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775787_1001 is received from 127.0.0.1:35093
2020-12-03 07:22:44,321 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4157)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:35093 receiving: 0, received: 1, deleted: 0
2020-12-03 07:22:44,329 [PacketResponder: BP-553029280-172.17.0.10-1606980156826:blk_-9223372036854775786_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56590, dest: /127.0.0.1:34171, bytes: 2097152, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2086109447_1, offset: 0, srvID: ac2c185f-8b0e-4e4f-b0c8-58495b79d4f5, blockid: BP-553029280-172.17.0.10-1606980156826:blk_-9223372036854775786_1001, duration(ns): 436004513
2020-12-03 07:22:44,329 [PacketResponder: BP-553029280-172.17.0.10-1606980156826:blk_-9223372036854775786_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-553029280-172.17.0.10-1606980156826:blk_-9223372036854775786_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:22:44,336 [PacketResponder: BP-553029280-172.17.0.10-1606980156826:blk_-9223372036854775785_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:52428, dest: /127.0.0.1:46621, bytes: 2097152, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2086109447_1, offset: 0, srvID: adab20bb-214b-4a74-bb76-b832f6e8c8d9, blockid: BP-553029280-172.17.0.10-1606980156826:blk_-9223372036854775785_1001, duration(ns): 402869685
2020-12-03 07:22:44,336 [IPC Server handler 5 on default port 46381] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1627)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34171, datanodeUuid=ac2c185f-8b0e-4e4f-b0c8-58495b79d4f5, infoPort=40452, infoSecurePort=0, ipcPort=35388, storageInfo=lv=-57;cid=testClusterID;nsid=1340213695;c=1606980156826) 1 blocks.
2020-12-03 07:22:44,337 [PacketResponder: BP-553029280-172.17.0.10-1606980156826:blk_-9223372036854775785_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-553029280-172.17.0.10-1606980156826:blk_-9223372036854775785_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:22:44,337 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4021)) - Reported block blk_-9223372036854775786_1001 on 127.0.0.1:34171 size 2097152 replicaState = FINALIZED
2020-12-03 07:22:44,337 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4044)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-12-03 07:22:44,338 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3351)) - BLOCK* addStoredBlock: 127.0.0.1:34171 is added to blk_-9223372036854775792_1001 (size=0)
2020-12-03 07:22:44,338 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4154)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775786_1001 is received from 127.0.0.1:34171
2020-12-03 07:22:44,338 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4157)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34171 receiving: 0, received: 1, deleted: 0
2020-12-03 07:22:44,349 [PacketResponder: BP-553029280-172.17.0.10-1606980156826:blk_-9223372036854775784_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38190, dest: /127.0.0.1:43254, bytes: 2097152, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2086109447_1, offset: 0, srvID: 7e66e6f2-77d4-4df8-8ba0-4db0382c661e, blockid: BP-553029280-172.17.0.10-1606980156826:blk_-9223372036854775784_1001, duration(ns): 390698622
2020-12-03 07:22:44,349 [PacketResponder: BP-553029280-172.17.0.10-1606980156826:blk_-9223372036854775784_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-553029280-172.17.0.10-1606980156826:blk_-9223372036854775784_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:22:44,351 [IPC Server handler 2 on default port 46381] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1627)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:43254, datanodeUuid=7e66e6f2-77d4-4df8-8ba0-4db0382c661e, infoPort=35472, infoSecurePort=0, ipcPort=37876, storageInfo=lv=-57;cid=testClusterID;nsid=1340213695;c=1606980156826) 1 blocks.
2020-12-03 07:22:44,351 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4021)) - Reported block blk_-9223372036854775784_1001 on 127.0.0.1:43254 size 2097152 replicaState = FINALIZED
2020-12-03 07:22:44,351 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4044)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-12-03 07:22:44,351 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3351)) - BLOCK* addStoredBlock: 127.0.0.1:43254 is added to blk_-9223372036854775792_1001 (size=0)
2020-12-03 07:22:44,351 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4154)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775784_1001 is received from 127.0.0.1:43254
2020-12-03 07:22:44,351 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4157)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:43254 receiving: 0, received: 1, deleted: 0
2020-12-03 07:22:44,355 [IPC Server handler 6 on default port 46381] DEBUG BlockStateChange (LowRedundancyBlocks.java:add(293)) - BLOCK* NameSystem.LowRedundancyBlock.add: blk_-9223372036854775792_1001 has only 8 replicas and need 9 replicas so is added to neededReconstructions at priority level 2
2020-12-03 07:22:44,355 [IPC Server handler 6 on default port 46381] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /foo is closed by DFSClient_NONMAPREDUCE_-2086109447_1
2020-12-03 07:22:44,357 [IPC Server handler 7 on default port 46381] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1627)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:46621, datanodeUuid=adab20bb-214b-4a74-bb76-b832f6e8c8d9, infoPort=39992, infoSecurePort=0, ipcPort=41711, storageInfo=lv=-57;cid=testClusterID;nsid=1340213695;c=1606980156826) 1 blocks.
2020-12-03 07:22:44,357 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4021)) - Reported block blk_-9223372036854775785_1001 on 127.0.0.1:46621 size 2097152 replicaState = FINALIZED
2020-12-03 07:22:44,357 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4044)) - In memory blockUCState = COMPLETE
2020-12-03 07:22:44,357 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3351)) - BLOCK* addStoredBlock: 127.0.0.1:46621 is added to blk_-9223372036854775792_1001 (size=12582912)
2020-12-03 07:22:44,359 [Block report processor] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775792_1001 from priority queue 2
2020-12-03 07:22:44,359 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4154)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775785_1001 is received from 127.0.0.1:46621
2020-12-03 07:22:44,359 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4157)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:46621 receiving: 0, received: 1, deleted: 0
2020-12-03 07:22:44,360 [Listener at localhost/42513] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:22:44,360 [Listener at localhost/42513] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:22:44,361 [Listener at localhost/42513] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:22:44,364 [Listener at localhost/42513] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:44,364 [Listener at localhost/42513] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:22:44,365 [Listener at localhost/42513] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is host9
2020-12-03 07:22:44,365 [Listener at localhost/42513] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:44,365 [Listener at localhost/42513] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:22:44,366 [Listener at localhost/42513] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:40666
2020-12-03 07:22:44,366 [Listener at localhost/42513] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:22:44,367 [Listener at localhost/42513] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:22:44,368 [Listener at localhost/42513] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:44,369 [Listener at localhost/42513] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:44,370 [Listener at localhost/42513] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:22:44,371 [Listener at localhost/42513] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:44,372 [Listener at localhost/42513] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:44,373 [Listener at localhost/42513] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:22:44,373 [Listener at localhost/42513] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:44,373 [Listener at localhost/42513] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:44,374 [Listener at localhost/42513] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 38083
2020-12-03 07:22:44,374 [Listener at localhost/42513] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:44,376 [Listener at localhost/42513] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@257cc1fc{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:44,376 [Listener at localhost/42513] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@57adfab0{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:44,384 [Listener at localhost/42513] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@34dc85a{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:22:44,387 [Listener at localhost/42513] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@371f7862{HTTP/1.1,[http/1.1]}{localhost:38083}
2020-12-03 07:22:44,387 [Listener at localhost/42513] INFO  server.Server (Server.java:doStart(419)) - Started @9588ms
2020-12-03 07:22:44,407 [Listener at localhost/42513] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:36137
2020-12-03 07:22:44,407 [Listener at localhost/42513] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:22:44,407 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5a6482a9] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:44,408 [Listener at localhost/42513] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:22:44,408 [Listener at localhost/42513] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:44,409 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:44,449 [Listener at localhost/38568] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:38568
2020-12-03 07:22:44,467 [Listener at localhost/38568] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:22:44,467 [Listener at localhost/38568] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:22:44,468 [Thread-465] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46381 starting to offer service
2020-12-03 07:22:44,475 [Thread-465] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46381
2020-12-03 07:22:44,475 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:44,475 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:44,482 [Thread-465] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:44,484 [IPC Server handler 8 on default port 46381] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:44,486 [Listener at localhost/38568] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:44,486 [Listener at localhost/38568] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:44,528 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1998)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-12-03 07:22:44,535 [Thread-465] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/in_use.lock acquired by nodename 5029@5a8b1b2f5494
2020-12-03 07:22:44,589 [IPC Server handler 9 on default port 46381] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:44,591 [Listener at localhost/38568] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:44,591 [Listener at localhost/38568] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:44,619 [Thread-465] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/in_use.lock acquired by nodename 5029@5a8b1b2f5494
2020-12-03 07:22:44,659 [Thread-465] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:44,660 [Thread-465] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:44,694 [IPC Server handler 3 on default port 46381] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:44,696 [Listener at localhost/38568] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:44,696 [Listener at localhost/38568] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:44,718 [Thread-465] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:44,718 [Thread-465] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:44,791 [Thread-465] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1340213695;bpid=BP-553029280-172.17.0.10-1606980156826;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1340213695;c=1606980156826;bpid=BP-553029280-172.17.0.10-1606980156826;dnuuid=b67852ef-41de-4129-852b-cdf1aa436090
2020-12-03 07:22:44,794 [Thread-465] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-61b82fc7-0cf4-4863-914d-b8b5d6ea1bdf
2020-12-03 07:22:44,794 [Thread-465] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, StorageType: DISK
2020-12-03 07:22:44,798 [IPC Server handler 4 on default port 46381] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:44,799 [Thread-465] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-f4dbfb9b-555a-4059-9031-6a9fbc4e3745
2020-12-03 07:22:44,802 [Thread-465] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, StorageType: DISK
2020-12-03 07:22:44,803 [Listener at localhost/38568] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:44,803 [Thread-465] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:22:44,805 [Thread-465] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:22:44,803 [Listener at localhost/38568] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:44,806 [Thread-465] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:22:44,806 [Thread-465] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:22:44,806 [Thread-465] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:22:44,806 [Thread-465] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:44,807 [Thread-478] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17...
2020-12-03 07:22:44,807 [Thread-479] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18...
2020-12-03 07:22:44,810 [Thread-478] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-553029280-172.17.0.10-1606980156826/current: 24576
2020-12-03 07:22:44,812 [Thread-479] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-553029280-172.17.0.10-1606980156826/current: 24576
2020-12-03 07:22:44,818 [Thread-478] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-553029280-172.17.0.10-1606980156826 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17: 11ms
2020-12-03 07:22:44,822 [Thread-479] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-553029280-172.17.0.10-1606980156826 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18: 15ms
2020-12-03 07:22:44,822 [Thread-465] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-553029280-172.17.0.10-1606980156826: 16ms
2020-12-03 07:22:44,823 [Thread-480] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17...
2020-12-03 07:22:44,823 [Thread-481] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18...
2020-12-03 07:22:44,823 [Thread-480] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-553029280-172.17.0.10-1606980156826/current/replicas doesn't exist 
2020-12-03 07:22:44,823 [Thread-481] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-553029280-172.17.0.10-1606980156826/current/replicas doesn't exist 
2020-12-03 07:22:44,823 [Thread-481] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18: 0ms
2020-12-03 07:22:44,823 [Thread-480] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17: 1ms
2020-12-03 07:22:44,826 [Thread-465] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-553029280-172.17.0.10-1606980156826: 3ms
2020-12-03 07:22:44,839 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-61b82fc7-0cf4-4863-914d-b8b5d6ea1bdf): no suitable block pools found to scan.  Waiting 1814398282 ms.
2020-12-03 07:22:44,839 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-f4dbfb9b-555a-4059-9031-6a9fbc4e3745): no suitable block pools found to scan.  Waiting 1814398282 ms.
2020-12-03 07:22:44,840 [Thread-465] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:47 AM with interval of 21600000ms
2020-12-03 07:22:44,842 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-553029280-172.17.0.10-1606980156826 (Datanode Uuid b67852ef-41de-4129-852b-cdf1aa436090) service to localhost/127.0.0.1:46381 beginning handshake with NN
2020-12-03 07:22:44,844 [IPC Server handler 1 on default port 46381] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:40666, datanodeUuid=b67852ef-41de-4129-852b-cdf1aa436090, infoPort=36137, infoSecurePort=0, ipcPort=38568, storageInfo=lv=-57;cid=testClusterID;nsid=1340213695;c=1606980156826) storage b67852ef-41de-4129-852b-cdf1aa436090
2020-12-03 07:22:44,844 [IPC Server handler 1 on default port 46381] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1078)) - BLOCK* registerDatanode: 127.0.0.1:44873 is replaced by DatanodeRegistration(127.0.0.1:40666, datanodeUuid=b67852ef-41de-4129-852b-cdf1aa436090, infoPort=36137, infoSecurePort=0, ipcPort=38568, storageInfo=lv=-57;cid=testClusterID;nsid=1340213695;c=1606980156826) with the same storageID b67852ef-41de-4129-852b-cdf1aa436090
2020-12-03 07:22:44,844 [IPC Server handler 1 on default port 46381] INFO  net.NetworkTopology (NetworkTopology.java:remove(219)) - Removing a node: /r5/127.0.0.1:44873
2020-12-03 07:22:44,844 [IPC Server handler 1 on default port 46381] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /r5/127.0.0.1:40666
2020-12-03 07:22:44,845 [IPC Server handler 1 on default port 46381] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateFailedStorage(562)) - [DISK]DS-f4dbfb9b-555a-4059-9031-6a9fbc4e3745:NORMAL:127.0.0.1:40666 failed.
2020-12-03 07:22:44,845 [IPC Server handler 1 on default port 46381] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateFailedStorage(562)) - [DISK]DS-61b82fc7-0cf4-4863-914d-b8b5d6ea1bdf:NORMAL:127.0.0.1:40666 failed.
2020-12-03 07:22:44,845 [IPC Server handler 1 on default port 46381] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:pruneStorageMap(548)) - Removed storage [DISK]DS-f4dbfb9b-555a-4059-9031-6a9fbc4e3745:FAILED:127.0.0.1:40666 from DataNode 127.0.0.1:40666
2020-12-03 07:22:44,845 [IPC Server handler 1 on default port 46381] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:pruneStorageMap(548)) - Removed storage [DISK]DS-61b82fc7-0cf4-4863-914d-b8b5d6ea1bdf:FAILED:127.0.0.1:40666 from DataNode 127.0.0.1:40666
2020-12-03 07:22:44,846 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-553029280-172.17.0.10-1606980156826 (Datanode Uuid b67852ef-41de-4129-852b-cdf1aa436090) service to localhost/127.0.0.1:46381 successfully registered with NN
2020-12-03 07:22:44,846 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:46381 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:22:44,851 [IPC Server handler 5 on default port 46381] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-61b82fc7-0cf4-4863-914d-b8b5d6ea1bdf for DN 127.0.0.1:40666
2020-12-03 07:22:44,853 [IPC Server handler 5 on default port 46381] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-f4dbfb9b-555a-4059-9031-6a9fbc4e3745 for DN 127.0.0.1:40666
2020-12-03 07:22:44,860 [IPC Server handler 5 on default port 46381] WARN  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:requestLease(230)) - DN b67852ef-41de-4129-852b-cdf1aa436090 (127.0.0.1:40666) requested a lease even though it wasn't yet registered.  Registering now.
2020-12-03 07:22:44,861 [IPC Server handler 5 on default port 46381] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN b67852ef-41de-4129-852b-cdf1aa436090 (127.0.0.1:40666).
2020-12-03 07:22:44,864 [IPC Server handler 2 on default port 46381] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1566)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:40666, datanodeUuid=b67852ef-41de-4129-852b-cdf1aa436090, infoPort=36137, infoSecurePort=0, ipcPort=38568, storageInfo=lv=-57;cid=testClusterID;nsid=1340213695;c=1606980156826), reports.length=2
2020-12-03 07:22:44,865 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x65b032efe775743c: Processing first storage report for DS-f4dbfb9b-555a-4059-9031-6a9fbc4e3745 from datanode b67852ef-41de-4129-852b-cdf1aa436090
2020-12-03 07:22:44,865 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x65b032efe775743c: from storage DS-f4dbfb9b-555a-4059-9031-6a9fbc4e3745 node DatanodeRegistration(127.0.0.1:40666, datanodeUuid=b67852ef-41de-4129-852b-cdf1aa436090, infoPort=36137, infoSecurePort=0, ipcPort=38568, storageInfo=lv=-57;cid=testClusterID;nsid=1340213695;c=1606980156826), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:44,865 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x65b032efe775743c: Processing first storage report for DS-61b82fc7-0cf4-4863-914d-b8b5d6ea1bdf from datanode b67852ef-41de-4129-852b-cdf1aa436090
2020-12-03 07:22:44,865 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x65b032efe775743c: from storage DS-61b82fc7-0cf4-4863-914d-b8b5d6ea1bdf node DatanodeRegistration(127.0.0.1:40666, datanodeUuid=b67852ef-41de-4129-852b-cdf1aa436090, infoPort=36137, infoSecurePort=0, ipcPort=38568, storageInfo=lv=-57;cid=testClusterID;nsid=1340213695;c=1606980156826), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:44,865 [IPC Server handler 2 on default port 46381] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2700)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x65b032efe775743c
2020-12-03 07:22:44,868 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x65b032efe775743c,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:44,868 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:44,907 [IPC Server handler 7 on default port 46381] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:44,909 [Listener at localhost/38568] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:22:44,909 [Listener at localhost/38568] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopDataNode(2331)) - MiniDFSCluster Stopping DataNode host11:34223 from a total of 10 datanodes.
2020-12-03 07:22:44,910 [Listener at localhost/38568] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:22:44,910 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@6594402a] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:22:44,913 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21, DS-38ba94e2-2ce4-49bf-99db-685a54d217e4) exiting.
2020-12-03 07:22:44,913 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22, DS-53377210-e960-4ec0-ab7e-bfaeb689ad6d) exiting.
2020-12-03 07:22:44,932 [Listener at localhost/38568] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6aa648b9{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:22:44,933 [Listener at localhost/38568] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@23c650a3{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:44,934 [Listener at localhost/38568] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@721eb7df{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:44,934 [Listener at localhost/38568] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@38600b{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:44,936 [Listener at localhost/38568] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 42513
2020-12-03 07:22:44,952 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:44,952 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:44,952 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:44,955 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-553029280-172.17.0.10-1606980156826 (Datanode Uuid 2eee4d7d-a7de-413d-86d9-9bf7d9a28d3e) service to localhost/127.0.0.1:46381
2020-12-03 07:22:44,956 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-553029280-172.17.0.10-1606980156826 (Datanode Uuid 2eee4d7d-a7de-413d-86d9-9bf7d9a28d3e)
2020-12-03 07:22:44,956 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:44,958 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21/current/BP-553029280-172.17.0.10-1606980156826] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:44,958 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22/current/BP-553029280-172.17.0.10-1606980156826] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:44,967 [Listener at localhost/38568] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:22:44,967 [Listener at localhost/38568] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:22:44,969 [Listener at localhost/38568] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:22:44,969 [Listener at localhost/38568] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:22:44,973 [Listener at localhost/38568] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:22:44,974 [Listener at localhost/38568] INFO  hdfs.StateChange (DatanodeManager.java:removeDeadDatanode(754)) - BLOCK* removeDeadDatanode: lost heartbeat from 127.0.0.1:34223, removeBlocksFromBlockMap true
2020-12-03 07:22:44,974 [Listener at localhost/38568] DEBUG BlockStateChange (BlockManager.java:removeStoredBlock(3891)) - BLOCK* removeStoredBlock: blk_-9223372036854775792_1001 from 127.0.0.1:34223
2020-12-03 07:22:44,976 [Listener at localhost/38568] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775792_1001 has only 8 replicas and needs 9 replicas so is added to neededReconstructions at priority level 2
2020-12-03 07:22:44,977 [Listener at localhost/38568] INFO  net.NetworkTopology (NetworkTopology.java:remove(219)) - Removing a node: /r6/127.0.0.1:34223
2020-12-03 07:22:44,977 [Listener at localhost/38568] INFO  blockmanagement.TestReconstructStripedBlocksWithRackAwareness (TestReconstructStripedBlocksWithRackAwareness.java:stopDataNode(120)) - stop datanode host11
2020-12-03 07:22:45,635 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (ErasureCodingWork.java:<init>(47)) - Creating an ErasureCodingWork to blk_-9223372036854775792_1001 reconstruct 
2020-12-03 07:22:45,635 [RedundancyMonitor] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(427)) - storageTypes={DISK=1}
2020-12-03 07:22:45,637 [RedundancyMonitor] DEBUG blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseLocalRack(655)) - Failed to choose from local rack (location = /r4), retry with the rack of the next replica (location = /r4)
org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy$NotEnoughReplicasException: 
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRandom(BlockPlacementPolicyDefault.java:852)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRandom(BlockPlacementPolicyDefault.java:740)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseLocalRack(BlockPlacementPolicyDefault.java:647)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseLocalStorage(BlockPlacementPolicyDefault.java:607)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyRackFaultTolerant.chooseOnce(BlockPlacementPolicyRackFaultTolerant.java:218)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyRackFaultTolerant.chooseTargetInOrder(BlockPlacementPolicyRackFaultTolerant.java:126)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:437)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:309)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:149)
	at org.apache.hadoop.hdfs.server.blockmanagement.ErasureCodingWork.chooseTargets(ErasureCodingWork.java:60)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.computeReconstructionWorkForBlocks(BlockManager.java:1960)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.computeBlockReconstructionWork(BlockManager.java:1912)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.computeDatanodeWork(BlockManager.java:4813)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$RedundancyMonitor.run(BlockManager.java:4680)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:22:45,639 [RedundancyMonitor] DEBUG blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseFromNextRack(687)) - Failed to choose from the next rack (location = /r4), retry choosing randomly
org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy$NotEnoughReplicasException: 
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRandom(BlockPlacementPolicyDefault.java:852)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRandom(BlockPlacementPolicyDefault.java:740)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseFromNextRack(BlockPlacementPolicyDefault.java:683)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseLocalRack(BlockPlacementPolicyDefault.java:659)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseLocalStorage(BlockPlacementPolicyDefault.java:607)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyRackFaultTolerant.chooseOnce(BlockPlacementPolicyRackFaultTolerant.java:218)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyRackFaultTolerant.chooseTargetInOrder(BlockPlacementPolicyRackFaultTolerant.java:126)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:437)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:309)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:149)
	at org.apache.hadoop.hdfs.server.blockmanagement.ErasureCodingWork.chooseTargets(ErasureCodingWork.java:60)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.computeReconstructionWorkForBlocks(BlockManager.java:1960)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.computeBlockReconstructionWork(BlockManager.java:1912)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.computeDatanodeWork(BlockManager.java:4813)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$RedundancyMonitor.run(BlockManager.java:4680)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:22:45,639 [RedundancyMonitor] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyRackFaultTolerant.java:chooseTargetInOrder(135)) - Chosen nodes: [[DISK]DS-989ab400-edd5-4c26-8129-27b187f55bea:NORMAL:127.0.0.1:39297, [DISK]DS-d776ca84-07fa-451c-9d5c-5823f2a9c283:NORMAL:127.0.0.1:46575, [DISK]DS-7d23030f-e4b7-41c3-86d6-2f213d105c85:NORMAL:127.0.0.1:43893, [DISK]DS-d2a4899e-ef3e-4caa-92a7-edff2cf40784:NORMAL:127.0.0.1:36853, [DISK]DS-529740d6-cc36-46d6-8bf0-550bd7bc3681:NORMAL:127.0.0.1:35093, [DISK]DS-9858e8d6-2e19-4c6d-b267-646ed6d48c33:NORMAL:127.0.0.1:34171, [DISK]DS-e0eebb59-dd2d-433a-93fb-dc405cc68a0e:NORMAL:127.0.0.1:46621, [DISK]DS-1065d737-6687-4441-a64b-8cff8d91e6c0:NORMAL:127.0.0.1:43254, [DISK]DS-f4dbfb9b-555a-4059-9031-6a9fbc4e3745:NORMAL:127.0.0.1:40666]
2020-12-03 07:22:45,639 [RedundancyMonitor] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyRackFaultTolerant.java:chooseTargetInOrder(136)) - Excluded nodes: [127.0.0.1:40666, 127.0.0.1:43254, 127.0.0.1:46575, 127.0.0.1:36853, 127.0.0.1:35093, 127.0.0.1:39297, 127.0.0.1:43893, 127.0.0.1:34171, 127.0.0.1:46621]
2020-12-03 07:22:45,641 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (DatanodeDescriptor.java:addBlockToBeErasureCoded(658)) - Adding block reconstruction task BlockECReconstructionInfo(
  Recovering BP-553029280-172.17.0.10-1606980156826:blk_-9223372036854775792_1001 From: [127.0.0.1:39297, 127.0.0.1:46575, 127.0.0.1:43893, 127.0.0.1:36853, 127.0.0.1:35093, 127.0.0.1:34171, 127.0.0.1:46621, 127.0.0.1:43254] To: [[127.0.0.1:40666])
 Block Indices: [0, 1, 2, 3, 5, 6, 7, 8]to 127.0.0.1:40666, current queue size is 1
2020-12-03 07:22:45,641 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:validateReconstructionWork(2152)) - BLOCK* block blk_-9223372036854775792_1001 is moved from neededReconstruction to pendingReconstruction
2020-12-03 07:22:45,642 [RedundancyMonitor] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(376)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775792_1001 from priority queue 2
2020-12-03 07:22:45,642 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1993)) - BLOCK* ask [127.0.0.1:39297, 127.0.0.1:46575, 127.0.0.1:43893, 127.0.0.1:36853, 127.0.0.1:35093, 127.0.0.1:34171, 127.0.0.1:46621, 127.0.0.1:43254] to replicate blk_-9223372036854775792_1001 to datanode(s) 127.0.0.1:40666
2020-12-03 07:22:45,642 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1998)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 1
2020-12-03 07:22:46,087 [IPC Server handler 3 on default port 46381] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1566)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:35093, datanodeUuid=0fb937fa-2aba-45e3-8780-b03d3f5859b2, infoPort=44155, infoSecurePort=0, ipcPort=36965, storageInfo=lv=-57;cid=testClusterID;nsid=1340213695;c=1606980156826), reports.length=2
2020-12-03 07:22:46,107 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xb12ce49738b31079: Processing first storage report for DS-9c05daf8-c5f6-400f-9196-df42ff74880a from datanode 0fb937fa-2aba-45e3-8780-b03d3f5859b2
2020-12-03 07:22:46,107 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xb12ce49738b31079: from storage DS-9c05daf8-c5f6-400f-9196-df42ff74880a node DatanodeRegistration(127.0.0.1:35093, datanodeUuid=0fb937fa-2aba-45e3-8780-b03d3f5859b2, infoPort=44155, infoSecurePort=0, ipcPort=36965, storageInfo=lv=-57;cid=testClusterID;nsid=1340213695;c=1606980156826), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:46,107 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xb12ce49738b31079: Processing first storage report for DS-529740d6-cc36-46d6-8bf0-550bd7bc3681 from datanode 0fb937fa-2aba-45e3-8780-b03d3f5859b2
2020-12-03 07:22:46,108 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processFirstBlockReport(2885)) - Initial report of block blk_-9223372036854775787 on 127.0.0.1:35093 size 2097152 replicaState = FINALIZED
2020-12-03 07:22:46,108 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3365)) - BLOCK* addStoredBlock: Redundant addStoredBlock request received for blk_-9223372036854775792_1001 on node 127.0.0.1:35093 size 12582912
2020-12-03 07:22:46,108 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xb12ce49738b31079: from storage DS-529740d6-cc36-46d6-8bf0-550bd7bc3681 node DatanodeRegistration(127.0.0.1:35093, datanodeUuid=0fb937fa-2aba-45e3-8780-b03d3f5859b2, infoPort=44155, infoSecurePort=0, ipcPort=36965, storageInfo=lv=-57;cid=testClusterID;nsid=1340213695;c=1606980156826), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:46,112 [IPC Server handler 3 on default port 46381] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2700)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xb12ce49738b31079
2020-12-03 07:22:46,113 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xb12ce49738b31079,  containing 2 storage report(s), of which we sent 2. The reports had 1 total blocks and used 1 RPC(s). This took 0 msec to generate and 28 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:46,113 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:46,113 [IPC Server handler 7 on default port 46381] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1566)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:46621, datanodeUuid=adab20bb-214b-4a74-bb76-b832f6e8c8d9, infoPort=39992, infoSecurePort=0, ipcPort=41711, storageInfo=lv=-57;cid=testClusterID;nsid=1340213695;c=1606980156826), reports.length=2
2020-12-03 07:22:46,113 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x2a078848a6f9273f: Processing first storage report for DS-d592cf78-a277-4a6c-8bcb-f07e7ab49315 from datanode adab20bb-214b-4a74-bb76-b832f6e8c8d9
2020-12-03 07:22:46,114 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x2a078848a6f9273f: from storage DS-d592cf78-a277-4a6c-8bcb-f07e7ab49315 node DatanodeRegistration(127.0.0.1:46621, datanodeUuid=adab20bb-214b-4a74-bb76-b832f6e8c8d9, infoPort=39992, infoSecurePort=0, ipcPort=41711, storageInfo=lv=-57;cid=testClusterID;nsid=1340213695;c=1606980156826), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:22:46,114 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x2a078848a6f9273f: Processing first storage report for DS-e0eebb59-dd2d-433a-93fb-dc405cc68a0e from datanode adab20bb-214b-4a74-bb76-b832f6e8c8d9
2020-12-03 07:22:46,114 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processFirstBlockReport(2885)) - Initial report of block blk_-9223372036854775785 on 127.0.0.1:46621 size 2097152 replicaState = FINALIZED
2020-12-03 07:22:46,114 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3365)) - BLOCK* addStoredBlock: Redundant addStoredBlock request received for blk_-9223372036854775792_1001 on node 127.0.0.1:46621 size 12582912
2020-12-03 07:22:46,114 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x2a078848a6f9273f: from storage DS-e0eebb59-dd2d-433a-93fb-dc405cc68a0e node DatanodeRegistration(127.0.0.1:46621, datanodeUuid=adab20bb-214b-4a74-bb76-b832f6e8c8d9, infoPort=39992, infoSecurePort=0, ipcPort=41711, storageInfo=lv=-57;cid=testClusterID;nsid=1340213695;c=1606980156826), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:46,114 [IPC Server handler 7 on default port 46381] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2700)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x2a078848a6f9273f
2020-12-03 07:22:46,115 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x2a078848a6f9273f,  containing 2 storage report(s), of which we sent 2. The reports had 1 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:46,115 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:46,642 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1998)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 1
2020-12-03 07:22:47,643 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1998)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 1
2020-12-03 07:22:47,874 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(793)) - DatanodeCommand action: DNA_ERASURE_CODING_RECOVERY
2020-12-03 07:22:47,895 [StripedBlockReconstruction-0] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:47,918 [StripedBlockReconstruction-0] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:47,921 [StripedBlockReconstruction-0] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:47,923 [StripedBlockReconstruction-0] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:47,927 [StripedBlockReconstruction-0] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:47,932 [StripedBlockReconstruction-0] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:47,936 [StripedBlockReconstruction-0] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:47,945 [DataXceiver for client  at /127.0.0.1:47350 [Receiving block BP-553029280-172.17.0.10-1606980156826:blk_-9223372036854775788_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-553029280-172.17.0.10-1606980156826:blk_-9223372036854775788_1001 src: /127.0.0.1:47350 dest: /127.0.0.1:40666
2020-12-03 07:22:48,030 [DataXceiver for client  at /127.0.0.1:47350 [Receiving block BP-553029280-172.17.0.10-1606980156826:blk_-9223372036854775788_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(931)) - Received BP-553029280-172.17.0.10-1606980156826:blk_-9223372036854775788_1001 src: /127.0.0.1:47350 dest: /127.0.0.1:40666 of size 2097152
2020-12-03 07:22:48,033 [IPC Server handler 6 on default port 46381] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1627)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:40666, datanodeUuid=b67852ef-41de-4129-852b-cdf1aa436090, infoPort=36137, infoSecurePort=0, ipcPort=38568, storageInfo=lv=-57;cid=testClusterID;nsid=1340213695;c=1606980156826) 1 blocks.
2020-12-03 07:22:48,034 [Block report processor] DEBUG blockmanagement.BlockManager (PendingReconstructionBlocks.java:decrement(108)) - Removing pending reconstruction for blk_-9223372036854775792_1001
2020-12-03 07:22:48,034 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4021)) - Reported block blk_-9223372036854775788_1001 on 127.0.0.1:40666 size 2097152 replicaState = FINALIZED
2020-12-03 07:22:48,038 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4044)) - In memory blockUCState = COMPLETE
2020-12-03 07:22:48,038 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3351)) - BLOCK* addStoredBlock: 127.0.0.1:40666 is added to blk_-9223372036854775792_1001 (size=12582912)
2020-12-03 07:22:48,039 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4154)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775788_1001 is received from 127.0.0.1:40666
2020-12-03 07:22:48,039 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4157)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:40666 receiving: 0, received: 1, deleted: 0
2020-12-03 07:22:48,643 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1998)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-12-03 07:22:48,980 [Listener at localhost/38568] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19
2020-12-03 07:22:48,981 [Listener at localhost/38568] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20
2020-12-03 07:22:48,982 [Listener at localhost/38568] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:22:48,987 [Listener at localhost/38568] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:48,987 [Listener at localhost/38568] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:22:48,988 [Listener at localhost/38568] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is host10
2020-12-03 07:22:48,988 [Listener at localhost/38568] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:48,988 [Listener at localhost/38568] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:22:48,990 [Listener at localhost/38568] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:45325
2020-12-03 07:22:48,990 [Listener at localhost/38568] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:22:48,990 [Listener at localhost/38568] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:22:48,991 [Listener at localhost/38568] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:48,993 [Listener at localhost/38568] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:48,994 [Listener at localhost/38568] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:22:48,994 [Listener at localhost/38568] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:48,997 [Listener at localhost/38568] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:48,998 [Listener at localhost/38568] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:22:48,998 [Listener at localhost/38568] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:48,998 [Listener at localhost/38568] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:48,999 [Listener at localhost/38568] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 42745
2020-12-03 07:22:48,999 [Listener at localhost/38568] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:49,001 [Listener at localhost/38568] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2822c6ff{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:49,002 [Listener at localhost/38568] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@53e3a87a{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:49,009 [Listener at localhost/38568] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@159a48a6{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:22:49,012 [Listener at localhost/38568] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@15bc339{HTTP/1.1,[http/1.1]}{localhost:42745}
2020-12-03 07:22:49,012 [Listener at localhost/38568] INFO  server.Server (Server.java:doStart(419)) - Started @14213ms
2020-12-03 07:22:49,033 [Listener at localhost/38568] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:36832
2020-12-03 07:22:49,033 [Listener at localhost/38568] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:22:49,034 [Listener at localhost/38568] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:22:49,033 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@385ef531] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:49,034 [Listener at localhost/38568] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:49,035 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:49,040 [Listener at localhost/44314] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:44314
2020-12-03 07:22:49,048 [Listener at localhost/44314] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:22:49,048 [Listener at localhost/44314] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:22:49,049 [Thread-510] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46381 starting to offer service
2020-12-03 07:22:49,052 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:49,052 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:49,055 [Thread-510] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46381
2020-12-03 07:22:49,056 [Thread-510] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:49,061 [Listener at localhost/44314] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21
2020-12-03 07:22:49,062 [Listener at localhost/44314] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22
2020-12-03 07:22:49,065 [Listener at localhost/44314] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:22:49,069 [Listener at localhost/44314] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:49,069 [Listener at localhost/44314] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:22:49,070 [Listener at localhost/44314] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is host11
2020-12-03 07:22:49,070 [Listener at localhost/44314] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:49,070 [Listener at localhost/44314] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:22:49,071 [Listener at localhost/44314] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:41594
2020-12-03 07:22:49,072 [Listener at localhost/44314] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:22:49,072 [Listener at localhost/44314] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:22:49,073 [Listener at localhost/44314] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:49,075 [Listener at localhost/44314] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:49,075 [Listener at localhost/44314] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:22:49,076 [Listener at localhost/44314] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:49,079 [Listener at localhost/44314] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:49,079 [Listener at localhost/44314] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:22:49,079 [Listener at localhost/44314] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:49,080 [Listener at localhost/44314] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:49,081 [Listener at localhost/44314] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 39464
2020-12-03 07:22:49,081 [Listener at localhost/44314] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:49,083 [Listener at localhost/44314] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2d5f7182{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:49,084 [Listener at localhost/44314] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@29ea78b1{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:49,093 [Listener at localhost/44314] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3350ebdd{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:22:49,094 [Listener at localhost/44314] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6818d900{HTTP/1.1,[http/1.1]}{localhost:39464}
2020-12-03 07:22:49,095 [Listener at localhost/44314] INFO  server.Server (Server.java:doStart(419)) - Started @14296ms
2020-12-03 07:22:49,114 [Listener at localhost/44314] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:44050
2020-12-03 07:22:49,115 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1f193686] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:49,115 [Listener at localhost/44314] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:22:49,115 [Listener at localhost/44314] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:22:49,116 [Listener at localhost/44314] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:49,116 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:49,121 [Listener at localhost/41222] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:41222
2020-12-03 07:22:49,125 [Thread-510] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19/in_use.lock acquired by nodename 5029@5a8b1b2f5494
2020-12-03 07:22:49,129 [Listener at localhost/41222] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:22:49,130 [Listener at localhost/41222] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:22:49,131 [Thread-532] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46381 starting to offer service
2020-12-03 07:22:49,135 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:49,137 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:49,142 [Thread-532] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46381
2020-12-03 07:22:49,143 [Thread-532] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:49,143 [IPC Server handler 8 on default port 46381] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:49,145 [Listener at localhost/41222] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:49,145 [Listener at localhost/41222] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:49,200 [Thread-532] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21/in_use.lock acquired by nodename 5029@5a8b1b2f5494
2020-12-03 07:22:49,242 [Thread-510] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20/in_use.lock acquired by nodename 5029@5a8b1b2f5494
2020-12-03 07:22:49,247 [IPC Server handler 4 on default port 46381] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:49,249 [Listener at localhost/41222] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:49,249 [Listener at localhost/41222] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:49,350 [IPC Server handler 9 on default port 46381] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:49,352 [Listener at localhost/41222] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:49,352 [Listener at localhost/41222] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:49,381 [Thread-510] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:49,382 [Thread-510] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19/current/BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:49,428 [Thread-532] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22/in_use.lock acquired by nodename 5029@5a8b1b2f5494
2020-12-03 07:22:49,454 [IPC Server handler 1 on default port 46381] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:49,456 [Listener at localhost/41222] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:49,456 [Listener at localhost/41222] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:49,492 [Thread-510] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:49,492 [Thread-510] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20/current/BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:49,532 [Thread-532] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:49,533 [Thread-532] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21/current/BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:49,558 [IPC Server handler 5 on default port 46381] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:49,560 [Listener at localhost/41222] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:49,560 [Listener at localhost/41222] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:49,570 [Thread-510] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1340213695;bpid=BP-553029280-172.17.0.10-1606980156826;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1340213695;c=1606980156826;bpid=BP-553029280-172.17.0.10-1606980156826;dnuuid=2f03b26a-3875-4a82-b77d-a44b653d6091
2020-12-03 07:22:49,573 [Thread-510] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-7daa0dcb-00a1-4340-9cd9-d4a965f46cca
2020-12-03 07:22:49,573 [Thread-510] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19, StorageType: DISK
2020-12-03 07:22:49,576 [Thread-510] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-c2d06ce4-d7fc-4f12-8985-fe5ab0cb5910
2020-12-03 07:22:49,576 [Thread-510] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20, StorageType: DISK
2020-12-03 07:22:49,577 [Thread-510] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:22:49,578 [Thread-510] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19
2020-12-03 07:22:49,580 [Thread-510] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19
2020-12-03 07:22:49,581 [Thread-510] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20
2020-12-03 07:22:49,581 [Thread-510] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20
2020-12-03 07:22:49,582 [Thread-510] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:49,582 [Thread-545] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19...
2020-12-03 07:22:49,583 [Thread-546] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20...
2020-12-03 07:22:49,584 [Thread-545] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19/current/BP-553029280-172.17.0.10-1606980156826/current: 24576
2020-12-03 07:22:49,585 [Thread-546] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20/current/BP-553029280-172.17.0.10-1606980156826/current: 24576
2020-12-03 07:22:49,592 [Thread-545] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-553029280-172.17.0.10-1606980156826 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19: 9ms
2020-12-03 07:22:49,592 [Thread-546] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-553029280-172.17.0.10-1606980156826 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20: 9ms
2020-12-03 07:22:49,593 [Thread-510] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-553029280-172.17.0.10-1606980156826: 11ms
2020-12-03 07:22:49,593 [Thread-547] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19...
2020-12-03 07:22:49,593 [Thread-547] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19/current/BP-553029280-172.17.0.10-1606980156826/current/replicas doesn't exist 
2020-12-03 07:22:49,593 [Thread-548] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20...
2020-12-03 07:22:49,593 [Thread-548] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20/current/BP-553029280-172.17.0.10-1606980156826/current/replicas doesn't exist 
2020-12-03 07:22:49,593 [Thread-547] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19: 1ms
2020-12-03 07:22:49,594 [Thread-548] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20: 1ms
2020-12-03 07:22:49,594 [Thread-510] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-553029280-172.17.0.10-1606980156826: 1ms
2020-12-03 07:22:49,595 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19, DS-7daa0dcb-00a1-4340-9cd9-d4a965f46cca): no suitable block pools found to scan.  Waiting 1814393519 ms.
2020-12-03 07:22:49,595 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20, DS-c2d06ce4-d7fc-4f12-8985-fe5ab0cb5910): no suitable block pools found to scan.  Waiting 1814393518 ms.
2020-12-03 07:22:49,595 [Thread-510] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 7:50 AM with interval of 21600000ms
2020-12-03 07:22:49,597 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-553029280-172.17.0.10-1606980156826 (Datanode Uuid 2f03b26a-3875-4a82-b77d-a44b653d6091) service to localhost/127.0.0.1:46381 beginning handshake with NN
2020-12-03 07:22:49,598 [IPC Server handler 3 on default port 46381] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:45325, datanodeUuid=2f03b26a-3875-4a82-b77d-a44b653d6091, infoPort=36832, infoSecurePort=0, ipcPort=44314, storageInfo=lv=-57;cid=testClusterID;nsid=1340213695;c=1606980156826) storage 2f03b26a-3875-4a82-b77d-a44b653d6091
2020-12-03 07:22:49,599 [IPC Server handler 3 on default port 46381] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1078)) - BLOCK* registerDatanode: 127.0.0.1:45934 is replaced by DatanodeRegistration(127.0.0.1:45325, datanodeUuid=2f03b26a-3875-4a82-b77d-a44b653d6091, infoPort=36832, infoSecurePort=0, ipcPort=44314, storageInfo=lv=-57;cid=testClusterID;nsid=1340213695;c=1606980156826) with the same storageID 2f03b26a-3875-4a82-b77d-a44b653d6091
2020-12-03 07:22:49,599 [IPC Server handler 3 on default port 46381] INFO  net.NetworkTopology (NetworkTopology.java:remove(219)) - Removing a node: /r5/127.0.0.1:45934
2020-12-03 07:22:49,599 [IPC Server handler 3 on default port 46381] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /r5/127.0.0.1:45325
2020-12-03 07:22:49,599 [IPC Server handler 3 on default port 46381] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateFailedStorage(562)) - [DISK]DS-c2d06ce4-d7fc-4f12-8985-fe5ab0cb5910:NORMAL:127.0.0.1:45325 failed.
2020-12-03 07:22:49,599 [IPC Server handler 3 on default port 46381] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateFailedStorage(562)) - [DISK]DS-7daa0dcb-00a1-4340-9cd9-d4a965f46cca:NORMAL:127.0.0.1:45325 failed.
2020-12-03 07:22:49,599 [IPC Server handler 3 on default port 46381] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:pruneStorageMap(548)) - Removed storage [DISK]DS-c2d06ce4-d7fc-4f12-8985-fe5ab0cb5910:FAILED:127.0.0.1:45325 from DataNode 127.0.0.1:45325
2020-12-03 07:22:49,600 [IPC Server handler 3 on default port 46381] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:pruneStorageMap(548)) - Removed storage [DISK]DS-7daa0dcb-00a1-4340-9cd9-d4a965f46cca:FAILED:127.0.0.1:45325 from DataNode 127.0.0.1:45325
2020-12-03 07:22:49,600 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-553029280-172.17.0.10-1606980156826 (Datanode Uuid 2f03b26a-3875-4a82-b77d-a44b653d6091) service to localhost/127.0.0.1:46381 successfully registered with NN
2020-12-03 07:22:49,601 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:46381 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:22:49,603 [IPC Server handler 2 on default port 46381] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-7daa0dcb-00a1-4340-9cd9-d4a965f46cca for DN 127.0.0.1:45325
2020-12-03 07:22:49,604 [IPC Server handler 2 on default port 46381] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c2d06ce4-d7fc-4f12-8985-fe5ab0cb5910 for DN 127.0.0.1:45325
2020-12-03 07:22:49,605 [IPC Server handler 2 on default port 46381] WARN  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:requestLease(230)) - DN 2f03b26a-3875-4a82-b77d-a44b653d6091 (127.0.0.1:45325) requested a lease even though it wasn't yet registered.  Registering now.
2020-12-03 07:22:49,605 [IPC Server handler 2 on default port 46381] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 2f03b26a-3875-4a82-b77d-a44b653d6091 (127.0.0.1:45325).
2020-12-03 07:22:49,609 [IPC Server handler 7 on default port 46381] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1566)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:45325, datanodeUuid=2f03b26a-3875-4a82-b77d-a44b653d6091, infoPort=36832, infoSecurePort=0, ipcPort=44314, storageInfo=lv=-57;cid=testClusterID;nsid=1340213695;c=1606980156826), reports.length=2
2020-12-03 07:22:49,609 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xac33a3c1e6aa3e68: Processing first storage report for DS-c2d06ce4-d7fc-4f12-8985-fe5ab0cb5910 from datanode 2f03b26a-3875-4a82-b77d-a44b653d6091
2020-12-03 07:22:49,609 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xac33a3c1e6aa3e68: from storage DS-c2d06ce4-d7fc-4f12-8985-fe5ab0cb5910 node DatanodeRegistration(127.0.0.1:45325, datanodeUuid=2f03b26a-3875-4a82-b77d-a44b653d6091, infoPort=36832, infoSecurePort=0, ipcPort=44314, storageInfo=lv=-57;cid=testClusterID;nsid=1340213695;c=1606980156826), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:49,610 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xac33a3c1e6aa3e68: Processing first storage report for DS-7daa0dcb-00a1-4340-9cd9-d4a965f46cca from datanode 2f03b26a-3875-4a82-b77d-a44b653d6091
2020-12-03 07:22:49,610 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xac33a3c1e6aa3e68: from storage DS-7daa0dcb-00a1-4340-9cd9-d4a965f46cca node DatanodeRegistration(127.0.0.1:45325, datanodeUuid=2f03b26a-3875-4a82-b77d-a44b653d6091, infoPort=36832, infoSecurePort=0, ipcPort=44314, storageInfo=lv=-57;cid=testClusterID;nsid=1340213695;c=1606980156826), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:49,610 [IPC Server handler 7 on default port 46381] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2700)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xac33a3c1e6aa3e68
2020-12-03 07:22:49,610 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xac33a3c1e6aa3e68,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 4 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:49,611 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:49,614 [Thread-532] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:49,614 [Thread-532] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22/current/BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:49,644 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1998)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-12-03 07:22:49,662 [IPC Server handler 0 on default port 46381] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:49,664 [Listener at localhost/41222] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:49,664 [Listener at localhost/41222] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:49,669 [Thread-532] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1340213695;bpid=BP-553029280-172.17.0.10-1606980156826;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1340213695;c=1606980156826;bpid=BP-553029280-172.17.0.10-1606980156826;dnuuid=2eee4d7d-a7de-413d-86d9-9bf7d9a28d3e
2020-12-03 07:22:49,677 [Thread-532] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-38ba94e2-2ce4-49bf-99db-685a54d217e4
2020-12-03 07:22:49,679 [Thread-532] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21, StorageType: DISK
2020-12-03 07:22:49,680 [Thread-532] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-53377210-e960-4ec0-ab7e-bfaeb689ad6d
2020-12-03 07:22:49,680 [Thread-532] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22, StorageType: DISK
2020-12-03 07:22:49,682 [Thread-532] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:22:49,684 [Thread-532] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21
2020-12-03 07:22:49,684 [Thread-532] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21
2020-12-03 07:22:49,685 [Thread-532] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22
2020-12-03 07:22:49,685 [Thread-532] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22
2020-12-03 07:22:49,686 [Thread-532] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:49,686 [Thread-554] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21...
2020-12-03 07:22:49,686 [Thread-555] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22...
2020-12-03 07:22:49,688 [Thread-555] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22/current/BP-553029280-172.17.0.10-1606980156826/current: 24576
2020-12-03 07:22:49,688 [Thread-554] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21/current/BP-553029280-172.17.0.10-1606980156826/current: 2138119
2020-12-03 07:22:49,699 [Thread-555] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-553029280-172.17.0.10-1606980156826 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22: 12ms
2020-12-03 07:22:49,705 [Thread-554] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-553029280-172.17.0.10-1606980156826 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21: 19ms
2020-12-03 07:22:49,706 [Thread-532] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-553029280-172.17.0.10-1606980156826: 21ms
2020-12-03 07:22:49,707 [Thread-556] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21...
2020-12-03 07:22:49,707 [Thread-557] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22...
2020-12-03 07:22:49,708 [Thread-557] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22/current/BP-553029280-172.17.0.10-1606980156826/current/replicas doesn't exist 
2020-12-03 07:22:49,708 [Thread-557] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22: 0ms
2020-12-03 07:22:49,719 [Thread-556] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(925)) - Successfully read replica from cache file : /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21/current/BP-553029280-172.17.0.10-1606980156826/current/replicas
2020-12-03 07:22:49,720 [Thread-556] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-553029280-172.17.0.10-1606980156826 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21: 13ms
2020-12-03 07:22:49,720 [Thread-532] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-553029280-172.17.0.10-1606980156826: 13ms
2020-12-03 07:22:49,721 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21, DS-38ba94e2-2ce4-49bf-99db-685a54d217e4): no suitable block pools found to scan.  Waiting 1814393391 ms.
2020-12-03 07:22:49,721 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22, DS-53377210-e960-4ec0-ab7e-bfaeb689ad6d): no suitable block pools found to scan.  Waiting 1814393392 ms.
2020-12-03 07:22:49,722 [Thread-532] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 10:44 AM with interval of 21600000ms
2020-12-03 07:22:49,723 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-553029280-172.17.0.10-1606980156826 (Datanode Uuid 2eee4d7d-a7de-413d-86d9-9bf7d9a28d3e) service to localhost/127.0.0.1:46381 beginning handshake with NN
2020-12-03 07:22:49,725 [IPC Server handler 6 on default port 46381] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:41594, datanodeUuid=2eee4d7d-a7de-413d-86d9-9bf7d9a28d3e, infoPort=44050, infoSecurePort=0, ipcPort=41222, storageInfo=lv=-57;cid=testClusterID;nsid=1340213695;c=1606980156826) storage 2eee4d7d-a7de-413d-86d9-9bf7d9a28d3e
2020-12-03 07:22:49,725 [IPC Server handler 6 on default port 46381] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1078)) - BLOCK* registerDatanode: 127.0.0.1:34223 is replaced by DatanodeRegistration(127.0.0.1:41594, datanodeUuid=2eee4d7d-a7de-413d-86d9-9bf7d9a28d3e, infoPort=44050, infoSecurePort=0, ipcPort=41222, storageInfo=lv=-57;cid=testClusterID;nsid=1340213695;c=1606980156826) with the same storageID 2eee4d7d-a7de-413d-86d9-9bf7d9a28d3e
2020-12-03 07:22:49,725 [IPC Server handler 6 on default port 46381] INFO  net.NetworkTopology (NetworkTopology.java:remove(219)) - Removing a node: /r6/127.0.0.1:34223
2020-12-03 07:22:49,726 [IPC Server handler 6 on default port 46381] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /r6/127.0.0.1:41594
2020-12-03 07:22:49,726 [IPC Server handler 6 on default port 46381] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateFailedStorage(562)) - [DISK]DS-38ba94e2-2ce4-49bf-99db-685a54d217e4:NORMAL:127.0.0.1:41594 failed.
2020-12-03 07:22:49,726 [IPC Server handler 6 on default port 46381] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateFailedStorage(562)) - [DISK]DS-53377210-e960-4ec0-ab7e-bfaeb689ad6d:NORMAL:127.0.0.1:41594 failed.
2020-12-03 07:22:49,726 [IPC Server handler 6 on default port 46381] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:pruneStorageMap(548)) - Removed storage [DISK]DS-38ba94e2-2ce4-49bf-99db-685a54d217e4:FAILED:127.0.0.1:41594 from DataNode 127.0.0.1:41594
2020-12-03 07:22:49,726 [IPC Server handler 6 on default port 46381] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:pruneStorageMap(548)) - Removed storage [DISK]DS-53377210-e960-4ec0-ab7e-bfaeb689ad6d:FAILED:127.0.0.1:41594 from DataNode 127.0.0.1:41594
2020-12-03 07:22:49,727 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-553029280-172.17.0.10-1606980156826 (Datanode Uuid 2eee4d7d-a7de-413d-86d9-9bf7d9a28d3e) service to localhost/127.0.0.1:46381 successfully registered with NN
2020-12-03 07:22:49,727 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:46381 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:22:49,730 [IPC Server handler 8 on default port 46381] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-38ba94e2-2ce4-49bf-99db-685a54d217e4 for DN 127.0.0.1:41594
2020-12-03 07:22:49,731 [IPC Server handler 8 on default port 46381] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-53377210-e960-4ec0-ab7e-bfaeb689ad6d for DN 127.0.0.1:41594
2020-12-03 07:22:49,738 [IPC Server handler 8 on default port 46381] WARN  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:requestLease(230)) - DN 2eee4d7d-a7de-413d-86d9-9bf7d9a28d3e (127.0.0.1:41594) requested a lease even though it wasn't yet registered.  Registering now.
2020-12-03 07:22:49,738 [IPC Server handler 8 on default port 46381] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 2eee4d7d-a7de-413d-86d9-9bf7d9a28d3e (127.0.0.1:41594).
2020-12-03 07:22:49,740 [IPC Server handler 4 on default port 46381] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1566)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:41594, datanodeUuid=2eee4d7d-a7de-413d-86d9-9bf7d9a28d3e, infoPort=44050, infoSecurePort=0, ipcPort=41222, storageInfo=lv=-57;cid=testClusterID;nsid=1340213695;c=1606980156826), reports.length=2
2020-12-03 07:22:49,740 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xf050feea5bf22b00: Processing first storage report for DS-38ba94e2-2ce4-49bf-99db-685a54d217e4 from datanode 2eee4d7d-a7de-413d-86d9-9bf7d9a28d3e
2020-12-03 07:22:49,741 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processFirstBlockReport(2885)) - Initial report of block blk_-9223372036854775788 on 127.0.0.1:41594 size 2097152 replicaState = FINALIZED
2020-12-03 07:22:49,741 [Block report processor] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775792_1001 has only 9 replicas and needs 9 replicas so is added to neededReconstructions at priority level 3
2020-12-03 07:22:49,742 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xf050feea5bf22b00: from storage DS-38ba94e2-2ce4-49bf-99db-685a54d217e4 node DatanodeRegistration(127.0.0.1:41594, datanodeUuid=2eee4d7d-a7de-413d-86d9-9bf7d9a28d3e, infoPort=44050, infoSecurePort=0, ipcPort=41222, storageInfo=lv=-57;cid=testClusterID;nsid=1340213695;c=1606980156826), blocks: 1, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:22:49,742 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xf050feea5bf22b00: Processing first storage report for DS-53377210-e960-4ec0-ab7e-bfaeb689ad6d from datanode 2eee4d7d-a7de-413d-86d9-9bf7d9a28d3e
2020-12-03 07:22:49,742 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xf050feea5bf22b00: from storage DS-53377210-e960-4ec0-ab7e-bfaeb689ad6d node DatanodeRegistration(127.0.0.1:41594, datanodeUuid=2eee4d7d-a7de-413d-86d9-9bf7d9a28d3e, infoPort=44050, infoSecurePort=0, ipcPort=41222, storageInfo=lv=-57;cid=testClusterID;nsid=1340213695;c=1606980156826), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:49,742 [IPC Server handler 4 on default port 46381] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2700)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xf050feea5bf22b00
2020-12-03 07:22:49,743 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xf050feea5bf22b00,  containing 2 storage report(s), of which we sent 2. The reports had 1 total blocks and used 1 RPC(s). This took 0 msec to generate and 4 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:49,743 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:49,766 [IPC Server handler 9 on default port 46381] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:49,770 [Listener at localhost/41222] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:22:49,780 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:46381
2020-12-03 07:22:49,782 [IPC Server handler 5 on default port 46381] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1566)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:41594, datanodeUuid=2eee4d7d-a7de-413d-86d9-9bf7d9a28d3e, infoPort=44050, infoSecurePort=0, ipcPort=41222, storageInfo=lv=-57;cid=testClusterID;nsid=1340213695;c=1606980156826), reports.length=2
2020-12-03 07:22:49,782 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:reportDiffSorted(2966)) - Reported block blk_-9223372036854775788_1001 on 127.0.0.1:41594 size 2097152 replicaState = FINALIZED
2020-12-03 07:22:49,783 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:reportDiffSortedInner(3033)) - In memory blockUCState = COMPLETE
2020-12-03 07:22:49,783 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xf050feea5bf22b01: from storage DS-38ba94e2-2ce4-49bf-99db-685a54d217e4 node DatanodeRegistration(127.0.0.1:41594, datanodeUuid=2eee4d7d-a7de-413d-86d9-9bf7d9a28d3e, infoPort=44050, infoSecurePort=0, ipcPort=41222, storageInfo=lv=-57;cid=testClusterID;nsid=1340213695;c=1606980156826), blocks: 1, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:22:49,783 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xf050feea5bf22b01: from storage DS-53377210-e960-4ec0-ab7e-bfaeb689ad6d node DatanodeRegistration(127.0.0.1:41594, datanodeUuid=2eee4d7d-a7de-413d-86d9-9bf7d9a28d3e, infoPort=44050, infoSecurePort=0, ipcPort=41222, storageInfo=lv=-57;cid=testClusterID;nsid=1340213695;c=1606980156826), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:49,783 [IPC Server handler 5 on default port 46381] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2700)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xf050feea5bf22b01
2020-12-03 07:22:49,784 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xf050feea5bf22b01,  containing 2 storage report(s), of which we sent 2. The reports had 1 total blocks and used 1 RPC(s). This took 0 msec to generate and 4 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:49,784 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:49,873 [Listener at localhost/41222] INFO  blockmanagement.DatanodeAdminManager (DatanodeAdminManager.java:startDecommission(216)) - Starting decommission of 127.0.0.1:40666 [DISK]DS-f4dbfb9b-555a-4059-9031-6a9fbc4e3745:NORMAL:127.0.0.1:40666 with 0 blocks
2020-12-03 07:22:49,874 [Listener at localhost/41222] INFO  blockmanagement.DatanodeAdminManager (DatanodeAdminManager.java:startDecommission(216)) - Starting decommission of 127.0.0.1:40666 [DISK]DS-61b82fc7-0cf4-4863-914d-b8b5d6ea1bdf:NORMAL:127.0.0.1:40666 with 1 blocks
2020-12-03 07:22:50,645 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (ErasureCodingWork.java:<init>(47)) - Creating an ErasureCodingWork to blk_-9223372036854775792_1001 reconstruct 
2020-12-03 07:22:50,645 [RedundancyMonitor] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(427)) - storageTypes={DISK=1}
2020-12-03 07:22:50,646 [RedundancyMonitor] DEBUG blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseLocalRack(655)) - Failed to choose from local rack (location = /r4), retry with the rack of the next replica (location = /r4)
org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy$NotEnoughReplicasException: 
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRandom(BlockPlacementPolicyDefault.java:852)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRandom(BlockPlacementPolicyDefault.java:740)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseLocalRack(BlockPlacementPolicyDefault.java:647)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseLocalStorage(BlockPlacementPolicyDefault.java:607)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyRackFaultTolerant.chooseOnce(BlockPlacementPolicyRackFaultTolerant.java:218)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyRackFaultTolerant.chooseTargetInOrder(BlockPlacementPolicyRackFaultTolerant.java:126)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:437)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:309)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:149)
	at org.apache.hadoop.hdfs.server.blockmanagement.ErasureCodingWork.chooseTargets(ErasureCodingWork.java:60)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.computeReconstructionWorkForBlocks(BlockManager.java:1960)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.computeBlockReconstructionWork(BlockManager.java:1912)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.computeDatanodeWork(BlockManager.java:4813)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$RedundancyMonitor.run(BlockManager.java:4680)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:22:50,646 [RedundancyMonitor] DEBUG blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseFromNextRack(687)) - Failed to choose from the next rack (location = /r4), retry choosing randomly
org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy$NotEnoughReplicasException: 
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRandom(BlockPlacementPolicyDefault.java:852)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRandom(BlockPlacementPolicyDefault.java:740)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseFromNextRack(BlockPlacementPolicyDefault.java:683)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseLocalRack(BlockPlacementPolicyDefault.java:659)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseLocalStorage(BlockPlacementPolicyDefault.java:607)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyRackFaultTolerant.chooseOnce(BlockPlacementPolicyRackFaultTolerant.java:218)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyRackFaultTolerant.chooseTargetInOrder(BlockPlacementPolicyRackFaultTolerant.java:126)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:437)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:309)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:149)
	at org.apache.hadoop.hdfs.server.blockmanagement.ErasureCodingWork.chooseTargets(ErasureCodingWork.java:60)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.computeReconstructionWorkForBlocks(BlockManager.java:1960)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.computeBlockReconstructionWork(BlockManager.java:1912)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.computeDatanodeWork(BlockManager.java:4813)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$RedundancyMonitor.run(BlockManager.java:4680)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:22:50,647 [RedundancyMonitor] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyRackFaultTolerant.java:chooseTargetInOrder(135)) - Chosen nodes: [[DISK]DS-989ab400-edd5-4c26-8129-27b187f55bea:NORMAL:127.0.0.1:39297, [DISK]DS-d776ca84-07fa-451c-9d5c-5823f2a9c283:NORMAL:127.0.0.1:46575, [DISK]DS-7d23030f-e4b7-41c3-86d6-2f213d105c85:NORMAL:127.0.0.1:43893, [DISK]DS-d2a4899e-ef3e-4caa-92a7-edff2cf40784:NORMAL:127.0.0.1:36853, [DISK]DS-529740d6-cc36-46d6-8bf0-550bd7bc3681:NORMAL:127.0.0.1:35093, [DISK]DS-9858e8d6-2e19-4c6d-b267-646ed6d48c33:NORMAL:127.0.0.1:34171, [DISK]DS-e0eebb59-dd2d-433a-93fb-dc405cc68a0e:NORMAL:127.0.0.1:46621, [DISK]DS-1065d737-6687-4441-a64b-8cff8d91e6c0:NORMAL:127.0.0.1:43254, [DISK]DS-38ba94e2-2ce4-49bf-99db-685a54d217e4:NORMAL:127.0.0.1:41594, [DISK]DS-c2d06ce4-d7fc-4f12-8985-fe5ab0cb5910:NORMAL:127.0.0.1:45325]
2020-12-03 07:22:50,647 [RedundancyMonitor] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyRackFaultTolerant.java:chooseTargetInOrder(136)) - Excluded nodes: [127.0.0.1:40666, 127.0.0.1:43254, 127.0.0.1:46575, 127.0.0.1:36853, 127.0.0.1:35093, 127.0.0.1:39297, 127.0.0.1:43893, 127.0.0.1:34171, 127.0.0.1:46621, 127.0.0.1:41594, 127.0.0.1:45325]
2020-12-03 07:22:50,648 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:isInNewRack(2095)) - check if target 127.0.0.1:45325 increases racks, srcs=[127.0.0.1:39297, 127.0.0.1:46575, 127.0.0.1:43893, 127.0.0.1:36853, 127.0.0.1:40666, 127.0.0.1:35093, 127.0.0.1:34171, 127.0.0.1:46621, 127.0.0.1:43254, 127.0.0.1:41594]
2020-12-03 07:22:50,649 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (ErasureCodingWork.java:createReplicationWork(161)) - Add replication task from source 127.0.0.1:46621 to target [DISK]DS-c2d06ce4-d7fc-4f12-8985-fe5ab0cb5910:NORMAL:127.0.0.1:45325 for EC block blk_-9223372036854775785_1001
2020-12-03 07:22:50,649 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:validateReconstructionWork(2152)) - BLOCK* block blk_-9223372036854775792_1001 is moved from neededReconstruction to pendingReconstruction
2020-12-03 07:22:50,649 [RedundancyMonitor] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(376)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775792_1001 from priority queue 3
2020-12-03 07:22:50,649 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1993)) - BLOCK* ask [127.0.0.1:39297, 127.0.0.1:46575, 127.0.0.1:43893, 127.0.0.1:36853, 127.0.0.1:40666, 127.0.0.1:35093, 127.0.0.1:34171, 127.0.0.1:46621, 127.0.0.1:43254, 127.0.0.1:41594] to replicate blk_-9223372036854775792_1001 to datanode(s) 127.0.0.1:45325
2020-12-03 07:22:50,649 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1998)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 1
2020-12-03 07:22:51,527 [DatanodeAdminMonitor-0] INFO  BlockStateChange (DatanodeAdminManager.java:logBlockReplicationInfo(407)) - Block: blk_-9223372036854775792_1001, Expected Replicas: 9, live replicas: 9, corrupt replicas: 0, decommissioned replicas: 0, decommissioning replicas: 1, maintenance replicas: 0, live entering maintenance replicas: 0, excess replicas: 0, Is Open File: false, Datanodes having this block: 127.0.0.1:39297 127.0.0.1:46575 127.0.0.1:43893 127.0.0.1:36853 127.0.0.1:40666 127.0.0.1:35093 127.0.0.1:34171 127.0.0.1:46621 127.0.0.1:43254 127.0.0.1:41594 , Current Datanode: 127.0.0.1:40666, Is current datanode decommissioning: true, Is current datanode entering maintenance: false
2020-12-03 07:22:51,529 [DatanodeAdminMonitor-0] INFO  blockmanagement.DatanodeAdminManager (DatanodeAdminManager.java:run(510)) - Checked 1 blocks and 1 nodes this tick
2020-12-03 07:22:51,650 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1998)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 1
2020-12-03 07:22:52,110 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (DataNode.java:transferBlock(2358)) - DatanodeRegistration(127.0.0.1:46621, datanodeUuid=adab20bb-214b-4a74-bb76-b832f6e8c8d9, infoPort=39992, infoSecurePort=0, ipcPort=41711, storageInfo=lv=-57;cid=testClusterID;nsid=1340213695;c=1606980156826) Starting thread to transfer BP-553029280-172.17.0.10-1606980156826:blk_-9223372036854775785_1001 to 127.0.0.1:45325 
2020-12-03 07:22:52,113 [org.apache.hadoop.hdfs.server.datanode.DataNode$DataTransfer@247eaa2d] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:52,119 [DataXceiver for client  at /127.0.0.1:60830 [Receiving block BP-553029280-172.17.0.10-1606980156826:blk_-9223372036854775785_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-553029280-172.17.0.10-1606980156826:blk_-9223372036854775785_1001 src: /127.0.0.1:60830 dest: /127.0.0.1:45325
2020-12-03 07:22:52,129 [org.apache.hadoop.hdfs.server.datanode.DataNode$DataTransfer@247eaa2d] INFO  datanode.DataNode (DataNode.java:run(2571)) - DataTransfer, at host6:46621: Transmitted BP-553029280-172.17.0.10-1606980156826:blk_-9223372036854775785_1001 (numBytes=2097152) to /127.0.0.1:45325
2020-12-03 07:22:52,130 [DataXceiver for client  at /127.0.0.1:60830 [Receiving block BP-553029280-172.17.0.10-1606980156826:blk_-9223372036854775785_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(931)) - Received BP-553029280-172.17.0.10-1606980156826:blk_-9223372036854775785_1001 src: /127.0.0.1:60830 dest: /127.0.0.1:45325 of size 2097152
2020-12-03 07:22:52,144 [IPC Server handler 5 on default port 46381] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1627)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:45325, datanodeUuid=2f03b26a-3875-4a82-b77d-a44b653d6091, infoPort=36832, infoSecurePort=0, ipcPort=44314, storageInfo=lv=-57;cid=testClusterID;nsid=1340213695;c=1606980156826) 1 blocks.
2020-12-03 07:22:52,145 [Block report processor] DEBUG blockmanagement.BlockManager (PendingReconstructionBlocks.java:decrement(108)) - Removing pending reconstruction for blk_-9223372036854775792_1001
2020-12-03 07:22:52,145 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4021)) - Reported block blk_-9223372036854775785_1001 on 127.0.0.1:45325 size 2097152 replicaState = FINALIZED
2020-12-03 07:22:52,145 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(4044)) - In memory blockUCState = COMPLETE
2020-12-03 07:22:52,146 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3351)) - BLOCK* addStoredBlock: 127.0.0.1:45325 is added to blk_-9223372036854775792_1001 (size=12582912)
2020-12-03 07:22:52,147 [Block report processor] DEBUG BlockStateChange (ExcessRedundancyMap.java:add(86)) - BLOCK* ExcessRedundancyMap.add(127.0.0.1:46621, blk_-9223372036854775792_1001)
2020-12-03 07:22:52,147 [Block report processor] DEBUG BlockStateChange (InvalidateBlocks.java:add(190)) - BLOCK* InvalidateBlocks: add blk_-9223372036854775785_1001 to 127.0.0.1:46621
2020-12-03 07:22:52,147 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processChosenExcessRedundancy(3872)) - BLOCK* chooseExcessRedundancies: ([DISK]DS-e0eebb59-dd2d-433a-93fb-dc405cc68a0e:NORMAL:127.0.0.1:46621, blk_-9223372036854775792_1001) is added to invalidated blocks set
2020-12-03 07:22:52,148 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4154)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775785_1001 is received from 127.0.0.1:45325
2020-12-03 07:22:52,148 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4157)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:45325 receiving: 0, received: 1, deleted: 0
2020-12-03 07:22:52,652 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1998)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-12-03 07:22:52,653 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4505)) - BLOCK* BlockManager: ask 127.0.0.1:46621 to delete [blk_-9223372036854775785_1001]
2020-12-03 07:22:53,653 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1998)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-12-03 07:22:54,523 [DatanodeAdminMonitor-0] INFO  blockmanagement.DatanodeAdminManager (DatanodeAdminManager.java:setDecommissioned(332)) - Decommissioning complete for node 127.0.0.1:40666
2020-12-03 07:22:54,524 [DatanodeAdminMonitor-0] INFO  blockmanagement.DatanodeAdminManager (DatanodeAdminManager.java:run(510)) - Checked 2 blocks and 1 nodes this tick
2020-12-03 07:22:54,654 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1998)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-12-03 07:22:54,877 [Listener at localhost/41222] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:22:54,878 [Listener at localhost/41222] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 10
2020-12-03 07:22:54,878 [Listener at localhost/41222] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:22:54,878 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@3051e0b2] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:22:54,880 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22, DS-53377210-e960-4ec0-ab7e-bfaeb689ad6d) exiting.
2020-12-03 07:22:54,880 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21, DS-38ba94e2-2ce4-49bf-99db-685a54d217e4) exiting.
2020-12-03 07:22:54,983 [Listener at localhost/41222] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@3350ebdd{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:22:54,989 [Listener at localhost/41222] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6818d900{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:54,999 [Listener at localhost/41222] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@29ea78b1{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:55,000 [Listener at localhost/41222] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2d5f7182{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:55,002 [Listener at localhost/41222] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 41222
2020-12-03 07:22:55,006 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:55,006 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:55,010 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:55,010 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-553029280-172.17.0.10-1606980156826 (Datanode Uuid 2eee4d7d-a7de-413d-86d9-9bf7d9a28d3e) service to localhost/127.0.0.1:46381
2020-12-03 07:22:55,011 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-553029280-172.17.0.10-1606980156826 (Datanode Uuid 2eee4d7d-a7de-413d-86d9-9bf7d9a28d3e)
2020-12-03 07:22:55,012 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:55,012 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21/current/BP-553029280-172.17.0.10-1606980156826] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:55,013 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22/current/BP-553029280-172.17.0.10-1606980156826] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:55,017 [Listener at localhost/41222] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:22:55,017 [Listener at localhost/41222] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:22:55,018 [Listener at localhost/41222] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:22:55,018 [Listener at localhost/41222] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:22:55,020 [Listener at localhost/41222] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:22:55,021 [Listener at localhost/41222] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 9
2020-12-03 07:22:55,021 [Listener at localhost/41222] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:22:55,021 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@64aad6db] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:22:55,026 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19, DS-7daa0dcb-00a1-4340-9cd9-d4a965f46cca) exiting.
2020-12-03 07:22:55,026 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20, DS-c2d06ce4-d7fc-4f12-8985-fe5ab0cb5910) exiting.
2020-12-03 07:22:55,049 [Listener at localhost/41222] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@159a48a6{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:22:55,050 [Listener at localhost/41222] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@15bc339{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:55,050 [Listener at localhost/41222] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@53e3a87a{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:55,051 [Listener at localhost/41222] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2822c6ff{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:55,052 [Listener at localhost/41222] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 44314
2020-12-03 07:22:55,123 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:55,123 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:55,123 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:55,123 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-553029280-172.17.0.10-1606980156826 (Datanode Uuid 2f03b26a-3875-4a82-b77d-a44b653d6091) service to localhost/127.0.0.1:46381
2020-12-03 07:22:55,128 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-553029280-172.17.0.10-1606980156826 (Datanode Uuid 2f03b26a-3875-4a82-b77d-a44b653d6091)
2020-12-03 07:22:55,128 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:55,130 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20/current/BP-553029280-172.17.0.10-1606980156826] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:55,131 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19/current/BP-553029280-172.17.0.10-1606980156826] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:55,134 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(226)) - Scheduling blk_-9223372036854775785_1001 replica FinalizedReplica, blk_-9223372036854775785_1001, FINALIZED
  getNumBytes()     = 2097152
  getBytesOnDisk()  = 2097152
  getVisibleLength()= 2097152
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-553029280-172.17.0.10-1606980156826/current/finalized/subdir0/subdir0/blk_-9223372036854775785 for deletion
2020-12-03 07:22:55,150 [Listener at localhost/41222] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:22:55,150 [Listener at localhost/41222] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:22:55,153 [Listener at localhost/41222] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:22:55,153 [Listener at localhost/41222] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:22:55,159 [Async disk worker #0 for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(334)) - Deleted BP-553029280-172.17.0.10-1606980156826 blk_-9223372036854775785_1001 URI file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-553029280-172.17.0.10-1606980156826/current/finalized/subdir0/subdir0/blk_-9223372036854775785
2020-12-03 07:22:55,168 [Listener at localhost/41222] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:22:55,168 [Listener at localhost/41222] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 8
2020-12-03 07:22:55,169 [Listener at localhost/41222] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:22:55,169 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@1b005a0b] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:22:55,192 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-f4dbfb9b-555a-4059-9031-6a9fbc4e3745) exiting.
2020-12-03 07:22:55,192 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-61b82fc7-0cf4-4863-914d-b8b5d6ea1bdf) exiting.
2020-12-03 07:22:55,228 [Listener at localhost/41222] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@34dc85a{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:22:55,229 [Listener at localhost/41222] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@371f7862{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:55,229 [Listener at localhost/41222] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@57adfab0{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:55,230 [Listener at localhost/41222] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@257cc1fc{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:55,236 [Listener at localhost/41222] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 38568
2020-12-03 07:22:55,242 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:55,242 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:55,251 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:55,251 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-553029280-172.17.0.10-1606980156826 (Datanode Uuid b67852ef-41de-4129-852b-cdf1aa436090) service to localhost/127.0.0.1:46381
2020-12-03 07:22:55,251 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-553029280-172.17.0.10-1606980156826 (Datanode Uuid b67852ef-41de-4129-852b-cdf1aa436090)
2020-12-03 07:22:55,252 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:55,253 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-553029280-172.17.0.10-1606980156826] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:55,253 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-553029280-172.17.0.10-1606980156826] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:55,262 [Listener at localhost/41222] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:22:55,262 [Listener at localhost/41222] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:22:55,265 [Listener at localhost/41222] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:22:55,265 [Listener at localhost/41222] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:22:55,273 [Listener at localhost/41222] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:22:55,273 [Listener at localhost/41222] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 7
2020-12-03 07:22:55,274 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@308a6984] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:22:55,274 [Listener at localhost/41222] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:22:55,278 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-989ab400-edd5-4c26-8129-27b187f55bea) exiting.
2020-12-03 07:22:55,278 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-0bcac960-967a-40ed-b8c5-387870c04d08) exiting.
2020-12-03 07:22:55,321 [Listener at localhost/41222] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@71652c98{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:22:55,328 [Listener at localhost/41222] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@51bde877{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:55,329 [Listener at localhost/41222] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@85ec632{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:55,329 [Listener at localhost/41222] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@bae47a0{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:55,333 [Listener at localhost/41222] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 41006
2020-12-03 07:22:55,337 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:55,340 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:55,341 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:55,341 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-553029280-172.17.0.10-1606980156826 (Datanode Uuid 4e9c8f7c-7ed9-464f-af37-72d5c79cf464) service to localhost/127.0.0.1:46381
2020-12-03 07:22:55,341 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-553029280-172.17.0.10-1606980156826 (Datanode Uuid 4e9c8f7c-7ed9-464f-af37-72d5c79cf464)
2020-12-03 07:22:55,341 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:55,342 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-553029280-172.17.0.10-1606980156826] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:55,343 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-553029280-172.17.0.10-1606980156826] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:55,351 [Listener at localhost/41222] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:22:55,351 [Listener at localhost/41222] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:22:55,354 [Listener at localhost/41222] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:22:55,355 [Listener at localhost/41222] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:22:55,368 [Listener at localhost/41222] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:22:55,368 [Listener at localhost/41222] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 6
2020-12-03 07:22:55,369 [Listener at localhost/41222] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:22:55,371 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@106faf11] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:22:55,380 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-0a405c40-4d26-4ad5-858e-e8b6d4387025) exiting.
2020-12-03 07:22:55,380 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-d776ca84-07fa-451c-9d5c-5823f2a9c283) exiting.
2020-12-03 07:22:55,409 [Listener at localhost/41222] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@4102b1b1{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:22:55,412 [Listener at localhost/41222] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@61a5b4ae{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:55,413 [Listener at localhost/41222] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@53bc1328{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:55,413 [Listener at localhost/41222] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7bfc3126{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:55,414 [Listener at localhost/41222] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 44771
2020-12-03 07:22:55,419 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:55,419 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:55,419 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:55,419 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-553029280-172.17.0.10-1606980156826 (Datanode Uuid 2b735e97-c043-4614-a472-ecf3212bd218) service to localhost/127.0.0.1:46381
2020-12-03 07:22:55,428 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-553029280-172.17.0.10-1606980156826 (Datanode Uuid 2b735e97-c043-4614-a472-ecf3212bd218)
2020-12-03 07:22:55,428 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:55,429 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-553029280-172.17.0.10-1606980156826] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:55,429 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-553029280-172.17.0.10-1606980156826] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:55,451 [Listener at localhost/41222] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:22:55,451 [Listener at localhost/41222] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:22:55,455 [Listener at localhost/41222] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:22:55,456 [Listener at localhost/41222] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:22:55,469 [Listener at localhost/41222] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:22:55,469 [Listener at localhost/41222] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 5
2020-12-03 07:22:55,470 [Listener at localhost/41222] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:22:55,470 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@e72dba7] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:22:55,478 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-d592cf78-a277-4a6c-8bcb-f07e7ab49315) exiting.
2020-12-03 07:22:55,480 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-e0eebb59-dd2d-433a-93fb-dc405cc68a0e) exiting.
2020-12-03 07:22:55,534 [Listener at localhost/41222] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6f6a7463{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:22:55,535 [Listener at localhost/41222] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@1bdaa23d{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:55,535 [Listener at localhost/41222] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3fabf088{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:55,536 [Listener at localhost/41222] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@610db97e{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:55,538 [Listener at localhost/41222] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 41711
2020-12-03 07:22:55,539 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:55,540 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:55,540 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-553029280-172.17.0.10-1606980156826 (Datanode Uuid adab20bb-214b-4a74-bb76-b832f6e8c8d9) service to localhost/127.0.0.1:46381
2020-12-03 07:22:55,540 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-553029280-172.17.0.10-1606980156826 (Datanode Uuid adab20bb-214b-4a74-bb76-b832f6e8c8d9)
2020-12-03 07:22:55,540 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:55,541 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-553029280-172.17.0.10-1606980156826] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:55,541 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-553029280-172.17.0.10-1606980156826] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:55,558 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:55,570 [Listener at localhost/41222] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:22:55,570 [Listener at localhost/41222] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:22:55,575 [Listener at localhost/41222] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:22:55,576 [Listener at localhost/41222] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:22:55,590 [Listener at localhost/41222] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:22:55,590 [Listener at localhost/41222] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 4
2020-12-03 07:22:55,591 [Listener at localhost/41222] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:22:55,591 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@1b39fd82] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:22:55,599 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-1065d737-6687-4441-a64b-8cff8d91e6c0) exiting.
2020-12-03 07:22:55,599 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-969ad042-8fa6-4020-a93e-a04cbcb9ee38) exiting.
2020-12-03 07:22:55,632 [Listener at localhost/41222] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@50b8ae8d{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:22:55,634 [Listener at localhost/41222] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@255990cc{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:55,635 [Listener at localhost/41222] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@c074c0c{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:55,635 [Listener at localhost/41222] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2024293c{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:55,638 [Listener at localhost/41222] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 37876
2020-12-03 07:22:55,638 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:55,656 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1998)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-12-03 07:22:55,657 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:55,657 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:55,657 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-553029280-172.17.0.10-1606980156826 (Datanode Uuid 7e66e6f2-77d4-4df8-8ba0-4db0382c661e) service to localhost/127.0.0.1:46381
2020-12-03 07:22:55,658 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-553029280-172.17.0.10-1606980156826 (Datanode Uuid 7e66e6f2-77d4-4df8-8ba0-4db0382c661e)
2020-12-03 07:22:55,658 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:55,659 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-553029280-172.17.0.10-1606980156826] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:55,659 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-553029280-172.17.0.10-1606980156826] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:55,718 [Listener at localhost/41222] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:22:55,718 [Listener at localhost/41222] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:22:55,723 [Listener at localhost/41222] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:22:55,724 [Listener at localhost/41222] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:22:55,754 [Listener at localhost/41222] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:22:55,754 [Listener at localhost/41222] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 3
2020-12-03 07:22:55,755 [Listener at localhost/41222] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:22:55,755 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@c41709a] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:22:55,773 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-9858e8d6-2e19-4c6d-b267-646ed6d48c33) exiting.
2020-12-03 07:22:55,775 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-88f48494-4b0c-4d6a-8850-141d185c4b08) exiting.
2020-12-03 07:22:55,807 [Listener at localhost/41222] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@324dcd31{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:22:55,809 [Listener at localhost/41222] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@503d56b5{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:55,809 [Listener at localhost/41222] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@cc62a3b{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:55,810 [Listener at localhost/41222] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1edb61b1{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:55,811 [Listener at localhost/41222] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 35388
2020-12-03 07:22:55,818 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:55,823 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:55,824 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:55,824 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-553029280-172.17.0.10-1606980156826 (Datanode Uuid ac2c185f-8b0e-4e4f-b0c8-58495b79d4f5) service to localhost/127.0.0.1:46381
2020-12-03 07:22:55,824 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-553029280-172.17.0.10-1606980156826 (Datanode Uuid ac2c185f-8b0e-4e4f-b0c8-58495b79d4f5)
2020-12-03 07:22:55,824 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:55,825 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-553029280-172.17.0.10-1606980156826] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:55,825 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-553029280-172.17.0.10-1606980156826] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:55,831 [Listener at localhost/41222] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:22:55,831 [Listener at localhost/41222] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:22:55,838 [Listener at localhost/41222] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:22:55,838 [Listener at localhost/41222] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:22:55,839 [Listener at localhost/41222] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:22:55,840 [Listener at localhost/41222] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 2
2020-12-03 07:22:55,840 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@241a53ef] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:22:55,841 [Listener at localhost/41222] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:22:55,847 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-9c05daf8-c5f6-400f-9196-df42ff74880a) exiting.
2020-12-03 07:22:55,847 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-529740d6-cc36-46d6-8bf0-550bd7bc3681) exiting.
2020-12-03 07:22:55,866 [Listener at localhost/41222] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@443dbe42{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:22:55,876 [Listener at localhost/41222] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@473b3b7a{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:55,877 [Listener at localhost/41222] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7249dadf{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:55,878 [Listener at localhost/41222] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1827a871{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:55,903 [Listener at localhost/41222] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 36965
2020-12-03 07:22:55,912 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:55,913 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:55,919 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:55,919 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-553029280-172.17.0.10-1606980156826 (Datanode Uuid 0fb937fa-2aba-45e3-8780-b03d3f5859b2) service to localhost/127.0.0.1:46381
2020-12-03 07:22:55,919 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-553029280-172.17.0.10-1606980156826 (Datanode Uuid 0fb937fa-2aba-45e3-8780-b03d3f5859b2)
2020-12-03 07:22:55,920 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:55,921 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-553029280-172.17.0.10-1606980156826] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:55,928 [Listener at localhost/41222] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:22:55,928 [Listener at localhost/41222] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:22:55,921 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-553029280-172.17.0.10-1606980156826] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:55,934 [Listener at localhost/41222] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:22:55,935 [Listener at localhost/41222] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:22:55,936 [Listener at localhost/41222] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:22:55,936 [Listener at localhost/41222] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 1
2020-12-03 07:22:55,936 [Listener at localhost/41222] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:22:55,936 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@2ca65ce4] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:22:55,945 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-7d23030f-e4b7-41c3-86d6-2f213d105c85) exiting.
2020-12-03 07:22:55,946 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-dee073db-38dc-4e86-b76e-620390a0797a) exiting.
2020-12-03 07:22:55,977 [Listener at localhost/41222] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@40bffbca{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:22:55,978 [Listener at localhost/41222] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2449cff7{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:55,979 [Listener at localhost/41222] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@72efb5c1{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:55,979 [Listener at localhost/41222] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2970a5bc{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:55,987 [Listener at localhost/41222] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 46185
2020-12-03 07:22:56,003 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:56,003 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:56,012 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:56,012 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-553029280-172.17.0.10-1606980156826 (Datanode Uuid e49ebb27-c895-49e4-980b-5953315ee3da) service to localhost/127.0.0.1:46381
2020-12-03 07:22:56,012 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-553029280-172.17.0.10-1606980156826 (Datanode Uuid e49ebb27-c895-49e4-980b-5953315ee3da)
2020-12-03 07:22:56,012 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:56,021 [Listener at localhost/41222] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:22:56,021 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-553029280-172.17.0.10-1606980156826] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:56,021 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-553029280-172.17.0.10-1606980156826] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:56,021 [Listener at localhost/41222] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:22:56,029 [Listener at localhost/41222] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:22:56,029 [Listener at localhost/41222] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:22:56,041 [Listener at localhost/41222] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:22:56,042 [Listener at localhost/41222] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:22:56,043 [Listener at localhost/41222] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:22:56,043 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@58670130] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:22:56,050 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-30d9c94d-ca53-4e48-9d49-19bd923387f8) exiting.
2020-12-03 07:22:56,050 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-d2a4899e-ef3e-4caa-92a7-edff2cf40784) exiting.
2020-12-03 07:22:56,260 [Listener at localhost/41222] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@64beebb7{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:22:56,262 [Listener at localhost/41222] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7813cb11{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:56,262 [Listener at localhost/41222] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@186978a6{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:56,263 [Listener at localhost/41222] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@107ed6fc{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:56,269 [Listener at localhost/41222] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 34080
2020-12-03 07:22:56,282 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:56,283 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:56,283 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-553029280-172.17.0.10-1606980156826 (Datanode Uuid bb55c2ab-550b-47a9-aef1-bbeebaea4626) service to localhost/127.0.0.1:46381
2020-12-03 07:22:56,283 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:56,384 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-553029280-172.17.0.10-1606980156826 (Datanode Uuid bb55c2ab-550b-47a9-aef1-bbeebaea4626)
2020-12-03 07:22:56,385 [BP-553029280-172.17.0.10-1606980156826 heartbeating to localhost/127.0.0.1:46381] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-553029280-172.17.0.10-1606980156826
2020-12-03 07:22:56,386 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-553029280-172.17.0.10-1606980156826] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:56,386 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-553029280-172.17.0.10-1606980156826] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:56,392 [Listener at localhost/41222] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:22:56,393 [Listener at localhost/41222] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:22:56,399 [Listener at localhost/41222] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:22:56,399 [Listener at localhost/41222] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:22:56,400 [Listener at localhost/41222] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:22:56,401 [Listener at localhost/41222] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:22:56,401 [Listener at localhost/41222] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:22:56,402 [Listener at localhost/41222] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 1, 8
2020-12-03 07:22:56,402 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@242aa8d9] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:22:56,403 [Listener at localhost/41222] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 9 Total time for transactions(ms): 21 Number of transactions batched in Syncs: 0 Number of syncs: 10 SyncTimes(ms): 1 1 
2020-12-03 07:22:56,404 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@7be58f16] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:22:56,404 [Listener at localhost/41222] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000009
2020-12-03 07:22:56,405 [Listener at localhost/41222] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000009
2020-12-03 07:22:56,406 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:22:56,406 [CacheReplicationMonitor(457603143)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:22:56,407 [Listener at localhost/41222] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 46381
2020-12-03 07:22:56,415 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:56,428 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:56,440 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:22:56,441 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:22:56,442 [org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor@47db5fa5] DEBUG blockmanagement.BlockManager (PendingReconstructionBlocks.java:run(248)) - PendingReconstructionMonitor thread is interrupted.
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor.run(PendingReconstructionBlocks.java:246)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:22:56,498 [Listener at localhost/41222] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:22:56,499 [Listener at localhost/41222] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:22:56,500 [Listener at localhost/41222] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@3e44f2a5{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:22:56,503 [Listener at localhost/41222] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@589da3f3{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:56,504 [Listener at localhost/41222] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7eecb5b8{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:56,504 [Listener at localhost/41222] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@28cda624{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:56,509 [Listener at localhost/41222] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-12-03 07:22:56,510 [Listener at localhost/41222] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-12-03 07:22:56,511 [Listener at localhost/41222] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
msx-rc 0
