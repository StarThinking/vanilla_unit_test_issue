2020-12-03 07:24:37,224 [main] INFO  hdfs.TestSafeModeWithStripedFileWithRandomECPolicy (TestSafeModeWithStripedFileWithRandomECPolicy.java:<init>(40)) - run TestSafeModeWithStripedFile with RS-LEGACY-6-3-1024k.
2020-12-03 07:24:37,468 [Thread-0] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=9
Formatting using clusterid: testClusterID
2020-12-03 07:24:38,276 [Thread-0] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:24:38,293 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:24:38,295 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:24:38,296 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:24:38,304 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:24:38,304 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:24:38,305 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:24:38,306 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:24:38,361 [Thread-0] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:38,367 [Thread-0] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2020-12-03 07:24:38,367 [Thread-0] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:24:38,367 [Thread-0] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:24:38,372 [Thread-0] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:24:38,373 [Thread-0] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:24:38
2020-12-03 07:24:38,377 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:24:38,377 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:38,380 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-12-03 07:24:38,380 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:24:38,405 [Thread-0] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:24:38,406 [Thread-0] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:24:38,413 [Thread-0] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:24:38,414 [Thread-0] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:24:38,414 [Thread-0] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:24:38,414 [Thread-0] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:24:38,415 [Thread-0] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:24:38,415 [Thread-0] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:24:38,416 [Thread-0] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:24:38,416 [Thread-0] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:24:38,416 [Thread-0] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:24:38,416 [Thread-0] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:24:38,417 [Thread-0] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:24:38,467 [Thread-0] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GLOBAL serial map: bits=29 maxEntries=536870911
2020-12-03 07:24:38,468 [Thread-0] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - USER serial map: bits=24 maxEntries=16777215
2020-12-03 07:24:38,468 [Thread-0] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GROUP serial map: bits=24 maxEntries=16777215
2020-12-03 07:24:38,468 [Thread-0] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - XATTR serial map: bits=24 maxEntries=16777215
2020-12-03 07:24:38,488 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:24:38,488 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:38,489 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-12-03 07:24:38,489 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:24:38,495 [Thread-0] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:24:38,496 [Thread-0] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:24:38,496 [Thread-0] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:24:38,496 [Thread-0] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:24:38,503 [Thread-0] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:24:38,507 [Thread-0] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:24:38,514 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:24:38,515 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:38,515 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-12-03 07:24:38,516 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:24:38,527 [Thread-0] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:24:38,527 [Thread-0] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:24:38,528 [Thread-0] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:24:38,532 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:24:38,532 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:24:38,535 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:24:38,535 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:38,536 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-12-03 07:24:38,536 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:24:38,582 [Thread-0] INFO  namenode.FSImage (FSImage.java:format(185)) - Allocated new BlockPoolId: BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:38,651 [Thread-0] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-12-03 07:24:38,728 [Thread-0] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-12-03 07:24:38,767 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:24:38,767 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:24:38,918 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:24:38,921 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:24:39,002 [Thread-0] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-12-03 07:24:39,006 [Thread-0] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:24:39,127 [Thread-0] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:24:39,399 [Thread-0] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:24:39,399 [Thread-0] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:24:39,436 [Thread-0] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-12-03 07:24:39,489 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5ed711ff] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:39,514 [Thread-0] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:24:39,522 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:39,540 [Thread-0] INFO  util.log (Log.java:initialized(192)) - Logging initialized @3291ms
2020-12-03 07:24:39,670 [Thread-0] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:39,675 [Thread-0] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:24:39,676 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:39,686 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:39,688 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:24:39,689 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:39,689 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:39,719 [Thread-0] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:24:39,719 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:24:39,729 [Thread-0] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 42381
2020-12-03 07:24:39,731 [Thread-0] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:39,783 [Thread-0] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@525f428f{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:39,784 [Thread-0] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4d746801{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:39,830 [Thread-0] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@279c4ae6{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:24:39,839 [Thread-0] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@5860ad70{HTTP/1.1,[http/1.1]}{localhost:42381}
2020-12-03 07:24:39,840 [Thread-0] INFO  server.Server (Server.java:doStart(419)) - Started @3592ms
2020-12-03 07:24:39,853 [Thread-0] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:24:39,854 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:24:39,854 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:24:39,854 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:24:39,855 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:24:39,855 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:24:39,855 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:24:39,855 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:24:39,856 [Thread-0] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:39,857 [Thread-0] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:24:39,857 [Thread-0] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:24:39,857 [Thread-0] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:24:39,858 [Thread-0] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:24:39
2020-12-03 07:24:39,858 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:24:39,858 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:39,859 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:24:39,859 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:24:39,870 [Thread-0] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:24:39,871 [Thread-0] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:24:39,871 [Thread-0] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:24:39,872 [Thread-0] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:24:39,872 [Thread-0] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:24:39,873 [Thread-0] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:24:39,873 [Thread-0] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:24:39,873 [Thread-0] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:24:39,873 [Thread-0] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:24:39,874 [Thread-0] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:24:39,874 [Thread-0] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:24:39,874 [Thread-0] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:24:39,875 [Thread-0] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:24:39,875 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:24:39,876 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:39,876 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:24:39,876 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:24:39,891 [Thread-0] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:24:39,900 [Thread-0] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:24:39,901 [Thread-0] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:24:39,901 [Thread-0] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:24:39,901 [Thread-0] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:24:39,901 [Thread-0] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:24:39,901 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:24:39,902 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:39,902 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:24:39,902 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:24:39,904 [Thread-0] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:24:39,904 [Thread-0] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:24:39,904 [Thread-0] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:24:39,904 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:24:39,905 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:24:39,905 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:24:39,905 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:39,906 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:24:39,906 [Thread-0] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:24:39,931 [Thread-0] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 11964@2bb02abc3fe0
2020-12-03 07:24:39,957 [Thread-0] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 11964@2bb02abc3fe0
2020-12-03 07:24:39,962 [Thread-0] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-12-03 07:24:39,962 [Thread-0] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-12-03 07:24:39,963 [Thread-0] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:24:39,963 [Thread-0] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:24:39,996 [Thread-0] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:24:40,002 [Thread-0] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:24:40,002 [Thread-0] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-12-03 07:24:40,007 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:24:40,008 [Thread-0] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 1
2020-12-03 07:24:40,110 [Thread-0] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:24:40,111 [Thread-0] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 203 msecs
2020-12-03 07:24:40,434 [Thread-0] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:24:40,495 [Thread-0] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:40,516 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:40,862 [Listener at localhost/43954] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:43954 to access this namenode/service.
2020-12-03 07:24:40,865 [Listener at localhost/43954] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:24:40,895 [Listener at localhost/43954] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:24:40,916 [Listener at localhost/43954] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:24:40,917 [Listener at localhost/43954] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:24:40,917 [Listener at localhost/43954] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:24:40,918 [Listener at localhost/43954] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:24:40,923 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 0
2020-12-03 07:24:40,923 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:24:40,923 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:24:40,923 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:24:40,924 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:24:40,924 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 7 msec
2020-12-03 07:24:40,969 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:40,970 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:40,988 [Listener at localhost/43954] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:43954
2020-12-03 07:24:40,996 [Listener at localhost/43954] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:24:40,996 [Listener at localhost/43954] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:24:41,010 [Listener at localhost/43954] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 14 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:24:41,023 [CacheReplicationMonitor(1912035462)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:24:41,026 [Listener at localhost/43954] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:24:41,127 [Listener at localhost/43954] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:24:41,149 [Listener at localhost/43954] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:24:41,180 [Listener at localhost/43954] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:24:41,187 [Listener at localhost/43954] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:41,191 [Listener at localhost/43954] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:24:41,198 [Listener at localhost/43954] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:24:41,199 [Listener at localhost/43954] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:41,205 [Listener at localhost/43954] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:24:41,211 [Listener at localhost/43954] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:37088
2020-12-03 07:24:41,213 [Listener at localhost/43954] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:24:41,213 [Listener at localhost/43954] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:24:41,232 [Listener at localhost/43954] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:41,235 [Listener at localhost/43954] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:41,236 [Listener at localhost/43954] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:24:41,236 [Listener at localhost/43954] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:41,239 [Listener at localhost/43954] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:41,240 [Listener at localhost/43954] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:24:41,240 [Listener at localhost/43954] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:41,240 [Listener at localhost/43954] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:41,244 [Listener at localhost/43954] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 32770
2020-12-03 07:24:41,244 [Listener at localhost/43954] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:41,246 [Listener at localhost/43954] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6e8bf2f6{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:41,247 [Listener at localhost/43954] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@68f7864f{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:41,253 [Listener at localhost/43954] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@749809a2{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:24:41,254 [Listener at localhost/43954] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@970e897{HTTP/1.1,[http/1.1]}{localhost:32770}
2020-12-03 07:24:41,255 [Listener at localhost/43954] INFO  server.Server (Server.java:doStart(419)) - Started @5007ms
2020-12-03 07:24:41,627 [Listener at localhost/43954] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:42001
2020-12-03 07:24:41,628 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7c9db21b] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:41,629 [Listener at localhost/43954] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:24:41,630 [Listener at localhost/43954] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:24:41,828 [Listener at localhost/43954] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:41,829 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:41,839 [Listener at localhost/38029] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:38029
2020-12-03 07:24:41,866 [Listener at localhost/38029] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:24:41,868 [Listener at localhost/38029] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:24:41,883 [Thread-60] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43954 starting to offer service
2020-12-03 07:24:41,891 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:41,891 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:41,895 [Listener at localhost/38029] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:24:41,897 [Listener at localhost/38029] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:24:41,898 [Listener at localhost/38029] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:24:41,900 [Listener at localhost/38029] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:24:41,901 [Listener at localhost/38029] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:41,901 [Listener at localhost/38029] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:24:41,901 [Listener at localhost/38029] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:24:41,902 [Listener at localhost/38029] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:41,902 [Listener at localhost/38029] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:24:41,903 [Listener at localhost/38029] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:36036
2020-12-03 07:24:41,903 [Listener at localhost/38029] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:24:41,903 [Listener at localhost/38029] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:24:41,904 [Listener at localhost/38029] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:41,906 [Listener at localhost/38029] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:41,906 [Listener at localhost/38029] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:24:41,907 [Listener at localhost/38029] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:41,909 [Listener at localhost/38029] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:41,910 [Listener at localhost/38029] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:24:41,910 [Listener at localhost/38029] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:41,910 [Listener at localhost/38029] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:41,911 [Listener at localhost/38029] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 37226
2020-12-03 07:24:41,911 [Listener at localhost/38029] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:41,913 [Listener at localhost/38029] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@78410454{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:41,914 [Listener at localhost/38029] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1461a0d8{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:41,921 [Listener at localhost/38029] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7a654dc7{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:24:41,923 [Listener at localhost/38029] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4452cb6e{HTTP/1.1,[http/1.1]}{localhost:37226}
2020-12-03 07:24:41,924 [Listener at localhost/38029] INFO  server.Server (Server.java:doStart(419)) - Started @5676ms
2020-12-03 07:24:41,990 [Listener at localhost/38029] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:39431
2020-12-03 07:24:41,992 [Listener at localhost/38029] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:24:41,992 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6d58e9ec] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:41,992 [Listener at localhost/38029] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:24:41,993 [Listener at localhost/38029] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:41,995 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:42,002 [Listener at localhost/38222] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:38222
2020-12-03 07:24:42,012 [Listener at localhost/38222] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:24:42,013 [Listener at localhost/38222] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:24:42,014 [Thread-84] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43954 starting to offer service
2020-12-03 07:24:42,016 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:42,017 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:42,021 [Listener at localhost/38222] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:24:42,023 [Listener at localhost/38222] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:24:42,024 [Listener at localhost/38222] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:24:42,026 [Listener at localhost/38222] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:24:42,026 [Listener at localhost/38222] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:42,027 [Listener at localhost/38222] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:24:42,027 [Listener at localhost/38222] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:24:42,027 [Listener at localhost/38222] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:42,028 [Listener at localhost/38222] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:24:42,029 [Listener at localhost/38222] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:46279
2020-12-03 07:24:42,029 [Listener at localhost/38222] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:24:42,030 [Listener at localhost/38222] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:24:42,031 [Listener at localhost/38222] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:42,034 [Listener at localhost/38222] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:42,035 [Listener at localhost/38222] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:24:42,035 [Listener at localhost/38222] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:42,039 [Listener at localhost/38222] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:42,041 [Listener at localhost/38222] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:24:42,041 [Listener at localhost/38222] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:42,041 [Listener at localhost/38222] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:42,042 [Listener at localhost/38222] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 34178
2020-12-03 07:24:42,043 [Listener at localhost/38222] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:42,045 [Listener at localhost/38222] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1357a570{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:42,046 [Listener at localhost/38222] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3977f84a{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:42,056 [Listener at localhost/38222] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@476a123a{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:24:42,057 [Listener at localhost/38222] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2bb53d1f{HTTP/1.1,[http/1.1]}{localhost:34178}
2020-12-03 07:24:42,057 [Listener at localhost/38222] INFO  server.Server (Server.java:doStart(419)) - Started @5810ms
2020-12-03 07:24:42,079 [Listener at localhost/38222] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:36012
2020-12-03 07:24:42,079 [Listener at localhost/38222] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:24:42,079 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@74fc48df] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:42,079 [Listener at localhost/38222] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:24:42,080 [Listener at localhost/38222] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:42,085 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:42,096 [Listener at localhost/42918] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:42918
2020-12-03 07:24:42,101 [Listener at localhost/42918] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:24:42,102 [Listener at localhost/42918] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:24:42,103 [Thread-106] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43954 starting to offer service
2020-12-03 07:24:42,105 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:42,105 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:42,109 [Listener at localhost/42918] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 3 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:24:42,111 [Listener at localhost/42918] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:24:42,111 [Listener at localhost/42918] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:24:42,112 [Listener at localhost/42918] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:24:42,113 [Listener at localhost/42918] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:42,113 [Listener at localhost/42918] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:24:42,114 [Listener at localhost/42918] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:24:42,114 [Listener at localhost/42918] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:42,114 [Listener at localhost/42918] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:24:42,115 [Listener at localhost/42918] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:44016
2020-12-03 07:24:42,115 [Listener at localhost/42918] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:24:42,115 [Listener at localhost/42918] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:24:42,116 [Listener at localhost/42918] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:42,118 [Listener at localhost/42918] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:42,119 [Listener at localhost/42918] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:24:42,119 [Listener at localhost/42918] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:42,122 [Listener at localhost/42918] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:42,123 [Listener at localhost/42918] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:24:42,123 [Listener at localhost/42918] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:42,124 [Listener at localhost/42918] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:42,124 [Listener at localhost/42918] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 35934
2020-12-03 07:24:42,125 [Listener at localhost/42918] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:42,127 [Listener at localhost/42918] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2e349ec2{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:42,127 [Listener at localhost/42918] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@37c94948{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:42,134 [Listener at localhost/42918] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@4be41510{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:24:42,135 [Listener at localhost/42918] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@71f2c909{HTTP/1.1,[http/1.1]}{localhost:35934}
2020-12-03 07:24:42,135 [Listener at localhost/42918] INFO  server.Server (Server.java:doStart(419)) - Started @5887ms
2020-12-03 07:24:42,173 [Listener at localhost/42918] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:43514
2020-12-03 07:24:42,174 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7c081328] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:42,174 [Listener at localhost/42918] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:24:42,174 [Listener at localhost/42918] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:24:42,175 [Listener at localhost/42918] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:42,176 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:42,181 [Listener at localhost/45669] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:45669
2020-12-03 07:24:42,187 [Listener at localhost/45669] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:24:42,188 [Listener at localhost/45669] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:24:42,189 [Thread-128] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43954 starting to offer service
2020-12-03 07:24:42,203 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:42,204 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:42,208 [Listener at localhost/45669] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 4 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:24:42,211 [Listener at localhost/45669] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:24:42,211 [Thread-128] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43954
2020-12-03 07:24:42,211 [Thread-84] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43954
2020-12-03 07:24:42,211 [Thread-60] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43954
2020-12-03 07:24:42,211 [Thread-106] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43954
2020-12-03 07:24:42,212 [Listener at localhost/45669] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:24:42,215 [Thread-106] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:24:42,215 [Thread-84] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:24:42,215 [Thread-60] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:24:42,215 [Thread-128] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:24:42,215 [Listener at localhost/45669] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:24:42,216 [Listener at localhost/45669] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:42,216 [Listener at localhost/45669] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:24:42,217 [Listener at localhost/45669] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:24:42,217 [Listener at localhost/45669] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:42,218 [Listener at localhost/45669] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:24:42,219 [Listener at localhost/45669] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:44848
2020-12-03 07:24:42,219 [Listener at localhost/45669] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:24:42,219 [Listener at localhost/45669] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:24:42,221 [Listener at localhost/45669] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:42,222 [Listener at localhost/45669] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:42,223 [Listener at localhost/45669] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:24:42,224 [Listener at localhost/45669] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:42,226 [Listener at localhost/45669] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:42,227 [Listener at localhost/45669] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:24:42,227 [Listener at localhost/45669] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:42,227 [Listener at localhost/45669] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:42,228 [Listener at localhost/45669] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 41728
2020-12-03 07:24:42,228 [Listener at localhost/45669] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:42,231 [Listener at localhost/45669] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6cadeb00{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:42,231 [Listener at localhost/45669] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@20af3275{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:42,237 [Listener at localhost/45669] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@73d28aa6{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:24:42,238 [Listener at localhost/45669] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1b1d7f5f{HTTP/1.1,[http/1.1]}{localhost:41728}
2020-12-03 07:24:42,239 [Listener at localhost/45669] INFO  server.Server (Server.java:doStart(419)) - Started @5991ms
2020-12-03 07:24:42,254 [Listener at localhost/45669] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:35422
2020-12-03 07:24:42,254 [Listener at localhost/45669] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:24:42,254 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@75bf5f4f] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:42,254 [Listener at localhost/45669] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:24:42,255 [Listener at localhost/45669] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:42,256 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:42,259 [Listener at localhost/41618] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:41618
2020-12-03 07:24:42,263 [Listener at localhost/41618] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:24:42,264 [Listener at localhost/41618] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:24:42,264 [Thread-150] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43954 starting to offer service
2020-12-03 07:24:42,266 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:42,266 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:42,270 [Thread-150] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43954
2020-12-03 07:24:42,271 [Listener at localhost/41618] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 5 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:24:42,271 [Thread-150] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:24:42,272 [Listener at localhost/41618] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:24:42,277 [Listener at localhost/41618] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:24:42,279 [Listener at localhost/41618] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:24:42,279 [Listener at localhost/41618] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:42,279 [Listener at localhost/41618] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:24:42,279 [Thread-106] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 11964@2bb02abc3fe0
2020-12-03 07:24:42,279 [Thread-84] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 11964@2bb02abc3fe0
2020-12-03 07:24:42,280 [Listener at localhost/41618] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:24:42,280 [Thread-60] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 11964@2bb02abc3fe0
2020-12-03 07:24:42,280 [Listener at localhost/41618] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:42,280 [Thread-106] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 is not formatted for namespace 829214013. Formatting...
2020-12-03 07:24:42,281 [Thread-84] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 is not formatted for namespace 829214013. Formatting...
2020-12-03 07:24:42,280 [Thread-60] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 829214013. Formatting...
2020-12-03 07:24:42,281 [Listener at localhost/41618] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:24:42,282 [Thread-60] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-86b77411-628e-439a-83fb-b288094a00ab for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-12-03 07:24:42,282 [Listener at localhost/41618] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:33258
2020-12-03 07:24:42,282 [Thread-84] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-0095e818-e243-4a1c-aa13-99da0fd9e056 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 
2020-12-03 07:24:42,282 [Thread-106] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-c003fc79-c50f-47e0-92be-1300d56d1d0d for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 
2020-12-03 07:24:42,282 [Thread-128] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/in_use.lock acquired by nodename 11964@2bb02abc3fe0
2020-12-03 07:24:42,282 [Listener at localhost/41618] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:24:42,283 [Listener at localhost/41618] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:24:42,283 [Thread-128] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 is not formatted for namespace 829214013. Formatting...
2020-12-03 07:24:42,283 [Thread-128] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-4a4533dc-c0f5-4eba-8ab7-8f9fd4e59ffc for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 
2020-12-03 07:24:42,284 [Listener at localhost/41618] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:42,285 [Listener at localhost/41618] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:42,286 [Listener at localhost/41618] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:24:42,286 [Listener at localhost/41618] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:42,288 [Listener at localhost/41618] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:42,289 [Listener at localhost/41618] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:24:42,289 [Listener at localhost/41618] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:42,289 [Listener at localhost/41618] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:42,290 [Listener at localhost/41618] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 46548
2020-12-03 07:24:42,290 [Listener at localhost/41618] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:42,291 [Listener at localhost/41618] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3a4fc381{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:42,292 [Listener at localhost/41618] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@495a022d{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:42,298 [Listener at localhost/41618] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@571015a5{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:24:42,299 [Listener at localhost/41618] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@63b2af8f{HTTP/1.1,[http/1.1]}{localhost:46548}
2020-12-03 07:24:42,300 [Listener at localhost/41618] INFO  server.Server (Server.java:doStart(419)) - Started @6052ms
2020-12-03 07:24:42,313 [Listener at localhost/41618] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:44157
2020-12-03 07:24:42,314 [Thread-150] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/in_use.lock acquired by nodename 11964@2bb02abc3fe0
2020-12-03 07:24:42,314 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@424dde6b] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:42,314 [Listener at localhost/41618] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:24:42,314 [Thread-150] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 is not formatted for namespace 829214013. Formatting...
2020-12-03 07:24:42,314 [Listener at localhost/41618] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:24:42,315 [Thread-150] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-642bfc7c-ff8d-4514-94bd-79381f534ac2 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 
2020-12-03 07:24:42,315 [Listener at localhost/41618] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:42,318 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:42,322 [Listener at localhost/33152] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:33152
2020-12-03 07:24:42,341 [Listener at localhost/33152] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:24:42,341 [Listener at localhost/33152] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:24:42,342 [Thread-172] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43954 starting to offer service
2020-12-03 07:24:42,344 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:42,344 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:42,347 [Listener at localhost/33152] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 6 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:24:42,349 [Thread-172] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43954
2020-12-03 07:24:42,349 [Listener at localhost/33152] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:24:42,349 [Thread-172] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:24:42,349 [Listener at localhost/33152] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:24:42,350 [Listener at localhost/33152] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:24:42,351 [Listener at localhost/33152] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:42,351 [Listener at localhost/33152] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:24:42,352 [Listener at localhost/33152] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:24:42,352 [Listener at localhost/33152] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:42,352 [Listener at localhost/33152] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:24:42,353 [Listener at localhost/33152] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:43823
2020-12-03 07:24:42,353 [Listener at localhost/33152] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:24:42,353 [Listener at localhost/33152] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:24:42,354 [Listener at localhost/33152] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:42,356 [Listener at localhost/33152] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:42,356 [Listener at localhost/33152] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:24:42,357 [Listener at localhost/33152] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:42,359 [Listener at localhost/33152] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:42,359 [Listener at localhost/33152] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:24:42,360 [Listener at localhost/33152] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:42,360 [Listener at localhost/33152] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:42,360 [Listener at localhost/33152] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 36288
2020-12-03 07:24:42,361 [Listener at localhost/33152] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:42,362 [Listener at localhost/33152] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@413b44fe{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:42,363 [Listener at localhost/33152] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@12b86e0e{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:42,369 [Listener at localhost/33152] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3a84a9d4{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:24:42,370 [Listener at localhost/33152] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@e779541{HTTP/1.1,[http/1.1]}{localhost:36288}
2020-12-03 07:24:42,370 [Listener at localhost/33152] INFO  server.Server (Server.java:doStart(419)) - Started @6123ms
2020-12-03 07:24:42,385 [Listener at localhost/33152] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:37174
2020-12-03 07:24:42,386 [Listener at localhost/33152] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:24:42,386 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@626d2a09] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:42,386 [Listener at localhost/33152] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:24:42,387 [Listener at localhost/33152] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:42,387 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:42,391 [Listener at localhost/35038] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:35038
2020-12-03 07:24:42,395 [Listener at localhost/35038] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:24:42,396 [Listener at localhost/35038] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:24:42,396 [Thread-194] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43954 starting to offer service
2020-12-03 07:24:42,398 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:42,398 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:42,402 [Thread-194] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43954
2020-12-03 07:24:42,402 [Listener at localhost/35038] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 7 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:24:42,403 [Thread-172] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/in_use.lock acquired by nodename 11964@2bb02abc3fe0
2020-12-03 07:24:42,403 [Thread-194] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:24:42,404 [Thread-172] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 is not formatted for namespace 829214013. Formatting...
2020-12-03 07:24:42,405 [Thread-172] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-5a11274f-c1da-45a9-aa5e-f76140593ef7 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 
2020-12-03 07:24:42,406 [Listener at localhost/35038] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:24:42,406 [Listener at localhost/35038] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:24:42,409 [Listener at localhost/35038] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:24:42,409 [Listener at localhost/35038] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:42,409 [Listener at localhost/35038] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:24:42,410 [Listener at localhost/35038] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:24:42,410 [Listener at localhost/35038] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:42,410 [Listener at localhost/35038] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:24:42,411 [Listener at localhost/35038] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:38762
2020-12-03 07:24:42,411 [Listener at localhost/35038] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:24:42,411 [Listener at localhost/35038] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:24:42,412 [Listener at localhost/35038] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:42,414 [Listener at localhost/35038] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:42,415 [Listener at localhost/35038] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:24:42,415 [Listener at localhost/35038] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:42,417 [Listener at localhost/35038] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:42,417 [Listener at localhost/35038] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:24:42,417 [Listener at localhost/35038] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:42,418 [Listener at localhost/35038] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:42,418 [Listener at localhost/35038] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 34152
2020-12-03 07:24:42,419 [Listener at localhost/35038] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:42,420 [Listener at localhost/35038] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@15dd18fe{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:42,421 [Listener at localhost/35038] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3c04674{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:42,429 [Listener at localhost/35038] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@67908516{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:24:42,430 [Listener at localhost/35038] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4c2b0ab7{HTTP/1.1,[http/1.1]}{localhost:34152}
2020-12-03 07:24:42,431 [Listener at localhost/35038] INFO  server.Server (Server.java:doStart(419)) - Started @6183ms
2020-12-03 07:24:42,509 [Thread-194] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/in_use.lock acquired by nodename 11964@2bb02abc3fe0
2020-12-03 07:24:42,509 [Thread-194] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 is not formatted for namespace 829214013. Formatting...
2020-12-03 07:24:42,511 [Thread-194] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-ea8236f0-3cb7-4341-b448-d9673239316e for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 
2020-12-03 07:24:42,526 [Listener at localhost/35038] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:44750
2020-12-03 07:24:42,527 [Listener at localhost/35038] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:24:42,527 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2daa15cf] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:42,527 [Listener at localhost/35038] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:24:42,528 [Listener at localhost/35038] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:42,529 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:42,534 [Listener at localhost/33323] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:33323
2020-12-03 07:24:42,541 [Listener at localhost/33323] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:24:42,541 [Listener at localhost/33323] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:24:42,542 [Thread-216] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43954 starting to offer service
2020-12-03 07:24:42,544 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:42,544 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:42,552 [Thread-216] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43954
2020-12-03 07:24:42,553 [Thread-216] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:24:42,553 [Listener at localhost/33323] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 8 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:24:42,554 [Listener at localhost/33323] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:24:42,555 [Listener at localhost/33323] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:24:42,555 [Thread-106] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 11964@2bb02abc3fe0
2020-12-03 07:24:42,556 [Thread-60] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 11964@2bb02abc3fe0
2020-12-03 07:24:42,555 [Thread-84] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 11964@2bb02abc3fe0
2020-12-03 07:24:42,555 [Thread-128] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/in_use.lock acquired by nodename 11964@2bb02abc3fe0
2020-12-03 07:24:42,556 [Thread-60] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 829214013. Formatting...
2020-12-03 07:24:42,556 [Thread-106] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 is not formatted for namespace 829214013. Formatting...
2020-12-03 07:24:42,556 [Thread-128] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 is not formatted for namespace 829214013. Formatting...
2020-12-03 07:24:42,556 [Thread-84] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 is not formatted for namespace 829214013. Formatting...
2020-12-03 07:24:42,569 [Thread-128] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-652cfcf7-8574-41cf-86aa-f7d20cbe2811 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 
2020-12-03 07:24:42,569 [Thread-84] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-f45a8750-594d-4642-87e3-93d21021bf5a for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 
2020-12-03 07:24:42,569 [Thread-60] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-519a1287-ec06-4bbf-8d21-79dbaca51fcb for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-12-03 07:24:42,569 [Thread-106] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-bd1ff44c-a092-4057-b4a3-2c31abfa7ab4 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 
2020-12-03 07:24:42,570 [Listener at localhost/33323] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:24:42,571 [Listener at localhost/33323] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:42,571 [Listener at localhost/33323] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:24:42,572 [Listener at localhost/33323] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:24:42,572 [Listener at localhost/33323] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:42,572 [Listener at localhost/33323] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:24:42,573 [Listener at localhost/33323] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:32788
2020-12-03 07:24:42,573 [Listener at localhost/33323] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:24:42,573 [Listener at localhost/33323] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:24:42,575 [Listener at localhost/33323] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:42,576 [Listener at localhost/33323] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:42,577 [Listener at localhost/33323] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:24:42,577 [Listener at localhost/33323] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:42,579 [Listener at localhost/33323] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:42,580 [Listener at localhost/33323] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:24:42,580 [Listener at localhost/33323] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:42,580 [Listener at localhost/33323] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:42,581 [Listener at localhost/33323] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 44420
2020-12-03 07:24:42,581 [Listener at localhost/33323] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:42,583 [Listener at localhost/33323] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@386a45c8{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:42,584 [Listener at localhost/33323] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1aff6a4c{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:42,590 [Listener at localhost/33323] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@766ad58f{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:24:42,591 [Listener at localhost/33323] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1f7ae072{HTTP/1.1,[http/1.1]}{localhost:44420}
2020-12-03 07:24:42,591 [Listener at localhost/33323] INFO  server.Server (Server.java:doStart(419)) - Started @6343ms
2020-12-03 07:24:42,610 [Listener at localhost/33323] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:38114
2020-12-03 07:24:42,611 [Listener at localhost/33323] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:24:42,611 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@723dc2bf] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:42,611 [Listener at localhost/33323] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:24:42,612 [Listener at localhost/33323] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:42,613 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:42,614 [Thread-216] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/in_use.lock acquired by nodename 11964@2bb02abc3fe0
2020-12-03 07:24:42,614 [Thread-150] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/in_use.lock acquired by nodename 11964@2bb02abc3fe0
2020-12-03 07:24:42,614 [Thread-216] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 is not formatted for namespace 829214013. Formatting...
2020-12-03 07:24:42,615 [Thread-150] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 is not formatted for namespace 829214013. Formatting...
2020-12-03 07:24:42,615 [Thread-216] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-bda183c3-643a-4595-8903-8df17740c647 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 
2020-12-03 07:24:42,615 [Thread-150] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-bf7ef67b-e5ab-452a-a984-fbd8e1fd6d82 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 
2020-12-03 07:24:42,617 [Listener at localhost/36976] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:36976
2020-12-03 07:24:42,622 [Listener at localhost/36976] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:24:42,622 [Listener at localhost/36976] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:24:42,623 [Thread-238] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43954 starting to offer service
2020-12-03 07:24:42,626 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:42,628 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:42,632 [Thread-238] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43954
2020-12-03 07:24:42,633 [Thread-238] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:24:42,689 [Thread-172] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/in_use.lock acquired by nodename 11964@2bb02abc3fe0
2020-12-03 07:24:42,689 [Thread-238] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/in_use.lock acquired by nodename 11964@2bb02abc3fe0
2020-12-03 07:24:42,689 [Thread-172] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 is not formatted for namespace 829214013. Formatting...
2020-12-03 07:24:42,690 [Thread-238] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 is not formatted for namespace 829214013. Formatting...
2020-12-03 07:24:42,690 [Thread-172] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-36579057-efca-436e-8f83-6abab3daf2e6 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 
2020-12-03 07:24:42,690 [Thread-238] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-fee6374f-fab9-484b-840a-3bb039765f1d for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 
2020-12-03 07:24:42,740 [Thread-60] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:42,740 [Thread-106] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:42,740 [Thread-60] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:42,740 [Thread-106] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:42,744 [Thread-60] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-1006108214-172.17.0.5-1606980278566 is not formatted. Formatting ...
2020-12-03 07:24:42,744 [Thread-106] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 and block pool id BP-1006108214-172.17.0.5-1606980278566 is not formatted. Formatting ...
2020-12-03 07:24:42,744 [Thread-60] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1006108214-172.17.0.5-1606980278566 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1006108214-172.17.0.5-1606980278566/current
2020-12-03 07:24:42,744 [Thread-106] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1006108214-172.17.0.5-1606980278566 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1006108214-172.17.0.5-1606980278566/current
2020-12-03 07:24:42,746 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:42,746 [Thread-84] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:42,747 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 and block pool id BP-1006108214-172.17.0.5-1606980278566 is not formatted. Formatting ...
2020-12-03 07:24:42,747 [Thread-128] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:42,747 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1006108214-172.17.0.5-1606980278566 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1006108214-172.17.0.5-1606980278566/current
2020-12-03 07:24:42,747 [Thread-128] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:42,747 [Thread-128] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 and block pool id BP-1006108214-172.17.0.5-1606980278566 is not formatted. Formatting ...
2020-12-03 07:24:42,747 [Thread-128] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1006108214-172.17.0.5-1606980278566 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1006108214-172.17.0.5-1606980278566/current
2020-12-03 07:24:42,748 [Thread-194] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/in_use.lock acquired by nodename 11964@2bb02abc3fe0
2020-12-03 07:24:42,748 [Thread-194] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 is not formatted for namespace 829214013. Formatting...
2020-12-03 07:24:42,752 [Thread-194] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-24768886-4de0-4de1-9388-2b4ca3a5077c for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 
2020-12-03 07:24:42,757 [Thread-150] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:42,758 [Thread-150] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:42,758 [Thread-150] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 and block pool id BP-1006108214-172.17.0.5-1606980278566 is not formatted. Formatting ...
2020-12-03 07:24:42,758 [Thread-150] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1006108214-172.17.0.5-1606980278566 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1006108214-172.17.0.5-1606980278566/current
2020-12-03 07:24:42,818 [Thread-172] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:42,818 [Thread-172] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:42,818 [Thread-172] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 and block pool id BP-1006108214-172.17.0.5-1606980278566 is not formatted. Formatting ...
2020-12-03 07:24:42,818 [Thread-172] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1006108214-172.17.0.5-1606980278566 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1006108214-172.17.0.5-1606980278566/current
2020-12-03 07:24:42,889 [Thread-216] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/in_use.lock acquired by nodename 11964@2bb02abc3fe0
2020-12-03 07:24:42,889 [Thread-216] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 is not formatted for namespace 829214013. Formatting...
2020-12-03 07:24:42,891 [Thread-216] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-fd75e4f2-39b3-4d3a-864b-ad2d2be6069e for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 
2020-12-03 07:24:42,944 [Thread-238] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/in_use.lock acquired by nodename 11964@2bb02abc3fe0
2020-12-03 07:24:42,944 [Thread-238] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 is not formatted for namespace 829214013. Formatting...
2020-12-03 07:24:42,945 [Thread-238] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-4f8bde89-39bc-4664-8495-24db1fc9070c for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 
2020-12-03 07:24:42,955 [Thread-106] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:42,955 [Thread-106] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:42,955 [Thread-106] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 and block pool id BP-1006108214-172.17.0.5-1606980278566 is not formatted. Formatting ...
2020-12-03 07:24:42,955 [Thread-106] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1006108214-172.17.0.5-1606980278566 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1006108214-172.17.0.5-1606980278566/current
2020-12-03 07:24:42,957 [Thread-60] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:42,957 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:42,957 [Thread-128] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:42,957 [Thread-60] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:42,957 [Thread-84] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:42,957 [Thread-128] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:42,957 [Thread-60] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-1006108214-172.17.0.5-1606980278566 is not formatted. Formatting ...
2020-12-03 07:24:42,958 [Thread-128] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 and block pool id BP-1006108214-172.17.0.5-1606980278566 is not formatted. Formatting ...
2020-12-03 07:24:42,958 [Thread-60] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1006108214-172.17.0.5-1606980278566 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1006108214-172.17.0.5-1606980278566/current
2020-12-03 07:24:42,958 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 and block pool id BP-1006108214-172.17.0.5-1606980278566 is not formatted. Formatting ...
2020-12-03 07:24:42,958 [Thread-128] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1006108214-172.17.0.5-1606980278566 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1006108214-172.17.0.5-1606980278566/current
2020-12-03 07:24:42,958 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1006108214-172.17.0.5-1606980278566 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1006108214-172.17.0.5-1606980278566/current
2020-12-03 07:24:42,992 [Thread-194] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:42,993 [Thread-194] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:42,993 [Thread-194] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 and block pool id BP-1006108214-172.17.0.5-1606980278566 is not formatted. Formatting ...
2020-12-03 07:24:42,993 [Thread-150] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:42,993 [Thread-194] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1006108214-172.17.0.5-1606980278566 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1006108214-172.17.0.5-1606980278566/current
2020-12-03 07:24:42,993 [Thread-150] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:42,994 [Thread-150] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 and block pool id BP-1006108214-172.17.0.5-1606980278566 is not formatted. Formatting ...
2020-12-03 07:24:42,994 [Thread-150] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1006108214-172.17.0.5-1606980278566 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1006108214-172.17.0.5-1606980278566/current
2020-12-03 07:24:43,081 [Thread-172] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:43,082 [Thread-172] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:43,082 [Thread-172] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 and block pool id BP-1006108214-172.17.0.5-1606980278566 is not formatted. Formatting ...
2020-12-03 07:24:43,082 [Thread-172] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1006108214-172.17.0.5-1606980278566 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1006108214-172.17.0.5-1606980278566/current
2020-12-03 07:24:43,119 [IPC Server handler 0 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:43,127 [Listener at localhost/36976] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:43,128 [Listener at localhost/36976] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:43,177 [Thread-216] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:43,177 [Thread-216] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:43,177 [Thread-216] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 and block pool id BP-1006108214-172.17.0.5-1606980278566 is not formatted. Formatting ...
2020-12-03 07:24:43,177 [Thread-216] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1006108214-172.17.0.5-1606980278566 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1006108214-172.17.0.5-1606980278566/current
2020-12-03 07:24:43,217 [Thread-106] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=829214013;bpid=BP-1006108214-172.17.0.5-1606980278566;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=829214013;c=1606980278566;bpid=BP-1006108214-172.17.0.5-1606980278566;dnuuid=null
2020-12-03 07:24:43,217 [Thread-128] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=829214013;bpid=BP-1006108214-172.17.0.5-1606980278566;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=829214013;c=1606980278566;bpid=BP-1006108214-172.17.0.5-1606980278566;dnuuid=null
2020-12-03 07:24:43,217 [Thread-84] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=829214013;bpid=BP-1006108214-172.17.0.5-1606980278566;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=829214013;c=1606980278566;bpid=BP-1006108214-172.17.0.5-1606980278566;dnuuid=null
2020-12-03 07:24:43,217 [Thread-60] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=829214013;bpid=BP-1006108214-172.17.0.5-1606980278566;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=829214013;c=1606980278566;bpid=BP-1006108214-172.17.0.5-1606980278566;dnuuid=null
2020-12-03 07:24:43,226 [Thread-238] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:43,226 [Thread-238] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:43,226 [Thread-238] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 and block pool id BP-1006108214-172.17.0.5-1606980278566 is not formatted. Formatting ...
2020-12-03 07:24:43,226 [Thread-238] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1006108214-172.17.0.5-1606980278566 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1006108214-172.17.0.5-1606980278566/current
2020-12-03 07:24:43,230 [IPC Server handler 3 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:43,231 [Listener at localhost/36976] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:43,232 [Listener at localhost/36976] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:43,269 [Thread-150] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=829214013;bpid=BP-1006108214-172.17.0.5-1606980278566;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=829214013;c=1606980278566;bpid=BP-1006108214-172.17.0.5-1606980278566;dnuuid=null
2020-12-03 07:24:43,278 [Thread-194] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:43,278 [Thread-194] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:43,278 [Thread-194] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 and block pool id BP-1006108214-172.17.0.5-1606980278566 is not formatted. Formatting ...
2020-12-03 07:24:43,278 [Thread-194] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1006108214-172.17.0.5-1606980278566 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1006108214-172.17.0.5-1606980278566/current
2020-12-03 07:24:43,334 [IPC Server handler 8 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:43,335 [Listener at localhost/36976] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:43,335 [Listener at localhost/36976] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:43,377 [Thread-172] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=829214013;bpid=BP-1006108214-172.17.0.5-1606980278566;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=829214013;c=1606980278566;bpid=BP-1006108214-172.17.0.5-1606980278566;dnuuid=null
2020-12-03 07:24:43,437 [IPC Server handler 7 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:43,438 [Listener at localhost/36976] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:43,438 [Listener at localhost/36976] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:43,498 [Thread-216] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:43,499 [Thread-216] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:43,499 [Thread-216] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 and block pool id BP-1006108214-172.17.0.5-1606980278566 is not formatted. Formatting ...
2020-12-03 07:24:43,499 [Thread-216] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1006108214-172.17.0.5-1606980278566 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1006108214-172.17.0.5-1606980278566/current
2020-12-03 07:24:43,540 [IPC Server handler 4 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:43,541 [Listener at localhost/36976] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:43,541 [Listener at localhost/36976] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:43,615 [Thread-84] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID af552311-853c-41f7-a978-1842b97d4d48
2020-12-03 07:24:43,615 [Thread-60] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 65fee986-f2dc-4671-a566-834a8ba38ec2
2020-12-03 07:24:43,615 [Thread-106] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 85df5b2e-a97a-41c1-835b-035a6b9b8a7e
2020-12-03 07:24:43,615 [Thread-128] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 9ef29ebf-468b-497a-b175-e15a6fddabac
2020-12-03 07:24:43,626 [Thread-238] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:43,627 [Thread-238] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:43,627 [Thread-238] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 and block pool id BP-1006108214-172.17.0.5-1606980278566 is not formatted. Formatting ...
2020-12-03 07:24:43,627 [Thread-238] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1006108214-172.17.0.5-1606980278566 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1006108214-172.17.0.5-1606980278566/current
2020-12-03 07:24:43,643 [IPC Server handler 9 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:43,644 [Listener at localhost/36976] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:43,644 [Listener at localhost/36976] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:43,707 [Thread-150] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 64ab98d0-afa7-4e91-8bf0-90433700df57
2020-12-03 07:24:43,707 [Thread-194] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=829214013;bpid=BP-1006108214-172.17.0.5-1606980278566;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=829214013;c=1606980278566;bpid=BP-1006108214-172.17.0.5-1606980278566;dnuuid=null
2020-12-03 07:24:43,747 [IPC Server handler 0 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:43,748 [Listener at localhost/36976] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:43,748 [Listener at localhost/36976] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:43,758 [Thread-150] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-642bfc7c-ff8d-4514-94bd-79381f534ac2
2020-12-03 07:24:43,759 [Thread-150] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, StorageType: DISK
2020-12-03 07:24:43,759 [Thread-84] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-0095e818-e243-4a1c-aa13-99da0fd9e056
2020-12-03 07:24:43,759 [Thread-106] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-c003fc79-c50f-47e0-92be-1300d56d1d0d
2020-12-03 07:24:43,760 [Thread-84] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: DISK
2020-12-03 07:24:43,758 [Thread-128] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-4a4533dc-c0f5-4eba-8ab7-8f9fd4e59ffc
2020-12-03 07:24:43,760 [Thread-106] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, StorageType: DISK
2020-12-03 07:24:43,761 [Thread-128] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, StorageType: DISK
2020-12-03 07:24:43,759 [Thread-60] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-86b77411-628e-439a-83fb-b288094a00ab
2020-12-03 07:24:43,762 [Thread-60] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-12-03 07:24:43,764 [Thread-150] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-bf7ef67b-e5ab-452a-a984-fbd8e1fd6d82
2020-12-03 07:24:43,764 [Thread-150] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, StorageType: DISK
2020-12-03 07:24:43,766 [Thread-60] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-519a1287-ec06-4bbf-8d21-79dbaca51fcb
2020-12-03 07:24:43,767 [Thread-60] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-12-03 07:24:43,768 [Thread-128] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-652cfcf7-8574-41cf-86aa-f7d20cbe2811
2020-12-03 07:24:43,768 [Thread-128] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, StorageType: DISK
2020-12-03 07:24:43,769 [Thread-106] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-bd1ff44c-a092-4057-b4a3-2c31abfa7ab4
2020-12-03 07:24:43,770 [Thread-106] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, StorageType: DISK
2020-12-03 07:24:43,772 [Thread-84] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-f45a8750-594d-4642-87e3-93d21021bf5a
2020-12-03 07:24:43,775 [Thread-84] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: DISK
2020-12-03 07:24:43,777 [Thread-60] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:24:43,777 [Thread-128] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:24:43,777 [Thread-150] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:24:43,777 [Thread-106] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:24:43,777 [Thread-84] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:24:43,785 [Thread-60] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:24:43,787 [Thread-84] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:24:43,785 [Thread-172] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 2a2a30fb-7121-4535-8e69-ccc1d4e70ec3
2020-12-03 07:24:43,790 [Thread-150] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:24:43,789 [Thread-106] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:24:43,792 [Thread-128] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:24:43,793 [Thread-172] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-5a11274f-c1da-45a9-aa5e-f76140593ef7
2020-12-03 07:24:43,794 [Thread-172] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, StorageType: DISK
2020-12-03 07:24:43,800 [Thread-150] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:24:43,800 [Thread-106] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:24:43,800 [Thread-128] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:24:43,800 [Thread-84] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:24:43,800 [Thread-60] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:24:43,802 [Thread-150] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:24:43,802 [Thread-106] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:24:43,802 [Thread-84] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:24:43,802 [Thread-60] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:24:43,804 [Thread-84] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:24:43,804 [Thread-172] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-36579057-efca-436e-8f83-6abab3daf2e6
2020-12-03 07:24:43,804 [Thread-172] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, StorageType: DISK
2020-12-03 07:24:43,802 [Thread-128] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:24:43,804 [Thread-128] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:24:43,804 [Thread-84] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:43,804 [Thread-60] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:24:43,803 [Thread-106] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:24:43,802 [Thread-150] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:24:43,805 [Thread-106] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:43,805 [Thread-60] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:43,805 [Thread-172] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:24:43,806 [Thread-264] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:24:43,805 [Thread-150] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:43,807 [Thread-172] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:24:43,809 [Thread-268] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-12-03 07:24:43,809 [Thread-265] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:24:43,816 [Thread-270] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-12-03 07:24:43,812 [Thread-266] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:24:43,816 [Thread-271] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:24:43,812 [Thread-128] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:43,809 [Thread-267] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:24:43,816 [Thread-172] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:24:43,817 [Thread-172] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:24:43,817 [Thread-172] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:24:43,816 [Thread-269] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:24:43,817 [Thread-273] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-12-03 07:24:43,817 [Thread-272] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-12-03 07:24:43,820 [Thread-172] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:43,821 [Thread-274] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11...
2020-12-03 07:24:43,821 [Thread-275] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12...
2020-12-03 07:24:43,851 [IPC Server handler 2 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:43,852 [Listener at localhost/36976] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:43,852 [Listener at localhost/36976] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:43,868 [Thread-216] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=829214013;bpid=BP-1006108214-172.17.0.5-1606980278566;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=829214013;c=1606980278566;bpid=BP-1006108214-172.17.0.5-1606980278566;dnuuid=null
2020-12-03 07:24:43,927 [Thread-238] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=829214013;bpid=BP-1006108214-172.17.0.5-1606980278566;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=829214013;c=1606980278566;bpid=BP-1006108214-172.17.0.5-1606980278566;dnuuid=null
2020-12-03 07:24:43,927 [Thread-271] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1006108214-172.17.0.5-1606980278566 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 110ms
2020-12-03 07:24:43,927 [Thread-266] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1006108214-172.17.0.5-1606980278566 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 112ms
2020-12-03 07:24:43,941 [Thread-268] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1006108214-172.17.0.5-1606980278566 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 132ms
2020-12-03 07:24:43,954 [Thread-272] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1006108214-172.17.0.5-1606980278566 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 134ms
2020-12-03 07:24:43,964 [IPC Server handler 1 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:43,966 [Listener at localhost/36976] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:43,966 [Listener at localhost/36976] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:43,974 [Thread-273] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1006108214-172.17.0.5-1606980278566 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 154ms
2020-12-03 07:24:43,975 [Thread-128] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1006108214-172.17.0.5-1606980278566: 158ms
2020-12-03 07:24:43,983 [Thread-265] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1006108214-172.17.0.5-1606980278566 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 169ms
2020-12-03 07:24:43,985 [Thread-288] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-12-03 07:24:43,986 [Thread-289] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-12-03 07:24:43,986 [Thread-289] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1006108214-172.17.0.5-1606980278566/current/replicas doesn't exist 
2020-12-03 07:24:43,988 [Thread-275] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1006108214-172.17.0.5-1606980278566 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12: 167ms
2020-12-03 07:24:43,988 [Thread-194] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID d328db1a-8487-4a15-b7e1-b59a97d27898
2020-12-03 07:24:43,986 [Thread-288] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1006108214-172.17.0.5-1606980278566/current/replicas doesn't exist 
2020-12-03 07:24:43,992 [Thread-194] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-ea8236f0-3cb7-4341-b448-d9673239316e
2020-12-03 07:24:43,993 [Thread-194] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, StorageType: DISK
2020-12-03 07:24:43,995 [Thread-194] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-24768886-4de0-4de1-9388-2b4ca3a5077c
2020-12-03 07:24:43,995 [Thread-194] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, StorageType: DISK
2020-12-03 07:24:43,998 [Thread-194] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:24:43,998 [Thread-289] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 11ms
2020-12-03 07:24:44,000 [Thread-270] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1006108214-172.17.0.5-1606980278566 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 184ms
2020-12-03 07:24:44,000 [Thread-194] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:24:44,000 [Thread-150] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1006108214-172.17.0.5-1606980278566: 194ms
2020-12-03 07:24:44,001 [Thread-292] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-12-03 07:24:44,001 [Thread-293] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-12-03 07:24:44,001 [Thread-194] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:24:44,001 [Thread-293] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1006108214-172.17.0.5-1606980278566/current/replicas doesn't exist 
2020-12-03 07:24:44,001 [Thread-292] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1006108214-172.17.0.5-1606980278566/current/replicas doesn't exist 
2020-12-03 07:24:44,001 [Thread-194] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:24:44,002 [Thread-293] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 1ms
2020-12-03 07:24:44,001 [Thread-269] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1006108214-172.17.0.5-1606980278566 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 185ms
2020-12-03 07:24:44,002 [Thread-194] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:24:44,003 [Thread-194] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:44,003 [Thread-292] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 3ms
2020-12-03 07:24:44,004 [Thread-106] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1006108214-172.17.0.5-1606980278566: 198ms
2020-12-03 07:24:44,004 [Thread-150] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1006108214-172.17.0.5-1606980278566: 3ms
2020-12-03 07:24:44,009 [Thread-296] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14...
2020-12-03 07:24:44,011 [Thread-294] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13...
2020-12-03 07:24:44,011 [Thread-264] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1006108214-172.17.0.5-1606980278566 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 205ms
2020-12-03 07:24:44,011 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:24:44,012 [Thread-84] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1006108214-172.17.0.5-1606980278566: 207ms
2020-12-03 07:24:44,013 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-642bfc7c-ff8d-4514-94bd-79381f534ac2): finished scanning block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:44,013 [Thread-267] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1006108214-172.17.0.5-1606980278566 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 196ms
2020-12-03 07:24:44,013 [Thread-274] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1006108214-172.17.0.5-1606980278566 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11: 192ms
2020-12-03 07:24:44,013 [Thread-172] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1006108214-172.17.0.5-1606980278566: 194ms
2020-12-03 07:24:44,014 [Thread-298] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:24:44,014 [Thread-295] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:24:44,014 [Thread-298] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1006108214-172.17.0.5-1606980278566/current/replicas doesn't exist 
2020-12-03 07:24:44,014 [Thread-297] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:24:44,014 [Thread-295] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1006108214-172.17.0.5-1606980278566/current/replicas doesn't exist 
2020-12-03 07:24:44,015 [Thread-297] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1006108214-172.17.0.5-1606980278566/current/replicas doesn't exist 
2020-12-03 07:24:44,015 [Thread-60] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1006108214-172.17.0.5-1606980278566: 209ms
2020-12-03 07:24:44,014 [Thread-288] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 29ms
2020-12-03 07:24:44,016 [Thread-299] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11...
2020-12-03 07:24:44,017 [Thread-298] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 3ms
2020-12-03 07:24:44,017 [Thread-128] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1006108214-172.17.0.5-1606980278566: 40ms
2020-12-03 07:24:44,017 [Thread-295] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 3ms
2020-12-03 07:24:44,017 [Thread-299] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1006108214-172.17.0.5-1606980278566/current/replicas doesn't exist 
2020-12-03 07:24:44,017 [Thread-297] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 2ms
2020-12-03 07:24:44,018 [Thread-301] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12...
2020-12-03 07:24:44,018 [Thread-299] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11: 2ms
2020-12-03 07:24:44,018 [Thread-300] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:24:44,019 [Thread-300] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1006108214-172.17.0.5-1606980278566/current/replicas doesn't exist 
2020-12-03 07:24:44,019 [Thread-301] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1006108214-172.17.0.5-1606980278566/current/replicas doesn't exist 
2020-12-03 07:24:44,019 [Thread-301] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12: 1ms
2020-12-03 07:24:44,033 [Thread-106] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1006108214-172.17.0.5-1606980278566: 29ms
2020-12-03 07:24:44,018 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:24:44,034 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:24:44,034 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-4a4533dc-c0f5-4eba-8ab7-8f9fd4e59ffc): finished scanning block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:44,034 [Thread-300] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 15ms
2020-12-03 07:24:44,034 [Thread-172] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1006108214-172.17.0.5-1606980278566: 21ms
2020-12-03 07:24:44,018 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:24:44,013 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:24:44,060 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-652cfcf7-8574-41cf-86aa-f7d20cbe2811): finished scanning block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:44,060 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-bf7ef67b-e5ab-452a-a984-fbd8e1fd6d82): finished scanning block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:44,059 [Thread-84] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1006108214-172.17.0.5-1606980278566: 48ms
2020-12-03 07:24:44,034 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-bd1ff44c-a092-4057-b4a3-2c31abfa7ab4): finished scanning block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:44,061 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:24:44,061 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:24:44,061 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-0095e818-e243-4a1c-aa13-99da0fd9e056): finished scanning block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:44,061 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-f45a8750-594d-4642-87e3-93d21021bf5a): finished scanning block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:44,062 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:24:44,062 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:24:44,062 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-36579057-efca-436e-8f83-6abab3daf2e6): finished scanning block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:44,062 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-5a11274f-c1da-45a9-aa5e-f76140593ef7): finished scanning block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:44,063 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:24:44,064 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-c003fc79-c50f-47e0-92be-1300d56d1d0d): finished scanning block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:44,064 [Thread-303] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:24:44,064 [Thread-303] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1006108214-172.17.0.5-1606980278566/current/replicas doesn't exist 
2020-12-03 07:24:44,065 [Thread-303] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 1ms
2020-12-03 07:24:44,071 [Thread-310] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:24:44,072 [Thread-310] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1006108214-172.17.0.5-1606980278566/current/replicas doesn't exist 
2020-12-03 07:24:44,072 [Thread-310] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 1ms
2020-12-03 07:24:44,076 [IPC Server handler 5 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:44,077 [Listener at localhost/36976] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:44,077 [Listener at localhost/36976] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:44,079 [Thread-60] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1006108214-172.17.0.5-1606980278566: 63ms
2020-12-03 07:24:44,081 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:24:44,081 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:24:44,081 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-86b77411-628e-439a-83fb-b288094a00ab): finished scanning block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:44,081 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-519a1287-ec06-4bbf-8d21-79dbaca51fcb): finished scanning block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:44,090 [Thread-60] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 12:59 PM with interval of 21600000ms
2020-12-03 07:24:44,093 [Thread-172] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 12:44 PM with interval of 21600000ms
2020-12-03 07:24:44,093 [Thread-150] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 12:42 PM with interval of 21600000ms
2020-12-03 07:24:44,091 [Thread-84] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 8:08 AM with interval of 21600000ms
2020-12-03 07:24:44,095 [Thread-106] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 8:42 AM with interval of 21600000ms
2020-12-03 07:24:44,096 [Thread-128] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 10:13 AM with interval of 21600000ms
2020-12-03 07:24:44,096 [Thread-296] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1006108214-172.17.0.5-1606980278566 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14: 88ms
2020-12-03 07:24:44,099 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-f45a8750-594d-4642-87e3-93d21021bf5a): no suitable block pools found to scan.  Waiting 1814399962 ms.
2020-12-03 07:24:44,099 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-36579057-efca-436e-8f83-6abab3daf2e6): no suitable block pools found to scan.  Waiting 1814399963 ms.
2020-12-03 07:24:44,099 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-5a11274f-c1da-45a9-aa5e-f76140593ef7): no suitable block pools found to scan.  Waiting 1814399963 ms.
2020-12-03 07:24:44,099 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-519a1287-ec06-4bbf-8d21-79dbaca51fcb): no suitable block pools found to scan.  Waiting 1814399981 ms.
2020-12-03 07:24:44,099 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-bf7ef67b-e5ab-452a-a984-fbd8e1fd6d82): no suitable block pools found to scan.  Waiting 1814399912 ms.
2020-12-03 07:24:44,100 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-bd1ff44c-a092-4057-b4a3-2c31abfa7ab4): no suitable block pools found to scan.  Waiting 1814399934 ms.
2020-12-03 07:24:44,100 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-c003fc79-c50f-47e0-92be-1300d56d1d0d): no suitable block pools found to scan.  Waiting 1814399934 ms.
2020-12-03 07:24:44,100 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-652cfcf7-8574-41cf-86aa-f7d20cbe2811): no suitable block pools found to scan.  Waiting 1814399917 ms.
2020-12-03 07:24:44,100 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-4a4533dc-c0f5-4eba-8ab7-8f9fd4e59ffc): no suitable block pools found to scan.  Waiting 1814399917 ms.
2020-12-03 07:24:44,099 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-0095e818-e243-4a1c-aa13-99da0fd9e056): no suitable block pools found to scan.  Waiting 1814399962 ms.
2020-12-03 07:24:44,100 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-642bfc7c-ff8d-4514-94bd-79381f534ac2): no suitable block pools found to scan.  Waiting 1814399911 ms.
2020-12-03 07:24:44,100 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-86b77411-628e-439a-83fb-b288094a00ab): no suitable block pools found to scan.  Waiting 1814399980 ms.
2020-12-03 07:24:44,108 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1006108214-172.17.0.5-1606980278566 (Datanode Uuid 85df5b2e-a97a-41c1-835b-035a6b9b8a7e) service to localhost/127.0.0.1:43954 beginning handshake with NN
2020-12-03 07:24:44,108 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1006108214-172.17.0.5-1606980278566 (Datanode Uuid 65fee986-f2dc-4671-a566-834a8ba38ec2) service to localhost/127.0.0.1:43954 beginning handshake with NN
2020-12-03 07:24:44,109 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1006108214-172.17.0.5-1606980278566 (Datanode Uuid 2a2a30fb-7121-4535-8e69-ccc1d4e70ec3) service to localhost/127.0.0.1:43954 beginning handshake with NN
2020-12-03 07:24:44,110 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1006108214-172.17.0.5-1606980278566 (Datanode Uuid af552311-853c-41f7-a978-1842b97d4d48) service to localhost/127.0.0.1:43954 beginning handshake with NN
2020-12-03 07:24:44,111 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1006108214-172.17.0.5-1606980278566 (Datanode Uuid 9ef29ebf-468b-497a-b175-e15a6fddabac) service to localhost/127.0.0.1:43954 beginning handshake with NN
2020-12-03 07:24:44,112 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1006108214-172.17.0.5-1606980278566 (Datanode Uuid 64ab98d0-afa7-4e91-8bf0-90433700df57) service to localhost/127.0.0.1:43954 beginning handshake with NN
2020-12-03 07:24:44,113 [Thread-294] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1006108214-172.17.0.5-1606980278566 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13: 102ms
2020-12-03 07:24:44,113 [Thread-194] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1006108214-172.17.0.5-1606980278566: 110ms
2020-12-03 07:24:44,113 [Thread-324] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13...
2020-12-03 07:24:44,114 [Thread-324] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1006108214-172.17.0.5-1606980278566/current/replicas doesn't exist 
2020-12-03 07:24:44,114 [Thread-325] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14...
2020-12-03 07:24:44,114 [Thread-325] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1006108214-172.17.0.5-1606980278566/current/replicas doesn't exist 
2020-12-03 07:24:44,114 [Thread-324] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13: 0ms
2020-12-03 07:24:44,114 [Thread-325] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14: 1ms
2020-12-03 07:24:44,115 [Thread-194] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1006108214-172.17.0.5-1606980278566: 2ms
2020-12-03 07:24:44,116 [Thread-194] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 12:45 PM with interval of 21600000ms
2020-12-03 07:24:44,119 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:24:44,119 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1006108214-172.17.0.5-1606980278566 (Datanode Uuid d328db1a-8487-4a15-b7e1-b59a97d27898) service to localhost/127.0.0.1:43954 beginning handshake with NN
2020-12-03 07:24:44,119 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-24768886-4de0-4de1-9388-2b4ca3a5077c): finished scanning block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:44,119 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:24:44,120 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-ea8236f0-3cb7-4341-b448-d9673239316e): finished scanning block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:44,120 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-24768886-4de0-4de1-9388-2b4ca3a5077c): no suitable block pools found to scan.  Waiting 1814399995 ms.
2020-12-03 07:24:44,121 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-ea8236f0-3cb7-4341-b448-d9673239316e): no suitable block pools found to scan.  Waiting 1814399994 ms.
2020-12-03 07:24:44,134 [IPC Server handler 3 on default port 43954] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:44016, datanodeUuid=9ef29ebf-468b-497a-b175-e15a6fddabac, infoPort=43514, infoSecurePort=0, ipcPort=45669, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566) storage 9ef29ebf-468b-497a-b175-e15a6fddabac
2020-12-03 07:24:44,136 [IPC Server handler 3 on default port 43954] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:44016
2020-12-03 07:24:44,136 [IPC Server handler 3 on default port 43954] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 9ef29ebf-468b-497a-b175-e15a6fddabac (127.0.0.1:44016).
2020-12-03 07:24:44,138 [IPC Server handler 8 on default port 43954] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:43823, datanodeUuid=d328db1a-8487-4a15-b7e1-b59a97d27898, infoPort=37174, infoSecurePort=0, ipcPort=35038, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566) storage d328db1a-8487-4a15-b7e1-b59a97d27898
2020-12-03 07:24:44,138 [IPC Server handler 8 on default port 43954] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:43823
2020-12-03 07:24:44,139 [IPC Server handler 8 on default port 43954] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN d328db1a-8487-4a15-b7e1-b59a97d27898 (127.0.0.1:43823).
2020-12-03 07:24:44,139 [IPC Server handler 6 on default port 43954] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:44848, datanodeUuid=64ab98d0-afa7-4e91-8bf0-90433700df57, infoPort=35422, infoSecurePort=0, ipcPort=41618, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566) storage 64ab98d0-afa7-4e91-8bf0-90433700df57
2020-12-03 07:24:44,140 [IPC Server handler 6 on default port 43954] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:44848
2020-12-03 07:24:44,140 [IPC Server handler 6 on default port 43954] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 64ab98d0-afa7-4e91-8bf0-90433700df57 (127.0.0.1:44848).
2020-12-03 07:24:44,140 [IPC Server handler 7 on default port 43954] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:46279, datanodeUuid=85df5b2e-a97a-41c1-835b-035a6b9b8a7e, infoPort=36012, infoSecurePort=0, ipcPort=42918, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566) storage 85df5b2e-a97a-41c1-835b-035a6b9b8a7e
2020-12-03 07:24:44,140 [IPC Server handler 7 on default port 43954] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:46279
2020-12-03 07:24:44,141 [IPC Server handler 7 on default port 43954] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 85df5b2e-a97a-41c1-835b-035a6b9b8a7e (127.0.0.1:46279).
2020-12-03 07:24:44,142 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1006108214-172.17.0.5-1606980278566 (Datanode Uuid 9ef29ebf-468b-497a-b175-e15a6fddabac) service to localhost/127.0.0.1:43954 successfully registered with NN
2020-12-03 07:24:44,142 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1006108214-172.17.0.5-1606980278566 (Datanode Uuid d328db1a-8487-4a15-b7e1-b59a97d27898) service to localhost/127.0.0.1:43954 successfully registered with NN
2020-12-03 07:24:44,142 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:43954 using BLOCKREPORT_INTERVAL of 100msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:24:44,142 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:43954 using BLOCKREPORT_INTERVAL of 100msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:24:44,142 [IPC Server handler 4 on default port 43954] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:33258, datanodeUuid=2a2a30fb-7121-4535-8e69-ccc1d4e70ec3, infoPort=44157, infoSecurePort=0, ipcPort=33152, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566) storage 2a2a30fb-7121-4535-8e69-ccc1d4e70ec3
2020-12-03 07:24:44,143 [IPC Server handler 4 on default port 43954] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:33258
2020-12-03 07:24:44,143 [IPC Server handler 4 on default port 43954] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 2a2a30fb-7121-4535-8e69-ccc1d4e70ec3 (127.0.0.1:33258).
2020-12-03 07:24:44,143 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1006108214-172.17.0.5-1606980278566 (Datanode Uuid 85df5b2e-a97a-41c1-835b-035a6b9b8a7e) service to localhost/127.0.0.1:43954 successfully registered with NN
2020-12-03 07:24:44,143 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:43954 using BLOCKREPORT_INTERVAL of 100msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:24:44,144 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1006108214-172.17.0.5-1606980278566 (Datanode Uuid 2a2a30fb-7121-4535-8e69-ccc1d4e70ec3) service to localhost/127.0.0.1:43954 successfully registered with NN
2020-12-03 07:24:44,144 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:43954 using BLOCKREPORT_INTERVAL of 100msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:24:44,142 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1006108214-172.17.0.5-1606980278566 (Datanode Uuid 64ab98d0-afa7-4e91-8bf0-90433700df57) service to localhost/127.0.0.1:43954 successfully registered with NN
2020-12-03 07:24:44,143 [IPC Server handler 9 on default port 43954] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:37088, datanodeUuid=65fee986-f2dc-4671-a566-834a8ba38ec2, infoPort=42001, infoSecurePort=0, ipcPort=38029, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566) storage 65fee986-f2dc-4671-a566-834a8ba38ec2
2020-12-03 07:24:44,145 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:43954 using BLOCKREPORT_INTERVAL of 100msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:24:44,145 [IPC Server handler 9 on default port 43954] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:37088
2020-12-03 07:24:44,145 [IPC Server handler 9 on default port 43954] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 65fee986-f2dc-4671-a566-834a8ba38ec2 (127.0.0.1:37088).
2020-12-03 07:24:44,147 [IPC Server handler 0 on default port 43954] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:36036, datanodeUuid=af552311-853c-41f7-a978-1842b97d4d48, infoPort=39431, infoSecurePort=0, ipcPort=38222, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566) storage af552311-853c-41f7-a978-1842b97d4d48
2020-12-03 07:24:44,148 [IPC Server handler 0 on default port 43954] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36036
2020-12-03 07:24:44,148 [IPC Server handler 0 on default port 43954] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN af552311-853c-41f7-a978-1842b97d4d48 (127.0.0.1:36036).
2020-12-03 07:24:44,148 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1006108214-172.17.0.5-1606980278566 (Datanode Uuid 65fee986-f2dc-4671-a566-834a8ba38ec2) service to localhost/127.0.0.1:43954 successfully registered with NN
2020-12-03 07:24:44,148 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:43954 using BLOCKREPORT_INTERVAL of 100msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:24:44,149 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1006108214-172.17.0.5-1606980278566 (Datanode Uuid af552311-853c-41f7-a978-1842b97d4d48) service to localhost/127.0.0.1:43954 successfully registered with NN
2020-12-03 07:24:44,149 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:43954 using BLOCKREPORT_INTERVAL of 100msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:24:44,151 [Thread-216] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 881212a7-8d98-4a8f-86c4-1a8a1d6599a6
2020-12-03 07:24:44,154 [Thread-216] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-bda183c3-643a-4595-8903-8df17740c647
2020-12-03 07:24:44,154 [Thread-216] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, StorageType: DISK
2020-12-03 07:24:44,161 [Thread-216] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-fd75e4f2-39b3-4d3a-864b-ad2d2be6069e
2020-12-03 07:24:44,162 [Thread-216] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, StorageType: DISK
2020-12-03 07:24:44,164 [Thread-216] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:24:44,169 [Thread-216] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:24:44,169 [IPC Server handler 1 on default port 43954] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-5a11274f-c1da-45a9-aa5e-f76140593ef7 for DN 127.0.0.1:33258
2020-12-03 07:24:44,170 [Thread-216] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:24:44,170 [Thread-216] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:24:44,170 [IPC Server handler 1 on default port 43954] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-36579057-efca-436e-8f83-6abab3daf2e6 for DN 127.0.0.1:33258
2020-12-03 07:24:44,170 [Thread-216] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:24:44,171 [Thread-216] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:44,171 [IPC Server handler 7 on default port 43954] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-ea8236f0-3cb7-4341-b448-d9673239316e for DN 127.0.0.1:43823
2020-12-03 07:24:44,173 [IPC Server handler 7 on default port 43954] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-24768886-4de0-4de1-9388-2b4ca3a5077c for DN 127.0.0.1:43823
2020-12-03 07:24:44,173 [Thread-331] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15...
2020-12-03 07:24:44,173 [Thread-332] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16...
2020-12-03 07:24:44,173 [IPC Server handler 6 on default port 43954] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-642bfc7c-ff8d-4514-94bd-79381f534ac2 for DN 127.0.0.1:44848
2020-12-03 07:24:44,173 [IPC Server handler 6 on default port 43954] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-bf7ef67b-e5ab-452a-a984-fbd8e1fd6d82 for DN 127.0.0.1:44848
2020-12-03 07:24:44,174 [IPC Server handler 3 on default port 43954] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-86b77411-628e-439a-83fb-b288094a00ab for DN 127.0.0.1:37088
2020-12-03 07:24:44,174 [IPC Server handler 3 on default port 43954] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-519a1287-ec06-4bbf-8d21-79dbaca51fcb for DN 127.0.0.1:37088
2020-12-03 07:24:44,175 [IPC Server handler 8 on default port 43954] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-4a4533dc-c0f5-4eba-8ab7-8f9fd4e59ffc for DN 127.0.0.1:44016
2020-12-03 07:24:44,175 [IPC Server handler 8 on default port 43954] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-652cfcf7-8574-41cf-86aa-f7d20cbe2811 for DN 127.0.0.1:44016
2020-12-03 07:24:44,176 [IPC Server handler 5 on default port 43954] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-0095e818-e243-4a1c-aa13-99da0fd9e056 for DN 127.0.0.1:36036
2020-12-03 07:24:44,176 [IPC Server handler 5 on default port 43954] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-f45a8750-594d-4642-87e3-93d21021bf5a for DN 127.0.0.1:36036
2020-12-03 07:24:44,177 [IPC Server handler 2 on default port 43954] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c003fc79-c50f-47e0-92be-1300d56d1d0d for DN 127.0.0.1:46279
2020-12-03 07:24:44,177 [IPC Server handler 2 on default port 43954] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-bd1ff44c-a092-4057-b4a3-2c31abfa7ab4 for DN 127.0.0.1:46279
2020-12-03 07:24:44,182 [IPC Server handler 4 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:44,190 [Listener at localhost/36976] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:44,191 [Listener at localhost/36976] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:44,208 [Thread-331] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1006108214-172.17.0.5-1606980278566 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15: 35ms
2020-12-03 07:24:44,209 [Thread-332] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1006108214-172.17.0.5-1606980278566 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16: 36ms
2020-12-03 07:24:44,209 [Thread-216] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1006108214-172.17.0.5-1606980278566: 37ms
2020-12-03 07:24:44,210 [Thread-335] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15...
2020-12-03 07:24:44,210 [Thread-336] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16...
2020-12-03 07:24:44,210 [Thread-335] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1006108214-172.17.0.5-1606980278566/current/replicas doesn't exist 
2020-12-03 07:24:44,210 [Thread-336] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1006108214-172.17.0.5-1606980278566/current/replicas doesn't exist 
2020-12-03 07:24:44,210 [Thread-335] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15: 0ms
2020-12-03 07:24:44,210 [Thread-336] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16: 1ms
2020-12-03 07:24:44,210 [Thread-216] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1006108214-172.17.0.5-1606980278566: 1ms
2020-12-03 07:24:44,211 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:24:44,211 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:24:44,211 [Thread-216] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 12:51 PM with interval of 21600000ms
2020-12-03 07:24:44,211 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-bda183c3-643a-4595-8903-8df17740c647): finished scanning block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:44,211 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-fd75e4f2-39b3-4d3a-864b-ad2d2be6069e): finished scanning block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:44,215 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1006108214-172.17.0.5-1606980278566 (Datanode Uuid 881212a7-8d98-4a8f-86c4-1a8a1d6599a6) service to localhost/127.0.0.1:43954 beginning handshake with NN
2020-12-03 07:24:44,215 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-fd75e4f2-39b3-4d3a-864b-ad2d2be6069e): no suitable block pools found to scan.  Waiting 1814399996 ms.
2020-12-03 07:24:44,216 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-bda183c3-643a-4595-8903-8df17740c647): no suitable block pools found to scan.  Waiting 1814399996 ms.
2020-12-03 07:24:44,224 [IPC Server handler 9 on default port 43954] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:38762, datanodeUuid=881212a7-8d98-4a8f-86c4-1a8a1d6599a6, infoPort=44750, infoSecurePort=0, ipcPort=33323, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566) storage 881212a7-8d98-4a8f-86c4-1a8a1d6599a6
2020-12-03 07:24:44,228 [IPC Server handler 9 on default port 43954] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38762
2020-12-03 07:24:44,229 [IPC Server handler 9 on default port 43954] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 881212a7-8d98-4a8f-86c4-1a8a1d6599a6 (127.0.0.1:38762).
2020-12-03 07:24:44,234 [Thread-238] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 2e7687d0-5262-40f4-b8e8-9f72db15646f
2020-12-03 07:24:44,234 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x3eb32648cd63f3bd: Processing first storage report for DS-36579057-efca-436e-8f83-6abab3daf2e6 from datanode 2a2a30fb-7121-4535-8e69-ccc1d4e70ec3
2020-12-03 07:24:44,234 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1006108214-172.17.0.5-1606980278566 (Datanode Uuid 881212a7-8d98-4a8f-86c4-1a8a1d6599a6) service to localhost/127.0.0.1:43954 successfully registered with NN
2020-12-03 07:24:44,235 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:43954 using BLOCKREPORT_INTERVAL of 100msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:24:44,237 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x3eb32648cd63f3bd: from storage DS-36579057-efca-436e-8f83-6abab3daf2e6 node DatanodeRegistration(127.0.0.1:33258, datanodeUuid=2a2a30fb-7121-4535-8e69-ccc1d4e70ec3, infoPort=44157, infoSecurePort=0, ipcPort=33152, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566), blocks: 0, hasStaleStorage: true, processing time: 3 msecs, invalidatedBlocks: 0
2020-12-03 07:24:44,237 [Thread-238] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-fee6374f-fab9-484b-840a-3bb039765f1d
2020-12-03 07:24:44,237 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xabbc48f9ff00e2cd: Processing first storage report for DS-24768886-4de0-4de1-9388-2b4ca3a5077c from datanode d328db1a-8487-4a15-b7e1-b59a97d27898
2020-12-03 07:24:44,237 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xabbc48f9ff00e2cd: from storage DS-24768886-4de0-4de1-9388-2b4ca3a5077c node DatanodeRegistration(127.0.0.1:43823, datanodeUuid=d328db1a-8487-4a15-b7e1-b59a97d27898, infoPort=37174, infoSecurePort=0, ipcPort=35038, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:24:44,238 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x995774e22c85dd8b: Processing first storage report for DS-519a1287-ec06-4bbf-8d21-79dbaca51fcb from datanode 65fee986-f2dc-4671-a566-834a8ba38ec2
2020-12-03 07:24:44,237 [Thread-238] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, StorageType: DISK
2020-12-03 07:24:44,239 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x995774e22c85dd8b: from storage DS-519a1287-ec06-4bbf-8d21-79dbaca51fcb node DatanodeRegistration(127.0.0.1:37088, datanodeUuid=65fee986-f2dc-4671-a566-834a8ba38ec2, infoPort=42001, infoSecurePort=0, ipcPort=38029, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566), blocks: 0, hasStaleStorage: true, processing time: 2 msecs, invalidatedBlocks: 0
2020-12-03 07:24:44,240 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xabbc48f9ff00e2cd: Processing first storage report for DS-ea8236f0-3cb7-4341-b448-d9673239316e from datanode d328db1a-8487-4a15-b7e1-b59a97d27898
2020-12-03 07:24:44,240 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xabbc48f9ff00e2cd: from storage DS-ea8236f0-3cb7-4341-b448-d9673239316e node DatanodeRegistration(127.0.0.1:43823, datanodeUuid=d328db1a-8487-4a15-b7e1-b59a97d27898, infoPort=37174, infoSecurePort=0, ipcPort=35038, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:44,240 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x995774e22c85dd8b: Processing first storage report for DS-86b77411-628e-439a-83fb-b288094a00ab from datanode 65fee986-f2dc-4671-a566-834a8ba38ec2
2020-12-03 07:24:44,240 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x995774e22c85dd8b: from storage DS-86b77411-628e-439a-83fb-b288094a00ab node DatanodeRegistration(127.0.0.1:37088, datanodeUuid=65fee986-f2dc-4671-a566-834a8ba38ec2, infoPort=42001, infoSecurePort=0, ipcPort=38029, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:44,241 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xccc2ff1dfae1d7d2: Processing first storage report for DS-4a4533dc-c0f5-4eba-8ab7-8f9fd4e59ffc from datanode 9ef29ebf-468b-497a-b175-e15a6fddabac
2020-12-03 07:24:44,241 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xccc2ff1dfae1d7d2: from storage DS-4a4533dc-c0f5-4eba-8ab7-8f9fd4e59ffc node DatanodeRegistration(127.0.0.1:44016, datanodeUuid=9ef29ebf-468b-497a-b175-e15a6fddabac, infoPort=43514, infoSecurePort=0, ipcPort=45669, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:44,241 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x1cfb67fca09bb846: Processing first storage report for DS-f45a8750-594d-4642-87e3-93d21021bf5a from datanode af552311-853c-41f7-a978-1842b97d4d48
2020-12-03 07:24:44,241 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x1cfb67fca09bb846: from storage DS-f45a8750-594d-4642-87e3-93d21021bf5a node DatanodeRegistration(127.0.0.1:36036, datanodeUuid=af552311-853c-41f7-a978-1842b97d4d48, infoPort=39431, infoSecurePort=0, ipcPort=38222, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:24:44,242 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x74dc073052238db1: Processing first storage report for DS-642bfc7c-ff8d-4514-94bd-79381f534ac2 from datanode 64ab98d0-afa7-4e91-8bf0-90433700df57
2020-12-03 07:24:44,242 [Thread-238] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-4f8bde89-39bc-4664-8495-24db1fc9070c
2020-12-03 07:24:44,244 [Thread-238] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, StorageType: DISK
2020-12-03 07:24:44,244 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x74dc073052238db1: from storage DS-642bfc7c-ff8d-4514-94bd-79381f534ac2 node DatanodeRegistration(127.0.0.1:44848, datanodeUuid=64ab98d0-afa7-4e91-8bf0-90433700df57, infoPort=35422, infoSecurePort=0, ipcPort=41618, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566), blocks: 0, hasStaleStorage: true, processing time: 2 msecs, invalidatedBlocks: 0
2020-12-03 07:24:44,245 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xccc2ff1dfae1d7d2: Processing first storage report for DS-652cfcf7-8574-41cf-86aa-f7d20cbe2811 from datanode 9ef29ebf-468b-497a-b175-e15a6fddabac
2020-12-03 07:24:44,245 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xccc2ff1dfae1d7d2: from storage DS-652cfcf7-8574-41cf-86aa-f7d20cbe2811 node DatanodeRegistration(127.0.0.1:44016, datanodeUuid=9ef29ebf-468b-497a-b175-e15a6fddabac, infoPort=43514, infoSecurePort=0, ipcPort=45669, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:44,245 [Thread-238] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:24:44,245 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x1cfb67fca09bb846: Processing first storage report for DS-0095e818-e243-4a1c-aa13-99da0fd9e056 from datanode af552311-853c-41f7-a978-1842b97d4d48
2020-12-03 07:24:44,245 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x1cfb67fca09bb846: from storage DS-0095e818-e243-4a1c-aa13-99da0fd9e056 node DatanodeRegistration(127.0.0.1:36036, datanodeUuid=af552311-853c-41f7-a978-1842b97d4d48, infoPort=39431, infoSecurePort=0, ipcPort=38222, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:44,246 [IPC Server handler 6 on default port 43954] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-bda183c3-643a-4595-8903-8df17740c647 for DN 127.0.0.1:38762
2020-12-03 07:24:44,246 [IPC Server handler 6 on default port 43954] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-fd75e4f2-39b3-4d3a-864b-ad2d2be6069e for DN 127.0.0.1:38762
2020-12-03 07:24:44,247 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x3eb32648cd63f3bd: Processing first storage report for DS-5a11274f-c1da-45a9-aa5e-f76140593ef7 from datanode 2a2a30fb-7121-4535-8e69-ccc1d4e70ec3
2020-12-03 07:24:44,247 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x3eb32648cd63f3bd: from storage DS-5a11274f-c1da-45a9-aa5e-f76140593ef7 node DatanodeRegistration(127.0.0.1:33258, datanodeUuid=2a2a30fb-7121-4535-8e69-ccc1d4e70ec3, infoPort=44157, infoSecurePort=0, ipcPort=33152, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:44,247 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x74dc073052238db1: Processing first storage report for DS-bf7ef67b-e5ab-452a-a984-fbd8e1fd6d82 from datanode 64ab98d0-afa7-4e91-8bf0-90433700df57
2020-12-03 07:24:44,249 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x74dc073052238db1: from storage DS-bf7ef67b-e5ab-452a-a984-fbd8e1fd6d82 node DatanodeRegistration(127.0.0.1:44848, datanodeUuid=64ab98d0-afa7-4e91-8bf0-90433700df57, infoPort=35422, infoSecurePort=0, ipcPort=41618, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:24:44,249 [Thread-238] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:24:44,251 [Thread-238] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:24:44,251 [Thread-238] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:24:44,251 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x4a3d4bc9109bba17: Processing first storage report for DS-bda183c3-643a-4595-8903-8df17740c647 from datanode 881212a7-8d98-4a8f-86c4-1a8a1d6599a6
2020-12-03 07:24:44,251 [Thread-238] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:24:44,251 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x4a3d4bc9109bba17: from storage DS-bda183c3-643a-4595-8903-8df17740c647 node DatanodeRegistration(127.0.0.1:38762, datanodeUuid=881212a7-8d98-4a8f-86c4-1a8a1d6599a6, infoPort=44750, infoSecurePort=0, ipcPort=33323, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:44,251 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x4a3d4bc9109bba17: Processing first storage report for DS-fd75e4f2-39b3-4d3a-864b-ad2d2be6069e from datanode 881212a7-8d98-4a8f-86c4-1a8a1d6599a6
2020-12-03 07:24:44,252 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x4a3d4bc9109bba17: from storage DS-fd75e4f2-39b3-4d3a-864b-ad2d2be6069e node DatanodeRegistration(127.0.0.1:38762, datanodeUuid=881212a7-8d98-4a8f-86c4-1a8a1d6599a6, infoPort=44750, infoSecurePort=0, ipcPort=33323, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:44,251 [Thread-238] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:44,252 [Thread-342] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17...
2020-12-03 07:24:44,252 [Thread-343] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18...
2020-12-03 07:24:44,285 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x1cfb67fca09bb846,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 10 msec to generate and 81 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:44,285 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x995774e22c85dd8b,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 9 msec to generate and 81 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:44,286 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:44,285 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x3eb32648cd63f3bd,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 10 msec to generate and 82 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:44,285 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xccc2ff1dfae1d7d2,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 3 msec to generate and 81 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:44,285 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x4a3d4bc9109bba17,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 35 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:44,285 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x74dc073052238db1,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 81 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:44,291 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:44,291 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:44,287 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xabbc48f9ff00e2cd,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 6 msec to generate and 83 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:44,286 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:44,286 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:44,291 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:44,291 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:44,296 [Thread-342] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1006108214-172.17.0.5-1606980278566 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17: 43ms
2020-12-03 07:24:44,299 [Thread-343] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1006108214-172.17.0.5-1606980278566 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18: 46ms
2020-12-03 07:24:44,299 [Thread-238] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1006108214-172.17.0.5-1606980278566: 48ms
2020-12-03 07:24:44,300 [Thread-346] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17...
2020-12-03 07:24:44,316 [Thread-347] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18...
2020-12-03 07:24:44,316 [Thread-346] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1006108214-172.17.0.5-1606980278566/current/replicas doesn't exist 
2020-12-03 07:24:44,316 [Thread-347] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1006108214-172.17.0.5-1606980278566/current/replicas doesn't exist 
2020-12-03 07:24:44,316 [Thread-346] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17: 0ms
2020-12-03 07:24:44,316 [Thread-347] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18: 1ms
2020-12-03 07:24:44,319 [Thread-238] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1006108214-172.17.0.5-1606980278566: 20ms
2020-12-03 07:24:44,320 [IPC Server handler 2 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:44,320 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:24:44,321 [Thread-238] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 12:45 PM with interval of 21600000ms
2020-12-03 07:24:44,321 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:24:44,321 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-4f8bde89-39bc-4664-8495-24db1fc9070c): finished scanning block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:44,321 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-fee6374f-fab9-484b-840a-3bb039765f1d): finished scanning block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:44,323 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1006108214-172.17.0.5-1606980278566 (Datanode Uuid 2e7687d0-5262-40f4-b8e8-9f72db15646f) service to localhost/127.0.0.1:43954 beginning handshake with NN
2020-12-03 07:24:44,323 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-4f8bde89-39bc-4664-8495-24db1fc9070c): no suitable block pools found to scan.  Waiting 1814399997 ms.
2020-12-03 07:24:44,326 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-fee6374f-fab9-484b-840a-3bb039765f1d): no suitable block pools found to scan.  Waiting 1814399994 ms.
2020-12-03 07:24:44,326 [Listener at localhost/36976] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:44,326 [Listener at localhost/36976] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:44,329 [IPC Server handler 9 on default port 43954] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:32788, datanodeUuid=2e7687d0-5262-40f4-b8e8-9f72db15646f, infoPort=38114, infoSecurePort=0, ipcPort=36976, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566) storage 2e7687d0-5262-40f4-b8e8-9f72db15646f
2020-12-03 07:24:44,329 [IPC Server handler 9 on default port 43954] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:32788
2020-12-03 07:24:44,330 [IPC Server handler 9 on default port 43954] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 2e7687d0-5262-40f4-b8e8-9f72db15646f (127.0.0.1:32788).
2020-12-03 07:24:44,331 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1006108214-172.17.0.5-1606980278566 (Datanode Uuid 2e7687d0-5262-40f4-b8e8-9f72db15646f) service to localhost/127.0.0.1:43954 successfully registered with NN
2020-12-03 07:24:44,331 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:43954 using BLOCKREPORT_INTERVAL of 100msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:24:44,336 [IPC Server handler 6 on default port 43954] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-fee6374f-fab9-484b-840a-3bb039765f1d for DN 127.0.0.1:32788
2020-12-03 07:24:44,336 [IPC Server handler 6 on default port 43954] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-4f8bde89-39bc-4664-8495-24db1fc9070c for DN 127.0.0.1:32788
2020-12-03 07:24:44,343 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x68abec6dcf38a8ec: Processing first storage report for DS-fee6374f-fab9-484b-840a-3bb039765f1d from datanode 2e7687d0-5262-40f4-b8e8-9f72db15646f
2020-12-03 07:24:44,343 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x68abec6dcf38a8ec: from storage DS-fee6374f-fab9-484b-840a-3bb039765f1d node DatanodeRegistration(127.0.0.1:32788, datanodeUuid=2e7687d0-5262-40f4-b8e8-9f72db15646f, infoPort=38114, infoSecurePort=0, ipcPort=36976, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:44,343 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x68abec6dcf38a8ec: Processing first storage report for DS-4f8bde89-39bc-4664-8495-24db1fc9070c from datanode 2e7687d0-5262-40f4-b8e8-9f72db15646f
2020-12-03 07:24:44,343 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x68abec6dcf38a8ec: from storage DS-4f8bde89-39bc-4664-8495-24db1fc9070c node DatanodeRegistration(127.0.0.1:32788, datanodeUuid=2e7687d0-5262-40f4-b8e8-9f72db15646f, infoPort=38114, infoSecurePort=0, ipcPort=36976, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:24:44,344 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x68abec6dcf38a8ec,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 7 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:44,345 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:44,428 [IPC Server handler 3 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:44,431 [Listener at localhost/36976] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:24:44,447 [IPC Server handler 4 on default port 43954] INFO  namenode.ErasureCodingPolicyManager (ErasureCodingPolicyManager.java:enablePolicy(429)) - Enable the erasure coding policy RS-LEGACY-6-3-1024k
2020-12-03 07:24:44,449 [IPC Server handler 4 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=enableErasureCodingPolicy	src=RS-LEGACY-6-3-1024k	dst=null	perm=null	proto=rpc
2020-12-03 07:24:44,470 [IPC Server handler 8 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setErasureCodingPolicy	src=/	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:24:44,478 [IPC Server handler 0 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:44,480 [Listener at localhost/36976] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:24:44,505 [IPC Server handler 1 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/testStripedFile_1048576	dst=null	perm=null	proto=rpc
2020-12-03 07:24:44,547 [IPC Server handler 5 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/testStripedFile_1048576	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:24:44,636 [IPC Server handler 2 on default port 43954] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_-9223372036854775792_1001, replicas=127.0.0.1:33258, 127.0.0.1:38762, 127.0.0.1:46279, 127.0.0.1:37088, 127.0.0.1:43823, 127.0.0.1:44848, 127.0.0.1:32788, 127.0.0.1:44016, 127.0.0.1:36036 for /testStripedFile_1048576
2020-12-03 07:24:44,671 [Thread-351] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:44,735 [DataXceiver for client DFSClient_NONMAPREDUCE_2100203935_24 at /127.0.0.1:50186 [Receiving block BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775792_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775792_1001 src: /127.0.0.1:50186 dest: /127.0.0.1:33258
2020-12-03 07:24:44,987 [Thread-357] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:45,005 [DataXceiver for client DFSClient_NONMAPREDUCE_2100203935_24 at /127.0.0.1:52846 [Receiving block BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775786_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775786_1001 src: /127.0.0.1:52846 dest: /127.0.0.1:32788
2020-12-03 07:24:45,034 [Thread-358] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:45,035 [DataXceiver for client DFSClient_NONMAPREDUCE_2100203935_24 at /127.0.0.1:36104 [Receiving block BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775785_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775785_1001 src: /127.0.0.1:36104 dest: /127.0.0.1:44016
2020-12-03 07:24:45,051 [Thread-359] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:45,053 [DataXceiver for client DFSClient_NONMAPREDUCE_2100203935_24 at /127.0.0.1:52364 [Receiving block BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775784_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775784_1001 src: /127.0.0.1:52364 dest: /127.0.0.1:36036
2020-12-03 07:24:45,072 [PacketResponder: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775792_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:50186, dest: /127.0.0.1:33258, bytes: 1048576, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2100203935_24, offset: 0, srvID: 2a2a30fb-7121-4535-8e69-ccc1d4e70ec3, blockid: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775792_1001, duration(ns): 291124824
2020-12-03 07:24:45,073 [PacketResponder: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775792_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775792_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:45,077 [PacketResponder: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775786_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:52846, dest: /127.0.0.1:32788, bytes: 1048576, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2100203935_24, offset: 0, srvID: 2e7687d0-5262-40f4-b8e8-9f72db15646f, blockid: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775786_1001, duration(ns): 67315001
2020-12-03 07:24:45,078 [PacketResponder: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775786_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775786_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:45,081 [PacketResponder: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775785_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:36104, dest: /127.0.0.1:44016, bytes: 1048576, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2100203935_24, offset: 0, srvID: 9ef29ebf-468b-497a-b175-e15a6fddabac, blockid: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775785_1001, duration(ns): 42464440
2020-12-03 07:24:45,081 [PacketResponder: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775785_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775785_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:45,084 [PacketResponder: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775784_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:52364, dest: /127.0.0.1:36036, bytes: 1048576, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2100203935_24, offset: 0, srvID: af552311-853c-41f7-a978-1842b97d4d48, blockid: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775784_1001, duration(ns): 25125881
2020-12-03 07:24:45,085 [PacketResponder: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775784_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775784_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:45,097 [IPC Server handler 8 on default port 43954] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2995)) - BLOCK* blk_-9223372036854775792_1001 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /testStripedFile_1048576
2020-12-03 07:24:45,503 [IPC Server handler 1 on default port 43954] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /testStripedFile_1048576 is closed by DFSClient_NONMAPREDUCE_2100203935_24
2020-12-03 07:24:45,582 [IPC Server handler 2 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/testStripedFile_25165824	dst=null	perm=null	proto=rpc
2020-12-03 07:24:45,585 [IPC Server handler 9 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/testStripedFile_25165824	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:24:45,622 [IPC Server handler 6 on default port 43954] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_-9223372036854775776_1002, replicas=127.0.0.1:43823, 127.0.0.1:44016, 127.0.0.1:36036, 127.0.0.1:44848, 127.0.0.1:37088, 127.0.0.1:46279, 127.0.0.1:32788, 127.0.0.1:33258, 127.0.0.1:38762 for /testStripedFile_25165824
2020-12-03 07:24:45,628 [Thread-373] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:45,629 [DataXceiver for client DFSClient_NONMAPREDUCE_2100203935_24 at /127.0.0.1:53460 [Receiving block BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775776_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775776_1002 src: /127.0.0.1:53460 dest: /127.0.0.1:43823
2020-12-03 07:24:45,637 [Thread-374] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:45,638 [DataXceiver for client DFSClient_NONMAPREDUCE_2100203935_24 at /127.0.0.1:36110 [Receiving block BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775775_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775775_1002 src: /127.0.0.1:36110 dest: /127.0.0.1:44016
2020-12-03 07:24:45,642 [Thread-375] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:45,646 [DataXceiver for client DFSClient_NONMAPREDUCE_2100203935_24 at /127.0.0.1:52370 [Receiving block BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775774_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775774_1002 src: /127.0.0.1:52370 dest: /127.0.0.1:36036
2020-12-03 07:24:45,650 [Thread-376] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:45,653 [DataXceiver for client DFSClient_NONMAPREDUCE_2100203935_24 at /127.0.0.1:54842 [Receiving block BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775773_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775773_1002 src: /127.0.0.1:54842 dest: /127.0.0.1:44848
2020-12-03 07:24:45,662 [Thread-377] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:45,664 [DataXceiver for client DFSClient_NONMAPREDUCE_2100203935_24 at /127.0.0.1:51596 [Receiving block BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775772_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775772_1002 src: /127.0.0.1:51596 dest: /127.0.0.1:37088
2020-12-03 07:24:45,671 [Thread-378] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:45,673 [DataXceiver for client DFSClient_NONMAPREDUCE_2100203935_24 at /127.0.0.1:55070 [Receiving block BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775771_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775771_1002 src: /127.0.0.1:55070 dest: /127.0.0.1:46279
2020-12-03 07:24:45,792 [Thread-379] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:45,796 [DataXceiver for client DFSClient_NONMAPREDUCE_2100203935_24 at /127.0.0.1:52866 [Receiving block BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775770_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775770_1002 src: /127.0.0.1:52866 dest: /127.0.0.1:32788
2020-12-03 07:24:45,807 [Thread-380] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:45,809 [DataXceiver for client DFSClient_NONMAPREDUCE_2100203935_24 at /127.0.0.1:50210 [Receiving block BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775769_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775769_1002 src: /127.0.0.1:50210 dest: /127.0.0.1:33258
2020-12-03 07:24:45,816 [Thread-381] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:45,832 [DataXceiver for client DFSClient_NONMAPREDUCE_2100203935_24 at /127.0.0.1:33396 [Receiving block BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775768_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775768_1002 src: /127.0.0.1:33396 dest: /127.0.0.1:38762
2020-12-03 07:24:46,030 [PacketResponder: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775775_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:36110, dest: /127.0.0.1:44016, bytes: 2097152, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2100203935_24, offset: 0, srvID: 9ef29ebf-468b-497a-b175-e15a6fddabac, blockid: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775775_1002, duration(ns): 384300480
2020-12-03 07:24:46,032 [PacketResponder: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775773_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54842, dest: /127.0.0.1:44848, bytes: 2097152, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2100203935_24, offset: 0, srvID: 64ab98d0-afa7-4e91-8bf0-90433700df57, blockid: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775773_1002, duration(ns): 371865073
2020-12-03 07:24:46,032 [PacketResponder: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775775_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775775_1002, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:46,033 [PacketResponder: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775773_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775773_1002, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:46,031 [PacketResponder: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775774_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:52370, dest: /127.0.0.1:36036, bytes: 2097152, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2100203935_24, offset: 0, srvID: af552311-853c-41f7-a978-1842b97d4d48, blockid: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775774_1002, duration(ns): 378881010
2020-12-03 07:24:46,030 [PacketResponder: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775776_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:53460, dest: /127.0.0.1:43823, bytes: 2097152, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2100203935_24, offset: 0, srvID: d328db1a-8487-4a15-b7e1-b59a97d27898, blockid: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775776_1002, duration(ns): 394508320
2020-12-03 07:24:46,030 [PacketResponder: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775770_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:52866, dest: /127.0.0.1:32788, bytes: 2097152, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2100203935_24, offset: 0, srvID: 2e7687d0-5262-40f4-b8e8-9f72db15646f, blockid: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775770_1002, duration(ns): 223904992
2020-12-03 07:24:46,035 [PacketResponder: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775774_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775774_1002, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:46,039 [PacketResponder: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775770_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775770_1002, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:46,039 [PacketResponder: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775776_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775776_1002, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:46,041 [PacketResponder: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775771_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55070, dest: /127.0.0.1:46279, bytes: 2097152, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2100203935_24, offset: 0, srvID: 85df5b2e-a97a-41c1-835b-035a6b9b8a7e, blockid: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775771_1002, duration(ns): 358539680
2020-12-03 07:24:46,041 [PacketResponder: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775772_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:51596, dest: /127.0.0.1:37088, bytes: 2097152, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2100203935_24, offset: 0, srvID: 65fee986-f2dc-4671-a566-834a8ba38ec2, blockid: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775772_1002, duration(ns): 364732969
2020-12-03 07:24:46,041 [PacketResponder: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775771_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775771_1002, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:46,041 [PacketResponder: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775772_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775772_1002, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:46,043 [PacketResponder: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775769_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:50210, dest: /127.0.0.1:33258, bytes: 2097152, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2100203935_24, offset: 0, srvID: 2a2a30fb-7121-4535-8e69-ccc1d4e70ec3, blockid: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775769_1002, duration(ns): 219455673
2020-12-03 07:24:46,044 [PacketResponder: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775769_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775769_1002, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:46,045 [PacketResponder: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775768_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:33396, dest: /127.0.0.1:38762, bytes: 2097152, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2100203935_24, offset: 0, srvID: 881212a7-8d98-4a8f-86c4-1a8a1d6599a6, blockid: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775768_1002, duration(ns): 191386604
2020-12-03 07:24:46,046 [PacketResponder: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775768_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775768_1002, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:46,055 [IPC Server handler 6 on default port 43954] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_-9223372036854775760_1003, replicas=127.0.0.1:36036, 127.0.0.1:46279, 127.0.0.1:33258, 127.0.0.1:43823, 127.0.0.1:37088, 127.0.0.1:44016, 127.0.0.1:38762, 127.0.0.1:44848, 127.0.0.1:32788 for /testStripedFile_25165824
2020-12-03 07:24:46,059 [DataStreamer for file /testStripedFile_25165824] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:46,061 [DataXceiver for client DFSClient_NONMAPREDUCE_2100203935_24 at /127.0.0.1:52398 [Receiving block BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775760_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775760_1003 src: /127.0.0.1:52398 dest: /127.0.0.1:36036
2020-12-03 07:24:46,066 [DataStreamer for file /testStripedFile_25165824] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:46,069 [DataXceiver for client DFSClient_NONMAPREDUCE_2100203935_24 at /127.0.0.1:55094 [Receiving block BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775759_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775759_1003 src: /127.0.0.1:55094 dest: /127.0.0.1:46279
2020-12-03 07:24:46,069 [DataStreamer for file /testStripedFile_25165824] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:46,071 [DataXceiver for client DFSClient_NONMAPREDUCE_2100203935_24 at /127.0.0.1:50232 [Receiving block BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775758_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775758_1003 src: /127.0.0.1:50232 dest: /127.0.0.1:33258
2020-12-03 07:24:46,077 [DataStreamer for file /testStripedFile_25165824] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:46,079 [DataXceiver for client DFSClient_NONMAPREDUCE_2100203935_24 at /127.0.0.1:53500 [Receiving block BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775757_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775757_1003 src: /127.0.0.1:53500 dest: /127.0.0.1:43823
2020-12-03 07:24:46,082 [DataStreamer for file /testStripedFile_25165824] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:46,085 [DataXceiver for client DFSClient_NONMAPREDUCE_2100203935_24 at /127.0.0.1:51632 [Receiving block BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775756_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775756_1003 src: /127.0.0.1:51632 dest: /127.0.0.1:37088
2020-12-03 07:24:46,094 [DataStreamer for file /testStripedFile_25165824] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:46,096 [DataXceiver for client DFSClient_NONMAPREDUCE_2100203935_24 at /127.0.0.1:36154 [Receiving block BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775755_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775755_1003 src: /127.0.0.1:36154 dest: /127.0.0.1:44016
2020-12-03 07:24:46,248 [DataStreamer for file /testStripedFile_25165824] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:46,249 [DataXceiver for client DFSClient_NONMAPREDUCE_2100203935_24 at /127.0.0.1:33432 [Receiving block BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775754_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775754_1003 src: /127.0.0.1:33432 dest: /127.0.0.1:38762
2020-12-03 07:24:46,259 [DataStreamer for file /testStripedFile_25165824] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:46,261 [DataXceiver for client DFSClient_NONMAPREDUCE_2100203935_24 at /127.0.0.1:54890 [Receiving block BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775753_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775753_1003 src: /127.0.0.1:54890 dest: /127.0.0.1:44848
2020-12-03 07:24:46,266 [DataStreamer for file /testStripedFile_25165824] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:46,268 [DataXceiver for client DFSClient_NONMAPREDUCE_2100203935_24 at /127.0.0.1:52912 [Receiving block BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775752_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775752_1003 src: /127.0.0.1:52912 dest: /127.0.0.1:32788
2020-12-03 07:24:46,451 [PacketResponder: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775755_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:36154, dest: /127.0.0.1:44016, bytes: 2097152, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2100203935_24, offset: 0, srvID: 9ef29ebf-468b-497a-b175-e15a6fddabac, blockid: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775755_1003, duration(ns): 351746183
2020-12-03 07:24:46,453 [PacketResponder: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775760_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:52398, dest: /127.0.0.1:36036, bytes: 2097152, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2100203935_24, offset: 0, srvID: af552311-853c-41f7-a978-1842b97d4d48, blockid: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775760_1003, duration(ns): 386111395
2020-12-03 07:24:46,454 [PacketResponder: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775752_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:52912, dest: /127.0.0.1:32788, bytes: 2097152, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2100203935_24, offset: 0, srvID: 2e7687d0-5262-40f4-b8e8-9f72db15646f, blockid: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775752_1003, duration(ns): 180360273
2020-12-03 07:24:46,458 [PacketResponder: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775757_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:53500, dest: /127.0.0.1:43823, bytes: 2097152, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2100203935_24, offset: 0, srvID: d328db1a-8487-4a15-b7e1-b59a97d27898, blockid: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775757_1003, duration(ns): 368801066
2020-12-03 07:24:46,458 [PacketResponder: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775760_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775760_1003, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:46,459 [PacketResponder: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775757_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775757_1003, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:46,464 [PacketResponder: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775755_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775755_1003, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:46,458 [PacketResponder: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775753_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54890, dest: /127.0.0.1:44848, bytes: 2097152, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2100203935_24, offset: 0, srvID: 64ab98d0-afa7-4e91-8bf0-90433700df57, blockid: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775753_1003, duration(ns): 187552707
2020-12-03 07:24:46,466 [PacketResponder: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775753_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775753_1003, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:46,464 [PacketResponder: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775758_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:50232, dest: /127.0.0.1:33258, bytes: 2097152, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2100203935_24, offset: 0, srvID: 2a2a30fb-7121-4535-8e69-ccc1d4e70ec3, blockid: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775758_1003, duration(ns): 375760207
2020-12-03 07:24:46,458 [PacketResponder: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775756_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:51632, dest: /127.0.0.1:37088, bytes: 2097152, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2100203935_24, offset: 0, srvID: 65fee986-f2dc-4671-a566-834a8ba38ec2, blockid: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775756_1003, duration(ns): 361987379
2020-12-03 07:24:46,466 [PacketResponder: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775758_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775758_1003, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:46,467 [PacketResponder: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775756_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775756_1003, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:46,458 [PacketResponder: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775759_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55094, dest: /127.0.0.1:46279, bytes: 2097152, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2100203935_24, offset: 0, srvID: 85df5b2e-a97a-41c1-835b-035a6b9b8a7e, blockid: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775759_1003, duration(ns): 378164715
2020-12-03 07:24:46,468 [PacketResponder: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775759_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775759_1003, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:46,458 [PacketResponder: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775752_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775752_1003, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:46,476 [PacketResponder: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775754_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:33432, dest: /127.0.0.1:38762, bytes: 2097152, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2100203935_24, offset: 0, srvID: 881212a7-8d98-4a8f-86c4-1a8a1d6599a6, blockid: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775754_1003, duration(ns): 198870709
2020-12-03 07:24:46,476 [PacketResponder: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775754_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1006108214-172.17.0.5-1606980278566:blk_-9223372036854775754_1003, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:46,480 [IPC Server handler 6 on default port 43954] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /testStripedFile_25165824 is closed by DFSClient_NONMAPREDUCE_2100203935_24
2020-12-03 07:24:46,485 [Listener at localhost/36976] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopDataNode(2331)) - MiniDFSCluster Stopping DataNode 127.0.0.1:33258 from a total of 9 datanodes.
2020-12-03 07:24:46,485 [Listener at localhost/36976] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:24:46,486 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@5355622c] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:24:46,487 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-36579057-efca-436e-8f83-6abab3daf2e6) exiting.
2020-12-03 07:24:46,487 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-5a11274f-c1da-45a9-aa5e-f76140593ef7) exiting.
2020-12-03 07:24:46,512 [Listener at localhost/36976] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@571015a5{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:24:46,517 [Listener at localhost/36976] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@63b2af8f{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:46,518 [Listener at localhost/36976] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@495a022d{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:46,518 [Listener at localhost/36976] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3a4fc381{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:46,522 [Listener at localhost/36976] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 33152
2020-12-03 07:24:46,540 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:46,540 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:46,543 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:24:46,543 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1006108214-172.17.0.5-1606980278566 (Datanode Uuid 2a2a30fb-7121-4535-8e69-ccc1d4e70ec3) service to localhost/127.0.0.1:43954
2020-12-03 07:24:46,543 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1006108214-172.17.0.5-1606980278566 (Datanode Uuid 2a2a30fb-7121-4535-8e69-ccc1d4e70ec3)
2020-12-03 07:24:46,543 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:46,546 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1006108214-172.17.0.5-1606980278566] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:46,546 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1006108214-172.17.0.5-1606980278566] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:46,560 [Listener at localhost/36976] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:24:46,560 [Listener at localhost/36976] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:24:46,561 [Listener at localhost/36976] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:24:46,561 [Listener at localhost/36976] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:24:46,570 [Listener at localhost/36976] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:24:46,570 [Listener at localhost/36976] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopDataNode(2331)) - MiniDFSCluster Stopping DataNode 127.0.0.1:32788 from a total of 8 datanodes.
2020-12-03 07:24:46,571 [Listener at localhost/36976] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:24:46,571 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@589d20bb] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:24:46,581 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-4f8bde89-39bc-4664-8495-24db1fc9070c) exiting.
2020-12-03 07:24:46,581 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-fee6374f-fab9-484b-840a-3bb039765f1d) exiting.
2020-12-03 07:24:46,611 [Listener at localhost/36976] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@766ad58f{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:24:46,618 [Listener at localhost/36976] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@1f7ae072{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:46,619 [Listener at localhost/36976] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1aff6a4c{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:46,623 [Listener at localhost/36976] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@386a45c8{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:46,625 [Listener at localhost/36976] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 36976
2020-12-03 07:24:46,646 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:46,646 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:46,646 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:24:46,660 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1006108214-172.17.0.5-1606980278566 (Datanode Uuid 2e7687d0-5262-40f4-b8e8-9f72db15646f) service to localhost/127.0.0.1:43954
2020-12-03 07:24:46,660 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1006108214-172.17.0.5-1606980278566 (Datanode Uuid 2e7687d0-5262-40f4-b8e8-9f72db15646f)
2020-12-03 07:24:46,660 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:46,661 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1006108214-172.17.0.5-1606980278566] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:46,663 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1006108214-172.17.0.5-1606980278566] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:46,668 [Listener at localhost/36976] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:24:46,669 [Listener at localhost/36976] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:24:46,669 [Listener at localhost/36976] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:24:46,670 [Listener at localhost/36976] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:24:46,672 [Listener at localhost/36976] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:24:46,672 [Listener at localhost/36976] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopDataNode(2331)) - MiniDFSCluster Stopping DataNode 127.0.0.1:44016 from a total of 7 datanodes.
2020-12-03 07:24:46,672 [Listener at localhost/36976] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:24:46,672 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@83c35a3] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:24:46,674 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-4a4533dc-c0f5-4eba-8ab7-8f9fd4e59ffc) exiting.
2020-12-03 07:24:46,674 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-652cfcf7-8574-41cf-86aa-f7d20cbe2811) exiting.
2020-12-03 07:24:46,693 [Listener at localhost/36976] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@4be41510{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:24:46,693 [Listener at localhost/36976] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@71f2c909{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:46,694 [Listener at localhost/36976] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@37c94948{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:46,694 [Listener at localhost/36976] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2e349ec2{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:46,695 [Listener at localhost/36976] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 45669
2020-12-03 07:24:46,698 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:46,700 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:46,700 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:24:46,702 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1006108214-172.17.0.5-1606980278566 (Datanode Uuid 9ef29ebf-468b-497a-b175-e15a6fddabac) service to localhost/127.0.0.1:43954
2020-12-03 07:24:46,702 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1006108214-172.17.0.5-1606980278566 (Datanode Uuid 9ef29ebf-468b-497a-b175-e15a6fddabac)
2020-12-03 07:24:46,702 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:46,703 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1006108214-172.17.0.5-1606980278566] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:46,703 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1006108214-172.17.0.5-1606980278566] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:46,712 [Listener at localhost/36976] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:24:46,713 [Listener at localhost/36976] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:24:46,714 [Listener at localhost/36976] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:24:46,714 [Listener at localhost/36976] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:24:46,717 [Listener at localhost/36976] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:24:46,717 [Listener at localhost/36976] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopDataNode(2331)) - MiniDFSCluster Stopping DataNode 127.0.0.1:36036 from a total of 6 datanodes.
2020-12-03 07:24:46,717 [Listener at localhost/36976] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:24:46,717 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@77c2e4d7] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:24:46,719 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-f45a8750-594d-4642-87e3-93d21021bf5a) exiting.
2020-12-03 07:24:46,719 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-0095e818-e243-4a1c-aa13-99da0fd9e056) exiting.
2020-12-03 07:24:46,738 [Listener at localhost/36976] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@7a654dc7{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:24:46,739 [Listener at localhost/36976] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4452cb6e{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:46,740 [Listener at localhost/36976] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1461a0d8{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:46,740 [Listener at localhost/36976] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@78410454{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:46,741 [Listener at localhost/36976] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 38222
2020-12-03 07:24:46,744 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:46,744 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:46,744 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:24:46,747 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1006108214-172.17.0.5-1606980278566 (Datanode Uuid af552311-853c-41f7-a978-1842b97d4d48) service to localhost/127.0.0.1:43954
2020-12-03 07:24:46,747 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1006108214-172.17.0.5-1606980278566 (Datanode Uuid af552311-853c-41f7-a978-1842b97d4d48)
2020-12-03 07:24:46,748 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:46,749 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1006108214-172.17.0.5-1606980278566] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:46,749 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1006108214-172.17.0.5-1606980278566] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:46,753 [Listener at localhost/36976] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:24:46,754 [Listener at localhost/36976] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:24:46,755 [Listener at localhost/36976] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:24:46,755 [Listener at localhost/36976] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:24:46,758 [Listener at localhost/36976] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:24:46,758 [Listener at localhost/36976] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopDataNode(2331)) - MiniDFSCluster Stopping DataNode 127.0.0.1:37088 from a total of 5 datanodes.
2020-12-03 07:24:46,758 [Listener at localhost/36976] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:24:46,758 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@2e63d855] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:24:46,760 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-86b77411-628e-439a-83fb-b288094a00ab) exiting.
2020-12-03 07:24:46,760 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-519a1287-ec06-4bbf-8d21-79dbaca51fcb) exiting.
2020-12-03 07:24:46,776 [Listener at localhost/36976] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@749809a2{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:24:46,777 [Listener at localhost/36976] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@970e897{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:46,778 [Listener at localhost/36976] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@68f7864f{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:46,778 [Listener at localhost/36976] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6e8bf2f6{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:46,779 [Listener at localhost/36976] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 38029
2020-12-03 07:24:46,783 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:46,783 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:24:46,785 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:46,786 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1006108214-172.17.0.5-1606980278566 (Datanode Uuid 65fee986-f2dc-4671-a566-834a8ba38ec2) service to localhost/127.0.0.1:43954
2020-12-03 07:24:46,786 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1006108214-172.17.0.5-1606980278566 (Datanode Uuid 65fee986-f2dc-4671-a566-834a8ba38ec2)
2020-12-03 07:24:46,786 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:46,787 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1006108214-172.17.0.5-1606980278566] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:46,787 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1006108214-172.17.0.5-1606980278566] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:46,793 [Listener at localhost/36976] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:24:46,794 [Listener at localhost/36976] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:24:46,795 [Listener at localhost/36976] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:24:46,795 [Listener at localhost/36976] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:24:46,799 [Listener at localhost/36976] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:24:46,799 [Listener at localhost/36976] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopDataNode(2331)) - MiniDFSCluster Stopping DataNode 127.0.0.1:46279 from a total of 4 datanodes.
2020-12-03 07:24:46,799 [Listener at localhost/36976] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:24:46,799 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@2b6543c6] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:24:46,801 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-bd1ff44c-a092-4057-b4a3-2c31abfa7ab4) exiting.
2020-12-03 07:24:46,801 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-c003fc79-c50f-47e0-92be-1300d56d1d0d) exiting.
2020-12-03 07:24:46,819 [Listener at localhost/36976] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@476a123a{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:24:46,820 [Listener at localhost/36976] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2bb53d1f{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:46,820 [Listener at localhost/36976] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3977f84a{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:46,820 [Listener at localhost/36976] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1357a570{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:46,822 [Listener at localhost/36976] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 42918
2020-12-03 07:24:46,826 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:46,826 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:46,830 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:24:46,830 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1006108214-172.17.0.5-1606980278566 (Datanode Uuid 85df5b2e-a97a-41c1-835b-035a6b9b8a7e) service to localhost/127.0.0.1:43954
2020-12-03 07:24:46,830 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1006108214-172.17.0.5-1606980278566 (Datanode Uuid 85df5b2e-a97a-41c1-835b-035a6b9b8a7e)
2020-12-03 07:24:46,830 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:46,831 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1006108214-172.17.0.5-1606980278566] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:46,831 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1006108214-172.17.0.5-1606980278566] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:46,841 [Listener at localhost/36976] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:24:46,842 [Listener at localhost/36976] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:24:46,846 [Listener at localhost/36976] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:24:46,846 [Listener at localhost/36976] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:24:46,851 [Listener at localhost/36976] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:24:46,851 [Listener at localhost/36976] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopDataNode(2331)) - MiniDFSCluster Stopping DataNode 127.0.0.1:44848 from a total of 3 datanodes.
2020-12-03 07:24:46,851 [Listener at localhost/36976] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:24:46,851 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@29689525] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:24:46,853 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-642bfc7c-ff8d-4514-94bd-79381f534ac2) exiting.
2020-12-03 07:24:46,853 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-bf7ef67b-e5ab-452a-a984-fbd8e1fd6d82) exiting.
2020-12-03 07:24:46,871 [Listener at localhost/36976] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@73d28aa6{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:24:46,871 [Listener at localhost/36976] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@1b1d7f5f{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:46,872 [Listener at localhost/36976] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@20af3275{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:46,872 [Listener at localhost/36976] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6cadeb00{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:46,874 [Listener at localhost/36976] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 41618
2020-12-03 07:24:46,879 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:46,883 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:46,883 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:24:46,883 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1006108214-172.17.0.5-1606980278566 (Datanode Uuid 64ab98d0-afa7-4e91-8bf0-90433700df57) service to localhost/127.0.0.1:43954
2020-12-03 07:24:46,883 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1006108214-172.17.0.5-1606980278566 (Datanode Uuid 64ab98d0-afa7-4e91-8bf0-90433700df57)
2020-12-03 07:24:46,884 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:46,885 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1006108214-172.17.0.5-1606980278566] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:46,885 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1006108214-172.17.0.5-1606980278566] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:46,892 [Listener at localhost/36976] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:24:46,892 [Listener at localhost/36976] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:24:46,894 [Listener at localhost/36976] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:24:46,894 [Listener at localhost/36976] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:24:46,898 [Listener at localhost/36976] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:24:46,899 [Listener at localhost/36976] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopDataNode(2331)) - MiniDFSCluster Stopping DataNode 127.0.0.1:43823 from a total of 2 datanodes.
2020-12-03 07:24:46,899 [Listener at localhost/36976] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:24:46,899 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@7054eea3] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:24:46,902 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-24768886-4de0-4de1-9388-2b4ca3a5077c) exiting.
2020-12-03 07:24:46,902 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-ea8236f0-3cb7-4341-b448-d9673239316e) exiting.
2020-12-03 07:24:46,923 [Listener at localhost/36976] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@3a84a9d4{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:24:46,923 [Listener at localhost/36976] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@e779541{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:46,924 [Listener at localhost/36976] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@12b86e0e{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:46,924 [Listener at localhost/36976] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@413b44fe{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:46,925 [Listener at localhost/36976] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 35038
2020-12-03 07:24:46,931 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:46,931 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:46,936 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:24:46,936 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1006108214-172.17.0.5-1606980278566 (Datanode Uuid d328db1a-8487-4a15-b7e1-b59a97d27898) service to localhost/127.0.0.1:43954
2020-12-03 07:24:46,936 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1006108214-172.17.0.5-1606980278566 (Datanode Uuid d328db1a-8487-4a15-b7e1-b59a97d27898)
2020-12-03 07:24:46,936 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:46,937 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1006108214-172.17.0.5-1606980278566] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:46,937 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1006108214-172.17.0.5-1606980278566] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:46,949 [Listener at localhost/36976] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:24:46,950 [Listener at localhost/36976] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:24:46,952 [Listener at localhost/36976] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:24:46,953 [Listener at localhost/36976] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:24:46,959 [Listener at localhost/36976] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:24:46,959 [Listener at localhost/36976] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopDataNode(2331)) - MiniDFSCluster Stopping DataNode 127.0.0.1:38762 from a total of 1 datanodes.
2020-12-03 07:24:46,959 [Listener at localhost/36976] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:24:46,959 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@2278c4fb] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:24:46,963 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-bda183c3-643a-4595-8903-8df17740c647) exiting.
2020-12-03 07:24:46,963 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-fd75e4f2-39b3-4d3a-864b-ad2d2be6069e) exiting.
2020-12-03 07:24:46,982 [Listener at localhost/36976] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@67908516{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:24:46,983 [Listener at localhost/36976] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4c2b0ab7{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:46,983 [Listener at localhost/36976] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3c04674{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:46,984 [Listener at localhost/36976] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@15dd18fe{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:46,985 [Listener at localhost/36976] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 33323
2020-12-03 07:24:46,986 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:46,990 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:46,990 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:24:46,990 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1006108214-172.17.0.5-1606980278566 (Datanode Uuid 881212a7-8d98-4a8f-86c4-1a8a1d6599a6) service to localhost/127.0.0.1:43954
2020-12-03 07:24:46,995 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1006108214-172.17.0.5-1606980278566 (Datanode Uuid 881212a7-8d98-4a8f-86c4-1a8a1d6599a6)
2020-12-03 07:24:46,995 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:46,996 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1006108214-172.17.0.5-1606980278566] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:46,996 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1006108214-172.17.0.5-1606980278566] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:47,006 [Listener at localhost/36976] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:24:47,007 [Listener at localhost/36976] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:24:47,009 [Listener at localhost/36976] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:24:47,009 [Listener at localhost/36976] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:24:47,014 [Listener at localhost/36976] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:24:47,015 [Listener at localhost/36976] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:24:47,015 [Listener at localhost/36976] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:24:47,016 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@1eb6cf1f] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:24:47,016 [Listener at localhost/36976] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 1, 16
2020-12-03 07:24:47,016 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@64623e3d] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:24:47,016 [Listener at localhost/36976] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 17 Total time for transactions(ms): 19 Number of transactions batched in Syncs: 2 Number of syncs: 16 SyncTimes(ms): 3 3 
2020-12-03 07:24:47,018 [Listener at localhost/36976] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000017
2020-12-03 07:24:47,019 [Listener at localhost/36976] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000017
2020-12-03 07:24:47,019 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:24:47,020 [CacheReplicationMonitor(1912035462)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:24:47,127 [Listener at localhost/36976] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 43954
2020-12-03 07:24:47,130 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:47,132 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:47,132 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:24:47,132 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:24:47,171 [Listener at localhost/36976] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:24:47,171 [Listener at localhost/36976] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:24:47,173 [Listener at localhost/36976] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@279c4ae6{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:24:47,175 [Listener at localhost/36976] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@5860ad70{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:47,175 [Listener at localhost/36976] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4d746801{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:47,176 [Listener at localhost/36976] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@525f428f{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:47,178 [Listener at localhost/36976] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-12-03 07:24:47,200 [Listener at localhost/36976] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-12-03 07:24:47,201 [Listener at localhost/36976] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-12-03 07:24:47,205 [Listener at localhost/36976] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:24:47,209 [Listener at localhost/36976] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:24:47,211 [Listener at localhost/36976] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:24:47,211 [Listener at localhost/36976] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:24:47,212 [Listener at localhost/36976] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://localhost:43954
2020-12-03 07:24:47,212 [Listener at localhost/36976] INFO  namenode.NameNode (NameNode.java:<init>(944)) - Clients should use localhost:43954 to access this namenode/service.
2020-12-03 07:24:47,279 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@781e1ed4] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:47,279 [Listener at localhost/36976] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:42381
2020-12-03 07:24:47,280 [Listener at localhost/36976] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:47,282 [Listener at localhost/36976] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:47,283 [Listener at localhost/36976] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:24:47,283 [Listener at localhost/36976] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:47,285 [Listener at localhost/36976] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:47,285 [Listener at localhost/36976] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:24:47,285 [Listener at localhost/36976] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:47,286 [Listener at localhost/36976] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:47,287 [Listener at localhost/36976] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:24:47,287 [Listener at localhost/36976] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:24:47,288 [Listener at localhost/36976] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 42381
2020-12-03 07:24:47,288 [Listener at localhost/36976] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:47,290 [Listener at localhost/36976] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@71afd5ff{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:47,291 [Listener at localhost/36976] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7ba6760c{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:47,297 [Listener at localhost/36976] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@321a418a{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:24:47,303 [Listener at localhost/36976] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3bb87643{HTTP/1.1,[http/1.1]}{localhost:42381}
2020-12-03 07:24:47,303 [Listener at localhost/36976] INFO  server.Server (Server.java:doStart(419)) - Started @11055ms
2020-12-03 07:24:47,306 [Listener at localhost/36976] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:24:47,306 [Listener at localhost/36976] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:24:47,306 [Listener at localhost/36976] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:24:47,307 [Listener at localhost/36976] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:24:47,307 [Listener at localhost/36976] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:24:47,307 [Listener at localhost/36976] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:24:47,307 [Listener at localhost/36976] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:24:47,307 [Listener at localhost/36976] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:24:47,308 [Listener at localhost/36976] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:47,308 [Listener at localhost/36976] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:24:47,308 [Listener at localhost/36976] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:24:47,308 [Listener at localhost/36976] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:24:47,309 [Listener at localhost/36976] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:24:47
2020-12-03 07:24:47,309 [Listener at localhost/36976] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:24:47,309 [Listener at localhost/36976] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:47,309 [Listener at localhost/36976] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:24:47,309 [Listener at localhost/36976] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:24:47,318 [Listener at localhost/36976] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:24:47,319 [Listener at localhost/36976] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:24:47,319 [Listener at localhost/36976] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:24:47,319 [Listener at localhost/36976] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:24:47,319 [Listener at localhost/36976] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:24:47,319 [Listener at localhost/36976] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:24:47,319 [Listener at localhost/36976] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:24:47,319 [Listener at localhost/36976] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:24:47,320 [Listener at localhost/36976] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:24:47,320 [Listener at localhost/36976] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:24:47,320 [Listener at localhost/36976] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:24:47,320 [Listener at localhost/36976] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:24:47,320 [Listener at localhost/36976] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:24:47,320 [Listener at localhost/36976] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:24:47,321 [Listener at localhost/36976] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:47,321 [Listener at localhost/36976] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:24:47,321 [Listener at localhost/36976] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:24:47,324 [Listener at localhost/36976] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:24:47,324 [Listener at localhost/36976] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:24:47,325 [Listener at localhost/36976] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:24:47,325 [Listener at localhost/36976] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:24:47,325 [Listener at localhost/36976] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:24:47,325 [Listener at localhost/36976] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:24:47,325 [Listener at localhost/36976] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:24:47,325 [Listener at localhost/36976] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:47,326 [Listener at localhost/36976] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:24:47,326 [Listener at localhost/36976] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:24:47,327 [Listener at localhost/36976] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:24:47,328 [Listener at localhost/36976] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:24:47,328 [Listener at localhost/36976] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:24:47,329 [Listener at localhost/36976] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:24:47,329 [Listener at localhost/36976] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:24:47,329 [Listener at localhost/36976] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:24:47,329 [Listener at localhost/36976] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:47,329 [Listener at localhost/36976] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:24:47,329 [Listener at localhost/36976] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:24:47,372 [Listener at localhost/36976] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 11964@2bb02abc3fe0
2020-12-03 07:24:47,449 [Listener at localhost/36976] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 11964@2bb02abc3fe0
2020-12-03 07:24:47,451 [Listener at localhost/36976] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-12-03 07:24:47,453 [Listener at localhost/36976] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-12-03 07:24:47,458 [Listener at localhost/36976] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:24:47,465 [Listener at localhost/36976] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:24:47,466 [Listener at localhost/36976] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:24:47,466 [Listener at localhost/36976] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-12-03 07:24:47,470 [Listener at localhost/36976] INFO  namenode.FSImage (FSImage.java:loadEdits(910)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@47dc2e79 expecting start txid #1
2020-12-03 07:24:47,470 [Listener at localhost/36976] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000017, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000017 maxTxnsToRead = 9223372036854775807
2020-12-03 07:24:47,471 [Listener at localhost/36976] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000017' to transaction ID 1
2020-12-03 07:24:47,486 [Listener at localhost/36976] INFO  namenode.ErasureCodingPolicyManager (ErasureCodingPolicyManager.java:enablePolicy(429)) - Enable the erasure coding policy RS-LEGACY-6-3-1024k
2020-12-03 07:24:47,526 [Listener at localhost/36976] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(188)) - Loaded 1 edits file(s) (the last named /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000017, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000017) of total size 1183.0, total edits 17.0, total load time 22.0 ms
2020-12-03 07:24:47,527 [Listener at localhost/36976] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:24:47,527 [Listener at localhost/36976] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 18
2020-12-03 07:24:47,688 [Listener at localhost/36976] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:24:47,689 [Listener at localhost/36976] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 358 msecs
2020-12-03 07:24:47,689 [Listener at localhost/36976] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:43954
2020-12-03 07:24:47,690 [Listener at localhost/36976] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:47,691 [Socket Reader #1 for port 43954] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 43954
2020-12-03 07:24:47,702 [Listener at localhost/43954] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:24:47,775 [Listener at localhost/43954] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:24:47,777 [Listener at localhost/43954] INFO  hdfs.StateChange (BlockManagerSafeMode.java:reportStatus(617)) - STATE* Safe mode ON. 
The reported blocks 0 needs additional 2 blocks to reach the threshold 0.9990 of total blocks 3.
The minimum number of live datanodes is not required. Safe mode will be turned off automatically once the thresholds have been reached.
2020-12-03 07:24:47,784 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:47,789 [IPC Server listener on 43954] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 43954: starting
2020-12-03 07:24:47,797 [Listener at localhost/43954] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:43954
2020-12-03 07:24:47,797 [Listener at localhost/43954] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:24:47,797 [Listener at localhost/43954] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:24:47,800 [Listener at localhost/43954] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 2 milliseconds
name space=3
storage space=41943040
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:24:47,810 [Listener at localhost/43954] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:restartNameNode(2191)) - Restarted the namenode
2020-12-03 07:24:47,812 [CacheReplicationMonitor(339999552)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:24:47,843 [IPC Server handler 0 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:47,844 [Listener at localhost/43954] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:24:47,848 [Listener at localhost/43954] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:24:47,849 [Listener at localhost/43954] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:24:47,849 [Listener at localhost/43954] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:24:47,853 [Listener at localhost/43954] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:47,853 [Listener at localhost/43954] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:24:47,854 [Listener at localhost/43954] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:24:47,854 [Listener at localhost/43954] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:47,854 [Listener at localhost/43954] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:24:47,855 [Listener at localhost/43954] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:37054
2020-12-03 07:24:47,855 [Listener at localhost/43954] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:24:47,855 [Listener at localhost/43954] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:24:47,856 [Listener at localhost/43954] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:47,858 [Listener at localhost/43954] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:47,858 [Listener at localhost/43954] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:24:47,858 [Listener at localhost/43954] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:47,863 [Listener at localhost/43954] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:47,865 [Listener at localhost/43954] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:24:47,865 [Listener at localhost/43954] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:47,865 [Listener at localhost/43954] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:47,866 [Listener at localhost/43954] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 40758
2020-12-03 07:24:47,867 [Listener at localhost/43954] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:47,869 [Listener at localhost/43954] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5ef1d98b{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:47,869 [Listener at localhost/43954] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7602f6bd{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:47,878 [Listener at localhost/43954] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@614c06ee{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:24:47,885 [Listener at localhost/43954] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@72fd31c7{HTTP/1.1,[http/1.1]}{localhost:40758}
2020-12-03 07:24:47,885 [Listener at localhost/43954] INFO  server.Server (Server.java:doStart(419)) - Started @11637ms
2020-12-03 07:24:47,907 [Listener at localhost/43954] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:39686
2020-12-03 07:24:47,936 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@58e7212a] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:47,936 [Listener at localhost/43954] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:24:47,936 [Listener at localhost/43954] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:24:47,937 [Listener at localhost/43954] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:47,938 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:47,947 [Listener at localhost/43862] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:43862
2020-12-03 07:24:48,008 [Listener at localhost/43862] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:24:48,009 [Listener at localhost/43862] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:24:48,010 [Thread-486] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43954 starting to offer service
2020-12-03 07:24:48,021 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:48,022 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:48,022 [Thread-486] WARN  datanode.DataNode (BPServiceActor.java:retrieveNamespaceInfo(237)) - Problem connecting to server: localhost/127.0.0.1:43954
2020-12-03 07:24:48,039 [IPC Server handler 1 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:48,040 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:48,040 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:48,141 [IPC Server handler 2 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:48,142 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:48,142 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:48,244 [IPC Server handler 3 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:48,244 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:48,245 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:48,346 [IPC Server handler 4 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:48,347 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:48,347 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:48,448 [IPC Server handler 5 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:48,449 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:48,449 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:48,550 [IPC Server handler 6 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:48,551 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:48,551 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:48,653 [IPC Server handler 7 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:48,653 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:48,654 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:48,762 [IPC Server handler 8 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:48,763 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:48,763 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:48,865 [IPC Server handler 1 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:48,866 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:48,866 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:48,967 [IPC Server handler 2 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:48,968 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:48,968 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:49,070 [IPC Server handler 3 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:49,070 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:49,071 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:49,172 [IPC Server handler 4 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:49,173 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:49,173 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:49,274 [IPC Server handler 5 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:49,275 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:49,275 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:49,376 [IPC Server handler 6 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:49,377 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:49,377 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:49,479 [IPC Server handler 7 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:49,480 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:49,480 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:49,582 [IPC Server handler 8 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:49,583 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:49,583 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:49,684 [IPC Server handler 9 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:49,685 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:49,685 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:49,786 [IPC Server handler 0 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:49,787 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:49,787 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:49,889 [IPC Server handler 2 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:49,890 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:49,890 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:49,991 [IPC Server handler 3 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:49,992 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:49,992 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:50,094 [IPC Server handler 4 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:50,095 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:50,095 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:50,196 [IPC Server handler 5 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:50,197 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:50,197 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:50,298 [IPC Server handler 6 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:50,299 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:50,299 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:50,401 [IPC Server handler 7 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:50,401 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:50,402 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:50,503 [IPC Server handler 8 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:50,503 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:50,503 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:50,604 [IPC Server handler 9 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:50,605 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:50,605 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:50,706 [IPC Server handler 0 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:50,707 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:50,707 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:50,808 [IPC Server handler 1 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:50,809 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:50,809 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:50,910 [IPC Server handler 3 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:50,911 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:50,911 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:51,013 [IPC Server handler 4 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:51,013 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:51,013 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:51,114 [IPC Server handler 5 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:51,115 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:51,115 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:51,216 [IPC Server handler 6 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:51,217 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:51,217 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:51,318 [IPC Server handler 7 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:51,319 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:51,319 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:51,420 [IPC Server handler 8 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:51,421 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:51,421 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:51,522 [IPC Server handler 9 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:51,523 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:51,523 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:51,624 [IPC Server handler 0 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:51,625 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:51,625 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:51,726 [IPC Server handler 1 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:51,727 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:51,727 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:51,829 [IPC Server handler 2 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:51,829 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:51,829 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:51,930 [IPC Server handler 4 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:51,931 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:51,931 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:52,032 [IPC Server handler 5 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:52,033 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:52,033 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:52,134 [IPC Server handler 6 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:52,135 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:52,135 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:52,236 [IPC Server handler 7 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:52,236 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:52,236 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:52,337 [IPC Server handler 8 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:52,338 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:52,338 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:52,439 [IPC Server handler 9 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:52,442 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:52,443 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:52,544 [IPC Server handler 0 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:52,544 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:52,544 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:52,645 [IPC Server handler 1 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:52,646 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:52,646 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:52,747 [IPC Server handler 2 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:52,748 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:52,748 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:52,849 [IPC Server handler 3 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:52,850 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:52,850 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:52,951 [IPC Server handler 5 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:52,952 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:52,952 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:53,101 [IPC Server handler 7 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:53,102 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:53,102 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:53,102 [Thread-486] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43954
2020-12-03 07:24:53,103 [Thread-486] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:24:53,167 [Thread-486] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/in_use.lock acquired by nodename 11964@2bb02abc3fe0
2020-12-03 07:24:53,203 [IPC Server handler 8 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:53,203 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:53,203 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:53,226 [Thread-486] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/in_use.lock acquired by nodename 11964@2bb02abc3fe0
2020-12-03 07:24:53,261 [Thread-486] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:53,262 [Thread-486] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:53,305 [IPC Server handler 9 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:53,305 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:53,305 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:53,312 [Thread-486] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:53,312 [Thread-486] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:53,344 [Thread-486] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=829214013;bpid=BP-1006108214-172.17.0.5-1606980278566;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=829214013;c=1606980278566;bpid=BP-1006108214-172.17.0.5-1606980278566;dnuuid=2a2a30fb-7121-4535-8e69-ccc1d4e70ec3
2020-12-03 07:24:53,347 [Thread-486] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-5a11274f-c1da-45a9-aa5e-f76140593ef7
2020-12-03 07:24:53,347 [Thread-486] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, StorageType: DISK
2020-12-03 07:24:53,349 [Thread-486] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-36579057-efca-436e-8f83-6abab3daf2e6
2020-12-03 07:24:53,349 [Thread-486] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, StorageType: DISK
2020-12-03 07:24:53,351 [Thread-486] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:24:53,352 [Thread-486] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:24:53,352 [Thread-486] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:24:53,352 [Thread-486] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:24:53,353 [Thread-486] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:24:53,353 [Thread-486] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:53,353 [Thread-500] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11...
2020-12-03 07:24:53,353 [Thread-501] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12...
2020-12-03 07:24:53,356 [Thread-500] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1006108214-172.17.0.5-1606980278566/current: 3194894
2020-12-03 07:24:53,356 [Thread-501] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1006108214-172.17.0.5-1606980278566/current: 2138119
2020-12-03 07:24:53,364 [Thread-500] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1006108214-172.17.0.5-1606980278566 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11: 11ms
2020-12-03 07:24:53,364 [Thread-501] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1006108214-172.17.0.5-1606980278566 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12: 11ms
2020-12-03 07:24:53,365 [Thread-486] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1006108214-172.17.0.5-1606980278566: 13ms
2020-12-03 07:24:53,366 [Thread-502] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11...
2020-12-03 07:24:53,366 [Thread-503] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12...
2020-12-03 07:24:53,368 [Thread-503] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(925)) - Successfully read replica from cache file : /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1006108214-172.17.0.5-1606980278566/current/replicas
2020-12-03 07:24:53,368 [Thread-502] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(925)) - Successfully read replica from cache file : /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1006108214-172.17.0.5-1606980278566/current/replicas
2020-12-03 07:24:53,368 [Thread-503] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12: 3ms
2020-12-03 07:24:53,368 [Thread-502] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11: 3ms
2020-12-03 07:24:53,369 [Thread-486] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1006108214-172.17.0.5-1606980278566: 3ms
2020-12-03 07:24:53,382 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-36579057-efca-436e-8f83-6abab3daf2e6): no suitable block pools found to scan.  Waiting 1814390680 ms.
2020-12-03 07:24:53,383 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-5a11274f-c1da-45a9-aa5e-f76140593ef7): no suitable block pools found to scan.  Waiting 1814390679 ms.
2020-12-03 07:24:53,383 [Thread-486] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 7:39 AM with interval of 21600000ms
2020-12-03 07:24:53,384 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1006108214-172.17.0.5-1606980278566 (Datanode Uuid 2a2a30fb-7121-4535-8e69-ccc1d4e70ec3) service to localhost/127.0.0.1:43954 beginning handshake with NN
2020-12-03 07:24:53,385 [IPC Server handler 0 on default port 43954] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:37054, datanodeUuid=2a2a30fb-7121-4535-8e69-ccc1d4e70ec3, infoPort=39686, infoSecurePort=0, ipcPort=43862, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566) storage 2a2a30fb-7121-4535-8e69-ccc1d4e70ec3
2020-12-03 07:24:53,385 [IPC Server handler 0 on default port 43954] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:37054
2020-12-03 07:24:53,386 [IPC Server handler 0 on default port 43954] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 2a2a30fb-7121-4535-8e69-ccc1d4e70ec3 (127.0.0.1:37054).
2020-12-03 07:24:53,387 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1006108214-172.17.0.5-1606980278566 (Datanode Uuid 2a2a30fb-7121-4535-8e69-ccc1d4e70ec3) service to localhost/127.0.0.1:43954 successfully registered with NN
2020-12-03 07:24:53,387 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:43954 using BLOCKREPORT_INTERVAL of 100msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:24:53,389 [IPC Server handler 1 on default port 43954] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-5a11274f-c1da-45a9-aa5e-f76140593ef7 for DN 127.0.0.1:37054
2020-12-03 07:24:53,389 [IPC Server handler 1 on default port 43954] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-36579057-efca-436e-8f83-6abab3daf2e6 for DN 127.0.0.1:37054
2020-12-03 07:24:53,392 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xa0f7db8fbcc3a801: Processing first storage report for DS-36579057-efca-436e-8f83-6abab3daf2e6 from datanode 2a2a30fb-7121-4535-8e69-ccc1d4e70ec3
2020-12-03 07:24:53,392 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xa0f7db8fbcc3a801: from storage DS-36579057-efca-436e-8f83-6abab3daf2e6 node DatanodeRegistration(127.0.0.1:37054, datanodeUuid=2a2a30fb-7121-4535-8e69-ccc1d4e70ec3, infoPort=39686, infoSecurePort=0, ipcPort=43862, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566), blocks: 1, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:53,392 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xa0f7db8fbcc3a801: Processing first storage report for DS-5a11274f-c1da-45a9-aa5e-f76140593ef7 from datanode 2a2a30fb-7121-4535-8e69-ccc1d4e70ec3
2020-12-03 07:24:53,392 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xa0f7db8fbcc3a801: from storage DS-5a11274f-c1da-45a9-aa5e-f76140593ef7 node DatanodeRegistration(127.0.0.1:37054, datanodeUuid=2a2a30fb-7121-4535-8e69-ccc1d4e70ec3, infoPort=39686, infoSecurePort=0, ipcPort=43862, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566), blocks: 2, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:24:53,393 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xa0f7db8fbcc3a801,  containing 2 storage report(s), of which we sent 2. The reports had 3 total blocks and used 1 RPC(s). This took 1 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:53,393 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:53,406 [IPC Server handler 3 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:53,407 [Listener at localhost/43862] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:24:53,408 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:43954
2020-12-03 07:24:53,410 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2637)) - BLOCK* processReport 0xa0f7db8fbcc3a802: discarded non-initial block report from DatanodeRegistration(127.0.0.1:37054, datanodeUuid=2a2a30fb-7121-4535-8e69-ccc1d4e70ec3, infoPort=39686, infoSecurePort=0, ipcPort=43862, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566) because namenode still in startup phase
2020-12-03 07:24:53,410 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2637)) - BLOCK* processReport 0xa0f7db8fbcc3a802: discarded non-initial block report from DatanodeRegistration(127.0.0.1:37054, datanodeUuid=2a2a30fb-7121-4535-8e69-ccc1d4e70ec3, infoPort=39686, infoSecurePort=0, ipcPort=43862, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566) because namenode still in startup phase
2020-12-03 07:24:53,410 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xa0f7db8fbcc3a802,  containing 2 storage report(s), of which we sent 2. The reports had 3 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:53,411 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:53,508 [Listener at localhost/43862] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:24:53,509 [Listener at localhost/43862] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:24:53,510 [Listener at localhost/43862] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:24:53,511 [Listener at localhost/43862] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:53,511 [Listener at localhost/43862] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:24:53,511 [Listener at localhost/43862] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:24:53,512 [Listener at localhost/43862] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:53,512 [Listener at localhost/43862] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:24:53,513 [Listener at localhost/43862] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:40699
2020-12-03 07:24:53,513 [Listener at localhost/43862] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:24:53,513 [Listener at localhost/43862] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:24:53,514 [Listener at localhost/43862] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:53,516 [Listener at localhost/43862] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:53,519 [Listener at localhost/43862] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:24:53,519 [Listener at localhost/43862] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:53,521 [Listener at localhost/43862] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:53,521 [Listener at localhost/43862] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:24:53,521 [Listener at localhost/43862] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:53,521 [Listener at localhost/43862] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:53,522 [Listener at localhost/43862] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 34059
2020-12-03 07:24:53,522 [Listener at localhost/43862] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:53,524 [Listener at localhost/43862] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6f15a5e6{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:53,524 [Listener at localhost/43862] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7e266a2{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:53,529 [Listener at localhost/43862] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7cc56f2{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:24:53,530 [Listener at localhost/43862] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@13bf5b84{HTTP/1.1,[http/1.1]}{localhost:34059}
2020-12-03 07:24:53,530 [Listener at localhost/43862] INFO  server.Server (Server.java:doStart(419)) - Started @17282ms
2020-12-03 07:24:53,545 [Listener at localhost/43862] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:38503
2020-12-03 07:24:53,545 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7ded0825] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:53,545 [Listener at localhost/43862] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:24:53,546 [Listener at localhost/43862] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:24:53,546 [Listener at localhost/43862] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:53,547 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:53,550 [Listener at localhost/38380] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:38380
2020-12-03 07:24:53,553 [Listener at localhost/38380] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:24:53,553 [Listener at localhost/38380] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:24:53,554 [Thread-518] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43954 starting to offer service
2020-12-03 07:24:53,556 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:53,556 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:53,558 [Thread-518] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43954
2020-12-03 07:24:53,558 [Thread-518] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:24:53,559 [IPC Server handler 7 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:53,560 [Listener at localhost/38380] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:53,560 [Listener at localhost/38380] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:53,588 [Thread-518] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/in_use.lock acquired by nodename 11964@2bb02abc3fe0
2020-12-03 07:24:53,638 [Thread-518] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/in_use.lock acquired by nodename 11964@2bb02abc3fe0
2020-12-03 07:24:53,661 [IPC Server handler 8 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:53,662 [Listener at localhost/38380] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:53,662 [Listener at localhost/38380] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:53,673 [Thread-518] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:53,673 [Thread-518] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:53,708 [Thread-518] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:53,708 [Thread-518] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:53,739 [Thread-518] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=829214013;bpid=BP-1006108214-172.17.0.5-1606980278566;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=829214013;c=1606980278566;bpid=BP-1006108214-172.17.0.5-1606980278566;dnuuid=2e7687d0-5262-40f4-b8e8-9f72db15646f
2020-12-03 07:24:53,741 [Thread-518] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-fee6374f-fab9-484b-840a-3bb039765f1d
2020-12-03 07:24:53,742 [Thread-518] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, StorageType: DISK
2020-12-03 07:24:53,743 [Thread-518] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-4f8bde89-39bc-4664-8495-24db1fc9070c
2020-12-03 07:24:53,743 [Thread-518] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, StorageType: DISK
2020-12-03 07:24:53,744 [Thread-518] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:24:53,745 [Thread-518] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:24:53,746 [Thread-518] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:24:53,746 [Thread-518] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:24:53,746 [Thread-518] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:24:53,747 [Thread-518] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:53,747 [Thread-531] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17...
2020-12-03 07:24:53,747 [Thread-532] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18...
2020-12-03 07:24:53,749 [Thread-532] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1006108214-172.17.0.5-1606980278566/current: 2138119
2020-12-03 07:24:53,749 [Thread-531] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1006108214-172.17.0.5-1606980278566/current: 3194894
2020-12-03 07:24:53,757 [Thread-531] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1006108214-172.17.0.5-1606980278566 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17: 10ms
2020-12-03 07:24:53,757 [Thread-532] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1006108214-172.17.0.5-1606980278566 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18: 10ms
2020-12-03 07:24:53,757 [Thread-518] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1006108214-172.17.0.5-1606980278566: 10ms
2020-12-03 07:24:53,757 [Thread-533] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17...
2020-12-03 07:24:53,758 [Thread-534] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18...
2020-12-03 07:24:53,758 [Thread-534] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(925)) - Successfully read replica from cache file : /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1006108214-172.17.0.5-1606980278566/current/replicas
2020-12-03 07:24:53,758 [Thread-533] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(925)) - Successfully read replica from cache file : /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1006108214-172.17.0.5-1606980278566/current/replicas
2020-12-03 07:24:53,758 [Thread-534] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18: 1ms
2020-12-03 07:24:53,758 [Thread-533] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17: 1ms
2020-12-03 07:24:53,759 [Thread-518] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1006108214-172.17.0.5-1606980278566: 2ms
2020-12-03 07:24:53,760 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-4f8bde89-39bc-4664-8495-24db1fc9070c): no suitable block pools found to scan.  Waiting 1814390560 ms.
2020-12-03 07:24:53,760 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-fee6374f-fab9-484b-840a-3bb039765f1d): no suitable block pools found to scan.  Waiting 1814390560 ms.
2020-12-03 07:24:53,760 [Thread-518] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 7:34 AM with interval of 21600000ms
2020-12-03 07:24:53,761 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1006108214-172.17.0.5-1606980278566 (Datanode Uuid 2e7687d0-5262-40f4-b8e8-9f72db15646f) service to localhost/127.0.0.1:43954 beginning handshake with NN
2020-12-03 07:24:53,762 [IPC Server handler 9 on default port 43954] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:40699, datanodeUuid=2e7687d0-5262-40f4-b8e8-9f72db15646f, infoPort=38503, infoSecurePort=0, ipcPort=38380, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566) storage 2e7687d0-5262-40f4-b8e8-9f72db15646f
2020-12-03 07:24:53,762 [IPC Server handler 9 on default port 43954] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:40699
2020-12-03 07:24:53,762 [IPC Server handler 9 on default port 43954] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 2e7687d0-5262-40f4-b8e8-9f72db15646f (127.0.0.1:40699).
2020-12-03 07:24:53,763 [IPC Server handler 0 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:53,764 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1006108214-172.17.0.5-1606980278566 (Datanode Uuid 2e7687d0-5262-40f4-b8e8-9f72db15646f) service to localhost/127.0.0.1:43954 successfully registered with NN
2020-12-03 07:24:53,764 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:43954 using BLOCKREPORT_INTERVAL of 100msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:24:53,765 [IPC Server handler 1 on default port 43954] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-fee6374f-fab9-484b-840a-3bb039765f1d for DN 127.0.0.1:40699
2020-12-03 07:24:53,765 [IPC Server handler 1 on default port 43954] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-4f8bde89-39bc-4664-8495-24db1fc9070c for DN 127.0.0.1:40699
2020-12-03 07:24:53,766 [Listener at localhost/38380] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2798)) - No heartbeat from DataNode: 127.0.0.1:40699
2020-12-03 07:24:53,766 [Listener at localhost/38380] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:53,767 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x2a053dbcd6899eeb: Processing first storage report for DS-fee6374f-fab9-484b-840a-3bb039765f1d from datanode 2e7687d0-5262-40f4-b8e8-9f72db15646f
2020-12-03 07:24:53,767 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x2a053dbcd6899eeb: from storage DS-fee6374f-fab9-484b-840a-3bb039765f1d node DatanodeRegistration(127.0.0.1:40699, datanodeUuid=2e7687d0-5262-40f4-b8e8-9f72db15646f, infoPort=38503, infoSecurePort=0, ipcPort=38380, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566), blocks: 2, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:24:53,768 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x2a053dbcd6899eeb: Processing first storage report for DS-4f8bde89-39bc-4664-8495-24db1fc9070c from datanode 2e7687d0-5262-40f4-b8e8-9f72db15646f
2020-12-03 07:24:53,768 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x2a053dbcd6899eeb: from storage DS-4f8bde89-39bc-4664-8495-24db1fc9070c node DatanodeRegistration(127.0.0.1:40699, datanodeUuid=2e7687d0-5262-40f4-b8e8-9f72db15646f, infoPort=38503, infoSecurePort=0, ipcPort=38380, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:53,768 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x2a053dbcd6899eeb,  containing 2 storage report(s), of which we sent 2. The reports had 3 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:53,768 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:53,867 [IPC Server handler 3 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:53,868 [Listener at localhost/38380] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:24:53,870 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:43954
2020-12-03 07:24:53,871 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2637)) - BLOCK* processReport 0xa0f7db8fbcc3a803: discarded non-initial block report from DatanodeRegistration(127.0.0.1:37054, datanodeUuid=2a2a30fb-7121-4535-8e69-ccc1d4e70ec3, infoPort=39686, infoSecurePort=0, ipcPort=43862, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566) because namenode still in startup phase
2020-12-03 07:24:53,871 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2637)) - BLOCK* processReport 0xa0f7db8fbcc3a803: discarded non-initial block report from DatanodeRegistration(127.0.0.1:37054, datanodeUuid=2a2a30fb-7121-4535-8e69-ccc1d4e70ec3, infoPort=39686, infoSecurePort=0, ipcPort=43862, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566) because namenode still in startup phase
2020-12-03 07:24:53,872 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xa0f7db8fbcc3a803,  containing 2 storage report(s), of which we sent 2. The reports had 3 total blocks and used 1 RPC(s). This took 1 msec to generate and 1 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:53,872 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:53,970 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:43954
2020-12-03 07:24:53,971 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2637)) - BLOCK* processReport 0x2a053dbcd6899eec: discarded non-initial block report from DatanodeRegistration(127.0.0.1:40699, datanodeUuid=2e7687d0-5262-40f4-b8e8-9f72db15646f, infoPort=38503, infoSecurePort=0, ipcPort=38380, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566) because namenode still in startup phase
2020-12-03 07:24:53,972 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2637)) - BLOCK* processReport 0x2a053dbcd6899eec: discarded non-initial block report from DatanodeRegistration(127.0.0.1:40699, datanodeUuid=2e7687d0-5262-40f4-b8e8-9f72db15646f, infoPort=38503, infoSecurePort=0, ipcPort=38380, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566) because namenode still in startup phase
2020-12-03 07:24:53,972 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x2a053dbcd6899eec,  containing 2 storage report(s), of which we sent 2. The reports had 3 total blocks and used 1 RPC(s). This took 0 msec to generate and 1 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:53,972 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:54,070 [Listener at localhost/38380] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:24:54,070 [Listener at localhost/38380] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:24:54,071 [Listener at localhost/38380] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:24:54,073 [Listener at localhost/38380] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:54,073 [Listener at localhost/38380] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:24:54,073 [Listener at localhost/38380] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:24:54,074 [Listener at localhost/38380] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:54,074 [Listener at localhost/38380] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:24:54,075 [Listener at localhost/38380] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:34930
2020-12-03 07:24:54,075 [Listener at localhost/38380] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:24:54,075 [Listener at localhost/38380] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:24:54,076 [Listener at localhost/38380] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:54,077 [Listener at localhost/38380] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:54,078 [Listener at localhost/38380] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:24:54,078 [Listener at localhost/38380] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:54,079 [Listener at localhost/38380] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:54,080 [Listener at localhost/38380] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:24:54,080 [Listener at localhost/38380] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:54,080 [Listener at localhost/38380] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:54,081 [Listener at localhost/38380] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 44527
2020-12-03 07:24:54,081 [Listener at localhost/38380] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:54,082 [Listener at localhost/38380] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@77da83ce{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:54,083 [Listener at localhost/38380] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7e33a5ee{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:54,087 [Listener at localhost/38380] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@75d817db{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:24:54,088 [Listener at localhost/38380] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@e7d2323{HTTP/1.1,[http/1.1]}{localhost:44527}
2020-12-03 07:24:54,088 [Listener at localhost/38380] INFO  server.Server (Server.java:doStart(419)) - Started @17841ms
2020-12-03 07:24:54,100 [Listener at localhost/38380] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:42048
2020-12-03 07:24:54,101 [Listener at localhost/38380] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:24:54,101 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@78e38795] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:54,101 [Listener at localhost/38380] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:24:54,101 [Listener at localhost/38380] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:54,102 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:54,105 [Listener at localhost/38111] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:38111
2020-12-03 07:24:54,108 [Listener at localhost/38111] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:24:54,108 [Listener at localhost/38111] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:24:54,108 [Thread-549] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43954 starting to offer service
2020-12-03 07:24:54,109 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:54,110 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:54,112 [Thread-549] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43954
2020-12-03 07:24:54,113 [Thread-549] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:24:54,113 [IPC Server handler 9 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:54,114 [Listener at localhost/38111] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:54,114 [Listener at localhost/38111] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:54,161 [Thread-549] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/in_use.lock acquired by nodename 11964@2bb02abc3fe0
2020-12-03 07:24:54,215 [IPC Server handler 0 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:54,216 [Listener at localhost/38111] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:54,216 [Listener at localhost/38111] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:54,294 [Thread-549] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/in_use.lock acquired by nodename 11964@2bb02abc3fe0
2020-12-03 07:24:54,317 [IPC Server handler 1 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:54,318 [Listener at localhost/38111] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:54,319 [Listener at localhost/38111] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:54,353 [Thread-549] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:54,353 [Thread-549] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:54,420 [IPC Server handler 2 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:54,421 [Listener at localhost/38111] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:54,421 [Listener at localhost/38111] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:54,436 [Thread-549] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:54,437 [Thread-549] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:54,471 [Thread-549] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=829214013;bpid=BP-1006108214-172.17.0.5-1606980278566;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=829214013;c=1606980278566;bpid=BP-1006108214-172.17.0.5-1606980278566;dnuuid=9ef29ebf-468b-497a-b175-e15a6fddabac
2020-12-03 07:24:54,474 [Thread-549] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-4a4533dc-c0f5-4eba-8ab7-8f9fd4e59ffc
2020-12-03 07:24:54,475 [Thread-549] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, StorageType: DISK
2020-12-03 07:24:54,476 [Thread-549] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-652cfcf7-8574-41cf-86aa-f7d20cbe2811
2020-12-03 07:24:54,476 [Thread-549] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, StorageType: DISK
2020-12-03 07:24:54,477 [Thread-549] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:24:54,477 [Thread-549] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:24:54,478 [Thread-549] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:24:54,478 [Thread-549] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:24:54,478 [Thread-549] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:24:54,479 [Thread-549] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:54,479 [Thread-562] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-12-03 07:24:54,479 [Thread-563] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-12-03 07:24:54,481 [Thread-563] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1006108214-172.17.0.5-1606980278566/current: 2138119
2020-12-03 07:24:54,481 [Thread-562] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1006108214-172.17.0.5-1606980278566/current: 3194894
2020-12-03 07:24:54,488 [Thread-562] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1006108214-172.17.0.5-1606980278566 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 9ms
2020-12-03 07:24:54,488 [Thread-563] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1006108214-172.17.0.5-1606980278566 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 9ms
2020-12-03 07:24:54,488 [Thread-549] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1006108214-172.17.0.5-1606980278566: 9ms
2020-12-03 07:24:54,488 [Thread-564] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-12-03 07:24:54,489 [Thread-565] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-12-03 07:24:54,489 [Thread-565] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(925)) - Successfully read replica from cache file : /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1006108214-172.17.0.5-1606980278566/current/replicas
2020-12-03 07:24:54,489 [Thread-564] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(925)) - Successfully read replica from cache file : /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1006108214-172.17.0.5-1606980278566/current/replicas
2020-12-03 07:24:54,489 [Thread-565] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 1ms
2020-12-03 07:24:54,489 [Thread-564] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 1ms
2020-12-03 07:24:54,490 [Thread-549] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1006108214-172.17.0.5-1606980278566: 2ms
2020-12-03 07:24:54,490 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-4a4533dc-c0f5-4eba-8ab7-8f9fd4e59ffc): no suitable block pools found to scan.  Waiting 1814389527 ms.
2020-12-03 07:24:54,491 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-652cfcf7-8574-41cf-86aa-f7d20cbe2811): no suitable block pools found to scan.  Waiting 1814389526 ms.
2020-12-03 07:24:54,491 [Thread-549] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 10:58 AM with interval of 21600000ms
2020-12-03 07:24:54,492 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1006108214-172.17.0.5-1606980278566 (Datanode Uuid 9ef29ebf-468b-497a-b175-e15a6fddabac) service to localhost/127.0.0.1:43954 beginning handshake with NN
2020-12-03 07:24:54,493 [IPC Server handler 3 on default port 43954] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34930, datanodeUuid=9ef29ebf-468b-497a-b175-e15a6fddabac, infoPort=42048, infoSecurePort=0, ipcPort=38111, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566) storage 9ef29ebf-468b-497a-b175-e15a6fddabac
2020-12-03 07:24:54,493 [IPC Server handler 3 on default port 43954] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:34930
2020-12-03 07:24:54,493 [IPC Server handler 3 on default port 43954] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 9ef29ebf-468b-497a-b175-e15a6fddabac (127.0.0.1:34930).
2020-12-03 07:24:54,494 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1006108214-172.17.0.5-1606980278566 (Datanode Uuid 9ef29ebf-468b-497a-b175-e15a6fddabac) service to localhost/127.0.0.1:43954 successfully registered with NN
2020-12-03 07:24:54,494 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:43954 using BLOCKREPORT_INTERVAL of 100msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:24:54,496 [IPC Server handler 4 on default port 43954] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-4a4533dc-c0f5-4eba-8ab7-8f9fd4e59ffc for DN 127.0.0.1:34930
2020-12-03 07:24:54,497 [IPC Server handler 4 on default port 43954] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-652cfcf7-8574-41cf-86aa-f7d20cbe2811 for DN 127.0.0.1:34930
2020-12-03 07:24:54,499 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x600536680c6338b: Processing first storage report for DS-4a4533dc-c0f5-4eba-8ab7-8f9fd4e59ffc from datanode 9ef29ebf-468b-497a-b175-e15a6fddabac
2020-12-03 07:24:54,499 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x600536680c6338b: from storage DS-4a4533dc-c0f5-4eba-8ab7-8f9fd4e59ffc node DatanodeRegistration(127.0.0.1:34930, datanodeUuid=9ef29ebf-468b-497a-b175-e15a6fddabac, infoPort=42048, infoSecurePort=0, ipcPort=38111, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566), blocks: 2, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:54,499 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x600536680c6338b: Processing first storage report for DS-652cfcf7-8574-41cf-86aa-f7d20cbe2811 from datanode 9ef29ebf-468b-497a-b175-e15a6fddabac
2020-12-03 07:24:54,499 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x600536680c6338b: from storage DS-652cfcf7-8574-41cf-86aa-f7d20cbe2811 node DatanodeRegistration(127.0.0.1:34930, datanodeUuid=9ef29ebf-468b-497a-b175-e15a6fddabac, infoPort=42048, infoSecurePort=0, ipcPort=38111, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:54,500 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x600536680c6338b,  containing 2 storage report(s), of which we sent 2. The reports had 3 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:54,500 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:54,522 [IPC Server handler 6 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:54,524 [Listener at localhost/38111] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:24:54,526 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:43954
2020-12-03 07:24:54,527 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2637)) - BLOCK* processReport 0xa0f7db8fbcc3a804: discarded non-initial block report from DatanodeRegistration(127.0.0.1:37054, datanodeUuid=2a2a30fb-7121-4535-8e69-ccc1d4e70ec3, infoPort=39686, infoSecurePort=0, ipcPort=43862, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566) because namenode still in startup phase
2020-12-03 07:24:54,527 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2637)) - BLOCK* processReport 0xa0f7db8fbcc3a804: discarded non-initial block report from DatanodeRegistration(127.0.0.1:37054, datanodeUuid=2a2a30fb-7121-4535-8e69-ccc1d4e70ec3, infoPort=39686, infoSecurePort=0, ipcPort=43862, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566) because namenode still in startup phase
2020-12-03 07:24:54,528 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xa0f7db8fbcc3a804,  containing 2 storage report(s), of which we sent 2. The reports had 3 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:54,528 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:54,626 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:43954
2020-12-03 07:24:54,627 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2637)) - BLOCK* processReport 0x2a053dbcd6899eed: discarded non-initial block report from DatanodeRegistration(127.0.0.1:40699, datanodeUuid=2e7687d0-5262-40f4-b8e8-9f72db15646f, infoPort=38503, infoSecurePort=0, ipcPort=38380, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566) because namenode still in startup phase
2020-12-03 07:24:54,627 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2637)) - BLOCK* processReport 0x2a053dbcd6899eed: discarded non-initial block report from DatanodeRegistration(127.0.0.1:40699, datanodeUuid=2e7687d0-5262-40f4-b8e8-9f72db15646f, infoPort=38503, infoSecurePort=0, ipcPort=38380, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566) because namenode still in startup phase
2020-12-03 07:24:54,628 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x2a053dbcd6899eed,  containing 2 storage report(s), of which we sent 2. The reports had 3 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:54,628 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:54,726 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:43954
2020-12-03 07:24:54,727 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2637)) - BLOCK* processReport 0x600536680c6338c: discarded non-initial block report from DatanodeRegistration(127.0.0.1:34930, datanodeUuid=9ef29ebf-468b-497a-b175-e15a6fddabac, infoPort=42048, infoSecurePort=0, ipcPort=38111, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566) because namenode still in startup phase
2020-12-03 07:24:54,728 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2637)) - BLOCK* processReport 0x600536680c6338c: discarded non-initial block report from DatanodeRegistration(127.0.0.1:34930, datanodeUuid=9ef29ebf-468b-497a-b175-e15a6fddabac, infoPort=42048, infoSecurePort=0, ipcPort=38111, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566) because namenode still in startup phase
2020-12-03 07:24:54,728 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x600536680c6338c,  containing 2 storage report(s), of which we sent 2. The reports had 3 total blocks and used 1 RPC(s). This took 1 msec to generate and 1 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:54,728 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:54,825 [Listener at localhost/38111] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:24:54,826 [Listener at localhost/38111] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:24:54,827 [Listener at localhost/38111] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:24:54,828 [Listener at localhost/38111] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:54,828 [Listener at localhost/38111] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:24:54,828 [Listener at localhost/38111] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:24:54,828 [Listener at localhost/38111] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:54,829 [Listener at localhost/38111] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:24:54,829 [Listener at localhost/38111] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:34116
2020-12-03 07:24:54,829 [Listener at localhost/38111] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:24:54,829 [Listener at localhost/38111] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:24:54,830 [Listener at localhost/38111] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:54,832 [Listener at localhost/38111] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:54,832 [Listener at localhost/38111] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:24:54,832 [Listener at localhost/38111] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:54,834 [Listener at localhost/38111] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:54,834 [Listener at localhost/38111] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:24:54,835 [Listener at localhost/38111] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:54,835 [Listener at localhost/38111] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:54,835 [Listener at localhost/38111] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 38359
2020-12-03 07:24:54,835 [Listener at localhost/38111] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:54,837 [Listener at localhost/38111] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1cd5c291{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:54,837 [Listener at localhost/38111] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@390ea2ed{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:54,842 [Listener at localhost/38111] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@c1bfd20{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:24:54,843 [Listener at localhost/38111] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@13363aef{HTTP/1.1,[http/1.1]}{localhost:38359}
2020-12-03 07:24:54,844 [Listener at localhost/38111] INFO  server.Server (Server.java:doStart(419)) - Started @18596ms
2020-12-03 07:24:54,856 [Listener at localhost/38111] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:44687
2020-12-03 07:24:54,857 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6a5276b1] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:54,857 [Listener at localhost/38111] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:24:54,857 [Listener at localhost/38111] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:24:54,858 [Listener at localhost/38111] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:54,858 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:54,861 [Listener at localhost/33588] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:33588
2020-12-03 07:24:54,864 [Listener at localhost/33588] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:24:54,865 [Listener at localhost/33588] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:24:54,865 [Thread-580] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43954 starting to offer service
2020-12-03 07:24:54,867 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:54,868 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:54,870 [Thread-580] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43954
2020-12-03 07:24:54,870 [Thread-580] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:24:54,872 [IPC Server handler 4 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:54,873 [Listener at localhost/33588] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:54,873 [Listener at localhost/33588] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:54,901 [Thread-580] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 11964@2bb02abc3fe0
2020-12-03 07:24:54,960 [Thread-580] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 11964@2bb02abc3fe0
2020-12-03 07:24:54,975 [IPC Server handler 5 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:54,976 [Listener at localhost/33588] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:54,976 [Listener at localhost/33588] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:54,993 [Thread-580] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:54,994 [Thread-580] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:55,036 [Thread-580] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:55,036 [Thread-580] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:55,062 [Thread-580] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=829214013;bpid=BP-1006108214-172.17.0.5-1606980278566;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=829214013;c=1606980278566;bpid=BP-1006108214-172.17.0.5-1606980278566;dnuuid=af552311-853c-41f7-a978-1842b97d4d48
2020-12-03 07:24:55,064 [Thread-580] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-0095e818-e243-4a1c-aa13-99da0fd9e056
2020-12-03 07:24:55,064 [Thread-580] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: DISK
2020-12-03 07:24:55,066 [Thread-580] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-f45a8750-594d-4642-87e3-93d21021bf5a
2020-12-03 07:24:55,067 [Thread-580] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: DISK
2020-12-03 07:24:55,068 [Thread-580] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:24:55,069 [Thread-580] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:24:55,070 [Thread-580] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:24:55,070 [Thread-580] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:24:55,071 [Thread-580] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:24:55,071 [Thread-580] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:55,072 [Thread-593] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:24:55,073 [Thread-593] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1006108214-172.17.0.5-1606980278566/current: 3194894
2020-12-03 07:24:55,074 [Thread-594] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:24:55,075 [Thread-594] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1006108214-172.17.0.5-1606980278566/current: 2138119
2020-12-03 07:24:55,077 [IPC Server handler 6 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:55,078 [Listener at localhost/33588] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:55,078 [Listener at localhost/33588] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:55,084 [Thread-593] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1006108214-172.17.0.5-1606980278566 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 12ms
2020-12-03 07:24:55,084 [Thread-594] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1006108214-172.17.0.5-1606980278566 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 10ms
2020-12-03 07:24:55,084 [Thread-580] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1006108214-172.17.0.5-1606980278566: 13ms
2020-12-03 07:24:55,085 [Thread-595] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:24:55,086 [Thread-595] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(925)) - Successfully read replica from cache file : /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1006108214-172.17.0.5-1606980278566/current/replicas
2020-12-03 07:24:55,086 [Thread-596] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:24:55,086 [Thread-595] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 1ms
2020-12-03 07:24:55,086 [Thread-596] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(925)) - Successfully read replica from cache file : /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1006108214-172.17.0.5-1606980278566/current/replicas
2020-12-03 07:24:55,087 [Thread-596] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 1ms
2020-12-03 07:24:55,087 [Thread-580] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1006108214-172.17.0.5-1606980278566: 2ms
2020-12-03 07:24:55,087 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-0095e818-e243-4a1c-aa13-99da0fd9e056): no suitable block pools found to scan.  Waiting 1814388974 ms.
2020-12-03 07:24:55,088 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-f45a8750-594d-4642-87e3-93d21021bf5a): no suitable block pools found to scan.  Waiting 1814388973 ms.
2020-12-03 07:24:55,088 [Thread-580] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:43 AM with interval of 21600000ms
2020-12-03 07:24:55,089 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1006108214-172.17.0.5-1606980278566 (Datanode Uuid af552311-853c-41f7-a978-1842b97d4d48) service to localhost/127.0.0.1:43954 beginning handshake with NN
2020-12-03 07:24:55,090 [IPC Server handler 7 on default port 43954] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34116, datanodeUuid=af552311-853c-41f7-a978-1842b97d4d48, infoPort=44687, infoSecurePort=0, ipcPort=33588, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566) storage af552311-853c-41f7-a978-1842b97d4d48
2020-12-03 07:24:55,090 [IPC Server handler 7 on default port 43954] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:34116
2020-12-03 07:24:55,090 [IPC Server handler 7 on default port 43954] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN af552311-853c-41f7-a978-1842b97d4d48 (127.0.0.1:34116).
2020-12-03 07:24:55,091 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1006108214-172.17.0.5-1606980278566 (Datanode Uuid af552311-853c-41f7-a978-1842b97d4d48) service to localhost/127.0.0.1:43954 successfully registered with NN
2020-12-03 07:24:55,091 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:43954 using BLOCKREPORT_INTERVAL of 100msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:24:55,093 [IPC Server handler 8 on default port 43954] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-0095e818-e243-4a1c-aa13-99da0fd9e056 for DN 127.0.0.1:34116
2020-12-03 07:24:55,093 [IPC Server handler 8 on default port 43954] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-f45a8750-594d-4642-87e3-93d21021bf5a for DN 127.0.0.1:34116
2020-12-03 07:24:55,095 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x690ca83591fc4db3: Processing first storage report for DS-f45a8750-594d-4642-87e3-93d21021bf5a from datanode af552311-853c-41f7-a978-1842b97d4d48
2020-12-03 07:24:55,095 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x690ca83591fc4db3: from storage DS-f45a8750-594d-4642-87e3-93d21021bf5a node DatanodeRegistration(127.0.0.1:34116, datanodeUuid=af552311-853c-41f7-a978-1842b97d4d48, infoPort=44687, infoSecurePort=0, ipcPort=33588, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566), blocks: 1, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:55,095 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x690ca83591fc4db3: Processing first storage report for DS-0095e818-e243-4a1c-aa13-99da0fd9e056 from datanode af552311-853c-41f7-a978-1842b97d4d48
2020-12-03 07:24:55,095 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x690ca83591fc4db3: from storage DS-0095e818-e243-4a1c-aa13-99da0fd9e056 node DatanodeRegistration(127.0.0.1:34116, datanodeUuid=af552311-853c-41f7-a978-1842b97d4d48, infoPort=44687, infoSecurePort=0, ipcPort=33588, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566), blocks: 2, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:24:55,096 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x690ca83591fc4db3,  containing 2 storage report(s), of which we sent 2. The reports had 3 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:55,096 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:55,179 [IPC Server handler 0 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:55,180 [Listener at localhost/33588] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:24:55,182 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:43954
2020-12-03 07:24:55,183 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2637)) - BLOCK* processReport 0xa0f7db8fbcc3a805: discarded non-initial block report from DatanodeRegistration(127.0.0.1:37054, datanodeUuid=2a2a30fb-7121-4535-8e69-ccc1d4e70ec3, infoPort=39686, infoSecurePort=0, ipcPort=43862, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566) because namenode still in startup phase
2020-12-03 07:24:55,183 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2637)) - BLOCK* processReport 0xa0f7db8fbcc3a805: discarded non-initial block report from DatanodeRegistration(127.0.0.1:37054, datanodeUuid=2a2a30fb-7121-4535-8e69-ccc1d4e70ec3, infoPort=39686, infoSecurePort=0, ipcPort=43862, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566) because namenode still in startup phase
2020-12-03 07:24:55,184 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xa0f7db8fbcc3a805,  containing 2 storage report(s), of which we sent 2. The reports had 3 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:55,184 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:55,282 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:43954
2020-12-03 07:24:55,283 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2637)) - BLOCK* processReport 0x2a053dbcd6899eee: discarded non-initial block report from DatanodeRegistration(127.0.0.1:40699, datanodeUuid=2e7687d0-5262-40f4-b8e8-9f72db15646f, infoPort=38503, infoSecurePort=0, ipcPort=38380, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566) because namenode still in startup phase
2020-12-03 07:24:55,283 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2637)) - BLOCK* processReport 0x2a053dbcd6899eee: discarded non-initial block report from DatanodeRegistration(127.0.0.1:40699, datanodeUuid=2e7687d0-5262-40f4-b8e8-9f72db15646f, infoPort=38503, infoSecurePort=0, ipcPort=38380, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566) because namenode still in startup phase
2020-12-03 07:24:55,284 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x2a053dbcd6899eee,  containing 2 storage report(s), of which we sent 2. The reports had 3 total blocks and used 1 RPC(s). This took 1 msec to generate and 1 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:55,284 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:55,382 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:43954
2020-12-03 07:24:55,383 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2637)) - BLOCK* processReport 0x600536680c6338d: discarded non-initial block report from DatanodeRegistration(127.0.0.1:34930, datanodeUuid=9ef29ebf-468b-497a-b175-e15a6fddabac, infoPort=42048, infoSecurePort=0, ipcPort=38111, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566) because namenode still in startup phase
2020-12-03 07:24:55,383 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2637)) - BLOCK* processReport 0x600536680c6338d: discarded non-initial block report from DatanodeRegistration(127.0.0.1:34930, datanodeUuid=9ef29ebf-468b-497a-b175-e15a6fddabac, infoPort=42048, infoSecurePort=0, ipcPort=38111, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566) because namenode still in startup phase
2020-12-03 07:24:55,384 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x600536680c6338d,  containing 2 storage report(s), of which we sent 2. The reports had 3 total blocks and used 1 RPC(s). This took 1 msec to generate and 1 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:55,384 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:55,482 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:43954
2020-12-03 07:24:55,483 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2637)) - BLOCK* processReport 0x690ca83591fc4db4: discarded non-initial block report from DatanodeRegistration(127.0.0.1:34116, datanodeUuid=af552311-853c-41f7-a978-1842b97d4d48, infoPort=44687, infoSecurePort=0, ipcPort=33588, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566) because namenode still in startup phase
2020-12-03 07:24:55,483 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2637)) - BLOCK* processReport 0x690ca83591fc4db4: discarded non-initial block report from DatanodeRegistration(127.0.0.1:34116, datanodeUuid=af552311-853c-41f7-a978-1842b97d4d48, infoPort=44687, infoSecurePort=0, ipcPort=33588, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566) because namenode still in startup phase
2020-12-03 07:24:55,484 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x690ca83591fc4db4,  containing 2 storage report(s), of which we sent 2. The reports had 3 total blocks and used 1 RPC(s). This took 0 msec to generate and 1 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:55,484 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:55,582 [Listener at localhost/33588] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:24:55,582 [Listener at localhost/33588] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:24:55,584 [Listener at localhost/33588] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:24:55,584 [Listener at localhost/33588] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:55,584 [Listener at localhost/33588] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:24:55,585 [Listener at localhost/33588] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:24:55,585 [Listener at localhost/33588] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:55,585 [Listener at localhost/33588] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:24:55,585 [Listener at localhost/33588] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:35170
2020-12-03 07:24:55,586 [Listener at localhost/33588] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:24:55,586 [Listener at localhost/33588] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:24:55,586 [Listener at localhost/33588] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:55,588 [Listener at localhost/33588] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:55,589 [Listener at localhost/33588] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:24:55,589 [Listener at localhost/33588] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:55,591 [Listener at localhost/33588] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:55,591 [Listener at localhost/33588] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:24:55,591 [Listener at localhost/33588] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:55,591 [Listener at localhost/33588] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:55,592 [Listener at localhost/33588] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 46686
2020-12-03 07:24:55,592 [Listener at localhost/33588] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:55,594 [Listener at localhost/33588] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7271ef47{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:55,595 [Listener at localhost/33588] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5f9bf061{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:55,600 [Listener at localhost/33588] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@47d497e7{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:24:55,601 [Listener at localhost/33588] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@48bc24cf{HTTP/1.1,[http/1.1]}{localhost:46686}
2020-12-03 07:24:55,601 [Listener at localhost/33588] INFO  server.Server (Server.java:doStart(419)) - Started @19353ms
2020-12-03 07:24:55,613 [Listener at localhost/33588] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:41003
2020-12-03 07:24:55,613 [Listener at localhost/33588] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:24:55,613 [Listener at localhost/33588] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:24:55,613 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@23bacf68] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:55,614 [Listener at localhost/33588] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:55,615 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:55,621 [Listener at localhost/44265] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:44265
2020-12-03 07:24:55,624 [Listener at localhost/44265] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:24:55,625 [Listener at localhost/44265] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:24:55,625 [Thread-611] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43954 starting to offer service
2020-12-03 07:24:55,628 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:55,629 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:55,631 [Thread-611] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43954
2020-12-03 07:24:55,631 [Thread-611] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:24:55,633 [IPC Server handler 0 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:55,634 [Listener at localhost/44265] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:55,634 [Listener at localhost/44265] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:55,665 [Thread-611] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 11964@2bb02abc3fe0
2020-12-03 07:24:55,716 [Thread-611] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 11964@2bb02abc3fe0
2020-12-03 07:24:55,735 [IPC Server handler 1 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:55,736 [Listener at localhost/44265] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:55,736 [Listener at localhost/44265] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:55,748 [Thread-611] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:55,748 [Thread-611] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:55,782 [Thread-611] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:55,782 [Thread-611] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:55,834 [Thread-611] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=829214013;bpid=BP-1006108214-172.17.0.5-1606980278566;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=829214013;c=1606980278566;bpid=BP-1006108214-172.17.0.5-1606980278566;dnuuid=65fee986-f2dc-4671-a566-834a8ba38ec2
2020-12-03 07:24:55,835 [Thread-611] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-86b77411-628e-439a-83fb-b288094a00ab
2020-12-03 07:24:55,835 [Thread-611] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-12-03 07:24:55,837 [IPC Server handler 2 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:55,838 [Thread-611] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-519a1287-ec06-4bbf-8d21-79dbaca51fcb
2020-12-03 07:24:55,838 [Thread-611] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-12-03 07:24:55,839 [Listener at localhost/44265] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:55,839 [Thread-611] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:24:55,839 [Listener at localhost/44265] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:55,840 [Thread-611] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:24:55,840 [Thread-611] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:24:55,840 [Thread-611] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:24:55,841 [Thread-611] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:24:55,841 [Thread-611] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:55,842 [Thread-624] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:24:55,842 [Thread-625] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:24:55,843 [Thread-624] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1006108214-172.17.0.5-1606980278566/current: 2138119
2020-12-03 07:24:55,843 [Thread-625] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1006108214-172.17.0.5-1606980278566/current: 2138119
2020-12-03 07:24:55,850 [Thread-625] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1006108214-172.17.0.5-1606980278566 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 8ms
2020-12-03 07:24:55,850 [Thread-624] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1006108214-172.17.0.5-1606980278566 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 8ms
2020-12-03 07:24:55,851 [Thread-611] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1006108214-172.17.0.5-1606980278566: 9ms
2020-12-03 07:24:55,851 [Thread-626] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:24:55,851 [Thread-627] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:24:55,852 [Thread-627] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(925)) - Successfully read replica from cache file : /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1006108214-172.17.0.5-1606980278566/current/replicas
2020-12-03 07:24:55,852 [Thread-626] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(925)) - Successfully read replica from cache file : /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1006108214-172.17.0.5-1606980278566/current/replicas
2020-12-03 07:24:55,852 [Thread-627] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 1ms
2020-12-03 07:24:55,852 [Thread-626] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 1ms
2020-12-03 07:24:55,852 [Thread-611] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1006108214-172.17.0.5-1606980278566: 2ms
2020-12-03 07:24:55,853 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-519a1287-ec06-4bbf-8d21-79dbaca51fcb): no suitable block pools found to scan.  Waiting 1814388227 ms.
2020-12-03 07:24:55,853 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-86b77411-628e-439a-83fb-b288094a00ab): no suitable block pools found to scan.  Waiting 1814388227 ms.
2020-12-03 07:24:55,854 [Thread-611] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:55 AM with interval of 21600000ms
2020-12-03 07:24:55,854 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1006108214-172.17.0.5-1606980278566 (Datanode Uuid 65fee986-f2dc-4671-a566-834a8ba38ec2) service to localhost/127.0.0.1:43954 beginning handshake with NN
2020-12-03 07:24:55,856 [IPC Server handler 3 on default port 43954] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35170, datanodeUuid=65fee986-f2dc-4671-a566-834a8ba38ec2, infoPort=41003, infoSecurePort=0, ipcPort=44265, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566) storage 65fee986-f2dc-4671-a566-834a8ba38ec2
2020-12-03 07:24:55,856 [IPC Server handler 3 on default port 43954] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:35170
2020-12-03 07:24:55,856 [IPC Server handler 3 on default port 43954] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 65fee986-f2dc-4671-a566-834a8ba38ec2 (127.0.0.1:35170).
2020-12-03 07:24:55,857 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1006108214-172.17.0.5-1606980278566 (Datanode Uuid 65fee986-f2dc-4671-a566-834a8ba38ec2) service to localhost/127.0.0.1:43954 successfully registered with NN
2020-12-03 07:24:55,857 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:43954 using BLOCKREPORT_INTERVAL of 100msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:24:55,859 [IPC Server handler 4 on default port 43954] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-86b77411-628e-439a-83fb-b288094a00ab for DN 127.0.0.1:35170
2020-12-03 07:24:55,859 [IPC Server handler 4 on default port 43954] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-519a1287-ec06-4bbf-8d21-79dbaca51fcb for DN 127.0.0.1:35170
2020-12-03 07:24:55,860 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x69cc4790095936da: Processing first storage report for DS-519a1287-ec06-4bbf-8d21-79dbaca51fcb from datanode 65fee986-f2dc-4671-a566-834a8ba38ec2
2020-12-03 07:24:55,861 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x69cc4790095936da: from storage DS-519a1287-ec06-4bbf-8d21-79dbaca51fcb node DatanodeRegistration(127.0.0.1:35170, datanodeUuid=65fee986-f2dc-4671-a566-834a8ba38ec2, infoPort=41003, infoSecurePort=0, ipcPort=44265, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566), blocks: 1, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:55,861 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x69cc4790095936da: Processing first storage report for DS-86b77411-628e-439a-83fb-b288094a00ab from datanode 65fee986-f2dc-4671-a566-834a8ba38ec2
2020-12-03 07:24:55,861 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x69cc4790095936da: from storage DS-86b77411-628e-439a-83fb-b288094a00ab node DatanodeRegistration(127.0.0.1:35170, datanodeUuid=65fee986-f2dc-4671-a566-834a8ba38ec2, infoPort=41003, infoSecurePort=0, ipcPort=44265, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:55,862 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x69cc4790095936da,  containing 2 storage report(s), of which we sent 2. The reports had 2 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:55,862 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:55,940 [IPC Server handler 6 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:55,941 [Listener at localhost/44265] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:24:55,943 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:43954
2020-12-03 07:24:55,944 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2637)) - BLOCK* processReport 0xa0f7db8fbcc3a806: discarded non-initial block report from DatanodeRegistration(127.0.0.1:37054, datanodeUuid=2a2a30fb-7121-4535-8e69-ccc1d4e70ec3, infoPort=39686, infoSecurePort=0, ipcPort=43862, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566) because namenode still in startup phase
2020-12-03 07:24:55,944 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2637)) - BLOCK* processReport 0xa0f7db8fbcc3a806: discarded non-initial block report from DatanodeRegistration(127.0.0.1:37054, datanodeUuid=2a2a30fb-7121-4535-8e69-ccc1d4e70ec3, infoPort=39686, infoSecurePort=0, ipcPort=43862, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566) because namenode still in startup phase
2020-12-03 07:24:55,945 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xa0f7db8fbcc3a806,  containing 2 storage report(s), of which we sent 2. The reports had 3 total blocks and used 1 RPC(s). This took 1 msec to generate and 1 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:55,945 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:56,043 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:43954
2020-12-03 07:24:56,044 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2637)) - BLOCK* processReport 0x2a053dbcd6899eef: discarded non-initial block report from DatanodeRegistration(127.0.0.1:40699, datanodeUuid=2e7687d0-5262-40f4-b8e8-9f72db15646f, infoPort=38503, infoSecurePort=0, ipcPort=38380, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566) because namenode still in startup phase
2020-12-03 07:24:56,045 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2637)) - BLOCK* processReport 0x2a053dbcd6899eef: discarded non-initial block report from DatanodeRegistration(127.0.0.1:40699, datanodeUuid=2e7687d0-5262-40f4-b8e8-9f72db15646f, infoPort=38503, infoSecurePort=0, ipcPort=38380, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566) because namenode still in startup phase
2020-12-03 07:24:56,045 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x2a053dbcd6899eef,  containing 2 storage report(s), of which we sent 2. The reports had 3 total blocks and used 1 RPC(s). This took 0 msec to generate and 1 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:56,045 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:56,143 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:43954
2020-12-03 07:24:56,144 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2637)) - BLOCK* processReport 0x600536680c6338e: discarded non-initial block report from DatanodeRegistration(127.0.0.1:34930, datanodeUuid=9ef29ebf-468b-497a-b175-e15a6fddabac, infoPort=42048, infoSecurePort=0, ipcPort=38111, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566) because namenode still in startup phase
2020-12-03 07:24:56,144 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2637)) - BLOCK* processReport 0x600536680c6338e: discarded non-initial block report from DatanodeRegistration(127.0.0.1:34930, datanodeUuid=9ef29ebf-468b-497a-b175-e15a6fddabac, infoPort=42048, infoSecurePort=0, ipcPort=38111, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566) because namenode still in startup phase
2020-12-03 07:24:56,145 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x600536680c6338e,  containing 2 storage report(s), of which we sent 2. The reports had 3 total blocks and used 1 RPC(s). This took 1 msec to generate and 1 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:56,145 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:56,244 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:43954
2020-12-03 07:24:56,245 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2637)) - BLOCK* processReport 0x690ca83591fc4db5: discarded non-initial block report from DatanodeRegistration(127.0.0.1:34116, datanodeUuid=af552311-853c-41f7-a978-1842b97d4d48, infoPort=44687, infoSecurePort=0, ipcPort=33588, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566) because namenode still in startup phase
2020-12-03 07:24:56,245 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2637)) - BLOCK* processReport 0x690ca83591fc4db5: discarded non-initial block report from DatanodeRegistration(127.0.0.1:34116, datanodeUuid=af552311-853c-41f7-a978-1842b97d4d48, infoPort=44687, infoSecurePort=0, ipcPort=33588, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566) because namenode still in startup phase
2020-12-03 07:24:56,245 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x690ca83591fc4db5,  containing 2 storage report(s), of which we sent 2. The reports had 3 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:56,245 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:56,343 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:43954
2020-12-03 07:24:56,344 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2637)) - BLOCK* processReport 0x69cc4790095936db: discarded non-initial block report from DatanodeRegistration(127.0.0.1:35170, datanodeUuid=65fee986-f2dc-4671-a566-834a8ba38ec2, infoPort=41003, infoSecurePort=0, ipcPort=44265, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566) because namenode still in startup phase
2020-12-03 07:24:56,345 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2637)) - BLOCK* processReport 0x69cc4790095936db: discarded non-initial block report from DatanodeRegistration(127.0.0.1:35170, datanodeUuid=65fee986-f2dc-4671-a566-834a8ba38ec2, infoPort=41003, infoSecurePort=0, ipcPort=44265, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566) because namenode still in startup phase
2020-12-03 07:24:56,345 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x69cc4790095936db,  containing 2 storage report(s), of which we sent 2. The reports had 2 total blocks and used 1 RPC(s). This took 0 msec to generate and 1 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:56,345 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:56,444 [Listener at localhost/44265] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:24:56,444 [Listener at localhost/44265] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:24:56,445 [Listener at localhost/44265] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:24:56,446 [Listener at localhost/44265] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:56,446 [Listener at localhost/44265] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:24:56,447 [Listener at localhost/44265] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:24:56,447 [Listener at localhost/44265] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:56,447 [Listener at localhost/44265] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:24:56,447 [Listener at localhost/44265] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:46556
2020-12-03 07:24:56,448 [Listener at localhost/44265] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:24:56,448 [Listener at localhost/44265] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:24:56,449 [Listener at localhost/44265] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:56,450 [Listener at localhost/44265] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:56,450 [Listener at localhost/44265] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:24:56,451 [Listener at localhost/44265] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:56,452 [Listener at localhost/44265] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:56,453 [Listener at localhost/44265] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:24:56,453 [Listener at localhost/44265] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:56,453 [Listener at localhost/44265] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:56,453 [Listener at localhost/44265] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 43364
2020-12-03 07:24:56,454 [Listener at localhost/44265] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:56,455 [Listener at localhost/44265] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@55819061{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:56,455 [Listener at localhost/44265] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@e2cea{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:56,460 [Listener at localhost/44265] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@10f567cb{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:24:56,460 [Listener at localhost/44265] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@55d92fa8{HTTP/1.1,[http/1.1]}{localhost:43364}
2020-12-03 07:24:56,461 [Listener at localhost/44265] INFO  server.Server (Server.java:doStart(419)) - Started @20213ms
2020-12-03 07:24:56,474 [Listener at localhost/44265] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:41710
2020-12-03 07:24:56,474 [Listener at localhost/44265] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:24:56,474 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@729ba2e6] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:56,474 [Listener at localhost/44265] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:24:56,475 [Listener at localhost/44265] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:56,475 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:56,478 [Listener at localhost/41609] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:41609
2020-12-03 07:24:56,481 [Listener at localhost/41609] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:24:56,482 [Listener at localhost/41609] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:24:56,482 [Thread-642] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43954 starting to offer service
2020-12-03 07:24:56,484 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:56,484 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:56,487 [Thread-642] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43954
2020-12-03 07:24:56,487 [Thread-642] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:24:56,489 [IPC Server handler 8 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:56,490 [Listener at localhost/41609] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:56,490 [Listener at localhost/41609] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:56,528 [Thread-642] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 11964@2bb02abc3fe0
2020-12-03 07:24:56,591 [IPC Server handler 9 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:56,592 [Listener at localhost/41609] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:56,593 [Listener at localhost/41609] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:56,648 [Thread-642] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 11964@2bb02abc3fe0
2020-12-03 07:24:56,694 [IPC Server handler 0 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:56,695 [Listener at localhost/41609] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:56,695 [Listener at localhost/41609] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:56,709 [Thread-642] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:56,710 [Thread-642] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:56,780 [Thread-642] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:56,781 [Thread-642] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:56,796 [IPC Server handler 1 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:56,798 [Listener at localhost/41609] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:56,798 [Listener at localhost/41609] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:56,899 [IPC Server handler 2 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:56,900 [Listener at localhost/41609] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:56,900 [Listener at localhost/41609] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:57,001 [IPC Server handler 3 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:57,002 [Listener at localhost/41609] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:57,002 [Listener at localhost/41609] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:57,103 [IPC Server handler 4 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:57,104 [Listener at localhost/41609] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:57,104 [Listener at localhost/41609] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:57,204 [IPC Server handler 5 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:57,205 [Listener at localhost/41609] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:57,205 [Listener at localhost/41609] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:57,208 [Thread-642] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=829214013;bpid=BP-1006108214-172.17.0.5-1606980278566;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=829214013;c=1606980278566;bpid=BP-1006108214-172.17.0.5-1606980278566;dnuuid=85df5b2e-a97a-41c1-835b-035a6b9b8a7e
2020-12-03 07:24:57,210 [Thread-642] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-c003fc79-c50f-47e0-92be-1300d56d1d0d
2020-12-03 07:24:57,210 [Thread-642] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, StorageType: DISK
2020-12-03 07:24:57,212 [Thread-642] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-bd1ff44c-a092-4057-b4a3-2c31abfa7ab4
2020-12-03 07:24:57,213 [Thread-642] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, StorageType: DISK
2020-12-03 07:24:57,214 [Thread-642] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:24:57,214 [Thread-642] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:24:57,215 [Thread-642] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:24:57,215 [Thread-642] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:24:57,215 [Thread-642] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:24:57,216 [Thread-642] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:57,217 [Thread-655] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:24:57,217 [Thread-656] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:24:57,218 [Thread-655] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1006108214-172.17.0.5-1606980278566/current: 2138119
2020-12-03 07:24:57,218 [Thread-656] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(292)) - Cached dfsUsed found for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1006108214-172.17.0.5-1606980278566/current: 2138119
2020-12-03 07:24:57,225 [Thread-655] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1006108214-172.17.0.5-1606980278566 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 8ms
2020-12-03 07:24:57,225 [Thread-656] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1006108214-172.17.0.5-1606980278566 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 8ms
2020-12-03 07:24:57,226 [Thread-642] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1006108214-172.17.0.5-1606980278566: 9ms
2020-12-03 07:24:57,226 [Thread-657] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:24:57,226 [Thread-658] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:24:57,227 [Thread-657] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(925)) - Successfully read replica from cache file : /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1006108214-172.17.0.5-1606980278566/current/replicas
2020-12-03 07:24:57,227 [Thread-658] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(925)) - Successfully read replica from cache file : /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1006108214-172.17.0.5-1606980278566/current/replicas
2020-12-03 07:24:57,227 [Thread-657] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 2ms
2020-12-03 07:24:57,227 [Thread-658] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1006108214-172.17.0.5-1606980278566 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 1ms
2020-12-03 07:24:57,227 [Thread-642] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1006108214-172.17.0.5-1606980278566: 2ms
2020-12-03 07:24:57,228 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-bd1ff44c-a092-4057-b4a3-2c31abfa7ab4): no suitable block pools found to scan.  Waiting 1814386806 ms.
2020-12-03 07:24:57,228 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-c003fc79-c50f-47e0-92be-1300d56d1d0d): no suitable block pools found to scan.  Waiting 1814386806 ms.
2020-12-03 07:24:57,229 [Thread-642] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:35 AM with interval of 21600000ms
2020-12-03 07:24:57,229 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1006108214-172.17.0.5-1606980278566 (Datanode Uuid 85df5b2e-a97a-41c1-835b-035a6b9b8a7e) service to localhost/127.0.0.1:43954 beginning handshake with NN
2020-12-03 07:24:57,230 [IPC Server handler 6 on default port 43954] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:46556, datanodeUuid=85df5b2e-a97a-41c1-835b-035a6b9b8a7e, infoPort=41710, infoSecurePort=0, ipcPort=41609, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566) storage 85df5b2e-a97a-41c1-835b-035a6b9b8a7e
2020-12-03 07:24:57,231 [IPC Server handler 6 on default port 43954] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:46556
2020-12-03 07:24:57,231 [IPC Server handler 6 on default port 43954] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 85df5b2e-a97a-41c1-835b-035a6b9b8a7e (127.0.0.1:46556).
2020-12-03 07:24:57,231 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1006108214-172.17.0.5-1606980278566 (Datanode Uuid 85df5b2e-a97a-41c1-835b-035a6b9b8a7e) service to localhost/127.0.0.1:43954 successfully registered with NN
2020-12-03 07:24:57,232 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:43954 using BLOCKREPORT_INTERVAL of 100msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:24:57,234 [IPC Server handler 7 on default port 43954] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c003fc79-c50f-47e0-92be-1300d56d1d0d for DN 127.0.0.1:46556
2020-12-03 07:24:57,234 [IPC Server handler 7 on default port 43954] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-bd1ff44c-a092-4057-b4a3-2c31abfa7ab4 for DN 127.0.0.1:46556
2020-12-03 07:24:57,236 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xaf18bd90059a1561: Processing first storage report for DS-c003fc79-c50f-47e0-92be-1300d56d1d0d from datanode 85df5b2e-a97a-41c1-835b-035a6b9b8a7e
2020-12-03 07:24:57,236 [Block report processor] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:24:57,237 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(395)) - STATE* Safe mode is OFF
2020-12-03 07:24:57,237 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 9 secs
2020-12-03 07:24:57,237 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 1 racks and 6 datanodes
2020-12-03 07:24:57,237 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:24:57,237 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xaf18bd90059a1561: from storage DS-c003fc79-c50f-47e0-92be-1300d56d1d0d node DatanodeRegistration(127.0.0.1:46556, datanodeUuid=85df5b2e-a97a-41c1-835b-035a6b9b8a7e, infoPort=41710, infoSecurePort=0, ipcPort=41609, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566), blocks: 1, hasStaleStorage: true, processing time: 2 msecs, invalidatedBlocks: 0
2020-12-03 07:24:57,241 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 3
2020-12-03 07:24:57,241 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:24:57,241 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 2
2020-12-03 07:24:57,241 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:24:57,242 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:24:57,242 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 5 msec
2020-12-03 07:24:57,242 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xaf18bd90059a1561: Processing first storage report for DS-bd1ff44c-a092-4057-b4a3-2c31abfa7ab4 from datanode 85df5b2e-a97a-41c1-835b-035a6b9b8a7e
2020-12-03 07:24:57,243 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xaf18bd90059a1561: from storage DS-bd1ff44c-a092-4057-b4a3-2c31abfa7ab4 node DatanodeRegistration(127.0.0.1:46556, datanodeUuid=85df5b2e-a97a-41c1-835b-035a6b9b8a7e, infoPort=41710, infoSecurePort=0, ipcPort=41609, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566), blocks: 1, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:24:57,244 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xaf18bd90059a1561,  containing 2 storage report(s), of which we sent 2. The reports had 2 total blocks and used 1 RPC(s). This took 0 msec to generate and 9 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:57,244 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:57,307 [IPC Server handler 9 on default port 43954] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:57,308 [Listener at localhost/41609] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:24:57,310 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:43954
2020-12-03 07:24:57,311 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xa0f7db8fbcc3a807: from storage DS-36579057-efca-436e-8f83-6abab3daf2e6 node DatanodeRegistration(127.0.0.1:37054, datanodeUuid=2a2a30fb-7121-4535-8e69-ccc1d4e70ec3, infoPort=39686, infoSecurePort=0, ipcPort=43862, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:57,311 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xa0f7db8fbcc3a807: from storage DS-5a11274f-c1da-45a9-aa5e-f76140593ef7 node DatanodeRegistration(127.0.0.1:37054, datanodeUuid=2a2a30fb-7121-4535-8e69-ccc1d4e70ec3, infoPort=39686, infoSecurePort=0, ipcPort=43862, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566), blocks: 2, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:57,312 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xa0f7db8fbcc3a807,  containing 2 storage report(s), of which we sent 2. The reports had 3 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:57,312 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:57,410 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:43954
2020-12-03 07:24:57,411 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x2a053dbcd6899ef0: from storage DS-fee6374f-fab9-484b-840a-3bb039765f1d node DatanodeRegistration(127.0.0.1:40699, datanodeUuid=2e7687d0-5262-40f4-b8e8-9f72db15646f, infoPort=38503, infoSecurePort=0, ipcPort=38380, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566), blocks: 2, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:57,411 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x2a053dbcd6899ef0: from storage DS-4f8bde89-39bc-4664-8495-24db1fc9070c node DatanodeRegistration(127.0.0.1:40699, datanodeUuid=2e7687d0-5262-40f4-b8e8-9f72db15646f, infoPort=38503, infoSecurePort=0, ipcPort=38380, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:57,411 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x2a053dbcd6899ef0,  containing 2 storage report(s), of which we sent 2. The reports had 3 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:57,412 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:57,510 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:43954
2020-12-03 07:24:57,511 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x600536680c6338f: from storage DS-4a4533dc-c0f5-4eba-8ab7-8f9fd4e59ffc node DatanodeRegistration(127.0.0.1:34930, datanodeUuid=9ef29ebf-468b-497a-b175-e15a6fddabac, infoPort=42048, infoSecurePort=0, ipcPort=38111, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566), blocks: 2, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:57,511 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x600536680c6338f: from storage DS-652cfcf7-8574-41cf-86aa-f7d20cbe2811 node DatanodeRegistration(127.0.0.1:34930, datanodeUuid=9ef29ebf-468b-497a-b175-e15a6fddabac, infoPort=42048, infoSecurePort=0, ipcPort=38111, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:57,512 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x600536680c6338f,  containing 2 storage report(s), of which we sent 2. The reports had 3 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:57,512 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:57,610 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:43954
2020-12-03 07:24:57,611 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x690ca83591fc4db6: from storage DS-f45a8750-594d-4642-87e3-93d21021bf5a node DatanodeRegistration(127.0.0.1:34116, datanodeUuid=af552311-853c-41f7-a978-1842b97d4d48, infoPort=44687, infoSecurePort=0, ipcPort=33588, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:57,611 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x690ca83591fc4db6: from storage DS-0095e818-e243-4a1c-aa13-99da0fd9e056 node DatanodeRegistration(127.0.0.1:34116, datanodeUuid=af552311-853c-41f7-a978-1842b97d4d48, infoPort=44687, infoSecurePort=0, ipcPort=33588, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566), blocks: 2, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:57,611 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x690ca83591fc4db6,  containing 2 storage report(s), of which we sent 2. The reports had 3 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:57,612 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:57,710 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:43954
2020-12-03 07:24:57,711 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x69cc4790095936dc: from storage DS-519a1287-ec06-4bbf-8d21-79dbaca51fcb node DatanodeRegistration(127.0.0.1:35170, datanodeUuid=65fee986-f2dc-4671-a566-834a8ba38ec2, infoPort=41003, infoSecurePort=0, ipcPort=44265, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:57,712 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x69cc4790095936dc: from storage DS-86b77411-628e-439a-83fb-b288094a00ab node DatanodeRegistration(127.0.0.1:35170, datanodeUuid=65fee986-f2dc-4671-a566-834a8ba38ec2, infoPort=41003, infoSecurePort=0, ipcPort=44265, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:57,712 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x69cc4790095936dc,  containing 2 storage report(s), of which we sent 2. The reports had 2 total blocks and used 1 RPC(s). This took 0 msec to generate and 1 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:57,712 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:57,810 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:43954
2020-12-03 07:24:57,811 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xaf18bd90059a1562: from storage DS-c003fc79-c50f-47e0-92be-1300d56d1d0d node DatanodeRegistration(127.0.0.1:46556, datanodeUuid=85df5b2e-a97a-41c1-835b-035a6b9b8a7e, infoPort=41710, infoSecurePort=0, ipcPort=41609, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566), blocks: 1, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:24:57,812 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xaf18bd90059a1562: from storage DS-bd1ff44c-a092-4057-b4a3-2c31abfa7ab4 node DatanodeRegistration(127.0.0.1:46556, datanodeUuid=85df5b2e-a97a-41c1-835b-035a6b9b8a7e, infoPort=41710, infoSecurePort=0, ipcPort=41609, storageInfo=lv=-57;cid=testClusterID;nsid=829214013;c=1606980278566), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:57,812 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xaf18bd90059a1562,  containing 2 storage report(s), of which we sent 2. The reports had 2 total blocks and used 1 RPC(s). This took 0 msec to generate and 1 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:57,812 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:57,909 [Listener at localhost/41609] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:24:57,910 [Listener at localhost/41609] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 5
2020-12-03 07:24:57,910 [Listener at localhost/41609] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:24:57,910 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@5a742a9a] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:24:57,911 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-bd1ff44c-a092-4057-b4a3-2c31abfa7ab4) exiting.
2020-12-03 07:24:57,911 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-c003fc79-c50f-47e0-92be-1300d56d1d0d) exiting.
2020-12-03 07:24:57,932 [Listener at localhost/41609] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@10f567cb{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:24:57,933 [Listener at localhost/41609] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@55d92fa8{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:57,934 [Listener at localhost/41609] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@e2cea{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:57,934 [Listener at localhost/41609] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@55819061{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:57,935 [Listener at localhost/41609] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 41609
2020-12-03 07:24:57,938 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:57,939 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:57,940 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:24:57,941 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1006108214-172.17.0.5-1606980278566 (Datanode Uuid 85df5b2e-a97a-41c1-835b-035a6b9b8a7e) service to localhost/127.0.0.1:43954
2020-12-03 07:24:57,941 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1006108214-172.17.0.5-1606980278566 (Datanode Uuid 85df5b2e-a97a-41c1-835b-035a6b9b8a7e)
2020-12-03 07:24:57,941 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:57,942 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1006108214-172.17.0.5-1606980278566] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:57,942 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1006108214-172.17.0.5-1606980278566] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:57,945 [Listener at localhost/41609] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:24:57,945 [Listener at localhost/41609] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:24:57,946 [Listener at localhost/41609] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:24:57,946 [Listener at localhost/41609] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:24:57,948 [Listener at localhost/41609] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:24:57,948 [Listener at localhost/41609] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 4
2020-12-03 07:24:57,948 [Listener at localhost/41609] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:24:57,948 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@6a6e9d3e] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:24:57,949 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-519a1287-ec06-4bbf-8d21-79dbaca51fcb) exiting.
2020-12-03 07:24:57,949 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-86b77411-628e-439a-83fb-b288094a00ab) exiting.
2020-12-03 07:24:57,966 [Listener at localhost/41609] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@47d497e7{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:24:57,966 [Listener at localhost/41609] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@48bc24cf{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:57,967 [Listener at localhost/41609] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5f9bf061{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:57,967 [Listener at localhost/41609] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7271ef47{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:57,968 [Listener at localhost/41609] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 44265
2020-12-03 07:24:57,969 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:57,970 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:57,977 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:24:57,977 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1006108214-172.17.0.5-1606980278566 (Datanode Uuid 65fee986-f2dc-4671-a566-834a8ba38ec2) service to localhost/127.0.0.1:43954
2020-12-03 07:24:57,977 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1006108214-172.17.0.5-1606980278566 (Datanode Uuid 65fee986-f2dc-4671-a566-834a8ba38ec2)
2020-12-03 07:24:57,978 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:57,978 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1006108214-172.17.0.5-1606980278566] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:57,979 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1006108214-172.17.0.5-1606980278566] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:57,983 [Listener at localhost/41609] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:24:57,983 [Listener at localhost/41609] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:24:57,984 [Listener at localhost/41609] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:24:57,984 [Listener at localhost/41609] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:24:57,986 [Listener at localhost/41609] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:24:57,986 [Listener at localhost/41609] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 3
2020-12-03 07:24:57,986 [Listener at localhost/41609] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:24:57,986 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@5fed1881] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:24:57,987 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-f45a8750-594d-4642-87e3-93d21021bf5a) exiting.
2020-12-03 07:24:57,987 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-0095e818-e243-4a1c-aa13-99da0fd9e056) exiting.
2020-12-03 07:24:58,003 [Listener at localhost/41609] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@c1bfd20{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:24:58,003 [Listener at localhost/41609] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@13363aef{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:58,004 [Listener at localhost/41609] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@390ea2ed{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:58,004 [Listener at localhost/41609] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1cd5c291{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:58,005 [Listener at localhost/41609] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 33588
2020-12-03 07:24:58,006 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:58,006 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:58,007 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:24:58,008 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1006108214-172.17.0.5-1606980278566 (Datanode Uuid af552311-853c-41f7-a978-1842b97d4d48) service to localhost/127.0.0.1:43954
2020-12-03 07:24:58,008 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1006108214-172.17.0.5-1606980278566 (Datanode Uuid af552311-853c-41f7-a978-1842b97d4d48)
2020-12-03 07:24:58,008 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:58,008 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1006108214-172.17.0.5-1606980278566] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:58,009 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1006108214-172.17.0.5-1606980278566] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:58,013 [Listener at localhost/41609] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:24:58,013 [Listener at localhost/41609] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:24:58,014 [Listener at localhost/41609] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:24:58,014 [Listener at localhost/41609] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:24:58,016 [Listener at localhost/41609] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:24:58,016 [Listener at localhost/41609] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 2
2020-12-03 07:24:58,016 [Listener at localhost/41609] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:24:58,016 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@3ad3c380] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:24:58,017 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-4a4533dc-c0f5-4eba-8ab7-8f9fd4e59ffc) exiting.
2020-12-03 07:24:58,017 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-652cfcf7-8574-41cf-86aa-f7d20cbe2811) exiting.
2020-12-03 07:24:58,040 [Listener at localhost/41609] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@75d817db{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:24:58,040 [Listener at localhost/41609] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@e7d2323{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:58,040 [Listener at localhost/41609] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7e33a5ee{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:58,041 [Listener at localhost/41609] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@77da83ce{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:58,042 [Listener at localhost/41609] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 38111
2020-12-03 07:24:58,044 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:58,044 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:58,045 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:24:58,046 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1006108214-172.17.0.5-1606980278566 (Datanode Uuid 9ef29ebf-468b-497a-b175-e15a6fddabac) service to localhost/127.0.0.1:43954
2020-12-03 07:24:58,046 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1006108214-172.17.0.5-1606980278566 (Datanode Uuid 9ef29ebf-468b-497a-b175-e15a6fddabac)
2020-12-03 07:24:58,046 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:58,047 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1006108214-172.17.0.5-1606980278566] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:58,047 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1006108214-172.17.0.5-1606980278566] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:58,052 [Listener at localhost/41609] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:24:58,052 [Listener at localhost/41609] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:24:58,054 [Listener at localhost/41609] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:24:58,054 [Listener at localhost/41609] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:24:58,056 [Listener at localhost/41609] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:24:58,057 [Listener at localhost/41609] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 1
2020-12-03 07:24:58,057 [Listener at localhost/41609] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:24:58,057 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@5f6ec91f] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:24:58,058 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-fee6374f-fab9-484b-840a-3bb039765f1d) exiting.
2020-12-03 07:24:58,058 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-4f8bde89-39bc-4664-8495-24db1fc9070c) exiting.
2020-12-03 07:24:58,073 [Listener at localhost/41609] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@7cc56f2{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:24:58,073 [Listener at localhost/41609] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@13bf5b84{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:58,074 [Listener at localhost/41609] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7e266a2{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:58,074 [Listener at localhost/41609] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6f15a5e6{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:58,075 [Listener at localhost/41609] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 38380
2020-12-03 07:24:58,077 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:58,079 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:58,079 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:24:58,079 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1006108214-172.17.0.5-1606980278566 (Datanode Uuid 2e7687d0-5262-40f4-b8e8-9f72db15646f) service to localhost/127.0.0.1:43954
2020-12-03 07:24:58,079 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1006108214-172.17.0.5-1606980278566 (Datanode Uuid 2e7687d0-5262-40f4-b8e8-9f72db15646f)
2020-12-03 07:24:58,079 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:58,080 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1006108214-172.17.0.5-1606980278566] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:58,081 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1006108214-172.17.0.5-1606980278566] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:58,086 [Listener at localhost/41609] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:24:58,086 [Listener at localhost/41609] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:24:58,088 [Listener at localhost/41609] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:24:58,088 [Listener at localhost/41609] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:24:58,090 [Listener at localhost/41609] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:24:58,091 [Listener at localhost/41609] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:24:58,091 [Listener at localhost/41609] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:24:58,091 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@3e019d77] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:24:58,092 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-5a11274f-c1da-45a9-aa5e-f76140593ef7) exiting.
2020-12-03 07:24:58,092 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-36579057-efca-436e-8f83-6abab3daf2e6) exiting.
2020-12-03 07:24:58,111 [Listener at localhost/41609] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@614c06ee{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:24:58,111 [Listener at localhost/41609] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@72fd31c7{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:58,112 [Listener at localhost/41609] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7602f6bd{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:58,112 [Listener at localhost/41609] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5ef1d98b{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:58,113 [Listener at localhost/41609] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 43862
2020-12-03 07:24:58,115 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:58,115 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:58,117 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:24:58,117 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1006108214-172.17.0.5-1606980278566 (Datanode Uuid 2a2a30fb-7121-4535-8e69-ccc1d4e70ec3) service to localhost/127.0.0.1:43954
2020-12-03 07:24:58,117 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1006108214-172.17.0.5-1606980278566 (Datanode Uuid 2a2a30fb-7121-4535-8e69-ccc1d4e70ec3)
2020-12-03 07:24:58,117 [BP-1006108214-172.17.0.5-1606980278566 heartbeating to localhost/127.0.0.1:43954] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1006108214-172.17.0.5-1606980278566
2020-12-03 07:24:58,118 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1006108214-172.17.0.5-1606980278566] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:58,119 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1006108214-172.17.0.5-1606980278566] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:58,125 [Listener at localhost/41609] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:24:58,125 [Listener at localhost/41609] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:24:58,127 [Listener at localhost/41609] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:24:58,127 [Listener at localhost/41609] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:24:58,130 [Listener at localhost/41609] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:24:58,130 [Listener at localhost/41609] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:24:58,130 [Listener at localhost/41609] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:24:58,131 [Listener at localhost/41609] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 18, 18
2020-12-03 07:24:58,131 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@1862375a] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:24:58,131 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@2866b1be] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:24:58,134 [Listener at localhost/41609] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 2 Total time for transactions(ms): 12 Number of transactions batched in Syncs: 17 Number of syncs: 3 SyncTimes(ms): 8 16 
2020-12-03 07:24:58,135 [Listener at localhost/41609] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000018 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000018-0000000000000000019
2020-12-03 07:24:58,137 [Listener at localhost/41609] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000018 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000018-0000000000000000019
2020-12-03 07:24:58,137 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:24:58,138 [CacheReplicationMonitor(339999552)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:24:58,170 [Listener at localhost/41609] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 43954
2020-12-03 07:24:58,173 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:58,173 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:24:58,173 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:24:58,175 [IPC Server listener on 43954] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 43954
2020-12-03 07:24:58,184 [Listener at localhost/41609] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:24:58,184 [Listener at localhost/41609] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:24:58,185 [Listener at localhost/41609] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@321a418a{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:24:58,186 [Listener at localhost/41609] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@3bb87643{HTTP/1.1,[http/1.1]}{localhost:42381}
2020-12-03 07:24:58,186 [Listener at localhost/41609] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7ba6760c{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:58,187 [Listener at localhost/41609] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@71afd5ff{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:58,187 [Listener at localhost/41609] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-12-03 07:24:58,198 [Listener at localhost/41609] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-12-03 07:24:58,198 [Listener at localhost/41609] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
msx-rc 0
