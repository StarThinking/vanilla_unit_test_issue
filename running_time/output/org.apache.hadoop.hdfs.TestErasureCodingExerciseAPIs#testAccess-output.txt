2020-12-03 07:22:12,910 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=9
Formatting using clusterid: testClusterID
2020-12-03 07:22:13,773 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:22:13,912 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: KeyProviderCryptoExtension: jceks://file/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/7e0MclrDP5/test.jks
2020-12-03 07:22:13,914 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:22:13,914 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:22:13,915 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:22:13,915 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:22:13,916 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:22:13,916 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:22:13,970 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:13,975 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2020-12-03 07:22:13,976 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:22:13,976 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:22:13,984 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:22:13,985 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:22:13
2020-12-03 07:22:13,988 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:22:13,990 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:13,993 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-12-03 07:22:13,993 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:22:14,016 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:22:14,017 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:22:14,024 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:22:14,025 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:22:14,025 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:22:14,026 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:22:14,027 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:22:14,027 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:22:14,027 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:22:14,027 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:22:14,028 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:22:14,028 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:22:14,028 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:22:14,061 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GLOBAL serial map: bits=29 maxEntries=536870911
2020-12-03 07:22:14,061 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - USER serial map: bits=24 maxEntries=16777215
2020-12-03 07:22:14,062 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GROUP serial map: bits=24 maxEntries=16777215
2020-12-03 07:22:14,062 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - XATTR serial map: bits=24 maxEntries=16777215
2020-12-03 07:22:14,081 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:22:14,082 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:14,082 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-12-03 07:22:14,083 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:22:14,090 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? true
2020-12-03 07:22:14,090 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:22:14,091 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:22:14,091 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:22:14,099 [main] INFO  namenode.ReencryptionHandler (ReencryptionHandler.java:<init>(213)) - Configured throttleLimitHandlerRatio=1.0 for re-encryption
2020-12-03 07:22:14,109 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:22:14,113 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:22:14,121 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:22:14,122 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:14,122 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-12-03 07:22:14,123 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:22:14,134 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:22:14,135 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:22:14,135 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:22:14,141 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:22:14,142 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:22:14,146 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:22:14,147 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:14,148 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-12-03 07:22:14,148 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:22:14,205 [main] INFO  namenode.FSImage (FSImage.java:format(185)) - Allocated new BlockPoolId: BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:14,324 [main] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-12-03 07:22:14,375 [main] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-12-03 07:22:14,422 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:22:14,425 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:22:14,573 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:22:14,573 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:22:14,653 [main] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-12-03 07:22:14,659 [main] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:22:14,974 [main] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:22:15,086 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:22:15,087 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:22:15,098 [main] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-12-03 07:22:15,148 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@76a4ebf2] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:15,165 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:22:15,171 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:15,186 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @3564ms
2020-12-03 07:22:15,344 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:15,348 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:22:15,348 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:15,356 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:15,358 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:22:15,359 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:15,359 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:15,390 [main] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:22:15,390 [main] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:22:15,400 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 41570
2020-12-03 07:22:15,402 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:15,445 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@776a6d9b{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:15,446 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1f760b47{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:15,493 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@4e31276e{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:22:15,505 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@387d8985{HTTP/1.1,[http/1.1]}{localhost:41570}
2020-12-03 07:22:15,506 [main] INFO  server.Server (Server.java:doStart(419)) - Started @3884ms
2020-12-03 07:22:15,520 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:22:15,524 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: KeyProviderCryptoExtension: jceks://file/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/7e0MclrDP5/test.jks
2020-12-03 07:22:15,524 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:22:15,524 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:22:15,525 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:22:15,525 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:22:15,525 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:22:15,525 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:22:15,528 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:15,529 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:22:15,529 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:22:15,530 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:22:15,530 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:22:15
2020-12-03 07:22:15,530 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:22:15,531 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:15,531 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:22:15,532 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:22:15,536 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:22:15,536 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:22:15,537 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:22:15,537 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:22:15,538 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:22:15,538 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:22:15,538 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:22:15,539 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:22:15,539 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:22:15,539 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:22:15,540 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:22:15,544 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:22:15,544 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:22:15,545 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:22:15,546 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:15,546 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:22:15,547 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:22:15,553 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? true
2020-12-03 07:22:15,554 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:22:15,555 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:22:15,555 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:22:15,555 [main] INFO  namenode.ReencryptionHandler (ReencryptionHandler.java:<init>(213)) - Configured throttleLimitHandlerRatio=1.0 for re-encryption
2020-12-03 07:22:15,556 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:22:15,556 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:22:15,557 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:22:15,557 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:15,558 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:22:15,558 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:22:15,560 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:22:15,560 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:22:15,560 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:22:15,561 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:22:15,561 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:22:15,562 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:22:15,562 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:22:15,563 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:22:15,563 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:22:15,599 [main] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 6154@274d470f39cc
2020-12-03 07:22:15,624 [main] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 6154@274d470f39cc
2020-12-03 07:22:15,629 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-12-03 07:22:15,630 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-12-03 07:22:15,631 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:22:15,632 [main] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:22:15,692 [main] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:22:15,701 [main] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:22:15,702 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-12-03 07:22:15,710 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:22:15,711 [main] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 1
2020-12-03 07:22:15,784 [main] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:22:15,785 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 219 msecs
2020-12-03 07:22:15,993 [main] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:22:16,061 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:16,082 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:16,357 [Listener at localhost/46867] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:46867 to access this namenode/service.
2020-12-03 07:22:16,361 [Listener at localhost/46867] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:22:16,380 [Listener at localhost/46867] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:22:16,392 [Listener at localhost/46867] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:22:16,393 [Listener at localhost/46867] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:22:16,393 [Listener at localhost/46867] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:22:16,393 [Listener at localhost/46867] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:22:16,394 [Listener at localhost/46867] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(347)) - Updating the current master key for generating delegation tokens
2020-12-03 07:22:16,398 [Thread[Thread-34,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(679)) - Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-12-03 07:22:16,398 [Thread[Thread-34,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(347)) - Updating the current master key for generating delegation tokens
2020-12-03 07:22:16,400 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 0
2020-12-03 07:22:16,400 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:22:16,400 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:22:16,400 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:22:16,400 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:22:16,401 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 8 msec
2020-12-03 07:22:16,429 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:16,430 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:16,433 [Listener at localhost/46867] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:46867
2020-12-03 07:22:16,437 [Listener at localhost/46867] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:22:16,437 [Listener at localhost/46867] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:22:16,446 [Listener at localhost/46867] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 9 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:22:16,447 [reencryptionHandlerThread #0] INFO  namenode.ReencryptionHandler (ReencryptionHandler.java:run(326)) - Starting up re-encrypt thread with interval=60000 millisecond.
2020-12-03 07:22:16,452 [CacheReplicationMonitor(1732399539)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:22:16,455 [Warm Up EDEK Cache Thread #0] INFO  namenode.NameNode (FSDirEncryptionZoneOp.java:run(571)) - Warming up 0 EDEKs... (initialDelay=3000, retryInterval=1000)
2020-12-03 07:22:16,463 [Listener at localhost/46867] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:22:16,486 [Listener at localhost/46867] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:22:16,505 [Listener at localhost/46867] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:22:16,536 [Listener at localhost/46867] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:22:16,549 [Listener at localhost/46867] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:16,553 [Listener at localhost/46867] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:22:16,560 [Listener at localhost/46867] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:22:16,561 [Listener at localhost/46867] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:16,568 [Listener at localhost/46867] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:22:16,578 [Listener at localhost/46867] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:35466
2020-12-03 07:22:16,581 [Listener at localhost/46867] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:22:16,581 [Listener at localhost/46867] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:22:16,605 [Listener at localhost/46867] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:16,608 [Listener at localhost/46867] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:16,610 [Listener at localhost/46867] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:22:16,610 [Listener at localhost/46867] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:16,614 [Listener at localhost/46867] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:16,615 [Listener at localhost/46867] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:22:16,616 [Listener at localhost/46867] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:16,616 [Listener at localhost/46867] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:16,621 [Listener at localhost/46867] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 34752
2020-12-03 07:22:16,622 [Listener at localhost/46867] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:16,624 [Listener at localhost/46867] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@36b0fcd5{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:16,625 [Listener at localhost/46867] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@475835b1{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:16,633 [Listener at localhost/46867] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@76c7beb3{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:22:16,634 [Listener at localhost/46867] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@64337702{HTTP/1.1,[http/1.1]}{localhost:34752}
2020-12-03 07:22:16,635 [Listener at localhost/46867] INFO  server.Server (Server.java:doStart(419)) - Started @5013ms
2020-12-03 07:22:17,259 [Listener at localhost/46867] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:38786
2020-12-03 07:22:17,264 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@54afd745] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:17,265 [Listener at localhost/46867] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:22:17,271 [Listener at localhost/46867] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:22:17,293 [Listener at localhost/46867] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:17,294 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:17,302 [Listener at localhost/34703] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:34703
2020-12-03 07:22:17,317 [Listener at localhost/34703] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:22:17,318 [Listener at localhost/34703] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:22:17,329 [Thread-63] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46867 starting to offer service
2020-12-03 07:22:17,340 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:17,340 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:17,344 [Listener at localhost/34703] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:22:17,347 [Listener at localhost/34703] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:22:17,347 [Listener at localhost/34703] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:22:17,349 [Listener at localhost/34703] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:22:17,350 [Listener at localhost/34703] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:17,350 [Listener at localhost/34703] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:22:17,350 [Listener at localhost/34703] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:22:17,351 [Listener at localhost/34703] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:17,351 [Listener at localhost/34703] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:22:17,352 [Listener at localhost/34703] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:35589
2020-12-03 07:22:17,352 [Listener at localhost/34703] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:22:17,352 [Listener at localhost/34703] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:22:17,354 [Listener at localhost/34703] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:17,355 [Listener at localhost/34703] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:17,356 [Listener at localhost/34703] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:22:17,356 [Listener at localhost/34703] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:17,358 [Listener at localhost/34703] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:17,359 [Listener at localhost/34703] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:22:17,359 [Listener at localhost/34703] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:17,359 [Listener at localhost/34703] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:17,360 [Listener at localhost/34703] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 44605
2020-12-03 07:22:17,361 [Listener at localhost/34703] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:17,362 [Listener at localhost/34703] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2ef8a8c3{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:17,363 [Listener at localhost/34703] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@63fd4873{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:17,370 [Listener at localhost/34703] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@425357dd{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:22:17,371 [Listener at localhost/34703] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2102a4d5{HTTP/1.1,[http/1.1]}{localhost:44605}
2020-12-03 07:22:17,371 [Listener at localhost/34703] INFO  server.Server (Server.java:doStart(419)) - Started @5749ms
2020-12-03 07:22:17,512 [Listener at localhost/34703] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:33086
2020-12-03 07:22:17,513 [Listener at localhost/34703] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:22:17,514 [Listener at localhost/34703] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:22:17,513 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3d4d3fe7] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:17,515 [Listener at localhost/34703] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:17,516 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:17,523 [Listener at localhost/35629] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:35629
2020-12-03 07:22:17,529 [Listener at localhost/35629] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:22:17,529 [Listener at localhost/35629] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:22:17,530 [Thread-87] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46867 starting to offer service
2020-12-03 07:22:17,532 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:17,532 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:17,549 [Listener at localhost/35629] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:22:17,551 [Listener at localhost/35629] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:22:17,552 [Listener at localhost/35629] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:22:17,553 [Listener at localhost/35629] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:22:17,554 [Listener at localhost/35629] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:17,554 [Listener at localhost/35629] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:22:17,555 [Listener at localhost/35629] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:22:17,555 [Listener at localhost/35629] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:17,556 [Listener at localhost/35629] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:22:17,557 [Listener at localhost/35629] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:36349
2020-12-03 07:22:17,557 [Listener at localhost/35629] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:22:17,557 [Listener at localhost/35629] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:22:17,559 [Listener at localhost/35629] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:17,561 [Listener at localhost/35629] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:17,563 [Listener at localhost/35629] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:22:17,563 [Listener at localhost/35629] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:17,565 [Listener at localhost/35629] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:17,566 [Listener at localhost/35629] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:22:17,566 [Listener at localhost/35629] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:17,567 [Listener at localhost/35629] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:17,568 [Listener at localhost/35629] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 45173
2020-12-03 07:22:17,568 [Listener at localhost/35629] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:17,570 [Listener at localhost/35629] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@49a64d82{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:17,570 [Listener at localhost/35629] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@66d23e4a{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:17,577 [Listener at localhost/35629] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@4593ff34{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:22:17,582 [Listener at localhost/35629] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@37d3d232{HTTP/1.1,[http/1.1]}{localhost:45173}
2020-12-03 07:22:17,588 [Listener at localhost/35629] INFO  server.Server (Server.java:doStart(419)) - Started @5960ms
2020-12-03 07:22:17,620 [Listener at localhost/35629] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:38741
2020-12-03 07:22:17,620 [Listener at localhost/35629] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:22:17,620 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@581d969c] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:17,621 [Listener at localhost/35629] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:22:17,621 [Listener at localhost/35629] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:17,622 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:17,626 [Listener at localhost/42532] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:42532
2020-12-03 07:22:17,630 [Listener at localhost/42532] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:22:17,631 [Listener at localhost/42532] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:22:17,631 [Thread-109] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46867 starting to offer service
2020-12-03 07:22:17,633 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:17,633 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:17,638 [Listener at localhost/42532] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 3 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:22:17,640 [Listener at localhost/42532] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:22:17,640 [Listener at localhost/42532] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:22:17,642 [Listener at localhost/42532] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:22:17,643 [Listener at localhost/42532] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:17,643 [Listener at localhost/42532] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:22:17,644 [Listener at localhost/42532] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:22:17,644 [Listener at localhost/42532] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:17,645 [Listener at localhost/42532] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:22:17,646 [Listener at localhost/42532] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:35197
2020-12-03 07:22:17,647 [Listener at localhost/42532] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:22:17,647 [Listener at localhost/42532] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:22:17,648 [Listener at localhost/42532] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:17,651 [Listener at localhost/42532] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:17,652 [Listener at localhost/42532] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:22:17,652 [Listener at localhost/42532] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:17,655 [Listener at localhost/42532] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:17,656 [Listener at localhost/42532] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:22:17,657 [Listener at localhost/42532] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:17,657 [Listener at localhost/42532] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:17,659 [Listener at localhost/42532] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 33783
2020-12-03 07:22:17,659 [Listener at localhost/42532] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:17,661 [Listener at localhost/42532] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7728643a{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:17,662 [Listener at localhost/42532] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5167268{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:17,680 [Listener at localhost/42532] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@88d6f9b{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:22:17,682 [Listener at localhost/42532] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@47d93e0d{HTTP/1.1,[http/1.1]}{localhost:33783}
2020-12-03 07:22:17,682 [Listener at localhost/42532] INFO  server.Server (Server.java:doStart(419)) - Started @6060ms
2020-12-03 07:22:17,746 [Listener at localhost/42532] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:33921
2020-12-03 07:22:17,746 [Listener at localhost/42532] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:22:17,746 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@751e664e] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:17,747 [Listener at localhost/42532] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:22:17,748 [Listener at localhost/42532] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:17,748 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:17,752 [Listener at localhost/46511] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:46511
2020-12-03 07:22:17,765 [Listener at localhost/46511] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:22:17,765 [Listener at localhost/46511] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:22:17,766 [Thread-131] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46867 starting to offer service
2020-12-03 07:22:17,768 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:17,768 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:17,776 [Listener at localhost/46511] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 4 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:22:17,778 [Listener at localhost/46511] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:22:17,779 [Listener at localhost/46511] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:22:17,783 [Listener at localhost/46511] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:22:17,784 [Listener at localhost/46511] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:17,784 [Listener at localhost/46511] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:22:17,785 [Listener at localhost/46511] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:22:17,785 [Listener at localhost/46511] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:17,785 [Listener at localhost/46511] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:22:17,786 [Listener at localhost/46511] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:41230
2020-12-03 07:22:17,786 [Listener at localhost/46511] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:22:17,787 [Listener at localhost/46511] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:22:17,788 [Listener at localhost/46511] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:17,791 [Listener at localhost/46511] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:17,793 [Listener at localhost/46511] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:22:17,793 [Listener at localhost/46511] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:17,796 [Listener at localhost/46511] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:17,797 [Listener at localhost/46511] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:22:17,798 [Listener at localhost/46511] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:17,798 [Thread-87] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46867
2020-12-03 07:22:17,798 [Thread-131] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46867
2020-12-03 07:22:17,798 [Listener at localhost/46511] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:17,799 [Thread-109] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46867
2020-12-03 07:22:17,800 [Thread-63] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46867
2020-12-03 07:22:17,801 [Listener at localhost/46511] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 41474
2020-12-03 07:22:17,801 [Thread-109] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:17,801 [Listener at localhost/46511] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:17,801 [Thread-131] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:17,804 [Thread-63] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:17,804 [Thread-87] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:17,805 [Listener at localhost/46511] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6b85300e{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:17,806 [Listener at localhost/46511] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5cbf9e9f{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:17,813 [Listener at localhost/46511] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@4acf72b6{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:22:17,814 [Listener at localhost/46511] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7561db12{HTTP/1.1,[http/1.1]}{localhost:41474}
2020-12-03 07:22:17,814 [Listener at localhost/46511] INFO  server.Server (Server.java:doStart(419)) - Started @6192ms
2020-12-03 07:22:17,827 [Listener at localhost/46511] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:46350
2020-12-03 07:22:17,828 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@24b52d3e] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:17,828 [Listener at localhost/46511] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:22:17,828 [Listener at localhost/46511] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:22:17,829 [Listener at localhost/46511] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:17,830 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:17,835 [Listener at localhost/35404] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:35404
2020-12-03 07:22:17,840 [Listener at localhost/35404] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:22:17,841 [Listener at localhost/35404] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:22:17,842 [Thread-153] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46867 starting to offer service
2020-12-03 07:22:17,844 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:17,845 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:17,847 [Thread-153] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46867
2020-12-03 07:22:17,848 [Thread-153] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:17,848 [Listener at localhost/35404] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 5 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:22:17,849 [Listener at localhost/35404] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:22:17,849 [Listener at localhost/35404] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:22:17,850 [Listener at localhost/35404] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:22:17,851 [Listener at localhost/35404] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:17,851 [Listener at localhost/35404] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:22:17,852 [Listener at localhost/35404] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:22:17,852 [Listener at localhost/35404] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:17,852 [Listener at localhost/35404] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:22:17,853 [Listener at localhost/35404] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:45410
2020-12-03 07:22:17,853 [Listener at localhost/35404] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:22:17,853 [Listener at localhost/35404] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:22:17,854 [Listener at localhost/35404] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:17,856 [Listener at localhost/35404] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:17,856 [Listener at localhost/35404] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:22:17,856 [Listener at localhost/35404] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:17,858 [Listener at localhost/35404] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:17,859 [Listener at localhost/35404] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:22:17,859 [Listener at localhost/35404] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:17,859 [Listener at localhost/35404] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:17,860 [Listener at localhost/35404] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 39530
2020-12-03 07:22:17,860 [Listener at localhost/35404] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:17,862 [Listener at localhost/35404] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@13c612bd{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:17,863 [Listener at localhost/35404] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6b739528{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:17,871 [Listener at localhost/35404] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@61e3a1fd{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:22:17,872 [Listener at localhost/35404] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@51abf713{HTTP/1.1,[http/1.1]}{localhost:39530}
2020-12-03 07:22:17,873 [Listener at localhost/35404] INFO  server.Server (Server.java:doStart(419)) - Started @6251ms
2020-12-03 07:22:17,892 [Listener at localhost/35404] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:43592
2020-12-03 07:22:17,892 [Listener at localhost/35404] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:22:17,892 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4d4d48a6] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:17,893 [Listener at localhost/35404] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:22:17,893 [Listener at localhost/35404] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:17,894 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:17,895 [Thread-153] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/in_use.lock acquired by nodename 6154@274d470f39cc
2020-12-03 07:22:17,895 [Thread-109] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 6154@274d470f39cc
2020-12-03 07:22:17,896 [Thread-87] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 6154@274d470f39cc
2020-12-03 07:22:17,895 [Thread-63] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 6154@274d470f39cc
2020-12-03 07:22:17,895 [Thread-131] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/in_use.lock acquired by nodename 6154@274d470f39cc
2020-12-03 07:22:17,897 [Thread-153] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 is not formatted for namespace 2057979486. Formatting...
2020-12-03 07:22:17,897 [Thread-87] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 is not formatted for namespace 2057979486. Formatting...
2020-12-03 07:22:17,897 [Thread-131] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 is not formatted for namespace 2057979486. Formatting...
2020-12-03 07:22:17,897 [Thread-109] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 is not formatted for namespace 2057979486. Formatting...
2020-12-03 07:22:17,897 [Thread-63] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 2057979486. Formatting...
2020-12-03 07:22:17,898 [Thread-153] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-1da9a190-9e06-4f85-a403-b1c9f1a05a12 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 
2020-12-03 07:22:17,898 [Thread-63] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-5e5cd84f-8271-464a-85ba-e85d47b940d8 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-12-03 07:22:17,898 [Thread-87] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-dcf662f1-c431-4f1d-905d-f2c8a7c53691 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 
2020-12-03 07:22:17,898 [Thread-131] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-44c575dd-518f-4d6a-9736-123dfb9ef4e0 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 
2020-12-03 07:22:17,899 [Thread-109] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-a756ff9b-797d-4a9e-926c-68bbc728b725 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 
2020-12-03 07:22:17,899 [Listener at localhost/36001] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:36001
2020-12-03 07:22:17,903 [Listener at localhost/36001] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:22:17,904 [Listener at localhost/36001] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:22:17,905 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:17,905 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:17,909 [Thread-175] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46867 starting to offer service
2020-12-03 07:22:17,959 [Listener at localhost/36001] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 6 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:22:17,961 [Listener at localhost/36001] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:22:17,962 [Listener at localhost/36001] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:22:17,964 [Listener at localhost/36001] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:22:17,964 [Listener at localhost/36001] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:17,965 [Listener at localhost/36001] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:22:17,965 [Listener at localhost/36001] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:22:17,966 [Listener at localhost/36001] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:17,966 [Listener at localhost/36001] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:22:17,967 [Listener at localhost/36001] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:38755
2020-12-03 07:22:17,967 [Listener at localhost/36001] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:22:17,967 [Listener at localhost/36001] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:22:17,973 [Listener at localhost/36001] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:17,976 [Listener at localhost/36001] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:17,981 [Listener at localhost/36001] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:22:17,981 [Listener at localhost/36001] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:17,984 [Thread-175] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46867
2020-12-03 07:22:17,984 [Listener at localhost/36001] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:17,985 [Thread-175] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:17,986 [Listener at localhost/36001] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:22:17,986 [Listener at localhost/36001] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:17,986 [Listener at localhost/36001] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:17,987 [Listener at localhost/36001] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 37445
2020-12-03 07:22:17,987 [Listener at localhost/36001] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:17,990 [Listener at localhost/36001] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6548bb7d{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:17,991 [Listener at localhost/36001] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@54336c81{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:18,001 [Listener at localhost/36001] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@17ae98d7{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:22:18,002 [Listener at localhost/36001] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@59221b97{HTTP/1.1,[http/1.1]}{localhost:37445}
2020-12-03 07:22:18,002 [Listener at localhost/36001] INFO  server.Server (Server.java:doStart(419)) - Started @6380ms
2020-12-03 07:22:18,024 [Thread-175] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/in_use.lock acquired by nodename 6154@274d470f39cc
2020-12-03 07:22:18,024 [Thread-175] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 is not formatted for namespace 2057979486. Formatting...
2020-12-03 07:22:18,025 [Thread-175] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-b1868b9e-e800-4127-9f6e-905f0d6e29c2 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 
2020-12-03 07:22:18,043 [Listener at localhost/36001] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:45132
2020-12-03 07:22:18,044 [Listener at localhost/36001] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:22:18,044 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5a772895] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:18,044 [Listener at localhost/36001] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:22:18,045 [Listener at localhost/36001] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:18,046 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:18,050 [Listener at localhost/44256] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:44256
2020-12-03 07:22:18,055 [Listener at localhost/44256] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:22:18,055 [Listener at localhost/44256] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:22:18,056 [Thread-197] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46867 starting to offer service
2020-12-03 07:22:18,058 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:18,058 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:18,066 [Thread-197] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46867
2020-12-03 07:22:18,067 [Thread-197] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:18,067 [Listener at localhost/44256] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 7 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:22:18,069 [Listener at localhost/44256] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:22:18,069 [Listener at localhost/44256] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:22:18,071 [Listener at localhost/44256] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:22:18,072 [Listener at localhost/44256] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:18,072 [Listener at localhost/44256] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:22:18,073 [Listener at localhost/44256] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:22:18,073 [Listener at localhost/44256] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:18,073 [Listener at localhost/44256] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:22:18,075 [Thread-131] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/in_use.lock acquired by nodename 6154@274d470f39cc
2020-12-03 07:22:18,075 [Thread-109] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 6154@274d470f39cc
2020-12-03 07:22:18,075 [Thread-131] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 is not formatted for namespace 2057979486. Formatting...
2020-12-03 07:22:18,075 [Thread-109] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 is not formatted for namespace 2057979486. Formatting...
2020-12-03 07:22:18,075 [Thread-131] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-a8ac44bd-2d90-4975-b170-7e0be4f54f1d for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 
2020-12-03 07:22:18,075 [Listener at localhost/44256] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:33247
2020-12-03 07:22:18,075 [Thread-109] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-aaa11e61-23fd-4415-8832-dea8228b06ec for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 
2020-12-03 07:22:18,076 [Listener at localhost/44256] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:22:18,077 [Listener at localhost/44256] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:22:18,078 [Listener at localhost/44256] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:18,080 [Listener at localhost/44256] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:18,081 [Listener at localhost/44256] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:22:18,081 [Listener at localhost/44256] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:18,084 [Listener at localhost/44256] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:18,084 [Listener at localhost/44256] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:22:18,085 [Listener at localhost/44256] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:18,085 [Listener at localhost/44256] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:18,086 [Listener at localhost/44256] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 45286
2020-12-03 07:22:18,086 [Listener at localhost/44256] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:18,088 [Listener at localhost/44256] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1db0ec27{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:18,089 [Listener at localhost/44256] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@d4ab71a{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:18,096 [Listener at localhost/44256] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@273c947f{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:22:18,099 [Listener at localhost/44256] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@30457e14{HTTP/1.1,[http/1.1]}{localhost:45286}
2020-12-03 07:22:18,099 [Listener at localhost/44256] INFO  server.Server (Server.java:doStart(419)) - Started @6477ms
2020-12-03 07:22:18,117 [Thread-87] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 6154@274d470f39cc
2020-12-03 07:22:18,117 [Thread-153] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/in_use.lock acquired by nodename 6154@274d470f39cc
2020-12-03 07:22:18,117 [Thread-87] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 is not formatted for namespace 2057979486. Formatting...
2020-12-03 07:22:18,118 [Thread-153] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 is not formatted for namespace 2057979486. Formatting...
2020-12-03 07:22:18,118 [Thread-87] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-a67153a8-dc0e-41b7-928e-2bec0596e04e for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 
2020-12-03 07:22:18,117 [Thread-63] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 6154@274d470f39cc
2020-12-03 07:22:18,118 [Thread-63] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 2057979486. Formatting...
2020-12-03 07:22:18,119 [Thread-63] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-6ded7c5e-260d-452e-9a88-6cf4eca391f6 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-12-03 07:22:18,118 [Thread-153] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-fd189235-0037-4626-b4b3-7bcf8d76254a for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 
2020-12-03 07:22:18,126 [Thread-197] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/in_use.lock acquired by nodename 6154@274d470f39cc
2020-12-03 07:22:18,127 [Thread-197] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 is not formatted for namespace 2057979486. Formatting...
2020-12-03 07:22:18,127 [Thread-197] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-b720b757-1081-4f84-a9d2-42cf7586af8d for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 
2020-12-03 07:22:18,156 [Listener at localhost/44256] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:36390
2020-12-03 07:22:18,157 [Listener at localhost/44256] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:22:18,157 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@632aa1a3] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:18,157 [Listener at localhost/44256] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:22:18,158 [Listener at localhost/44256] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:18,158 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:18,163 [Listener at localhost/40756] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:40756
2020-12-03 07:22:18,168 [Listener at localhost/40756] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:22:18,168 [Listener at localhost/40756] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:22:18,169 [Thread-219] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46867 starting to offer service
2020-12-03 07:22:18,173 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:18,173 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:18,178 [Listener at localhost/40756] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 8 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:22:18,178 [Thread-219] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46867
2020-12-03 07:22:18,179 [Thread-219] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:18,180 [Listener at localhost/40756] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:22:18,181 [Listener at localhost/40756] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:22:18,192 [Listener at localhost/40756] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:22:18,193 [Listener at localhost/40756] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:18,193 [Listener at localhost/40756] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:22:18,194 [Listener at localhost/40756] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:22:18,194 [Listener at localhost/40756] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:22:18,194 [Listener at localhost/40756] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:22:18,195 [Listener at localhost/40756] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:46171
2020-12-03 07:22:18,195 [Listener at localhost/40756] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:22:18,195 [Listener at localhost/40756] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:22:18,197 [Listener at localhost/40756] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:18,198 [Listener at localhost/40756] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:22:18,199 [Listener at localhost/40756] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:22:18,199 [Listener at localhost/40756] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:22:18,201 [Listener at localhost/40756] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:22:18,201 [Listener at localhost/40756] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:22:18,201 [Listener at localhost/40756] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:22:18,202 [Listener at localhost/40756] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:22:18,202 [Listener at localhost/40756] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 36960
2020-12-03 07:22:18,203 [Listener at localhost/40756] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:22:18,204 [Listener at localhost/40756] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@62e8f862{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:22:18,205 [Listener at localhost/40756] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3c49fab6{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:22:18,205 [Thread-175] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/in_use.lock acquired by nodename 6154@274d470f39cc
2020-12-03 07:22:18,206 [Thread-175] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 is not formatted for namespace 2057979486. Formatting...
2020-12-03 07:22:18,221 [Thread-175] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-c16f6bf6-3694-486c-a5d2-60f3ca71a13e for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 
2020-12-03 07:22:18,227 [Listener at localhost/40756] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@55a8dc49{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:22:18,229 [Listener at localhost/40756] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2a415aa9{HTTP/1.1,[http/1.1]}{localhost:36960}
2020-12-03 07:22:18,229 [Listener at localhost/40756] INFO  server.Server (Server.java:doStart(419)) - Started @6607ms
2020-12-03 07:22:18,237 [Thread-131] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:18,237 [Thread-109] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:18,237 [Thread-131] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:18,237 [Thread-109] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:18,239 [Thread-131] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 and block pool id BP-1381366540-172.17.0.6-1606980134186 is not formatted. Formatting ...
2020-12-03 07:22:18,239 [Thread-109] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 and block pool id BP-1381366540-172.17.0.6-1606980134186 is not formatted. Formatting ...
2020-12-03 07:22:18,239 [Thread-131] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1381366540-172.17.0.6-1606980134186 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1381366540-172.17.0.6-1606980134186/current
2020-12-03 07:22:18,239 [Thread-109] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1381366540-172.17.0.6-1606980134186 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1381366540-172.17.0.6-1606980134186/current
2020-12-03 07:22:18,256 [Listener at localhost/40756] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:34647
2020-12-03 07:22:18,257 [Listener at localhost/40756] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:22:18,257 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@71ea1fda] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:22:18,257 [Listener at localhost/40756] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:22:18,258 [Listener at localhost/40756] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:22:18,258 [Thread-219] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/in_use.lock acquired by nodename 6154@274d470f39cc
2020-12-03 07:22:18,258 [Thread-219] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 is not formatted for namespace 2057979486. Formatting...
2020-12-03 07:22:18,259 [Thread-219] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-26fd1b49-3ac0-4652-9e2b-01266ac6cd25 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 
2020-12-03 07:22:18,259 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:22:18,262 [Listener at localhost/36315] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:36315
2020-12-03 07:22:18,268 [Listener at localhost/36315] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:22:18,269 [Listener at localhost/36315] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:22:18,270 [Thread-241] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46867 starting to offer service
2020-12-03 07:22:18,271 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:22:18,272 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:22:18,278 [Thread-241] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46867
2020-12-03 07:22:18,279 [Thread-241] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:22:18,316 [Thread-153] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:18,317 [Thread-87] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:18,317 [Thread-153] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:18,317 [Thread-63] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:18,317 [Thread-153] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 and block pool id BP-1381366540-172.17.0.6-1606980134186 is not formatted. Formatting ...
2020-12-03 07:22:18,317 [Thread-87] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:18,317 [Thread-153] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1381366540-172.17.0.6-1606980134186 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1381366540-172.17.0.6-1606980134186/current
2020-12-03 07:22:18,317 [Thread-87] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 and block pool id BP-1381366540-172.17.0.6-1606980134186 is not formatted. Formatting ...
2020-12-03 07:22:18,317 [Thread-63] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:18,318 [Thread-87] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1381366540-172.17.0.6-1606980134186 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1381366540-172.17.0.6-1606980134186/current
2020-12-03 07:22:18,318 [Thread-63] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-1381366540-172.17.0.6-1606980134186 is not formatted. Formatting ...
2020-12-03 07:22:18,318 [Thread-63] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1381366540-172.17.0.6-1606980134186 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1381366540-172.17.0.6-1606980134186/current
2020-12-03 07:22:18,340 [Thread-241] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/in_use.lock acquired by nodename 6154@274d470f39cc
2020-12-03 07:22:18,341 [Thread-241] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 is not formatted for namespace 2057979486. Formatting...
2020-12-03 07:22:18,343 [Thread-241] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-372699bb-d6ed-4718-be65-3b97a1865aff for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 
2020-12-03 07:22:18,408 [Thread-197] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/in_use.lock acquired by nodename 6154@274d470f39cc
2020-12-03 07:22:18,408 [Thread-197] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 is not formatted for namespace 2057979486. Formatting...
2020-12-03 07:22:18,409 [Thread-197] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-f69d61df-5ff2-4e47-9f2d-eb2ce927381c for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 
2020-12-03 07:22:18,429 [Thread-131] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:18,431 [Thread-131] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:18,431 [Thread-131] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 and block pool id BP-1381366540-172.17.0.6-1606980134186 is not formatted. Formatting ...
2020-12-03 07:22:18,431 [Thread-131] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1381366540-172.17.0.6-1606980134186 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1381366540-172.17.0.6-1606980134186/current
2020-12-03 07:22:18,431 [Thread-175] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:18,432 [Thread-175] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:18,433 [Thread-175] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 and block pool id BP-1381366540-172.17.0.6-1606980134186 is not formatted. Formatting ...
2020-12-03 07:22:18,433 [Thread-175] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1381366540-172.17.0.6-1606980134186 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1381366540-172.17.0.6-1606980134186/current
2020-12-03 07:22:18,448 [Thread-109] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:18,448 [Thread-109] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:18,448 [Thread-109] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 and block pool id BP-1381366540-172.17.0.6-1606980134186 is not formatted. Formatting ...
2020-12-03 07:22:18,448 [Thread-109] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1381366540-172.17.0.6-1606980134186 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1381366540-172.17.0.6-1606980134186/current
2020-12-03 07:22:18,530 [Thread-153] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:18,531 [Thread-153] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:18,531 [Thread-153] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 and block pool id BP-1381366540-172.17.0.6-1606980134186 is not formatted. Formatting ...
2020-12-03 07:22:18,531 [Thread-153] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1381366540-172.17.0.6-1606980134186 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1381366540-172.17.0.6-1606980134186/current
2020-12-03 07:22:18,532 [Thread-63] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:18,533 [Thread-63] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:18,533 [Thread-63] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-1381366540-172.17.0.6-1606980134186 is not formatted. Formatting ...
2020-12-03 07:22:18,533 [Thread-63] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1381366540-172.17.0.6-1606980134186 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1381366540-172.17.0.6-1606980134186/current
2020-12-03 07:22:18,538 [Thread-87] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:18,538 [Thread-87] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:18,539 [Thread-87] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 and block pool id BP-1381366540-172.17.0.6-1606980134186 is not formatted. Formatting ...
2020-12-03 07:22:18,539 [Thread-87] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1381366540-172.17.0.6-1606980134186 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1381366540-172.17.0.6-1606980134186/current
2020-12-03 07:22:18,547 [Thread-219] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/in_use.lock acquired by nodename 6154@274d470f39cc
2020-12-03 07:22:18,547 [Thread-219] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 is not formatted for namespace 2057979486. Formatting...
2020-12-03 07:22:18,549 [Thread-219] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-d07d3af6-0c3e-4eda-bf94-13f5cbd7954e for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 
2020-12-03 07:22:18,600 [Thread-109] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=2057979486;bpid=BP-1381366540-172.17.0.6-1606980134186;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=2057979486;c=1606980134186;bpid=BP-1381366540-172.17.0.6-1606980134186;dnuuid=null
2020-12-03 07:22:18,600 [Thread-131] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=2057979486;bpid=BP-1381366540-172.17.0.6-1606980134186;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=2057979486;c=1606980134186;bpid=BP-1381366540-172.17.0.6-1606980134186;dnuuid=null
2020-12-03 07:22:18,612 [Thread-175] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:18,612 [Thread-175] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:18,613 [Thread-175] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 and block pool id BP-1381366540-172.17.0.6-1606980134186 is not formatted. Formatting ...
2020-12-03 07:22:18,613 [Thread-197] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:18,613 [Thread-175] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1381366540-172.17.0.6-1606980134186 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1381366540-172.17.0.6-1606980134186/current
2020-12-03 07:22:18,613 [Thread-197] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:18,613 [Thread-197] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 and block pool id BP-1381366540-172.17.0.6-1606980134186 is not formatted. Formatting ...
2020-12-03 07:22:18,613 [Thread-197] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1381366540-172.17.0.6-1606980134186 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1381366540-172.17.0.6-1606980134186/current
2020-12-03 07:22:18,640 [Thread-241] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/in_use.lock acquired by nodename 6154@274d470f39cc
2020-12-03 07:22:18,640 [Thread-241] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 is not formatted for namespace 2057979486. Formatting...
2020-12-03 07:22:18,640 [Thread-241] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-bd138a52-784f-4b6f-b6ff-f75aed74d335 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 
2020-12-03 07:22:18,701 [Thread-153] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=2057979486;bpid=BP-1381366540-172.17.0.6-1606980134186;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=2057979486;c=1606980134186;bpid=BP-1381366540-172.17.0.6-1606980134186;dnuuid=null
2020-12-03 07:22:18,701 [Thread-87] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=2057979486;bpid=BP-1381366540-172.17.0.6-1606980134186;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=2057979486;c=1606980134186;bpid=BP-1381366540-172.17.0.6-1606980134186;dnuuid=null
2020-12-03 07:22:18,701 [Thread-63] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=2057979486;bpid=BP-1381366540-172.17.0.6-1606980134186;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=2057979486;c=1606980134186;bpid=BP-1381366540-172.17.0.6-1606980134186;dnuuid=null
2020-12-03 07:22:18,757 [Thread-219] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:18,757 [Thread-219] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:18,757 [Thread-219] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 and block pool id BP-1381366540-172.17.0.6-1606980134186 is not formatted. Formatting ...
2020-12-03 07:22:18,757 [Thread-219] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1381366540-172.17.0.6-1606980134186 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1381366540-172.17.0.6-1606980134186/current
2020-12-03 07:22:18,815 [IPC Server handler 1 on default port 46867] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:18,818 [Thread-175] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=2057979486;bpid=BP-1381366540-172.17.0.6-1606980134186;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=2057979486;c=1606980134186;bpid=BP-1381366540-172.17.0.6-1606980134186;dnuuid=null
2020-12-03 07:22:18,819 [Thread-131] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID f52a640d-cec3-4842-be39-1e22246ccbb2
2020-12-03 07:22:18,822 [Thread-109] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 43e9848a-a092-46f2-8448-9b32427a54e4
2020-12-03 07:22:18,825 [Listener at localhost/36315] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:18,825 [Listener at localhost/36315] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:18,828 [Thread-197] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:18,829 [Thread-197] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:18,829 [Thread-197] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 and block pool id BP-1381366540-172.17.0.6-1606980134186 is not formatted. Formatting ...
2020-12-03 07:22:18,829 [Thread-197] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1381366540-172.17.0.6-1606980134186 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1381366540-172.17.0.6-1606980134186/current
2020-12-03 07:22:18,890 [Thread-241] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:18,891 [Thread-241] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:18,891 [Thread-241] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 and block pool id BP-1381366540-172.17.0.6-1606980134186 is not formatted. Formatting ...
2020-12-03 07:22:18,891 [Thread-241] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1381366540-172.17.0.6-1606980134186 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1381366540-172.17.0.6-1606980134186/current
2020-12-03 07:22:18,928 [IPC Server handler 8 on default port 46867] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:18,929 [Listener at localhost/36315] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:18,930 [Listener at localhost/36315] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:18,945 [Thread-87] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 0e8b5977-e06f-48fe-92af-e39b9c077e31
2020-12-03 07:22:18,947 [Thread-63] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 88d2a2c7-b145-4b11-a071-9cd675e25027
2020-12-03 07:22:18,948 [Thread-153] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID afd1feac-1349-4680-b546-4b9da88c0fb3
2020-12-03 07:22:18,953 [Thread-153] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-1da9a190-9e06-4f85-a403-b1c9f1a05a12
2020-12-03 07:22:18,953 [Thread-153] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, StorageType: DISK
2020-12-03 07:22:18,953 [Thread-131] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-44c575dd-518f-4d6a-9736-123dfb9ef4e0
2020-12-03 07:22:18,954 [Thread-109] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-a756ff9b-797d-4a9e-926c-68bbc728b725
2020-12-03 07:22:18,954 [Thread-63] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-5e5cd84f-8271-464a-85ba-e85d47b940d8
2020-12-03 07:22:18,953 [Thread-87] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-dcf662f1-c431-4f1d-905d-f2c8a7c53691
2020-12-03 07:22:18,956 [Thread-63] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-12-03 07:22:18,956 [Thread-109] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, StorageType: DISK
2020-12-03 07:22:18,956 [Thread-131] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, StorageType: DISK
2020-12-03 07:22:18,956 [Thread-87] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: DISK
2020-12-03 07:22:18,957 [Thread-153] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-fd189235-0037-4626-b4b3-7bcf8d76254a
2020-12-03 07:22:18,957 [Thread-153] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, StorageType: DISK
2020-12-03 07:22:18,959 [Thread-63] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-6ded7c5e-260d-452e-9a88-6cf4eca391f6
2020-12-03 07:22:18,960 [Thread-63] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-12-03 07:22:18,961 [Thread-87] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-a67153a8-dc0e-41b7-928e-2bec0596e04e
2020-12-03 07:22:18,961 [Thread-87] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: DISK
2020-12-03 07:22:18,962 [Thread-131] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-a8ac44bd-2d90-4975-b170-7e0be4f54f1d
2020-12-03 07:22:18,963 [Thread-131] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, StorageType: DISK
2020-12-03 07:22:18,964 [Thread-109] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-aaa11e61-23fd-4415-8832-dea8228b06ec
2020-12-03 07:22:18,965 [Thread-109] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, StorageType: DISK
2020-12-03 07:22:18,966 [Thread-131] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:22:18,966 [Thread-63] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:22:18,967 [Thread-153] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:22:18,967 [Thread-87] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:22:18,966 [Thread-109] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:22:18,972 [Thread-131] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:22:18,974 [Thread-109] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:22:18,981 [Thread-131] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:22:18,981 [Thread-109] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:22:18,983 [Thread-87] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:22:18,983 [Thread-87] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:22:18,983 [Thread-109] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:22:18,984 [Thread-87] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:22:18,984 [Thread-109] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:22:18,983 [Thread-131] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:22:18,986 [Thread-87] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:22:18,986 [Thread-109] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:18,986 [Thread-131] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:22:18,987 [Thread-87] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:18,987 [Thread-131] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:18,988 [Thread-265] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1381366540-172.17.0.6-1606980134186 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:22:18,988 [Thread-266] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1381366540-172.17.0.6-1606980134186 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:22:18,989 [Thread-267] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1381366540-172.17.0.6-1606980134186 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-12-03 07:22:18,989 [Thread-153] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:22:18,990 [Thread-268] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1381366540-172.17.0.6-1606980134186 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:22:18,990 [Thread-270] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1381366540-172.17.0.6-1606980134186 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-12-03 07:22:18,990 [Thread-269] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1381366540-172.17.0.6-1606980134186 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:22:18,991 [Thread-153] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:22:18,991 [Thread-63] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:22:18,991 [Thread-153] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:22:18,991 [Thread-153] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:22:18,992 [Thread-153] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:18,992 [Thread-63] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:22:18,992 [Thread-63] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:22:18,992 [Thread-271] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1381366540-172.17.0.6-1606980134186 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-12-03 07:22:18,992 [Thread-272] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1381366540-172.17.0.6-1606980134186 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-12-03 07:22:18,992 [Thread-63] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:22:18,995 [Thread-63] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:18,995 [Thread-273] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1381366540-172.17.0.6-1606980134186 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:22:18,995 [Thread-274] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1381366540-172.17.0.6-1606980134186 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:22:19,025 [Thread-219] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:19,026 [Thread-219] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:19,026 [Thread-219] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 and block pool id BP-1381366540-172.17.0.6-1606980134186 is not formatted. Formatting ...
2020-12-03 07:22:19,026 [Thread-219] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1381366540-172.17.0.6-1606980134186 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1381366540-172.17.0.6-1606980134186/current
2020-12-03 07:22:19,032 [IPC Server handler 6 on default port 46867] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:19,033 [Listener at localhost/36315] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:19,033 [Listener at localhost/36315] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:19,060 [Thread-175] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 3cb97ca3-ca98-4950-b55b-e6e794bf8f21
2020-12-03 07:22:19,060 [Thread-197] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=2057979486;bpid=BP-1381366540-172.17.0.6-1606980134186;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=2057979486;c=1606980134186;bpid=BP-1381366540-172.17.0.6-1606980134186;dnuuid=null
2020-12-03 07:22:19,080 [Thread-175] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-b1868b9e-e800-4127-9f6e-905f0d6e29c2
2020-12-03 07:22:19,080 [Thread-175] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, StorageType: DISK
2020-12-03 07:22:19,082 [Thread-175] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-c16f6bf6-3694-486c-a5d2-60f3ca71a13e
2020-12-03 07:22:19,082 [Thread-175] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, StorageType: DISK
2020-12-03 07:22:19,082 [Thread-175] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:22:19,084 [Thread-175] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:22:19,092 [Thread-269] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1381366540-172.17.0.6-1606980134186 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 102ms
2020-12-03 07:22:19,099 [Thread-271] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1381366540-172.17.0.6-1606980134186 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 105ms
2020-12-03 07:22:19,101 [Thread-274] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1381366540-172.17.0.6-1606980134186 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 106ms
2020-12-03 07:22:19,105 [Thread-268] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1381366540-172.17.0.6-1606980134186 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 115ms
2020-12-03 07:22:19,106 [Thread-175] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:22:19,106 [Thread-175] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:22:19,106 [Thread-273] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1381366540-172.17.0.6-1606980134186 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 111ms
2020-12-03 07:22:19,106 [Thread-175] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:22:19,107 [Thread-63] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1381366540-172.17.0.6-1606980134186: 112ms
2020-12-03 07:22:19,107 [Thread-175] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:19,107 [Thread-272] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1381366540-172.17.0.6-1606980134186 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 113ms
2020-12-03 07:22:19,107 [Thread-266] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1381366540-172.17.0.6-1606980134186 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 118ms
2020-12-03 07:22:19,108 [Thread-153] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1381366540-172.17.0.6-1606980134186: 116ms
2020-12-03 07:22:19,108 [Thread-87] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1381366540-172.17.0.6-1606980134186: 121ms
2020-12-03 07:22:19,108 [Thread-270] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1381366540-172.17.0.6-1606980134186 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 118ms
2020-12-03 07:22:19,108 [Thread-287] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1381366540-172.17.0.6-1606980134186 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11...
2020-12-03 07:22:19,108 [Thread-288] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1381366540-172.17.0.6-1606980134186 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12...
2020-12-03 07:22:19,110 [Thread-289] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1381366540-172.17.0.6-1606980134186 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:22:19,110 [Thread-267] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1381366540-172.17.0.6-1606980134186 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 121ms
2020-12-03 07:22:19,110 [Thread-291] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1381366540-172.17.0.6-1606980134186 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:22:19,110 [Thread-289] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1381366540-172.17.0.6-1606980134186/current/replicas doesn't exist 
2020-12-03 07:22:19,110 [Thread-292] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1381366540-172.17.0.6-1606980134186 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:22:19,111 [Thread-265] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1381366540-172.17.0.6-1606980134186 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 123ms
2020-12-03 07:22:19,111 [Thread-109] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1381366540-172.17.0.6-1606980134186: 124ms
2020-12-03 07:22:19,111 [Thread-289] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1381366540-172.17.0.6-1606980134186 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 1ms
2020-12-03 07:22:19,112 [Thread-295] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1381366540-172.17.0.6-1606980134186 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:22:19,112 [Thread-296] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1381366540-172.17.0.6-1606980134186 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:22:19,110 [Thread-291] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1381366540-172.17.0.6-1606980134186/current/replicas doesn't exist 
2020-12-03 07:22:19,110 [Thread-290] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1381366540-172.17.0.6-1606980134186 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-12-03 07:22:19,112 [Thread-296] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1381366540-172.17.0.6-1606980134186/current/replicas doesn't exist 
2020-12-03 07:22:19,118 [Thread-290] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1381366540-172.17.0.6-1606980134186/current/replicas doesn't exist 
2020-12-03 07:22:19,112 [Thread-295] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1381366540-172.17.0.6-1606980134186/current/replicas doesn't exist 
2020-12-03 07:22:19,111 [Thread-292] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1381366540-172.17.0.6-1606980134186/current/replicas doesn't exist 
2020-12-03 07:22:19,119 [Thread-295] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1381366540-172.17.0.6-1606980134186 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 7ms
2020-12-03 07:22:19,119 [Thread-292] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1381366540-172.17.0.6-1606980134186 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 9ms
2020-12-03 07:22:19,119 [Thread-63] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1381366540-172.17.0.6-1606980134186: 10ms
2020-12-03 07:22:19,110 [Thread-293] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1381366540-172.17.0.6-1606980134186 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-12-03 07:22:19,110 [Thread-294] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1381366540-172.17.0.6-1606980134186 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:22:19,121 [Thread-294] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1381366540-172.17.0.6-1606980134186/current/replicas doesn't exist 
2020-12-03 07:22:19,121 [Thread-294] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1381366540-172.17.0.6-1606980134186 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 0ms
2020-12-03 07:22:19,110 [Thread-131] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1381366540-172.17.0.6-1606980134186: 122ms
2020-12-03 07:22:19,124 [Thread-290] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1381366540-172.17.0.6-1606980134186 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 5ms
2020-12-03 07:22:19,123 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1381366540-172.17.0.6-1606980134186 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:22:19,121 [Thread-293] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1381366540-172.17.0.6-1606980134186/current/replicas doesn't exist 
2020-12-03 07:22:19,118 [Thread-296] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1381366540-172.17.0.6-1606980134186 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 6ms
2020-12-03 07:22:19,118 [Thread-291] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1381366540-172.17.0.6-1606980134186 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 8ms
2020-12-03 07:22:19,125 [Thread-109] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1381366540-172.17.0.6-1606980134186: 14ms
2020-12-03 07:22:19,125 [Thread-297] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1381366540-172.17.0.6-1606980134186 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-12-03 07:22:19,128 [Thread-298] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1381366540-172.17.0.6-1606980134186 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-12-03 07:22:19,128 [Thread-297] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1381366540-172.17.0.6-1606980134186/current/replicas doesn't exist 
2020-12-03 07:22:19,128 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1381366540-172.17.0.6-1606980134186 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:22:19,128 [Thread-297] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1381366540-172.17.0.6-1606980134186 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 0ms
2020-12-03 07:22:19,129 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-a756ff9b-797d-4a9e-926c-68bbc728b725): finished scanning block pool BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:19,128 [Thread-87] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1381366540-172.17.0.6-1606980134186: 19ms
2020-12-03 07:22:19,130 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1381366540-172.17.0.6-1606980134186 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:22:19,131 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1381366540-172.17.0.6-1606980134186 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:22:19,131 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-a67153a8-dc0e-41b7-928e-2bec0596e04e): finished scanning block pool BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:19,127 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-5e5cd84f-8271-464a-85ba-e85d47b940d8): finished scanning block pool BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:19,126 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1381366540-172.17.0.6-1606980134186 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:22:19,143 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-aaa11e61-23fd-4415-8832-dea8228b06ec): finished scanning block pool BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:19,143 [IPC Server handler 5 on default port 46867] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:19,126 [Thread-293] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1381366540-172.17.0.6-1606980134186 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 5ms
2020-12-03 07:22:19,143 [Thread-153] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1381366540-172.17.0.6-1606980134186: 34ms
2020-12-03 07:22:19,143 [Listener at localhost/36315] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:19,144 [Listener at localhost/36315] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:19,144 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1381366540-172.17.0.6-1606980134186 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:22:19,144 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-fd189235-0037-4626-b4b3-7bcf8d76254a): finished scanning block pool BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:19,124 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1381366540-172.17.0.6-1606980134186 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:22:19,144 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1381366540-172.17.0.6-1606980134186 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:22:19,138 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-dcf662f1-c431-4f1d-905d-f2c8a7c53691): finished scanning block pool BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:19,138 [Thread-241] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:19,128 [Thread-298] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1381366540-172.17.0.6-1606980134186/current/replicas doesn't exist 
2020-12-03 07:22:19,145 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-1da9a190-9e06-4f85-a403-b1c9f1a05a12): finished scanning block pool BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:19,145 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-6ded7c5e-260d-452e-9a88-6cf4eca391f6): finished scanning block pool BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:19,146 [Thread-241] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:19,146 [Thread-298] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1381366540-172.17.0.6-1606980134186 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 18ms
2020-12-03 07:22:19,146 [Thread-241] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 and block pool id BP-1381366540-172.17.0.6-1606980134186 is not formatted. Formatting ...
2020-12-03 07:22:19,146 [Thread-131] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1381366540-172.17.0.6-1606980134186: 22ms
2020-12-03 07:22:19,146 [Thread-241] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1381366540-172.17.0.6-1606980134186 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1381366540-172.17.0.6-1606980134186/current
2020-12-03 07:22:19,147 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1381366540-172.17.0.6-1606980134186 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:22:19,147 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1381366540-172.17.0.6-1606980134186 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:22:19,147 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-44c575dd-518f-4d6a-9736-123dfb9ef4e0): finished scanning block pool BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:19,147 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-a8ac44bd-2d90-4975-b170-7e0be4f54f1d): finished scanning block pool BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:19,157 [Thread-109] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:13 AM with interval of 21600000ms
2020-12-03 07:22:19,157 [Thread-87] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 1:03 PM with interval of 21600000ms
2020-12-03 07:22:19,157 [Thread-63] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 10:31 AM with interval of 21600000ms
2020-12-03 07:22:19,157 [Thread-131] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 8:10 AM with interval of 21600000ms
2020-12-03 07:22:19,157 [Thread-153] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 8:36 AM with interval of 21600000ms
2020-12-03 07:22:19,160 [Thread-287] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1381366540-172.17.0.6-1606980134186 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11: 51ms
2020-12-03 07:22:19,169 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-dcf662f1-c431-4f1d-905d-f2c8a7c53691): no suitable block pools found to scan.  Waiting 1814399961 ms.
2020-12-03 07:22:19,170 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1381366540-172.17.0.6-1606980134186 (Datanode Uuid 0e8b5977-e06f-48fe-92af-e39b9c077e31) service to localhost/127.0.0.1:46867 beginning handshake with NN
2020-12-03 07:22:19,170 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-a67153a8-dc0e-41b7-928e-2bec0596e04e): no suitable block pools found to scan.  Waiting 1814399960 ms.
2020-12-03 07:22:19,170 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-a756ff9b-797d-4a9e-926c-68bbc728b725): no suitable block pools found to scan.  Waiting 1814399956 ms.
2020-12-03 07:22:19,170 [Thread-288] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1381366540-172.17.0.6-1606980134186 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12: 61ms
2020-12-03 07:22:19,170 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-44c575dd-518f-4d6a-9736-123dfb9ef4e0): no suitable block pools found to scan.  Waiting 1814399977 ms.
2020-12-03 07:22:19,170 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1381366540-172.17.0.6-1606980134186 (Datanode Uuid f52a640d-cec3-4842-be39-1e22246ccbb2) service to localhost/127.0.0.1:46867 beginning handshake with NN
2020-12-03 07:22:19,170 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1381366540-172.17.0.6-1606980134186 (Datanode Uuid afd1feac-1349-4680-b546-4b9da88c0fb3) service to localhost/127.0.0.1:46867 beginning handshake with NN
2020-12-03 07:22:19,170 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1381366540-172.17.0.6-1606980134186 (Datanode Uuid 88d2a2c7-b145-4b11-a071-9cd675e25027) service to localhost/127.0.0.1:46867 beginning handshake with NN
2020-12-03 07:22:19,169 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-1da9a190-9e06-4f85-a403-b1c9f1a05a12): no suitable block pools found to scan.  Waiting 1814399974 ms.
2020-12-03 07:22:19,169 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-5e5cd84f-8271-464a-85ba-e85d47b940d8): no suitable block pools found to scan.  Waiting 1814399952 ms.
2020-12-03 07:22:19,169 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-6ded7c5e-260d-452e-9a88-6cf4eca391f6): no suitable block pools found to scan.  Waiting 1814399955 ms.
2020-12-03 07:22:19,170 [Thread-175] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1381366540-172.17.0.6-1606980134186: 63ms
2020-12-03 07:22:19,170 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1381366540-172.17.0.6-1606980134186 (Datanode Uuid 43e9848a-a092-46f2-8448-9b32427a54e4) service to localhost/127.0.0.1:46867 beginning handshake with NN
2020-12-03 07:22:19,170 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-fd189235-0037-4626-b4b3-7bcf8d76254a): no suitable block pools found to scan.  Waiting 1814399974 ms.
2020-12-03 07:22:19,170 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-aaa11e61-23fd-4415-8832-dea8228b06ec): no suitable block pools found to scan.  Waiting 1814399956 ms.
2020-12-03 07:22:19,170 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-a8ac44bd-2d90-4975-b170-7e0be4f54f1d): no suitable block pools found to scan.  Waiting 1814399977 ms.
2020-12-03 07:22:19,171 [Thread-316] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1381366540-172.17.0.6-1606980134186 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11...
2020-12-03 07:22:19,172 [Thread-317] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1381366540-172.17.0.6-1606980134186 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12...
2020-12-03 07:22:19,172 [Thread-316] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1381366540-172.17.0.6-1606980134186/current/replicas doesn't exist 
2020-12-03 07:22:19,172 [Thread-317] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1381366540-172.17.0.6-1606980134186/current/replicas doesn't exist 
2020-12-03 07:22:19,172 [Thread-317] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1381366540-172.17.0.6-1606980134186 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12: 0ms
2020-12-03 07:22:19,172 [Thread-316] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1381366540-172.17.0.6-1606980134186 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11: 0ms
2020-12-03 07:22:19,174 [Thread-175] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1381366540-172.17.0.6-1606980134186: 2ms
2020-12-03 07:22:19,174 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1381366540-172.17.0.6-1606980134186 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:22:19,174 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1381366540-172.17.0.6-1606980134186 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:22:19,174 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-b1868b9e-e800-4127-9f6e-905f0d6e29c2): finished scanning block pool BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:19,174 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-c16f6bf6-3694-486c-a5d2-60f3ca71a13e): finished scanning block pool BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:19,175 [Thread-175] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 1:05 PM with interval of 21600000ms
2020-12-03 07:22:19,176 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1381366540-172.17.0.6-1606980134186 (Datanode Uuid 3cb97ca3-ca98-4950-b55b-e6e794bf8f21) service to localhost/127.0.0.1:46867 beginning handshake with NN
2020-12-03 07:22:19,176 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-b1868b9e-e800-4127-9f6e-905f0d6e29c2): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-12-03 07:22:19,176 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-c16f6bf6-3694-486c-a5d2-60f3ca71a13e): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-12-03 07:22:19,199 [IPC Server handler 3 on default port 46867] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:36349, datanodeUuid=43e9848a-a092-46f2-8448-9b32427a54e4, infoPort=38741, infoSecurePort=0, ipcPort=42532, storageInfo=lv=-57;cid=testClusterID;nsid=2057979486;c=1606980134186) storage 43e9848a-a092-46f2-8448-9b32427a54e4
2020-12-03 07:22:19,201 [IPC Server handler 3 on default port 46867] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36349
2020-12-03 07:22:19,202 [IPC Server handler 3 on default port 46867] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 43e9848a-a092-46f2-8448-9b32427a54e4 (127.0.0.1:36349).
2020-12-03 07:22:19,209 [IPC Server handler 4 on default port 46867] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35589, datanodeUuid=0e8b5977-e06f-48fe-92af-e39b9c077e31, infoPort=33086, infoSecurePort=0, ipcPort=35629, storageInfo=lv=-57;cid=testClusterID;nsid=2057979486;c=1606980134186) storage 0e8b5977-e06f-48fe-92af-e39b9c077e31
2020-12-03 07:22:19,209 [IPC Server handler 4 on default port 46867] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:35589
2020-12-03 07:22:19,210 [IPC Server handler 4 on default port 46867] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 0e8b5977-e06f-48fe-92af-e39b9c077e31 (127.0.0.1:35589).
2020-12-03 07:22:19,210 [IPC Server handler 9 on default port 46867] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:45410, datanodeUuid=3cb97ca3-ca98-4950-b55b-e6e794bf8f21, infoPort=43592, infoSecurePort=0, ipcPort=36001, storageInfo=lv=-57;cid=testClusterID;nsid=2057979486;c=1606980134186) storage 3cb97ca3-ca98-4950-b55b-e6e794bf8f21
2020-12-03 07:22:19,210 [IPC Server handler 9 on default port 46867] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:45410
2020-12-03 07:22:19,210 [IPC Server handler 9 on default port 46867] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 3cb97ca3-ca98-4950-b55b-e6e794bf8f21 (127.0.0.1:45410).
2020-12-03 07:22:19,211 [IPC Server handler 0 on default port 46867] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35466, datanodeUuid=88d2a2c7-b145-4b11-a071-9cd675e25027, infoPort=38786, infoSecurePort=0, ipcPort=34703, storageInfo=lv=-57;cid=testClusterID;nsid=2057979486;c=1606980134186) storage 88d2a2c7-b145-4b11-a071-9cd675e25027
2020-12-03 07:22:19,211 [IPC Server handler 0 on default port 46867] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:35466
2020-12-03 07:22:19,211 [IPC Server handler 0 on default port 46867] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 88d2a2c7-b145-4b11-a071-9cd675e25027 (127.0.0.1:35466).
2020-12-03 07:22:19,212 [IPC Server handler 1 on default port 46867] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:41230, datanodeUuid=afd1feac-1349-4680-b546-4b9da88c0fb3, infoPort=46350, infoSecurePort=0, ipcPort=35404, storageInfo=lv=-57;cid=testClusterID;nsid=2057979486;c=1606980134186) storage afd1feac-1349-4680-b546-4b9da88c0fb3
2020-12-03 07:22:19,212 [IPC Server handler 1 on default port 46867] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41230
2020-12-03 07:22:19,212 [IPC Server handler 1 on default port 46867] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN afd1feac-1349-4680-b546-4b9da88c0fb3 (127.0.0.1:41230).
2020-12-03 07:22:19,212 [IPC Server handler 2 on default port 46867] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35197, datanodeUuid=f52a640d-cec3-4842-be39-1e22246ccbb2, infoPort=33921, infoSecurePort=0, ipcPort=46511, storageInfo=lv=-57;cid=testClusterID;nsid=2057979486;c=1606980134186) storage f52a640d-cec3-4842-be39-1e22246ccbb2
2020-12-03 07:22:19,213 [IPC Server handler 2 on default port 46867] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:35197
2020-12-03 07:22:19,213 [IPC Server handler 2 on default port 46867] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN f52a640d-cec3-4842-be39-1e22246ccbb2 (127.0.0.1:35197).
2020-12-03 07:22:19,225 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1381366540-172.17.0.6-1606980134186 (Datanode Uuid 43e9848a-a092-46f2-8448-9b32427a54e4) service to localhost/127.0.0.1:46867 successfully registered with NN
2020-12-03 07:22:19,226 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1381366540-172.17.0.6-1606980134186 (Datanode Uuid 88d2a2c7-b145-4b11-a071-9cd675e25027) service to localhost/127.0.0.1:46867 successfully registered with NN
2020-12-03 07:22:19,225 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1381366540-172.17.0.6-1606980134186 (Datanode Uuid afd1feac-1349-4680-b546-4b9da88c0fb3) service to localhost/127.0.0.1:46867 successfully registered with NN
2020-12-03 07:22:19,226 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:46867 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:22:19,227 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:46867 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:22:19,226 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:46867 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:22:19,226 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1381366540-172.17.0.6-1606980134186 (Datanode Uuid 0e8b5977-e06f-48fe-92af-e39b9c077e31) service to localhost/127.0.0.1:46867 successfully registered with NN
2020-12-03 07:22:19,227 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:46867 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:22:19,226 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1381366540-172.17.0.6-1606980134186 (Datanode Uuid f52a640d-cec3-4842-be39-1e22246ccbb2) service to localhost/127.0.0.1:46867 successfully registered with NN
2020-12-03 07:22:19,228 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:46867 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:22:19,229 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1381366540-172.17.0.6-1606980134186 (Datanode Uuid 3cb97ca3-ca98-4950-b55b-e6e794bf8f21) service to localhost/127.0.0.1:46867 successfully registered with NN
2020-12-03 07:22:19,229 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:46867 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:22:19,253 [IPC Server handler 7 on default port 46867] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-5e5cd84f-8271-464a-85ba-e85d47b940d8 for DN 127.0.0.1:35466
2020-12-03 07:22:19,254 [IPC Server handler 7 on default port 46867] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-6ded7c5e-260d-452e-9a88-6cf4eca391f6 for DN 127.0.0.1:35466
2020-12-03 07:22:19,255 [IPC Server handler 5 on default port 46867] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-1da9a190-9e06-4f85-a403-b1c9f1a05a12 for DN 127.0.0.1:41230
2020-12-03 07:22:19,256 [IPC Server handler 5 on default port 46867] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-fd189235-0037-4626-b4b3-7bcf8d76254a for DN 127.0.0.1:41230
2020-12-03 07:22:19,257 [IPC Server handler 3 on default port 46867] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-dcf662f1-c431-4f1d-905d-f2c8a7c53691 for DN 127.0.0.1:35589
2020-12-03 07:22:19,257 [IPC Server handler 3 on default port 46867] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-a67153a8-dc0e-41b7-928e-2bec0596e04e for DN 127.0.0.1:35589
2020-12-03 07:22:19,258 [IPC Server handler 1 on default port 46867] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-44c575dd-518f-4d6a-9736-123dfb9ef4e0 for DN 127.0.0.1:35197
2020-12-03 07:22:19,258 [IPC Server handler 1 on default port 46867] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-a8ac44bd-2d90-4975-b170-7e0be4f54f1d for DN 127.0.0.1:35197
2020-12-03 07:22:19,259 [IPC Server handler 8 on default port 46867] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-a756ff9b-797d-4a9e-926c-68bbc728b725 for DN 127.0.0.1:36349
2020-12-03 07:22:19,259 [IPC Server handler 8 on default port 46867] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-aaa11e61-23fd-4415-8832-dea8228b06ec for DN 127.0.0.1:36349
2020-12-03 07:22:19,259 [Thread-219] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=2057979486;bpid=BP-1381366540-172.17.0.6-1606980134186;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=2057979486;c=1606980134186;bpid=BP-1381366540-172.17.0.6-1606980134186;dnuuid=null
2020-12-03 07:22:19,260 [IPC Server handler 0 on default port 46867] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-b1868b9e-e800-4127-9f6e-905f0d6e29c2 for DN 127.0.0.1:45410
2020-12-03 07:22:19,260 [IPC Server handler 0 on default port 46867] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c16f6bf6-3694-486c-a5d2-60f3ca71a13e for DN 127.0.0.1:45410
2020-12-03 07:22:19,261 [IPC Server handler 6 on default port 46867] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:19,271 [Listener at localhost/36315] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:19,271 [Listener at localhost/36315] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:19,293 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xcec1f3a0e4ac5b14: Processing first storage report for DS-aaa11e61-23fd-4415-8832-dea8228b06ec from datanode 43e9848a-a092-46f2-8448-9b32427a54e4
2020-12-03 07:22:19,295 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xcec1f3a0e4ac5b14: from storage DS-aaa11e61-23fd-4415-8832-dea8228b06ec node DatanodeRegistration(127.0.0.1:36349, datanodeUuid=43e9848a-a092-46f2-8448-9b32427a54e4, infoPort=38741, infoSecurePort=0, ipcPort=42532, storageInfo=lv=-57;cid=testClusterID;nsid=2057979486;c=1606980134186), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:22:19,295 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xf3de34a48d3dd808: Processing first storage report for DS-dcf662f1-c431-4f1d-905d-f2c8a7c53691 from datanode 0e8b5977-e06f-48fe-92af-e39b9c077e31
2020-12-03 07:22:19,295 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xf3de34a48d3dd808: from storage DS-dcf662f1-c431-4f1d-905d-f2c8a7c53691 node DatanodeRegistration(127.0.0.1:35589, datanodeUuid=0e8b5977-e06f-48fe-92af-e39b9c077e31, infoPort=33086, infoSecurePort=0, ipcPort=35629, storageInfo=lv=-57;cid=testClusterID;nsid=2057979486;c=1606980134186), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:19,295 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xc42af55630983e70: Processing first storage report for DS-5e5cd84f-8271-464a-85ba-e85d47b940d8 from datanode 88d2a2c7-b145-4b11-a071-9cd675e25027
2020-12-03 07:22:19,295 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xc42af55630983e70: from storage DS-5e5cd84f-8271-464a-85ba-e85d47b940d8 node DatanodeRegistration(127.0.0.1:35466, datanodeUuid=88d2a2c7-b145-4b11-a071-9cd675e25027, infoPort=38786, infoSecurePort=0, ipcPort=34703, storageInfo=lv=-57;cid=testClusterID;nsid=2057979486;c=1606980134186), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:19,295 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x92aa52835e4436cb: Processing first storage report for DS-b1868b9e-e800-4127-9f6e-905f0d6e29c2 from datanode 3cb97ca3-ca98-4950-b55b-e6e794bf8f21
2020-12-03 07:22:19,295 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x92aa52835e4436cb: from storage DS-b1868b9e-e800-4127-9f6e-905f0d6e29c2 node DatanodeRegistration(127.0.0.1:45410, datanodeUuid=3cb97ca3-ca98-4950-b55b-e6e794bf8f21, infoPort=43592, infoSecurePort=0, ipcPort=36001, storageInfo=lv=-57;cid=testClusterID;nsid=2057979486;c=1606980134186), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:19,296 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x1bbdb7e45cbf18d9: Processing first storage report for DS-1da9a190-9e06-4f85-a403-b1c9f1a05a12 from datanode afd1feac-1349-4680-b546-4b9da88c0fb3
2020-12-03 07:22:19,296 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x1bbdb7e45cbf18d9: from storage DS-1da9a190-9e06-4f85-a403-b1c9f1a05a12 node DatanodeRegistration(127.0.0.1:41230, datanodeUuid=afd1feac-1349-4680-b546-4b9da88c0fb3, infoPort=46350, infoSecurePort=0, ipcPort=35404, storageInfo=lv=-57;cid=testClusterID;nsid=2057979486;c=1606980134186), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:22:19,296 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x4c111979f12522b8: Processing first storage report for DS-44c575dd-518f-4d6a-9736-123dfb9ef4e0 from datanode f52a640d-cec3-4842-be39-1e22246ccbb2
2020-12-03 07:22:19,296 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x4c111979f12522b8: from storage DS-44c575dd-518f-4d6a-9736-123dfb9ef4e0 node DatanodeRegistration(127.0.0.1:35197, datanodeUuid=f52a640d-cec3-4842-be39-1e22246ccbb2, infoPort=33921, infoSecurePort=0, ipcPort=46511, storageInfo=lv=-57;cid=testClusterID;nsid=2057979486;c=1606980134186), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:19,296 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xcec1f3a0e4ac5b14: Processing first storage report for DS-a756ff9b-797d-4a9e-926c-68bbc728b725 from datanode 43e9848a-a092-46f2-8448-9b32427a54e4
2020-12-03 07:22:19,296 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xcec1f3a0e4ac5b14: from storage DS-a756ff9b-797d-4a9e-926c-68bbc728b725 node DatanodeRegistration(127.0.0.1:36349, datanodeUuid=43e9848a-a092-46f2-8448-9b32427a54e4, infoPort=38741, infoSecurePort=0, ipcPort=42532, storageInfo=lv=-57;cid=testClusterID;nsid=2057979486;c=1606980134186), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:19,296 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xf3de34a48d3dd808: Processing first storage report for DS-a67153a8-dc0e-41b7-928e-2bec0596e04e from datanode 0e8b5977-e06f-48fe-92af-e39b9c077e31
2020-12-03 07:22:19,297 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xf3de34a48d3dd808: from storage DS-a67153a8-dc0e-41b7-928e-2bec0596e04e node DatanodeRegistration(127.0.0.1:35589, datanodeUuid=0e8b5977-e06f-48fe-92af-e39b9c077e31, infoPort=33086, infoSecurePort=0, ipcPort=35629, storageInfo=lv=-57;cid=testClusterID;nsid=2057979486;c=1606980134186), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:19,297 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xc42af55630983e70: Processing first storage report for DS-6ded7c5e-260d-452e-9a88-6cf4eca391f6 from datanode 88d2a2c7-b145-4b11-a071-9cd675e25027
2020-12-03 07:22:19,297 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xc42af55630983e70: from storage DS-6ded7c5e-260d-452e-9a88-6cf4eca391f6 node DatanodeRegistration(127.0.0.1:35466, datanodeUuid=88d2a2c7-b145-4b11-a071-9cd675e25027, infoPort=38786, infoSecurePort=0, ipcPort=34703, storageInfo=lv=-57;cid=testClusterID;nsid=2057979486;c=1606980134186), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:19,297 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x92aa52835e4436cb: Processing first storage report for DS-c16f6bf6-3694-486c-a5d2-60f3ca71a13e from datanode 3cb97ca3-ca98-4950-b55b-e6e794bf8f21
2020-12-03 07:22:19,297 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x92aa52835e4436cb: from storage DS-c16f6bf6-3694-486c-a5d2-60f3ca71a13e node DatanodeRegistration(127.0.0.1:45410, datanodeUuid=3cb97ca3-ca98-4950-b55b-e6e794bf8f21, infoPort=43592, infoSecurePort=0, ipcPort=36001, storageInfo=lv=-57;cid=testClusterID;nsid=2057979486;c=1606980134186), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:19,297 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x1bbdb7e45cbf18d9: Processing first storage report for DS-fd189235-0037-4626-b4b3-7bcf8d76254a from datanode afd1feac-1349-4680-b546-4b9da88c0fb3
2020-12-03 07:22:19,297 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x1bbdb7e45cbf18d9: from storage DS-fd189235-0037-4626-b4b3-7bcf8d76254a node DatanodeRegistration(127.0.0.1:41230, datanodeUuid=afd1feac-1349-4680-b546-4b9da88c0fb3, infoPort=46350, infoSecurePort=0, ipcPort=35404, storageInfo=lv=-57;cid=testClusterID;nsid=2057979486;c=1606980134186), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:19,298 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x4c111979f12522b8: Processing first storage report for DS-a8ac44bd-2d90-4975-b170-7e0be4f54f1d from datanode f52a640d-cec3-4842-be39-1e22246ccbb2
2020-12-03 07:22:19,298 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x4c111979f12522b8: from storage DS-a8ac44bd-2d90-4975-b170-7e0be4f54f1d node DatanodeRegistration(127.0.0.1:35197, datanodeUuid=f52a640d-cec3-4842-be39-1e22246ccbb2, infoPort=33921, infoSecurePort=0, ipcPort=46511, storageInfo=lv=-57;cid=testClusterID;nsid=2057979486;c=1606980134186), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:22:19,298 [Thread-197] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 76e075f9-8394-4c92-8ea2-4b4d0cca38e9
2020-12-03 07:22:19,302 [Thread-197] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-b720b757-1081-4f84-a9d2-42cf7586af8d
2020-12-03 07:22:19,302 [Thread-197] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, StorageType: DISK
2020-12-03 07:22:19,305 [Thread-197] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-f69d61df-5ff2-4e47-9f2d-eb2ce927381c
2020-12-03 07:22:19,306 [Thread-197] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, StorageType: DISK
2020-12-03 07:22:19,307 [Thread-197] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:22:19,308 [Thread-197] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:22:19,309 [Thread-197] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:22:19,309 [Thread-197] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:22:19,310 [Thread-197] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:22:19,310 [Thread-197] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:19,311 [Thread-323] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1381366540-172.17.0.6-1606980134186 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13...
2020-12-03 07:22:19,312 [Thread-324] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1381366540-172.17.0.6-1606980134186 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14...
2020-12-03 07:22:19,320 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xcec1f3a0e4ac5b14,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 44 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:19,330 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x4c111979f12522b8,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 55 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:19,330 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xf3de34a48d3dd808,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 45 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:19,320 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xc42af55630983e70,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 44 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:19,331 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:19,332 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x92aa52835e4436cb,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 56 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:19,331 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:19,331 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:19,332 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x1bbdb7e45cbf18d9,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 56 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:19,331 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:19,334 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:19,334 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:19,348 [Thread-241] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=2057979486;bpid=BP-1381366540-172.17.0.6-1606980134186;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=2057979486;c=1606980134186;bpid=BP-1381366540-172.17.0.6-1606980134186;dnuuid=null
2020-12-03 07:22:19,351 [Thread-324] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1381366540-172.17.0.6-1606980134186 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14: 38ms
2020-12-03 07:22:19,351 [Thread-323] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1381366540-172.17.0.6-1606980134186 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13: 39ms
2020-12-03 07:22:19,352 [Thread-197] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1381366540-172.17.0.6-1606980134186: 42ms
2020-12-03 07:22:19,352 [Thread-327] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1381366540-172.17.0.6-1606980134186 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13...
2020-12-03 07:22:19,352 [Thread-327] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1381366540-172.17.0.6-1606980134186/current/replicas doesn't exist 
2020-12-03 07:22:19,352 [Thread-328] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1381366540-172.17.0.6-1606980134186 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14...
2020-12-03 07:22:19,353 [Thread-328] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1381366540-172.17.0.6-1606980134186/current/replicas doesn't exist 
2020-12-03 07:22:19,353 [Thread-327] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1381366540-172.17.0.6-1606980134186 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13: 1ms
2020-12-03 07:22:19,353 [Thread-328] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1381366540-172.17.0.6-1606980134186 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14: 1ms
2020-12-03 07:22:19,353 [Thread-197] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1381366540-172.17.0.6-1606980134186: 1ms
2020-12-03 07:22:19,354 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1381366540-172.17.0.6-1606980134186 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:22:19,354 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1381366540-172.17.0.6-1606980134186 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:22:19,354 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-b720b757-1081-4f84-a9d2-42cf7586af8d): finished scanning block pool BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:19,354 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-f69d61df-5ff2-4e47-9f2d-eb2ce927381c): finished scanning block pool BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:19,354 [Thread-197] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:46 AM with interval of 21600000ms
2020-12-03 07:22:19,355 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-b720b757-1081-4f84-a9d2-42cf7586af8d): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:22:19,355 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-f69d61df-5ff2-4e47-9f2d-eb2ce927381c): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:22:19,356 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1381366540-172.17.0.6-1606980134186 (Datanode Uuid 76e075f9-8394-4c92-8ea2-4b4d0cca38e9) service to localhost/127.0.0.1:46867 beginning handshake with NN
2020-12-03 07:22:19,358 [IPC Server handler 7 on default port 46867] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:38755, datanodeUuid=76e075f9-8394-4c92-8ea2-4b4d0cca38e9, infoPort=45132, infoSecurePort=0, ipcPort=44256, storageInfo=lv=-57;cid=testClusterID;nsid=2057979486;c=1606980134186) storage 76e075f9-8394-4c92-8ea2-4b4d0cca38e9
2020-12-03 07:22:19,359 [IPC Server handler 7 on default port 46867] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38755
2020-12-03 07:22:19,359 [IPC Server handler 7 on default port 46867] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 76e075f9-8394-4c92-8ea2-4b4d0cca38e9 (127.0.0.1:38755).
2020-12-03 07:22:19,360 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1381366540-172.17.0.6-1606980134186 (Datanode Uuid 76e075f9-8394-4c92-8ea2-4b4d0cca38e9) service to localhost/127.0.0.1:46867 successfully registered with NN
2020-12-03 07:22:19,360 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:46867 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:22:19,363 [IPC Server handler 3 on default port 46867] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-b720b757-1081-4f84-a9d2-42cf7586af8d for DN 127.0.0.1:38755
2020-12-03 07:22:19,363 [IPC Server handler 3 on default port 46867] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-f69d61df-5ff2-4e47-9f2d-eb2ce927381c for DN 127.0.0.1:38755
2020-12-03 07:22:19,366 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x2b39500b6a6a6367: Processing first storage report for DS-f69d61df-5ff2-4e47-9f2d-eb2ce927381c from datanode 76e075f9-8394-4c92-8ea2-4b4d0cca38e9
2020-12-03 07:22:19,366 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x2b39500b6a6a6367: from storage DS-f69d61df-5ff2-4e47-9f2d-eb2ce927381c node DatanodeRegistration(127.0.0.1:38755, datanodeUuid=76e075f9-8394-4c92-8ea2-4b4d0cca38e9, infoPort=45132, infoSecurePort=0, ipcPort=44256, storageInfo=lv=-57;cid=testClusterID;nsid=2057979486;c=1606980134186), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:19,366 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x2b39500b6a6a6367: Processing first storage report for DS-b720b757-1081-4f84-a9d2-42cf7586af8d from datanode 76e075f9-8394-4c92-8ea2-4b4d0cca38e9
2020-12-03 07:22:19,367 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x2b39500b6a6a6367: from storage DS-b720b757-1081-4f84-a9d2-42cf7586af8d node DatanodeRegistration(127.0.0.1:38755, datanodeUuid=76e075f9-8394-4c92-8ea2-4b4d0cca38e9, infoPort=45132, infoSecurePort=0, ipcPort=44256, storageInfo=lv=-57;cid=testClusterID;nsid=2057979486;c=1606980134186), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:19,367 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x2b39500b6a6a6367,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:19,367 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:19,373 [IPC Server handler 6 on default port 46867] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:19,375 [Listener at localhost/36315] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:19,375 [Listener at localhost/36315] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:19,439 [Thread-219] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 1642b796-0ef3-4f48-a49a-38b308222cba
2020-12-03 07:22:19,443 [Thread-219] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-26fd1b49-3ac0-4652-9e2b-01266ac6cd25
2020-12-03 07:22:19,443 [Thread-219] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, StorageType: DISK
2020-12-03 07:22:19,452 [Thread-219] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-d07d3af6-0c3e-4eda-bf94-13f5cbd7954e
2020-12-03 07:22:19,452 [Thread-219] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, StorageType: DISK
2020-12-03 07:22:19,453 [Thread-219] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:22:19,454 [Thread-219] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:22:19,455 [Thread-219] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:22:19,456 [Thread-219] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:22:19,456 [Thread-219] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:22:19,465 [Warm Up EDEK Cache Thread #0] INFO  namenode.NameNode (FSDirEncryptionZoneOp.java:run(589)) - Successfully warmed up 0 EDEKs.
2020-12-03 07:22:19,473 [Thread-219] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:19,473 [Thread-334] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1381366540-172.17.0.6-1606980134186 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15...
2020-12-03 07:22:19,475 [Thread-335] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1381366540-172.17.0.6-1606980134186 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16...
2020-12-03 07:22:19,481 [IPC Server handler 8 on default port 46867] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:19,482 [Listener at localhost/36315] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:19,483 [Listener at localhost/36315] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:19,514 [Thread-334] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1381366540-172.17.0.6-1606980134186 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15: 41ms
2020-12-03 07:22:19,516 [Thread-335] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1381366540-172.17.0.6-1606980134186 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16: 41ms
2020-12-03 07:22:19,516 [Thread-219] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1381366540-172.17.0.6-1606980134186: 43ms
2020-12-03 07:22:19,517 [Thread-338] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1381366540-172.17.0.6-1606980134186 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15...
2020-12-03 07:22:19,517 [Thread-339] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1381366540-172.17.0.6-1606980134186 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16...
2020-12-03 07:22:19,517 [Thread-338] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1381366540-172.17.0.6-1606980134186/current/replicas doesn't exist 
2020-12-03 07:22:19,517 [Thread-339] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1381366540-172.17.0.6-1606980134186/current/replicas doesn't exist 
2020-12-03 07:22:19,517 [Thread-338] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1381366540-172.17.0.6-1606980134186 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15: 0ms
2020-12-03 07:22:19,518 [Thread-339] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1381366540-172.17.0.6-1606980134186 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16: 0ms
2020-12-03 07:22:19,518 [Thread-219] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1381366540-172.17.0.6-1606980134186: 2ms
2020-12-03 07:22:19,518 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1381366540-172.17.0.6-1606980134186 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:22:19,518 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1381366540-172.17.0.6-1606980134186 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:22:19,519 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-26fd1b49-3ac0-4652-9e2b-01266ac6cd25): finished scanning block pool BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:19,519 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-d07d3af6-0c3e-4eda-bf94-13f5cbd7954e): finished scanning block pool BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:19,519 [Thread-219] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 9:11 AM with interval of 21600000ms
2020-12-03 07:22:19,519 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-26fd1b49-3ac0-4652-9e2b-01266ac6cd25): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:22:19,522 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1381366540-172.17.0.6-1606980134186 (Datanode Uuid 1642b796-0ef3-4f48-a49a-38b308222cba) service to localhost/127.0.0.1:46867 beginning handshake with NN
2020-12-03 07:22:19,523 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-d07d3af6-0c3e-4eda-bf94-13f5cbd7954e): no suitable block pools found to scan.  Waiting 1814399995 ms.
2020-12-03 07:22:19,524 [IPC Server handler 9 on default port 46867] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:33247, datanodeUuid=1642b796-0ef3-4f48-a49a-38b308222cba, infoPort=36390, infoSecurePort=0, ipcPort=40756, storageInfo=lv=-57;cid=testClusterID;nsid=2057979486;c=1606980134186) storage 1642b796-0ef3-4f48-a49a-38b308222cba
2020-12-03 07:22:19,525 [IPC Server handler 9 on default port 46867] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:33247
2020-12-03 07:22:19,525 [IPC Server handler 9 on default port 46867] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 1642b796-0ef3-4f48-a49a-38b308222cba (127.0.0.1:33247).
2020-12-03 07:22:19,526 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1381366540-172.17.0.6-1606980134186 (Datanode Uuid 1642b796-0ef3-4f48-a49a-38b308222cba) service to localhost/127.0.0.1:46867 successfully registered with NN
2020-12-03 07:22:19,526 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:46867 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:22:19,529 [IPC Server handler 2 on default port 46867] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-26fd1b49-3ac0-4652-9e2b-01266ac6cd25 for DN 127.0.0.1:33247
2020-12-03 07:22:19,529 [IPC Server handler 2 on default port 46867] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d07d3af6-0c3e-4eda-bf94-13f5cbd7954e for DN 127.0.0.1:33247
2020-12-03 07:22:19,533 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x7e67c5d77bae01d9: Processing first storage report for DS-26fd1b49-3ac0-4652-9e2b-01266ac6cd25 from datanode 1642b796-0ef3-4f48-a49a-38b308222cba
2020-12-03 07:22:19,534 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x7e67c5d77bae01d9: from storage DS-26fd1b49-3ac0-4652-9e2b-01266ac6cd25 node DatanodeRegistration(127.0.0.1:33247, datanodeUuid=1642b796-0ef3-4f48-a49a-38b308222cba, infoPort=36390, infoSecurePort=0, ipcPort=40756, storageInfo=lv=-57;cid=testClusterID;nsid=2057979486;c=1606980134186), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:19,534 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x7e67c5d77bae01d9: Processing first storage report for DS-d07d3af6-0c3e-4eda-bf94-13f5cbd7954e from datanode 1642b796-0ef3-4f48-a49a-38b308222cba
2020-12-03 07:22:19,534 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x7e67c5d77bae01d9: from storage DS-d07d3af6-0c3e-4eda-bf94-13f5cbd7954e node DatanodeRegistration(127.0.0.1:33247, datanodeUuid=1642b796-0ef3-4f48-a49a-38b308222cba, infoPort=36390, infoSecurePort=0, ipcPort=40756, storageInfo=lv=-57;cid=testClusterID;nsid=2057979486;c=1606980134186), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:19,535 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x7e67c5d77bae01d9,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 5 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:19,535 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:19,565 [Thread-241] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 0f8167d5-dd27-446a-9a96-6922e7c7a7a7
2020-12-03 07:22:19,568 [Thread-241] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-372699bb-d6ed-4718-be65-3b97a1865aff
2020-12-03 07:22:19,569 [Thread-241] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, StorageType: DISK
2020-12-03 07:22:19,570 [Thread-241] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-bd138a52-784f-4b6f-b6ff-f75aed74d335
2020-12-03 07:22:19,570 [Thread-241] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, StorageType: DISK
2020-12-03 07:22:19,572 [Thread-241] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:22:19,573 [Thread-241] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:22:19,573 [Thread-241] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:22:19,574 [Thread-241] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:22:19,574 [Thread-241] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:22:19,574 [Thread-241] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:19,574 [Thread-345] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1381366540-172.17.0.6-1606980134186 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17...
2020-12-03 07:22:19,574 [Thread-346] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1381366540-172.17.0.6-1606980134186 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18...
2020-12-03 07:22:19,585 [IPC Server handler 5 on default port 46867] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:19,587 [Listener at localhost/36315] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:22:19,587 [Listener at localhost/36315] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:22:19,616 [Thread-346] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1381366540-172.17.0.6-1606980134186 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18: 42ms
2020-12-03 07:22:19,618 [Thread-345] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1381366540-172.17.0.6-1606980134186 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17: 44ms
2020-12-03 07:22:19,621 [Thread-241] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1381366540-172.17.0.6-1606980134186: 47ms
2020-12-03 07:22:19,622 [Thread-349] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1381366540-172.17.0.6-1606980134186 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17...
2020-12-03 07:22:19,622 [Thread-349] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1381366540-172.17.0.6-1606980134186/current/replicas doesn't exist 
2020-12-03 07:22:19,622 [Thread-349] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1381366540-172.17.0.6-1606980134186 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17: 0ms
2020-12-03 07:22:19,622 [Thread-350] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1381366540-172.17.0.6-1606980134186 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18...
2020-12-03 07:22:19,623 [Thread-350] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1381366540-172.17.0.6-1606980134186/current/replicas doesn't exist 
2020-12-03 07:22:19,627 [Thread-350] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1381366540-172.17.0.6-1606980134186 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18: 4ms
2020-12-03 07:22:19,628 [Thread-241] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1381366540-172.17.0.6-1606980134186: 7ms
2020-12-03 07:22:19,628 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1381366540-172.17.0.6-1606980134186 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:22:19,628 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1381366540-172.17.0.6-1606980134186 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:22:19,629 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-bd138a52-784f-4b6f-b6ff-f75aed74d335): finished scanning block pool BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:19,629 [Thread-241] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 8:04 AM with interval of 21600000ms
2020-12-03 07:22:19,629 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-372699bb-d6ed-4718-be65-3b97a1865aff): finished scanning block pool BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:19,629 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-bd138a52-784f-4b6f-b6ff-f75aed74d335): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:22:19,630 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-372699bb-d6ed-4718-be65-3b97a1865aff): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-12-03 07:22:19,631 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1381366540-172.17.0.6-1606980134186 (Datanode Uuid 0f8167d5-dd27-446a-9a96-6922e7c7a7a7) service to localhost/127.0.0.1:46867 beginning handshake with NN
2020-12-03 07:22:19,634 [IPC Server handler 0 on default port 46867] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:46171, datanodeUuid=0f8167d5-dd27-446a-9a96-6922e7c7a7a7, infoPort=34647, infoSecurePort=0, ipcPort=36315, storageInfo=lv=-57;cid=testClusterID;nsid=2057979486;c=1606980134186) storage 0f8167d5-dd27-446a-9a96-6922e7c7a7a7
2020-12-03 07:22:19,634 [IPC Server handler 0 on default port 46867] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:46171
2020-12-03 07:22:19,634 [IPC Server handler 0 on default port 46867] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 0f8167d5-dd27-446a-9a96-6922e7c7a7a7 (127.0.0.1:46171).
2020-12-03 07:22:19,635 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1381366540-172.17.0.6-1606980134186 (Datanode Uuid 0f8167d5-dd27-446a-9a96-6922e7c7a7a7) service to localhost/127.0.0.1:46867 successfully registered with NN
2020-12-03 07:22:19,635 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:46867 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:22:19,639 [IPC Server handler 7 on default port 46867] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-372699bb-d6ed-4718-be65-3b97a1865aff for DN 127.0.0.1:46171
2020-12-03 07:22:19,639 [IPC Server handler 7 on default port 46867] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-bd138a52-784f-4b6f-b6ff-f75aed74d335 for DN 127.0.0.1:46171
2020-12-03 07:22:19,647 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xf42cc0d3ae68ed74: Processing first storage report for DS-bd138a52-784f-4b6f-b6ff-f75aed74d335 from datanode 0f8167d5-dd27-446a-9a96-6922e7c7a7a7
2020-12-03 07:22:19,648 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xf42cc0d3ae68ed74: from storage DS-bd138a52-784f-4b6f-b6ff-f75aed74d335 node DatanodeRegistration(127.0.0.1:46171, datanodeUuid=0f8167d5-dd27-446a-9a96-6922e7c7a7a7, infoPort=34647, infoSecurePort=0, ipcPort=36315, storageInfo=lv=-57;cid=testClusterID;nsid=2057979486;c=1606980134186), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:19,648 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xf42cc0d3ae68ed74: Processing first storage report for DS-372699bb-d6ed-4718-be65-3b97a1865aff from datanode 0f8167d5-dd27-446a-9a96-6922e7c7a7a7
2020-12-03 07:22:19,648 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xf42cc0d3ae68ed74: from storage DS-372699bb-d6ed-4718-be65-3b97a1865aff node DatanodeRegistration(127.0.0.1:46171, datanodeUuid=0f8167d5-dd27-446a-9a96-6922e7c7a7a7, infoPort=34647, infoSecurePort=0, ipcPort=36315, storageInfo=lv=-57;cid=testClusterID;nsid=2057979486;c=1606980134186), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:19,649 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xf42cc0d3ae68ed74,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 9 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:19,649 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:19,690 [IPC Server handler 1 on default port 46867] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:19,694 [Listener at localhost/36315] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:22:19,702 [IPC Server handler 6 on default port 46867] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:19,704 [Listener at localhost/36315] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:22:19,723 [IPC Server handler 8 on default port 46867] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=enableErasureCodingPolicy	src=RS-6-3-1024k	dst=null	perm=null	proto=rpc
2020-12-03 07:22:19,735 [IPC Server handler 9 on default port 46867] INFO  namenode.ErasureCodingPolicyManager (ErasureCodingPolicyManager.java:enablePolicy(429)) - Enable the erasure coding policy RS-3-2-1024k
2020-12-03 07:22:19,736 [IPC Server handler 9 on default port 46867] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=enableErasureCodingPolicy	src=RS-3-2-1024k	dst=null	perm=null	proto=rpc
2020-12-03 07:22:19,737 [IPC Server handler 2 on default port 46867] INFO  namenode.ErasureCodingPolicyManager (ErasureCodingPolicyManager.java:enablePolicy(429)) - Enable the erasure coding policy RS-LEGACY-6-3-1024k
2020-12-03 07:22:19,737 [IPC Server handler 2 on default port 46867] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=enableErasureCodingPolicy	src=RS-LEGACY-6-3-1024k	dst=null	perm=null	proto=rpc
2020-12-03 07:22:19,739 [IPC Server handler 4 on default port 46867] INFO  namenode.ErasureCodingPolicyManager (ErasureCodingPolicyManager.java:enablePolicy(429)) - Enable the erasure coding policy XOR-2-1-1024k
2020-12-03 07:22:19,739 [IPC Server handler 4 on default port 46867] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=enableErasureCodingPolicy	src=XOR-2-1-1024k	dst=null	perm=null	proto=rpc
2020-12-03 07:22:19,740 [IPC Server handler 5 on default port 46867] INFO  namenode.ErasureCodingPolicyManager (ErasureCodingPolicyManager.java:enablePolicy(429)) - Enable the erasure coding policy RS-10-4-1024k
2020-12-03 07:22:19,741 [IPC Server handler 5 on default port 46867] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=enableErasureCodingPolicy	src=RS-10-4-1024k	dst=null	perm=null	proto=rpc
2020-12-03 07:22:19,753 [IPC Server handler 0 on default port 46867] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setErasureCodingPolicy	src=/	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:22:19,769 [IPC Server handler 7 on default port 46867] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/p1	dst=null	perm=root:supergroup:r--r--r--	proto=rpc
2020-12-03 07:22:19,777 [IPC Server handler 3 on default port 46867] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setOwner	src=/p1	dst=null	perm=user1:group1:r--r--r--	proto=rpc
2020-12-03 07:22:19,793 [IPC Server handler 1 on default port 46867] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=user1 (auth:SIMPLE)	ip=/127.0.0.1	cmd=setOwner	src=/p1	dst=null	perm=user1:group1:r--r--r--	proto=rpc
2020-12-03 07:22:19,803 [IPC Server handler 8 on default port 46867] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setTimes	src=/p1	dst=null	perm=user1:group1:r--r--r--	proto=rpc
2020-12-03 07:22:19,811 [IPC Server handler 9 on default port 46867] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/p1	dst=null	perm=null	proto=rpc
2020-12-03 07:22:19,815 [Listener at localhost/36315] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:22:19,815 [Listener at localhost/36315] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 8
2020-12-03 07:22:19,816 [Listener at localhost/36315] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:22:19,816 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@1b70203f] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:22:19,817 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-372699bb-d6ed-4718-be65-3b97a1865aff) exiting.
2020-12-03 07:22:19,817 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-bd138a52-784f-4b6f-b6ff-f75aed74d335) exiting.
2020-12-03 07:22:20,016 [Listener at localhost/36315] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@55a8dc49{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:22:20,026 [Listener at localhost/36315] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2a415aa9{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:20,027 [Listener at localhost/36315] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3c49fab6{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:20,027 [Listener at localhost/36315] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@62e8f862{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:20,030 [Listener at localhost/36315] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 36315
2020-12-03 07:22:20,059 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:20,059 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:20,071 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:20,082 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1381366540-172.17.0.6-1606980134186 (Datanode Uuid 0f8167d5-dd27-446a-9a96-6922e7c7a7a7) service to localhost/127.0.0.1:46867
2020-12-03 07:22:20,083 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1381366540-172.17.0.6-1606980134186 (Datanode Uuid 0f8167d5-dd27-446a-9a96-6922e7c7a7a7)
2020-12-03 07:22:20,083 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:20,084 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1381366540-172.17.0.6-1606980134186] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:20,084 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1381366540-172.17.0.6-1606980134186] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:20,090 [Listener at localhost/36315] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:22:20,091 [Listener at localhost/36315] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:22:20,092 [Listener at localhost/36315] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:22:20,092 [Listener at localhost/36315] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:22:20,114 [Listener at localhost/36315] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:22:20,115 [Listener at localhost/36315] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 7
2020-12-03 07:22:20,116 [Listener at localhost/36315] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:22:20,116 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@31198ceb] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:22:20,122 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-26fd1b49-3ac0-4652-9e2b-01266ac6cd25) exiting.
2020-12-03 07:22:20,122 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-d07d3af6-0c3e-4eda-bf94-13f5cbd7954e) exiting.
2020-12-03 07:22:20,160 [Listener at localhost/36315] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@273c947f{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:22:20,161 [Listener at localhost/36315] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@30457e14{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:20,161 [Listener at localhost/36315] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@d4ab71a{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:20,162 [Listener at localhost/36315] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1db0ec27{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:20,163 [Listener at localhost/36315] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 40756
2020-12-03 07:22:20,167 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:20,168 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:20,173 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:20,175 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1381366540-172.17.0.6-1606980134186 (Datanode Uuid 1642b796-0ef3-4f48-a49a-38b308222cba) service to localhost/127.0.0.1:46867
2020-12-03 07:22:20,175 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1381366540-172.17.0.6-1606980134186 (Datanode Uuid 1642b796-0ef3-4f48-a49a-38b308222cba)
2020-12-03 07:22:20,175 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:20,176 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1381366540-172.17.0.6-1606980134186] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:20,176 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1381366540-172.17.0.6-1606980134186] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:20,181 [Listener at localhost/36315] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:22:20,182 [Listener at localhost/36315] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:22:20,184 [Listener at localhost/36315] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:22:20,184 [Listener at localhost/36315] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:22:20,186 [Listener at localhost/36315] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:22:20,187 [Listener at localhost/36315] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 6
2020-12-03 07:22:20,187 [Listener at localhost/36315] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:22:20,187 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@5fd9b663] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:22:20,188 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-f69d61df-5ff2-4e47-9f2d-eb2ce927381c) exiting.
2020-12-03 07:22:20,188 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-b720b757-1081-4f84-a9d2-42cf7586af8d) exiting.
2020-12-03 07:22:20,250 [Listener at localhost/36315] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@17ae98d7{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:22:20,257 [Listener at localhost/36315] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@59221b97{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:20,258 [Listener at localhost/36315] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@54336c81{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:20,258 [Listener at localhost/36315] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6548bb7d{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:20,277 [Listener at localhost/36315] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 44256
2020-12-03 07:22:20,279 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:20,280 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:20,280 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:20,280 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1381366540-172.17.0.6-1606980134186 (Datanode Uuid 76e075f9-8394-4c92-8ea2-4b4d0cca38e9) service to localhost/127.0.0.1:46867
2020-12-03 07:22:20,280 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1381366540-172.17.0.6-1606980134186 (Datanode Uuid 76e075f9-8394-4c92-8ea2-4b4d0cca38e9)
2020-12-03 07:22:20,280 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:20,283 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1381366540-172.17.0.6-1606980134186] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:20,284 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1381366540-172.17.0.6-1606980134186] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:20,291 [Listener at localhost/36315] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:22:20,292 [Listener at localhost/36315] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:22:20,295 [Listener at localhost/36315] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:22:20,295 [Listener at localhost/36315] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:22:20,300 [Listener at localhost/36315] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:22:20,300 [Listener at localhost/36315] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 5
2020-12-03 07:22:20,300 [Listener at localhost/36315] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:22:20,300 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@78e16155] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:22:20,302 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-c16f6bf6-3694-486c-a5d2-60f3ca71a13e) exiting.
2020-12-03 07:22:20,302 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-b1868b9e-e800-4127-9f6e-905f0d6e29c2) exiting.
2020-12-03 07:22:20,331 [Listener at localhost/36315] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@61e3a1fd{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:22:20,332 [Listener at localhost/36315] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@51abf713{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:20,332 [Listener at localhost/36315] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6b739528{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:20,332 [Listener at localhost/36315] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@13c612bd{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:20,334 [Listener at localhost/36315] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 36001
2020-12-03 07:22:20,337 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:20,339 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:20,339 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:20,339 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1381366540-172.17.0.6-1606980134186 (Datanode Uuid 3cb97ca3-ca98-4950-b55b-e6e794bf8f21) service to localhost/127.0.0.1:46867
2020-12-03 07:22:20,340 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1381366540-172.17.0.6-1606980134186 (Datanode Uuid 3cb97ca3-ca98-4950-b55b-e6e794bf8f21)
2020-12-03 07:22:20,340 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:20,340 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1381366540-172.17.0.6-1606980134186] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:20,340 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1381366540-172.17.0.6-1606980134186] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:20,349 [Listener at localhost/36315] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:22:20,349 [Listener at localhost/36315] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:22:20,352 [Listener at localhost/36315] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:22:20,352 [Listener at localhost/36315] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:22:20,357 [Listener at localhost/36315] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:22:20,358 [Listener at localhost/36315] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 4
2020-12-03 07:22:20,358 [Listener at localhost/36315] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:22:20,358 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@4ced35ed] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:22:20,360 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-1da9a190-9e06-4f85-a403-b1c9f1a05a12) exiting.
2020-12-03 07:22:20,361 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-fd189235-0037-4626-b4b3-7bcf8d76254a) exiting.
2020-12-03 07:22:20,388 [Listener at localhost/36315] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@4acf72b6{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:22:20,391 [Listener at localhost/36315] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7561db12{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:20,391 [Listener at localhost/36315] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5cbf9e9f{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:20,392 [Listener at localhost/36315] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6b85300e{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:20,394 [Listener at localhost/36315] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 35404
2020-12-03 07:22:20,399 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:20,399 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:20,399 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:20,399 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1381366540-172.17.0.6-1606980134186 (Datanode Uuid afd1feac-1349-4680-b546-4b9da88c0fb3) service to localhost/127.0.0.1:46867
2020-12-03 07:22:20,400 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1381366540-172.17.0.6-1606980134186 (Datanode Uuid afd1feac-1349-4680-b546-4b9da88c0fb3)
2020-12-03 07:22:20,400 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:20,404 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1381366540-172.17.0.6-1606980134186] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:20,408 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1381366540-172.17.0.6-1606980134186] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:20,420 [Listener at localhost/36315] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:22:20,420 [Listener at localhost/36315] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:22:20,423 [Listener at localhost/36315] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:22:20,423 [Listener at localhost/36315] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:22:20,428 [Listener at localhost/36315] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:22:20,428 [Listener at localhost/36315] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 3
2020-12-03 07:22:20,428 [Listener at localhost/36315] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:22:20,429 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@5949eba8] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:22:20,434 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-44c575dd-518f-4d6a-9736-123dfb9ef4e0) exiting.
2020-12-03 07:22:20,435 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-a8ac44bd-2d90-4975-b170-7e0be4f54f1d) exiting.
2020-12-03 07:22:20,465 [Listener at localhost/36315] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@88d6f9b{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:22:20,466 [Listener at localhost/36315] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@47d93e0d{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:20,466 [Listener at localhost/36315] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5167268{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:20,470 [Listener at localhost/36315] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7728643a{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:20,494 [Listener at localhost/36315] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 46511
2020-12-03 07:22:20,506 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:20,506 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:20,506 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:20,507 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1381366540-172.17.0.6-1606980134186 (Datanode Uuid f52a640d-cec3-4842-be39-1e22246ccbb2) service to localhost/127.0.0.1:46867
2020-12-03 07:22:20,507 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1381366540-172.17.0.6-1606980134186 (Datanode Uuid f52a640d-cec3-4842-be39-1e22246ccbb2)
2020-12-03 07:22:20,507 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:20,507 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1381366540-172.17.0.6-1606980134186] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:20,507 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1381366540-172.17.0.6-1606980134186] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:20,525 [Listener at localhost/36315] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:22:20,525 [Listener at localhost/36315] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:22:20,528 [Listener at localhost/36315] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:22:20,529 [Listener at localhost/36315] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:22:20,534 [Listener at localhost/36315] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:22:20,534 [Listener at localhost/36315] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 2
2020-12-03 07:22:20,535 [Listener at localhost/36315] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:22:20,535 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@6cc0bcf6] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:22:20,538 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-aaa11e61-23fd-4415-8832-dea8228b06ec) exiting.
2020-12-03 07:22:20,538 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-a756ff9b-797d-4a9e-926c-68bbc728b725) exiting.
2020-12-03 07:22:20,563 [Listener at localhost/36315] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@4593ff34{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:22:20,564 [Listener at localhost/36315] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@37d3d232{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:20,564 [Listener at localhost/36315] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@66d23e4a{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:20,565 [Listener at localhost/36315] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@49a64d82{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:20,566 [Listener at localhost/36315] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 42532
2020-12-03 07:22:20,567 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:20,568 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:20,568 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:20,568 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1381366540-172.17.0.6-1606980134186 (Datanode Uuid 43e9848a-a092-46f2-8448-9b32427a54e4) service to localhost/127.0.0.1:46867
2020-12-03 07:22:20,568 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1381366540-172.17.0.6-1606980134186 (Datanode Uuid 43e9848a-a092-46f2-8448-9b32427a54e4)
2020-12-03 07:22:20,568 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:20,569 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1381366540-172.17.0.6-1606980134186] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:20,569 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1381366540-172.17.0.6-1606980134186] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:20,592 [Listener at localhost/36315] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:22:20,593 [Listener at localhost/36315] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:22:20,600 [Listener at localhost/36315] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:22:20,600 [Listener at localhost/36315] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:22:20,607 [Listener at localhost/36315] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:22:20,607 [Listener at localhost/36315] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 1
2020-12-03 07:22:20,608 [Listener at localhost/36315] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:22:20,608 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@4362d7df] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:22:20,611 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-dcf662f1-c431-4f1d-905d-f2c8a7c53691) exiting.
2020-12-03 07:22:20,611 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-a67153a8-dc0e-41b7-928e-2bec0596e04e) exiting.
2020-12-03 07:22:20,639 [Listener at localhost/36315] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@425357dd{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:22:20,640 [Listener at localhost/36315] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2102a4d5{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:20,640 [Listener at localhost/36315] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@63fd4873{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:20,640 [Listener at localhost/36315] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2ef8a8c3{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:20,642 [Listener at localhost/36315] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 35629
2020-12-03 07:22:20,649 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:20,652 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:20,658 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:20,658 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1381366540-172.17.0.6-1606980134186 (Datanode Uuid 0e8b5977-e06f-48fe-92af-e39b9c077e31) service to localhost/127.0.0.1:46867
2020-12-03 07:22:20,659 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1381366540-172.17.0.6-1606980134186 (Datanode Uuid 0e8b5977-e06f-48fe-92af-e39b9c077e31)
2020-12-03 07:22:20,659 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:20,659 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1381366540-172.17.0.6-1606980134186] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:20,659 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1381366540-172.17.0.6-1606980134186] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:20,678 [Listener at localhost/36315] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:22:20,678 [Listener at localhost/36315] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:22:20,682 [Listener at localhost/36315] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:22:20,682 [Listener at localhost/36315] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:22:20,690 [Listener at localhost/36315] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:22:20,691 [Listener at localhost/36315] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:22:20,691 [Listener at localhost/36315] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:22:20,691 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@21005f6c] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:22:20,696 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-5e5cd84f-8271-464a-85ba-e85d47b940d8) exiting.
2020-12-03 07:22:20,696 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-6ded7c5e-260d-452e-9a88-6cf4eca391f6) exiting.
2020-12-03 07:22:20,720 [Listener at localhost/36315] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@76c7beb3{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:22:20,721 [Listener at localhost/36315] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@64337702{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:20,721 [Listener at localhost/36315] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@475835b1{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:20,722 [Listener at localhost/36315] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@36b0fcd5{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:20,726 [Listener at localhost/36315] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 34703
2020-12-03 07:22:20,735 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:20,735 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:20,747 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:20,747 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1381366540-172.17.0.6-1606980134186 (Datanode Uuid 88d2a2c7-b145-4b11-a071-9cd675e25027) service to localhost/127.0.0.1:46867
2020-12-03 07:22:20,747 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1381366540-172.17.0.6-1606980134186 (Datanode Uuid 88d2a2c7-b145-4b11-a071-9cd675e25027)
2020-12-03 07:22:20,747 [BP-1381366540-172.17.0.6-1606980134186 heartbeating to localhost/127.0.0.1:46867] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1381366540-172.17.0.6-1606980134186
2020-12-03 07:22:20,748 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1381366540-172.17.0.6-1606980134186] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:20,748 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1381366540-172.17.0.6-1606980134186] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:20,795 [Listener at localhost/36315] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:22:20,795 [Listener at localhost/36315] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:22:20,800 [Listener at localhost/36315] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:22:20,800 [Listener at localhost/36315] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:22:20,808 [Listener at localhost/36315] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:22:20,808 [Listener at localhost/36315] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:22:20,809 [Listener at localhost/36315] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:22:20,809 [Thread[Thread-34,5,main]] ERROR delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(700)) - ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-12-03 07:22:20,810 [Listener at localhost/36315] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 1, 13
2020-12-03 07:22:20,810 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@2c3dec30] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:22:20,811 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@e260766] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:22:20,811 [Listener at localhost/36315] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 14 Total time for transactions(ms): 19 Number of transactions batched in Syncs: 0 Number of syncs: 15 SyncTimes(ms): 3 1 
2020-12-03 07:22:20,813 [Listener at localhost/36315] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000014
2020-12-03 07:22:20,814 [Listener at localhost/36315] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000014
2020-12-03 07:22:20,814 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:22:20,815 [reencryptionUpdaterThread #0] WARN  namenode.ReencryptionUpdater (ReencryptionUpdater.java:run(266)) - Re-encryption updater thread interrupted. Exiting.
2020-12-03 07:22:20,815 [CacheReplicationMonitor(1732399539)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:22:20,815 [reencryptionHandlerThread #0] INFO  namenode.ReencryptionHandler (ReencryptionHandler.java:run(335)) - Re-encrypt handler interrupted. Exiting
2020-12-03 07:22:20,973 [Listener at localhost/36315] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 46867
2020-12-03 07:22:20,986 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:20,986 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:21,007 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:22:21,009 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:22:21,066 [Listener at localhost/36315] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:22:21,067 [Listener at localhost/36315] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:22:21,068 [Listener at localhost/36315] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@4e31276e{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:22:21,070 [Listener at localhost/36315] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@387d8985{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:21,070 [Listener at localhost/36315] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1f760b47{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:21,071 [Listener at localhost/36315] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@776a6d9b{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:21,075 [Listener at localhost/36315] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-12-03 07:22:21,101 [Listener at localhost/36315] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-12-03 07:22:21,102 [Listener at localhost/36315] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
msx-rc 0
