1: length=-1, (b, c, d) = (0, 0, -1)
2: length=0, (b, c, d) = (0, 0, 0)
3: length=1, (b, c, d) = (0, 0, 1)
4: length=65535, (b, c, d) = (0, 1, -1)
5: length=65536, (b, c, d) = (0, 1, 0)
6: length=65537, (b, c, d) = (0, 1, 1)
7: length=131071, (b, c, d) = (0, 2, -1)
8: length=131072, (b, c, d) = (0, 2, 0)
9: length=131073, (b, c, d) = (0, 2, 1)
10: length=196607, (b, c, d) = (0, 3, -1)
11: length=196608, (b, c, d) = (0, 3, 0)
12: length=196609, (b, c, d) = (0, 3, 1)
13: length=262143, (b, c, d) = (0, 4, -1)
14: length=262144, (b, c, d) = (0, 4, 0)
15: length=262145, (b, c, d) = (0, 4, 1)
16: length=327679, (b, c, d) = (0, 5, -1)
17: length=327680, (b, c, d) = (0, 5, 0)
18: length=327681, (b, c, d) = (0, 5, 1)
19: length=393215, (b, c, d) = (0, 6, -1)
20: length=393216, (b, c, d) = (0, 6, 0)
21: length=393217, (b, c, d) = (0, 6, 1)
22: length=458751, (b, c, d) = (0, 7, -1)
23: length=458752, (b, c, d) = (0, 7, 0)
24: length=458753, (b, c, d) = (0, 7, 1)
25: length=524287, (b, c, d) = (0, 8, -1)
26: length=524288, (b, c, d) = (0, 8, 0)
27: length=524289, (b, c, d) = (0, 8, 1)
28: length=589823, (b, c, d) = (0, 9, -1)
29: length=589824, (b, c, d) = (0, 9, 0)
30: length=589825, (b, c, d) = (0, 9, 1)
31: length=655359, (b, c, d) = (0, 10, -1)
32: length=655360, (b, c, d) = (0, 10, 0)
33: length=655361, (b, c, d) = (0, 10, 1)
34: length=720895, (b, c, d) = (0, 11, -1)
35: length=720896, (b, c, d) = (0, 11, 0)
36: length=720897, (b, c, d) = (0, 11, 1)
37: length=786431, (b, c, d) = (0, 12, -1)
38: length=786432, (b, c, d) = (0, 12, 0)
39: length=786433, (b, c, d) = (0, 12, 1)
40: length=851967, (b, c, d) = (0, 13, -1)
41: length=851968, (b, c, d) = (0, 13, 0)
42: length=851969, (b, c, d) = (0, 13, 1)
43: length=917503, (b, c, d) = (0, 14, -1)
44: length=917504, (b, c, d) = (0, 14, 0)
45: length=917505, (b, c, d) = (0, 14, 1)
46: length=983039, (b, c, d) = (0, 15, -1)
47: length=983040, (b, c, d) = (0, 15, 0)
48: length=983041, (b, c, d) = (0, 15, 1)
49: length=1048575, (b, c, d) = (0, 16, -1)
50: length=1048576, (b, c, d) = (0, 16, 0)
51: length=1048577, (b, c, d) = (0, 16, 1)
52: length=1114111, (b, c, d) = (0, 17, -1)
53: length=1114112, (b, c, d) = (0, 17, 0)
54: length=1114113, (b, c, d) = (0, 17, 1)
55: length=1179647, (b, c, d) = (0, 18, -1)
56: length=1179648, (b, c, d) = (0, 18, 0)
57: length=1179649, (b, c, d) = (0, 18, 1)
58: length=1245183, (b, c, d) = (0, 19, -1)
59: length=1245184, (b, c, d) = (0, 19, 0)
60: length=1245185, (b, c, d) = (0, 19, 1)
61: length=1310719, (b, c, d) = (0, 20, -1)
62: length=1310720, (b, c, d) = (0, 20, 0)
63: length=1310721, (b, c, d) = (0, 20, 1)
64: length=1376255, (b, c, d) = (0, 21, -1)
65: length=1376256, (b, c, d) = (0, 21, 0)
66: length=1376257, (b, c, d) = (0, 21, 1)
67: length=1441791, (b, c, d) = (0, 22, -1)
68: length=1441792, (b, c, d) = (0, 22, 0)
69: length=1441793, (b, c, d) = (0, 22, 1)
70: length=1507327, (b, c, d) = (0, 23, -1)
71: length=1507328, (b, c, d) = (0, 23, 0)
72: length=1507329, (b, c, d) = (0, 23, 1)
73: length=1572863, (b, c, d) = (1, 0, -1)
74: length=1572864, (b, c, d) = (1, 0, 0)
75: length=1572865, (b, c, d) = (1, 0, 1)
76: length=1638399, (b, c, d) = (1, 1, -1)
77: length=1638400, (b, c, d) = (1, 1, 0)
78: length=1638401, (b, c, d) = (1, 1, 1)
79: length=1703935, (b, c, d) = (1, 2, -1)
80: length=1703936, (b, c, d) = (1, 2, 0)
81: length=1703937, (b, c, d) = (1, 2, 1)
82: length=1769471, (b, c, d) = (1, 3, -1)
83: length=1769472, (b, c, d) = (1, 3, 0)
84: length=1769473, (b, c, d) = (1, 3, 1)
85: length=1835007, (b, c, d) = (1, 4, -1)
86: length=1835008, (b, c, d) = (1, 4, 0)
87: length=1835009, (b, c, d) = (1, 4, 1)
88: length=1900543, (b, c, d) = (1, 5, -1)
89: length=1900544, (b, c, d) = (1, 5, 0)
90: length=1900545, (b, c, d) = (1, 5, 1)
91: length=1966079, (b, c, d) = (1, 6, -1)
92: length=1966080, (b, c, d) = (1, 6, 0)
93: length=1966081, (b, c, d) = (1, 6, 1)
94: length=2031615, (b, c, d) = (1, 7, -1)
95: length=2031616, (b, c, d) = (1, 7, 0)
96: length=2031617, (b, c, d) = (1, 7, 1)
97: length=2097151, (b, c, d) = (1, 8, -1)
98: length=2097152, (b, c, d) = (1, 8, 0)
99: length=2097153, (b, c, d) = (1, 8, 1)
100: length=2162687, (b, c, d) = (1, 9, -1)
101: length=2162688, (b, c, d) = (1, 9, 0)
102: length=2162689, (b, c, d) = (1, 9, 1)
103: length=2228223, (b, c, d) = (1, 10, -1)
104: length=2228224, (b, c, d) = (1, 10, 0)
105: length=2228225, (b, c, d) = (1, 10, 1)
106: length=2293759, (b, c, d) = (1, 11, -1)
107: length=2293760, (b, c, d) = (1, 11, 0)
108: length=2293761, (b, c, d) = (1, 11, 1)
109: length=2359295, (b, c, d) = (1, 12, -1)
110: length=2359296, (b, c, d) = (1, 12, 0)
111: length=2359297, (b, c, d) = (1, 12, 1)
112: length=2424831, (b, c, d) = (1, 13, -1)
113: length=2424832, (b, c, d) = (1, 13, 0)
114: length=2424833, (b, c, d) = (1, 13, 1)
115: length=2490367, (b, c, d) = (1, 14, -1)
116: length=2490368, (b, c, d) = (1, 14, 0)
117: length=2490369, (b, c, d) = (1, 14, 1)
118: length=2555903, (b, c, d) = (1, 15, -1)
119: length=2555904, (b, c, d) = (1, 15, 0)
120: length=2555905, (b, c, d) = (1, 15, 1)
121: length=2621439, (b, c, d) = (1, 16, -1)
122: length=2621440, (b, c, d) = (1, 16, 0)
123: length=2621441, (b, c, d) = (1, 16, 1)
124: length=2686975, (b, c, d) = (1, 17, -1)
125: length=2686976, (b, c, d) = (1, 17, 0)
126: length=2686977, (b, c, d) = (1, 17, 1)
127: length=2752511, (b, c, d) = (1, 18, -1)
128: length=2752512, (b, c, d) = (1, 18, 0)
129: length=2752513, (b, c, d) = (1, 18, 1)
130: length=2818047, (b, c, d) = (1, 19, -1)
131: length=2818048, (b, c, d) = (1, 19, 0)
132: length=2818049, (b, c, d) = (1, 19, 1)
133: length=2883583, (b, c, d) = (1, 20, -1)
134: length=2883584, (b, c, d) = (1, 20, 0)
135: length=2883585, (b, c, d) = (1, 20, 1)
136: length=2949119, (b, c, d) = (1, 21, -1)
137: length=2949120, (b, c, d) = (1, 21, 0)
138: length=2949121, (b, c, d) = (1, 21, 1)
139: length=3014655, (b, c, d) = (1, 22, -1)
140: length=3014656, (b, c, d) = (1, 22, 0)
141: length=3014657, (b, c, d) = (1, 22, 1)
142: length=3080191, (b, c, d) = (1, 23, -1)
143: length=3080192, (b, c, d) = (1, 23, 0)
144: length=3080193, (b, c, d) = (1, 23, 1)
145: length=3145727, (b, c, d) = (2, 0, -1)
146: length=3145728, (b, c, d) = (2, 0, 0)
147: length=3145729, (b, c, d) = (2, 0, 1)
148: length=3211263, (b, c, d) = (2, 1, -1)
149: length=3211264, (b, c, d) = (2, 1, 0)
150: length=3211265, (b, c, d) = (2, 1, 1)
151: length=3276799, (b, c, d) = (2, 2, -1)
152: length=3276800, (b, c, d) = (2, 2, 0)
153: length=3276801, (b, c, d) = (2, 2, 1)
154: length=3342335, (b, c, d) = (2, 3, -1)
155: length=3342336, (b, c, d) = (2, 3, 0)
156: length=3342337, (b, c, d) = (2, 3, 1)
157: length=3407871, (b, c, d) = (2, 4, -1)
158: length=3407872, (b, c, d) = (2, 4, 0)
159: length=3407873, (b, c, d) = (2, 4, 1)
160: length=3473407, (b, c, d) = (2, 5, -1)
161: length=3473408, (b, c, d) = (2, 5, 0)
162: length=3473409, (b, c, d) = (2, 5, 1)
163: length=3538943, (b, c, d) = (2, 6, -1)
164: length=3538944, (b, c, d) = (2, 6, 0)
165: length=3538945, (b, c, d) = (2, 6, 1)
166: length=3604479, (b, c, d) = (2, 7, -1)
167: length=3604480, (b, c, d) = (2, 7, 0)
168: length=3604481, (b, c, d) = (2, 7, 1)
169: length=3670015, (b, c, d) = (2, 8, -1)
170: length=3670016, (b, c, d) = (2, 8, 0)
171: length=3670017, (b, c, d) = (2, 8, 1)
172: length=3735551, (b, c, d) = (2, 9, -1)
173: length=3735552, (b, c, d) = (2, 9, 0)
174: length=3735553, (b, c, d) = (2, 9, 1)
175: length=3801087, (b, c, d) = (2, 10, -1)
176: length=3801088, (b, c, d) = (2, 10, 0)
177: length=3801089, (b, c, d) = (2, 10, 1)
178: length=3866623, (b, c, d) = (2, 11, -1)
179: length=3866624, (b, c, d) = (2, 11, 0)
180: length=3866625, (b, c, d) = (2, 11, 1)
181: length=3932159, (b, c, d) = (2, 12, -1)
182: length=3932160, (b, c, d) = (2, 12, 0)
183: length=3932161, (b, c, d) = (2, 12, 1)
184: length=3997695, (b, c, d) = (2, 13, -1)
185: length=3997696, (b, c, d) = (2, 13, 0)
186: length=3997697, (b, c, d) = (2, 13, 1)
187: length=4063231, (b, c, d) = (2, 14, -1)
188: length=4063232, (b, c, d) = (2, 14, 0)
189: length=4063233, (b, c, d) = (2, 14, 1)
190: length=4128767, (b, c, d) = (2, 15, -1)
191: length=4128768, (b, c, d) = (2, 15, 0)
192: length=4128769, (b, c, d) = (2, 15, 1)
193: length=4194303, (b, c, d) = (2, 16, -1)
194: length=4194304, (b, c, d) = (2, 16, 0)
195: length=4194305, (b, c, d) = (2, 16, 1)
196: length=4259839, (b, c, d) = (2, 17, -1)
197: length=4259840, (b, c, d) = (2, 17, 0)
198: length=4259841, (b, c, d) = (2, 17, 1)
199: length=4325375, (b, c, d) = (2, 18, -1)
200: length=4325376, (b, c, d) = (2, 18, 0)
201: length=4325377, (b, c, d) = (2, 18, 1)
202: length=4390911, (b, c, d) = (2, 19, -1)
203: length=4390912, (b, c, d) = (2, 19, 0)
204: length=4390913, (b, c, d) = (2, 19, 1)
205: length=4456447, (b, c, d) = (2, 20, -1)
206: length=4456448, (b, c, d) = (2, 20, 0)
207: length=4456449, (b, c, d) = (2, 20, 1)
208: length=4521983, (b, c, d) = (2, 21, -1)
209: length=4521984, (b, c, d) = (2, 21, 0)
210: length=4521985, (b, c, d) = (2, 21, 1)
211: length=4587519, (b, c, d) = (2, 22, -1)
212: length=4587520, (b, c, d) = (2, 22, 0)
213: length=4587521, (b, c, d) = (2, 22, 1)
214: length=4653055, (b, c, d) = (2, 23, -1)
215: length=4653056, (b, c, d) = (2, 23, 0)
216: length=4653057, (b, c, d) = (2, 23, 1)
2020-12-03 07:24:22,698 [main] INFO  hdfs.TestDFSStripedOutputStreamWithFailure (TestDFSStripedOutputStreamWithFailure.java:testCloseWithExceptionsInStreamer(257)) - runTestWithMultipleFailure2: length==655360, killPos=[218453, 436906], dnIndex=[4, 5]
NUM_DATA_BLOCKS  = 6
NUM_PARITY_BLOCKS= 3
CELL_SIZE        = 65536 (=64 KB)
BLOCK_SIZE       = 262144 (=256 KB)
BLOCK_GROUP_SIZE = 1572864 (=1.50 MB)
2020-12-03 07:24:22,776 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=9
Formatting using clusterid: testClusterID
2020-12-03 07:24:23,562 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:24:23,577 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:24:23,578 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:24:23,579 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:24:23,586 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:24:23,587 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:24:23,587 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:24:23,588 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:24:23,639 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:23,644 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2020-12-03 07:24:23,645 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:24:23,645 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=20, effected=1000
2020-12-03 07:24:23,645 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:24:23,645 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:24:23,653 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:24:23,654 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:24:23
2020-12-03 07:24:23,656 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:24:23,656 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:23,657 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-12-03 07:24:23,657 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:24:23,673 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:24:23,674 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:24:23,678 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:24:23,678 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:24:23,681 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:24:23,686 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:24:23,686 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:24:23,687 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:24:23,687 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:24:23,688 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:24:23,688 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:24:23,688 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:24:23,688 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 0
2020-12-03 07:24:23,689 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:24:23,689 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:24:23,689 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:24:23,726 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GLOBAL serial map: bits=29 maxEntries=536870911
2020-12-03 07:24:23,727 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - USER serial map: bits=24 maxEntries=16777215
2020-12-03 07:24:23,727 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GROUP serial map: bits=24 maxEntries=16777215
2020-12-03 07:24:23,727 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - XATTR serial map: bits=24 maxEntries=16777215
2020-12-03 07:24:23,742 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:24:23,743 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:23,743 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-12-03 07:24:23,743 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:24:23,750 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:24:23,750 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:24:23,750 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:24:23,751 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:24:23,756 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:24:23,761 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:24:23,765 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:24:23,766 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:23,766 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-12-03 07:24:23,766 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:24:23,775 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:24:23,775 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:24:23,776 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:24:23,780 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:24:23,780 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:24:23,783 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:24:23,783 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:23,783 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-12-03 07:24:23,784 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:24:23,816 [main] INFO  namenode.FSImage (FSImage.java:format(185)) - Allocated new BlockPoolId: BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:23,955 [main] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-12-03 07:24:24,015 [main] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-12-03 07:24:24,075 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:24:24,075 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:24:24,235 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:24:24,235 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:24:24,327 [main] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-12-03 07:24:24,332 [main] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:24:24,693 [main] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:24:24,792 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:24:24,793 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:24:24,841 [main] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-12-03 07:24:24,901 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3cebbb30] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:24,920 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:24:24,927 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:24,956 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @3351ms
2020-12-03 07:24:25,125 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:25,128 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:24:25,129 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:25,140 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:25,142 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:24:25,142 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:25,143 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:25,171 [main] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:24:25,172 [main] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:24:25,266 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 40649
2020-12-03 07:24:25,268 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:25,389 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@508dec2b{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:25,390 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@37313c65{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:25,449 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@266374ef{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:24:25,459 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1f81aa00{HTTP/1.1,[http/1.1]}{localhost:40649}
2020-12-03 07:24:25,459 [main] INFO  server.Server (Server.java:doStart(419)) - Started @3855ms
2020-12-03 07:24:25,470 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:24:25,470 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:24:25,470 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:24:25,471 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:24:25,471 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:24:25,471 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:24:25,471 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:24:25,472 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:24:25,472 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:25,473 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:24:25,473 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=20, effected=1000
2020-12-03 07:24:25,473 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:24:25,473 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:24:25,474 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:24:25,474 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:24:25
2020-12-03 07:24:25,475 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:24:25,475 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:25,475 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:24:25,475 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:24:25,480 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:24:25,480 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:24:25,480 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:24:25,481 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:24:25,481 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:24:25,481 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:24:25,482 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:24:25,482 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:24:25,482 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:24:25,482 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:24:25,482 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:24:25,483 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:24:25,483 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 0
2020-12-03 07:24:25,483 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:24:25,484 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:24:25,484 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:24:25,484 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:24:25,485 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:25,485 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:24:25,485 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:24:25,488 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:24:25,488 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:24:25,488 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:24:25,488 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:24:25,488 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:24:25,489 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:24:25,489 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:24:25,489 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:25,489 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:24:25,490 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:24:25,491 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:24:25,491 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:24:25,491 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:24:25,491 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:24:25,491 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:24:25,492 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:24:25,492 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:25,492 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:24:25,492 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:24:25,544 [main] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 11600@0b2162a51c02
2020-12-03 07:24:25,627 [main] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 11600@0b2162a51c02
2020-12-03 07:24:25,631 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-12-03 07:24:25,631 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-12-03 07:24:25,631 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:24:25,632 [main] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:24:25,660 [main] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:24:25,667 [main] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:24:25,667 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-12-03 07:24:25,671 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:24:25,672 [main] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 1
2020-12-03 07:24:25,833 [main] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:24:25,834 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 339 msecs
2020-12-03 07:24:26,026 [main] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:24:26,067 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:26,091 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:26,402 [Listener at localhost/37942] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:37942 to access this namenode/service.
2020-12-03 07:24:26,406 [Listener at localhost/37942] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:24:26,422 [Listener at localhost/37942] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:24:26,434 [Listener at localhost/37942] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:24:26,434 [Listener at localhost/37942] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:24:26,435 [Listener at localhost/37942] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:24:26,435 [Listener at localhost/37942] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:24:26,455 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 0
2020-12-03 07:24:26,455 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:24:26,456 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:24:26,456 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:24:26,456 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:24:26,456 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 22 msec
2020-12-03 07:24:26,488 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:26,488 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:26,493 [Listener at localhost/37942] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:37942
2020-12-03 07:24:26,496 [Listener at localhost/37942] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:24:26,497 [Listener at localhost/37942] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:24:26,562 [Listener at localhost/37942] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 65 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:24:26,567 [CacheReplicationMonitor(1424378291)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:24:26,575 [Listener at localhost/37942] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:24:26,640 [Listener at localhost/37942] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:24:26,656 [Listener at localhost/37942] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:24:26,679 [Listener at localhost/37942] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:24:26,684 [Listener at localhost/37942] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:26,687 [Listener at localhost/37942] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:24:26,691 [Listener at localhost/37942] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:24:26,692 [Listener at localhost/37942] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:26,692 [Listener at localhost/37942] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:24:26,693 [Listener at localhost/37942] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:24:26,697 [Listener at localhost/37942] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:24:26,704 [Listener at localhost/37942] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:41639
2020-12-03 07:24:26,706 [Listener at localhost/37942] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:24:26,706 [Listener at localhost/37942] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:24:26,724 [Listener at localhost/37942] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:26,726 [Listener at localhost/37942] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:26,727 [Listener at localhost/37942] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:24:26,727 [Listener at localhost/37942] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:26,730 [Listener at localhost/37942] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:26,731 [Listener at localhost/37942] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:24:26,731 [Listener at localhost/37942] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:26,731 [Listener at localhost/37942] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:26,735 [Listener at localhost/37942] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 36298
2020-12-03 07:24:26,735 [Listener at localhost/37942] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:26,736 [Listener at localhost/37942] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@61526469{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:26,737 [Listener at localhost/37942] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@76ba13c{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:26,744 [Listener at localhost/37942] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@235f4c10{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:24:26,745 [Listener at localhost/37942] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@743cb8e0{HTTP/1.1,[http/1.1]}{localhost:36298}
2020-12-03 07:24:26,745 [Listener at localhost/37942] INFO  server.Server (Server.java:doStart(419)) - Started @5141ms
2020-12-03 07:24:27,408 [Listener at localhost/37942] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:41408
2020-12-03 07:24:27,409 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@76318a7d] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:27,410 [Listener at localhost/37942] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:24:27,410 [Listener at localhost/37942] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:24:27,425 [Listener at localhost/37942] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:27,426 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:27,434 [Listener at localhost/40858] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:40858
2020-12-03 07:24:27,451 [Listener at localhost/40858] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:24:27,453 [Listener at localhost/40858] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:24:27,467 [Thread-59] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37942 starting to offer service
2020-12-03 07:24:27,473 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:27,473 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:27,478 [Listener at localhost/40858] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:24:27,481 [Listener at localhost/40858] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:24:27,482 [Listener at localhost/40858] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:24:27,484 [Listener at localhost/40858] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:24:27,485 [Listener at localhost/40858] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:27,485 [Listener at localhost/40858] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:24:27,486 [Listener at localhost/40858] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:24:27,486 [Listener at localhost/40858] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:27,486 [Listener at localhost/40858] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:24:27,486 [Listener at localhost/40858] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:24:27,486 [Listener at localhost/40858] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:24:27,487 [Listener at localhost/40858] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:46808
2020-12-03 07:24:27,487 [Listener at localhost/40858] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:24:27,488 [Listener at localhost/40858] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:24:27,489 [Listener at localhost/40858] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:27,491 [Listener at localhost/40858] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:27,491 [Listener at localhost/40858] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:24:27,491 [Listener at localhost/40858] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:27,499 [Listener at localhost/40858] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:27,501 [Listener at localhost/40858] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:24:27,501 [Listener at localhost/40858] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:27,501 [Listener at localhost/40858] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:27,502 [Listener at localhost/40858] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 46377
2020-12-03 07:24:27,503 [Listener at localhost/40858] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:27,509 [Listener at localhost/40858] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@29ad44e3{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:27,510 [Listener at localhost/40858] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5af9926a{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:27,521 [Listener at localhost/40858] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@73393584{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:24:27,522 [Listener at localhost/40858] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@31500940{HTTP/1.1,[http/1.1]}{localhost:46377}
2020-12-03 07:24:27,522 [Listener at localhost/40858] INFO  server.Server (Server.java:doStart(419)) - Started @5918ms
2020-12-03 07:24:27,620 [Listener at localhost/40858] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:36623
2020-12-03 07:24:27,621 [Listener at localhost/40858] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:24:27,621 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@48e64352] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:27,621 [Listener at localhost/40858] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:24:27,622 [Listener at localhost/40858] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:27,623 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:27,629 [Listener at localhost/40304] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:40304
2020-12-03 07:24:27,637 [Listener at localhost/40304] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:24:27,638 [Listener at localhost/40304] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:24:27,638 [Thread-83] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37942 starting to offer service
2020-12-03 07:24:27,640 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:27,641 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:27,645 [Listener at localhost/40304] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:24:27,647 [Listener at localhost/40304] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:24:27,648 [Listener at localhost/40304] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:24:27,651 [Listener at localhost/40304] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:24:27,651 [Listener at localhost/40304] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:27,652 [Listener at localhost/40304] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:24:27,652 [Listener at localhost/40304] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:24:27,653 [Listener at localhost/40304] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:27,653 [Listener at localhost/40304] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:24:27,653 [Listener at localhost/40304] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:24:27,654 [Listener at localhost/40304] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:24:27,655 [Listener at localhost/40304] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:46036
2020-12-03 07:24:27,655 [Listener at localhost/40304] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:24:27,655 [Listener at localhost/40304] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:24:27,657 [Listener at localhost/40304] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:27,659 [Listener at localhost/40304] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:27,660 [Listener at localhost/40304] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:24:27,660 [Listener at localhost/40304] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:27,663 [Listener at localhost/40304] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:27,665 [Listener at localhost/40304] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:24:27,665 [Listener at localhost/40304] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:27,665 [Listener at localhost/40304] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:27,667 [Listener at localhost/40304] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 43401
2020-12-03 07:24:27,667 [Listener at localhost/40304] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:27,669 [Listener at localhost/40304] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2102a4d5{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:27,669 [Listener at localhost/40304] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3d4d3fe7{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:27,679 [Listener at localhost/40304] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@2a551a63{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:24:27,680 [Listener at localhost/40304] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1a6f5124{HTTP/1.1,[http/1.1]}{localhost:43401}
2020-12-03 07:24:27,680 [Listener at localhost/40304] INFO  server.Server (Server.java:doStart(419)) - Started @6076ms
2020-12-03 07:24:27,704 [Listener at localhost/40304] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:36214
2020-12-03 07:24:27,705 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@ec2bf82] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:27,705 [Listener at localhost/40304] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:24:27,706 [Listener at localhost/40304] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:24:27,706 [Listener at localhost/40304] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:27,707 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:27,713 [Listener at localhost/36510] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:36510
2020-12-03 07:24:27,720 [Listener at localhost/36510] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:24:27,720 [Listener at localhost/36510] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:24:27,721 [Thread-106] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37942 starting to offer service
2020-12-03 07:24:27,723 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:27,724 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:27,730 [Listener at localhost/36510] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 3 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:24:27,731 [Listener at localhost/36510] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:24:27,732 [Listener at localhost/36510] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:24:27,733 [Listener at localhost/36510] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:24:27,736 [Listener at localhost/36510] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:27,736 [Listener at localhost/36510] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:24:27,737 [Listener at localhost/36510] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:24:27,737 [Listener at localhost/36510] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:27,737 [Listener at localhost/36510] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:24:27,737 [Listener at localhost/36510] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:24:27,738 [Listener at localhost/36510] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:24:27,739 [Listener at localhost/36510] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:35139
2020-12-03 07:24:27,739 [Listener at localhost/36510] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:24:27,740 [Listener at localhost/36510] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:24:27,742 [Listener at localhost/36510] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:27,744 [Listener at localhost/36510] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:27,745 [Listener at localhost/36510] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:24:27,745 [Listener at localhost/36510] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:27,748 [Listener at localhost/36510] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:27,749 [Listener at localhost/36510] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:24:27,749 [Listener at localhost/36510] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:27,749 [Listener at localhost/36510] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:27,750 [Listener at localhost/36510] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 40344
2020-12-03 07:24:27,751 [Listener at localhost/36510] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:27,753 [Listener at localhost/36510] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4593ff34{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:27,754 [Listener at localhost/36510] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@30c0ccff{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:27,761 [Listener at localhost/36510] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@2024293c{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:24:27,763 [Listener at localhost/36510] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7048f722{HTTP/1.1,[http/1.1]}{localhost:40344}
2020-12-03 07:24:27,763 [Listener at localhost/36510] INFO  server.Server (Server.java:doStart(419)) - Started @6159ms
2020-12-03 07:24:27,826 [Listener at localhost/36510] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:40382
2020-12-03 07:24:27,827 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@58a55449] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:27,827 [Listener at localhost/36510] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:24:27,827 [Listener at localhost/36510] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:24:27,828 [Listener at localhost/36510] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:27,830 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:27,839 [Listener at localhost/38013] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:38013
2020-12-03 07:24:27,844 [Listener at localhost/38013] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:24:27,844 [Listener at localhost/38013] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:24:27,846 [Thread-128] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37942 starting to offer service
2020-12-03 07:24:27,849 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:27,850 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:27,854 [Listener at localhost/38013] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 4 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:24:27,856 [Listener at localhost/38013] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:24:27,858 [Listener at localhost/38013] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:24:27,861 [Listener at localhost/38013] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:24:27,862 [Listener at localhost/38013] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:27,862 [Listener at localhost/38013] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:24:27,863 [Listener at localhost/38013] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:24:27,863 [Listener at localhost/38013] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:27,864 [Listener at localhost/38013] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:24:27,864 [Listener at localhost/38013] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:24:27,864 [Listener at localhost/38013] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:24:27,866 [Listener at localhost/38013] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:45408
2020-12-03 07:24:27,866 [Listener at localhost/38013] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:24:27,866 [Listener at localhost/38013] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:24:27,868 [Listener at localhost/38013] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:27,872 [Listener at localhost/38013] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:27,874 [Listener at localhost/38013] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:24:27,874 [Listener at localhost/38013] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:27,877 [Listener at localhost/38013] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:27,878 [Listener at localhost/38013] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:24:27,878 [Listener at localhost/38013] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:27,878 [Listener at localhost/38013] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:27,879 [Listener at localhost/38013] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 35731
2020-12-03 07:24:27,880 [Listener at localhost/38013] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:27,883 [Listener at localhost/38013] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1bc53649{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:27,884 [Listener at localhost/38013] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@47d93e0d{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:27,893 [Listener at localhost/38013] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@610db97e{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:24:27,895 [Listener at localhost/38013] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6f0628de{HTTP/1.1,[http/1.1]}{localhost:35731}
2020-12-03 07:24:27,896 [Listener at localhost/38013] INFO  server.Server (Server.java:doStart(419)) - Started @6292ms
2020-12-03 07:24:27,910 [Thread-106] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37942
2020-12-03 07:24:27,910 [Thread-83] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37942
2020-12-03 07:24:27,910 [Thread-128] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37942
2020-12-03 07:24:27,910 [Thread-59] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37942
2020-12-03 07:24:27,914 [Thread-128] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:24:27,914 [Thread-106] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:24:27,914 [Thread-83] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:24:27,914 [Thread-59] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:24:27,921 [Listener at localhost/38013] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:46309
2020-12-03 07:24:27,921 [Listener at localhost/38013] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:24:27,921 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1e392345] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:27,921 [Listener at localhost/38013] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:24:27,922 [Listener at localhost/38013] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:27,923 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:27,927 [Listener at localhost/38179] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:38179
2020-12-03 07:24:27,931 [Listener at localhost/38179] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:24:27,931 [Listener at localhost/38179] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:24:27,932 [Thread-150] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37942 starting to offer service
2020-12-03 07:24:27,933 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:27,934 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:27,937 [Thread-150] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37942
2020-12-03 07:24:27,938 [Thread-150] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:24:27,938 [Listener at localhost/38179] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 5 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:24:27,939 [Listener at localhost/38179] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:24:27,940 [Listener at localhost/38179] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:24:27,941 [Listener at localhost/38179] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:24:27,942 [Listener at localhost/38179] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:27,942 [Listener at localhost/38179] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:24:27,942 [Listener at localhost/38179] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:24:27,943 [Listener at localhost/38179] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:27,943 [Listener at localhost/38179] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:24:27,943 [Listener at localhost/38179] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:24:27,943 [Listener at localhost/38179] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:24:27,944 [Listener at localhost/38179] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:34859
2020-12-03 07:24:27,945 [Listener at localhost/38179] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:24:27,945 [Listener at localhost/38179] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:24:27,946 [Listener at localhost/38179] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:27,948 [Listener at localhost/38179] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:27,948 [Listener at localhost/38179] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:24:27,949 [Listener at localhost/38179] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:27,951 [Listener at localhost/38179] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:27,951 [Listener at localhost/38179] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:24:27,951 [Listener at localhost/38179] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:27,952 [Listener at localhost/38179] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:27,952 [Listener at localhost/38179] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 36646
2020-12-03 07:24:27,953 [Listener at localhost/38179] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:27,954 [Listener at localhost/38179] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@a23a01d{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:27,955 [Listener at localhost/38179] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7561db12{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:27,961 [Listener at localhost/38179] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3e792ce3{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:24:27,963 [Listener at localhost/38179] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@53bc1328{HTTP/1.1,[http/1.1]}{localhost:36646}
2020-12-03 07:24:27,963 [Listener at localhost/38179] INFO  server.Server (Server.java:doStart(419)) - Started @6359ms
2020-12-03 07:24:27,980 [Listener at localhost/38179] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:44221
2020-12-03 07:24:27,981 [Listener at localhost/38179] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:24:27,981 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3c1e3314] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:27,981 [Listener at localhost/38179] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:24:27,982 [Listener at localhost/38179] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:27,982 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:27,986 [Listener at localhost/44273] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:44273
2020-12-03 07:24:27,989 [Listener at localhost/44273] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:24:27,990 [Listener at localhost/44273] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:24:27,991 [Thread-172] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37942 starting to offer service
2020-12-03 07:24:27,992 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:27,992 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:27,995 [Thread-172] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37942
2020-12-03 07:24:27,995 [Listener at localhost/44273] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 6 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:24:27,996 [Thread-172] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:24:27,997 [Listener at localhost/44273] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:24:27,997 [Listener at localhost/44273] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:24:27,998 [Listener at localhost/44273] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:24:27,999 [Listener at localhost/44273] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:27,999 [Listener at localhost/44273] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:24:28,000 [Listener at localhost/44273] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:24:28,000 [Listener at localhost/44273] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:28,000 [Listener at localhost/44273] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:24:28,000 [Listener at localhost/44273] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:24:28,001 [Listener at localhost/44273] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:24:28,001 [Listener at localhost/44273] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:43939
2020-12-03 07:24:28,001 [Listener at localhost/44273] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:24:28,002 [Listener at localhost/44273] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:24:28,003 [Listener at localhost/44273] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:28,004 [Listener at localhost/44273] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:28,005 [Listener at localhost/44273] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:24:28,005 [Listener at localhost/44273] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:28,007 [Listener at localhost/44273] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:28,007 [Listener at localhost/44273] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:24:28,007 [Listener at localhost/44273] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:28,008 [Listener at localhost/44273] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:28,008 [Listener at localhost/44273] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 42171
2020-12-03 07:24:28,008 [Listener at localhost/44273] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:28,010 [Listener at localhost/44273] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@271f18d3{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:28,011 [Listener at localhost/44273] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@61e3a1fd{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:28,017 [Listener at localhost/44273] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@74a9c4b0{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:24:28,018 [Listener at localhost/44273] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@85ec632{HTTP/1.1,[http/1.1]}{localhost:42171}
2020-12-03 07:24:28,018 [Listener at localhost/44273] INFO  server.Server (Server.java:doStart(419)) - Started @6414ms
2020-12-03 07:24:28,023 [Thread-83] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 11600@0b2162a51c02
2020-12-03 07:24:28,023 [Thread-106] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 11600@0b2162a51c02
2020-12-03 07:24:28,023 [Thread-59] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 11600@0b2162a51c02
2020-12-03 07:24:28,023 [Thread-128] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/in_use.lock acquired by nodename 11600@0b2162a51c02
2020-12-03 07:24:28,023 [Thread-150] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/in_use.lock acquired by nodename 11600@0b2162a51c02
2020-12-03 07:24:28,024 [Thread-83] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 is not formatted for namespace 728208751. Formatting...
2020-12-03 07:24:28,024 [Thread-59] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 728208751. Formatting...
2020-12-03 07:24:28,024 [Thread-106] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 is not formatted for namespace 728208751. Formatting...
2020-12-03 07:24:28,024 [Thread-128] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 is not formatted for namespace 728208751. Formatting...
2020-12-03 07:24:28,025 [Thread-150] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 is not formatted for namespace 728208751. Formatting...
2020-12-03 07:24:28,027 [Thread-59] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-dbecbb28-d168-4eb9-ba31-b857b3014299 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-12-03 07:24:28,027 [Thread-128] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-bd675065-6cc8-4703-9ce8-7e1aa5d0f9dc for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 
2020-12-03 07:24:28,027 [Thread-106] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-64b240c2-d3e0-4acf-93d6-cebd18220651 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 
2020-12-03 07:24:28,028 [Thread-83] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-58c3452e-b5a4-4351-a5dd-720979be90e5 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 
2020-12-03 07:24:28,028 [Thread-150] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-8c30b030-99db-4142-8d95-5495cf2e3bb5 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 
2020-12-03 07:24:28,035 [Listener at localhost/44273] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:44791
2020-12-03 07:24:28,035 [Listener at localhost/44273] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:24:28,035 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@65ef722a] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:28,035 [Listener at localhost/44273] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:24:28,036 [Listener at localhost/44273] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:28,037 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:28,040 [Listener at localhost/40240] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:40240
2020-12-03 07:24:28,044 [Listener at localhost/40240] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:24:28,044 [Listener at localhost/40240] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:24:28,045 [Thread-194] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37942 starting to offer service
2020-12-03 07:24:28,046 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:28,047 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:28,049 [Thread-194] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37942
2020-12-03 07:24:28,050 [Thread-194] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:24:28,050 [Listener at localhost/40240] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 7 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:24:28,052 [Listener at localhost/40240] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:24:28,052 [Listener at localhost/40240] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:24:28,054 [Listener at localhost/40240] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:24:28,054 [Listener at localhost/40240] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:28,054 [Listener at localhost/40240] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:24:28,055 [Listener at localhost/40240] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:24:28,055 [Listener at localhost/40240] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:28,055 [Listener at localhost/40240] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:24:28,055 [Listener at localhost/40240] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:24:28,056 [Listener at localhost/40240] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:24:28,056 [Listener at localhost/40240] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:40699
2020-12-03 07:24:28,056 [Listener at localhost/40240] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:24:28,056 [Listener at localhost/40240] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:24:28,057 [Listener at localhost/40240] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:28,059 [Listener at localhost/40240] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:28,059 [Listener at localhost/40240] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:24:28,059 [Listener at localhost/40240] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:28,061 [Listener at localhost/40240] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:28,062 [Listener at localhost/40240] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:24:28,062 [Listener at localhost/40240] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:28,062 [Listener at localhost/40240] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:28,063 [Listener at localhost/40240] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 43410
2020-12-03 07:24:28,063 [Listener at localhost/40240] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:28,064 [Listener at localhost/40240] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@57dc9128{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:28,065 [Listener at localhost/40240] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@17ae98d7{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:28,071 [Listener at localhost/40240] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5c371e13{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:24:28,072 [Listener at localhost/40240] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@530a8454{HTTP/1.1,[http/1.1]}{localhost:43410}
2020-12-03 07:24:28,072 [Listener at localhost/40240] INFO  server.Server (Server.java:doStart(419)) - Started @6468ms
2020-12-03 07:24:28,121 [Listener at localhost/40240] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:46821
2020-12-03 07:24:28,122 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5215cd9a] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:28,122 [Listener at localhost/40240] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:24:28,122 [Listener at localhost/40240] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:24:28,123 [Listener at localhost/40240] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:28,124 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:28,127 [Listener at localhost/36341] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:36341
2020-12-03 07:24:28,132 [Listener at localhost/36341] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:24:28,132 [Listener at localhost/36341] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:24:28,133 [Thread-216] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37942 starting to offer service
2020-12-03 07:24:28,134 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:28,134 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:28,135 [Thread-172] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/in_use.lock acquired by nodename 11600@0b2162a51c02
2020-12-03 07:24:28,137 [Thread-172] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 is not formatted for namespace 728208751. Formatting...
2020-12-03 07:24:28,138 [Thread-172] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-c69444b7-75df-4430-81d2-ce7868dd7889 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 
2020-12-03 07:24:28,138 [Listener at localhost/36341] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 8 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:24:28,138 [Thread-216] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37942
2020-12-03 07:24:28,139 [Thread-216] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:24:28,140 [Listener at localhost/36341] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:24:28,140 [Listener at localhost/36341] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:24:28,142 [Listener at localhost/36341] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:24:28,142 [Listener at localhost/36341] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:28,143 [Listener at localhost/36341] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:24:28,143 [Listener at localhost/36341] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:24:28,143 [Listener at localhost/36341] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:28,143 [Listener at localhost/36341] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:24:28,144 [Listener at localhost/36341] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:24:28,144 [Listener at localhost/36341] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:24:28,144 [Listener at localhost/36341] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:41151
2020-12-03 07:24:28,145 [Listener at localhost/36341] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:24:28,145 [Listener at localhost/36341] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:24:28,146 [Listener at localhost/36341] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:28,147 [Listener at localhost/36341] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:28,148 [Listener at localhost/36341] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:24:28,148 [Listener at localhost/36341] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:28,150 [Listener at localhost/36341] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:28,151 [Listener at localhost/36341] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:24:28,151 [Listener at localhost/36341] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:28,151 [Listener at localhost/36341] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:28,152 [Listener at localhost/36341] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 41615
2020-12-03 07:24:28,152 [Listener at localhost/36341] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:28,154 [Listener at localhost/36341] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@50cf5a23{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:28,155 [Listener at localhost/36341] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@273c947f{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:28,160 [Listener at localhost/36341] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@2c1dc8e{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:24:28,162 [Listener at localhost/36341] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@b273a59{HTTP/1.1,[http/1.1]}{localhost:41615}
2020-12-03 07:24:28,162 [Listener at localhost/36341] INFO  server.Server (Server.java:doStart(419)) - Started @6558ms
2020-12-03 07:24:28,177 [Listener at localhost/36341] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:45134
2020-12-03 07:24:28,177 [Listener at localhost/36341] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:24:28,177 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@251ebf23] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:28,177 [Listener at localhost/36341] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:24:28,178 [Listener at localhost/36341] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:28,179 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:28,182 [Listener at localhost/42122] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:42122
2020-12-03 07:24:28,187 [Listener at localhost/42122] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:24:28,187 [Listener at localhost/42122] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:24:28,188 [Thread-238] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37942 starting to offer service
2020-12-03 07:24:28,192 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:28,192 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:28,195 [Thread-238] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37942
2020-12-03 07:24:28,196 [Thread-238] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:24:28,200 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSClient.java:<init>(318)) - Sets dfs.client.block.write.replace-datanode-on-failure.min-replication to 0
2020-12-03 07:24:28,206 [Thread-194] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/in_use.lock acquired by nodename 11600@0b2162a51c02
2020-12-03 07:24:28,206 [Thread-194] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 is not formatted for namespace 728208751. Formatting...
2020-12-03 07:24:28,208 [Thread-194] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-5eaccf1b-8417-47bc-a260-6b7d108d3890 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 
2020-12-03 07:24:28,306 [Thread-216] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/in_use.lock acquired by nodename 11600@0b2162a51c02
2020-12-03 07:24:28,306 [Thread-238] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/in_use.lock acquired by nodename 11600@0b2162a51c02
2020-12-03 07:24:28,306 [Thread-216] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 is not formatted for namespace 728208751. Formatting...
2020-12-03 07:24:28,306 [Thread-238] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 is not formatted for namespace 728208751. Formatting...
2020-12-03 07:24:28,307 [Thread-216] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-fed01141-fff1-42c6-b3e3-2fd935c70283 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 
2020-12-03 07:24:28,307 [Thread-238] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-0539376e-ad17-43e8-b692-2105b79e3e6f for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 
2020-12-03 07:24:28,586 [Thread-83] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 11600@0b2162a51c02
2020-12-03 07:24:28,586 [Thread-150] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/in_use.lock acquired by nodename 11600@0b2162a51c02
2020-12-03 07:24:28,586 [Thread-83] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 is not formatted for namespace 728208751. Formatting...
2020-12-03 07:24:28,586 [Thread-150] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 is not formatted for namespace 728208751. Formatting...
2020-12-03 07:24:28,586 [Thread-106] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 11600@0b2162a51c02
2020-12-03 07:24:28,587 [Thread-128] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/in_use.lock acquired by nodename 11600@0b2162a51c02
2020-12-03 07:24:28,587 [Thread-106] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 is not formatted for namespace 728208751. Formatting...
2020-12-03 07:24:28,587 [Thread-128] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 is not formatted for namespace 728208751. Formatting...
2020-12-03 07:24:28,587 [Thread-59] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 11600@0b2162a51c02
2020-12-03 07:24:28,587 [Thread-59] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 728208751. Formatting...
2020-12-03 07:24:28,588 [Thread-106] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-2b1930b4-e95b-4943-b1ab-05b98259886a for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 
2020-12-03 07:24:28,588 [Thread-150] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-3ce64bf6-e24c-4061-a4ce-b388ab5aa2c5 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 
2020-12-03 07:24:28,588 [Thread-83] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-64790cae-1f9a-427b-8afc-04566b3d97c3 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 
2020-12-03 07:24:28,588 [Thread-128] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-0a7b21f4-bc72-417b-a4b0-d8ece257c7ca for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 
2020-12-03 07:24:28,588 [Thread-59] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-4a408526-9e3d-400e-9c97-b7f2da3ca414 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-12-03 07:24:28,657 [IPC Server handler 4 on default port 37942] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:28,665 [Listener at localhost/42122] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:28,665 [Listener at localhost/42122] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:28,680 [Thread-172] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/in_use.lock acquired by nodename 11600@0b2162a51c02
2020-12-03 07:24:28,680 [Thread-172] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 is not formatted for namespace 728208751. Formatting...
2020-12-03 07:24:28,682 [Thread-172] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-59fe4be7-7d46-4bcc-944e-0f4b194e3df4 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 
2020-12-03 07:24:28,768 [IPC Server handler 3 on default port 37942] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:28,769 [Thread-194] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/in_use.lock acquired by nodename 11600@0b2162a51c02
2020-12-03 07:24:28,769 [Listener at localhost/42122] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:28,769 [Listener at localhost/42122] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:28,769 [Thread-194] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 is not formatted for namespace 728208751. Formatting...
2020-12-03 07:24:28,772 [Thread-194] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-05560e71-949b-4174-be33-ae1a2a0941d8 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 
2020-12-03 07:24:28,855 [Thread-238] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/in_use.lock acquired by nodename 11600@0b2162a51c02
2020-12-03 07:24:28,855 [Thread-216] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/in_use.lock acquired by nodename 11600@0b2162a51c02
2020-12-03 07:24:28,855 [Thread-238] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 is not formatted for namespace 728208751. Formatting...
2020-12-03 07:24:28,856 [Thread-216] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 is not formatted for namespace 728208751. Formatting...
2020-12-03 07:24:28,858 [Thread-238] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-713fdee5-399a-4945-8293-dd270e62d1e4 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 
2020-12-03 07:24:28,858 [Thread-216] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-d11be790-a115-4b62-b13d-a4d0d7a30b7a for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 
2020-12-03 07:24:28,871 [IPC Server handler 5 on default port 37942] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:28,872 [Listener at localhost/42122] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:28,872 [Listener at localhost/42122] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:28,971 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:28,972 [Thread-106] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:28,972 [Thread-150] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:28,972 [Thread-106] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:28,972 [Thread-59] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:28,972 [Thread-150] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:28,973 [Thread-150] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 and block pool id BP-101448600-172.17.0.4-1606980263805 is not formatted. Formatting ...
2020-12-03 07:24:28,973 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-101448600-172.17.0.4-1606980263805 is not formatted. Formatting ...
2020-12-03 07:24:28,973 [Thread-106] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 and block pool id BP-101448600-172.17.0.4-1606980263805 is not formatted. Formatting ...
2020-12-03 07:24:28,973 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-101448600-172.17.0.4-1606980263805 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-101448600-172.17.0.4-1606980263805/current
2020-12-03 07:24:28,973 [Thread-150] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-101448600-172.17.0.4-1606980263805 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-101448600-172.17.0.4-1606980263805/current
2020-12-03 07:24:28,973 [Thread-106] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-101448600-172.17.0.4-1606980263805 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-101448600-172.17.0.4-1606980263805/current
2020-12-03 07:24:28,974 [Thread-128] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:28,974 [Thread-128] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:28,975 [IPC Server handler 1 on default port 37942] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:28,975 [Thread-128] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 and block pool id BP-101448600-172.17.0.4-1606980263805 is not formatted. Formatting ...
2020-12-03 07:24:28,975 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:28,975 [Thread-128] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-101448600-172.17.0.4-1606980263805 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-101448600-172.17.0.4-1606980263805/current
2020-12-03 07:24:28,975 [Thread-83] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:28,975 [Listener at localhost/42122] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:28,976 [Listener at localhost/42122] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:28,975 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 and block pool id BP-101448600-172.17.0.4-1606980263805 is not formatted. Formatting ...
2020-12-03 07:24:28,976 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-101448600-172.17.0.4-1606980263805 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-101448600-172.17.0.4-1606980263805/current
2020-12-03 07:24:29,067 [Thread-172] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:29,067 [Thread-172] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:29,067 [Thread-172] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 and block pool id BP-101448600-172.17.0.4-1606980263805 is not formatted. Formatting ...
2020-12-03 07:24:29,067 [Thread-172] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-101448600-172.17.0.4-1606980263805 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-101448600-172.17.0.4-1606980263805/current
2020-12-03 07:24:29,078 [IPC Server handler 8 on default port 37942] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:29,078 [Listener at localhost/42122] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:29,079 [Listener at localhost/42122] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:29,170 [Thread-194] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:29,170 [Thread-194] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:29,171 [Thread-194] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 and block pool id BP-101448600-172.17.0.4-1606980263805 is not formatted. Formatting ...
2020-12-03 07:24:29,171 [Thread-194] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-101448600-172.17.0.4-1606980263805 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-101448600-172.17.0.4-1606980263805/current
2020-12-03 07:24:29,181 [IPC Server handler 6 on default port 37942] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:29,181 [Listener at localhost/42122] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:29,181 [Listener at localhost/42122] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:29,267 [Thread-216] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:29,267 [Thread-238] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:29,267 [Thread-216] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:29,268 [Thread-238] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:29,268 [Thread-216] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 and block pool id BP-101448600-172.17.0.4-1606980263805 is not formatted. Formatting ...
2020-12-03 07:24:29,268 [Thread-238] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 and block pool id BP-101448600-172.17.0.4-1606980263805 is not formatted. Formatting ...
2020-12-03 07:24:29,268 [Thread-216] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-101448600-172.17.0.4-1606980263805 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-101448600-172.17.0.4-1606980263805/current
2020-12-03 07:24:29,268 [Thread-238] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-101448600-172.17.0.4-1606980263805 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-101448600-172.17.0.4-1606980263805/current
2020-12-03 07:24:29,284 [IPC Server handler 9 on default port 37942] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:29,285 [Listener at localhost/42122] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:29,286 [Listener at localhost/42122] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:29,348 [Thread-128] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:29,348 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:29,349 [Thread-128] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:29,349 [Thread-83] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:29,349 [Thread-128] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 and block pool id BP-101448600-172.17.0.4-1606980263805 is not formatted. Formatting ...
2020-12-03 07:24:29,349 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 and block pool id BP-101448600-172.17.0.4-1606980263805 is not formatted. Formatting ...
2020-12-03 07:24:29,349 [Thread-106] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:29,349 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-101448600-172.17.0.4-1606980263805 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-101448600-172.17.0.4-1606980263805/current
2020-12-03 07:24:29,349 [Thread-128] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-101448600-172.17.0.4-1606980263805 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-101448600-172.17.0.4-1606980263805/current
2020-12-03 07:24:29,350 [Thread-106] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:29,350 [Thread-106] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 and block pool id BP-101448600-172.17.0.4-1606980263805 is not formatted. Formatting ...
2020-12-03 07:24:29,350 [Thread-150] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:29,350 [Thread-106] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-101448600-172.17.0.4-1606980263805 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-101448600-172.17.0.4-1606980263805/current
2020-12-03 07:24:29,351 [Thread-150] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:29,351 [Thread-150] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 and block pool id BP-101448600-172.17.0.4-1606980263805 is not formatted. Formatting ...
2020-12-03 07:24:29,351 [Thread-150] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-101448600-172.17.0.4-1606980263805 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-101448600-172.17.0.4-1606980263805/current
2020-12-03 07:24:29,352 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:29,352 [Thread-59] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:29,352 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-101448600-172.17.0.4-1606980263805 is not formatted. Formatting ...
2020-12-03 07:24:29,352 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-101448600-172.17.0.4-1606980263805 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-101448600-172.17.0.4-1606980263805/current
2020-12-03 07:24:29,388 [IPC Server handler 4 on default port 37942] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:29,388 [Listener at localhost/42122] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:29,389 [Listener at localhost/42122] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:29,467 [Thread-172] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:29,468 [Thread-172] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:29,468 [Thread-172] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 and block pool id BP-101448600-172.17.0.4-1606980263805 is not formatted. Formatting ...
2020-12-03 07:24:29,468 [Thread-172] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-101448600-172.17.0.4-1606980263805 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-101448600-172.17.0.4-1606980263805/current
2020-12-03 07:24:29,491 [IPC Server handler 3 on default port 37942] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:29,491 [Listener at localhost/42122] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:29,492 [Listener at localhost/42122] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:29,594 [IPC Server handler 5 on default port 37942] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:29,594 [Thread-194] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:29,595 [Listener at localhost/42122] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:29,595 [Listener at localhost/42122] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:29,595 [Thread-194] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:29,595 [Thread-194] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 and block pool id BP-101448600-172.17.0.4-1606980263805 is not formatted. Formatting ...
2020-12-03 07:24:29,596 [Thread-194] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-101448600-172.17.0.4-1606980263805 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-101448600-172.17.0.4-1606980263805/current
2020-12-03 07:24:29,701 [IPC Server handler 2 on default port 37942] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:29,701 [Listener at localhost/42122] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:29,703 [Listener at localhost/42122] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:29,708 [Thread-216] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:29,708 [Thread-238] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:29,709 [Thread-216] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:29,709 [Thread-238] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:29,709 [Thread-216] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 and block pool id BP-101448600-172.17.0.4-1606980263805 is not formatted. Formatting ...
2020-12-03 07:24:29,709 [Thread-238] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 and block pool id BP-101448600-172.17.0.4-1606980263805 is not formatted. Formatting ...
2020-12-03 07:24:29,709 [Thread-216] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-101448600-172.17.0.4-1606980263805 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-101448600-172.17.0.4-1606980263805/current
2020-12-03 07:24:29,709 [Thread-238] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-101448600-172.17.0.4-1606980263805 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-101448600-172.17.0.4-1606980263805/current
2020-12-03 07:24:29,782 [Thread-106] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=728208751;bpid=BP-101448600-172.17.0.4-1606980263805;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=728208751;c=1606980263805;bpid=BP-101448600-172.17.0.4-1606980263805;dnuuid=null
2020-12-03 07:24:29,782 [Thread-128] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=728208751;bpid=BP-101448600-172.17.0.4-1606980263805;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=728208751;c=1606980263805;bpid=BP-101448600-172.17.0.4-1606980263805;dnuuid=null
2020-12-03 07:24:29,782 [Thread-150] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=728208751;bpid=BP-101448600-172.17.0.4-1606980263805;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=728208751;c=1606980263805;bpid=BP-101448600-172.17.0.4-1606980263805;dnuuid=null
2020-12-03 07:24:29,782 [Thread-83] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=728208751;bpid=BP-101448600-172.17.0.4-1606980263805;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=728208751;c=1606980263805;bpid=BP-101448600-172.17.0.4-1606980263805;dnuuid=null
2020-12-03 07:24:29,782 [Thread-59] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=728208751;bpid=BP-101448600-172.17.0.4-1606980263805;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=728208751;c=1606980263805;bpid=BP-101448600-172.17.0.4-1606980263805;dnuuid=null
2020-12-03 07:24:29,805 [IPC Server handler 0 on default port 37942] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:29,806 [Listener at localhost/42122] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:29,807 [Listener at localhost/42122] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:29,883 [Thread-172] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=728208751;bpid=BP-101448600-172.17.0.4-1606980263805;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=728208751;c=1606980263805;bpid=BP-101448600-172.17.0.4-1606980263805;dnuuid=null
2020-12-03 07:24:29,909 [IPC Server handler 1 on default port 37942] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:29,910 [Listener at localhost/42122] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:29,910 [Listener at localhost/42122] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:29,990 [Thread-194] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=728208751;bpid=BP-101448600-172.17.0.4-1606980263805;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=728208751;c=1606980263805;bpid=BP-101448600-172.17.0.4-1606980263805;dnuuid=null
2020-12-03 07:24:30,012 [IPC Server handler 7 on default port 37942] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:30,013 [Listener at localhost/42122] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:30,013 [Listener at localhost/42122] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:30,080 [Thread-238] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=728208751;bpid=BP-101448600-172.17.0.4-1606980263805;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=728208751;c=1606980263805;bpid=BP-101448600-172.17.0.4-1606980263805;dnuuid=null
2020-12-03 07:24:30,081 [Thread-216] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=728208751;bpid=BP-101448600-172.17.0.4-1606980263805;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=728208751;c=1606980263805;bpid=BP-101448600-172.17.0.4-1606980263805;dnuuid=null
2020-12-03 07:24:30,116 [IPC Server handler 6 on default port 37942] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:30,117 [Listener at localhost/42122] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:30,117 [Listener at localhost/42122] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:30,170 [Thread-106] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID fc65a25e-b981-4606-bf42-5ab919638725
2020-12-03 07:24:30,170 [Thread-83] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 3d6f040b-d45e-46f5-a3a5-f40179b44cc0
2020-12-03 07:24:30,170 [Thread-150] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 465a80b3-febd-4847-917b-1dc53950f7b6
2020-12-03 07:24:30,170 [Thread-59] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 8aedd082-415f-407a-9939-da8f8aa1070e
2020-12-03 07:24:30,170 [Thread-128] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 7a4b452a-06fd-49f4-826c-a3fc6bc9bddf
2020-12-03 07:24:30,219 [IPC Server handler 9 on default port 37942] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:30,220 [Listener at localhost/42122] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:30,220 [Listener at localhost/42122] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:30,245 [Thread-172] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 1c08a3ea-8510-4f3b-8323-c247c1ad19bf
2020-12-03 07:24:30,305 [Thread-106] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-64b240c2-d3e0-4acf-93d6-cebd18220651
2020-12-03 07:24:30,307 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-58c3452e-b5a4-4351-a5dd-720979be90e5
2020-12-03 07:24:30,305 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-dbecbb28-d168-4eb9-ba31-b857b3014299
2020-12-03 07:24:30,308 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: DISK
2020-12-03 07:24:30,308 [Thread-106] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, StorageType: DISK
2020-12-03 07:24:30,305 [Thread-150] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-8c30b030-99db-4142-8d95-5495cf2e3bb5
2020-12-03 07:24:30,309 [Thread-150] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, StorageType: DISK
2020-12-03 07:24:30,309 [Thread-128] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-bd675065-6cc8-4703-9ce8-7e1aa5d0f9dc
2020-12-03 07:24:30,310 [Thread-128] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, StorageType: DISK
2020-12-03 07:24:30,310 [Thread-172] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-c69444b7-75df-4430-81d2-ce7868dd7889
2020-12-03 07:24:30,311 [Thread-172] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, StorageType: DISK
2020-12-03 07:24:30,312 [Thread-106] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-2b1930b4-e95b-4943-b1ab-05b98259886a
2020-12-03 07:24:30,308 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-12-03 07:24:30,315 [Thread-128] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-0a7b21f4-bc72-417b-a4b0-d8ece257c7ca
2020-12-03 07:24:30,316 [Thread-128] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, StorageType: DISK
2020-12-03 07:24:30,315 [Thread-106] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, StorageType: DISK
2020-12-03 07:24:30,314 [Thread-172] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-59fe4be7-7d46-4bcc-944e-0f4b194e3df4
2020-12-03 07:24:30,317 [Thread-172] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, StorageType: DISK
2020-12-03 07:24:30,324 [IPC Server handler 4 on default port 37942] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:30,325 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-64790cae-1f9a-427b-8afc-04566b3d97c3
2020-12-03 07:24:30,325 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: DISK
2020-12-03 07:24:30,326 [Thread-194] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID a694dd51-5287-4646-b84f-3cf953f6fc1c
2020-12-03 07:24:30,326 [Thread-106] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:24:30,327 [Thread-128] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:24:30,327 [Thread-150] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-3ce64bf6-e24c-4061-a4ce-b388ab5aa2c5
2020-12-03 07:24:30,327 [Thread-150] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, StorageType: DISK
2020-12-03 07:24:30,329 [Thread-150] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:24:30,326 [Thread-172] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:24:30,329 [Listener at localhost/42122] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:30,331 [Listener at localhost/42122] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:30,329 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:24:30,336 [Thread-128] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:24:30,338 [Thread-106] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:24:30,340 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-4a408526-9e3d-400e-9c97-b7f2da3ca414
2020-12-03 07:24:30,341 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-12-03 07:24:30,342 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:24:30,342 [Thread-83] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:24:30,345 [Thread-150] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:24:30,347 [Thread-172] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:24:30,348 [Thread-194] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-5eaccf1b-8417-47bc-a260-6b7d108d3890
2020-12-03 07:24:30,364 [Thread-194] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, StorageType: DISK
2020-12-03 07:24:30,364 [Thread-59] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:24:30,357 [Thread-172] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:24:30,363 [Thread-128] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:24:30,364 [Thread-150] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:24:30,364 [Thread-106] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:24:30,363 [Thread-83] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:24:30,367 [Thread-59] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:24:30,369 [Thread-59] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:24:30,369 [Thread-59] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:24:30,369 [Thread-172] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:24:30,369 [Thread-194] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-05560e71-949b-4174-be33-ae1a2a0941d8
2020-12-03 07:24:30,371 [Thread-150] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:24:30,369 [Thread-83] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:24:30,369 [Thread-172] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:24:30,372 [Thread-106] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:24:30,373 [Thread-172] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:30,372 [Thread-83] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:24:30,372 [Thread-128] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:24:30,371 [Thread-194] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, StorageType: DISK
2020-12-03 07:24:30,376 [Thread-194] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:24:30,376 [Thread-128] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:24:30,376 [Thread-128] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:30,377 [Thread-268] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-101448600-172.17.0.4-1606980263805 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-12-03 07:24:30,372 [Thread-150] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:24:30,372 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:30,377 [Thread-150] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:30,376 [Thread-238] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 1f53bb69-aae2-4eb5-9dde-35ced37b4811
2020-12-03 07:24:30,376 [Thread-216] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 67bdfdb6-f4be-4592-925f-42e7b62de913
2020-12-03 07:24:30,375 [Thread-267] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-101448600-172.17.0.4-1606980263805 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12...
2020-12-03 07:24:30,378 [Thread-194] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:24:30,375 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:30,378 [Thread-270] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-101448600-172.17.0.4-1606980263805 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:24:30,375 [Thread-266] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-101448600-172.17.0.4-1606980263805 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11...
2020-12-03 07:24:30,379 [Thread-273] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-101448600-172.17.0.4-1606980263805 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-12-03 07:24:30,373 [Thread-106] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:24:30,379 [Thread-272] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-101448600-172.17.0.4-1606980263805 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:24:30,379 [Thread-106] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:30,378 [Thread-271] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-101448600-172.17.0.4-1606980263805 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-12-03 07:24:30,378 [Thread-269] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-101448600-172.17.0.4-1606980263805 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-12-03 07:24:30,380 [Thread-274] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-101448600-172.17.0.4-1606980263805 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:24:30,381 [Thread-194] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:24:30,382 [Thread-194] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:24:30,382 [Thread-216] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-fed01141-fff1-42c6-b3e3-2fd935c70283
2020-12-03 07:24:30,382 [Thread-216] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, StorageType: DISK
2020-12-03 07:24:30,382 [Thread-194] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:24:30,383 [Thread-194] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:30,384 [Thread-276] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-101448600-172.17.0.4-1606980263805 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:24:30,385 [Thread-279] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-101448600-172.17.0.4-1606980263805 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13...
2020-12-03 07:24:30,388 [Thread-281] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-101448600-172.17.0.4-1606980263805 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14...
2020-12-03 07:24:30,388 [Thread-238] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-0539376e-ad17-43e8-b692-2105b79e3e6f
2020-12-03 07:24:30,390 [Thread-280] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-101448600-172.17.0.4-1606980263805 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:24:30,390 [Thread-238] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, StorageType: DISK
2020-12-03 07:24:30,390 [Thread-275] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-101448600-172.17.0.4-1606980263805 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:24:30,390 [Thread-216] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-d11be790-a115-4b62-b13d-a4d0d7a30b7a
2020-12-03 07:24:30,391 [Thread-216] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, StorageType: DISK
2020-12-03 07:24:30,391 [Thread-216] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:24:30,393 [Thread-238] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-713fdee5-399a-4945-8293-dd270e62d1e4
2020-12-03 07:24:30,393 [Thread-238] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, StorageType: DISK
2020-12-03 07:24:30,394 [Thread-216] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:24:30,395 [Thread-238] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:24:30,396 [Thread-216] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:24:30,396 [Thread-216] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:24:30,396 [Thread-216] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:24:30,397 [Thread-216] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:30,397 [Thread-238] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:24:30,398 [Thread-284] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-101448600-172.17.0.4-1606980263805 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15...
2020-12-03 07:24:30,398 [Thread-285] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-101448600-172.17.0.4-1606980263805 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16...
2020-12-03 07:24:30,398 [Thread-238] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:24:30,398 [Thread-238] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:24:30,398 [Thread-238] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:24:30,399 [Thread-238] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:30,400 [Thread-286] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-101448600-172.17.0.4-1606980263805 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17...
2020-12-03 07:24:30,400 [Thread-287] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-101448600-172.17.0.4-1606980263805 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18...
2020-12-03 07:24:30,443 [IPC Server handler 3 on default port 37942] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:30,446 [Listener at localhost/42122] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:30,447 [Listener at localhost/42122] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:30,488 [Thread-274] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-101448600-172.17.0.4-1606980263805 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 108ms
2020-12-03 07:24:30,490 [Thread-271] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-101448600-172.17.0.4-1606980263805 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 110ms
2020-12-03 07:24:30,510 [Thread-276] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-101448600-172.17.0.4-1606980263805 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 125ms
2020-12-03 07:24:30,513 [Thread-269] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-101448600-172.17.0.4-1606980263805 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 134ms
2020-12-03 07:24:30,513 [Thread-281] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-101448600-172.17.0.4-1606980263805 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14: 125ms
2020-12-03 07:24:30,515 [Thread-268] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-101448600-172.17.0.4-1606980263805 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 138ms
2020-12-03 07:24:30,515 [Thread-280] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-101448600-172.17.0.4-1606980263805 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 126ms
2020-12-03 07:24:30,515 [Thread-106] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-101448600-172.17.0.4-1606980263805: 136ms
2020-12-03 07:24:30,530 [Thread-306] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-101448600-172.17.0.4-1606980263805 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:24:30,530 [Thread-306] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-101448600-172.17.0.4-1606980263805/current/replicas doesn't exist 
2020-12-03 07:24:30,530 [Thread-307] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-101448600-172.17.0.4-1606980263805 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:24:30,533 [Thread-128] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-101448600-172.17.0.4-1606980263805: 157ms
2020-12-03 07:24:30,534 [Thread-308] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-101448600-172.17.0.4-1606980263805 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-12-03 07:24:30,535 [Thread-306] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-101448600-172.17.0.4-1606980263805 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 5ms
2020-12-03 07:24:30,535 [Thread-309] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-101448600-172.17.0.4-1606980263805 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-12-03 07:24:30,541 [Thread-309] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-101448600-172.17.0.4-1606980263805/current/replicas doesn't exist 
2020-12-03 07:24:30,530 [Thread-307] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-101448600-172.17.0.4-1606980263805/current/replicas doesn't exist 
2020-12-03 07:24:30,542 [Thread-309] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-101448600-172.17.0.4-1606980263805 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 7ms
2020-12-03 07:24:30,534 [Thread-308] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-101448600-172.17.0.4-1606980263805/current/replicas doesn't exist 
2020-12-03 07:24:30,553 [Thread-308] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-101448600-172.17.0.4-1606980263805 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 19ms
2020-12-03 07:24:30,549 [Thread-286] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-101448600-172.17.0.4-1606980263805 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17: 148ms
2020-12-03 07:24:30,554 [Thread-128] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-101448600-172.17.0.4-1606980263805: 20ms
2020-12-03 07:24:30,558 [IPC Server handler 5 on default port 37942] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:30,559 [Thread-272] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-101448600-172.17.0.4-1606980263805 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 180ms
2020-12-03 07:24:30,559 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-101448600-172.17.0.4-1606980263805 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:24:30,559 [Listener at localhost/42122] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:30,559 [Listener at localhost/42122] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:30,559 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-101448600-172.17.0.4-1606980263805 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:24:30,561 [Thread-267] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-101448600-172.17.0.4-1606980263805 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12: 183ms
2020-12-03 07:24:30,561 [Thread-307] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-101448600-172.17.0.4-1606980263805 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 30ms
2020-12-03 07:24:30,562 [Thread-279] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-101448600-172.17.0.4-1606980263805 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13: 174ms
2020-12-03 07:24:30,562 [Thread-287] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-101448600-172.17.0.4-1606980263805 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18: 162ms
2020-12-03 07:24:30,561 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-0a7b21f4-bc72-417b-a4b0-d8ece257c7ca): finished scanning block pool BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:30,563 [Thread-238] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-101448600-172.17.0.4-1606980263805: 164ms
2020-12-03 07:24:30,563 [Thread-194] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-101448600-172.17.0.4-1606980263805: 179ms
2020-12-03 07:24:30,563 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-bd675065-6cc8-4703-9ce8-7e1aa5d0f9dc): finished scanning block pool BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:30,563 [Thread-106] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-101448600-172.17.0.4-1606980263805: 34ms
2020-12-03 07:24:30,564 [Thread-313] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-101448600-172.17.0.4-1606980263805 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18...
2020-12-03 07:24:30,565 [Thread-313] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-101448600-172.17.0.4-1606980263805/current/replicas doesn't exist 
2020-12-03 07:24:30,565 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-101448600-172.17.0.4-1606980263805 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:24:30,564 [Thread-311] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-101448600-172.17.0.4-1606980263805 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17...
2020-12-03 07:24:30,565 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-101448600-172.17.0.4-1606980263805 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:24:30,565 [Thread-311] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-101448600-172.17.0.4-1606980263805/current/replicas doesn't exist 
2020-12-03 07:24:30,565 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-64b240c2-d3e0-4acf-93d6-cebd18220651): finished scanning block pool BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:30,565 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-2b1930b4-e95b-4943-b1ab-05b98259886a): finished scanning block pool BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:30,566 [Thread-284] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-101448600-172.17.0.4-1606980263805 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15: 168ms
2020-12-03 07:24:30,567 [Thread-266] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-101448600-172.17.0.4-1606980263805 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11: 188ms
2020-12-03 07:24:30,567 [Thread-172] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-101448600-172.17.0.4-1606980263805: 193ms
2020-12-03 07:24:30,568 [Thread-311] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-101448600-172.17.0.4-1606980263805 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17: 3ms
2020-12-03 07:24:30,568 [Thread-314] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-101448600-172.17.0.4-1606980263805 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13...
2020-12-03 07:24:30,571 [Thread-314] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-101448600-172.17.0.4-1606980263805/current/replicas doesn't exist 
2020-12-03 07:24:30,571 [Thread-314] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-101448600-172.17.0.4-1606980263805 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13: 3ms
2020-12-03 07:24:30,571 [Thread-273] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-101448600-172.17.0.4-1606980263805 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 193ms
2020-12-03 07:24:30,571 [Thread-313] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-101448600-172.17.0.4-1606980263805 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18: 7ms
2020-12-03 07:24:30,571 [Thread-316] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-101448600-172.17.0.4-1606980263805 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14...
2020-12-03 07:24:30,572 [Thread-238] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-101448600-172.17.0.4-1606980263805: 8ms
2020-12-03 07:24:30,572 [Thread-319] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-101448600-172.17.0.4-1606980263805 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12...
2020-12-03 07:24:30,572 [Thread-319] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-101448600-172.17.0.4-1606980263805/current/replicas doesn't exist 
2020-12-03 07:24:30,573 [Thread-319] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-101448600-172.17.0.4-1606980263805 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12: 0ms
2020-12-03 07:24:30,572 [Thread-150] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-101448600-172.17.0.4-1606980263805: 194ms
2020-12-03 07:24:30,573 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-101448600-172.17.0.4-1606980263805 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:24:30,573 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-713fdee5-399a-4945-8293-dd270e62d1e4): finished scanning block pool BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:30,572 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-101448600-172.17.0.4-1606980263805 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:24:30,572 [Thread-316] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-101448600-172.17.0.4-1606980263805/current/replicas doesn't exist 
2020-12-03 07:24:30,572 [Thread-317] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-101448600-172.17.0.4-1606980263805 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11...
2020-12-03 07:24:30,574 [Thread-317] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-101448600-172.17.0.4-1606980263805/current/replicas doesn't exist 
2020-12-03 07:24:30,574 [Thread-275] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-101448600-172.17.0.4-1606980263805 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 184ms
2020-12-03 07:24:30,575 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-101448600-172.17.0.4-1606980263805: 197ms
2020-12-03 07:24:30,574 [Thread-323] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-101448600-172.17.0.4-1606980263805 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-12-03 07:24:30,574 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-0539376e-ad17-43e8-b692-2105b79e3e6f): finished scanning block pool BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:30,576 [Thread-324] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-101448600-172.17.0.4-1606980263805 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:24:30,576 [Thread-325] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-101448600-172.17.0.4-1606980263805 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:24:30,576 [Thread-325] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-101448600-172.17.0.4-1606980263805/current/replicas doesn't exist 
2020-12-03 07:24:30,576 [Thread-324] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-101448600-172.17.0.4-1606980263805/current/replicas doesn't exist 
2020-12-03 07:24:30,576 [Thread-323] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-101448600-172.17.0.4-1606980263805/current/replicas doesn't exist 
2020-12-03 07:24:30,576 [Thread-325] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-101448600-172.17.0.4-1606980263805 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 1ms
2020-12-03 07:24:30,574 [Thread-322] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-101448600-172.17.0.4-1606980263805 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-12-03 07:24:30,580 [Thread-316] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-101448600-172.17.0.4-1606980263805 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14: 8ms
2020-12-03 07:24:30,580 [Thread-322] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-101448600-172.17.0.4-1606980263805/current/replicas doesn't exist 
2020-12-03 07:24:30,580 [Thread-317] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-101448600-172.17.0.4-1606980263805 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11: 6ms
2020-12-03 07:24:30,589 [Thread-172] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-101448600-172.17.0.4-1606980263805: 20ms
2020-12-03 07:24:30,589 [Thread-270] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-101448600-172.17.0.4-1606980263805 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 201ms
2020-12-03 07:24:30,589 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-101448600-172.17.0.4-1606980263805 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:24:30,580 [Thread-194] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-101448600-172.17.0.4-1606980263805: 15ms
2020-12-03 07:24:30,589 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-101448600-172.17.0.4-1606980263805 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:24:30,590 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-101448600-172.17.0.4-1606980263805: 212ms
2020-12-03 07:24:30,590 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-101448600-172.17.0.4-1606980263805 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:24:30,590 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-c69444b7-75df-4430-81d2-ce7868dd7889): finished scanning block pool BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:30,590 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-05560e71-949b-4174-be33-ae1a2a0941d8): finished scanning block pool BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:30,580 [Thread-323] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-101448600-172.17.0.4-1606980263805 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 5ms
2020-12-03 07:24:30,587 [Thread-322] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-101448600-172.17.0.4-1606980263805 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 8ms
2020-12-03 07:24:30,590 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-59fe4be7-7d46-4bcc-944e-0f4b194e3df4): finished scanning block pool BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:30,591 [Thread-285] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-101448600-172.17.0.4-1606980263805 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16: 194ms
2020-12-03 07:24:30,592 [Thread-216] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-101448600-172.17.0.4-1606980263805: 194ms
2020-12-03 07:24:30,592 [Thread-324] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-101448600-172.17.0.4-1606980263805 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 17ms
2020-12-03 07:24:30,593 [Thread-331] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-101448600-172.17.0.4-1606980263805 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:24:30,593 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-101448600-172.17.0.4-1606980263805: 17ms
2020-12-03 07:24:30,593 [Thread-331] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-101448600-172.17.0.4-1606980263805/current/replicas doesn't exist 
2020-12-03 07:24:30,594 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-101448600-172.17.0.4-1606980263805 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:24:30,594 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-101448600-172.17.0.4-1606980263805 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:24:30,594 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-101448600-172.17.0.4-1606980263805 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:24:30,594 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-58c3452e-b5a4-4351-a5dd-720979be90e5): finished scanning block pool BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:30,597 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-64790cae-1f9a-427b-8afc-04566b3d97c3): finished scanning block pool BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:30,597 [Thread-333] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-101448600-172.17.0.4-1606980263805 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16...
2020-12-03 07:24:30,597 [Thread-330] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-101448600-172.17.0.4-1606980263805 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15...
2020-12-03 07:24:30,596 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-5eaccf1b-8417-47bc-a260-6b7d108d3890): finished scanning block pool BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:30,595 [Thread-328] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-101448600-172.17.0.4-1606980263805 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:24:30,595 [Thread-150] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-101448600-172.17.0.4-1606980263805: 23ms
2020-12-03 07:24:30,599 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-101448600-172.17.0.4-1606980263805 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:24:30,600 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-8c30b030-99db-4142-8d95-5495cf2e3bb5): finished scanning block pool BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:30,599 [Thread-328] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-101448600-172.17.0.4-1606980263805/current/replicas doesn't exist 
2020-12-03 07:24:30,600 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-101448600-172.17.0.4-1606980263805 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:24:30,599 [Thread-330] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-101448600-172.17.0.4-1606980263805/current/replicas doesn't exist 
2020-12-03 07:24:30,606 [Thread-330] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-101448600-172.17.0.4-1606980263805 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15: 8ms
2020-12-03 07:24:30,599 [Thread-333] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-101448600-172.17.0.4-1606980263805/current/replicas doesn't exist 
2020-12-03 07:24:30,598 [Thread-331] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-101448600-172.17.0.4-1606980263805 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 5ms
2020-12-03 07:24:30,606 [Thread-328] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-101448600-172.17.0.4-1606980263805 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 8ms
2020-12-03 07:24:30,606 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-3ce64bf6-e24c-4061-a4ce-b388ab5aa2c5): finished scanning block pool BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:30,609 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-101448600-172.17.0.4-1606980263805: 19ms
2020-12-03 07:24:30,609 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-101448600-172.17.0.4-1606980263805 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:24:30,608 [Thread-333] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-101448600-172.17.0.4-1606980263805 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16: 10ms
2020-12-03 07:24:30,609 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-101448600-172.17.0.4-1606980263805 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:24:30,610 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-4a408526-9e3d-400e-9c97-b7f2da3ca414): finished scanning block pool BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:30,610 [Thread-216] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-101448600-172.17.0.4-1606980263805: 18ms
2020-12-03 07:24:30,610 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-dbecbb28-d168-4eb9-ba31-b857b3014299): finished scanning block pool BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:30,610 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-101448600-172.17.0.4-1606980263805 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:24:30,610 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-101448600-172.17.0.4-1606980263805 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:24:30,610 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-fed01141-fff1-42c6-b3e3-2fd935c70283): finished scanning block pool BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:30,611 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-d11be790-a115-4b62-b13d-a4d0d7a30b7a): finished scanning block pool BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:30,614 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-64b240c2-d3e0-4acf-93d6-cebd18220651): no suitable block pools found to scan.  Waiting 1814399951 ms.
2020-12-03 07:24:30,614 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-c69444b7-75df-4430-81d2-ce7868dd7889): no suitable block pools found to scan.  Waiting 1814399975 ms.
2020-12-03 07:24:30,614 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-fed01141-fff1-42c6-b3e3-2fd935c70283): no suitable block pools found to scan.  Waiting 1814399996 ms.
2020-12-03 07:24:30,614 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-713fdee5-399a-4945-8293-dd270e62d1e4): no suitable block pools found to scan.  Waiting 1814399958 ms.
2020-12-03 07:24:30,614 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-58c3452e-b5a4-4351-a5dd-720979be90e5): no suitable block pools found to scan.  Waiting 1814399980 ms.
2020-12-03 07:24:30,614 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-bd675065-6cc8-4703-9ce8-7e1aa5d0f9dc): no suitable block pools found to scan.  Waiting 1814399945 ms.
2020-12-03 07:24:30,614 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-05560e71-949b-4174-be33-ae1a2a0941d8): no suitable block pools found to scan.  Waiting 1814399976 ms.
2020-12-03 07:24:30,615 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-64790cae-1f9a-427b-8afc-04566b3d97c3): no suitable block pools found to scan.  Waiting 1814399979 ms.
2020-12-03 07:24:30,615 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-0539376e-ad17-43e8-b692-2105b79e3e6f): no suitable block pools found to scan.  Waiting 1814399957 ms.
2020-12-03 07:24:30,615 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-dbecbb28-d168-4eb9-ba31-b857b3014299): no suitable block pools found to scan.  Waiting 1814399994 ms.
2020-12-03 07:24:30,614 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-d11be790-a115-4b62-b13d-a4d0d7a30b7a): no suitable block pools found to scan.  Waiting 1814399996 ms.
2020-12-03 07:24:30,615 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-2b1930b4-e95b-4943-b1ab-05b98259886a): no suitable block pools found to scan.  Waiting 1814399950 ms.
2020-12-03 07:24:30,615 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-59fe4be7-7d46-4bcc-944e-0f4b194e3df4): no suitable block pools found to scan.  Waiting 1814399974 ms.
2020-12-03 07:24:30,615 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-0a7b21f4-bc72-417b-a4b0-d8ece257c7ca): no suitable block pools found to scan.  Waiting 1814399944 ms.
2020-12-03 07:24:30,614 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-8c30b030-99db-4142-8d95-5495cf2e3bb5): no suitable block pools found to scan.  Waiting 1814399985 ms.
2020-12-03 07:24:30,614 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-5eaccf1b-8417-47bc-a260-6b7d108d3890): no suitable block pools found to scan.  Waiting 1814399976 ms.
2020-12-03 07:24:30,616 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-3ce64bf6-e24c-4061-a4ce-b388ab5aa2c5): no suitable block pools found to scan.  Waiting 1814399983 ms.
2020-12-03 07:24:30,616 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-4a408526-9e3d-400e-9c97-b7f2da3ca414): no suitable block pools found to scan.  Waiting 1814399993 ms.
2020-12-03 07:24:30,618 [Thread-238] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 8:34 AM with interval of 21600000ms
2020-12-03 07:24:30,619 [Thread-216] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:29 AM with interval of 21600000ms
2020-12-03 07:24:30,619 [Thread-106] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 12:02 PM with interval of 21600000ms
2020-12-03 07:24:30,618 [Thread-194] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 10:53 AM with interval of 21600000ms
2020-12-03 07:24:30,618 [Thread-128] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 9:04 AM with interval of 21600000ms
2020-12-03 07:24:30,630 [Thread-83] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 1:09 PM with interval of 21600000ms
2020-12-03 07:24:30,630 [Thread-59] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:26 AM with interval of 21600000ms
2020-12-03 07:24:30,630 [Thread-172] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 7:47 AM with interval of 21600000ms
2020-12-03 07:24:30,631 [Thread-150] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 12:41 PM with interval of 21600000ms
2020-12-03 07:24:30,635 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-101448600-172.17.0.4-1606980263805 (Datanode Uuid 7a4b452a-06fd-49f4-826c-a3fc6bc9bddf) service to localhost/127.0.0.1:37942 beginning handshake with NN
2020-12-03 07:24:30,635 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-101448600-172.17.0.4-1606980263805 (Datanode Uuid 8aedd082-415f-407a-9939-da8f8aa1070e) service to localhost/127.0.0.1:37942 beginning handshake with NN
2020-12-03 07:24:30,635 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-101448600-172.17.0.4-1606980263805 (Datanode Uuid a694dd51-5287-4646-b84f-3cf953f6fc1c) service to localhost/127.0.0.1:37942 beginning handshake with NN
2020-12-03 07:24:30,636 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-101448600-172.17.0.4-1606980263805 (Datanode Uuid 3d6f040b-d45e-46f5-a3a5-f40179b44cc0) service to localhost/127.0.0.1:37942 beginning handshake with NN
2020-12-03 07:24:30,635 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-101448600-172.17.0.4-1606980263805 (Datanode Uuid 67bdfdb6-f4be-4592-925f-42e7b62de913) service to localhost/127.0.0.1:37942 beginning handshake with NN
2020-12-03 07:24:30,635 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-101448600-172.17.0.4-1606980263805 (Datanode Uuid 1c08a3ea-8510-4f3b-8323-c247c1ad19bf) service to localhost/127.0.0.1:37942 beginning handshake with NN
2020-12-03 07:24:30,635 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-101448600-172.17.0.4-1606980263805 (Datanode Uuid 1f53bb69-aae2-4eb5-9dde-35ced37b4811) service to localhost/127.0.0.1:37942 beginning handshake with NN
2020-12-03 07:24:30,636 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-101448600-172.17.0.4-1606980263805 (Datanode Uuid 465a80b3-febd-4847-917b-1dc53950f7b6) service to localhost/127.0.0.1:37942 beginning handshake with NN
2020-12-03 07:24:30,635 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-101448600-172.17.0.4-1606980263805 (Datanode Uuid fc65a25e-b981-4606-bf42-5ab919638725) service to localhost/127.0.0.1:37942 beginning handshake with NN
2020-12-03 07:24:30,651 [IPC Server handler 0 on default port 37942] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:41639, datanodeUuid=8aedd082-415f-407a-9939-da8f8aa1070e, infoPort=41408, infoSecurePort=0, ipcPort=40858, storageInfo=lv=-57;cid=testClusterID;nsid=728208751;c=1606980263805) storage 8aedd082-415f-407a-9939-da8f8aa1070e
2020-12-03 07:24:30,656 [IPC Server handler 0 on default port 37942] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41639
2020-12-03 07:24:30,658 [IPC Server handler 0 on default port 37942] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 8aedd082-415f-407a-9939-da8f8aa1070e (127.0.0.1:41639).
2020-12-03 07:24:30,661 [IPC Server handler 2 on default port 37942] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:43939, datanodeUuid=a694dd51-5287-4646-b84f-3cf953f6fc1c, infoPort=44791, infoSecurePort=0, ipcPort=40240, storageInfo=lv=-57;cid=testClusterID;nsid=728208751;c=1606980263805) storage a694dd51-5287-4646-b84f-3cf953f6fc1c
2020-12-03 07:24:30,662 [IPC Server handler 2 on default port 37942] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:43939
2020-12-03 07:24:30,662 [IPC Server handler 2 on default port 37942] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN a694dd51-5287-4646-b84f-3cf953f6fc1c (127.0.0.1:43939).
2020-12-03 07:24:30,662 [IPC Server handler 1 on default port 37942] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35139, datanodeUuid=7a4b452a-06fd-49f4-826c-a3fc6bc9bddf, infoPort=40382, infoSecurePort=0, ipcPort=38013, storageInfo=lv=-57;cid=testClusterID;nsid=728208751;c=1606980263805) storage 7a4b452a-06fd-49f4-826c-a3fc6bc9bddf
2020-12-03 07:24:30,663 [IPC Server handler 1 on default port 37942] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:35139
2020-12-03 07:24:30,663 [IPC Server handler 1 on default port 37942] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 7a4b452a-06fd-49f4-826c-a3fc6bc9bddf (127.0.0.1:35139).
2020-12-03 07:24:30,663 [IPC Server handler 7 on default port 37942] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:40699, datanodeUuid=67bdfdb6-f4be-4592-925f-42e7b62de913, infoPort=46821, infoSecurePort=0, ipcPort=36341, storageInfo=lv=-57;cid=testClusterID;nsid=728208751;c=1606980263805) storage 67bdfdb6-f4be-4592-925f-42e7b62de913
2020-12-03 07:24:30,663 [IPC Server handler 7 on default port 37942] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:40699
2020-12-03 07:24:30,664 [IPC Server handler 7 on default port 37942] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 67bdfdb6-f4be-4592-925f-42e7b62de913 (127.0.0.1:40699).
2020-12-03 07:24:30,664 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-101448600-172.17.0.4-1606980263805 (Datanode Uuid a694dd51-5287-4646-b84f-3cf953f6fc1c) service to localhost/127.0.0.1:37942 successfully registered with NN
2020-12-03 07:24:30,664 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-101448600-172.17.0.4-1606980263805 (Datanode Uuid 7a4b452a-06fd-49f4-826c-a3fc6bc9bddf) service to localhost/127.0.0.1:37942 successfully registered with NN
2020-12-03 07:24:30,664 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-101448600-172.17.0.4-1606980263805 (Datanode Uuid 8aedd082-415f-407a-9939-da8f8aa1070e) service to localhost/127.0.0.1:37942 successfully registered with NN
2020-12-03 07:24:30,664 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:37942 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-12-03 07:24:30,664 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:37942 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-12-03 07:24:30,664 [IPC Server handler 8 on default port 37942] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:45408, datanodeUuid=465a80b3-febd-4847-917b-1dc53950f7b6, infoPort=46309, infoSecurePort=0, ipcPort=38179, storageInfo=lv=-57;cid=testClusterID;nsid=728208751;c=1606980263805) storage 465a80b3-febd-4847-917b-1dc53950f7b6
2020-12-03 07:24:30,664 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:37942 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-12-03 07:24:30,665 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-101448600-172.17.0.4-1606980263805 (Datanode Uuid 67bdfdb6-f4be-4592-925f-42e7b62de913) service to localhost/127.0.0.1:37942 successfully registered with NN
2020-12-03 07:24:30,665 [IPC Server handler 8 on default port 37942] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:45408
2020-12-03 07:24:30,665 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:37942 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-12-03 07:24:30,665 [IPC Server handler 8 on default port 37942] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 465a80b3-febd-4847-917b-1dc53950f7b6 (127.0.0.1:45408).
2020-12-03 07:24:30,667 [IPC Server handler 6 on default port 37942] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:41151, datanodeUuid=1f53bb69-aae2-4eb5-9dde-35ced37b4811, infoPort=45134, infoSecurePort=0, ipcPort=42122, storageInfo=lv=-57;cid=testClusterID;nsid=728208751;c=1606980263805) storage 1f53bb69-aae2-4eb5-9dde-35ced37b4811
2020-12-03 07:24:30,667 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-101448600-172.17.0.4-1606980263805 (Datanode Uuid 465a80b3-febd-4847-917b-1dc53950f7b6) service to localhost/127.0.0.1:37942 successfully registered with NN
2020-12-03 07:24:30,667 [IPC Server handler 6 on default port 37942] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41151
2020-12-03 07:24:30,667 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:37942 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-12-03 07:24:30,667 [IPC Server handler 6 on default port 37942] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 1f53bb69-aae2-4eb5-9dde-35ced37b4811 (127.0.0.1:41151).
2020-12-03 07:24:30,668 [IPC Server handler 9 on default port 37942] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34859, datanodeUuid=1c08a3ea-8510-4f3b-8323-c247c1ad19bf, infoPort=44221, infoSecurePort=0, ipcPort=44273, storageInfo=lv=-57;cid=testClusterID;nsid=728208751;c=1606980263805) storage 1c08a3ea-8510-4f3b-8323-c247c1ad19bf
2020-12-03 07:24:30,668 [IPC Server handler 9 on default port 37942] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:34859
2020-12-03 07:24:30,668 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-101448600-172.17.0.4-1606980263805 (Datanode Uuid 1f53bb69-aae2-4eb5-9dde-35ced37b4811) service to localhost/127.0.0.1:37942 successfully registered with NN
2020-12-03 07:24:30,669 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:37942 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-12-03 07:24:30,668 [IPC Server handler 9 on default port 37942] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 1c08a3ea-8510-4f3b-8323-c247c1ad19bf (127.0.0.1:34859).
2020-12-03 07:24:30,669 [IPC Server handler 4 on default port 37942] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:46808, datanodeUuid=3d6f040b-d45e-46f5-a3a5-f40179b44cc0, infoPort=36623, infoSecurePort=0, ipcPort=40304, storageInfo=lv=-57;cid=testClusterID;nsid=728208751;c=1606980263805) storage 3d6f040b-d45e-46f5-a3a5-f40179b44cc0
2020-12-03 07:24:30,670 [IPC Server handler 4 on default port 37942] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:46808
2020-12-03 07:24:30,670 [IPC Server handler 4 on default port 37942] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 3d6f040b-d45e-46f5-a3a5-f40179b44cc0 (127.0.0.1:46808).
2020-12-03 07:24:30,671 [IPC Server handler 3 on default port 37942] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:46036, datanodeUuid=fc65a25e-b981-4606-bf42-5ab919638725, infoPort=36214, infoSecurePort=0, ipcPort=36510, storageInfo=lv=-57;cid=testClusterID;nsid=728208751;c=1606980263805) storage fc65a25e-b981-4606-bf42-5ab919638725
2020-12-03 07:24:30,671 [IPC Server handler 3 on default port 37942] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:46036
2020-12-03 07:24:30,671 [IPC Server handler 3 on default port 37942] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN fc65a25e-b981-4606-bf42-5ab919638725 (127.0.0.1:46036).
2020-12-03 07:24:30,671 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-101448600-172.17.0.4-1606980263805 (Datanode Uuid 3d6f040b-d45e-46f5-a3a5-f40179b44cc0) service to localhost/127.0.0.1:37942 successfully registered with NN
2020-12-03 07:24:30,672 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:37942 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-12-03 07:24:30,672 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-101448600-172.17.0.4-1606980263805 (Datanode Uuid fc65a25e-b981-4606-bf42-5ab919638725) service to localhost/127.0.0.1:37942 successfully registered with NN
2020-12-03 07:24:30,672 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:37942 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-12-03 07:24:30,674 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-101448600-172.17.0.4-1606980263805 (Datanode Uuid 1c08a3ea-8510-4f3b-8323-c247c1ad19bf) service to localhost/127.0.0.1:37942 successfully registered with NN
2020-12-03 07:24:30,677 [IPC Server handler 5 on default port 37942] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:30,677 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:37942 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-12-03 07:24:30,686 [Listener at localhost/42122] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2798)) - No heartbeat from DataNode: 127.0.0.1:34859
2020-12-03 07:24:30,686 [Listener at localhost/42122] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:30,700 [IPC Server handler 0 on default port 37942] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-bd675065-6cc8-4703-9ce8-7e1aa5d0f9dc for DN 127.0.0.1:35139
2020-12-03 07:24:30,700 [IPC Server handler 0 on default port 37942] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-0a7b21f4-bc72-417b-a4b0-d8ece257c7ca for DN 127.0.0.1:35139
2020-12-03 07:24:30,702 [IPC Server handler 3 on default port 37942] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-0539376e-ad17-43e8-b692-2105b79e3e6f for DN 127.0.0.1:41151
2020-12-03 07:24:30,703 [IPC Server handler 3 on default port 37942] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-713fdee5-399a-4945-8293-dd270e62d1e4 for DN 127.0.0.1:41151
2020-12-03 07:24:30,704 [IPC Server handler 4 on default port 37942] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-58c3452e-b5a4-4351-a5dd-720979be90e5 for DN 127.0.0.1:46808
2020-12-03 07:24:30,704 [IPC Server handler 4 on default port 37942] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-64790cae-1f9a-427b-8afc-04566b3d97c3 for DN 127.0.0.1:46808
2020-12-03 07:24:30,704 [IPC Server handler 9 on default port 37942] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-fed01141-fff1-42c6-b3e3-2fd935c70283 for DN 127.0.0.1:40699
2020-12-03 07:24:30,704 [IPC Server handler 9 on default port 37942] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d11be790-a115-4b62-b13d-a4d0d7a30b7a for DN 127.0.0.1:40699
2020-12-03 07:24:30,705 [IPC Server handler 6 on default port 37942] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-8c30b030-99db-4142-8d95-5495cf2e3bb5 for DN 127.0.0.1:45408
2020-12-03 07:24:30,705 [IPC Server handler 6 on default port 37942] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-3ce64bf6-e24c-4061-a4ce-b388ab5aa2c5 for DN 127.0.0.1:45408
2020-12-03 07:24:30,705 [IPC Server handler 8 on default port 37942] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-5eaccf1b-8417-47bc-a260-6b7d108d3890 for DN 127.0.0.1:43939
2020-12-03 07:24:30,705 [IPC Server handler 8 on default port 37942] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-05560e71-949b-4174-be33-ae1a2a0941d8 for DN 127.0.0.1:43939
2020-12-03 07:24:30,705 [IPC Server handler 7 on default port 37942] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-64b240c2-d3e0-4acf-93d6-cebd18220651 for DN 127.0.0.1:46036
2020-12-03 07:24:30,706 [IPC Server handler 7 on default port 37942] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-2b1930b4-e95b-4943-b1ab-05b98259886a for DN 127.0.0.1:46036
2020-12-03 07:24:30,706 [IPC Server handler 2 on default port 37942] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-dbecbb28-d168-4eb9-ba31-b857b3014299 for DN 127.0.0.1:41639
2020-12-03 07:24:30,706 [IPC Server handler 2 on default port 37942] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-4a408526-9e3d-400e-9c97-b7f2da3ca414 for DN 127.0.0.1:41639
2020-12-03 07:24:30,706 [IPC Server handler 1 on default port 37942] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c69444b7-75df-4430-81d2-ce7868dd7889 for DN 127.0.0.1:34859
2020-12-03 07:24:30,706 [IPC Server handler 1 on default port 37942] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-59fe4be7-7d46-4bcc-944e-0f4b194e3df4 for DN 127.0.0.1:34859
2020-12-03 07:24:30,739 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x349c2620298419a1: Processing first storage report for DS-0539376e-ad17-43e8-b692-2105b79e3e6f from datanode 1f53bb69-aae2-4eb5-9dde-35ced37b4811
2020-12-03 07:24:30,741 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x349c2620298419a1: from storage DS-0539376e-ad17-43e8-b692-2105b79e3e6f node DatanodeRegistration(127.0.0.1:41151, datanodeUuid=1f53bb69-aae2-4eb5-9dde-35ced37b4811, infoPort=45134, infoSecurePort=0, ipcPort=42122, storageInfo=lv=-57;cid=testClusterID;nsid=728208751;c=1606980263805), blocks: 0, hasStaleStorage: true, processing time: 2 msecs, invalidatedBlocks: 0
2020-12-03 07:24:30,741 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xc0289ce2ffc580a0: Processing first storage report for DS-5eaccf1b-8417-47bc-a260-6b7d108d3890 from datanode a694dd51-5287-4646-b84f-3cf953f6fc1c
2020-12-03 07:24:30,741 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xc0289ce2ffc580a0: from storage DS-5eaccf1b-8417-47bc-a260-6b7d108d3890 node DatanodeRegistration(127.0.0.1:43939, datanodeUuid=a694dd51-5287-4646-b84f-3cf953f6fc1c, infoPort=44791, infoSecurePort=0, ipcPort=40240, storageInfo=lv=-57;cid=testClusterID;nsid=728208751;c=1606980263805), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:30,741 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x9a6eec7cad0ec834: Processing first storage report for DS-bd675065-6cc8-4703-9ce8-7e1aa5d0f9dc from datanode 7a4b452a-06fd-49f4-826c-a3fc6bc9bddf
2020-12-03 07:24:30,742 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x9a6eec7cad0ec834: from storage DS-bd675065-6cc8-4703-9ce8-7e1aa5d0f9dc node DatanodeRegistration(127.0.0.1:35139, datanodeUuid=7a4b452a-06fd-49f4-826c-a3fc6bc9bddf, infoPort=40382, infoSecurePort=0, ipcPort=38013, storageInfo=lv=-57;cid=testClusterID;nsid=728208751;c=1606980263805), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:30,742 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xd89fa387af04d7e8: Processing first storage report for DS-8c30b030-99db-4142-8d95-5495cf2e3bb5 from datanode 465a80b3-febd-4847-917b-1dc53950f7b6
2020-12-03 07:24:30,742 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xd89fa387af04d7e8: from storage DS-8c30b030-99db-4142-8d95-5495cf2e3bb5 node DatanodeRegistration(127.0.0.1:45408, datanodeUuid=465a80b3-febd-4847-917b-1dc53950f7b6, infoPort=46309, infoSecurePort=0, ipcPort=38179, storageInfo=lv=-57;cid=testClusterID;nsid=728208751;c=1606980263805), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:30,742 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xe23325330b2bf8ca: Processing first storage report for DS-fed01141-fff1-42c6-b3e3-2fd935c70283 from datanode 67bdfdb6-f4be-4592-925f-42e7b62de913
2020-12-03 07:24:30,742 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xe23325330b2bf8ca: from storage DS-fed01141-fff1-42c6-b3e3-2fd935c70283 node DatanodeRegistration(127.0.0.1:40699, datanodeUuid=67bdfdb6-f4be-4592-925f-42e7b62de913, infoPort=46821, infoSecurePort=0, ipcPort=36341, storageInfo=lv=-57;cid=testClusterID;nsid=728208751;c=1606980263805), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:30,742 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xc22e7e731e87768d: Processing first storage report for DS-58c3452e-b5a4-4351-a5dd-720979be90e5 from datanode 3d6f040b-d45e-46f5-a3a5-f40179b44cc0
2020-12-03 07:24:30,742 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xc22e7e731e87768d: from storage DS-58c3452e-b5a4-4351-a5dd-720979be90e5 node DatanodeRegistration(127.0.0.1:46808, datanodeUuid=3d6f040b-d45e-46f5-a3a5-f40179b44cc0, infoPort=36623, infoSecurePort=0, ipcPort=40304, storageInfo=lv=-57;cid=testClusterID;nsid=728208751;c=1606980263805), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:30,743 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x349c2620298419a1: Processing first storage report for DS-713fdee5-399a-4945-8293-dd270e62d1e4 from datanode 1f53bb69-aae2-4eb5-9dde-35ced37b4811
2020-12-03 07:24:30,743 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x349c2620298419a1: from storage DS-713fdee5-399a-4945-8293-dd270e62d1e4 node DatanodeRegistration(127.0.0.1:41151, datanodeUuid=1f53bb69-aae2-4eb5-9dde-35ced37b4811, infoPort=45134, infoSecurePort=0, ipcPort=42122, storageInfo=lv=-57;cid=testClusterID;nsid=728208751;c=1606980263805), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:30,743 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xc0289ce2ffc580a0: Processing first storage report for DS-05560e71-949b-4174-be33-ae1a2a0941d8 from datanode a694dd51-5287-4646-b84f-3cf953f6fc1c
2020-12-03 07:24:30,743 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xc0289ce2ffc580a0: from storage DS-05560e71-949b-4174-be33-ae1a2a0941d8 node DatanodeRegistration(127.0.0.1:43939, datanodeUuid=a694dd51-5287-4646-b84f-3cf953f6fc1c, infoPort=44791, infoSecurePort=0, ipcPort=40240, storageInfo=lv=-57;cid=testClusterID;nsid=728208751;c=1606980263805), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:24:30,744 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x9a6eec7cad0ec834: Processing first storage report for DS-0a7b21f4-bc72-417b-a4b0-d8ece257c7ca from datanode 7a4b452a-06fd-49f4-826c-a3fc6bc9bddf
2020-12-03 07:24:30,744 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x9a6eec7cad0ec834: from storage DS-0a7b21f4-bc72-417b-a4b0-d8ece257c7ca node DatanodeRegistration(127.0.0.1:35139, datanodeUuid=7a4b452a-06fd-49f4-826c-a3fc6bc9bddf, infoPort=40382, infoSecurePort=0, ipcPort=38013, storageInfo=lv=-57;cid=testClusterID;nsid=728208751;c=1606980263805), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:30,744 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xd89fa387af04d7e8: Processing first storage report for DS-3ce64bf6-e24c-4061-a4ce-b388ab5aa2c5 from datanode 465a80b3-febd-4847-917b-1dc53950f7b6
2020-12-03 07:24:30,744 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xd89fa387af04d7e8: from storage DS-3ce64bf6-e24c-4061-a4ce-b388ab5aa2c5 node DatanodeRegistration(127.0.0.1:45408, datanodeUuid=465a80b3-febd-4847-917b-1dc53950f7b6, infoPort=46309, infoSecurePort=0, ipcPort=38179, storageInfo=lv=-57;cid=testClusterID;nsid=728208751;c=1606980263805), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:30,744 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xe23325330b2bf8ca: Processing first storage report for DS-d11be790-a115-4b62-b13d-a4d0d7a30b7a from datanode 67bdfdb6-f4be-4592-925f-42e7b62de913
2020-12-03 07:24:30,744 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xe23325330b2bf8ca: from storage DS-d11be790-a115-4b62-b13d-a4d0d7a30b7a node DatanodeRegistration(127.0.0.1:40699, datanodeUuid=67bdfdb6-f4be-4592-925f-42e7b62de913, infoPort=46821, infoSecurePort=0, ipcPort=36341, storageInfo=lv=-57;cid=testClusterID;nsid=728208751;c=1606980263805), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:30,744 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xc22e7e731e87768d: Processing first storage report for DS-64790cae-1f9a-427b-8afc-04566b3d97c3 from datanode 3d6f040b-d45e-46f5-a3a5-f40179b44cc0
2020-12-03 07:24:30,745 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xc22e7e731e87768d: from storage DS-64790cae-1f9a-427b-8afc-04566b3d97c3 node DatanodeRegistration(127.0.0.1:46808, datanodeUuid=3d6f040b-d45e-46f5-a3a5-f40179b44cc0, infoPort=36623, infoSecurePort=0, ipcPort=40304, storageInfo=lv=-57;cid=testClusterID;nsid=728208751;c=1606980263805), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:30,768 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x349c2620298419a1,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 7 msec to generate and 41 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:30,768 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xc0289ce2ffc580a0,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 5 msec to generate and 41 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:30,768 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xe23325330b2bf8ca,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 7 msec to generate and 41 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:30,768 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x9a6eec7cad0ec834,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 41 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:30,768 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xd89fa387af04d7e8,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 7 msec to generate and 41 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:30,768 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xc22e7e731e87768d,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 7 msec to generate and 41 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:30,769 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:30,769 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:30,768 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:30,768 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:30,768 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:30,769 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:30,788 [IPC Server handler 7 on default port 37942] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:30,791 [Listener at localhost/42122] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:24:30,798 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSClient.java:<init>(318)) - Sets dfs.client.block.write.replace-datanode-on-failure.min-replication to 0
2020-12-03 07:24:30,800 [IPC Server handler 2 on default port 37942] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:30,802 [Listener at localhost/42122] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:24:30,803 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSClient.java:<init>(318)) - Sets dfs.client.block.write.replace-datanode-on-failure.min-replication to 0
2020-12-03 07:24:30,900 [IPC Server handler 8 on default port 37942] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=addErasureCodingPolicies	src=[RS-6-3-64k]	dst=null	perm=null	proto=rpc
2020-12-03 07:24:30,916 [IPC Server handler 0 on default port 37942] INFO  namenode.ErasureCodingPolicyManager (ErasureCodingPolicyManager.java:enablePolicy(429)) - Enable the erasure coding policy RS-6-3-64k
2020-12-03 07:24:30,916 [IPC Server handler 0 on default port 37942] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=enableErasureCodingPolicy	src=RS-6-3-64k	dst=null	perm=null	proto=rpc
2020-12-03 07:24:30,920 [IPC Server handler 4 on default port 37942] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=enableErasureCodingPolicy	src=RS-6-3-1024k	dst=null	perm=null	proto=rpc
2020-12-03 07:24:30,922 [IPC Server handler 3 on default port 37942] INFO  namenode.ErasureCodingPolicyManager (ErasureCodingPolicyManager.java:enablePolicy(429)) - Enable the erasure coding policy RS-3-2-1024k
2020-12-03 07:24:30,922 [IPC Server handler 3 on default port 37942] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=enableErasureCodingPolicy	src=RS-3-2-1024k	dst=null	perm=null	proto=rpc
2020-12-03 07:24:30,923 [IPC Server handler 6 on default port 37942] INFO  namenode.ErasureCodingPolicyManager (ErasureCodingPolicyManager.java:enablePolicy(429)) - Enable the erasure coding policy RS-LEGACY-6-3-1024k
2020-12-03 07:24:30,924 [IPC Server handler 6 on default port 37942] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=enableErasureCodingPolicy	src=RS-LEGACY-6-3-1024k	dst=null	perm=null	proto=rpc
2020-12-03 07:24:30,925 [IPC Server handler 9 on default port 37942] INFO  namenode.ErasureCodingPolicyManager (ErasureCodingPolicyManager.java:enablePolicy(429)) - Enable the erasure coding policy XOR-2-1-1024k
2020-12-03 07:24:30,925 [IPC Server handler 9 on default port 37942] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=enableErasureCodingPolicy	src=XOR-2-1-1024k	dst=null	perm=null	proto=rpc
2020-12-03 07:24:30,927 [IPC Server handler 1 on default port 37942] INFO  namenode.ErasureCodingPolicyManager (ErasureCodingPolicyManager.java:enablePolicy(429)) - Enable the erasure coding policy RS-10-4-1024k
2020-12-03 07:24:30,927 [IPC Server handler 1 on default port 37942] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=enableErasureCodingPolicy	src=RS-10-4-1024k	dst=null	perm=null	proto=rpc
2020-12-03 07:24:30,929 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSClient.java:primitiveMkdir(2423)) - /TestDFSStripedOutputStreamWithFailureBase: masked={ masked: rwxr-xr-x, unmasked: rwxrwxrwx }
2020-12-03 07:24:30,940 [IPC Server handler 5 on default port 37942] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/TestDFSStripedOutputStreamWithFailureBase	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:24:30,955 [IPC Server handler 7 on default port 37942] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setErasureCodingPolicy	src=/TestDFSStripedOutputStreamWithFailureBase	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:24:30,959 [Listener at localhost/42122] INFO  hdfs.TestDFSStripedOutputStreamWithFailureBase (TestDFSStripedOutputStreamWithFailureBase.java:runTest(299)) - fullPath=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906]
2020-12-03 07:24:30,960 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSClient.java:create(1216)) - /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906]: masked={ masked: rw-r--r--, unmasked: rw-rw-rw- }
2020-12-03 07:24:30,989 [IPC Server handler 2 on default port 37942] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906]	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:24:31,005 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,006 [Listener at localhost/42122] DEBUG hdfs.DFSOutputStream (DFSStripedOutputStream.java:<init>(293)) - Creating DFSStripedOutputStream for /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906]
2020-12-03 07:24:31,018 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,108 [Listener at localhost/42122] DEBUG hdfs.DFSOutputStream (DFSStripedOutputStream.java:allocateNewBlock(472)) - Excluding DataNodes when allocating new block: []
2020-12-03 07:24:31,113 [Listener at localhost/42122] DEBUG hdfs.DFSOutputStream (DFSStripedOutputStream.java:allocateNewBlock(478)) - Allocating new block group. The previous block group: null
2020-12-03 07:24:31,122 [IPC Server handler 8 on default port 37942] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(427)) - storageTypes={DISK=9}
2020-12-03 07:24:31,128 [IPC Server handler 8 on default port 37942] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_-9223372036854775792_1001, replicas=127.0.0.1:41151, 127.0.0.1:45408, 127.0.0.1:34859, 127.0.0.1:43939, 127.0.0.1:35139, 127.0.0.1:46808, 127.0.0.1:41639, 127.0.0.1:46036, 127.0.0.1:40699 for /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906]
2020-12-03 07:24:31,148 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=0, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], packetSize=65016, chunksPerPacket=126, bytesCurBlock=0, DFSStripedOutputStream:#0: block==null
2020-12-03 07:24:31,149 [Listener at localhost/42122] INFO  hdfs.TestDFSStripedOutputStreamWithFailureBase (TestDFSStripedOutputStreamWithFailureBase.java:getGenerationStamp(376)) - getGenerationStamp returns 1001
2020-12-03 07:24:31,182 [Listener at localhost/42122] DEBUG hdfs.DFSOutputStream (DFSStripedOutputStream.java:enqueueCurrentPacketFull(576)) - enqueue full packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 64512, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], bytesCurBlock=64512, blockSize=262144, appendChunk=false, #0: block==null
2020-12-03 07:24:31,183 [Listener at localhost/42122] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 64512, #0: block==null
2020-12-03 07:24:31,183 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,187 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=1, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], packetSize=65016, chunksPerPacket=126, bytesCurBlock=64512, DFSStripedOutputStream:#0: block==null
2020-12-03 07:24:31,188 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,188 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=0, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], packetSize=65016, chunksPerPacket=126, bytesCurBlock=0, DFSStripedOutputStream:#1: block==null
2020-12-03 07:24:31,192 [Thread-351] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, #0: block==null
2020-12-03 07:24:31,192 [Thread-351] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: #0: block==null
2020-12-03 07:24:31,193 [Thread-351] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:41151,DS-0539376e-ad17-43e8-b692-2105b79e3e6f,DISK]], #0: blk_-9223372036854775792_1001
2020-12-03 07:24:31,193 [Thread-351] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:41151
2020-12-03 07:24:31,197 [Thread-351] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-12-03 07:24:31,197 [Thread-351] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:31,203 [Listener at localhost/42122] DEBUG hdfs.DFSOutputStream (DFSStripedOutputStream.java:enqueueCurrentPacketFull(576)) - enqueue full packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 64512, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], bytesCurBlock=64512, blockSize=262144, appendChunk=false, #1: block==null
2020-12-03 07:24:31,203 [Listener at localhost/42122] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 64512, #1: block==null
2020-12-03 07:24:31,203 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,206 [Thread-352] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, #1: block==null
2020-12-03 07:24:31,206 [Thread-352] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: #1: block==null
2020-12-03 07:24:31,206 [Thread-352] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:45408,DS-8c30b030-99db-4142-8d95-5495cf2e3bb5,DISK]], #1: blk_-9223372036854775791_1001
2020-12-03 07:24:31,207 [Thread-352] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:45408
2020-12-03 07:24:31,207 [Thread-352] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-12-03 07:24:31,206 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=1, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], packetSize=65016, chunksPerPacket=126, bytesCurBlock=64512, DFSStripedOutputStream:#1: block==null
2020-12-03 07:24:31,207 [Thread-352] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:31,208 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,209 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=0, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], packetSize=65016, chunksPerPacket=126, bytesCurBlock=0, DFSStripedOutputStream:#2: block==null
2020-12-03 07:24:31,217 [Listener at localhost/42122] DEBUG hdfs.DFSOutputStream (DFSStripedOutputStream.java:enqueueCurrentPacketFull(576)) - enqueue full packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 64512, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], bytesCurBlock=64512, blockSize=262144, appendChunk=false, #2: block==null
2020-12-03 07:24:31,217 [Listener at localhost/42122] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 64512, #2: block==null
2020-12-03 07:24:31,217 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,218 [Thread-353] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, #2: block==null
2020-12-03 07:24:31,218 [Thread-353] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: #2: block==null
2020-12-03 07:24:31,218 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=1, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], packetSize=65016, chunksPerPacket=126, bytesCurBlock=64512, DFSStripedOutputStream:#2: block==null
2020-12-03 07:24:31,218 [Thread-353] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:34859,DS-c69444b7-75df-4430-81d2-ce7868dd7889,DISK]], #2: blk_-9223372036854775790_1001
2020-12-03 07:24:31,219 [Thread-353] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:34859
2020-12-03 07:24:31,218 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,219 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=0, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], packetSize=65016, chunksPerPacket=126, bytesCurBlock=0, DFSStripedOutputStream:#3: block==null
2020-12-03 07:24:31,219 [Thread-353] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-12-03 07:24:31,221 [Thread-353] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:31,225 [Listener at localhost/42122] INFO  hdfs.TestDFSStripedOutputStreamWithFailureBase (TestDFSStripedOutputStreamWithFailureBase.java:getGenerationStamp(376)) - getGenerationStamp returns 1001
2020-12-03 07:24:31,225 [Listener at localhost/42122] INFO  hdfs.TestDFSStripedOutputStreamWithFailureBase (TestDFSStripedOutputStreamWithFailureBase.java:killDatanode(410)) - killDatanode 4: DatanodeInfoWithStorage[127.0.0.1:35139,DS-bd675065-6cc8-4703-9ce8-7e1aa5d0f9dc,DISK], pos=218454
2020-12-03 07:24:31,225 [Listener at localhost/42122] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopDataNode(2331)) - MiniDFSCluster Stopping DataNode 127.0.0.1:35139 from a total of 9 datanodes.
2020-12-03 07:24:31,226 [Listener at localhost/42122] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:24:31,226 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@433ffad1] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:24:31,228 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-bd675065-6cc8-4703-9ce8-7e1aa5d0f9dc) exiting.
2020-12-03 07:24:31,228 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-0a7b21f4-bc72-417b-a4b0-d8ece257c7ca) exiting.
2020-12-03 07:24:31,281 [Listener at localhost/42122] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@2024293c{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:24:31,286 [Listener at localhost/42122] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7048f722{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:31,287 [Listener at localhost/42122] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@30c0ccff{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:31,287 [Listener at localhost/42122] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4593ff34{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:31,290 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:39054 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775792_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775792_1001 src: /127.0.0.1:39054 dest: /127.0.0.1:41151
2020-12-03 07:24:31,290 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:41860 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775791_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775791_1001 src: /127.0.0.1:41860 dest: /127.0.0.1:45408
2020-12-03 07:24:31,290 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:45948 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775790_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775790_1001 src: /127.0.0.1:45948 dest: /127.0.0.1:34859
2020-12-03 07:24:31,293 [Listener at localhost/42122] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 38013
2020-12-03 07:24:31,299 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:31,300 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:31,303 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:24:31,303 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-101448600-172.17.0.4-1606980263805 (Datanode Uuid 7a4b452a-06fd-49f4-826c-a3fc6bc9bddf) service to localhost/127.0.0.1:37942
2020-12-03 07:24:31,303 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-101448600-172.17.0.4-1606980263805 (Datanode Uuid 7a4b452a-06fd-49f4-826c-a3fc6bc9bddf)
2020-12-03 07:24:31,303 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:31,304 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-101448600-172.17.0.4-1606980263805] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:31,304 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-101448600-172.17.0.4-1606980263805] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:31,309 [Listener at localhost/42122] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:24:31,309 [Listener at localhost/42122] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:24:31,311 [Listener at localhost/42122] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:24:31,311 [Listener at localhost/42122] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:24:31,318 [Listener at localhost/42122] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:24:31,323 [Listener at localhost/42122] DEBUG hdfs.DFSOutputStream (DFSStripedOutputStream.java:enqueueCurrentPacketFull(576)) - enqueue full packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 64512, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], bytesCurBlock=64512, blockSize=262144, appendChunk=false, #3: block==null
2020-12-03 07:24:31,323 [Listener at localhost/42122] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 64512, #3: block==null
2020-12-03 07:24:31,323 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,324 [Thread-354] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, #3: block==null
2020-12-03 07:24:31,324 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=1, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], packetSize=65016, chunksPerPacket=126, bytesCurBlock=64512, DFSStripedOutputStream:#3: block==null
2020-12-03 07:24:31,324 [Thread-354] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: #3: block==null
2020-12-03 07:24:31,324 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,324 [Thread-354] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:43939,DS-5eaccf1b-8417-47bc-a260-6b7d108d3890,DISK]], #3: blk_-9223372036854775789_1001
2020-12-03 07:24:31,324 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=0, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], packetSize=65016, chunksPerPacket=126, bytesCurBlock=0, DFSStripedOutputStream:#4: block==null
2020-12-03 07:24:31,324 [Thread-354] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:43939
2020-12-03 07:24:31,325 [Thread-354] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-12-03 07:24:31,325 [Thread-354] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:31,330 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:49342 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775789_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775789_1001 src: /127.0.0.1:49342 dest: /127.0.0.1:43939
2020-12-03 07:24:31,333 [Listener at localhost/42122] DEBUG hdfs.DFSOutputStream (DFSStripedOutputStream.java:enqueueCurrentPacketFull(576)) - enqueue full packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 64512, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], bytesCurBlock=64512, blockSize=262144, appendChunk=false, #4: block==null
2020-12-03 07:24:31,333 [Listener at localhost/42122] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 64512, #4: block==null
2020-12-03 07:24:31,333 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,334 [Thread-355] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, #4: block==null
2020-12-03 07:24:31,334 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=1, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], packetSize=65016, chunksPerPacket=126, bytesCurBlock=64512, DFSStripedOutputStream:#4: block==null
2020-12-03 07:24:31,334 [Thread-355] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: #4: block==null
2020-12-03 07:24:31,335 [Thread-355] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:35139,DS-bd675065-6cc8-4703-9ce8-7e1aa5d0f9dc,DISK]], #4: blk_-9223372036854775788_1001
2020-12-03 07:24:31,335 [Thread-355] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:35139
2020-12-03 07:24:31,335 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,335 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=0, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], packetSize=65016, chunksPerPacket=126, bytesCurBlock=0, DFSStripedOutputStream:#5: block==null
2020-12-03 07:24:31,336 [Thread-355] INFO  hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1790)) - Exception in createBlockOutputStream #4: blk_-9223372036854775788_1001
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:533)
	at org.apache.hadoop.hdfs.DataStreamer.createSocketForPipeline(DataStreamer.java:253)
	at org.apache.hadoop.hdfs.DataStreamer.createBlockOutputStream(DataStreamer.java:1725)
	at org.apache.hadoop.hdfs.StripedDataStreamer.nextBlockOutputStream(StripedDataStreamer.java:106)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:716)
	at org.apache.hadoop.hdfs.StripedDataStreamer.run(StripedDataStreamer.java:46)
2020-12-03 07:24:31,341 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775790_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:34859,DS-c69444b7-75df-4430-81d2-ce7868dd7889,DISK]] storageTypes [DISK] storageIDs [DS-c69444b7-75df-4430-81d2-ce7868dd7889]
2020-12-03 07:24:31,340 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775791_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:45408,DS-8c30b030-99db-4142-8d95-5495cf2e3bb5,DISK]] storageTypes [DISK] storageIDs [DS-8c30b030-99db-4142-8d95-5495cf2e3bb5]
2020-12-03 07:24:31,339 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775792_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:41151,DS-0539376e-ad17-43e8-b692-2105b79e3e6f,DISK]] storageTypes [DISK] storageIDs [DS-0539376e-ad17-43e8-b692-2105b79e3e6f]
2020-12-03 07:24:31,339 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775789_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:43939,DS-5eaccf1b-8417-47bc-a260-6b7d108d3890,DISK]] storageTypes [DISK] storageIDs [DS-5eaccf1b-8417-47bc-a260-6b7d108d3890]
2020-12-03 07:24:31,342 [Thread-355] WARN  hdfs.DataStreamer (StripedDataStreamer.java:nextBlockOutputStream(112)) - Excluding datanode DatanodeInfoWithStorage[127.0.0.1:35139,DS-bd675065-6cc8-4703-9ce8-7e1aa5d0f9dc,DISK]
2020-12-03 07:24:31,345 [Listener at localhost/42122] DEBUG hdfs.DFSOutputStream (DFSStripedOutputStream.java:enqueueCurrentPacketFull(576)) - enqueue full packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 64512, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], bytesCurBlock=64512, blockSize=262144, appendChunk=false, #5: block==null
2020-12-03 07:24:31,345 [Thread-355] WARN  hdfs.DataStreamer (DataStreamer.java:run(826)) - DataStreamer Exception
java.io.IOException: Unable to create new block.#4: failed, block==null
	at org.apache.hadoop.hdfs.StripedDataStreamer.nextBlockOutputStream(StripedDataStreamer.java:114)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:716)
	at org.apache.hadoop.hdfs.StripedDataStreamer.run(StripedDataStreamer.java:46)
2020-12-03 07:24:31,345 [Listener at localhost/42122] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 64512, #5: block==null
2020-12-03 07:24:31,346 [Thread-355] DEBUG hdfs.DataStreamer (DataStreamer.java:processDatanodeOrExternalError(1229)) - start process datanode/external error, #4: failed, block==null
2020-12-03 07:24:31,347 [Thread-356] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, #5: block==null
2020-12-03 07:24:31,346 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,347 [Thread-356] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: #5: block==null
2020-12-03 07:24:31,347 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=1, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], packetSize=65016, chunksPerPacket=126, bytesCurBlock=64512, DFSStripedOutputStream:#5: block==null
2020-12-03 07:24:31,349 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775791_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - #1: blk_-9223372036854775791_1001 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 64512
2020-12-03 07:24:31,348 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775792_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - #0: blk_-9223372036854775792_1001 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 64512
2020-12-03 07:24:31,348 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775790_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - #2: blk_-9223372036854775790_1001 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 64512
2020-12-03 07:24:31,348 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775789_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - #3: blk_-9223372036854775789_1001 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 64512
2020-12-03 07:24:31,351 [Thread-355] WARN  hdfs.DataStreamer (DataStreamer.java:setupPipelineForAppendOrRecovery(1476)) - Could not get block locations. Source file "/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906]" - Aborting...#4: failed, block==null
2020-12-03 07:24:31,349 [Thread-356] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:46808,DS-58c3452e-b5a4-4351-a5dd-720979be90e5,DISK]], #5: blk_-9223372036854775787_1001
2020-12-03 07:24:31,352 [Thread-356] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:46808
2020-12-03 07:24:31,353 [Thread-356] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-12-03 07:24:31,353 [Thread-356] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:31,355 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,355 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:38240 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775787_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775787_1001 src: /127.0.0.1:38240 dest: /127.0.0.1:46808
2020-12-03 07:24:31,362 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775787_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:46808,DS-58c3452e-b5a4-4351-a5dd-720979be90e5,DISK]] storageTypes [DISK] storageIDs [DS-58c3452e-b5a4-4351-a5dd-720979be90e5]
2020-12-03 07:24:31,363 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775787_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - #5: blk_-9223372036854775787_1001 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 64512
2020-12-03 07:24:31,365 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=0, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], packetSize=65016, chunksPerPacket=126, bytesCurBlock=0, DFSStripedOutputStream:#6: block==null
2020-12-03 07:24:31,374 [Listener at localhost/42122] DEBUG hdfs.DFSOutputStream (DFSStripedOutputStream.java:enqueueCurrentPacketFull(576)) - enqueue full packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 64512, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], bytesCurBlock=64512, blockSize=262144, appendChunk=false, #6: block==null
2020-12-03 07:24:31,375 [Listener at localhost/42122] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 64512, #6: block==null
2020-12-03 07:24:31,376 [Thread-357] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, #6: block==null
2020-12-03 07:24:31,376 [Thread-357] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: #6: block==null
2020-12-03 07:24:31,376 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,376 [Thread-357] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:41639,DS-dbecbb28-d168-4eb9-ba31-b857b3014299,DISK]], #6: blk_-9223372036854775786_1001
2020-12-03 07:24:31,377 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=1, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], packetSize=65016, chunksPerPacket=126, bytesCurBlock=64512, DFSStripedOutputStream:#6: blk_-9223372036854775786_1001
2020-12-03 07:24:31,377 [Thread-357] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:41639
2020-12-03 07:24:31,378 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,379 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=0, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], packetSize=65016, chunksPerPacket=126, bytesCurBlock=0, DFSStripedOutputStream:#7: block==null
2020-12-03 07:24:31,381 [Thread-357] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-12-03 07:24:31,381 [Thread-357] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:31,383 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:34412 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775786_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775786_1001 src: /127.0.0.1:34412 dest: /127.0.0.1:41639
2020-12-03 07:24:31,383 [Listener at localhost/42122] DEBUG hdfs.DFSOutputStream (DFSStripedOutputStream.java:enqueueCurrentPacketFull(576)) - enqueue full packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 64512, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], bytesCurBlock=64512, blockSize=262144, appendChunk=false, #7: block==null
2020-12-03 07:24:31,383 [Listener at localhost/42122] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 64512, #7: block==null
2020-12-03 07:24:31,383 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,384 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=1, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], packetSize=65016, chunksPerPacket=126, bytesCurBlock=64512, DFSStripedOutputStream:#7: block==null
2020-12-03 07:24:31,384 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,384 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=0, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], packetSize=65016, chunksPerPacket=126, bytesCurBlock=0, DFSStripedOutputStream:#8: block==null
2020-12-03 07:24:31,385 [ResponseProcessor for block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775792_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2020-12-03 07:24:31,385 [ResponseProcessor for block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775787_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2020-12-03 07:24:31,385 [ResponseProcessor for block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775790_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2020-12-03 07:24:31,385 [ResponseProcessor for block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775791_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2020-12-03 07:24:31,385 [ResponseProcessor for block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775789_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2020-12-03 07:24:31,385 [Listener at localhost/42122] DEBUG hdfs.DFSOutputStream (DFSStripedOutputStream.java:enqueueCurrentPacketFull(576)) - enqueue full packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 64512, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], bytesCurBlock=64512, blockSize=262144, appendChunk=false, #8: block==null
2020-12-03 07:24:31,386 [Listener at localhost/42122] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 64512, #8: block==null
2020-12-03 07:24:31,386 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,386 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=1, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], packetSize=65016, chunksPerPacket=126, bytesCurBlock=64512, DFSStripedOutputStream:#8: block==null
2020-12-03 07:24:31,387 [Listener at localhost/42122] DEBUG hdfs.DFSOutputStream (DFSStripedOutputStream.java:checkStreamers(390)) - checkStreamers: [#0: blk_-9223372036854775792_1001, #1: blk_-9223372036854775791_1001, #2: blk_-9223372036854775790_1001, #3: blk_-9223372036854775789_1001, #4: failed, block==null, #5: blk_-9223372036854775787_1001, #6: blk_-9223372036854775786_1001, #7: block==null, #8: block==null]
2020-12-03 07:24:31,387 [Listener at localhost/42122] DEBUG hdfs.DFSOutputStream (DFSStripedOutputStream.java:checkStreamers(391)) - healthy streamer count=8
2020-12-03 07:24:31,387 [Listener at localhost/42122] DEBUG hdfs.DFSOutputStream (DFSStripedOutputStream.java:checkStreamers(392)) - original failed streamers: []
2020-12-03 07:24:31,387 [Listener at localhost/42122] DEBUG hdfs.DFSOutputStream (DFSStripedOutputStream.java:checkStreamers(393)) - newly failed streamers: [#4: failed, block==null]
2020-12-03 07:24:31,389 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,389 [Thread-358] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, #7: block==null
2020-12-03 07:24:31,390 [Thread-358] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: #7: block==null
2020-12-03 07:24:31,391 [Thread-358] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:46036,DS-2b1930b4-e95b-4943-b1ab-05b98259886a,DISK]], #7: blk_-9223372036854775785_1001
2020-12-03 07:24:31,391 [Listener at localhost/42122] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 64512 lastPacketInBlock: false lastByteOffsetInBlock: 65536, #0: blk_-9223372036854775792_1001
2020-12-03 07:24:31,391 [Thread-359] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, #8: block==null
2020-12-03 07:24:31,391 [Thread-358] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:46036
2020-12-03 07:24:31,399 [Thread-359] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: #8: block==null
2020-12-03 07:24:31,399 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775792_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, #0: blk_-9223372036854775792_1001
2020-12-03 07:24:31,400 [Thread-359] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:40699,DS-fed01141-fff1-42c6-b3e3-2fd935c70283,DISK]], #8: blk_-9223372036854775784_1001
2020-12-03 07:24:31,401 [Thread-359] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:40699
2020-12-03 07:24:31,400 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775786_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:41639,DS-dbecbb28-d168-4eb9-ba31-b857b3014299,DISK]] storageTypes [DISK] storageIDs [DS-dbecbb28-d168-4eb9-ba31-b857b3014299]
2020-12-03 07:24:31,402 [Thread-359] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-12-03 07:24:31,401 [Thread-358] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-12-03 07:24:31,403 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,401 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775792_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - #0: blk_-9223372036854775792_1001 sending packet seqno: 1 offsetInBlock: 64512 lastPacketInBlock: false lastByteOffsetInBlock: 65536
2020-12-03 07:24:31,404 [Listener at localhost/42122] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 64512 lastPacketInBlock: false lastByteOffsetInBlock: 65536, #1: blk_-9223372036854775791_1001
2020-12-03 07:24:31,404 [pool-119-thread-1] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - #0: blk_-9223372036854775792_1001 waiting for ack for: 1
2020-12-03 07:24:31,404 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775786_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - #6: blk_-9223372036854775786_1001 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 64512
2020-12-03 07:24:31,405 [pool-119-thread-2] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - #1: blk_-9223372036854775791_1001 waiting for ack for: 1
2020-12-03 07:24:31,403 [Thread-358] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:31,403 [Thread-359] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:31,404 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,405 [ResponseProcessor for block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775792_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2020-12-03 07:24:31,404 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775791_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, #1: blk_-9223372036854775791_1001
2020-12-03 07:24:31,405 [Listener at localhost/42122] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 64512 lastPacketInBlock: false lastByteOffsetInBlock: 65536, #2: blk_-9223372036854775790_1001
2020-12-03 07:24:31,408 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775791_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - #1: blk_-9223372036854775791_1001 sending packet seqno: 1 offsetInBlock: 64512 lastPacketInBlock: false lastByteOffsetInBlock: 65536
2020-12-03 07:24:31,408 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775790_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, #2: blk_-9223372036854775790_1001
2020-12-03 07:24:31,408 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,410 [Listener at localhost/42122] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 64512 lastPacketInBlock: false lastByteOffsetInBlock: 65536, #3: blk_-9223372036854775789_1001
2020-12-03 07:24:31,410 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775789_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, #3: blk_-9223372036854775789_1001
2020-12-03 07:24:31,411 [pool-119-thread-3] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - #2: blk_-9223372036854775790_1001 waiting for ack for: 1
2020-12-03 07:24:31,411 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775790_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - #2: blk_-9223372036854775790_1001 sending packet seqno: 1 offsetInBlock: 64512 lastPacketInBlock: false lastByteOffsetInBlock: 65536
2020-12-03 07:24:31,411 [ResponseProcessor for block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775786_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2020-12-03 07:24:31,411 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775789_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - #3: blk_-9223372036854775789_1001 sending packet seqno: 1 offsetInBlock: 64512 lastPacketInBlock: false lastByteOffsetInBlock: 65536
2020-12-03 07:24:31,413 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:50912 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775785_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775785_1001 src: /127.0.0.1:50912 dest: /127.0.0.1:46036
2020-12-03 07:24:31,413 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:59888 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775784_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775784_1001 src: /127.0.0.1:59888 dest: /127.0.0.1:40699
2020-12-03 07:24:31,413 [ResponseProcessor for block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775789_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2020-12-03 07:24:31,415 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,415 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,415 [ResponseProcessor for block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775790_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2020-12-03 07:24:31,415 [Listener at localhost/42122] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 64512 lastPacketInBlock: false lastByteOffsetInBlock: 65536, #5: blk_-9223372036854775787_1001
2020-12-03 07:24:31,417 [pool-119-thread-4] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - #3: blk_-9223372036854775789_1001 waiting for ack for: 1
2020-12-03 07:24:31,417 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775785_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:46036,DS-2b1930b4-e95b-4943-b1ab-05b98259886a,DISK]] storageTypes [DISK] storageIDs [DS-2b1930b4-e95b-4943-b1ab-05b98259886a]
2020-12-03 07:24:31,424 [pool-119-thread-5] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - #5: blk_-9223372036854775787_1001 waiting for ack for: 1
2020-12-03 07:24:31,424 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,424 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775787_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, #5: blk_-9223372036854775787_1001
2020-12-03 07:24:31,426 [Listener at localhost/42122] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 64512 lastPacketInBlock: false lastByteOffsetInBlock: 65536, #6: blk_-9223372036854775786_1001
2020-12-03 07:24:31,426 [ResponseProcessor for block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775791_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2020-12-03 07:24:31,426 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775786_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, #6: blk_-9223372036854775786_1001
2020-12-03 07:24:31,428 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775785_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - #7: blk_-9223372036854775785_1001 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 64512
2020-12-03 07:24:31,428 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775784_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:40699,DS-fed01141-fff1-42c6-b3e3-2fd935c70283,DISK]] storageTypes [DISK] storageIDs [DS-fed01141-fff1-42c6-b3e3-2fd935c70283]
2020-12-03 07:24:31,428 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,428 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775786_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - #6: blk_-9223372036854775786_1001 sending packet seqno: 1 offsetInBlock: 64512 lastPacketInBlock: false lastByteOffsetInBlock: 65536
2020-12-03 07:24:31,428 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775787_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - #5: blk_-9223372036854775787_1001 sending packet seqno: 1 offsetInBlock: 64512 lastPacketInBlock: false lastByteOffsetInBlock: 65536
2020-12-03 07:24:31,430 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775784_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - #8: blk_-9223372036854775784_1001 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 64512
2020-12-03 07:24:31,430 [Listener at localhost/42122] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 64512 lastPacketInBlock: false lastByteOffsetInBlock: 65536, #7: blk_-9223372036854775785_1001
2020-12-03 07:24:31,428 [pool-119-thread-6] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - #6: blk_-9223372036854775786_1001 waiting for ack for: 1
2020-12-03 07:24:31,431 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775785_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, #7: blk_-9223372036854775785_1001
2020-12-03 07:24:31,433 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,435 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775785_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - #7: blk_-9223372036854775785_1001 sending packet seqno: 1 offsetInBlock: 64512 lastPacketInBlock: false lastByteOffsetInBlock: 65536
2020-12-03 07:24:31,437 [Listener at localhost/42122] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 64512 lastPacketInBlock: false lastByteOffsetInBlock: 65536, #8: blk_-9223372036854775784_1001
2020-12-03 07:24:31,435 [pool-119-thread-7] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - #7: blk_-9223372036854775785_1001 waiting for ack for: 1
2020-12-03 07:24:31,439 [ResponseProcessor for block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775785_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2020-12-03 07:24:31,439 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775784_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, #8: blk_-9223372036854775784_1001
2020-12-03 07:24:31,440 [pool-119-thread-8] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - #8: blk_-9223372036854775784_1001 waiting for ack for: 1
2020-12-03 07:24:31,437 [ResponseProcessor for block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775787_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2020-12-03 07:24:31,436 [ResponseProcessor for block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775786_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2020-12-03 07:24:31,441 [ResponseProcessor for block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775785_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2020-12-03 07:24:31,441 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775784_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - #8: blk_-9223372036854775784_1001 sending packet seqno: 1 offsetInBlock: 64512 lastPacketInBlock: false lastByteOffsetInBlock: 65536
2020-12-03 07:24:31,439 [ResponseProcessor for block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775784_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2020-12-03 07:24:31,439 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,446 [ResponseProcessor for block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775784_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2020-12-03 07:24:31,446 [Listener at localhost/42122] DEBUG hdfs.DFSOutputStream (DFSStripedOutputStream.java:checkStreamers(390)) - checkStreamers: [#0: blk_-9223372036854775792_1001, #1: blk_-9223372036854775791_1001, #2: blk_-9223372036854775790_1001, #3: blk_-9223372036854775789_1001, #4: failed, block==null, #5: blk_-9223372036854775787_1001, #6: blk_-9223372036854775786_1001, #7: blk_-9223372036854775785_1001, #8: blk_-9223372036854775784_1001]
2020-12-03 07:24:31,446 [Listener at localhost/42122] DEBUG hdfs.DFSOutputStream (DFSStripedOutputStream.java:checkStreamers(391)) - healthy streamer count=8
2020-12-03 07:24:31,447 [Listener at localhost/42122] DEBUG hdfs.DFSOutputStream (DFSStripedOutputStream.java:checkStreamers(392)) - original failed streamers: []
2020-12-03 07:24:31,447 [Listener at localhost/42122] DEBUG hdfs.DFSOutputStream (DFSStripedOutputStream.java:checkStreamers(393)) - newly failed streamers: [#4: failed, block==null]
2020-12-03 07:24:31,448 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775789_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:processDatanodeOrExternalError(1229)) - start process datanode/external error, #3: blk_-9223372036854775789_1001
2020-12-03 07:24:31,448 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775784_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:processDatanodeOrExternalError(1229)) - start process datanode/external error, #8: blk_-9223372036854775784_1001
2020-12-03 07:24:31,448 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775786_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:processDatanodeOrExternalError(1229)) - start process datanode/external error, #6: blk_-9223372036854775786_1001
2020-12-03 07:24:31,448 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775787_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:processDatanodeOrExternalError(1229)) - start process datanode/external error, #5: blk_-9223372036854775787_1001
2020-12-03 07:24:31,448 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775785_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:processDatanodeOrExternalError(1229)) - start process datanode/external error, #7: blk_-9223372036854775785_1001
2020-12-03 07:24:31,448 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775792_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:processDatanodeOrExternalError(1229)) - start process datanode/external error, #0: blk_-9223372036854775792_1001
2020-12-03 07:24:31,448 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:34412 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775786_1001]] INFO  datanode.DataNode (BlockReceiver.java:receiveBlock(1010)) - Exception for BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775786_1001
java.io.IOException: Premature EOF from inputStream
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:212)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:908)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:31,448 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:49342 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775789_1001]] INFO  datanode.DataNode (BlockReceiver.java:receiveBlock(1010)) - Exception for BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775789_1001
java.io.IOException: Premature EOF from inputStream
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:212)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:908)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:31,448 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:59888 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775784_1001]] INFO  datanode.DataNode (BlockReceiver.java:receiveBlock(1010)) - Exception for BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775784_1001
java.io.IOException: Premature EOF from inputStream
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:212)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:908)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:31,448 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775790_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:processDatanodeOrExternalError(1229)) - start process datanode/external error, #2: blk_-9223372036854775790_1001
2020-12-03 07:24:31,450 [PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775784_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1470)) - PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775784_1001, type=LAST_IN_PIPELINE: Thread is interrupted.
2020-12-03 07:24:31,449 [PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775789_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1470)) - PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775789_1001, type=LAST_IN_PIPELINE: Thread is interrupted.
2020-12-03 07:24:31,453 [PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775789_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775789_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:31,449 [PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775786_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1470)) - PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775786_1001, type=LAST_IN_PIPELINE: Thread is interrupted.
2020-12-03 07:24:31,453 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:49342 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775789_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(939)) - opWriteBlock BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775789_1001 received exception java.io.IOException: Premature EOF from inputStream
2020-12-03 07:24:31,448 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:39054 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775792_1001]] INFO  datanode.DataNode (BlockReceiver.java:receiveBlock(1010)) - Exception for BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775792_1001
java.io.IOException: Premature EOF from inputStream
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:212)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:908)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:31,448 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:50912 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775785_1001]] INFO  datanode.DataNode (BlockReceiver.java:receiveBlock(1010)) - Exception for BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775785_1001
java.io.IOException: Premature EOF from inputStream
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:212)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:908)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:31,448 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:38240 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775787_1001]] INFO  datanode.DataNode (BlockReceiver.java:receiveBlock(1010)) - Exception for BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775787_1001
java.io.IOException: Premature EOF from inputStream
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:212)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:908)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:31,455 [PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775785_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1470)) - PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775785_1001, type=LAST_IN_PIPELINE: Thread is interrupted.
2020-12-03 07:24:31,455 [PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775785_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775785_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:31,454 [PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775792_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1470)) - PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775792_1001, type=LAST_IN_PIPELINE: Thread is interrupted.
2020-12-03 07:24:31,453 [PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775786_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775786_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:31,451 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:45948 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775790_1001]] INFO  datanode.DataNode (BlockReceiver.java:receiveBlock(1010)) - Exception for BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775790_1001
java.io.IOException: Premature EOF from inputStream
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:212)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:908)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:31,451 [PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775784_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775784_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:31,451 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775791_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:processDatanodeOrExternalError(1229)) - start process datanode/external error, #1: blk_-9223372036854775791_1001
2020-12-03 07:24:31,456 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:59888 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775784_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(939)) - opWriteBlock BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775784_1001 received exception java.io.IOException: Premature EOF from inputStream
2020-12-03 07:24:31,456 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:41860 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775791_1001]] INFO  datanode.DataNode (BlockReceiver.java:receiveBlock(1010)) - Exception for BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775791_1001
java.io.IOException: Premature EOF from inputStream
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:212)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:908)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:31,456 [PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775790_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1470)) - PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775790_1001, type=LAST_IN_PIPELINE: Thread is interrupted.
2020-12-03 07:24:31,457 [PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775790_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775790_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:31,461 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:49342 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775789_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:43939:DataXceiver error processing WRITE_BLOCK operation  src: /127.0.0.1:49342 dst: /127.0.0.1:43939
java.io.IOException: Premature EOF from inputStream
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:212)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:908)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:31,456 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:34412 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775786_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(939)) - opWriteBlock BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775786_1001 received exception java.io.IOException: Premature EOF from inputStream
2020-12-03 07:24:31,455 [PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775792_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775792_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:31,455 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:50912 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775785_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(939)) - opWriteBlock BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775785_1001 received exception java.io.IOException: Premature EOF from inputStream
2020-12-03 07:24:31,455 [PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775787_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1470)) - PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775787_1001, type=LAST_IN_PIPELINE: Thread is interrupted.
2020-12-03 07:24:31,462 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:34412 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775786_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:41639:DataXceiver error processing WRITE_BLOCK operation  src: /127.0.0.1:34412 dst: /127.0.0.1:41639
java.io.IOException: Premature EOF from inputStream
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:212)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:908)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:31,462 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:39054 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775792_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(939)) - opWriteBlock BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775792_1001 received exception java.io.IOException: Premature EOF from inputStream
2020-12-03 07:24:31,461 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:45948 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775790_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(939)) - opWriteBlock BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775790_1001 received exception java.io.IOException: Premature EOF from inputStream
2020-12-03 07:24:31,461 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:59888 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775784_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:40699:DataXceiver error processing WRITE_BLOCK operation  src: /127.0.0.1:59888 dst: /127.0.0.1:40699
java.io.IOException: Premature EOF from inputStream
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:212)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:908)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:31,457 [PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775791_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1470)) - PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775791_1001, type=LAST_IN_PIPELINE: Thread is interrupted.
2020-12-03 07:24:31,463 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:45948 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775790_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:34859:DataXceiver error processing WRITE_BLOCK operation  src: /127.0.0.1:45948 dst: /127.0.0.1:34859
java.io.IOException: Premature EOF from inputStream
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:212)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:908)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:31,462 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:39054 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775792_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:41151:DataXceiver error processing WRITE_BLOCK operation  src: /127.0.0.1:39054 dst: /127.0.0.1:41151
java.io.IOException: Premature EOF from inputStream
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:212)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:908)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:31,462 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:50912 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775785_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:46036:DataXceiver error processing WRITE_BLOCK operation  src: /127.0.0.1:50912 dst: /127.0.0.1:46036
java.io.IOException: Premature EOF from inputStream
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:212)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:908)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:31,462 [PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775787_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775787_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:31,463 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775784_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:40699,DS-fed01141-fff1-42c6-b3e3-2fd935c70283,DISK]], #8: blk_-9223372036854775784_1001
2020-12-03 07:24:31,463 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775785_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:46036,DS-2b1930b4-e95b-4943-b1ab-05b98259886a,DISK]], #7: blk_-9223372036854775785_1001
2020-12-03 07:24:31,463 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775786_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:41639,DS-dbecbb28-d168-4eb9-ba31-b857b3014299,DISK]], #6: blk_-9223372036854775786_1001
2020-12-03 07:24:31,463 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775787_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:46808,DS-58c3452e-b5a4-4351-a5dd-720979be90e5,DISK]], #5: blk_-9223372036854775787_1001
2020-12-03 07:24:31,464 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775787_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:46808
2020-12-03 07:24:31,463 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775790_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:34859,DS-c69444b7-75df-4430-81d2-ce7868dd7889,DISK]], #2: blk_-9223372036854775790_1001
2020-12-03 07:24:31,465 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775790_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:34859
2020-12-03 07:24:31,465 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775787_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-12-03 07:24:31,465 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775787_1001] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:31,465 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775790_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-12-03 07:24:31,463 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775789_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:43939,DS-5eaccf1b-8417-47bc-a260-6b7d108d3890,DISK]], #3: blk_-9223372036854775789_1001
2020-12-03 07:24:31,463 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775791_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:45408,DS-8c30b030-99db-4142-8d95-5495cf2e3bb5,DISK]], #1: blk_-9223372036854775791_1001
2020-12-03 07:24:31,463 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775792_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:41151,DS-0539376e-ad17-43e8-b692-2105b79e3e6f,DISK]], #0: blk_-9223372036854775792_1001
2020-12-03 07:24:31,463 [PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775791_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775791_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:31,468 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775792_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:41151
2020-12-03 07:24:31,468 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775791_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:45408
2020-12-03 07:24:31,468 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775789_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:43939
2020-12-03 07:24:31,467 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775790_1001] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:31,468 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775792_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-12-03 07:24:31,469 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775791_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-12-03 07:24:31,464 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775786_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:41639
2020-12-03 07:24:31,464 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775785_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:46036
2020-12-03 07:24:31,464 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775784_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:40699
2020-12-03 07:24:31,464 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:38240 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775787_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(939)) - opWriteBlock BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775787_1001 received exception java.io.IOException: Premature EOF from inputStream
2020-12-03 07:24:31,472 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:45970 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775790_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775790_1001 src: /127.0.0.1:45970 dest: /127.0.0.1:34859
2020-12-03 07:24:31,472 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775784_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-12-03 07:24:31,472 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:38240 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775787_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:46808:DataXceiver error processing WRITE_BLOCK operation  src: /127.0.0.1:38240 dst: /127.0.0.1:46808
java.io.IOException: Premature EOF from inputStream
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:212)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:908)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:31,469 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775791_1001] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:31,469 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775789_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-12-03 07:24:31,469 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775792_1001] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:31,468 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:38248 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775787_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775787_1001 src: /127.0.0.1:38248 dest: /127.0.0.1:46808
2020-12-03 07:24:31,468 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:41860 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775791_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(939)) - opWriteBlock BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775791_1001 received exception java.io.IOException: Premature EOF from inputStream
2020-12-03 07:24:31,475 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:38248 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775787_1001]] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:recoverRbw(1443)) - Recover RBW replica BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775787_1001
2020-12-03 07:24:31,474 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775789_1001] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:31,472 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775784_1001] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:31,472 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:45970 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775790_1001]] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:recoverRbw(1443)) - Recover RBW replica BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775790_1001
2020-12-03 07:24:31,472 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775785_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-12-03 07:24:31,472 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775786_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-12-03 07:24:31,479 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:38248 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775787_1001]] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:recoverRbw(1459)) - At 127.0.0.1:46808, Recovering ReplicaBeingWritten, blk_-9223372036854775787_1001, RBW
  getNumBytes()     = 65536
  getBytesOnDisk()  = 65536
  getVisibleLength()= 65536
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-101448600-172.17.0.4-1606980263805/current/rbw/blk_-9223372036854775787
  bytesAcked=65536
  bytesOnDisk=65536
2020-12-03 07:24:31,480 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:45970 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775790_1001]] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:recoverRbw(1459)) - At 127.0.0.1:34859, Recovering ReplicaBeingWritten, blk_-9223372036854775790_1001, RBW
  getNumBytes()     = 65536
  getBytesOnDisk()  = 65536
  getVisibleLength()= 65536
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-101448600-172.17.0.4-1606980263805/current/rbw/blk_-9223372036854775790
  bytesAcked=65536
  bytesOnDisk=65536
2020-12-03 07:24:31,479 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775785_1001] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:31,479 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:41890 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775791_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775791_1001 src: /127.0.0.1:41890 dest: /127.0.0.1:45408
2020-12-03 07:24:31,479 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:41860 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775791_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:45408:DataXceiver error processing WRITE_BLOCK operation  src: /127.0.0.1:41860 dst: /127.0.0.1:45408
java.io.IOException: Premature EOF from inputStream
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:212)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:908)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:31,482 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:50928 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775785_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775785_1001 src: /127.0.0.1:50928 dest: /127.0.0.1:46036
2020-12-03 07:24:31,479 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:39084 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775792_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775792_1001 src: /127.0.0.1:39084 dest: /127.0.0.1:41151
2020-12-03 07:24:31,482 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:50928 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775785_1001]] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:recoverRbw(1443)) - Recover RBW replica BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775785_1001
2020-12-03 07:24:31,482 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:41890 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775791_1001]] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:recoverRbw(1443)) - Recover RBW replica BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775791_1001
2020-12-03 07:24:31,480 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:59904 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775784_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775784_1001 src: /127.0.0.1:59904 dest: /127.0.0.1:40699
2020-12-03 07:24:31,480 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:49362 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775789_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775789_1001 src: /127.0.0.1:49362 dest: /127.0.0.1:43939
2020-12-03 07:24:31,479 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775786_1001] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:31,488 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:49362 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775789_1001]] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:recoverRbw(1443)) - Recover RBW replica BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775789_1001
2020-12-03 07:24:31,488 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:41890 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775791_1001]] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:recoverRbw(1459)) - At 127.0.0.1:45408, Recovering ReplicaBeingWritten, blk_-9223372036854775791_1001, RBW
  getNumBytes()     = 65536
  getBytesOnDisk()  = 65536
  getVisibleLength()= 65536
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-101448600-172.17.0.4-1606980263805/current/rbw/blk_-9223372036854775791
  bytesAcked=65536
  bytesOnDisk=65536
2020-12-03 07:24:31,488 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:59904 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775784_1001]] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:recoverRbw(1443)) - Recover RBW replica BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775784_1001
2020-12-03 07:24:31,488 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:50928 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775785_1001]] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:recoverRbw(1459)) - At 127.0.0.1:46036, Recovering ReplicaBeingWritten, blk_-9223372036854775785_1001, RBW
  getNumBytes()     = 65536
  getBytesOnDisk()  = 65536
  getVisibleLength()= 65536
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-101448600-172.17.0.4-1606980263805/current/rbw/blk_-9223372036854775785
  bytesAcked=65536
  bytesOnDisk=65536
2020-12-03 07:24:31,487 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:39084 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775792_1001]] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:recoverRbw(1443)) - Recover RBW replica BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775792_1001
2020-12-03 07:24:31,489 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:49362 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775789_1001]] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:recoverRbw(1459)) - At 127.0.0.1:43939, Recovering ReplicaBeingWritten, blk_-9223372036854775789_1001, RBW
  getNumBytes()     = 65536
  getBytesOnDisk()  = 65536
  getVisibleLength()= 65536
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-101448600-172.17.0.4-1606980263805/current/rbw/blk_-9223372036854775789
  bytesAcked=65536
  bytesOnDisk=65536
2020-12-03 07:24:31,491 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:59904 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775784_1001]] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:recoverRbw(1459)) - At 127.0.0.1:40699, Recovering ReplicaBeingWritten, blk_-9223372036854775784_1001, RBW
  getNumBytes()     = 65536
  getBytesOnDisk()  = 65536
  getVisibleLength()= 65536
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-101448600-172.17.0.4-1606980263805/current/rbw/blk_-9223372036854775784
  bytesAcked=65536
  bytesOnDisk=65536
2020-12-03 07:24:31,490 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:34428 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775786_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775786_1001 src: /127.0.0.1:34428 dest: /127.0.0.1:41639
2020-12-03 07:24:31,492 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:34428 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775786_1001]] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:recoverRbw(1443)) - Recover RBW replica BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775786_1001
2020-12-03 07:24:31,492 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:39084 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775792_1001]] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:recoverRbw(1459)) - At 127.0.0.1:41151, Recovering ReplicaBeingWritten, blk_-9223372036854775792_1001, RBW
  getNumBytes()     = 65536
  getBytesOnDisk()  = 65536
  getVisibleLength()= 65536
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-101448600-172.17.0.4-1606980263805/current/rbw/blk_-9223372036854775792
  bytesAcked=65536
  bytesOnDisk=65536
2020-12-03 07:24:31,493 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:34428 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775786_1001]] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:recoverRbw(1459)) - At 127.0.0.1:41639, Recovering ReplicaBeingWritten, blk_-9223372036854775786_1001, RBW
  getNumBytes()     = 65536
  getBytesOnDisk()  = 65536
  getVisibleLength()= 65536
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-101448600-172.17.0.4-1606980263805/current/rbw/blk_-9223372036854775786
  bytesAcked=65536
  bytesOnDisk=65536
2020-12-03 07:24:31,499 [IPC Server handler 6 on default port 37942] INFO  namenode.FSNamesystem (FSNamesystem.java:updatePipeline(5430)) - updatePipeline(blk_-9223372036854775792_1001, newGS=1002, newLength=393216, newNodes=[127.0.0.1:41151, 127.0.0.1:45408, 127.0.0.1:34859, 127.0.0.1:43939, null:0, 127.0.0.1:46808, 127.0.0.1:41639, 127.0.0.1:46036, 127.0.0.1:40699], client=DFSClient_NONMAPREDUCE_-730121065_1)
2020-12-03 07:24:31,501 [IPC Server handler 6 on default port 37942] INFO  namenode.FSNamesystem (FSNamesystem.java:updatePipeline(5448)) - updatePipeline(blk_-9223372036854775792_1001 => blk_-9223372036854775792_1002) success
2020-12-03 07:24:31,502 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775789_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:43939,DS-5eaccf1b-8417-47bc-a260-6b7d108d3890,DISK]] storageTypes [DISK] storageIDs [DS-5eaccf1b-8417-47bc-a260-6b7d108d3890]
2020-12-03 07:24:31,503 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775785_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:46036,DS-2b1930b4-e95b-4943-b1ab-05b98259886a,DISK]] storageTypes [DISK] storageIDs [DS-2b1930b4-e95b-4943-b1ab-05b98259886a]
2020-12-03 07:24:31,503 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,503 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775784_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:40699,DS-fed01141-fff1-42c6-b3e3-2fd935c70283,DISK]] storageTypes [DISK] storageIDs [DS-fed01141-fff1-42c6-b3e3-2fd935c70283]
2020-12-03 07:24:31,505 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=2, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], packetSize=65016, chunksPerPacket=126, bytesCurBlock=65536, DFSStripedOutputStream:#0: blk_-9223372036854775792_1002
2020-12-03 07:24:31,503 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775786_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:41639,DS-dbecbb28-d168-4eb9-ba31-b857b3014299,DISK]] storageTypes [DISK] storageIDs [DS-dbecbb28-d168-4eb9-ba31-b857b3014299]
2020-12-03 07:24:31,502 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775792_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:41151,DS-0539376e-ad17-43e8-b692-2105b79e3e6f,DISK]] storageTypes [DISK] storageIDs [DS-0539376e-ad17-43e8-b692-2105b79e3e6f]
2020-12-03 07:24:31,502 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775787_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:46808,DS-58c3452e-b5a4-4351-a5dd-720979be90e5,DISK]] storageTypes [DISK] storageIDs [DS-58c3452e-b5a4-4351-a5dd-720979be90e5]
2020-12-03 07:24:31,502 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775790_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:34859,DS-c69444b7-75df-4430-81d2-ce7868dd7889,DISK]] storageTypes [DISK] storageIDs [DS-c69444b7-75df-4430-81d2-ce7868dd7889]
2020-12-03 07:24:31,502 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775791_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:45408,DS-8c30b030-99db-4142-8d95-5495cf2e3bb5,DISK]] storageTypes [DISK] storageIDs [DS-8c30b030-99db-4142-8d95-5495cf2e3bb5]
2020-12-03 07:24:31,515 [Listener at localhost/42122] INFO  hdfs.TestDFSStripedOutputStreamWithFailureBase (TestDFSStripedOutputStreamWithFailureBase.java:getGenerationStamp(376)) - getGenerationStamp returns 1002
2020-12-03 07:24:31,515 [Listener at localhost/42122] INFO  hdfs.TestDFSStripedOutputStreamWithFailureBase (TestDFSStripedOutputStreamWithFailureBase.java:killDatanode(410)) - killDatanode 5: DatanodeInfoWithStorage[127.0.0.1:46808,DS-58c3452e-b5a4-4351-a5dd-720979be90e5,DISK], pos=436907
2020-12-03 07:24:31,516 [Listener at localhost/42122] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopDataNode(2331)) - MiniDFSCluster Stopping DataNode 127.0.0.1:46808 from a total of 8 datanodes.
2020-12-03 07:24:31,516 [Listener at localhost/42122] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:24:31,516 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@5d8445d7] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:24:31,519 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-58c3452e-b5a4-4351-a5dd-720979be90e5) exiting.
2020-12-03 07:24:31,519 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-64790cae-1f9a-427b-8afc-04566b3d97c3) exiting.
2020-12-03 07:24:31,521 [ResponseProcessor for block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775787_1002] WARN  hdfs.DataStreamer (DataStreamer.java:run(1196)) - Exception for BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775787_1002
java.io.EOFException: Unexpected EOF while trying to read response from server
	at org.apache.hadoop.hdfs.protocolPB.PBHelperClient.vintPrefixed(PBHelperClient.java:550)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PipelineAck.readFields(PipelineAck.java:213)
	at org.apache.hadoop.hdfs.DataStreamer$ResponseProcessor.run(DataStreamer.java:1086)
2020-12-03 07:24:31,522 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775787_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:processDatanodeOrExternalError(1229)) - start process datanode/external error, #5: failed, blk_-9223372036854775787_1002
2020-12-03 07:24:31,550 [Listener at localhost/42122] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@73393584{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:24:31,551 [Listener at localhost/42122] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@31500940{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:31,552 [Listener at localhost/42122] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5af9926a{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:31,552 [Listener at localhost/42122] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@29ad44e3{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:31,553 [Listener at localhost/42122] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 40304
2020-12-03 07:24:31,553 [PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775787_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1470)) - PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775787_1002, type=LAST_IN_PIPELINE: Thread is interrupted.
2020-12-03 07:24:31,554 [PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775787_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775787_1002, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:31,554 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:38248 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775787_1001]] INFO  datanode.DataNode (BlockReceiver.java:receiveBlock(1010)) - Exception for BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775787_1002
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 60000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:157)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:345)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:210)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:908)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:31,563 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:31,564 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:31,570 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:38248 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775787_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(939)) - opWriteBlock BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775787_1002 received exception java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 60000 millis timeout left.
2020-12-03 07:24:31,570 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:24:31,573 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-101448600-172.17.0.4-1606980263805 (Datanode Uuid 3d6f040b-d45e-46f5-a3a5-f40179b44cc0) service to localhost/127.0.0.1:37942
2020-12-03 07:24:31,573 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-101448600-172.17.0.4-1606980263805 (Datanode Uuid 3d6f040b-d45e-46f5-a3a5-f40179b44cc0)
2020-12-03 07:24:31,574 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:38248 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775787_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:46808:DataXceiver error processing WRITE_BLOCK operation  src: /127.0.0.1:38248 dst: /127.0.0.1:46808
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 60000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:157)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:345)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:210)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:908)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:31,574 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:31,577 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-101448600-172.17.0.4-1606980263805] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:31,577 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-101448600-172.17.0.4-1606980263805] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:31,581 [Listener at localhost/42122] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:24:31,582 [Listener at localhost/42122] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:24:31,583 [Listener at localhost/42122] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:24:31,583 [Listener at localhost/42122] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:24:31,585 [Listener at localhost/42122] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:24:31,595 [Listener at localhost/42122] DEBUG hdfs.DFSOutputStream (DFSStripedOutputStream.java:enqueueCurrentPacketFull(576)) - enqueue full packet seqno: 2 offsetInBlock: 65536 lastPacketInBlock: false lastByteOffsetInBlock: 130048, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], bytesCurBlock=130048, blockSize=262144, appendChunk=false, #0: blk_-9223372036854775792_1002
2020-12-03 07:24:31,595 [Listener at localhost/42122] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 2 offsetInBlock: 65536 lastPacketInBlock: false lastByteOffsetInBlock: 130048, #0: blk_-9223372036854775792_1002
2020-12-03 07:24:31,595 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,595 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775792_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, #0: blk_-9223372036854775792_1002
2020-12-03 07:24:31,595 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=3, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], packetSize=65016, chunksPerPacket=126, bytesCurBlock=130048, DFSStripedOutputStream:#0: blk_-9223372036854775792_1002
2020-12-03 07:24:31,597 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775792_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - #0: blk_-9223372036854775792_1002 sending packet seqno: 2 offsetInBlock: 65536 lastPacketInBlock: false lastByteOffsetInBlock: 130048
2020-12-03 07:24:31,597 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,598 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=2, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], packetSize=65016, chunksPerPacket=126, bytesCurBlock=65536, DFSStripedOutputStream:#1: blk_-9223372036854775791_1002
2020-12-03 07:24:31,604 [ResponseProcessor for block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775792_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 2 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2020-12-03 07:24:31,607 [Listener at localhost/42122] DEBUG hdfs.DFSOutputStream (DFSStripedOutputStream.java:enqueueCurrentPacketFull(576)) - enqueue full packet seqno: 2 offsetInBlock: 65536 lastPacketInBlock: false lastByteOffsetInBlock: 130048, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], bytesCurBlock=130048, blockSize=262144, appendChunk=false, #1: blk_-9223372036854775791_1002
2020-12-03 07:24:31,607 [Listener at localhost/42122] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 2 offsetInBlock: 65536 lastPacketInBlock: false lastByteOffsetInBlock: 130048, #1: blk_-9223372036854775791_1002
2020-12-03 07:24:31,607 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,607 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775791_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, #1: blk_-9223372036854775791_1002
2020-12-03 07:24:31,608 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=3, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], packetSize=65016, chunksPerPacket=126, bytesCurBlock=130048, DFSStripedOutputStream:#1: blk_-9223372036854775791_1002
2020-12-03 07:24:31,609 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775791_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - #1: blk_-9223372036854775791_1002 sending packet seqno: 2 offsetInBlock: 65536 lastPacketInBlock: false lastByteOffsetInBlock: 130048
2020-12-03 07:24:31,609 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,610 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=2, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], packetSize=65016, chunksPerPacket=126, bytesCurBlock=65536, DFSStripedOutputStream:#2: blk_-9223372036854775790_1002
2020-12-03 07:24:31,615 [ResponseProcessor for block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775791_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 2 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2020-12-03 07:24:31,619 [Listener at localhost/42122] DEBUG hdfs.DFSOutputStream (DFSStripedOutputStream.java:enqueueCurrentPacketFull(576)) - enqueue full packet seqno: 2 offsetInBlock: 65536 lastPacketInBlock: false lastByteOffsetInBlock: 130048, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], bytesCurBlock=130048, blockSize=262144, appendChunk=false, #2: blk_-9223372036854775790_1002
2020-12-03 07:24:31,619 [Listener at localhost/42122] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 2 offsetInBlock: 65536 lastPacketInBlock: false lastByteOffsetInBlock: 130048, #2: blk_-9223372036854775790_1002
2020-12-03 07:24:31,619 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,619 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775790_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, #2: blk_-9223372036854775790_1002
2020-12-03 07:24:31,619 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=3, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], packetSize=65016, chunksPerPacket=126, bytesCurBlock=130048, DFSStripedOutputStream:#2: blk_-9223372036854775790_1002
2020-12-03 07:24:31,620 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,620 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=2, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], packetSize=65016, chunksPerPacket=126, bytesCurBlock=65536, DFSStripedOutputStream:#3: blk_-9223372036854775789_1002
2020-12-03 07:24:31,626 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775790_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - #2: blk_-9223372036854775790_1002 sending packet seqno: 2 offsetInBlock: 65536 lastPacketInBlock: false lastByteOffsetInBlock: 130048
2020-12-03 07:24:31,629 [ResponseProcessor for block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775790_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 2 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2020-12-03 07:24:31,634 [Listener at localhost/42122] DEBUG hdfs.DFSOutputStream (DFSStripedOutputStream.java:enqueueCurrentPacketFull(576)) - enqueue full packet seqno: 2 offsetInBlock: 65536 lastPacketInBlock: false lastByteOffsetInBlock: 130048, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], bytesCurBlock=130048, blockSize=262144, appendChunk=false, #3: blk_-9223372036854775789_1002
2020-12-03 07:24:31,634 [Listener at localhost/42122] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 2 offsetInBlock: 65536 lastPacketInBlock: false lastByteOffsetInBlock: 130048, #3: blk_-9223372036854775789_1002
2020-12-03 07:24:31,634 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,634 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775789_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, #3: blk_-9223372036854775789_1002
2020-12-03 07:24:31,636 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775789_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - #3: blk_-9223372036854775789_1002 sending packet seqno: 2 offsetInBlock: 65536 lastPacketInBlock: false lastByteOffsetInBlock: 130048
2020-12-03 07:24:31,636 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=3, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], packetSize=65016, chunksPerPacket=126, bytesCurBlock=130048, DFSStripedOutputStream:#3: blk_-9223372036854775789_1002
2020-12-03 07:24:31,636 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,645 [ResponseProcessor for block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775789_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 2 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2020-12-03 07:24:31,658 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,658 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=2, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], packetSize=65016, chunksPerPacket=126, bytesCurBlock=65536, DFSStripedOutputStream:#6: blk_-9223372036854775786_1002
2020-12-03 07:24:31,662 [Listener at localhost/42122] DEBUG hdfs.DFSOutputStream (DFSStripedOutputStream.java:enqueueCurrentPacketFull(576)) - enqueue full packet seqno: 2 offsetInBlock: 65536 lastPacketInBlock: false lastByteOffsetInBlock: 130048, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], bytesCurBlock=130048, blockSize=262144, appendChunk=false, #6: blk_-9223372036854775786_1002
2020-12-03 07:24:31,662 [Listener at localhost/42122] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 2 offsetInBlock: 65536 lastPacketInBlock: false lastByteOffsetInBlock: 130048, #6: blk_-9223372036854775786_1002
2020-12-03 07:24:31,663 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,663 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775786_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, #6: blk_-9223372036854775786_1002
2020-12-03 07:24:31,663 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=3, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], packetSize=65016, chunksPerPacket=126, bytesCurBlock=130048, DFSStripedOutputStream:#6: blk_-9223372036854775786_1002
2020-12-03 07:24:31,663 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775786_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - #6: blk_-9223372036854775786_1002 sending packet seqno: 2 offsetInBlock: 65536 lastPacketInBlock: false lastByteOffsetInBlock: 130048
2020-12-03 07:24:31,663 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,667 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=2, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], packetSize=65016, chunksPerPacket=126, bytesCurBlock=65536, DFSStripedOutputStream:#7: blk_-9223372036854775785_1002
2020-12-03 07:24:31,671 [ResponseProcessor for block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775786_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 2 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2020-12-03 07:24:31,672 [Listener at localhost/42122] DEBUG hdfs.DFSOutputStream (DFSStripedOutputStream.java:enqueueCurrentPacketFull(576)) - enqueue full packet seqno: 2 offsetInBlock: 65536 lastPacketInBlock: false lastByteOffsetInBlock: 130048, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], bytesCurBlock=130048, blockSize=262144, appendChunk=false, #7: blk_-9223372036854775785_1002
2020-12-03 07:24:31,672 [Listener at localhost/42122] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 2 offsetInBlock: 65536 lastPacketInBlock: false lastByteOffsetInBlock: 130048, #7: blk_-9223372036854775785_1002
2020-12-03 07:24:31,672 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,672 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=3, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], packetSize=65016, chunksPerPacket=126, bytesCurBlock=130048, DFSStripedOutputStream:#7: blk_-9223372036854775785_1002
2020-12-03 07:24:31,678 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,672 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775785_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, #7: blk_-9223372036854775785_1002
2020-12-03 07:24:31,689 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=2, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], packetSize=65016, chunksPerPacket=126, bytesCurBlock=65536, DFSStripedOutputStream:#8: blk_-9223372036854775784_1002
2020-12-03 07:24:31,697 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775785_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - #7: blk_-9223372036854775785_1002 sending packet seqno: 2 offsetInBlock: 65536 lastPacketInBlock: false lastByteOffsetInBlock: 130048
2020-12-03 07:24:31,698 [Listener at localhost/42122] DEBUG hdfs.DFSOutputStream (DFSStripedOutputStream.java:enqueueCurrentPacketFull(576)) - enqueue full packet seqno: 2 offsetInBlock: 65536 lastPacketInBlock: false lastByteOffsetInBlock: 130048, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], bytesCurBlock=130048, blockSize=262144, appendChunk=false, #8: blk_-9223372036854775784_1002
2020-12-03 07:24:31,698 [Listener at localhost/42122] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 2 offsetInBlock: 65536 lastPacketInBlock: false lastByteOffsetInBlock: 130048, #8: blk_-9223372036854775784_1002
2020-12-03 07:24:31,698 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,704 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775784_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, #8: blk_-9223372036854775784_1002
2020-12-03 07:24:31,712 [ResponseProcessor for block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775785_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 2 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2020-12-03 07:24:31,711 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=3, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], packetSize=65016, chunksPerPacket=126, bytesCurBlock=130048, DFSStripedOutputStream:#8: blk_-9223372036854775784_1002
2020-12-03 07:24:31,713 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775784_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - #8: blk_-9223372036854775784_1002 sending packet seqno: 2 offsetInBlock: 65536 lastPacketInBlock: false lastByteOffsetInBlock: 130048
2020-12-03 07:24:31,714 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,714 [Listener at localhost/42122] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 3 offsetInBlock: 130048 lastPacketInBlock: false lastByteOffsetInBlock: 131072, #0: blk_-9223372036854775792_1002
2020-12-03 07:24:31,714 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,714 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775792_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, #0: blk_-9223372036854775792_1002
2020-12-03 07:24:31,717 [Listener at localhost/42122] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 3 offsetInBlock: 130048 lastPacketInBlock: false lastByteOffsetInBlock: 131072, #1: blk_-9223372036854775791_1002
2020-12-03 07:24:31,718 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775792_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - #0: blk_-9223372036854775792_1002 sending packet seqno: 3 offsetInBlock: 130048 lastPacketInBlock: false lastByteOffsetInBlock: 131072
2020-12-03 07:24:31,722 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775791_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, #1: blk_-9223372036854775791_1002
2020-12-03 07:24:31,722 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,729 [ResponseProcessor for block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775784_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 2 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2020-12-03 07:24:31,727 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775791_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - #1: blk_-9223372036854775791_1002 sending packet seqno: 3 offsetInBlock: 130048 lastPacketInBlock: false lastByteOffsetInBlock: 131072
2020-12-03 07:24:31,729 [Listener at localhost/42122] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 3 offsetInBlock: 130048 lastPacketInBlock: false lastByteOffsetInBlock: 131072, #2: blk_-9223372036854775790_1002
2020-12-03 07:24:31,729 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,729 [ResponseProcessor for block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775792_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 3 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2020-12-03 07:24:31,729 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775790_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, #2: blk_-9223372036854775790_1002
2020-12-03 07:24:31,730 [ResponseProcessor for block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775791_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 3 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2020-12-03 07:24:31,730 [Listener at localhost/42122] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 3 offsetInBlock: 130048 lastPacketInBlock: false lastByteOffsetInBlock: 131072, #3: blk_-9223372036854775789_1002
2020-12-03 07:24:31,731 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775790_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - #2: blk_-9223372036854775790_1002 sending packet seqno: 3 offsetInBlock: 130048 lastPacketInBlock: false lastByteOffsetInBlock: 131072
2020-12-03 07:24:31,732 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,732 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775789_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, #3: blk_-9223372036854775789_1002
2020-12-03 07:24:31,732 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,733 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775789_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - #3: blk_-9223372036854775789_1002 sending packet seqno: 3 offsetInBlock: 130048 lastPacketInBlock: false lastByteOffsetInBlock: 131072
2020-12-03 07:24:31,734 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,734 [Listener at localhost/42122] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 3 offsetInBlock: 130048 lastPacketInBlock: false lastByteOffsetInBlock: 131072, #6: blk_-9223372036854775786_1002
2020-12-03 07:24:31,734 [ResponseProcessor for block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775790_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 3 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2020-12-03 07:24:31,734 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775786_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, #6: blk_-9223372036854775786_1002
2020-12-03 07:24:31,734 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,736 [ResponseProcessor for block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775789_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 3 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2020-12-03 07:24:31,736 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775786_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - #6: blk_-9223372036854775786_1002 sending packet seqno: 3 offsetInBlock: 130048 lastPacketInBlock: false lastByteOffsetInBlock: 131072
2020-12-03 07:24:31,736 [Listener at localhost/42122] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 3 offsetInBlock: 130048 lastPacketInBlock: false lastByteOffsetInBlock: 131072, #7: blk_-9223372036854775785_1002
2020-12-03 07:24:31,737 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,737 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775785_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, #7: blk_-9223372036854775785_1002
2020-12-03 07:24:31,737 [Listener at localhost/42122] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 3 offsetInBlock: 130048 lastPacketInBlock: false lastByteOffsetInBlock: 131072, #8: blk_-9223372036854775784_1002
2020-12-03 07:24:31,738 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775785_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - #7: blk_-9223372036854775785_1002 sending packet seqno: 3 offsetInBlock: 130048 lastPacketInBlock: false lastByteOffsetInBlock: 131072
2020-12-03 07:24:31,738 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,738 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775784_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, #8: blk_-9223372036854775784_1002
2020-12-03 07:24:31,739 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,738 [ResponseProcessor for block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775786_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 3 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2020-12-03 07:24:31,740 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775784_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - #8: blk_-9223372036854775784_1002 sending packet seqno: 3 offsetInBlock: 130048 lastPacketInBlock: false lastByteOffsetInBlock: 131072
2020-12-03 07:24:31,740 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,741 [pool-119-thread-9] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - #0: blk_-9223372036854775792_1002 waiting for ack for: 3
2020-12-03 07:24:31,741 [pool-119-thread-1] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - #1: blk_-9223372036854775791_1002 waiting for ack for: 3
2020-12-03 07:24:31,741 [ResponseProcessor for block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775785_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 3 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2020-12-03 07:24:31,741 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,741 [ResponseProcessor for block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775784_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 3 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2020-12-03 07:24:31,741 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,741 [pool-119-thread-3] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - #2: blk_-9223372036854775790_1002 waiting for ack for: 3
2020-12-03 07:24:31,742 [pool-119-thread-4] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - #3: blk_-9223372036854775789_1002 waiting for ack for: 3
2020-12-03 07:24:31,742 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,742 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,742 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,742 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,742 [pool-119-thread-2] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - #6: blk_-9223372036854775786_1002 waiting for ack for: 3
2020-12-03 07:24:31,743 [pool-119-thread-6] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - #7: blk_-9223372036854775785_1002 waiting for ack for: 3
2020-12-03 07:24:31,743 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,743 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,743 [pool-119-thread-7] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - #8: blk_-9223372036854775784_1002 waiting for ack for: 3
2020-12-03 07:24:31,743 [Listener at localhost/42122] DEBUG hdfs.DFSOutputStream (DFSStripedOutputStream.java:checkStreamers(390)) - checkStreamers: [#0: blk_-9223372036854775792_1002, #1: blk_-9223372036854775791_1002, #2: blk_-9223372036854775790_1002, #3: blk_-9223372036854775789_1002, #4: failed, block==null, #5: failed, blk_-9223372036854775787_1002, #6: blk_-9223372036854775786_1002, #7: blk_-9223372036854775785_1002, #8: blk_-9223372036854775784_1002]
2020-12-03 07:24:31,744 [Listener at localhost/42122] DEBUG hdfs.DFSOutputStream (DFSStripedOutputStream.java:checkStreamers(391)) - healthy streamer count=7
2020-12-03 07:24:31,744 [Listener at localhost/42122] DEBUG hdfs.DFSOutputStream (DFSStripedOutputStream.java:checkStreamers(392)) - original failed streamers: [#4: failed, block==null]
2020-12-03 07:24:31,744 [Listener at localhost/42122] DEBUG hdfs.DFSOutputStream (DFSStripedOutputStream.java:checkStreamers(393)) - newly failed streamers: [#5: failed, blk_-9223372036854775787_1002]
2020-12-03 07:24:31,744 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,744 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,744 [pool-119-thread-5] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - #0: blk_-9223372036854775792_1002 waiting for ack for: 3
2020-12-03 07:24:31,744 [pool-119-thread-8] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - #1: blk_-9223372036854775791_1002 waiting for ack for: 3
2020-12-03 07:24:31,744 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,745 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,745 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,745 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,745 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,746 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,746 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,746 [pool-119-thread-4] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - #7: blk_-9223372036854775785_1002 waiting for ack for: 3
2020-12-03 07:24:31,746 [pool-119-thread-3] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - #6: blk_-9223372036854775786_1002 waiting for ack for: 3
2020-12-03 07:24:31,746 [pool-119-thread-1] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - #3: blk_-9223372036854775789_1002 waiting for ack for: 3
2020-12-03 07:24:31,746 [pool-119-thread-9] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - #2: blk_-9223372036854775790_1002 waiting for ack for: 3
2020-12-03 07:24:31,746 [pool-119-thread-2] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - #8: blk_-9223372036854775784_1002 waiting for ack for: 3
2020-12-03 07:24:31,746 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,747 [Listener at localhost/42122] DEBUG hdfs.DFSOutputStream (DFSStripedOutputStream.java:checkStreamers(390)) - checkStreamers: [#0: blk_-9223372036854775792_1002, #1: blk_-9223372036854775791_1002, #2: blk_-9223372036854775790_1002, #3: blk_-9223372036854775789_1002, #4: failed, block==null, #5: failed, blk_-9223372036854775787_1002, #6: blk_-9223372036854775786_1002, #7: blk_-9223372036854775785_1002, #8: blk_-9223372036854775784_1002]
2020-12-03 07:24:31,747 [Listener at localhost/42122] DEBUG hdfs.DFSOutputStream (DFSStripedOutputStream.java:checkStreamers(391)) - healthy streamer count=7
2020-12-03 07:24:31,747 [Listener at localhost/42122] DEBUG hdfs.DFSOutputStream (DFSStripedOutputStream.java:checkStreamers(392)) - original failed streamers: [#4: failed, block==null]
2020-12-03 07:24:31,747 [Listener at localhost/42122] DEBUG hdfs.DFSOutputStream (DFSStripedOutputStream.java:checkStreamers(393)) - newly failed streamers: [#5: failed, blk_-9223372036854775787_1002]
2020-12-03 07:24:31,748 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775792_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:processDatanodeOrExternalError(1229)) - start process datanode/external error, #0: blk_-9223372036854775792_1002
2020-12-03 07:24:31,748 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775789_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:processDatanodeOrExternalError(1229)) - start process datanode/external error, #3: blk_-9223372036854775789_1002
2020-12-03 07:24:31,748 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775786_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:processDatanodeOrExternalError(1229)) - start process datanode/external error, #6: blk_-9223372036854775786_1002
2020-12-03 07:24:31,748 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:39084 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775792_1001]] INFO  datanode.DataNode (BlockReceiver.java:receiveBlock(1010)) - Exception for BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775792_1002
java.io.IOException: Premature EOF from inputStream
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:212)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:908)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:31,750 [PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775792_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1470)) - PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775792_1002, type=LAST_IN_PIPELINE: Thread is interrupted.
2020-12-03 07:24:31,750 [PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775792_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775792_1002, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:31,750 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:39084 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775792_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(939)) - opWriteBlock BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775792_1002 received exception java.io.IOException: Premature EOF from inputStream
2020-12-03 07:24:31,748 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775790_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:processDatanodeOrExternalError(1229)) - start process datanode/external error, #2: blk_-9223372036854775790_1002
2020-12-03 07:24:31,748 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775791_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:processDatanodeOrExternalError(1229)) - start process datanode/external error, #1: blk_-9223372036854775791_1002
2020-12-03 07:24:31,748 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:34428 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775786_1001]] INFO  datanode.DataNode (BlockReceiver.java:receiveBlock(1010)) - Exception for BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775786_1002
java.io.IOException: Premature EOF from inputStream
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:212)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:908)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:31,748 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775784_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:processDatanodeOrExternalError(1229)) - start process datanode/external error, #8: blk_-9223372036854775784_1002
2020-12-03 07:24:31,748 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:49362 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775789_1001]] INFO  datanode.DataNode (BlockReceiver.java:receiveBlock(1010)) - Exception for BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775789_1002
java.io.IOException: Premature EOF from inputStream
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:212)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:908)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:31,748 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775785_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:processDatanodeOrExternalError(1229)) - start process datanode/external error, #7: blk_-9223372036854775785_1002
2020-12-03 07:24:31,754 [PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775789_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1470)) - PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775789_1002, type=LAST_IN_PIPELINE: Thread is interrupted.
2020-12-03 07:24:31,754 [PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775789_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775789_1002, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:31,754 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:49362 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775789_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(939)) - opWriteBlock BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775789_1002 received exception java.io.IOException: Premature EOF from inputStream
2020-12-03 07:24:31,753 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:59904 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775784_1001]] INFO  datanode.DataNode (BlockReceiver.java:receiveBlock(1010)) - Exception for BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775784_1002
java.io.IOException: Premature EOF from inputStream
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:212)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:908)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:31,753 [PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775786_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1470)) - PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775786_1002, type=LAST_IN_PIPELINE: Thread is interrupted.
2020-12-03 07:24:31,756 [PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775786_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775786_1002, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:31,753 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:45970 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775790_1001]] INFO  datanode.DataNode (BlockReceiver.java:receiveBlock(1010)) - Exception for BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775790_1002
java.io.IOException: Premature EOF from inputStream
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:212)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:908)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:31,753 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:41890 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775791_1001]] INFO  datanode.DataNode (BlockReceiver.java:receiveBlock(1010)) - Exception for BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775791_1002
java.io.IOException: Premature EOF from inputStream
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:212)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:908)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:31,757 [PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775790_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1470)) - PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775790_1002, type=LAST_IN_PIPELINE: Thread is interrupted.
2020-12-03 07:24:31,757 [PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775790_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775790_1002, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:31,756 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:34428 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775786_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(939)) - opWriteBlock BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775786_1002 received exception java.io.IOException: Premature EOF from inputStream
2020-12-03 07:24:31,756 [PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775784_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1470)) - PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775784_1002, type=LAST_IN_PIPELINE: Thread is interrupted.
2020-12-03 07:24:31,759 [PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775784_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775784_1002, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:31,756 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:49362 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775789_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:43939:DataXceiver error processing WRITE_BLOCK operation  src: /127.0.0.1:49362 dst: /127.0.0.1:43939
java.io.IOException: Premature EOF from inputStream
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:212)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:908)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:31,754 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:50928 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775785_1001]] INFO  datanode.DataNode (BlockReceiver.java:receiveBlock(1010)) - Exception for BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775785_1002
java.io.IOException: Premature EOF from inputStream
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:212)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:908)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:31,754 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:39084 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775792_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:41151:DataXceiver error processing WRITE_BLOCK operation  src: /127.0.0.1:39084 dst: /127.0.0.1:41151
java.io.IOException: Premature EOF from inputStream
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:212)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:908)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:31,760 [PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775785_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1470)) - PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775785_1002, type=LAST_IN_PIPELINE: Thread is interrupted.
2020-12-03 07:24:31,759 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:59904 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775784_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(939)) - opWriteBlock BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775784_1002 received exception java.io.IOException: Premature EOF from inputStream
2020-12-03 07:24:31,759 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:34428 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775786_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:41639:DataXceiver error processing WRITE_BLOCK operation  src: /127.0.0.1:34428 dst: /127.0.0.1:41639
java.io.IOException: Premature EOF from inputStream
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:212)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:908)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:31,757 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:45970 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775790_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(939)) - opWriteBlock BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775790_1002 received exception java.io.IOException: Premature EOF from inputStream
2020-12-03 07:24:31,757 [PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775791_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1470)) - PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775791_1002, type=LAST_IN_PIPELINE: Thread is interrupted.
2020-12-03 07:24:31,762 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x43a05e31390c5be1: Processing first storage report for DS-dbecbb28-d168-4eb9-ba31-b857b3014299 from datanode 8aedd082-415f-407a-9939-da8f8aa1070e
2020-12-03 07:24:31,760 [PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775785_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775785_1002, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:31,762 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:59904 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775784_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:40699:DataXceiver error processing WRITE_BLOCK operation  src: /127.0.0.1:59904 dst: /127.0.0.1:40699
java.io.IOException: Premature EOF from inputStream
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:212)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:908)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:31,762 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775791_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:45408,DS-8c30b030-99db-4142-8d95-5495cf2e3bb5,DISK]], #1: blk_-9223372036854775791_1002
2020-12-03 07:24:31,762 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:45970 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775790_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:34859:DataXceiver error processing WRITE_BLOCK operation  src: /127.0.0.1:45970 dst: /127.0.0.1:34859
java.io.IOException: Premature EOF from inputStream
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:212)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:908)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:31,762 [PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775791_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775791_1002, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:31,762 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775791_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:45408
2020-12-03 07:24:31,762 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775784_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:40699,DS-fed01141-fff1-42c6-b3e3-2fd935c70283,DISK]], #8: blk_-9223372036854775784_1002
2020-12-03 07:24:31,762 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x43a05e31390c5be1: from storage DS-dbecbb28-d168-4eb9-ba31-b857b3014299 node DatanodeRegistration(127.0.0.1:41639, datanodeUuid=8aedd082-415f-407a-9939-da8f8aa1070e, infoPort=41408, infoSecurePort=0, ipcPort=40858, storageInfo=lv=-57;cid=testClusterID;nsid=728208751;c=1606980263805), blocks: 1, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:24:31,762 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775785_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:46036,DS-2b1930b4-e95b-4943-b1ab-05b98259886a,DISK]], #7: blk_-9223372036854775785_1002
2020-12-03 07:24:31,762 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775786_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:41639,DS-dbecbb28-d168-4eb9-ba31-b857b3014299,DISK]], #6: blk_-9223372036854775786_1002
2020-12-03 07:24:31,762 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775792_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:41151,DS-0539376e-ad17-43e8-b692-2105b79e3e6f,DISK]], #0: blk_-9223372036854775792_1002
2020-12-03 07:24:31,762 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775790_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:34859,DS-c69444b7-75df-4430-81d2-ce7868dd7889,DISK]], #2: blk_-9223372036854775790_1002
2020-12-03 07:24:31,762 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775789_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:43939,DS-5eaccf1b-8417-47bc-a260-6b7d108d3890,DISK]], #3: blk_-9223372036854775789_1002
2020-12-03 07:24:31,762 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:50928 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775785_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(939)) - opWriteBlock BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775785_1002 received exception java.io.IOException: Premature EOF from inputStream
2020-12-03 07:24:31,766 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775789_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:43939
2020-12-03 07:24:31,766 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775790_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:34859
2020-12-03 07:24:31,764 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775792_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:41151
2020-12-03 07:24:31,764 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775786_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:41639
2020-12-03 07:24:31,764 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775791_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-12-03 07:24:31,768 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775790_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-12-03 07:24:31,764 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775785_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:46036
2020-12-03 07:24:31,764 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x2807eb3c71808c4c: Processing first storage report for DS-c69444b7-75df-4430-81d2-ce7868dd7889 from datanode 1c08a3ea-8510-4f3b-8323-c247c1ad19bf
2020-12-03 07:24:31,763 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775784_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:40699
2020-12-03 07:24:31,777 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x2807eb3c71808c4c: from storage DS-c69444b7-75df-4430-81d2-ce7868dd7889 node DatanodeRegistration(127.0.0.1:34859, datanodeUuid=1c08a3ea-8510-4f3b-8323-c247c1ad19bf, infoPort=44221, infoSecurePort=0, ipcPort=44273, storageInfo=lv=-57;cid=testClusterID;nsid=728208751;c=1606980263805), blocks: 1, hasStaleStorage: true, processing time: 14 msecs, invalidatedBlocks: 0
2020-12-03 07:24:31,763 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:41890 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775791_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(939)) - opWriteBlock BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775791_1002 received exception java.io.IOException: Premature EOF from inputStream
2020-12-03 07:24:31,777 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x745b853ee6303f73: Processing first storage report for DS-2b1930b4-e95b-4943-b1ab-05b98259886a from datanode fc65a25e-b981-4606-bf42-5ab919638725
2020-12-03 07:24:31,777 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775785_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-12-03 07:24:31,777 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775792_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-12-03 07:24:31,769 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775790_1002] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:31,769 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775786_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-12-03 07:24:31,780 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775786_1002] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:31,768 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775791_1002] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:31,767 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775789_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-12-03 07:24:31,767 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:50928 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775785_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:46036:DataXceiver error processing WRITE_BLOCK operation  src: /127.0.0.1:50928 dst: /127.0.0.1:46036
java.io.IOException: Premature EOF from inputStream
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:212)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:908)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:31,780 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775789_1002] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:31,779 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775792_1002] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:31,779 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775784_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-12-03 07:24:31,779 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775785_1002] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:31,779 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:41890 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775791_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:45408:DataXceiver error processing WRITE_BLOCK operation  src: /127.0.0.1:41890 dst: /127.0.0.1:45408
java.io.IOException: Premature EOF from inputStream
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:212)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:908)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:31,779 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x745b853ee6303f73: from storage DS-2b1930b4-e95b-4943-b1ab-05b98259886a node DatanodeRegistration(127.0.0.1:46036, datanodeUuid=fc65a25e-b981-4606-bf42-5ab919638725, infoPort=36214, infoSecurePort=0, ipcPort=36510, storageInfo=lv=-57;cid=testClusterID;nsid=728208751;c=1606980263805), blocks: 0, hasStaleStorage: true, processing time: 2 msecs, invalidatedBlocks: 0
2020-12-03 07:24:31,781 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:49408 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775789_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775789_1002 src: /127.0.0.1:49408 dest: /127.0.0.1:43939
2020-12-03 07:24:31,781 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775784_1002] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:31,780 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:41936 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775791_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775791_1002 src: /127.0.0.1:41936 dest: /127.0.0.1:45408
2020-12-03 07:24:31,780 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:34478 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775786_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775786_1002 src: /127.0.0.1:34478 dest: /127.0.0.1:41639
2020-12-03 07:24:31,780 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:46024 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775790_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775790_1002 src: /127.0.0.1:46024 dest: /127.0.0.1:34859
2020-12-03 07:24:31,782 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:34478 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775786_1002]] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:recoverRbw(1443)) - Recover RBW replica BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775786_1002
2020-12-03 07:24:31,781 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:41936 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775791_1002]] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:recoverRbw(1443)) - Recover RBW replica BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775791_1002
2020-12-03 07:24:31,781 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:50978 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775785_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775785_1002 src: /127.0.0.1:50978 dest: /127.0.0.1:46036
2020-12-03 07:24:31,781 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:39138 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775792_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775792_1002 src: /127.0.0.1:39138 dest: /127.0.0.1:41151
2020-12-03 07:24:31,781 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:49408 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775789_1002]] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:recoverRbw(1443)) - Recover RBW replica BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775789_1002
2020-12-03 07:24:31,781 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x43a05e31390c5be1: Processing first storage report for DS-4a408526-9e3d-400e-9c97-b7f2da3ca414 from datanode 8aedd082-415f-407a-9939-da8f8aa1070e
2020-12-03 07:24:31,782 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:39138 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775792_1002]] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:recoverRbw(1443)) - Recover RBW replica BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775792_1002
2020-12-03 07:24:31,782 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:41936 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775791_1002]] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:recoverRbw(1459)) - At 127.0.0.1:45408, Recovering ReplicaBeingWritten, blk_-9223372036854775791_1002, RBW
  getNumBytes()     = 131072
  getBytesOnDisk()  = 131072
  getVisibleLength()= 131072
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-101448600-172.17.0.4-1606980263805/current/rbw/blk_-9223372036854775791
  bytesAcked=131072
  bytesOnDisk=131072
2020-12-03 07:24:31,782 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:50978 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775785_1002]] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:recoverRbw(1443)) - Recover RBW replica BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775785_1002
2020-12-03 07:24:31,782 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:34478 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775786_1002]] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:recoverRbw(1459)) - At 127.0.0.1:41639, Recovering ReplicaBeingWritten, blk_-9223372036854775786_1002, RBW
  getNumBytes()     = 131072
  getBytesOnDisk()  = 131072
  getVisibleLength()= 131072
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-101448600-172.17.0.4-1606980263805/current/rbw/blk_-9223372036854775786
  bytesAcked=131072
  bytesOnDisk=131072
2020-12-03 07:24:31,782 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:59954 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775784_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775784_1002 src: /127.0.0.1:59954 dest: /127.0.0.1:40699
2020-12-03 07:24:31,782 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:46024 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775790_1002]] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:recoverRbw(1443)) - Recover RBW replica BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775790_1002
2020-12-03 07:24:31,784 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:59954 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775784_1002]] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:recoverRbw(1443)) - Recover RBW replica BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775784_1002
2020-12-03 07:24:31,784 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:50978 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775785_1002]] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:recoverRbw(1459)) - At 127.0.0.1:46036, Recovering ReplicaBeingWritten, blk_-9223372036854775785_1002, RBW
  getNumBytes()     = 131072
  getBytesOnDisk()  = 131072
  getVisibleLength()= 131072
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-101448600-172.17.0.4-1606980263805/current/rbw/blk_-9223372036854775785
  bytesAcked=131072
  bytesOnDisk=131072
2020-12-03 07:24:31,786 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:59954 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775784_1002]] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:recoverRbw(1459)) - At 127.0.0.1:40699, Recovering ReplicaBeingWritten, blk_-9223372036854775784_1002, RBW
  getNumBytes()     = 131072
  getBytesOnDisk()  = 131072
  getVisibleLength()= 131072
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-101448600-172.17.0.4-1606980263805/current/rbw/blk_-9223372036854775784
  bytesAcked=131072
  bytesOnDisk=131072
2020-12-03 07:24:31,782 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:39138 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775792_1002]] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:recoverRbw(1459)) - At 127.0.0.1:41151, Recovering ReplicaBeingWritten, blk_-9223372036854775792_1002, RBW
  getNumBytes()     = 131072
  getBytesOnDisk()  = 131072
  getVisibleLength()= 131072
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-101448600-172.17.0.4-1606980263805/current/rbw/blk_-9223372036854775792
  bytesAcked=131072
  bytesOnDisk=131072
2020-12-03 07:24:31,782 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:49408 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775789_1002]] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:recoverRbw(1459)) - At 127.0.0.1:43939, Recovering ReplicaBeingWritten, blk_-9223372036854775789_1002, RBW
  getNumBytes()     = 131072
  getBytesOnDisk()  = 131072
  getVisibleLength()= 131072
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-101448600-172.17.0.4-1606980263805/current/rbw/blk_-9223372036854775789
  bytesAcked=131072
  bytesOnDisk=131072
2020-12-03 07:24:31,782 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x43a05e31390c5be1: from storage DS-4a408526-9e3d-400e-9c97-b7f2da3ca414 node DatanodeRegistration(127.0.0.1:41639, datanodeUuid=8aedd082-415f-407a-9939-da8f8aa1070e, infoPort=41408, infoSecurePort=0, ipcPort=40858, storageInfo=lv=-57;cid=testClusterID;nsid=728208751;c=1606980263805), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:24:31,786 [DataXceiver for client DFSClient_NONMAPREDUCE_-730121065_1 at /127.0.0.1:46024 [Receiving block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775790_1002]] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:recoverRbw(1459)) - At 127.0.0.1:34859, Recovering ReplicaBeingWritten, blk_-9223372036854775790_1002, RBW
  getNumBytes()     = 131072
  getBytesOnDisk()  = 131072
  getVisibleLength()= 131072
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-101448600-172.17.0.4-1606980263805/current/rbw/blk_-9223372036854775790
  bytesAcked=131072
  bytesOnDisk=131072
2020-12-03 07:24:31,792 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x2807eb3c71808c4c: Processing first storage report for DS-59fe4be7-7d46-4bcc-944e-0f4b194e3df4 from datanode 1c08a3ea-8510-4f3b-8323-c247c1ad19bf
2020-12-03 07:24:31,792 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x2807eb3c71808c4c: from storage DS-59fe4be7-7d46-4bcc-944e-0f4b194e3df4 node DatanodeRegistration(127.0.0.1:34859, datanodeUuid=1c08a3ea-8510-4f3b-8323-c247c1ad19bf, infoPort=44221, infoSecurePort=0, ipcPort=44273, storageInfo=lv=-57;cid=testClusterID;nsid=728208751;c=1606980263805), blocks: 0, hasStaleStorage: false, processing time: 2 msecs, invalidatedBlocks: 0
2020-12-03 07:24:31,793 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x745b853ee6303f73: Processing first storage report for DS-64b240c2-d3e0-4acf-93d6-cebd18220651 from datanode fc65a25e-b981-4606-bf42-5ab919638725
2020-12-03 07:24:31,793 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x43a05e31390c5be1,  containing 2 storage report(s), of which we sent 2. The reports had 1 total blocks and used 1 RPC(s). This took 0 msec to generate and 43 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:31,795 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x745b853ee6303f73: from storage DS-64b240c2-d3e0-4acf-93d6-cebd18220651 node DatanodeRegistration(127.0.0.1:46036, datanodeUuid=fc65a25e-b981-4606-bf42-5ab919638725, infoPort=36214, infoSecurePort=0, ipcPort=36510, storageInfo=lv=-57;cid=testClusterID;nsid=728208751;c=1606980263805), blocks: 1, hasStaleStorage: false, processing time: 2 msecs, invalidatedBlocks: 0
2020-12-03 07:24:31,795 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:31,795 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x2807eb3c71808c4c,  containing 2 storage report(s), of which we sent 2. The reports had 1 total blocks and used 1 RPC(s). This took 1 msec to generate and 41 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:31,795 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x745b853ee6303f73,  containing 2 storage report(s), of which we sent 2. The reports had 1 total blocks and used 1 RPC(s). This took 0 msec to generate and 40 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:31,795 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:31,796 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:31,796 [IPC Server handler 3 on default port 37942] INFO  namenode.FSNamesystem (FSNamesystem.java:updatePipeline(5430)) - updatePipeline(blk_-9223372036854775792_1002, newGS=1003, newLength=655360, newNodes=[127.0.0.1:41151, 127.0.0.1:45408, 127.0.0.1:34859, 127.0.0.1:43939, null:0, null:0, 127.0.0.1:41639, 127.0.0.1:46036, 127.0.0.1:40699], client=DFSClient_NONMAPREDUCE_-730121065_1)
2020-12-03 07:24:31,798 [IPC Server handler 3 on default port 37942] INFO  namenode.FSNamesystem (FSNamesystem.java:updatePipeline(5448)) - updatePipeline(blk_-9223372036854775792_1002 => blk_-9223372036854775792_1003) success
2020-12-03 07:24:31,799 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775792_1003] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:41151,DS-0539376e-ad17-43e8-b692-2105b79e3e6f,DISK]] storageTypes [DISK] storageIDs [DS-0539376e-ad17-43e8-b692-2105b79e3e6f]
2020-12-03 07:24:31,799 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775789_1003] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:43939,DS-5eaccf1b-8417-47bc-a260-6b7d108d3890,DISK]] storageTypes [DISK] storageIDs [DS-5eaccf1b-8417-47bc-a260-6b7d108d3890]
2020-12-03 07:24:31,799 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775785_1003] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:46036,DS-2b1930b4-e95b-4943-b1ab-05b98259886a,DISK]] storageTypes [DISK] storageIDs [DS-2b1930b4-e95b-4943-b1ab-05b98259886a]
2020-12-03 07:24:31,799 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775786_1003] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:41639,DS-dbecbb28-d168-4eb9-ba31-b857b3014299,DISK]] storageTypes [DISK] storageIDs [DS-dbecbb28-d168-4eb9-ba31-b857b3014299]
2020-12-03 07:24:31,799 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775790_1003] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:34859,DS-c69444b7-75df-4430-81d2-ce7868dd7889,DISK]] storageTypes [DISK] storageIDs [DS-c69444b7-75df-4430-81d2-ce7868dd7889]
2020-12-03 07:24:31,799 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,799 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775791_1003] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:45408,DS-8c30b030-99db-4142-8d95-5495cf2e3bb5,DISK]] storageTypes [DISK] storageIDs [DS-8c30b030-99db-4142-8d95-5495cf2e3bb5]
2020-12-03 07:24:31,802 [Listener at localhost/42122] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 4 offsetInBlock: 131072 lastPacketInBlock: true lastByteOffsetInBlock: 131072, #0: blk_-9223372036854775792_1003
2020-12-03 07:24:31,801 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775784_1003] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:40699,DS-fed01141-fff1-42c6-b3e3-2fd935c70283,DISK]] storageTypes [DISK] storageIDs [DS-fed01141-fff1-42c6-b3e3-2fd935c70283]
2020-12-03 07:24:31,802 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775792_1003] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, #0: blk_-9223372036854775792_1003
2020-12-03 07:24:31,802 [Listener at localhost/42122] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - #0: blk_-9223372036854775792_1003 waiting for ack for: 4
2020-12-03 07:24:31,813 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775792_1003] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - #0: blk_-9223372036854775792_1003 sending packet seqno: 4 offsetInBlock: 131072 lastPacketInBlock: true lastByteOffsetInBlock: 131072
2020-12-03 07:24:31,820 [PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775792_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39138, dest: /127.0.0.1:41151, bytes: 131072, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-730121065_1, offset: 0, srvID: 1f53bb69-aae2-4eb5-9dde-35ced37b4811, blockid: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775792_1003, duration(ns): 24310422
2020-12-03 07:24:31,823 [PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775792_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775792_1003, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:31,824 [ResponseProcessor for block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775792_1003] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 4 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2020-12-03 07:24:31,824 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,824 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775792_1003] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775792_1003
2020-12-03 07:24:31,824 [Listener at localhost/42122] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 4 offsetInBlock: 131072 lastPacketInBlock: true lastByteOffsetInBlock: 131072, #1: blk_-9223372036854775791_1003
2020-12-03 07:24:31,824 [Listener at localhost/42122] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - #1: blk_-9223372036854775791_1003 waiting for ack for: 4
2020-12-03 07:24:31,825 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775791_1003] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, #1: blk_-9223372036854775791_1003
2020-12-03 07:24:31,826 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775791_1003] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - #1: blk_-9223372036854775791_1003 sending packet seqno: 4 offsetInBlock: 131072 lastPacketInBlock: true lastByteOffsetInBlock: 131072
2020-12-03 07:24:31,829 [PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775791_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41936, dest: /127.0.0.1:45408, bytes: 131072, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-730121065_1, offset: 0, srvID: 465a80b3-febd-4847-917b-1dc53950f7b6, blockid: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775791_1003, duration(ns): 42558794
2020-12-03 07:24:31,833 [PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775791_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775791_1003, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:31,833 [ResponseProcessor for block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775791_1003] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 4 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2020-12-03 07:24:31,833 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775791_1003] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775791_1003
2020-12-03 07:24:31,833 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,833 [Listener at localhost/42122] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 4 offsetInBlock: 131072 lastPacketInBlock: true lastByteOffsetInBlock: 131072, #2: blk_-9223372036854775790_1003
2020-12-03 07:24:31,833 [Listener at localhost/42122] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - #2: blk_-9223372036854775790_1003 waiting for ack for: 4
2020-12-03 07:24:31,834 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775790_1003] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, #2: blk_-9223372036854775790_1003
2020-12-03 07:24:31,835 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775790_1003] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - #2: blk_-9223372036854775790_1003 sending packet seqno: 4 offsetInBlock: 131072 lastPacketInBlock: true lastByteOffsetInBlock: 131072
2020-12-03 07:24:31,841 [PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775790_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:46024, dest: /127.0.0.1:34859, bytes: 131072, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-730121065_1, offset: 0, srvID: 1c08a3ea-8510-4f3b-8323-c247c1ad19bf, blockid: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775790_1003, duration(ns): 47226466
2020-12-03 07:24:31,852 [PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775790_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775790_1003, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:31,853 [ResponseProcessor for block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775790_1003] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 4 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2020-12-03 07:24:31,853 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775790_1003] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775790_1003
2020-12-03 07:24:31,853 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,854 [Listener at localhost/42122] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 4 offsetInBlock: 131072 lastPacketInBlock: true lastByteOffsetInBlock: 131072, #3: blk_-9223372036854775789_1003
2020-12-03 07:24:31,854 [Listener at localhost/42122] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - #3: blk_-9223372036854775789_1003 waiting for ack for: 4
2020-12-03 07:24:31,854 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775789_1003] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, #3: blk_-9223372036854775789_1003
2020-12-03 07:24:31,855 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775789_1003] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - #3: blk_-9223372036854775789_1003 sending packet seqno: 4 offsetInBlock: 131072 lastPacketInBlock: true lastByteOffsetInBlock: 131072
2020-12-03 07:24:31,859 [PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775789_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:49408, dest: /127.0.0.1:43939, bytes: 131072, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-730121065_1, offset: 0, srvID: a694dd51-5287-4646-b84f-3cf953f6fc1c, blockid: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775789_1003, duration(ns): 62811521
2020-12-03 07:24:31,859 [PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775789_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775789_1003, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:31,860 [ResponseProcessor for block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775789_1003] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 4 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2020-12-03 07:24:31,860 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775789_1003] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775789_1003
2020-12-03 07:24:31,860 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,861 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,861 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,861 [Listener at localhost/42122] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 4 offsetInBlock: 131072 lastPacketInBlock: true lastByteOffsetInBlock: 131072, #6: blk_-9223372036854775786_1003
2020-12-03 07:24:31,861 [Listener at localhost/42122] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - #6: blk_-9223372036854775786_1003 waiting for ack for: 4
2020-12-03 07:24:31,861 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775786_1003] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, #6: blk_-9223372036854775786_1003
2020-12-03 07:24:31,862 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775786_1003] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - #6: blk_-9223372036854775786_1003 sending packet seqno: 4 offsetInBlock: 131072 lastPacketInBlock: true lastByteOffsetInBlock: 131072
2020-12-03 07:24:31,866 [PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775786_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:34478, dest: /127.0.0.1:41639, bytes: 131072, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-730121065_1, offset: 0, srvID: 8aedd082-415f-407a-9939-da8f8aa1070e, blockid: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775786_1003, duration(ns): 74019300
2020-12-03 07:24:31,871 [PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775786_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775786_1003, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:31,873 [ResponseProcessor for block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775786_1003] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 4 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2020-12-03 07:24:31,873 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775786_1003] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775786_1003
2020-12-03 07:24:31,873 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,873 [Listener at localhost/42122] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 4 offsetInBlock: 131072 lastPacketInBlock: true lastByteOffsetInBlock: 131072, #7: blk_-9223372036854775785_1003
2020-12-03 07:24:31,873 [Listener at localhost/42122] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - #7: blk_-9223372036854775785_1003 waiting for ack for: 4
2020-12-03 07:24:31,873 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775785_1003] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, #7: blk_-9223372036854775785_1003
2020-12-03 07:24:31,875 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775785_1003] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - #7: blk_-9223372036854775785_1003 sending packet seqno: 4 offsetInBlock: 131072 lastPacketInBlock: true lastByteOffsetInBlock: 131072
2020-12-03 07:24:31,878 [PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775785_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:50978, dest: /127.0.0.1:46036, bytes: 131072, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-730121065_1, offset: 0, srvID: fc65a25e-b981-4606-bf42-5ab919638725, blockid: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775785_1003, duration(ns): 84417504
2020-12-03 07:24:31,878 [PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775785_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775785_1003, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:31,880 [ResponseProcessor for block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775785_1003] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 4 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2020-12-03 07:24:31,880 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775785_1003] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775785_1003
2020-12-03 07:24:31,880 [Listener at localhost/42122] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:31,881 [Listener at localhost/42122] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 4 offsetInBlock: 131072 lastPacketInBlock: true lastByteOffsetInBlock: 131072, #8: blk_-9223372036854775784_1003
2020-12-03 07:24:31,881 [Listener at localhost/42122] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - #8: blk_-9223372036854775784_1003 waiting for ack for: 4
2020-12-03 07:24:31,881 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775784_1003] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, #8: blk_-9223372036854775784_1003
2020-12-03 07:24:31,883 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775784_1003] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - #8: blk_-9223372036854775784_1003 sending packet seqno: 4 offsetInBlock: 131072 lastPacketInBlock: true lastByteOffsetInBlock: 131072
2020-12-03 07:24:31,886 [PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775784_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59954, dest: /127.0.0.1:40699, bytes: 131072, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-730121065_1, offset: 0, srvID: 67bdfdb6-f4be-4592-925f-42e7b62de913, blockid: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775784_1003, duration(ns): 91956296
2020-12-03 07:24:31,886 [PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775784_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775784_1003, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:31,887 [ResponseProcessor for block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775784_1003] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 4 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2020-12-03 07:24:31,887 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775784_1003] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775784_1003
2020-12-03 07:24:31,894 [IPC Server handler 0 on default port 37942] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] is closed by DFSClient_NONMAPREDUCE_-730121065_1
2020-12-03 07:24:31,897 [Listener at localhost/42122] WARN  hdfs.DFSOutputStream (DFSStripedOutputStream.java:logCorruptBlocks(1308)) - Block group <1> failed to write 2 blocks.
2020-12-03 07:24:31,901 [IPC Server handler 4 on default port 37942] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getErasureCodingPolicy	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:31,909 [IPC Server handler 3 on default port 37942] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906]	dst=null	perm=null	proto=rpc
2020-12-03 07:24:31,918 [Listener at localhost/42122] INFO  hdfs.StripedFileTestUtil (StripedFileTestUtil.java:waitBlockGroupsReported(290)) - All blockGroups of file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906] verified to have all internalBlocks.
2020-12-03 07:24:31,920 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:37942
2020-12-03 07:24:31,922 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x43a05e31390c5be2: from storage DS-dbecbb28-d168-4eb9-ba31-b857b3014299 node DatanodeRegistration(127.0.0.1:41639, datanodeUuid=8aedd082-415f-407a-9939-da8f8aa1070e, infoPort=41408, infoSecurePort=0, ipcPort=40858, storageInfo=lv=-57;cid=testClusterID;nsid=728208751;c=1606980263805), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:31,922 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x43a05e31390c5be2: from storage DS-4a408526-9e3d-400e-9c97-b7f2da3ca414 node DatanodeRegistration(127.0.0.1:41639, datanodeUuid=8aedd082-415f-407a-9939-da8f8aa1070e, infoPort=41408, infoSecurePort=0, ipcPort=40858, storageInfo=lv=-57;cid=testClusterID;nsid=728208751;c=1606980263805), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:31,923 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x43a05e31390c5be2,  containing 2 storage report(s), of which we sent 2. The reports had 1 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:31,923 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:32,021 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:37942
2020-12-03 07:24:32,022 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x745b853ee6303f74: from storage DS-2b1930b4-e95b-4943-b1ab-05b98259886a node DatanodeRegistration(127.0.0.1:46036, datanodeUuid=fc65a25e-b981-4606-bf42-5ab919638725, infoPort=36214, infoSecurePort=0, ipcPort=36510, storageInfo=lv=-57;cid=testClusterID;nsid=728208751;c=1606980263805), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:32,023 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x745b853ee6303f74: from storage DS-64b240c2-d3e0-4acf-93d6-cebd18220651 node DatanodeRegistration(127.0.0.1:46036, datanodeUuid=fc65a25e-b981-4606-bf42-5ab919638725, infoPort=36214, infoSecurePort=0, ipcPort=36510, storageInfo=lv=-57;cid=testClusterID;nsid=728208751;c=1606980263805), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:32,023 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x745b853ee6303f74,  containing 2 storage report(s), of which we sent 2. The reports had 1 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:32,023 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:32,121 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:37942
2020-12-03 07:24:32,122 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xd89fa387af04d7e9: from storage DS-8c30b030-99db-4142-8d95-5495cf2e3bb5 node DatanodeRegistration(127.0.0.1:45408, datanodeUuid=465a80b3-febd-4847-917b-1dc53950f7b6, infoPort=46309, infoSecurePort=0, ipcPort=38179, storageInfo=lv=-57;cid=testClusterID;nsid=728208751;c=1606980263805), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:32,122 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xd89fa387af04d7e9: from storage DS-3ce64bf6-e24c-4061-a4ce-b388ab5aa2c5 node DatanodeRegistration(127.0.0.1:45408, datanodeUuid=465a80b3-febd-4847-917b-1dc53950f7b6, infoPort=46309, infoSecurePort=0, ipcPort=38179, storageInfo=lv=-57;cid=testClusterID;nsid=728208751;c=1606980263805), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:32,123 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xd89fa387af04d7e9,  containing 2 storage report(s), of which we sent 2. The reports had 1 total blocks and used 1 RPC(s). This took 0 msec to generate and 1 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:32,123 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:32,221 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:37942
2020-12-03 07:24:32,223 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x2807eb3c71808c4d: from storage DS-c69444b7-75df-4430-81d2-ce7868dd7889 node DatanodeRegistration(127.0.0.1:34859, datanodeUuid=1c08a3ea-8510-4f3b-8323-c247c1ad19bf, infoPort=44221, infoSecurePort=0, ipcPort=44273, storageInfo=lv=-57;cid=testClusterID;nsid=728208751;c=1606980263805), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:32,223 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x2807eb3c71808c4d: from storage DS-59fe4be7-7d46-4bcc-944e-0f4b194e3df4 node DatanodeRegistration(127.0.0.1:34859, datanodeUuid=1c08a3ea-8510-4f3b-8323-c247c1ad19bf, infoPort=44221, infoSecurePort=0, ipcPort=44273, storageInfo=lv=-57;cid=testClusterID;nsid=728208751;c=1606980263805), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:32,224 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x2807eb3c71808c4d,  containing 2 storage report(s), of which we sent 2. The reports had 1 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:32,224 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:32,321 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:37942
2020-12-03 07:24:32,323 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xc0289ce2ffc580a1: from storage DS-5eaccf1b-8417-47bc-a260-6b7d108d3890 node DatanodeRegistration(127.0.0.1:43939, datanodeUuid=a694dd51-5287-4646-b84f-3cf953f6fc1c, infoPort=44791, infoSecurePort=0, ipcPort=40240, storageInfo=lv=-57;cid=testClusterID;nsid=728208751;c=1606980263805), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:32,323 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xc0289ce2ffc580a1: from storage DS-05560e71-949b-4174-be33-ae1a2a0941d8 node DatanodeRegistration(127.0.0.1:43939, datanodeUuid=a694dd51-5287-4646-b84f-3cf953f6fc1c, infoPort=44791, infoSecurePort=0, ipcPort=40240, storageInfo=lv=-57;cid=testClusterID;nsid=728208751;c=1606980263805), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:32,324 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xc0289ce2ffc580a1,  containing 2 storage report(s), of which we sent 2. The reports had 1 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:32,324 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:32,432 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:37942
2020-12-03 07:24:32,435 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xe23325330b2bf8cb: from storage DS-fed01141-fff1-42c6-b3e3-2fd935c70283 node DatanodeRegistration(127.0.0.1:40699, datanodeUuid=67bdfdb6-f4be-4592-925f-42e7b62de913, infoPort=46821, infoSecurePort=0, ipcPort=36341, storageInfo=lv=-57;cid=testClusterID;nsid=728208751;c=1606980263805), blocks: 1, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:24:32,435 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xe23325330b2bf8cb: from storage DS-d11be790-a115-4b62-b13d-a4d0d7a30b7a node DatanodeRegistration(127.0.0.1:40699, datanodeUuid=67bdfdb6-f4be-4592-925f-42e7b62de913, infoPort=46821, infoSecurePort=0, ipcPort=36341, storageInfo=lv=-57;cid=testClusterID;nsid=728208751;c=1606980263805), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:32,436 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xe23325330b2bf8cb,  containing 2 storage report(s), of which we sent 2. The reports had 1 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:32,436 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:32,521 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:37942
2020-12-03 07:24:32,522 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x349c2620298419a2: from storage DS-0539376e-ad17-43e8-b692-2105b79e3e6f node DatanodeRegistration(127.0.0.1:41151, datanodeUuid=1f53bb69-aae2-4eb5-9dde-35ced37b4811, infoPort=45134, infoSecurePort=0, ipcPort=42122, storageInfo=lv=-57;cid=testClusterID;nsid=728208751;c=1606980263805), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:32,523 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x349c2620298419a2: from storage DS-713fdee5-399a-4945-8293-dd270e62d1e4 node DatanodeRegistration(127.0.0.1:41151, datanodeUuid=1f53bb69-aae2-4eb5-9dde-35ced37b4811, infoPort=45134, infoSecurePort=0, ipcPort=42122, storageInfo=lv=-57;cid=testClusterID;nsid=728208751;c=1606980263805), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:32,523 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x349c2620298419a2,  containing 2 storage report(s), of which we sent 2. The reports had 1 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:32,523 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:32,624 [IPC Server handler 7 on default port 37942] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906]	dst=null	perm=null	proto=rpc
2020-12-03 07:24:32,626 [IPC Server handler 1 on default port 37942] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len655360kill[218453, 436906]	dst=null	perm=null	proto=rpc
2020-12-03 07:24:32,631 [IPC Server handler 8 on default port 37942] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getErasureCodingPolicy	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:32,631 [Listener at localhost/42122] INFO  hdfs.StripedFileTestUtil (StripedFileTestUtil.java:checkData(385)) - gs=1003, oldGS=1002
2020-12-03 07:24:32,632 [Listener at localhost/42122] INFO  hdfs.StripedFileTestUtil (StripedFileTestUtil.java:checkData(425)) - i,j=0, 0, numCellInBlock=2, blockSize=131072, lb=LocatedBlock{BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775792_1003; getBlockSize()=131072; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41151,DS-0539376e-ad17-43e8-b692-2105b79e3e6f,DISK]]}
2020-12-03 07:24:32,675 [Listener at localhost/42122] INFO  hdfs.StripedFileTestUtil (StripedFileTestUtil.java:checkData(425)) - i,j=1, 1, numCellInBlock=2, blockSize=131072, lb=LocatedBlock{BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775791_1003; getBlockSize()=131072; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45408,DS-8c30b030-99db-4142-8d95-5495cf2e3bb5,DISK]]}
2020-12-03 07:24:32,678 [Listener at localhost/42122] INFO  hdfs.StripedFileTestUtil (StripedFileTestUtil.java:checkData(425)) - i,j=2, 2, numCellInBlock=2, blockSize=131072, lb=LocatedBlock{BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775790_1003; getBlockSize()=131072; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34859,DS-c69444b7-75df-4430-81d2-ce7868dd7889,DISK]]}
2020-12-03 07:24:32,680 [Listener at localhost/42122] INFO  hdfs.StripedFileTestUtil (StripedFileTestUtil.java:checkData(425)) - i,j=3, 3, numCellInBlock=2, blockSize=131072, lb=LocatedBlock{BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775789_1003; getBlockSize()=131072; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43939,DS-5eaccf1b-8417-47bc-a260-6b7d108d3890,DISK]]}
2020-12-03 07:24:32,683 [Listener at localhost/42122] INFO  hdfs.StripedFileTestUtil (StripedFileTestUtil.java:checkData(425)) - i,j=4, 4, numCellInBlock=1, blockSize=65536, lb=null
2020-12-03 07:24:32,683 [Listener at localhost/42122] INFO  hdfs.StripedFileTestUtil (StripedFileTestUtil.java:checkData(425)) - i,j=5, 5, numCellInBlock=1, blockSize=65536, lb=null
2020-12-03 07:24:32,683 [Listener at localhost/42122] INFO  hdfs.StripedFileTestUtil (StripedFileTestUtil.java:checkData(425)) - i,j=6, 0, numCellInBlock=2, blockSize=131072, lb=LocatedBlock{BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775786_1003; getBlockSize()=131072; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41639,DS-dbecbb28-d168-4eb9-ba31-b857b3014299,DISK]]}
2020-12-03 07:24:32,685 [Listener at localhost/42122] INFO  hdfs.StripedFileTestUtil (StripedFileTestUtil.java:checkData(425)) - i,j=7, 0, numCellInBlock=2, blockSize=131072, lb=LocatedBlock{BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775785_1003; getBlockSize()=131072; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46036,DS-64b240c2-d3e0-4acf-93d6-cebd18220651,DISK]]}
2020-12-03 07:24:32,688 [Listener at localhost/42122] INFO  hdfs.StripedFileTestUtil (StripedFileTestUtil.java:checkData(425)) - i,j=8, 0, numCellInBlock=2, blockSize=131072, lb=LocatedBlock{BP-101448600-172.17.0.4-1606980263805:blk_-9223372036854775784_1003; getBlockSize()=131072; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40699,DS-fed01141-fff1-42c6-b3e3-2fd935c70283,DISK]]}
2020-12-03 07:24:32,690 [Listener at localhost/42122] INFO  hdfs.StripedFileTestUtil (StripedFileTestUtil.java:checkData(446)) - Internal blocks to check: [0, 1, 2, 3, 6, 7, 8]
2020-12-03 07:24:33,042 [Listener at localhost/42122] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:24:33,043 [Listener at localhost/42122] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 6
2020-12-03 07:24:33,043 [Listener at localhost/42122] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:24:33,043 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@315ba14a] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:24:33,050 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-0539376e-ad17-43e8-b692-2105b79e3e6f) exiting.
2020-12-03 07:24:33,050 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-713fdee5-399a-4945-8293-dd270e62d1e4) exiting.
2020-12-03 07:24:33,069 [Listener at localhost/42122] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@2c1dc8e{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:24:33,070 [Listener at localhost/42122] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@b273a59{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:33,070 [Listener at localhost/42122] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@273c947f{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:33,070 [Listener at localhost/42122] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@50cf5a23{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:33,071 [Listener at localhost/42122] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 42122
2020-12-03 07:24:33,075 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:33,077 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:33,080 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:24:33,081 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-101448600-172.17.0.4-1606980263805 (Datanode Uuid 1f53bb69-aae2-4eb5-9dde-35ced37b4811) service to localhost/127.0.0.1:37942
2020-12-03 07:24:33,081 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-101448600-172.17.0.4-1606980263805 (Datanode Uuid 1f53bb69-aae2-4eb5-9dde-35ced37b4811)
2020-12-03 07:24:33,081 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:33,082 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-101448600-172.17.0.4-1606980263805] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:33,082 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-101448600-172.17.0.4-1606980263805] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:33,103 [Listener at localhost/42122] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:24:33,104 [Listener at localhost/42122] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:24:33,106 [Listener at localhost/42122] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:24:33,106 [Listener at localhost/42122] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:24:33,109 [Listener at localhost/42122] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:24:33,109 [Listener at localhost/42122] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 5
2020-12-03 07:24:33,109 [Listener at localhost/42122] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:24:33,109 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@117632cf] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:24:33,111 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-d11be790-a115-4b62-b13d-a4d0d7a30b7a) exiting.
2020-12-03 07:24:33,111 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-fed01141-fff1-42c6-b3e3-2fd935c70283) exiting.
2020-12-03 07:24:33,132 [Listener at localhost/42122] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5c371e13{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:24:33,133 [Listener at localhost/42122] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@530a8454{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:33,134 [Listener at localhost/42122] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@17ae98d7{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:33,134 [Listener at localhost/42122] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@57dc9128{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:33,136 [Listener at localhost/42122] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 36341
2020-12-03 07:24:33,149 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:33,149 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:33,149 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:24:33,149 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-101448600-172.17.0.4-1606980263805 (Datanode Uuid 67bdfdb6-f4be-4592-925f-42e7b62de913) service to localhost/127.0.0.1:37942
2020-12-03 07:24:33,150 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-101448600-172.17.0.4-1606980263805 (Datanode Uuid 67bdfdb6-f4be-4592-925f-42e7b62de913)
2020-12-03 07:24:33,150 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:33,151 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-101448600-172.17.0.4-1606980263805] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:33,155 [Listener at localhost/42122] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:24:33,156 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-101448600-172.17.0.4-1606980263805] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:33,156 [Listener at localhost/42122] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:24:33,158 [Listener at localhost/42122] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:24:33,159 [Listener at localhost/42122] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:24:33,162 [Listener at localhost/42122] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:24:33,162 [Listener at localhost/42122] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 4
2020-12-03 07:24:33,162 [Listener at localhost/42122] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:24:33,162 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@5b69fd74] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:24:33,164 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-05560e71-949b-4174-be33-ae1a2a0941d8) exiting.
2020-12-03 07:24:33,164 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-5eaccf1b-8417-47bc-a260-6b7d108d3890) exiting.
2020-12-03 07:24:33,183 [Listener at localhost/42122] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@74a9c4b0{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:24:33,184 [Listener at localhost/42122] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@85ec632{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:33,185 [Listener at localhost/42122] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@61e3a1fd{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:33,185 [Listener at localhost/42122] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@271f18d3{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:33,186 [Listener at localhost/42122] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 40240
2020-12-03 07:24:33,193 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:33,193 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:33,195 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:24:33,195 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-101448600-172.17.0.4-1606980263805 (Datanode Uuid a694dd51-5287-4646-b84f-3cf953f6fc1c) service to localhost/127.0.0.1:37942
2020-12-03 07:24:33,195 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-101448600-172.17.0.4-1606980263805 (Datanode Uuid a694dd51-5287-4646-b84f-3cf953f6fc1c)
2020-12-03 07:24:33,195 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:33,196 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-101448600-172.17.0.4-1606980263805] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:33,197 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-101448600-172.17.0.4-1606980263805] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:33,208 [Listener at localhost/42122] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:24:33,208 [Listener at localhost/42122] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:24:33,210 [Listener at localhost/42122] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:24:33,210 [Listener at localhost/42122] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:24:33,213 [Listener at localhost/42122] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:24:33,213 [Listener at localhost/42122] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 3
2020-12-03 07:24:33,214 [Listener at localhost/42122] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:24:33,214 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@50d68830] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:24:33,216 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-59fe4be7-7d46-4bcc-944e-0f4b194e3df4) exiting.
2020-12-03 07:24:33,216 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-c69444b7-75df-4430-81d2-ce7868dd7889) exiting.
2020-12-03 07:24:33,219 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-101448600-172.17.0.4-1606980263805 (Datanode Uuid 1c08a3ea-8510-4f3b-8323-c247c1ad19bf) service to localhost/127.0.0.1:37942
2020-12-03 07:24:33,219 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-101448600-172.17.0.4-1606980263805 (Datanode Uuid 1c08a3ea-8510-4f3b-8323-c247c1ad19bf)
2020-12-03 07:24:33,219 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:33,220 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-101448600-172.17.0.4-1606980263805] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:33,220 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-101448600-172.17.0.4-1606980263805] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:33,233 [Listener at localhost/42122] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@3e792ce3{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:24:33,234 [Listener at localhost/42122] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@53bc1328{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:33,235 [Listener at localhost/42122] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7561db12{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:33,235 [Listener at localhost/42122] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@a23a01d{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:33,236 [Listener at localhost/42122] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 44273
2020-12-03 07:24:33,243 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:33,243 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:33,246 [Listener at localhost/42122] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:24:33,247 [Listener at localhost/42122] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:24:33,248 [Listener at localhost/42122] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:24:33,248 [Listener at localhost/42122] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:24:33,252 [Listener at localhost/42122] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:24:33,252 [Listener at localhost/42122] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 2
2020-12-03 07:24:33,253 [Listener at localhost/42122] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:24:33,253 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@29d2d081] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:24:33,255 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-3ce64bf6-e24c-4061-a4ce-b388ab5aa2c5) exiting.
2020-12-03 07:24:33,255 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-8c30b030-99db-4142-8d95-5495cf2e3bb5) exiting.
2020-12-03 07:24:33,271 [Listener at localhost/42122] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@610db97e{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:24:33,272 [Listener at localhost/42122] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6f0628de{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:33,273 [Listener at localhost/42122] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@47d93e0d{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:33,273 [Listener at localhost/42122] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1bc53649{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:33,274 [Listener at localhost/42122] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 38179
2020-12-03 07:24:33,283 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:33,283 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:33,283 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:24:33,286 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-101448600-172.17.0.4-1606980263805 (Datanode Uuid 465a80b3-febd-4847-917b-1dc53950f7b6) service to localhost/127.0.0.1:37942
2020-12-03 07:24:33,286 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-101448600-172.17.0.4-1606980263805 (Datanode Uuid 465a80b3-febd-4847-917b-1dc53950f7b6)
2020-12-03 07:24:33,286 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:33,289 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-101448600-172.17.0.4-1606980263805] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:33,290 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-101448600-172.17.0.4-1606980263805] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:33,292 [Listener at localhost/42122] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:24:33,292 [Listener at localhost/42122] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:24:33,294 [Listener at localhost/42122] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:24:33,294 [Listener at localhost/42122] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:24:33,298 [Listener at localhost/42122] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:24:33,298 [Listener at localhost/42122] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 1
2020-12-03 07:24:33,299 [Listener at localhost/42122] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:24:33,299 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@77b7ffa4] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:24:33,301 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-2b1930b4-e95b-4943-b1ab-05b98259886a) exiting.
2020-12-03 07:24:33,301 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-64b240c2-d3e0-4acf-93d6-cebd18220651) exiting.
2020-12-03 07:24:33,317 [Listener at localhost/42122] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@2a551a63{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:24:33,318 [Listener at localhost/42122] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@1a6f5124{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:33,318 [Listener at localhost/42122] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3d4d3fe7{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:33,318 [Listener at localhost/42122] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2102a4d5{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:33,320 [Listener at localhost/42122] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 36510
2020-12-03 07:24:33,327 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:33,327 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:24:33,327 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:33,327 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-101448600-172.17.0.4-1606980263805 (Datanode Uuid fc65a25e-b981-4606-bf42-5ab919638725) service to localhost/127.0.0.1:37942
2020-12-03 07:24:33,327 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-101448600-172.17.0.4-1606980263805 (Datanode Uuid fc65a25e-b981-4606-bf42-5ab919638725)
2020-12-03 07:24:33,328 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:33,332 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-101448600-172.17.0.4-1606980263805] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:33,332 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-101448600-172.17.0.4-1606980263805] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:33,335 [Listener at localhost/42122] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:24:33,335 [Listener at localhost/42122] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:24:33,339 [Listener at localhost/42122] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:24:33,339 [Listener at localhost/42122] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:24:33,344 [Listener at localhost/42122] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:24:33,347 [Listener at localhost/42122] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:24:33,347 [Listener at localhost/42122] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:24:33,347 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@b40bb6e] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:24:33,351 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-4a408526-9e3d-400e-9c97-b7f2da3ca414) exiting.
2020-12-03 07:24:33,351 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-dbecbb28-d168-4eb9-ba31-b857b3014299) exiting.
2020-12-03 07:24:33,369 [Listener at localhost/42122] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@235f4c10{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:24:33,370 [Listener at localhost/42122] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@743cb8e0{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:33,370 [Listener at localhost/42122] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@76ba13c{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:33,370 [Listener at localhost/42122] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@61526469{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:33,372 [Listener at localhost/42122] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 40858
2020-12-03 07:24:33,378 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:33,379 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:24:33,379 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:33,382 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-101448600-172.17.0.4-1606980263805 (Datanode Uuid 8aedd082-415f-407a-9939-da8f8aa1070e) service to localhost/127.0.0.1:37942
2020-12-03 07:24:33,498 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-101448600-172.17.0.4-1606980263805 (Datanode Uuid 8aedd082-415f-407a-9939-da8f8aa1070e)
2020-12-03 07:24:33,498 [BP-101448600-172.17.0.4-1606980263805 heartbeating to localhost/127.0.0.1:37942] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-101448600-172.17.0.4-1606980263805
2020-12-03 07:24:33,503 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-101448600-172.17.0.4-1606980263805] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:33,505 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-101448600-172.17.0.4-1606980263805] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:33,509 [Listener at localhost/42122] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:24:33,510 [Listener at localhost/42122] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:24:33,518 [Listener at localhost/42122] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:24:33,532 [Listener at localhost/42122] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:24:33,563 [Listener at localhost/42122] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:24:33,564 [Listener at localhost/42122] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:24:33,564 [Listener at localhost/42122] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:24:33,565 [Listener at localhost/42122] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 1, 19
2020-12-03 07:24:33,565 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@7a8fa663] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:24:33,565 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@3a62c01e] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:24:33,566 [Listener at localhost/42122] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 20 Total time for transactions(ms): 25 Number of transactions batched in Syncs: 0 Number of syncs: 21 SyncTimes(ms): 3 1 
2020-12-03 07:24:33,923 [Listener at localhost/42122] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000020
2020-12-03 07:24:33,927 [Listener at localhost/42122] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000020
2020-12-03 07:24:33,928 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:24:33,928 [CacheReplicationMonitor(1424378291)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:24:33,936 [Listener at localhost/42122] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 37942
2020-12-03 07:24:33,940 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:33,940 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:33,943 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:24:33,943 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:24:33,981 [Listener at localhost/42122] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:24:33,981 [Listener at localhost/42122] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:24:33,982 [Listener at localhost/42122] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@266374ef{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:24:33,984 [Listener at localhost/42122] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@1f81aa00{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:33,984 [Listener at localhost/42122] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@37313c65{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:33,985 [Listener at localhost/42122] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@508dec2b{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:33,986 [Listener at localhost/42122] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-12-03 07:24:34,011 [Listener at localhost/42122] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-12-03 07:24:34,014 [Listener at localhost/42122] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-12-03 07:24:34,036 [Listener at localhost/42122] INFO  hdfs.TestDFSStripedOutputStreamWithFailure (TestDFSStripedOutputStreamWithFailure.java:testCloseWithExceptionsInStreamer(257)) - runTestWithMultipleFailure2: length==393339, killPos=[131113, 262226], dnIndex=[4, 5]
NUM_DATA_BLOCKS  = 6
NUM_PARITY_BLOCKS= 3
CELL_SIZE        = 65536 (=64 KB)
BLOCK_SIZE       = 262144 (=256 KB)
BLOCK_GROUP_SIZE = 1572864 (=1.50 MB)
2020-12-03 07:24:34,037 [Listener at localhost/42122] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=9
Formatting using clusterid: testClusterID
2020-12-03 07:24:34,041 [Listener at localhost/42122] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:24:34,042 [Listener at localhost/42122] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:24:34,042 [Listener at localhost/42122] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:24:34,042 [Listener at localhost/42122] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:24:34,043 [Listener at localhost/42122] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:24:34,043 [Listener at localhost/42122] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:24:34,043 [Listener at localhost/42122] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:24:34,043 [Listener at localhost/42122] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:24:34,044 [Listener at localhost/42122] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:34,044 [Listener at localhost/42122] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:24:34,045 [Listener at localhost/42122] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=20, effected=1000
2020-12-03 07:24:34,045 [Listener at localhost/42122] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:24:34,045 [Listener at localhost/42122] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:24:34,045 [Listener at localhost/42122] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:24:34,046 [Listener at localhost/42122] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:24:34
2020-12-03 07:24:34,046 [Listener at localhost/42122] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:24:34,046 [Listener at localhost/42122] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:34,046 [Listener at localhost/42122] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:24:34,047 [Listener at localhost/42122] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:24:34,053 [Listener at localhost/42122] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:24:34,053 [Listener at localhost/42122] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:24:34,054 [Listener at localhost/42122] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:24:34,054 [Listener at localhost/42122] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:24:34,054 [Listener at localhost/42122] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:24:34,054 [Listener at localhost/42122] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:24:34,054 [Listener at localhost/42122] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:24:34,055 [Listener at localhost/42122] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:24:34,055 [Listener at localhost/42122] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:24:34,055 [Listener at localhost/42122] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:24:34,055 [Listener at localhost/42122] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:24:34,055 [Listener at localhost/42122] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:24:34,055 [Listener at localhost/42122] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 0
2020-12-03 07:24:34,055 [Listener at localhost/42122] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:24:34,055 [Listener at localhost/42122] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:24:34,056 [Listener at localhost/42122] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:24:34,056 [Listener at localhost/42122] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:24:34,056 [Listener at localhost/42122] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:34,057 [Listener at localhost/42122] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:24:34,057 [Listener at localhost/42122] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:24:34,060 [Listener at localhost/42122] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:24:34,060 [Listener at localhost/42122] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:24:34,060 [Listener at localhost/42122] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:24:34,060 [Listener at localhost/42122] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:24:34,061 [Listener at localhost/42122] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:24:34,061 [Listener at localhost/42122] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:24:34,061 [Listener at localhost/42122] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:24:34,061 [Listener at localhost/42122] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:34,061 [Listener at localhost/42122] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:24:34,062 [Listener at localhost/42122] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:24:34,063 [Listener at localhost/42122] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:24:34,063 [Listener at localhost/42122] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:24:34,063 [Listener at localhost/42122] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:24:34,064 [Listener at localhost/42122] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:24:34,064 [Listener at localhost/42122] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:24:34,064 [Listener at localhost/42122] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:24:34,064 [Listener at localhost/42122] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:34,065 [Listener at localhost/42122] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:24:34,065 [Listener at localhost/42122] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:24:34,066 [Listener at localhost/42122] INFO  namenode.FSImage (FSImage.java:format(185)) - Allocated new BlockPoolId: BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:34,252 [Listener at localhost/42122] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-12-03 07:24:34,398 [Listener at localhost/42122] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-12-03 07:24:34,427 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:24:34,427 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:24:34,435 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 451 bytes saved in 0 seconds .
2020-12-03 07:24:34,435 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 451 bytes saved in 0 seconds .
2020-12-03 07:24:34,485 [Listener at localhost/42122] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-12-03 07:24:34,487 [Listener at localhost/42122] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:24:34,489 [Listener at localhost/42122] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:24:34,490 [Listener at localhost/42122] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:24:34,490 [Listener at localhost/42122] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:24:34,492 [Listener at localhost/42122] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-12-03 07:24:34,529 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@49798e84] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:34,529 [Listener at localhost/42122] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:24:34,530 [Listener at localhost/42122] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:34,531 [Listener at localhost/42122] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:34,532 [Listener at localhost/42122] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:24:34,532 [Listener at localhost/42122] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:34,534 [Listener at localhost/42122] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:34,534 [Listener at localhost/42122] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:24:34,535 [Listener at localhost/42122] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:34,535 [Listener at localhost/42122] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:34,536 [Listener at localhost/42122] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:24:34,536 [Listener at localhost/42122] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:24:34,537 [Listener at localhost/42122] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 35271
2020-12-03 07:24:34,537 [Listener at localhost/42122] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:34,539 [Listener at localhost/42122] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@27c04377{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:34,540 [Listener at localhost/42122] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@67403656{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:34,546 [Listener at localhost/42122] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@38a1c423{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:24:34,547 [Listener at localhost/42122] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@336365bc{HTTP/1.1,[http/1.1]}{localhost:35271}
2020-12-03 07:24:34,550 [Listener at localhost/42122] INFO  server.Server (Server.java:doStart(419)) - Started @12946ms
2020-12-03 07:24:34,552 [Listener at localhost/42122] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:24:34,553 [Listener at localhost/42122] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:24:34,553 [Listener at localhost/42122] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:24:34,553 [Listener at localhost/42122] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:24:34,553 [Listener at localhost/42122] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:24:34,554 [Listener at localhost/42122] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:24:34,554 [Listener at localhost/42122] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:24:34,554 [Listener at localhost/42122] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:24:34,554 [Listener at localhost/42122] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:34,555 [Listener at localhost/42122] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:24:34,555 [Listener at localhost/42122] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=20, effected=1000
2020-12-03 07:24:34,555 [Listener at localhost/42122] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:24:34,555 [Listener at localhost/42122] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:24:34,555 [Listener at localhost/42122] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:24:34,556 [Listener at localhost/42122] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:24:34
2020-12-03 07:24:34,556 [Listener at localhost/42122] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:24:34,556 [Listener at localhost/42122] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:34,556 [Listener at localhost/42122] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:24:34,556 [Listener at localhost/42122] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:24:34,564 [Listener at localhost/42122] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:24:34,564 [Listener at localhost/42122] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:24:34,565 [Listener at localhost/42122] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:24:34,565 [Listener at localhost/42122] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:24:34,565 [Listener at localhost/42122] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:24:34,565 [Listener at localhost/42122] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:24:34,565 [Listener at localhost/42122] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:24:34,566 [Listener at localhost/42122] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:24:34,566 [Listener at localhost/42122] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:24:34,566 [Listener at localhost/42122] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:24:34,566 [Listener at localhost/42122] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:24:34,566 [Listener at localhost/42122] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:24:34,566 [Listener at localhost/42122] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 0
2020-12-03 07:24:34,566 [Listener at localhost/42122] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:24:34,567 [Listener at localhost/42122] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:24:34,567 [Listener at localhost/42122] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:24:34,567 [Listener at localhost/42122] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:24:34,567 [Listener at localhost/42122] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:34,568 [Listener at localhost/42122] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:24:34,568 [Listener at localhost/42122] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:24:34,573 [Listener at localhost/42122] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:24:34,573 [Listener at localhost/42122] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:24:34,573 [Listener at localhost/42122] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:24:34,573 [Listener at localhost/42122] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:24:34,573 [Listener at localhost/42122] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:24:34,573 [Listener at localhost/42122] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:24:34,573 [Listener at localhost/42122] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:24:34,574 [Listener at localhost/42122] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:34,574 [Listener at localhost/42122] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:24:34,574 [Listener at localhost/42122] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:24:34,576 [Listener at localhost/42122] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:24:34,576 [Listener at localhost/42122] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:24:34,576 [Listener at localhost/42122] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:24:34,576 [Listener at localhost/42122] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:24:34,576 [Listener at localhost/42122] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:24:34,576 [Listener at localhost/42122] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:24:34,576 [Listener at localhost/42122] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:24:34,577 [Listener at localhost/42122] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:24:34,577 [Listener at localhost/42122] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:24:34,613 [Listener at localhost/42122] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 11600@0b2162a51c02
2020-12-03 07:24:34,669 [Listener at localhost/42122] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 11600@0b2162a51c02
2020-12-03 07:24:34,670 [Listener at localhost/42122] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-12-03 07:24:34,671 [Listener at localhost/42122] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-12-03 07:24:34,671 [Listener at localhost/42122] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:24:34,671 [Listener at localhost/42122] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:24:34,676 [Listener at localhost/42122] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:24:34,677 [Listener at localhost/42122] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:24:34,678 [Listener at localhost/42122] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-12-03 07:24:34,678 [Listener at localhost/42122] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:24:34,679 [Listener at localhost/42122] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 1
2020-12-03 07:24:34,808 [Listener at localhost/42122] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:24:34,808 [Listener at localhost/42122] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 231 msecs
2020-12-03 07:24:34,809 [Listener at localhost/42122] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:24:34,810 [Listener at localhost/42122] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:34,811 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:34,817 [Listener at localhost/42543] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:42543 to access this namenode/service.
2020-12-03 07:24:34,818 [Listener at localhost/42543] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:24:34,857 [Listener at localhost/42543] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:24:34,858 [Listener at localhost/42543] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:24:34,859 [Listener at localhost/42543] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:24:34,859 [Listener at localhost/42543] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:24:34,859 [Listener at localhost/42543] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:24:34,864 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 0
2020-12-03 07:24:34,864 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:24:34,864 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:24:34,865 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:24:34,865 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:24:34,865 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 6 msec
2020-12-03 07:24:34,868 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:34,868 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:34,873 [Listener at localhost/42543] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:42543
2020-12-03 07:24:34,873 [Listener at localhost/42543] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:24:34,873 [Listener at localhost/42543] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:24:34,874 [Listener at localhost/42543] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 1 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:24:34,882 [CacheReplicationMonitor(1458703896)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:24:34,910 [Listener at localhost/42543] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:24:34,911 [Listener at localhost/42543] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:24:34,912 [Listener at localhost/42543] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:24:34,917 [Listener at localhost/42543] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:24:34,917 [Listener at localhost/42543] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:34,917 [Listener at localhost/42543] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:24:34,918 [Listener at localhost/42543] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:24:34,918 [Listener at localhost/42543] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:34,918 [Listener at localhost/42543] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:24:34,918 [Listener at localhost/42543] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:24:34,918 [Listener at localhost/42543] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:24:34,919 [Listener at localhost/42543] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:46077
2020-12-03 07:24:34,919 [Listener at localhost/42543] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:24:34,919 [Listener at localhost/42543] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:24:34,921 [Listener at localhost/42543] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:34,922 [Listener at localhost/42543] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:34,923 [Listener at localhost/42543] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:24:34,923 [Listener at localhost/42543] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:34,925 [Listener at localhost/42543] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:34,925 [Listener at localhost/42543] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:24:34,925 [Listener at localhost/42543] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:34,926 [Listener at localhost/42543] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:34,926 [Listener at localhost/42543] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 41739
2020-12-03 07:24:34,926 [Listener at localhost/42543] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:34,928 [Listener at localhost/42543] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2a27cb34{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:34,928 [Listener at localhost/42543] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6fd1660{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:34,934 [Listener at localhost/42543] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@476a736d{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:24:34,934 [Listener at localhost/42543] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@5f80fa43{HTTP/1.1,[http/1.1]}{localhost:41739}
2020-12-03 07:24:34,938 [Listener at localhost/42543] INFO  server.Server (Server.java:doStart(419)) - Started @13333ms
2020-12-03 07:24:34,959 [Listener at localhost/42543] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:43965
2020-12-03 07:24:34,961 [Listener at localhost/42543] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:24:34,962 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7159139f] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:34,962 [Listener at localhost/42543] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:24:34,962 [Listener at localhost/42543] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:34,963 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:34,968 [Listener at localhost/33305] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:33305
2020-12-03 07:24:35,007 [Listener at localhost/33305] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:24:35,007 [Listener at localhost/33305] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:24:35,008 [Thread-492] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42543 starting to offer service
2020-12-03 07:24:35,018 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:35,019 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:35,032 [Listener at localhost/33305] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:24:35,039 [Listener at localhost/33305] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:24:35,039 [Thread-492] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42543
2020-12-03 07:24:35,041 [Listener at localhost/33305] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:24:35,042 [Thread-492] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:24:35,044 [Listener at localhost/33305] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:24:35,045 [Listener at localhost/33305] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:35,045 [Listener at localhost/33305] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:24:35,045 [Listener at localhost/33305] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:24:35,045 [Listener at localhost/33305] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:35,046 [Listener at localhost/33305] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:24:35,046 [Listener at localhost/33305] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:24:35,046 [Listener at localhost/33305] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:24:35,047 [Listener at localhost/33305] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:45564
2020-12-03 07:24:35,047 [Listener at localhost/33305] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:24:35,047 [Listener at localhost/33305] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:24:35,048 [Listener at localhost/33305] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:35,049 [Listener at localhost/33305] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:35,050 [Listener at localhost/33305] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:24:35,050 [Listener at localhost/33305] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:35,052 [Listener at localhost/33305] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:35,052 [Listener at localhost/33305] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:24:35,052 [Listener at localhost/33305] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:35,052 [Listener at localhost/33305] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:35,053 [Listener at localhost/33305] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 40038
2020-12-03 07:24:35,053 [Listener at localhost/33305] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:35,055 [Listener at localhost/33305] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@44cb460e{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:35,056 [Listener at localhost/33305] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2e3cdec2{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:35,061 [Listener at localhost/33305] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@153d4abb{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:24:35,061 [Listener at localhost/33305] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6d4c273c{HTTP/1.1,[http/1.1]}{localhost:40038}
2020-12-03 07:24:35,065 [Listener at localhost/33305] INFO  server.Server (Server.java:doStart(419)) - Started @13460ms
2020-12-03 07:24:35,085 [Listener at localhost/33305] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:41548
2020-12-03 07:24:35,086 [Listener at localhost/33305] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:24:35,086 [Listener at localhost/33305] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:24:35,086 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@545e57d7] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:35,086 [Listener at localhost/33305] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:35,087 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:35,090 [Thread-492] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 11600@0b2162a51c02
2020-12-03 07:24:35,091 [Thread-492] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 1090966717. Formatting...
2020-12-03 07:24:35,091 [Thread-492] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-ae8ccbfd-7348-435f-88e1-d0087e04a4d2 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-12-03 07:24:35,092 [Listener at localhost/38030] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:38030
2020-12-03 07:24:35,132 [Listener at localhost/38030] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:24:35,132 [Listener at localhost/38030] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:24:35,133 [Thread-515] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42543 starting to offer service
2020-12-03 07:24:35,140 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:35,140 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:35,151 [Thread-515] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42543
2020-12-03 07:24:35,153 [Thread-515] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:24:35,154 [Listener at localhost/38030] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:24:35,155 [Listener at localhost/38030] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:24:35,155 [Listener at localhost/38030] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:24:35,157 [Listener at localhost/38030] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:24:35,159 [Listener at localhost/38030] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:35,159 [Listener at localhost/38030] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:24:35,159 [Listener at localhost/38030] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:24:35,159 [Listener at localhost/38030] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:35,160 [Listener at localhost/38030] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:24:35,160 [Listener at localhost/38030] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:24:35,160 [Listener at localhost/38030] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:24:35,161 [Listener at localhost/38030] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:35995
2020-12-03 07:24:35,161 [Listener at localhost/38030] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:24:35,161 [Listener at localhost/38030] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:24:35,162 [Listener at localhost/38030] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:35,163 [Listener at localhost/38030] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:35,164 [Listener at localhost/38030] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:24:35,164 [Listener at localhost/38030] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:35,166 [Listener at localhost/38030] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:35,166 [Listener at localhost/38030] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:24:35,166 [Listener at localhost/38030] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:35,166 [Listener at localhost/38030] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:35,167 [Listener at localhost/38030] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 34087
2020-12-03 07:24:35,167 [Listener at localhost/38030] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:35,169 [Listener at localhost/38030] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6a9950f1{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:35,169 [Listener at localhost/38030] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@73017a80{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:35,174 [Listener at localhost/38030] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@4d48bd85{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:24:35,175 [Listener at localhost/38030] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7bbbb6a8{HTTP/1.1,[http/1.1]}{localhost:34087}
2020-12-03 07:24:35,178 [Listener at localhost/38030] INFO  server.Server (Server.java:doStart(419)) - Started @13574ms
2020-12-03 07:24:35,200 [Listener at localhost/38030] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:46686
2020-12-03 07:24:35,200 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@27d57a2c] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:35,201 [Listener at localhost/38030] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:24:35,201 [Listener at localhost/38030] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:24:35,201 [Listener at localhost/38030] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:35,201 [Thread-515] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 11600@0b2162a51c02
2020-12-03 07:24:35,202 [Thread-515] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 is not formatted for namespace 1090966717. Formatting...
2020-12-03 07:24:35,202 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:35,202 [Thread-515] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-e96c0c9c-1d9e-48ab-aefe-143fa18e9d0f for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 
2020-12-03 07:24:35,207 [Listener at localhost/37909] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:37909
2020-12-03 07:24:35,248 [Listener at localhost/37909] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:24:35,248 [Listener at localhost/37909] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:24:35,249 [Thread-537] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42543 starting to offer service
2020-12-03 07:24:35,262 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:35,267 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:35,356 [Thread-492] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 11600@0b2162a51c02
2020-12-03 07:24:35,356 [Thread-492] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 1090966717. Formatting...
2020-12-03 07:24:35,356 [Thread-492] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-42917285-e317-4fcd-ab18-58b06e3abf14 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-12-03 07:24:35,358 [Thread-537] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42543
2020-12-03 07:24:35,366 [Thread-537] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:24:35,384 [Listener at localhost/37909] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 3 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:24:35,385 [Listener at localhost/37909] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:24:35,386 [Listener at localhost/37909] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:24:35,388 [Listener at localhost/37909] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:24:35,396 [Listener at localhost/37909] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:35,397 [Listener at localhost/37909] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:24:35,397 [Listener at localhost/37909] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:24:35,397 [Listener at localhost/37909] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:35,397 [Listener at localhost/37909] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:24:35,397 [Listener at localhost/37909] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:24:35,398 [Listener at localhost/37909] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:24:35,399 [Listener at localhost/37909] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:35478
2020-12-03 07:24:35,399 [Listener at localhost/37909] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:24:35,399 [Listener at localhost/37909] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:24:35,400 [Listener at localhost/37909] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:35,401 [Listener at localhost/37909] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:35,402 [Listener at localhost/37909] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:24:35,402 [Listener at localhost/37909] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:35,403 [Listener at localhost/37909] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:35,406 [Listener at localhost/37909] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:24:35,407 [Listener at localhost/37909] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:35,407 [Listener at localhost/37909] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:35,407 [Listener at localhost/37909] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 39564
2020-12-03 07:24:35,408 [Listener at localhost/37909] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:35,409 [Listener at localhost/37909] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@369c9bb{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:35,409 [Listener at localhost/37909] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@42b21d99{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:35,414 [Listener at localhost/37909] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6f3f0fae{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:24:35,414 [Listener at localhost/37909] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@21a66d45{HTTP/1.1,[http/1.1]}{localhost:39564}
2020-12-03 07:24:35,416 [Listener at localhost/37909] INFO  server.Server (Server.java:doStart(419)) - Started @13812ms
2020-12-03 07:24:35,441 [Listener at localhost/37909] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:38411
2020-12-03 07:24:35,442 [Listener at localhost/37909] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:24:35,442 [Listener at localhost/37909] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:24:35,442 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7428de63] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:35,442 [Listener at localhost/37909] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:35,443 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:35,446 [Listener at localhost/40861] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:40861
2020-12-03 07:24:35,465 [Thread-537] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 11600@0b2162a51c02
2020-12-03 07:24:35,466 [Thread-537] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 is not formatted for namespace 1090966717. Formatting...
2020-12-03 07:24:35,466 [Thread-537] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-d72315d1-2ea3-44c3-ade3-d7b892bdf67f for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 
2020-12-03 07:24:35,488 [Listener at localhost/40861] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:24:35,489 [Listener at localhost/40861] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:24:35,491 [Thread-559] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42543 starting to offer service
2020-12-03 07:24:35,491 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:35,491 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:35,493 [Listener at localhost/40861] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 4 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:24:35,494 [Listener at localhost/40861] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:24:35,495 [Listener at localhost/40861] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:24:35,509 [Listener at localhost/40861] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:24:35,509 [Listener at localhost/40861] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:35,509 [Listener at localhost/40861] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:24:35,510 [Listener at localhost/40861] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:24:35,510 [Listener at localhost/40861] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:35,510 [Listener at localhost/40861] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:24:35,511 [Listener at localhost/40861] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:24:35,511 [Listener at localhost/40861] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:24:35,512 [Listener at localhost/40861] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:45506
2020-12-03 07:24:35,512 [Listener at localhost/40861] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:24:35,512 [Listener at localhost/40861] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:24:35,514 [Listener at localhost/40861] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:35,514 [Thread-559] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42543
2020-12-03 07:24:35,516 [Listener at localhost/40861] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:35,516 [Listener at localhost/40861] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:24:35,517 [Listener at localhost/40861] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:35,520 [Thread-559] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:24:35,520 [Listener at localhost/40861] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:35,524 [Listener at localhost/40861] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:24:35,524 [Listener at localhost/40861] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:35,524 [Listener at localhost/40861] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:35,525 [Listener at localhost/40861] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 38582
2020-12-03 07:24:35,526 [Listener at localhost/40861] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:35,529 [Listener at localhost/40861] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@191a709b{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:35,530 [Listener at localhost/40861] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@453d496b{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:35,539 [Listener at localhost/40861] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6ee8dcd3{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:24:35,539 [Listener at localhost/40861] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@a20b94b{HTTP/1.1,[http/1.1]}{localhost:38582}
2020-12-03 07:24:35,541 [Listener at localhost/40861] INFO  server.Server (Server.java:doStart(419)) - Started @13936ms
2020-12-03 07:24:35,552 [Thread-515] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 11600@0b2162a51c02
2020-12-03 07:24:35,552 [Thread-515] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 is not formatted for namespace 1090966717. Formatting...
2020-12-03 07:24:35,554 [Thread-515] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-780c3aad-5133-4c8c-a94b-8deef7fd424f for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 
2020-12-03 07:24:35,555 [Listener at localhost/40861] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:46100
2020-12-03 07:24:35,555 [Listener at localhost/40861] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:24:35,555 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@14f3c6fc] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:35,555 [Listener at localhost/40861] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:24:35,556 [Listener at localhost/40861] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:35,557 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:35,562 [Thread-492] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:35,562 [Thread-492] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:35,563 [Thread-492] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-1688424058-172.17.0.4-1606980274066 is not formatted. Formatting ...
2020-12-03 07:24:35,563 [Thread-492] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1688424058-172.17.0.4-1606980274066 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1688424058-172.17.0.4-1606980274066/current
2020-12-03 07:24:35,568 [Listener at localhost/44129] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:44129
2020-12-03 07:24:35,572 [Listener at localhost/44129] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:24:35,572 [Listener at localhost/44129] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:24:35,573 [Thread-581] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42543 starting to offer service
2020-12-03 07:24:35,575 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:35,575 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:35,578 [Thread-581] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42543
2020-12-03 07:24:35,579 [Thread-581] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:24:35,579 [Listener at localhost/44129] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 5 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:24:35,580 [Listener at localhost/44129] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:24:35,580 [Listener at localhost/44129] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:24:35,581 [Listener at localhost/44129] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:24:35,582 [Listener at localhost/44129] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:35,582 [Listener at localhost/44129] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:24:35,582 [Listener at localhost/44129] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:24:35,582 [Listener at localhost/44129] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:35,582 [Listener at localhost/44129] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:24:35,583 [Listener at localhost/44129] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:24:35,583 [Listener at localhost/44129] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:24:35,583 [Listener at localhost/44129] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:39536
2020-12-03 07:24:35,584 [Listener at localhost/44129] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:24:35,584 [Listener at localhost/44129] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:24:35,584 [Listener at localhost/44129] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:35,586 [Listener at localhost/44129] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:35,586 [Listener at localhost/44129] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:24:35,586 [Listener at localhost/44129] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:35,588 [Listener at localhost/44129] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:35,588 [Listener at localhost/44129] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:24:35,589 [Listener at localhost/44129] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:35,589 [Listener at localhost/44129] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:35,589 [Listener at localhost/44129] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 34750
2020-12-03 07:24:35,589 [Listener at localhost/44129] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:35,591 [Listener at localhost/44129] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2764c546{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:35,591 [Listener at localhost/44129] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@408b87aa{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:35,596 [Listener at localhost/44129] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@67b7c170{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:24:35,597 [Listener at localhost/44129] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@67440de6{HTTP/1.1,[http/1.1]}{localhost:34750}
2020-12-03 07:24:35,597 [Listener at localhost/44129] INFO  server.Server (Server.java:doStart(419)) - Started @13993ms
2020-12-03 07:24:35,612 [Listener at localhost/44129] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:38347
2020-12-03 07:24:35,613 [Listener at localhost/44129] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:24:35,613 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5246a3b3] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:35,613 [Listener at localhost/44129] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:24:35,613 [Listener at localhost/44129] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:35,614 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:35,616 [Thread-559] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/in_use.lock acquired by nodename 11600@0b2162a51c02
2020-12-03 07:24:35,616 [Thread-559] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 is not formatted for namespace 1090966717. Formatting...
2020-12-03 07:24:35,617 [Listener at localhost/39452] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:39452
2020-12-03 07:24:35,618 [Thread-559] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-ad168160-c5a9-4603-8799-f50df9b59658 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 
2020-12-03 07:24:35,620 [Listener at localhost/39452] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:24:35,621 [Listener at localhost/39452] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:24:35,621 [Thread-603] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42543 starting to offer service
2020-12-03 07:24:35,623 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:35,623 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:35,626 [Listener at localhost/39452] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 6 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:24:35,627 [Thread-603] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42543
2020-12-03 07:24:35,628 [Thread-603] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:24:35,628 [Listener at localhost/39452] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:24:35,628 [Listener at localhost/39452] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:24:35,629 [Listener at localhost/39452] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:24:35,630 [Listener at localhost/39452] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:35,630 [Listener at localhost/39452] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:24:35,630 [Listener at localhost/39452] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:24:35,631 [Listener at localhost/39452] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:35,631 [Listener at localhost/39452] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:24:35,631 [Listener at localhost/39452] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:24:35,631 [Listener at localhost/39452] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:24:35,632 [Listener at localhost/39452] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:38509
2020-12-03 07:24:35,632 [Listener at localhost/39452] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:24:35,632 [Listener at localhost/39452] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:24:35,633 [Listener at localhost/39452] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:35,634 [Listener at localhost/39452] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:35,634 [Listener at localhost/39452] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:24:35,635 [Listener at localhost/39452] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:35,636 [Listener at localhost/39452] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:35,637 [Listener at localhost/39452] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:24:35,637 [Listener at localhost/39452] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:35,637 [Listener at localhost/39452] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:35,638 [Listener at localhost/39452] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 36742
2020-12-03 07:24:35,638 [Listener at localhost/39452] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:35,639 [Listener at localhost/39452] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@b10a26d{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:35,640 [Listener at localhost/39452] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7e4d2287{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:35,645 [Listener at localhost/39452] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@4a8df3e2{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:24:35,646 [Listener at localhost/39452] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3d98d138{HTTP/1.1,[http/1.1]}{localhost:36742}
2020-12-03 07:24:35,646 [Listener at localhost/39452] INFO  server.Server (Server.java:doStart(419)) - Started @14042ms
2020-12-03 07:24:35,661 [Listener at localhost/39452] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:45134
2020-12-03 07:24:35,661 [Listener at localhost/39452] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:24:35,661 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@25c53f74] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:35,661 [Listener at localhost/39452] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:24:35,662 [Listener at localhost/39452] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:35,662 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:35,665 [Listener at localhost/39867] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:39867
2020-12-03 07:24:35,669 [Listener at localhost/39867] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:24:35,669 [Listener at localhost/39867] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:24:35,670 [Thread-625] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42543 starting to offer service
2020-12-03 07:24:35,673 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:35,674 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:35,677 [Thread-625] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42543
2020-12-03 07:24:35,678 [Listener at localhost/39867] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 7 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:24:35,678 [Thread-625] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:24:35,679 [Listener at localhost/39867] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:24:35,679 [Listener at localhost/39867] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:24:35,680 [Listener at localhost/39867] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:24:35,680 [Listener at localhost/39867] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:35,681 [Listener at localhost/39867] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:24:35,681 [Listener at localhost/39867] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:24:35,681 [Listener at localhost/39867] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:35,681 [Listener at localhost/39867] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:24:35,682 [Listener at localhost/39867] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:24:35,682 [Listener at localhost/39867] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:24:35,682 [Listener at localhost/39867] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:40183
2020-12-03 07:24:35,682 [Listener at localhost/39867] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:24:35,683 [Listener at localhost/39867] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:24:35,683 [Listener at localhost/39867] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:35,685 [Listener at localhost/39867] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:35,685 [Listener at localhost/39867] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:24:35,686 [Listener at localhost/39867] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:35,687 [Listener at localhost/39867] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:35,687 [Listener at localhost/39867] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:24:35,688 [Listener at localhost/39867] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:35,688 [Listener at localhost/39867] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:35,688 [Listener at localhost/39867] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 45320
2020-12-03 07:24:35,688 [Listener at localhost/39867] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:35,689 [Thread-581] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/in_use.lock acquired by nodename 11600@0b2162a51c02
2020-12-03 07:24:35,689 [Thread-581] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 is not formatted for namespace 1090966717. Formatting...
2020-12-03 07:24:35,690 [Listener at localhost/39867] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@43034809{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:35,691 [Thread-581] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-63280395-91a5-4718-be8d-5460920774c7 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 
2020-12-03 07:24:35,691 [Listener at localhost/39867] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@77010a30{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:35,695 [Listener at localhost/39867] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@29629fbb{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:24:35,696 [Listener at localhost/39867] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@681adc8f{HTTP/1.1,[http/1.1]}{localhost:45320}
2020-12-03 07:24:35,697 [Listener at localhost/39867] INFO  server.Server (Server.java:doStart(419)) - Started @14092ms
2020-12-03 07:24:35,709 [Listener at localhost/39867] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:42328
2020-12-03 07:24:35,709 [Listener at localhost/39867] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:24:35,710 [Listener at localhost/39867] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:24:35,709 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@35dd9ed3] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:35,710 [Listener at localhost/39867] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:35,711 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:35,716 [Listener at localhost/37033] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:37033
2020-12-03 07:24:35,720 [Listener at localhost/37033] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:24:35,720 [Listener at localhost/37033] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:24:35,721 [Thread-647] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42543 starting to offer service
2020-12-03 07:24:35,722 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:35,722 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:35,725 [Thread-647] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42543
2020-12-03 07:24:35,725 [Thread-647] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:24:35,726 [Listener at localhost/37033] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 8 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:24:35,727 [Listener at localhost/37033] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:24:35,727 [Listener at localhost/37033] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:24:35,728 [Listener at localhost/37033] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:24:35,729 [Listener at localhost/37033] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:35,729 [Listener at localhost/37033] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:24:35,729 [Listener at localhost/37033] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:24:35,729 [Listener at localhost/37033] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:24:35,729 [Listener at localhost/37033] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:24:35,730 [Listener at localhost/37033] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:24:35,730 [Listener at localhost/37033] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:24:35,730 [Listener at localhost/37033] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:39670
2020-12-03 07:24:35,730 [Listener at localhost/37033] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:24:35,731 [Listener at localhost/37033] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:24:35,731 [Listener at localhost/37033] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:35,733 [Listener at localhost/37033] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:24:35,733 [Listener at localhost/37033] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:24:35,733 [Listener at localhost/37033] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:24:35,735 [Listener at localhost/37033] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:24:35,735 [Listener at localhost/37033] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:24:35,735 [Listener at localhost/37033] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:24:35,736 [Listener at localhost/37033] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:24:35,736 [Listener at localhost/37033] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 41406
2020-12-03 07:24:35,736 [Listener at localhost/37033] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:24:35,737 [Listener at localhost/37033] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@11e33bac{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:24:35,738 [Listener at localhost/37033] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@289778cd{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:24:35,742 [Listener at localhost/37033] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@58a63629{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:24:35,745 [Listener at localhost/37033] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7de843ef{HTTP/1.1,[http/1.1]}{localhost:41406}
2020-12-03 07:24:35,745 [Listener at localhost/37033] INFO  server.Server (Server.java:doStart(419)) - Started @14141ms
2020-12-03 07:24:35,752 [Thread-603] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/in_use.lock acquired by nodename 11600@0b2162a51c02
2020-12-03 07:24:35,752 [Thread-625] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/in_use.lock acquired by nodename 11600@0b2162a51c02
2020-12-03 07:24:35,752 [Thread-603] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 is not formatted for namespace 1090966717. Formatting...
2020-12-03 07:24:35,753 [Thread-625] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 is not formatted for namespace 1090966717. Formatting...
2020-12-03 07:24:35,754 [Thread-603] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-532f25f9-06d4-4afd-8691-3f01f1faf6e8 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 
2020-12-03 07:24:35,754 [Thread-625] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-bfb9e676-bcb3-4b9b-8b21-3adff7deb76f for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 
2020-12-03 07:24:35,757 [Listener at localhost/37033] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:40910
2020-12-03 07:24:35,757 [Listener at localhost/37033] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:24:35,757 [Listener at localhost/37033] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:24:35,757 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3fd2322d] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:24:35,758 [Listener at localhost/37033] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:24:35,758 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:24:35,763 [Listener at localhost/38811] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:38811
2020-12-03 07:24:35,767 [Listener at localhost/38811] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:24:35,767 [Listener at localhost/38811] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:24:35,768 [Thread-669] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42543 starting to offer service
2020-12-03 07:24:35,769 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:24:35,769 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:24:35,774 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSClient.java:<init>(318)) - Sets dfs.client.block.write.replace-datanode-on-failure.min-replication to 0
2020-12-03 07:24:35,777 [Thread-669] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42543
2020-12-03 07:24:35,778 [Thread-669] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:24:35,779 [IPC Server handler 9 on default port 42543] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:35,780 [Listener at localhost/38811] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:35,780 [Listener at localhost/38811] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:35,829 [Thread-647] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/in_use.lock acquired by nodename 11600@0b2162a51c02
2020-12-03 07:24:35,829 [Thread-537] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 11600@0b2162a51c02
2020-12-03 07:24:35,830 [Thread-647] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 is not formatted for namespace 1090966717. Formatting...
2020-12-03 07:24:35,830 [Thread-537] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 is not formatted for namespace 1090966717. Formatting...
2020-12-03 07:24:35,832 [Thread-647] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-aa276f62-89b9-45fb-b1dc-db56c85396ff for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 
2020-12-03 07:24:35,832 [Thread-537] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-e1a62b65-ebd2-4b8a-8428-d9e31df860fe for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 
2020-12-03 07:24:35,837 [Thread-515] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:35,838 [Thread-515] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:35,838 [Thread-492] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:35,838 [Thread-515] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 and block pool id BP-1688424058-172.17.0.4-1606980274066 is not formatted. Formatting ...
2020-12-03 07:24:35,838 [Thread-515] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1688424058-172.17.0.4-1606980274066 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1688424058-172.17.0.4-1606980274066/current
2020-12-03 07:24:35,838 [Thread-492] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:35,838 [Thread-492] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-1688424058-172.17.0.4-1606980274066 is not formatted. Formatting ...
2020-12-03 07:24:35,838 [Thread-492] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1688424058-172.17.0.4-1606980274066 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1688424058-172.17.0.4-1606980274066/current
2020-12-03 07:24:35,883 [IPC Server handler 0 on default port 42543] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:35,884 [Listener at localhost/38811] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:35,884 [Listener at localhost/38811] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:35,899 [Thread-669] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/in_use.lock acquired by nodename 11600@0b2162a51c02
2020-12-03 07:24:35,899 [Thread-669] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 is not formatted for namespace 1090966717. Formatting...
2020-12-03 07:24:35,901 [Thread-669] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-301c141a-2a18-464c-bff6-f3cc085eb873 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 
2020-12-03 07:24:35,985 [IPC Server handler 1 on default port 42543] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:35,986 [Listener at localhost/38811] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:35,986 [Listener at localhost/38811] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:36,057 [Thread-559] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/in_use.lock acquired by nodename 11600@0b2162a51c02
2020-12-03 07:24:36,057 [Thread-559] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 is not formatted for namespace 1090966717. Formatting...
2020-12-03 07:24:36,058 [Thread-559] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-4a224303-3aff-47f8-9ce9-586dfad45f29 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 
2020-12-03 07:24:36,087 [IPC Server handler 2 on default port 42543] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:36,088 [Listener at localhost/38811] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:36,088 [Listener at localhost/38811] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:36,138 [Thread-581] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/in_use.lock acquired by nodename 11600@0b2162a51c02
2020-12-03 07:24:36,138 [Thread-492] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1090966717;bpid=BP-1688424058-172.17.0.4-1606980274066;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1090966717;c=1606980274066;bpid=BP-1688424058-172.17.0.4-1606980274066;dnuuid=null
2020-12-03 07:24:36,139 [Thread-581] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 is not formatted for namespace 1090966717. Formatting...
2020-12-03 07:24:36,141 [Thread-581] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-de2435ec-3606-4457-bfcf-cb6ef072dc0e for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 
2020-12-03 07:24:36,146 [Thread-537] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:36,146 [Thread-515] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:36,146 [Thread-537] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:36,146 [Thread-515] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:36,146 [Thread-537] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 and block pool id BP-1688424058-172.17.0.4-1606980274066 is not formatted. Formatting ...
2020-12-03 07:24:36,146 [Thread-515] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 and block pool id BP-1688424058-172.17.0.4-1606980274066 is not formatted. Formatting ...
2020-12-03 07:24:36,146 [Thread-537] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1688424058-172.17.0.4-1606980274066 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1688424058-172.17.0.4-1606980274066/current
2020-12-03 07:24:36,146 [Thread-515] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1688424058-172.17.0.4-1606980274066 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1688424058-172.17.0.4-1606980274066/current
2020-12-03 07:24:36,189 [IPC Server handler 3 on default port 42543] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:36,189 [Listener at localhost/38811] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:36,189 [Listener at localhost/38811] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:36,202 [Thread-625] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/in_use.lock acquired by nodename 11600@0b2162a51c02
2020-12-03 07:24:36,202 [Thread-603] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/in_use.lock acquired by nodename 11600@0b2162a51c02
2020-12-03 07:24:36,202 [Thread-625] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 is not formatted for namespace 1090966717. Formatting...
2020-12-03 07:24:36,202 [Thread-603] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 is not formatted for namespace 1090966717. Formatting...
2020-12-03 07:24:36,204 [Thread-625] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-ec3d9943-1545-4cf6-b156-a296d9b5e16e for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 
2020-12-03 07:24:36,204 [Thread-603] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-90decd12-583a-4d3d-8ffa-ff0c65a87d71 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 
2020-12-03 07:24:36,286 [Thread-647] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/in_use.lock acquired by nodename 11600@0b2162a51c02
2020-12-03 07:24:36,286 [Thread-647] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 is not formatted for namespace 1090966717. Formatting...
2020-12-03 07:24:36,288 [Thread-647] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-5435f169-1195-4ff2-be92-139ab30335f6 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 
2020-12-03 07:24:36,290 [IPC Server handler 4 on default port 42543] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:36,290 [Listener at localhost/38811] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:36,291 [Listener at localhost/38811] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:36,353 [Thread-669] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/in_use.lock acquired by nodename 11600@0b2162a51c02
2020-12-03 07:24:36,354 [Thread-669] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 is not formatted for namespace 1090966717. Formatting...
2020-12-03 07:24:36,355 [Thread-669] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-ccf36913-5b38-4a68-9d8f-bff774a3138d for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 
2020-12-03 07:24:36,362 [Thread-559] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:36,362 [Thread-559] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:36,362 [Thread-559] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 and block pool id BP-1688424058-172.17.0.4-1606980274066 is not formatted. Formatting ...
2020-12-03 07:24:36,362 [Thread-559] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1688424058-172.17.0.4-1606980274066 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1688424058-172.17.0.4-1606980274066/current
2020-12-03 07:24:36,391 [IPC Server handler 5 on default port 42543] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:36,392 [Listener at localhost/38811] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:36,392 [Listener at localhost/38811] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:36,444 [Thread-492] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID c063fb49-df5c-4081-9d45-b22fc275fc8d
2020-12-03 07:24:36,446 [Thread-515] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1090966717;bpid=BP-1688424058-172.17.0.4-1606980274066;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1090966717;c=1606980274066;bpid=BP-1688424058-172.17.0.4-1606980274066;dnuuid=null
2020-12-03 07:24:36,447 [Thread-492] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-ae8ccbfd-7348-435f-88e1-d0087e04a4d2
2020-12-03 07:24:36,448 [Thread-492] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-12-03 07:24:36,450 [Thread-492] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-42917285-e317-4fcd-ab18-58b06e3abf14
2020-12-03 07:24:36,450 [Thread-492] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-12-03 07:24:36,453 [Thread-492] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:24:36,454 [Thread-492] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:24:36,454 [Thread-492] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:24:36,454 [Thread-492] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:24:36,454 [Thread-492] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:24:36,455 [Thread-492] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:36,455 [Thread-683] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1688424058-172.17.0.4-1606980274066 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:24:36,456 [Thread-581] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:36,456 [Thread-537] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:36,456 [Thread-581] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:36,456 [Thread-537] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:36,456 [Thread-581] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 and block pool id BP-1688424058-172.17.0.4-1606980274066 is not formatted. Formatting ...
2020-12-03 07:24:36,458 [Thread-581] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1688424058-172.17.0.4-1606980274066 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1688424058-172.17.0.4-1606980274066/current
2020-12-03 07:24:36,458 [Thread-537] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 and block pool id BP-1688424058-172.17.0.4-1606980274066 is not formatted. Formatting ...
2020-12-03 07:24:36,458 [Thread-684] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1688424058-172.17.0.4-1606980274066 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:24:36,458 [Thread-537] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1688424058-172.17.0.4-1606980274066 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1688424058-172.17.0.4-1606980274066/current
2020-12-03 07:24:36,485 [Thread-684] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1688424058-172.17.0.4-1606980274066 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 27ms
2020-12-03 07:24:36,487 [Thread-683] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1688424058-172.17.0.4-1606980274066 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 32ms
2020-12-03 07:24:36,487 [Thread-492] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1688424058-172.17.0.4-1606980274066: 32ms
2020-12-03 07:24:36,488 [Thread-687] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1688424058-172.17.0.4-1606980274066 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:24:36,491 [Thread-688] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1688424058-172.17.0.4-1606980274066 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:24:36,491 [Thread-687] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1688424058-172.17.0.4-1606980274066/current/replicas doesn't exist 
2020-12-03 07:24:36,491 [Thread-688] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1688424058-172.17.0.4-1606980274066/current/replicas doesn't exist 
2020-12-03 07:24:36,491 [Thread-687] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1688424058-172.17.0.4-1606980274066 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 1ms
2020-12-03 07:24:36,491 [Thread-688] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1688424058-172.17.0.4-1606980274066 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 1ms
2020-12-03 07:24:36,491 [Thread-492] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1688424058-172.17.0.4-1606980274066: 4ms
2020-12-03 07:24:36,492 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1688424058-172.17.0.4-1606980274066 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:24:36,492 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1688424058-172.17.0.4-1606980274066 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:24:36,492 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-42917285-e317-4fcd-ab18-58b06e3abf14): finished scanning block pool BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:36,492 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-ae8ccbfd-7348-435f-88e1-d0087e04a4d2): finished scanning block pool BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:36,492 [Thread-492] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 8:57 AM with interval of 21600000ms
2020-12-03 07:24:36,493 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-42917285-e317-4fcd-ab18-58b06e3abf14): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:24:36,493 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1688424058-172.17.0.4-1606980274066 (Datanode Uuid c063fb49-df5c-4081-9d45-b22fc275fc8d) service to localhost/127.0.0.1:42543 beginning handshake with NN
2020-12-03 07:24:36,493 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-ae8ccbfd-7348-435f-88e1-d0087e04a4d2): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:24:36,494 [IPC Server handler 6 on default port 42543] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:36,494 [Listener at localhost/38811] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:36,495 [Listener at localhost/38811] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:36,494 [IPC Server handler 7 on default port 42543] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:46077, datanodeUuid=c063fb49-df5c-4081-9d45-b22fc275fc8d, infoPort=43965, infoSecurePort=0, ipcPort=33305, storageInfo=lv=-57;cid=testClusterID;nsid=1090966717;c=1606980274066) storage c063fb49-df5c-4081-9d45-b22fc275fc8d
2020-12-03 07:24:36,495 [IPC Server handler 7 on default port 42543] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:46077
2020-12-03 07:24:36,495 [IPC Server handler 7 on default port 42543] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN c063fb49-df5c-4081-9d45-b22fc275fc8d (127.0.0.1:46077).
2020-12-03 07:24:36,497 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1688424058-172.17.0.4-1606980274066 (Datanode Uuid c063fb49-df5c-4081-9d45-b22fc275fc8d) service to localhost/127.0.0.1:42543 successfully registered with NN
2020-12-03 07:24:36,497 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:42543 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-12-03 07:24:36,499 [IPC Server handler 8 on default port 42543] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-ae8ccbfd-7348-435f-88e1-d0087e04a4d2 for DN 127.0.0.1:46077
2020-12-03 07:24:36,499 [IPC Server handler 8 on default port 42543] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-42917285-e317-4fcd-ab18-58b06e3abf14 for DN 127.0.0.1:46077
2020-12-03 07:24:36,502 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x195365b17d3ee2dc: Processing first storage report for DS-ae8ccbfd-7348-435f-88e1-d0087e04a4d2 from datanode c063fb49-df5c-4081-9d45-b22fc275fc8d
2020-12-03 07:24:36,503 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x195365b17d3ee2dc: from storage DS-ae8ccbfd-7348-435f-88e1-d0087e04a4d2 node DatanodeRegistration(127.0.0.1:46077, datanodeUuid=c063fb49-df5c-4081-9d45-b22fc275fc8d, infoPort=43965, infoSecurePort=0, ipcPort=33305, storageInfo=lv=-57;cid=testClusterID;nsid=1090966717;c=1606980274066), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:36,503 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x195365b17d3ee2dc: Processing first storage report for DS-42917285-e317-4fcd-ab18-58b06e3abf14 from datanode c063fb49-df5c-4081-9d45-b22fc275fc8d
2020-12-03 07:24:36,503 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x195365b17d3ee2dc: from storage DS-42917285-e317-4fcd-ab18-58b06e3abf14 node DatanodeRegistration(127.0.0.1:46077, datanodeUuid=c063fb49-df5c-4081-9d45-b22fc275fc8d, infoPort=43965, infoSecurePort=0, ipcPort=33305, storageInfo=lv=-57;cid=testClusterID;nsid=1090966717;c=1606980274066), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:36,504 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x195365b17d3ee2dc,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:36,504 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:36,513 [Thread-603] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:36,513 [Thread-625] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:36,514 [Thread-603] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:36,514 [Thread-625] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:36,514 [Thread-603] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 and block pool id BP-1688424058-172.17.0.4-1606980274066 is not formatted. Formatting ...
2020-12-03 07:24:36,514 [Thread-625] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 and block pool id BP-1688424058-172.17.0.4-1606980274066 is not formatted. Formatting ...
2020-12-03 07:24:36,514 [Thread-603] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1688424058-172.17.0.4-1606980274066 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1688424058-172.17.0.4-1606980274066/current
2020-12-03 07:24:36,514 [Thread-625] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1688424058-172.17.0.4-1606980274066 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1688424058-172.17.0.4-1606980274066/current
2020-12-03 07:24:36,596 [IPC Server handler 0 on default port 42543] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:36,597 [Listener at localhost/38811] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:36,597 [Listener at localhost/38811] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:36,603 [Thread-647] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:36,603 [Thread-647] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:36,603 [Thread-647] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 and block pool id BP-1688424058-172.17.0.4-1606980274066 is not formatted. Formatting ...
2020-12-03 07:24:36,604 [Thread-647] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1688424058-172.17.0.4-1606980274066 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1688424058-172.17.0.4-1606980274066/current
2020-12-03 07:24:36,690 [Thread-669] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:36,690 [Thread-559] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:36,690 [Thread-669] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:36,690 [Thread-559] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:36,690 [Thread-669] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 and block pool id BP-1688424058-172.17.0.4-1606980274066 is not formatted. Formatting ...
2020-12-03 07:24:36,690 [Thread-559] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 and block pool id BP-1688424058-172.17.0.4-1606980274066 is not formatted. Formatting ...
2020-12-03 07:24:36,690 [Thread-669] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1688424058-172.17.0.4-1606980274066 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1688424058-172.17.0.4-1606980274066/current
2020-12-03 07:24:36,690 [Thread-559] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1688424058-172.17.0.4-1606980274066 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1688424058-172.17.0.4-1606980274066/current
2020-12-03 07:24:36,698 [IPC Server handler 1 on default port 42543] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:36,699 [Listener at localhost/38811] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:36,699 [Listener at localhost/38811] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:36,750 [Thread-515] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 98ea0ce4-a3b3-42e5-9bc8-9e81b791e85f
2020-12-03 07:24:36,750 [Thread-537] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1090966717;bpid=BP-1688424058-172.17.0.4-1606980274066;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1090966717;c=1606980274066;bpid=BP-1688424058-172.17.0.4-1606980274066;dnuuid=null
2020-12-03 07:24:36,752 [Thread-515] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-e96c0c9c-1d9e-48ab-aefe-143fa18e9d0f
2020-12-03 07:24:36,753 [Thread-515] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: DISK
2020-12-03 07:24:36,755 [Thread-515] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-780c3aad-5133-4c8c-a94b-8deef7fd424f
2020-12-03 07:24:36,755 [Thread-515] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: DISK
2020-12-03 07:24:36,756 [Thread-515] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:24:36,757 [Thread-515] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:24:36,758 [Thread-515] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:24:36,758 [Thread-515] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:24:36,758 [Thread-515] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:24:36,759 [Thread-515] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:36,759 [Thread-694] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1688424058-172.17.0.4-1606980274066 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:24:36,759 [Thread-695] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1688424058-172.17.0.4-1606980274066 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:24:36,760 [Thread-581] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:36,760 [Thread-581] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:36,761 [Thread-581] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 and block pool id BP-1688424058-172.17.0.4-1606980274066 is not formatted. Formatting ...
2020-12-03 07:24:36,761 [Thread-581] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1688424058-172.17.0.4-1606980274066 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1688424058-172.17.0.4-1606980274066/current
2020-12-03 07:24:36,785 [Thread-695] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1688424058-172.17.0.4-1606980274066 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 26ms
2020-12-03 07:24:36,785 [Thread-694] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1688424058-172.17.0.4-1606980274066 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 26ms
2020-12-03 07:24:36,786 [Thread-515] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1688424058-172.17.0.4-1606980274066: 27ms
2020-12-03 07:24:36,786 [Thread-698] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1688424058-172.17.0.4-1606980274066 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:24:36,786 [Thread-698] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1688424058-172.17.0.4-1606980274066/current/replicas doesn't exist 
2020-12-03 07:24:36,786 [Thread-699] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1688424058-172.17.0.4-1606980274066 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:24:36,787 [Thread-699] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1688424058-172.17.0.4-1606980274066/current/replicas doesn't exist 
2020-12-03 07:24:36,787 [Thread-698] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1688424058-172.17.0.4-1606980274066 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 0ms
2020-12-03 07:24:36,787 [Thread-699] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1688424058-172.17.0.4-1606980274066 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 0ms
2020-12-03 07:24:36,787 [Thread-515] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1688424058-172.17.0.4-1606980274066: 1ms
2020-12-03 07:24:36,787 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1688424058-172.17.0.4-1606980274066 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:24:36,787 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1688424058-172.17.0.4-1606980274066 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:24:36,787 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-780c3aad-5133-4c8c-a94b-8deef7fd424f): finished scanning block pool BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:36,787 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-e96c0c9c-1d9e-48ab-aefe-143fa18e9d0f): finished scanning block pool BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:36,788 [Thread-515] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:39 AM with interval of 21600000ms
2020-12-03 07:24:36,788 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-e96c0c9c-1d9e-48ab-aefe-143fa18e9d0f): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:24:36,789 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1688424058-172.17.0.4-1606980274066 (Datanode Uuid 98ea0ce4-a3b3-42e5-9bc8-9e81b791e85f) service to localhost/127.0.0.1:42543 beginning handshake with NN
2020-12-03 07:24:36,788 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-780c3aad-5133-4c8c-a94b-8deef7fd424f): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:24:36,790 [IPC Server handler 2 on default port 42543] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:45564, datanodeUuid=98ea0ce4-a3b3-42e5-9bc8-9e81b791e85f, infoPort=41548, infoSecurePort=0, ipcPort=38030, storageInfo=lv=-57;cid=testClusterID;nsid=1090966717;c=1606980274066) storage 98ea0ce4-a3b3-42e5-9bc8-9e81b791e85f
2020-12-03 07:24:36,790 [IPC Server handler 2 on default port 42543] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:45564
2020-12-03 07:24:36,790 [IPC Server handler 2 on default port 42543] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 98ea0ce4-a3b3-42e5-9bc8-9e81b791e85f (127.0.0.1:45564).
2020-12-03 07:24:36,791 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1688424058-172.17.0.4-1606980274066 (Datanode Uuid 98ea0ce4-a3b3-42e5-9bc8-9e81b791e85f) service to localhost/127.0.0.1:42543 successfully registered with NN
2020-12-03 07:24:36,791 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:42543 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-12-03 07:24:36,793 [IPC Server handler 3 on default port 42543] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-e96c0c9c-1d9e-48ab-aefe-143fa18e9d0f for DN 127.0.0.1:45564
2020-12-03 07:24:36,794 [IPC Server handler 3 on default port 42543] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-780c3aad-5133-4c8c-a94b-8deef7fd424f for DN 127.0.0.1:45564
2020-12-03 07:24:36,799 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xc899c9ab5a38add4: Processing first storage report for DS-780c3aad-5133-4c8c-a94b-8deef7fd424f from datanode 98ea0ce4-a3b3-42e5-9bc8-9e81b791e85f
2020-12-03 07:24:36,799 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xc899c9ab5a38add4: from storage DS-780c3aad-5133-4c8c-a94b-8deef7fd424f node DatanodeRegistration(127.0.0.1:45564, datanodeUuid=98ea0ce4-a3b3-42e5-9bc8-9e81b791e85f, infoPort=41548, infoSecurePort=0, ipcPort=38030, storageInfo=lv=-57;cid=testClusterID;nsid=1090966717;c=1606980274066), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:36,799 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xc899c9ab5a38add4: Processing first storage report for DS-e96c0c9c-1d9e-48ab-aefe-143fa18e9d0f from datanode 98ea0ce4-a3b3-42e5-9bc8-9e81b791e85f
2020-12-03 07:24:36,799 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xc899c9ab5a38add4: from storage DS-e96c0c9c-1d9e-48ab-aefe-143fa18e9d0f node DatanodeRegistration(127.0.0.1:45564, datanodeUuid=98ea0ce4-a3b3-42e5-9bc8-9e81b791e85f, infoPort=41548, infoSecurePort=0, ipcPort=38030, storageInfo=lv=-57;cid=testClusterID;nsid=1090966717;c=1606980274066), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:24:36,800 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xc899c9ab5a38add4,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:36,800 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:36,800 [IPC Server handler 5 on default port 42543] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:36,801 [Listener at localhost/38811] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:36,801 [Listener at localhost/38811] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:36,818 [Thread-603] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:36,818 [Thread-603] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:36,819 [Thread-603] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 and block pool id BP-1688424058-172.17.0.4-1606980274066 is not formatted. Formatting ...
2020-12-03 07:24:36,819 [Thread-603] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1688424058-172.17.0.4-1606980274066 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1688424058-172.17.0.4-1606980274066/current
2020-12-03 07:24:36,819 [Thread-625] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:36,819 [Thread-625] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:36,819 [Thread-625] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 and block pool id BP-1688424058-172.17.0.4-1606980274066 is not formatted. Formatting ...
2020-12-03 07:24:36,819 [Thread-625] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1688424058-172.17.0.4-1606980274066 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1688424058-172.17.0.4-1606980274066/current
2020-12-03 07:24:36,902 [IPC Server handler 6 on default port 42543] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:36,902 [Listener at localhost/38811] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:36,903 [Listener at localhost/38811] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:36,903 [Thread-647] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:36,903 [Thread-647] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:36,903 [Thread-647] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 and block pool id BP-1688424058-172.17.0.4-1606980274066 is not formatted. Formatting ...
2020-12-03 07:24:36,903 [Thread-647] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1688424058-172.17.0.4-1606980274066 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1688424058-172.17.0.4-1606980274066/current
2020-12-03 07:24:36,965 [Thread-559] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1090966717;bpid=BP-1688424058-172.17.0.4-1606980274066;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1090966717;c=1606980274066;bpid=BP-1688424058-172.17.0.4-1606980274066;dnuuid=null
2020-12-03 07:24:36,973 [Thread-669] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:36,973 [Thread-669] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:36,973 [Thread-669] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 and block pool id BP-1688424058-172.17.0.4-1606980274066 is not formatted. Formatting ...
2020-12-03 07:24:36,973 [Thread-669] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1688424058-172.17.0.4-1606980274066 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1688424058-172.17.0.4-1606980274066/current
2020-12-03 07:24:37,003 [IPC Server handler 7 on default port 42543] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:37,004 [Listener at localhost/38811] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:37,004 [Listener at localhost/38811] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:37,040 [Thread-537] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID c1d7d0bc-1e04-40b2-8bda-52556cd4f522
2020-12-03 07:24:37,040 [Thread-581] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1090966717;bpid=BP-1688424058-172.17.0.4-1606980274066;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1090966717;c=1606980274066;bpid=BP-1688424058-172.17.0.4-1606980274066;dnuuid=null
2020-12-03 07:24:37,042 [Thread-537] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-d72315d1-2ea3-44c3-ade3-d7b892bdf67f
2020-12-03 07:24:37,042 [Thread-537] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, StorageType: DISK
2020-12-03 07:24:37,045 [Thread-537] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-e1a62b65-ebd2-4b8a-8428-d9e31df860fe
2020-12-03 07:24:37,045 [Thread-537] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, StorageType: DISK
2020-12-03 07:24:37,046 [Thread-537] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:24:37,047 [Thread-537] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:24:37,048 [Thread-537] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:24:37,048 [Thread-537] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:24:37,048 [Thread-537] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:24:37,049 [Thread-537] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:37,049 [Thread-705] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1688424058-172.17.0.4-1606980274066 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:24:37,049 [Thread-706] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1688424058-172.17.0.4-1606980274066 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:24:37,075 [Thread-705] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1688424058-172.17.0.4-1606980274066 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 26ms
2020-12-03 07:24:37,077 [Thread-706] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1688424058-172.17.0.4-1606980274066 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 27ms
2020-12-03 07:24:37,077 [Thread-537] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1688424058-172.17.0.4-1606980274066: 28ms
2020-12-03 07:24:37,077 [Thread-709] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1688424058-172.17.0.4-1606980274066 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:24:37,077 [Thread-709] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1688424058-172.17.0.4-1606980274066/current/replicas doesn't exist 
2020-12-03 07:24:37,077 [Thread-710] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1688424058-172.17.0.4-1606980274066 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:24:37,077 [Thread-710] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1688424058-172.17.0.4-1606980274066/current/replicas doesn't exist 
2020-12-03 07:24:37,078 [Thread-709] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1688424058-172.17.0.4-1606980274066 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 0ms
2020-12-03 07:24:37,078 [Thread-710] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1688424058-172.17.0.4-1606980274066 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 0ms
2020-12-03 07:24:37,078 [Thread-537] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1688424058-172.17.0.4-1606980274066: 1ms
2020-12-03 07:24:37,078 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1688424058-172.17.0.4-1606980274066 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:24:37,078 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1688424058-172.17.0.4-1606980274066 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:24:37,078 [Thread-537] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 1:06 PM with interval of 21600000ms
2020-12-03 07:24:37,079 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-e1a62b65-ebd2-4b8a-8428-d9e31df860fe): finished scanning block pool BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:37,079 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-d72315d1-2ea3-44c3-ade3-d7b892bdf67f): finished scanning block pool BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:37,079 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1688424058-172.17.0.4-1606980274066 (Datanode Uuid c1d7d0bc-1e04-40b2-8bda-52556cd4f522) service to localhost/127.0.0.1:42543 beginning handshake with NN
2020-12-03 07:24:37,080 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-e1a62b65-ebd2-4b8a-8428-d9e31df860fe): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-12-03 07:24:37,080 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-d72315d1-2ea3-44c3-ade3-d7b892bdf67f): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-12-03 07:24:37,081 [IPC Server handler 8 on default port 42543] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35995, datanodeUuid=c1d7d0bc-1e04-40b2-8bda-52556cd4f522, infoPort=46686, infoSecurePort=0, ipcPort=37909, storageInfo=lv=-57;cid=testClusterID;nsid=1090966717;c=1606980274066) storage c1d7d0bc-1e04-40b2-8bda-52556cd4f522
2020-12-03 07:24:37,081 [IPC Server handler 8 on default port 42543] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:35995
2020-12-03 07:24:37,081 [IPC Server handler 8 on default port 42543] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN c1d7d0bc-1e04-40b2-8bda-52556cd4f522 (127.0.0.1:35995).
2020-12-03 07:24:37,082 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1688424058-172.17.0.4-1606980274066 (Datanode Uuid c1d7d0bc-1e04-40b2-8bda-52556cd4f522) service to localhost/127.0.0.1:42543 successfully registered with NN
2020-12-03 07:24:37,082 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:42543 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-12-03 07:24:37,084 [IPC Server handler 9 on default port 42543] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d72315d1-2ea3-44c3-ade3-d7b892bdf67f for DN 127.0.0.1:35995
2020-12-03 07:24:37,084 [IPC Server handler 9 on default port 42543] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-e1a62b65-ebd2-4b8a-8428-d9e31df860fe for DN 127.0.0.1:35995
2020-12-03 07:24:37,086 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x132cad7e090d09df: Processing first storage report for DS-d72315d1-2ea3-44c3-ade3-d7b892bdf67f from datanode c1d7d0bc-1e04-40b2-8bda-52556cd4f522
2020-12-03 07:24:37,086 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x132cad7e090d09df: from storage DS-d72315d1-2ea3-44c3-ade3-d7b892bdf67f node DatanodeRegistration(127.0.0.1:35995, datanodeUuid=c1d7d0bc-1e04-40b2-8bda-52556cd4f522, infoPort=46686, infoSecurePort=0, ipcPort=37909, storageInfo=lv=-57;cid=testClusterID;nsid=1090966717;c=1606980274066), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:24:37,086 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x132cad7e090d09df: Processing first storage report for DS-e1a62b65-ebd2-4b8a-8428-d9e31df860fe from datanode c1d7d0bc-1e04-40b2-8bda-52556cd4f522
2020-12-03 07:24:37,086 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x132cad7e090d09df: from storage DS-e1a62b65-ebd2-4b8a-8428-d9e31df860fe node DatanodeRegistration(127.0.0.1:35995, datanodeUuid=c1d7d0bc-1e04-40b2-8bda-52556cd4f522, infoPort=46686, infoSecurePort=0, ipcPort=37909, storageInfo=lv=-57;cid=testClusterID;nsid=1090966717;c=1606980274066), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:37,087 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x132cad7e090d09df,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:37,087 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:37,091 [Thread-603] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1090966717;bpid=BP-1688424058-172.17.0.4-1606980274066;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1090966717;c=1606980274066;bpid=BP-1688424058-172.17.0.4-1606980274066;dnuuid=null
2020-12-03 07:24:37,092 [Thread-625] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1090966717;bpid=BP-1688424058-172.17.0.4-1606980274066;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1090966717;c=1606980274066;bpid=BP-1688424058-172.17.0.4-1606980274066;dnuuid=null
2020-12-03 07:24:37,105 [IPC Server handler 1 on default port 42543] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:37,106 [Listener at localhost/38811] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:37,106 [Listener at localhost/38811] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:37,162 [Thread-647] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1090966717;bpid=BP-1688424058-172.17.0.4-1606980274066;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1090966717;c=1606980274066;bpid=BP-1688424058-172.17.0.4-1606980274066;dnuuid=null
2020-12-03 07:24:37,207 [IPC Server handler 2 on default port 42543] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:37,208 [Listener at localhost/38811] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:37,208 [Listener at localhost/38811] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:37,219 [Thread-559] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID b1a31110-b9aa-4184-8cd5-6778c3221b36
2020-12-03 07:24:37,219 [Thread-669] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1090966717;bpid=BP-1688424058-172.17.0.4-1606980274066;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1090966717;c=1606980274066;bpid=BP-1688424058-172.17.0.4-1606980274066;dnuuid=null
2020-12-03 07:24:37,221 [Thread-559] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-ad168160-c5a9-4603-8799-f50df9b59658
2020-12-03 07:24:37,221 [Thread-559] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, StorageType: DISK
2020-12-03 07:24:37,223 [Thread-559] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-4a224303-3aff-47f8-9ce9-586dfad45f29
2020-12-03 07:24:37,223 [Thread-559] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, StorageType: DISK
2020-12-03 07:24:37,224 [Thread-559] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:24:37,225 [Thread-559] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:24:37,226 [Thread-559] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:24:37,226 [Thread-559] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:24:37,226 [Thread-559] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:24:37,227 [Thread-559] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:37,227 [Thread-716] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1688424058-172.17.0.4-1606980274066 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-12-03 07:24:37,228 [Thread-717] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1688424058-172.17.0.4-1606980274066 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-12-03 07:24:37,255 [Thread-717] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1688424058-172.17.0.4-1606980274066 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 26ms
2020-12-03 07:24:37,255 [Thread-716] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1688424058-172.17.0.4-1606980274066 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 27ms
2020-12-03 07:24:37,255 [Thread-559] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1688424058-172.17.0.4-1606980274066: 29ms
2020-12-03 07:24:37,256 [Thread-720] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1688424058-172.17.0.4-1606980274066 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-12-03 07:24:37,256 [Thread-721] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1688424058-172.17.0.4-1606980274066 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-12-03 07:24:37,256 [Thread-720] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1688424058-172.17.0.4-1606980274066/current/replicas doesn't exist 
2020-12-03 07:24:37,256 [Thread-721] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1688424058-172.17.0.4-1606980274066/current/replicas doesn't exist 
2020-12-03 07:24:37,256 [Thread-720] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1688424058-172.17.0.4-1606980274066 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 1ms
2020-12-03 07:24:37,256 [Thread-721] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1688424058-172.17.0.4-1606980274066 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 0ms
2020-12-03 07:24:37,257 [Thread-559] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1688424058-172.17.0.4-1606980274066: 1ms
2020-12-03 07:24:37,257 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1688424058-172.17.0.4-1606980274066 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:24:37,257 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1688424058-172.17.0.4-1606980274066 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:24:37,257 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-4a224303-3aff-47f8-9ce9-586dfad45f29): finished scanning block pool BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:37,257 [Thread-559] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 12:48 PM with interval of 21600000ms
2020-12-03 07:24:37,257 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-ad168160-c5a9-4603-8799-f50df9b59658): finished scanning block pool BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:37,258 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1688424058-172.17.0.4-1606980274066 (Datanode Uuid b1a31110-b9aa-4184-8cd5-6778c3221b36) service to localhost/127.0.0.1:42543 beginning handshake with NN
2020-12-03 07:24:37,259 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-ad168160-c5a9-4603-8799-f50df9b59658): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-12-03 07:24:37,258 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-4a224303-3aff-47f8-9ce9-586dfad45f29): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:24:37,260 [IPC Server handler 3 on default port 42543] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35478, datanodeUuid=b1a31110-b9aa-4184-8cd5-6778c3221b36, infoPort=38411, infoSecurePort=0, ipcPort=40861, storageInfo=lv=-57;cid=testClusterID;nsid=1090966717;c=1606980274066) storage b1a31110-b9aa-4184-8cd5-6778c3221b36
2020-12-03 07:24:37,260 [IPC Server handler 3 on default port 42543] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:35478
2020-12-03 07:24:37,260 [IPC Server handler 3 on default port 42543] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN b1a31110-b9aa-4184-8cd5-6778c3221b36 (127.0.0.1:35478).
2020-12-03 07:24:37,261 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1688424058-172.17.0.4-1606980274066 (Datanode Uuid b1a31110-b9aa-4184-8cd5-6778c3221b36) service to localhost/127.0.0.1:42543 successfully registered with NN
2020-12-03 07:24:37,261 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:42543 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-12-03 07:24:37,263 [IPC Server handler 4 on default port 42543] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-ad168160-c5a9-4603-8799-f50df9b59658 for DN 127.0.0.1:35478
2020-12-03 07:24:37,264 [IPC Server handler 4 on default port 42543] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-4a224303-3aff-47f8-9ce9-586dfad45f29 for DN 127.0.0.1:35478
2020-12-03 07:24:37,265 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xcac04d2855b46725: Processing first storage report for DS-4a224303-3aff-47f8-9ce9-586dfad45f29 from datanode b1a31110-b9aa-4184-8cd5-6778c3221b36
2020-12-03 07:24:37,265 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xcac04d2855b46725: from storage DS-4a224303-3aff-47f8-9ce9-586dfad45f29 node DatanodeRegistration(127.0.0.1:35478, datanodeUuid=b1a31110-b9aa-4184-8cd5-6778c3221b36, infoPort=38411, infoSecurePort=0, ipcPort=40861, storageInfo=lv=-57;cid=testClusterID;nsid=1090966717;c=1606980274066), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:37,265 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xcac04d2855b46725: Processing first storage report for DS-ad168160-c5a9-4603-8799-f50df9b59658 from datanode b1a31110-b9aa-4184-8cd5-6778c3221b36
2020-12-03 07:24:37,265 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xcac04d2855b46725: from storage DS-ad168160-c5a9-4603-8799-f50df9b59658 node DatanodeRegistration(127.0.0.1:35478, datanodeUuid=b1a31110-b9aa-4184-8cd5-6778c3221b36, infoPort=38411, infoSecurePort=0, ipcPort=40861, storageInfo=lv=-57;cid=testClusterID;nsid=1090966717;c=1606980274066), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:37,266 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xcac04d2855b46725,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 1 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:37,266 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:37,277 [Thread-581] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID fec36e5c-fc03-445a-9259-7b3565aecf05
2020-12-03 07:24:37,279 [Thread-581] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-63280395-91a5-4718-be8d-5460920774c7
2020-12-03 07:24:37,279 [Thread-581] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, StorageType: DISK
2020-12-03 07:24:37,281 [Thread-581] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-de2435ec-3606-4457-bfcf-cb6ef072dc0e
2020-12-03 07:24:37,281 [Thread-581] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, StorageType: DISK
2020-12-03 07:24:37,282 [Thread-581] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:24:37,283 [Thread-581] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:24:37,284 [Thread-581] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:24:37,284 [Thread-581] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:24:37,284 [Thread-581] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:24:37,284 [Thread-581] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:37,285 [Thread-727] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1688424058-172.17.0.4-1606980274066 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-12-03 07:24:37,285 [Thread-728] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1688424058-172.17.0.4-1606980274066 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-12-03 07:24:37,309 [IPC Server handler 6 on default port 42543] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:37,310 [Listener at localhost/38811] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:37,311 [Listener at localhost/38811] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:37,311 [Thread-727] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1688424058-172.17.0.4-1606980274066 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 27ms
2020-12-03 07:24:37,311 [Thread-728] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1688424058-172.17.0.4-1606980274066 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 27ms
2020-12-03 07:24:37,311 [Thread-581] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1688424058-172.17.0.4-1606980274066: 27ms
2020-12-03 07:24:37,312 [Thread-731] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1688424058-172.17.0.4-1606980274066 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-12-03 07:24:37,312 [Thread-732] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1688424058-172.17.0.4-1606980274066 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-12-03 07:24:37,312 [Thread-731] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1688424058-172.17.0.4-1606980274066/current/replicas doesn't exist 
2020-12-03 07:24:37,312 [Thread-732] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1688424058-172.17.0.4-1606980274066/current/replicas doesn't exist 
2020-12-03 07:24:37,312 [Thread-731] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1688424058-172.17.0.4-1606980274066 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 1ms
2020-12-03 07:24:37,312 [Thread-732] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1688424058-172.17.0.4-1606980274066 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 1ms
2020-12-03 07:24:37,312 [Thread-581] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1688424058-172.17.0.4-1606980274066: 1ms
2020-12-03 07:24:37,313 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1688424058-172.17.0.4-1606980274066 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:24:37,313 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1688424058-172.17.0.4-1606980274066 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:24:37,313 [Thread-581] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 1:15 PM with interval of 21600000ms
2020-12-03 07:24:37,313 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-de2435ec-3606-4457-bfcf-cb6ef072dc0e): finished scanning block pool BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:37,313 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-63280395-91a5-4718-be8d-5460920774c7): finished scanning block pool BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:37,314 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1688424058-172.17.0.4-1606980274066 (Datanode Uuid fec36e5c-fc03-445a-9259-7b3565aecf05) service to localhost/127.0.0.1:42543 beginning handshake with NN
2020-12-03 07:24:37,314 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-de2435ec-3606-4457-bfcf-cb6ef072dc0e): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:24:37,314 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-63280395-91a5-4718-be8d-5460920774c7): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:24:37,315 [IPC Server handler 7 on default port 42543] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:45506, datanodeUuid=fec36e5c-fc03-445a-9259-7b3565aecf05, infoPort=46100, infoSecurePort=0, ipcPort=44129, storageInfo=lv=-57;cid=testClusterID;nsid=1090966717;c=1606980274066) storage fec36e5c-fc03-445a-9259-7b3565aecf05
2020-12-03 07:24:37,315 [IPC Server handler 7 on default port 42543] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:45506
2020-12-03 07:24:37,315 [IPC Server handler 7 on default port 42543] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN fec36e5c-fc03-445a-9259-7b3565aecf05 (127.0.0.1:45506).
2020-12-03 07:24:37,316 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1688424058-172.17.0.4-1606980274066 (Datanode Uuid fec36e5c-fc03-445a-9259-7b3565aecf05) service to localhost/127.0.0.1:42543 successfully registered with NN
2020-12-03 07:24:37,316 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:42543 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-12-03 07:24:37,319 [IPC Server handler 8 on default port 42543] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-63280395-91a5-4718-be8d-5460920774c7 for DN 127.0.0.1:45506
2020-12-03 07:24:37,319 [IPC Server handler 8 on default port 42543] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-de2435ec-3606-4457-bfcf-cb6ef072dc0e for DN 127.0.0.1:45506
2020-12-03 07:24:37,320 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x768a96ccea2d2d0a: Processing first storage report for DS-de2435ec-3606-4457-bfcf-cb6ef072dc0e from datanode fec36e5c-fc03-445a-9259-7b3565aecf05
2020-12-03 07:24:37,320 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x768a96ccea2d2d0a: from storage DS-de2435ec-3606-4457-bfcf-cb6ef072dc0e node DatanodeRegistration(127.0.0.1:45506, datanodeUuid=fec36e5c-fc03-445a-9259-7b3565aecf05, infoPort=46100, infoSecurePort=0, ipcPort=44129, storageInfo=lv=-57;cid=testClusterID;nsid=1090966717;c=1606980274066), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:37,320 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x768a96ccea2d2d0a: Processing first storage report for DS-63280395-91a5-4718-be8d-5460920774c7 from datanode fec36e5c-fc03-445a-9259-7b3565aecf05
2020-12-03 07:24:37,321 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x768a96ccea2d2d0a: from storage DS-63280395-91a5-4718-be8d-5460920774c7 node DatanodeRegistration(127.0.0.1:45506, datanodeUuid=fec36e5c-fc03-445a-9259-7b3565aecf05, infoPort=46100, infoSecurePort=0, ipcPort=44129, storageInfo=lv=-57;cid=testClusterID;nsid=1090966717;c=1606980274066), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:37,321 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x768a96ccea2d2d0a,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:37,321 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:37,348 [Thread-603] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 778e686f-955b-4664-b0d5-e7c9ffc5fcab
2020-12-03 07:24:37,348 [Thread-625] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 0c6f8970-d7dd-48b5-8d5e-a875696526d2
2020-12-03 07:24:37,350 [Thread-603] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-532f25f9-06d4-4afd-8691-3f01f1faf6e8
2020-12-03 07:24:37,350 [Thread-603] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, StorageType: DISK
2020-12-03 07:24:37,351 [Thread-625] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-bfb9e676-bcb3-4b9b-8b21-3adff7deb76f
2020-12-03 07:24:37,352 [Thread-625] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, StorageType: DISK
2020-12-03 07:24:37,353 [Thread-603] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-90decd12-583a-4d3d-8ffa-ff0c65a87d71
2020-12-03 07:24:37,353 [Thread-603] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, StorageType: DISK
2020-12-03 07:24:37,354 [Thread-603] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:24:37,354 [Thread-625] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-ec3d9943-1545-4cf6-b156-a296d9b5e16e
2020-12-03 07:24:37,354 [Thread-625] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, StorageType: DISK
2020-12-03 07:24:37,355 [Thread-625] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:24:37,356 [Thread-603] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:24:37,356 [Thread-625] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:24:37,356 [Thread-603] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:24:37,356 [Thread-603] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:24:37,356 [Thread-603] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:24:37,356 [Thread-603] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:37,357 [Thread-625] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:24:37,357 [Thread-625] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:24:37,357 [Thread-625] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:24:37,358 [Thread-741] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1688424058-172.17.0.4-1606980274066 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12...
2020-12-03 07:24:37,358 [Thread-740] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1688424058-172.17.0.4-1606980274066 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11...
2020-12-03 07:24:37,358 [Thread-625] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:37,359 [Thread-742] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1688424058-172.17.0.4-1606980274066 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13...
2020-12-03 07:24:37,359 [Thread-743] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1688424058-172.17.0.4-1606980274066 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14...
2020-12-03 07:24:37,396 [Thread-742] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1688424058-172.17.0.4-1606980274066 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13: 37ms
2020-12-03 07:24:37,396 [Thread-741] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1688424058-172.17.0.4-1606980274066 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12: 38ms
2020-12-03 07:24:37,396 [Thread-743] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1688424058-172.17.0.4-1606980274066 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14: 38ms
2020-12-03 07:24:37,397 [Thread-625] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1688424058-172.17.0.4-1606980274066: 39ms
2020-12-03 07:24:37,398 [Thread-748] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1688424058-172.17.0.4-1606980274066 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13...
2020-12-03 07:24:37,398 [Thread-749] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1688424058-172.17.0.4-1606980274066 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14...
2020-12-03 07:24:37,398 [Thread-748] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1688424058-172.17.0.4-1606980274066/current/replicas doesn't exist 
2020-12-03 07:24:37,398 [Thread-749] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1688424058-172.17.0.4-1606980274066/current/replicas doesn't exist 
2020-12-03 07:24:37,398 [Thread-740] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1688424058-172.17.0.4-1606980274066 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11: 40ms
2020-12-03 07:24:37,398 [Thread-603] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1688424058-172.17.0.4-1606980274066: 41ms
2020-12-03 07:24:37,398 [Thread-749] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1688424058-172.17.0.4-1606980274066 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14: 1ms
2020-12-03 07:24:37,398 [Thread-748] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1688424058-172.17.0.4-1606980274066 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13: 1ms
2020-12-03 07:24:37,399 [Thread-625] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1688424058-172.17.0.4-1606980274066: 2ms
2020-12-03 07:24:37,399 [Thread-750] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1688424058-172.17.0.4-1606980274066 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11...
2020-12-03 07:24:37,399 [Thread-751] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1688424058-172.17.0.4-1606980274066 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12...
2020-12-03 07:24:37,399 [Thread-750] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1688424058-172.17.0.4-1606980274066/current/replicas doesn't exist 
2020-12-03 07:24:37,399 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1688424058-172.17.0.4-1606980274066 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:24:37,399 [Thread-751] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1688424058-172.17.0.4-1606980274066/current/replicas doesn't exist 
2020-12-03 07:24:37,399 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1688424058-172.17.0.4-1606980274066 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:24:37,400 [Thread-750] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1688424058-172.17.0.4-1606980274066 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11: 0ms
2020-12-03 07:24:37,400 [Thread-625] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 7:46 AM with interval of 21600000ms
2020-12-03 07:24:37,400 [Thread-751] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1688424058-172.17.0.4-1606980274066 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12: 0ms
2020-12-03 07:24:37,400 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-bfb9e676-bcb3-4b9b-8b21-3adff7deb76f): finished scanning block pool BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:37,400 [Thread-603] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1688424058-172.17.0.4-1606980274066: 1ms
2020-12-03 07:24:37,400 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-ec3d9943-1545-4cf6-b156-a296d9b5e16e): finished scanning block pool BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:37,401 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1688424058-172.17.0.4-1606980274066 (Datanode Uuid 0c6f8970-d7dd-48b5-8d5e-a875696526d2) service to localhost/127.0.0.1:42543 beginning handshake with NN
2020-12-03 07:24:37,401 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1688424058-172.17.0.4-1606980274066 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:24:37,401 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1688424058-172.17.0.4-1606980274066 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:24:37,401 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-bfb9e676-bcb3-4b9b-8b21-3adff7deb76f): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-12-03 07:24:37,401 [Thread-603] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 12:02 PM with interval of 21600000ms
2020-12-03 07:24:37,401 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-532f25f9-06d4-4afd-8691-3f01f1faf6e8): finished scanning block pool BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:37,401 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-ec3d9943-1545-4cf6-b156-a296d9b5e16e): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-12-03 07:24:37,401 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-90decd12-583a-4d3d-8ffa-ff0c65a87d71): finished scanning block pool BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:37,402 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1688424058-172.17.0.4-1606980274066 (Datanode Uuid 778e686f-955b-4664-b0d5-e7c9ffc5fcab) service to localhost/127.0.0.1:42543 beginning handshake with NN
2020-12-03 07:24:37,403 [IPC Server handler 0 on default port 42543] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:38509, datanodeUuid=0c6f8970-d7dd-48b5-8d5e-a875696526d2, infoPort=45134, infoSecurePort=0, ipcPort=39867, storageInfo=lv=-57;cid=testClusterID;nsid=1090966717;c=1606980274066) storage 0c6f8970-d7dd-48b5-8d5e-a875696526d2
2020-12-03 07:24:37,403 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-532f25f9-06d4-4afd-8691-3f01f1faf6e8): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-12-03 07:24:37,403 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-90decd12-583a-4d3d-8ffa-ff0c65a87d71): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-12-03 07:24:37,403 [IPC Server handler 0 on default port 42543] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38509
2020-12-03 07:24:37,403 [IPC Server handler 0 on default port 42543] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 0c6f8970-d7dd-48b5-8d5e-a875696526d2 (127.0.0.1:38509).
2020-12-03 07:24:37,403 [IPC Server handler 1 on default port 42543] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:39536, datanodeUuid=778e686f-955b-4664-b0d5-e7c9ffc5fcab, infoPort=38347, infoSecurePort=0, ipcPort=39452, storageInfo=lv=-57;cid=testClusterID;nsid=1090966717;c=1606980274066) storage 778e686f-955b-4664-b0d5-e7c9ffc5fcab
2020-12-03 07:24:37,403 [IPC Server handler 1 on default port 42543] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:39536
2020-12-03 07:24:37,404 [IPC Server handler 1 on default port 42543] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 778e686f-955b-4664-b0d5-e7c9ffc5fcab (127.0.0.1:39536).
2020-12-03 07:24:37,404 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1688424058-172.17.0.4-1606980274066 (Datanode Uuid 0c6f8970-d7dd-48b5-8d5e-a875696526d2) service to localhost/127.0.0.1:42543 successfully registered with NN
2020-12-03 07:24:37,404 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:42543 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-12-03 07:24:37,404 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1688424058-172.17.0.4-1606980274066 (Datanode Uuid 778e686f-955b-4664-b0d5-e7c9ffc5fcab) service to localhost/127.0.0.1:42543 successfully registered with NN
2020-12-03 07:24:37,405 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:42543 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-12-03 07:24:37,406 [IPC Server handler 2 on default port 42543] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-bfb9e676-bcb3-4b9b-8b21-3adff7deb76f for DN 127.0.0.1:38509
2020-12-03 07:24:37,407 [IPC Server handler 2 on default port 42543] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-ec3d9943-1545-4cf6-b156-a296d9b5e16e for DN 127.0.0.1:38509
2020-12-03 07:24:37,407 [IPC Server handler 3 on default port 42543] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-532f25f9-06d4-4afd-8691-3f01f1faf6e8 for DN 127.0.0.1:39536
2020-12-03 07:24:37,407 [IPC Server handler 3 on default port 42543] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-90decd12-583a-4d3d-8ffa-ff0c65a87d71 for DN 127.0.0.1:39536
2020-12-03 07:24:37,409 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xddbe9e8baf15def3: Processing first storage report for DS-bfb9e676-bcb3-4b9b-8b21-3adff7deb76f from datanode 0c6f8970-d7dd-48b5-8d5e-a875696526d2
2020-12-03 07:24:37,409 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xddbe9e8baf15def3: from storage DS-bfb9e676-bcb3-4b9b-8b21-3adff7deb76f node DatanodeRegistration(127.0.0.1:38509, datanodeUuid=0c6f8970-d7dd-48b5-8d5e-a875696526d2, infoPort=45134, infoSecurePort=0, ipcPort=39867, storageInfo=lv=-57;cid=testClusterID;nsid=1090966717;c=1606980274066), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:37,409 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x1a8006ff51ee4d27: Processing first storage report for DS-90decd12-583a-4d3d-8ffa-ff0c65a87d71 from datanode 778e686f-955b-4664-b0d5-e7c9ffc5fcab
2020-12-03 07:24:37,409 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x1a8006ff51ee4d27: from storage DS-90decd12-583a-4d3d-8ffa-ff0c65a87d71 node DatanodeRegistration(127.0.0.1:39536, datanodeUuid=778e686f-955b-4664-b0d5-e7c9ffc5fcab, infoPort=38347, infoSecurePort=0, ipcPort=39452, storageInfo=lv=-57;cid=testClusterID;nsid=1090966717;c=1606980274066), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:37,409 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xddbe9e8baf15def3: Processing first storage report for DS-ec3d9943-1545-4cf6-b156-a296d9b5e16e from datanode 0c6f8970-d7dd-48b5-8d5e-a875696526d2
2020-12-03 07:24:37,409 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xddbe9e8baf15def3: from storage DS-ec3d9943-1545-4cf6-b156-a296d9b5e16e node DatanodeRegistration(127.0.0.1:38509, datanodeUuid=0c6f8970-d7dd-48b5-8d5e-a875696526d2, infoPort=45134, infoSecurePort=0, ipcPort=39867, storageInfo=lv=-57;cid=testClusterID;nsid=1090966717;c=1606980274066), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:37,409 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x1a8006ff51ee4d27: Processing first storage report for DS-532f25f9-06d4-4afd-8691-3f01f1faf6e8 from datanode 778e686f-955b-4664-b0d5-e7c9ffc5fcab
2020-12-03 07:24:37,409 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x1a8006ff51ee4d27: from storage DS-532f25f9-06d4-4afd-8691-3f01f1faf6e8 node DatanodeRegistration(127.0.0.1:39536, datanodeUuid=778e686f-955b-4664-b0d5-e7c9ffc5fcab, infoPort=38347, infoSecurePort=0, ipcPort=39452, storageInfo=lv=-57;cid=testClusterID;nsid=1090966717;c=1606980274066), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:37,410 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xddbe9e8baf15def3,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:37,410 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x1a8006ff51ee4d27,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:37,410 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:37,410 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:37,412 [IPC Server handler 6 on default port 42543] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:37,413 [Listener at localhost/38811] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:37,413 [Listener at localhost/38811] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:37,428 [Thread-647] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID fa199516-b4fb-46da-b156-01e59120b35f
2020-12-03 07:24:37,430 [Thread-647] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-aa276f62-89b9-45fb-b1dc-db56c85396ff
2020-12-03 07:24:37,430 [Thread-647] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, StorageType: DISK
2020-12-03 07:24:37,431 [Thread-647] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-5435f169-1195-4ff2-be92-139ab30335f6
2020-12-03 07:24:37,431 [Thread-647] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, StorageType: DISK
2020-12-03 07:24:37,432 [Thread-647] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:24:37,433 [Thread-647] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:24:37,434 [Thread-647] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:24:37,434 [Thread-647] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:24:37,434 [Thread-647] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:24:37,435 [Thread-647] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:37,435 [Thread-760] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1688424058-172.17.0.4-1606980274066 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15...
2020-12-03 07:24:37,435 [Thread-761] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1688424058-172.17.0.4-1606980274066 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16...
2020-12-03 07:24:37,463 [Thread-761] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1688424058-172.17.0.4-1606980274066 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16: 28ms
2020-12-03 07:24:37,463 [Thread-760] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1688424058-172.17.0.4-1606980274066 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15: 28ms
2020-12-03 07:24:37,464 [Thread-647] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1688424058-172.17.0.4-1606980274066: 30ms
2020-12-03 07:24:37,464 [Thread-764] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1688424058-172.17.0.4-1606980274066 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15...
2020-12-03 07:24:37,464 [Thread-765] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1688424058-172.17.0.4-1606980274066 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16...
2020-12-03 07:24:37,464 [Thread-764] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1688424058-172.17.0.4-1606980274066/current/replicas doesn't exist 
2020-12-03 07:24:37,465 [Thread-765] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1688424058-172.17.0.4-1606980274066/current/replicas doesn't exist 
2020-12-03 07:24:37,468 [Thread-764] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1688424058-172.17.0.4-1606980274066 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15: 3ms
2020-12-03 07:24:37,468 [Thread-765] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1688424058-172.17.0.4-1606980274066 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16: 3ms
2020-12-03 07:24:37,468 [Thread-647] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1688424058-172.17.0.4-1606980274066: 3ms
2020-12-03 07:24:37,468 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1688424058-172.17.0.4-1606980274066 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:24:37,468 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1688424058-172.17.0.4-1606980274066 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:24:37,468 [Thread-647] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 12:18 PM with interval of 21600000ms
2020-12-03 07:24:37,468 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-aa276f62-89b9-45fb-b1dc-db56c85396ff): finished scanning block pool BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:37,469 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-5435f169-1195-4ff2-be92-139ab30335f6): finished scanning block pool BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:37,469 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1688424058-172.17.0.4-1606980274066 (Datanode Uuid fa199516-b4fb-46da-b156-01e59120b35f) service to localhost/127.0.0.1:42543 beginning handshake with NN
2020-12-03 07:24:37,470 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-aa276f62-89b9-45fb-b1dc-db56c85396ff): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-12-03 07:24:37,470 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-5435f169-1195-4ff2-be92-139ab30335f6): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-12-03 07:24:37,471 [IPC Server handler 7 on default port 42543] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:40183, datanodeUuid=fa199516-b4fb-46da-b156-01e59120b35f, infoPort=42328, infoSecurePort=0, ipcPort=37033, storageInfo=lv=-57;cid=testClusterID;nsid=1090966717;c=1606980274066) storage fa199516-b4fb-46da-b156-01e59120b35f
2020-12-03 07:24:37,471 [IPC Server handler 7 on default port 42543] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:40183
2020-12-03 07:24:37,471 [IPC Server handler 7 on default port 42543] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN fa199516-b4fb-46da-b156-01e59120b35f (127.0.0.1:40183).
2020-12-03 07:24:37,472 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1688424058-172.17.0.4-1606980274066 (Datanode Uuid fa199516-b4fb-46da-b156-01e59120b35f) service to localhost/127.0.0.1:42543 successfully registered with NN
2020-12-03 07:24:37,472 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:42543 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-12-03 07:24:37,474 [IPC Server handler 8 on default port 42543] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-aa276f62-89b9-45fb-b1dc-db56c85396ff for DN 127.0.0.1:40183
2020-12-03 07:24:37,474 [IPC Server handler 8 on default port 42543] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-5435f169-1195-4ff2-be92-139ab30335f6 for DN 127.0.0.1:40183
2020-12-03 07:24:37,475 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xe74c4a171fa4f825: Processing first storage report for DS-aa276f62-89b9-45fb-b1dc-db56c85396ff from datanode fa199516-b4fb-46da-b156-01e59120b35f
2020-12-03 07:24:37,476 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xe74c4a171fa4f825: from storage DS-aa276f62-89b9-45fb-b1dc-db56c85396ff node DatanodeRegistration(127.0.0.1:40183, datanodeUuid=fa199516-b4fb-46da-b156-01e59120b35f, infoPort=42328, infoSecurePort=0, ipcPort=37033, storageInfo=lv=-57;cid=testClusterID;nsid=1090966717;c=1606980274066), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:37,476 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xe74c4a171fa4f825: Processing first storage report for DS-5435f169-1195-4ff2-be92-139ab30335f6 from datanode fa199516-b4fb-46da-b156-01e59120b35f
2020-12-03 07:24:37,476 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xe74c4a171fa4f825: from storage DS-5435f169-1195-4ff2-be92-139ab30335f6 node DatanodeRegistration(127.0.0.1:40183, datanodeUuid=fa199516-b4fb-46da-b156-01e59120b35f, infoPort=42328, infoSecurePort=0, ipcPort=37033, storageInfo=lv=-57;cid=testClusterID;nsid=1090966717;c=1606980274066), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:37,476 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xe74c4a171fa4f825,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:37,477 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:37,512 [Thread-669] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID d5e826a6-bb6a-4355-9ce3-e94594fc7594
2020-12-03 07:24:37,514 [IPC Server handler 1 on default port 42543] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:37,514 [Thread-669] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-301c141a-2a18-464c-bff6-f3cc085eb873
2020-12-03 07:24:37,515 [Thread-669] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, StorageType: DISK
2020-12-03 07:24:37,516 [Listener at localhost/38811] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:24:37,516 [Listener at localhost/38811] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:24:37,516 [Thread-669] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-ccf36913-5b38-4a68-9d8f-bff774a3138d
2020-12-03 07:24:37,516 [Thread-669] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, StorageType: DISK
2020-12-03 07:24:37,517 [Thread-669] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:24:37,518 [Thread-669] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:24:37,519 [Thread-669] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:24:37,519 [Thread-669] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:24:37,519 [Thread-669] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:24:37,520 [Thread-669] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:37,524 [Thread-771] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1688424058-172.17.0.4-1606980274066 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17...
2020-12-03 07:24:37,524 [Thread-772] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1688424058-172.17.0.4-1606980274066 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18...
2020-12-03 07:24:37,552 [Thread-771] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1688424058-172.17.0.4-1606980274066 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17: 28ms
2020-12-03 07:24:37,552 [Thread-772] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1688424058-172.17.0.4-1606980274066 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18: 28ms
2020-12-03 07:24:37,553 [Thread-669] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1688424058-172.17.0.4-1606980274066: 34ms
2020-12-03 07:24:37,554 [Thread-775] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1688424058-172.17.0.4-1606980274066 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17...
2020-12-03 07:24:37,554 [Thread-775] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1688424058-172.17.0.4-1606980274066/current/replicas doesn't exist 
2020-12-03 07:24:37,554 [Thread-776] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1688424058-172.17.0.4-1606980274066 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18...
2020-12-03 07:24:37,554 [Thread-776] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1688424058-172.17.0.4-1606980274066/current/replicas doesn't exist 
2020-12-03 07:24:37,554 [Thread-775] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1688424058-172.17.0.4-1606980274066 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17: 1ms
2020-12-03 07:24:37,555 [Thread-776] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1688424058-172.17.0.4-1606980274066 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18: 0ms
2020-12-03 07:24:37,555 [Thread-669] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1688424058-172.17.0.4-1606980274066: 1ms
2020-12-03 07:24:37,555 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1688424058-172.17.0.4-1606980274066 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:24:37,555 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1688424058-172.17.0.4-1606980274066 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:24:37,555 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-ccf36913-5b38-4a68-9d8f-bff774a3138d): finished scanning block pool BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:37,555 [Thread-669] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 10:33 AM with interval of 21600000ms
2020-12-03 07:24:37,555 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-301c141a-2a18-464c-bff6-f3cc085eb873): finished scanning block pool BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:37,556 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1688424058-172.17.0.4-1606980274066 (Datanode Uuid d5e826a6-bb6a-4355-9ce3-e94594fc7594) service to localhost/127.0.0.1:42543 beginning handshake with NN
2020-12-03 07:24:37,557 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-301c141a-2a18-464c-bff6-f3cc085eb873): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-12-03 07:24:37,557 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-ccf36913-5b38-4a68-9d8f-bff774a3138d): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-12-03 07:24:37,557 [IPC Server handler 2 on default port 42543] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:39670, datanodeUuid=d5e826a6-bb6a-4355-9ce3-e94594fc7594, infoPort=40910, infoSecurePort=0, ipcPort=38811, storageInfo=lv=-57;cid=testClusterID;nsid=1090966717;c=1606980274066) storage d5e826a6-bb6a-4355-9ce3-e94594fc7594
2020-12-03 07:24:37,558 [IPC Server handler 2 on default port 42543] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:39670
2020-12-03 07:24:37,558 [IPC Server handler 2 on default port 42543] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN d5e826a6-bb6a-4355-9ce3-e94594fc7594 (127.0.0.1:39670).
2020-12-03 07:24:37,559 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1688424058-172.17.0.4-1606980274066 (Datanode Uuid d5e826a6-bb6a-4355-9ce3-e94594fc7594) service to localhost/127.0.0.1:42543 successfully registered with NN
2020-12-03 07:24:37,559 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:42543 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-12-03 07:24:37,564 [IPC Server handler 3 on default port 42543] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-301c141a-2a18-464c-bff6-f3cc085eb873 for DN 127.0.0.1:39670
2020-12-03 07:24:37,564 [IPC Server handler 3 on default port 42543] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-ccf36913-5b38-4a68-9d8f-bff774a3138d for DN 127.0.0.1:39670
2020-12-03 07:24:37,567 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x2a136109e6dc22fc: Processing first storage report for DS-301c141a-2a18-464c-bff6-f3cc085eb873 from datanode d5e826a6-bb6a-4355-9ce3-e94594fc7594
2020-12-03 07:24:37,567 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x2a136109e6dc22fc: from storage DS-301c141a-2a18-464c-bff6-f3cc085eb873 node DatanodeRegistration(127.0.0.1:39670, datanodeUuid=d5e826a6-bb6a-4355-9ce3-e94594fc7594, infoPort=40910, infoSecurePort=0, ipcPort=38811, storageInfo=lv=-57;cid=testClusterID;nsid=1090966717;c=1606980274066), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:37,567 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x2a136109e6dc22fc: Processing first storage report for DS-ccf36913-5b38-4a68-9d8f-bff774a3138d from datanode d5e826a6-bb6a-4355-9ce3-e94594fc7594
2020-12-03 07:24:37,567 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x2a136109e6dc22fc: from storage DS-ccf36913-5b38-4a68-9d8f-bff774a3138d node DatanodeRegistration(127.0.0.1:39670, datanodeUuid=d5e826a6-bb6a-4355-9ce3-e94594fc7594, infoPort=40910, infoSecurePort=0, ipcPort=38811, storageInfo=lv=-57;cid=testClusterID;nsid=1090966717;c=1606980274066), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:37,567 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x2a136109e6dc22fc,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:37,568 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:37,618 [IPC Server handler 5 on default port 42543] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:37,619 [Listener at localhost/38811] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:24:37,621 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSClient.java:<init>(318)) - Sets dfs.client.block.write.replace-datanode-on-failure.min-replication to 0
2020-12-03 07:24:37,622 [IPC Server handler 6 on default port 42543] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:37,624 [Listener at localhost/38811] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:24:37,624 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSClient.java:<init>(318)) - Sets dfs.client.block.write.replace-datanode-on-failure.min-replication to 0
2020-12-03 07:24:37,627 [IPC Server handler 7 on default port 42543] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=addErasureCodingPolicies	src=[RS-6-3-64k]	dst=null	perm=null	proto=rpc
2020-12-03 07:24:37,629 [IPC Server handler 8 on default port 42543] INFO  namenode.ErasureCodingPolicyManager (ErasureCodingPolicyManager.java:enablePolicy(429)) - Enable the erasure coding policy RS-6-3-64k
2020-12-03 07:24:37,629 [IPC Server handler 8 on default port 42543] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=enableErasureCodingPolicy	src=RS-6-3-64k	dst=null	perm=null	proto=rpc
2020-12-03 07:24:37,630 [IPC Server handler 9 on default port 42543] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=enableErasureCodingPolicy	src=RS-6-3-1024k	dst=null	perm=null	proto=rpc
2020-12-03 07:24:37,631 [IPC Server handler 0 on default port 42543] INFO  namenode.ErasureCodingPolicyManager (ErasureCodingPolicyManager.java:enablePolicy(429)) - Enable the erasure coding policy RS-3-2-1024k
2020-12-03 07:24:37,631 [IPC Server handler 0 on default port 42543] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=enableErasureCodingPolicy	src=RS-3-2-1024k	dst=null	perm=null	proto=rpc
2020-12-03 07:24:37,632 [IPC Server handler 1 on default port 42543] INFO  namenode.ErasureCodingPolicyManager (ErasureCodingPolicyManager.java:enablePolicy(429)) - Enable the erasure coding policy RS-LEGACY-6-3-1024k
2020-12-03 07:24:37,632 [IPC Server handler 1 on default port 42543] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=enableErasureCodingPolicy	src=RS-LEGACY-6-3-1024k	dst=null	perm=null	proto=rpc
2020-12-03 07:24:37,633 [IPC Server handler 2 on default port 42543] INFO  namenode.ErasureCodingPolicyManager (ErasureCodingPolicyManager.java:enablePolicy(429)) - Enable the erasure coding policy XOR-2-1-1024k
2020-12-03 07:24:37,634 [IPC Server handler 2 on default port 42543] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=enableErasureCodingPolicy	src=XOR-2-1-1024k	dst=null	perm=null	proto=rpc
2020-12-03 07:24:37,635 [IPC Server handler 3 on default port 42543] INFO  namenode.ErasureCodingPolicyManager (ErasureCodingPolicyManager.java:enablePolicy(429)) - Enable the erasure coding policy RS-10-4-1024k
2020-12-03 07:24:37,635 [IPC Server handler 3 on default port 42543] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=enableErasureCodingPolicy	src=RS-10-4-1024k	dst=null	perm=null	proto=rpc
2020-12-03 07:24:37,635 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSClient.java:primitiveMkdir(2423)) - /TestDFSStripedOutputStreamWithFailureBase: masked={ masked: rwxr-xr-x, unmasked: rwxrwxrwx }
2020-12-03 07:24:37,637 [IPC Server handler 4 on default port 42543] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/TestDFSStripedOutputStreamWithFailureBase	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:24:37,638 [IPC Server handler 5 on default port 42543] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setErasureCodingPolicy	src=/TestDFSStripedOutputStreamWithFailureBase	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:24:37,639 [Listener at localhost/38811] INFO  hdfs.TestDFSStripedOutputStreamWithFailureBase (TestDFSStripedOutputStreamWithFailureBase.java:runTest(299)) - fullPath=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226]
2020-12-03 07:24:37,639 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSClient.java:create(1216)) - /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226]: masked={ masked: rw-r--r--, unmasked: rw-rw-rw- }
2020-12-03 07:24:37,641 [IPC Server handler 6 on default port 42543] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226]	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:24:37,641 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:37,642 [Listener at localhost/38811] DEBUG hdfs.DFSOutputStream (DFSStripedOutputStream.java:<init>(293)) - Creating DFSStripedOutputStream for /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226]
2020-12-03 07:24:37,642 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:37,649 [Listener at localhost/38811] DEBUG hdfs.DFSOutputStream (DFSStripedOutputStream.java:allocateNewBlock(472)) - Excluding DataNodes when allocating new block: []
2020-12-03 07:24:37,654 [Listener at localhost/38811] DEBUG hdfs.DFSOutputStream (DFSStripedOutputStream.java:allocateNewBlock(478)) - Allocating new block group. The previous block group: null
2020-12-03 07:24:37,655 [IPC Server handler 7 on default port 42543] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(427)) - storageTypes={DISK=9}
2020-12-03 07:24:37,657 [IPC Server handler 7 on default port 42543] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_-9223372036854775792_1001, replicas=127.0.0.1:40183, 127.0.0.1:45564, 127.0.0.1:38509, 127.0.0.1:35995, 127.0.0.1:45506, 127.0.0.1:46077, 127.0.0.1:35478, 127.0.0.1:39536, 127.0.0.1:39670 for /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226]
2020-12-03 07:24:37,659 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=0, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], packetSize=65016, chunksPerPacket=126, bytesCurBlock=0, DFSStripedOutputStream:#0: block==null
2020-12-03 07:24:37,659 [Listener at localhost/38811] INFO  hdfs.TestDFSStripedOutputStreamWithFailureBase (TestDFSStripedOutputStreamWithFailureBase.java:getGenerationStamp(376)) - getGenerationStamp returns 1001
2020-12-03 07:24:37,664 [Listener at localhost/38811] DEBUG hdfs.DFSOutputStream (DFSStripedOutputStream.java:enqueueCurrentPacketFull(576)) - enqueue full packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 64512, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], bytesCurBlock=64512, blockSize=262144, appendChunk=false, #0: block==null
2020-12-03 07:24:37,664 [Listener at localhost/38811] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 64512, #0: block==null
2020-12-03 07:24:37,664 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:37,665 [Thread-780] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, #0: block==null
2020-12-03 07:24:37,665 [Thread-780] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: #0: block==null
2020-12-03 07:24:37,665 [Thread-780] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:40183,DS-aa276f62-89b9-45fb-b1dc-db56c85396ff,DISK]], #0: blk_-9223372036854775792_1001
2020-12-03 07:24:37,665 [Thread-780] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:40183
2020-12-03 07:24:37,665 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=1, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], packetSize=65016, chunksPerPacket=126, bytesCurBlock=64512, DFSStripedOutputStream:#0: blk_-9223372036854775792_1001
2020-12-03 07:24:37,665 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:37,666 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=0, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], packetSize=65016, chunksPerPacket=126, bytesCurBlock=0, DFSStripedOutputStream:#1: block==null
2020-12-03 07:24:37,666 [Thread-780] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-12-03 07:24:37,666 [Thread-780] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:37,668 [DataXceiver for client DFSClient_NONMAPREDUCE_-1548708192_1 at /127.0.0.1:46792 [Receiving block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775792_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775792_1001 src: /127.0.0.1:46792 dest: /127.0.0.1:40183
2020-12-03 07:24:37,669 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775792_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:40183,DS-aa276f62-89b9-45fb-b1dc-db56c85396ff,DISK]] storageTypes [DISK] storageIDs [DS-aa276f62-89b9-45fb-b1dc-db56c85396ff]
2020-12-03 07:24:37,673 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775792_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - #0: blk_-9223372036854775792_1001 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 64512
2020-12-03 07:24:37,676 [ResponseProcessor for block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775792_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2020-12-03 07:24:37,678 [Listener at localhost/38811] INFO  hdfs.TestDFSStripedOutputStreamWithFailureBase (TestDFSStripedOutputStreamWithFailureBase.java:getGenerationStamp(376)) - getGenerationStamp returns 1001
2020-12-03 07:24:37,678 [Listener at localhost/38811] INFO  hdfs.TestDFSStripedOutputStreamWithFailureBase (TestDFSStripedOutputStreamWithFailureBase.java:killDatanode(410)) - killDatanode 4: DatanodeInfoWithStorage[127.0.0.1:45506,DS-de2435ec-3606-4457-bfcf-cb6ef072dc0e,DISK], pos=131114
2020-12-03 07:24:37,678 [Listener at localhost/38811] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopDataNode(2331)) - MiniDFSCluster Stopping DataNode 127.0.0.1:45506 from a total of 9 datanodes.
2020-12-03 07:24:37,679 [Listener at localhost/38811] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:24:37,679 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@e04ccf8] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:24:37,680 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-63280395-91a5-4718-be8d-5460920774c7) exiting.
2020-12-03 07:24:37,680 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-de2435ec-3606-4457-bfcf-cb6ef072dc0e) exiting.
2020-12-03 07:24:37,695 [Listener at localhost/38811] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6ee8dcd3{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:24:37,695 [Listener at localhost/38811] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@a20b94b{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:37,695 [Listener at localhost/38811] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@453d496b{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:37,696 [Listener at localhost/38811] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@191a709b{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:37,696 [Listener at localhost/38811] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 44129
2020-12-03 07:24:37,700 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:37,700 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:37,701 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:24:37,702 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1688424058-172.17.0.4-1606980274066 (Datanode Uuid fec36e5c-fc03-445a-9259-7b3565aecf05) service to localhost/127.0.0.1:42543
2020-12-03 07:24:37,702 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1688424058-172.17.0.4-1606980274066 (Datanode Uuid fec36e5c-fc03-445a-9259-7b3565aecf05)
2020-12-03 07:24:37,702 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:37,702 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1688424058-172.17.0.4-1606980274066] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:37,703 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1688424058-172.17.0.4-1606980274066] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:37,706 [Listener at localhost/38811] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:24:37,707 [Listener at localhost/38811] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:24:37,707 [Listener at localhost/38811] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:24:37,707 [Listener at localhost/38811] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:24:37,709 [Listener at localhost/38811] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:24:37,710 [Listener at localhost/38811] DEBUG hdfs.DFSOutputStream (DFSStripedOutputStream.java:enqueueCurrentPacketFull(576)) - enqueue full packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 64512, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], bytesCurBlock=64512, blockSize=262144, appendChunk=false, #1: block==null
2020-12-03 07:24:37,710 [Listener at localhost/38811] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 64512, #1: block==null
2020-12-03 07:24:37,710 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:37,711 [Thread-781] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, #1: block==null
2020-12-03 07:24:37,711 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=1, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], packetSize=65016, chunksPerPacket=126, bytesCurBlock=64512, DFSStripedOutputStream:#1: block==null
2020-12-03 07:24:37,711 [Thread-781] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: #1: block==null
2020-12-03 07:24:37,711 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:37,711 [Thread-781] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:45564,DS-780c3aad-5133-4c8c-a94b-8deef7fd424f,DISK]], #1: blk_-9223372036854775791_1001
2020-12-03 07:24:37,711 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=0, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], packetSize=65016, chunksPerPacket=126, bytesCurBlock=0, DFSStripedOutputStream:#2: block==null
2020-12-03 07:24:37,711 [Thread-781] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:45564
2020-12-03 07:24:37,712 [Thread-781] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-12-03 07:24:37,712 [Thread-781] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:37,713 [DataXceiver for client DFSClient_NONMAPREDUCE_-1548708192_1 at /127.0.0.1:55700 [Receiving block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775791_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775791_1001 src: /127.0.0.1:55700 dest: /127.0.0.1:45564
2020-12-03 07:24:37,714 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775791_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:45564,DS-780c3aad-5133-4c8c-a94b-8deef7fd424f,DISK]] storageTypes [DISK] storageIDs [DS-780c3aad-5133-4c8c-a94b-8deef7fd424f]
2020-12-03 07:24:37,714 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775791_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - #1: blk_-9223372036854775791_1001 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 64512
2020-12-03 07:24:37,718 [ResponseProcessor for block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775791_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2020-12-03 07:24:37,720 [Listener at localhost/38811] DEBUG hdfs.DFSOutputStream (DFSStripedOutputStream.java:enqueueCurrentPacketFull(576)) - enqueue full packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 64512, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], bytesCurBlock=64512, blockSize=262144, appendChunk=false, #2: block==null
2020-12-03 07:24:37,720 [Listener at localhost/38811] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 64512, #2: block==null
2020-12-03 07:24:37,720 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:37,721 [Thread-782] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, #2: block==null
2020-12-03 07:24:37,721 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=1, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], packetSize=65016, chunksPerPacket=126, bytesCurBlock=64512, DFSStripedOutputStream:#2: block==null
2020-12-03 07:24:37,721 [Thread-782] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: #2: block==null
2020-12-03 07:24:37,721 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:37,721 [Thread-782] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:38509,DS-bfb9e676-bcb3-4b9b-8b21-3adff7deb76f,DISK]], #2: blk_-9223372036854775790_1001
2020-12-03 07:24:37,721 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=0, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], packetSize=65016, chunksPerPacket=126, bytesCurBlock=0, DFSStripedOutputStream:#3: block==null
2020-12-03 07:24:37,721 [Thread-782] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:38509
2020-12-03 07:24:37,722 [Thread-782] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-12-03 07:24:37,722 [Thread-782] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:37,722 [DataXceiver for client DFSClient_NONMAPREDUCE_-1548708192_1 at /127.0.0.1:34072 [Receiving block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775790_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775790_1001 src: /127.0.0.1:34072 dest: /127.0.0.1:38509
2020-12-03 07:24:37,724 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775790_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:38509,DS-bfb9e676-bcb3-4b9b-8b21-3adff7deb76f,DISK]] storageTypes [DISK] storageIDs [DS-bfb9e676-bcb3-4b9b-8b21-3adff7deb76f]
2020-12-03 07:24:37,724 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775790_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - #2: blk_-9223372036854775790_1001 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 64512
2020-12-03 07:24:37,727 [ResponseProcessor for block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775790_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2020-12-03 07:24:37,729 [Listener at localhost/38811] INFO  hdfs.TestDFSStripedOutputStreamWithFailureBase (TestDFSStripedOutputStreamWithFailureBase.java:getGenerationStamp(376)) - getGenerationStamp returns 1001
2020-12-03 07:24:37,729 [Listener at localhost/38811] INFO  hdfs.TestDFSStripedOutputStreamWithFailureBase (TestDFSStripedOutputStreamWithFailureBase.java:killDatanode(410)) - killDatanode 5: DatanodeInfoWithStorage[127.0.0.1:46077,DS-ae8ccbfd-7348-435f-88e1-d0087e04a4d2,DISK], pos=262227
2020-12-03 07:24:37,729 [Listener at localhost/38811] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopDataNode(2331)) - MiniDFSCluster Stopping DataNode 127.0.0.1:46077 from a total of 8 datanodes.
2020-12-03 07:24:37,730 [Listener at localhost/38811] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:24:37,730 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@6edcd0d8] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:24:37,731 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-42917285-e317-4fcd-ab18-58b06e3abf14) exiting.
2020-12-03 07:24:37,731 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-ae8ccbfd-7348-435f-88e1-d0087e04a4d2) exiting.
2020-12-03 07:24:37,745 [Listener at localhost/38811] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@476a736d{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:24:37,745 [Listener at localhost/38811] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@5f80fa43{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:37,746 [Listener at localhost/38811] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6fd1660{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:37,746 [Listener at localhost/38811] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2a27cb34{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:37,747 [Listener at localhost/38811] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 33305
2020-12-03 07:24:37,750 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:37,752 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:37,754 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:24:37,755 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1688424058-172.17.0.4-1606980274066 (Datanode Uuid c063fb49-df5c-4081-9d45-b22fc275fc8d) service to localhost/127.0.0.1:42543
2020-12-03 07:24:37,764 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1688424058-172.17.0.4-1606980274066 (Datanode Uuid c063fb49-df5c-4081-9d45-b22fc275fc8d)
2020-12-03 07:24:37,764 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:37,764 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1688424058-172.17.0.4-1606980274066] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:37,764 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1688424058-172.17.0.4-1606980274066] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:37,769 [Listener at localhost/38811] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:24:37,769 [Listener at localhost/38811] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:24:37,770 [Listener at localhost/38811] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:24:37,770 [Listener at localhost/38811] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:24:37,772 [Listener at localhost/38811] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:24:37,772 [Listener at localhost/38811] DEBUG hdfs.DFSOutputStream (DFSStripedOutputStream.java:enqueueCurrentPacketFull(576)) - enqueue full packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 64512, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], bytesCurBlock=64512, blockSize=262144, appendChunk=false, #3: block==null
2020-12-03 07:24:37,773 [Listener at localhost/38811] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 64512, #3: block==null
2020-12-03 07:24:37,773 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:37,774 [Thread-783] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, #3: block==null
2020-12-03 07:24:37,774 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=1, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], packetSize=65016, chunksPerPacket=126, bytesCurBlock=64512, DFSStripedOutputStream:#3: block==null
2020-12-03 07:24:37,774 [Thread-783] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: #3: block==null
2020-12-03 07:24:37,774 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:37,774 [Thread-783] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:35995,DS-d72315d1-2ea3-44c3-ade3-d7b892bdf67f,DISK]], #3: blk_-9223372036854775789_1001
2020-12-03 07:24:37,774 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=0, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], packetSize=65016, chunksPerPacket=126, bytesCurBlock=0, DFSStripedOutputStream:#4: block==null
2020-12-03 07:24:37,774 [Thread-783] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:35995
2020-12-03 07:24:37,775 [Thread-783] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-12-03 07:24:37,775 [Thread-783] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:37,776 [DataXceiver for client DFSClient_NONMAPREDUCE_-1548708192_1 at /127.0.0.1:42728 [Receiving block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775789_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775789_1001 src: /127.0.0.1:42728 dest: /127.0.0.1:35995
2020-12-03 07:24:37,778 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775789_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:35995,DS-d72315d1-2ea3-44c3-ade3-d7b892bdf67f,DISK]] storageTypes [DISK] storageIDs [DS-d72315d1-2ea3-44c3-ade3-d7b892bdf67f]
2020-12-03 07:24:37,778 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775789_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - #3: blk_-9223372036854775789_1001 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 64512
2020-12-03 07:24:37,782 [ResponseProcessor for block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775789_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2020-12-03 07:24:37,783 [Listener at localhost/38811] DEBUG hdfs.DFSOutputStream (DFSStripedOutputStream.java:enqueueCurrentPacketFull(576)) - enqueue full packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 64512, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], bytesCurBlock=64512, blockSize=262144, appendChunk=false, #4: block==null
2020-12-03 07:24:37,783 [Listener at localhost/38811] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 64512, #4: block==null
2020-12-03 07:24:37,784 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:37,785 [Thread-784] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, #4: block==null
2020-12-03 07:24:37,785 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=1, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], packetSize=65016, chunksPerPacket=126, bytesCurBlock=64512, DFSStripedOutputStream:#4: block==null
2020-12-03 07:24:37,785 [Thread-784] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: #4: block==null
2020-12-03 07:24:37,785 [Thread-784] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:45506,DS-de2435ec-3606-4457-bfcf-cb6ef072dc0e,DISK]], #4: blk_-9223372036854775788_1001
2020-12-03 07:24:37,785 [Thread-784] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:45506
2020-12-03 07:24:37,785 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:37,785 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=0, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], packetSize=65016, chunksPerPacket=126, bytesCurBlock=0, DFSStripedOutputStream:#5: block==null
2020-12-03 07:24:37,786 [Thread-784] INFO  hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1790)) - Exception in createBlockOutputStream #4: blk_-9223372036854775788_1001
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:533)
	at org.apache.hadoop.hdfs.DataStreamer.createSocketForPipeline(DataStreamer.java:253)
	at org.apache.hadoop.hdfs.DataStreamer.createBlockOutputStream(DataStreamer.java:1725)
	at org.apache.hadoop.hdfs.StripedDataStreamer.nextBlockOutputStream(StripedDataStreamer.java:106)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:716)
	at org.apache.hadoop.hdfs.StripedDataStreamer.run(StripedDataStreamer.java:46)
2020-12-03 07:24:37,786 [Thread-784] WARN  hdfs.DataStreamer (StripedDataStreamer.java:nextBlockOutputStream(112)) - Excluding datanode DatanodeInfoWithStorage[127.0.0.1:45506,DS-de2435ec-3606-4457-bfcf-cb6ef072dc0e,DISK]
2020-12-03 07:24:37,786 [Thread-784] WARN  hdfs.DataStreamer (DataStreamer.java:run(826)) - DataStreamer Exception
java.io.IOException: Unable to create new block.#4: failed, block==null
	at org.apache.hadoop.hdfs.StripedDataStreamer.nextBlockOutputStream(StripedDataStreamer.java:114)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:716)
	at org.apache.hadoop.hdfs.StripedDataStreamer.run(StripedDataStreamer.java:46)
2020-12-03 07:24:37,786 [Thread-784] DEBUG hdfs.DataStreamer (DataStreamer.java:processDatanodeOrExternalError(1229)) - start process datanode/external error, #4: failed, block==null
2020-12-03 07:24:37,786 [Thread-784] WARN  hdfs.DataStreamer (DataStreamer.java:setupPipelineForAppendOrRecovery(1476)) - Could not get block locations. Source file "/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226]" - Aborting...#4: failed, block==null
2020-12-03 07:24:37,790 [Listener at localhost/38811] DEBUG hdfs.DFSOutputStream (DFSStripedOutputStream.java:enqueueCurrentPacketFull(576)) - enqueue full packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 64512, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], bytesCurBlock=64512, blockSize=262144, appendChunk=false, #5: block==null
2020-12-03 07:24:37,790 [Listener at localhost/38811] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 64512, #5: block==null
2020-12-03 07:24:37,791 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:37,792 [Thread-785] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, #5: block==null
2020-12-03 07:24:37,792 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=1, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], packetSize=65016, chunksPerPacket=126, bytesCurBlock=64512, DFSStripedOutputStream:#5: block==null
2020-12-03 07:24:37,792 [Thread-785] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: #5: block==null
2020-12-03 07:24:37,792 [Thread-785] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:46077,DS-ae8ccbfd-7348-435f-88e1-d0087e04a4d2,DISK]], #5: blk_-9223372036854775787_1001
2020-12-03 07:24:37,792 [Thread-785] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:46077
2020-12-03 07:24:37,792 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:37,792 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=0, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], packetSize=65016, chunksPerPacket=126, bytesCurBlock=0, DFSStripedOutputStream:#6: block==null
2020-12-03 07:24:37,792 [Thread-785] INFO  hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1790)) - Exception in createBlockOutputStream #5: blk_-9223372036854775787_1001
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:714)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:533)
	at org.apache.hadoop.hdfs.DataStreamer.createSocketForPipeline(DataStreamer.java:253)
	at org.apache.hadoop.hdfs.DataStreamer.createBlockOutputStream(DataStreamer.java:1725)
	at org.apache.hadoop.hdfs.StripedDataStreamer.nextBlockOutputStream(StripedDataStreamer.java:106)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:716)
	at org.apache.hadoop.hdfs.StripedDataStreamer.run(StripedDataStreamer.java:46)
2020-12-03 07:24:37,793 [Listener at localhost/38811] DEBUG hdfs.DFSOutputStream (DFSStripedOutputStream.java:enqueueCurrentPacketFull(576)) - enqueue full packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 64512, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], bytesCurBlock=64512, blockSize=262144, appendChunk=false, #6: block==null
2020-12-03 07:24:37,793 [Thread-785] WARN  hdfs.DataStreamer (StripedDataStreamer.java:nextBlockOutputStream(112)) - Excluding datanode DatanodeInfoWithStorage[127.0.0.1:46077,DS-ae8ccbfd-7348-435f-88e1-d0087e04a4d2,DISK]
2020-12-03 07:24:37,793 [Listener at localhost/38811] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 64512, #6: block==null
2020-12-03 07:24:37,793 [Thread-785] WARN  hdfs.DataStreamer (DataStreamer.java:run(826)) - DataStreamer Exception
java.io.IOException: Unable to create new block.#5: failed, block==null
	at org.apache.hadoop.hdfs.StripedDataStreamer.nextBlockOutputStream(StripedDataStreamer.java:114)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:716)
	at org.apache.hadoop.hdfs.StripedDataStreamer.run(StripedDataStreamer.java:46)
2020-12-03 07:24:37,795 [Thread-786] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, #6: block==null
2020-12-03 07:24:37,797 [Thread-786] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: #6: block==null
2020-12-03 07:24:37,793 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:37,800 [Thread-786] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:35478,DS-4a224303-3aff-47f8-9ce9-586dfad45f29,DISK]], #6: blk_-9223372036854775786_1001
2020-12-03 07:24:37,795 [Thread-785] DEBUG hdfs.DataStreamer (DataStreamer.java:processDatanodeOrExternalError(1229)) - start process datanode/external error, #5: failed, block==null
2020-12-03 07:24:37,800 [Thread-786] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:35478
2020-12-03 07:24:37,800 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=1, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], packetSize=65016, chunksPerPacket=126, bytesCurBlock=64512, DFSStripedOutputStream:#6: blk_-9223372036854775786_1001
2020-12-03 07:24:37,801 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:37,800 [Thread-785] WARN  hdfs.DataStreamer (DataStreamer.java:setupPipelineForAppendOrRecovery(1476)) - Could not get block locations. Source file "/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226]" - Aborting...#5: failed, block==null
2020-12-03 07:24:37,801 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=0, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], packetSize=65016, chunksPerPacket=126, bytesCurBlock=0, DFSStripedOutputStream:#7: block==null
2020-12-03 07:24:37,801 [Thread-786] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-12-03 07:24:37,802 [Listener at localhost/38811] DEBUG hdfs.DFSOutputStream (DFSStripedOutputStream.java:enqueueCurrentPacketFull(576)) - enqueue full packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 64512, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], bytesCurBlock=64512, blockSize=262144, appendChunk=false, #7: block==null
2020-12-03 07:24:37,802 [Thread-786] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:37,802 [Listener at localhost/38811] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 64512, #7: block==null
2020-12-03 07:24:37,803 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:37,804 [Thread-787] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, #7: block==null
2020-12-03 07:24:37,804 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=1, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], packetSize=65016, chunksPerPacket=126, bytesCurBlock=64512, DFSStripedOutputStream:#7: block==null
2020-12-03 07:24:37,804 [Thread-787] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: #7: block==null
2020-12-03 07:24:37,804 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:37,804 [Thread-787] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:39536,DS-90decd12-583a-4d3d-8ffa-ff0c65a87d71,DISK]], #7: blk_-9223372036854775785_1001
2020-12-03 07:24:37,804 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=0, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], packetSize=65016, chunksPerPacket=126, bytesCurBlock=0, DFSStripedOutputStream:#8: block==null
2020-12-03 07:24:37,804 [DataXceiver for client DFSClient_NONMAPREDUCE_-1548708192_1 at /127.0.0.1:59588 [Receiving block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775786_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775786_1001 src: /127.0.0.1:59588 dest: /127.0.0.1:35478
2020-12-03 07:24:37,804 [Thread-787] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:39536
2020-12-03 07:24:37,805 [Listener at localhost/38811] DEBUG hdfs.DFSOutputStream (DFSStripedOutputStream.java:enqueueCurrentPacketFull(576)) - enqueue full packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 64512, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], bytesCurBlock=64512, blockSize=262144, appendChunk=false, #8: block==null
2020-12-03 07:24:37,805 [Listener at localhost/38811] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 64512, #8: block==null
2020-12-03 07:24:37,805 [Thread-787] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-12-03 07:24:37,805 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:37,807 [Thread-788] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=PIPELINE_SETUP_CREATE, #8: block==null
2020-12-03 07:24:37,808 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775786_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:35478,DS-4a224303-3aff-47f8-9ce9-586dfad45f29,DISK]] storageTypes [DISK] storageIDs [DS-4a224303-3aff-47f8-9ce9-586dfad45f29]
2020-12-03 07:24:37,805 [Thread-787] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:37,808 [Thread-788] DEBUG hdfs.DataStreamer (DataStreamer.java:run(715)) - Allocating new block: #8: block==null
2020-12-03 07:24:37,807 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=1, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], packetSize=65016, chunksPerPacket=126, bytesCurBlock=64512, DFSStripedOutputStream:#8: block==null
2020-12-03 07:24:37,809 [Thread-788] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:39670,DS-301c141a-2a18-464c-bff6-f3cc085eb873,DISK]], #8: blk_-9223372036854775784_1001
2020-12-03 07:24:37,808 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775786_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - #6: blk_-9223372036854775786_1001 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 64512
2020-12-03 07:24:37,809 [Thread-788] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:39670
2020-12-03 07:24:37,809 [Listener at localhost/38811] DEBUG hdfs.DFSOutputStream (DFSStripedOutputStream.java:checkStreamers(390)) - checkStreamers: [#0: blk_-9223372036854775792_1001, #1: blk_-9223372036854775791_1001, #2: blk_-9223372036854775790_1001, #3: blk_-9223372036854775789_1001, #4: failed, block==null, #5: failed, block==null, #6: blk_-9223372036854775786_1001, #7: blk_-9223372036854775785_1001, #8: blk_-9223372036854775784_1001]
2020-12-03 07:24:37,810 [Listener at localhost/38811] DEBUG hdfs.DFSOutputStream (DFSStripedOutputStream.java:checkStreamers(391)) - healthy streamer count=7
2020-12-03 07:24:37,810 [Listener at localhost/38811] DEBUG hdfs.DFSOutputStream (DFSStripedOutputStream.java:checkStreamers(392)) - original failed streamers: []
2020-12-03 07:24:37,810 [DataXceiver for client DFSClient_NONMAPREDUCE_-1548708192_1 at /127.0.0.1:38734 [Receiving block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775785_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775785_1001 src: /127.0.0.1:38734 dest: /127.0.0.1:39536
2020-12-03 07:24:37,810 [Listener at localhost/38811] DEBUG hdfs.DFSOutputStream (DFSStripedOutputStream.java:checkStreamers(393)) - newly failed streamers: [#4: failed, block==null, #5: failed, block==null]
2020-12-03 07:24:37,810 [Thread-788] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-12-03 07:24:37,810 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:37,811 [Thread-788] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:37,811 [Listener at localhost/38811] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 64512 lastPacketInBlock: false lastByteOffsetInBlock: 65536, #0: blk_-9223372036854775792_1001
2020-12-03 07:24:37,811 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775792_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, #0: blk_-9223372036854775792_1001
2020-12-03 07:24:37,811 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775792_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - #0: blk_-9223372036854775792_1001 sending packet seqno: 1 offsetInBlock: 64512 lastPacketInBlock: false lastByteOffsetInBlock: 65536
2020-12-03 07:24:37,811 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:37,811 [pool-233-thread-1] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - #0: blk_-9223372036854775792_1001 waiting for ack for: 1
2020-12-03 07:24:37,811 [DataXceiver for client DFSClient_NONMAPREDUCE_-1548708192_1 at /127.0.0.1:47256 [Receiving block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775784_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775784_1001 src: /127.0.0.1:47256 dest: /127.0.0.1:39670
2020-12-03 07:24:37,811 [Listener at localhost/38811] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 64512 lastPacketInBlock: false lastByteOffsetInBlock: 65536, #1: blk_-9223372036854775791_1001
2020-12-03 07:24:37,812 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775791_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, #1: blk_-9223372036854775791_1001
2020-12-03 07:24:37,812 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775791_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - #1: blk_-9223372036854775791_1001 sending packet seqno: 1 offsetInBlock: 64512 lastPacketInBlock: false lastByteOffsetInBlock: 65536
2020-12-03 07:24:37,814 [pool-233-thread-2] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - #1: blk_-9223372036854775791_1001 waiting for ack for: 1
2020-12-03 07:24:37,814 [ResponseProcessor for block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775786_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2020-12-03 07:24:37,814 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:37,817 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775784_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:39670,DS-301c141a-2a18-464c-bff6-f3cc085eb873,DISK]] storageTypes [DISK] storageIDs [DS-301c141a-2a18-464c-bff6-f3cc085eb873]
2020-12-03 07:24:37,817 [ResponseProcessor for block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775792_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2020-12-03 07:24:37,817 [Listener at localhost/38811] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 64512 lastPacketInBlock: false lastByteOffsetInBlock: 65536, #2: blk_-9223372036854775790_1001
2020-12-03 07:24:37,817 [ResponseProcessor for block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775791_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2020-12-03 07:24:37,819 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775784_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - #8: blk_-9223372036854775784_1001 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 64512
2020-12-03 07:24:37,819 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775790_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, #2: blk_-9223372036854775790_1001
2020-12-03 07:24:37,819 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:37,818 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775785_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:39536,DS-90decd12-583a-4d3d-8ffa-ff0c65a87d71,DISK]] storageTypes [DISK] storageIDs [DS-90decd12-583a-4d3d-8ffa-ff0c65a87d71]
2020-12-03 07:24:37,820 [Listener at localhost/38811] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 64512 lastPacketInBlock: false lastByteOffsetInBlock: 65536, #3: blk_-9223372036854775789_1001
2020-12-03 07:24:37,820 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775790_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - #2: blk_-9223372036854775790_1001 sending packet seqno: 1 offsetInBlock: 64512 lastPacketInBlock: false lastByteOffsetInBlock: 65536
2020-12-03 07:24:37,820 [pool-233-thread-3] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - #2: blk_-9223372036854775790_1001 waiting for ack for: 1
2020-12-03 07:24:37,823 [pool-233-thread-4] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - #3: blk_-9223372036854775789_1001 waiting for ack for: 1
2020-12-03 07:24:37,823 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:37,821 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775789_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, #3: blk_-9223372036854775789_1001
2020-12-03 07:24:37,821 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775785_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - #7: blk_-9223372036854775785_1001 sending packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 64512
2020-12-03 07:24:37,823 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775789_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - #3: blk_-9223372036854775789_1001 sending packet seqno: 1 offsetInBlock: 64512 lastPacketInBlock: false lastByteOffsetInBlock: 65536
2020-12-03 07:24:37,823 [ResponseProcessor for block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775790_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2020-12-03 07:24:37,823 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:37,823 [ResponseProcessor for block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775784_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2020-12-03 07:24:37,824 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:37,825 [Listener at localhost/38811] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 64512 lastPacketInBlock: false lastByteOffsetInBlock: 65536, #6: blk_-9223372036854775786_1001
2020-12-03 07:24:37,827 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775786_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, #6: blk_-9223372036854775786_1001
2020-12-03 07:24:37,827 [ResponseProcessor for block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775789_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2020-12-03 07:24:37,827 [pool-233-thread-5] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - #6: blk_-9223372036854775786_1001 waiting for ack for: 1
2020-12-03 07:24:37,827 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775786_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - #6: blk_-9223372036854775786_1001 sending packet seqno: 1 offsetInBlock: 64512 lastPacketInBlock: false lastByteOffsetInBlock: 65536
2020-12-03 07:24:37,827 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:37,827 [ResponseProcessor for block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775785_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 0 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2020-12-03 07:24:37,828 [Listener at localhost/38811] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 64512 lastPacketInBlock: false lastByteOffsetInBlock: 65536, #7: blk_-9223372036854775785_1001
2020-12-03 07:24:37,829 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775785_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, #7: blk_-9223372036854775785_1001
2020-12-03 07:24:37,829 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:37,829 [pool-233-thread-6] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - #7: blk_-9223372036854775785_1001 waiting for ack for: 1
2020-12-03 07:24:37,829 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775785_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - #7: blk_-9223372036854775785_1001 sending packet seqno: 1 offsetInBlock: 64512 lastPacketInBlock: false lastByteOffsetInBlock: 65536
2020-12-03 07:24:37,829 [ResponseProcessor for block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775786_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2020-12-03 07:24:37,829 [Listener at localhost/38811] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 1 offsetInBlock: 64512 lastPacketInBlock: false lastByteOffsetInBlock: 65536, #8: blk_-9223372036854775784_1001
2020-12-03 07:24:37,829 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775784_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, #8: blk_-9223372036854775784_1001
2020-12-03 07:24:37,830 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:37,830 [ResponseProcessor for block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775785_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2020-12-03 07:24:37,830 [pool-233-thread-7] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - #8: blk_-9223372036854775784_1001 waiting for ack for: 1
2020-12-03 07:24:37,830 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775784_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - #8: blk_-9223372036854775784_1001 sending packet seqno: 1 offsetInBlock: 64512 lastPacketInBlock: false lastByteOffsetInBlock: 65536
2020-12-03 07:24:37,830 [ResponseProcessor for block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775784_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 1 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2020-12-03 07:24:37,831 [Listener at localhost/38811] DEBUG hdfs.DFSOutputStream (DFSStripedOutputStream.java:checkStreamers(390)) - checkStreamers: [#0: blk_-9223372036854775792_1001, #1: blk_-9223372036854775791_1001, #2: blk_-9223372036854775790_1001, #3: blk_-9223372036854775789_1001, #4: failed, block==null, #5: failed, block==null, #6: blk_-9223372036854775786_1001, #7: blk_-9223372036854775785_1001, #8: blk_-9223372036854775784_1001]
2020-12-03 07:24:37,831 [Listener at localhost/38811] DEBUG hdfs.DFSOutputStream (DFSStripedOutputStream.java:checkStreamers(391)) - healthy streamer count=7
2020-12-03 07:24:37,831 [Listener at localhost/38811] DEBUG hdfs.DFSOutputStream (DFSStripedOutputStream.java:checkStreamers(392)) - original failed streamers: []
2020-12-03 07:24:37,831 [Listener at localhost/38811] DEBUG hdfs.DFSOutputStream (DFSStripedOutputStream.java:checkStreamers(393)) - newly failed streamers: [#4: failed, block==null, #5: failed, block==null]
2020-12-03 07:24:37,831 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775791_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:processDatanodeOrExternalError(1229)) - start process datanode/external error, #1: blk_-9223372036854775791_1001
2020-12-03 07:24:37,831 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775784_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:processDatanodeOrExternalError(1229)) - start process datanode/external error, #8: blk_-9223372036854775784_1001
2020-12-03 07:24:37,831 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775792_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:processDatanodeOrExternalError(1229)) - start process datanode/external error, #0: blk_-9223372036854775792_1001
2020-12-03 07:24:37,832 [DataXceiver for client DFSClient_NONMAPREDUCE_-1548708192_1 at /127.0.0.1:47256 [Receiving block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775784_1001]] INFO  datanode.DataNode (BlockReceiver.java:receiveBlock(1010)) - Exception for BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775784_1001
java.io.IOException: Premature EOF from inputStream
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:212)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:908)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:37,831 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775790_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:processDatanodeOrExternalError(1229)) - start process datanode/external error, #2: blk_-9223372036854775790_1001
2020-12-03 07:24:37,831 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775785_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:processDatanodeOrExternalError(1229)) - start process datanode/external error, #7: blk_-9223372036854775785_1001
2020-12-03 07:24:37,831 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775789_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:processDatanodeOrExternalError(1229)) - start process datanode/external error, #3: blk_-9223372036854775789_1001
2020-12-03 07:24:37,832 [DataXceiver for client DFSClient_NONMAPREDUCE_-1548708192_1 at /127.0.0.1:34072 [Receiving block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775790_1001]] INFO  datanode.DataNode (BlockReceiver.java:receiveBlock(1010)) - Exception for BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775790_1001
java.io.IOException: Premature EOF from inputStream
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:212)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:908)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:37,832 [PacketResponder: BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775784_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1470)) - PacketResponder: BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775784_1001, type=LAST_IN_PIPELINE: Thread is interrupted.
2020-12-03 07:24:37,839 [PacketResponder: BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775784_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775784_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:37,832 [DataXceiver for client DFSClient_NONMAPREDUCE_-1548708192_1 at /127.0.0.1:46792 [Receiving block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775792_1001]] INFO  datanode.DataNode (BlockReceiver.java:receiveBlock(1010)) - Exception for BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775792_1001
java.io.IOException: Premature EOF from inputStream
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:212)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:908)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:37,832 [DataXceiver for client DFSClient_NONMAPREDUCE_-1548708192_1 at /127.0.0.1:55700 [Receiving block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775791_1001]] INFO  datanode.DataNode (BlockReceiver.java:receiveBlock(1010)) - Exception for BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775791_1001
java.io.IOException: Premature EOF from inputStream
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:212)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:908)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:37,831 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775786_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:processDatanodeOrExternalError(1229)) - start process datanode/external error, #6: blk_-9223372036854775786_1001
2020-12-03 07:24:37,840 [PacketResponder: BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775791_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1470)) - PacketResponder: BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775791_1001, type=LAST_IN_PIPELINE: Thread is interrupted.
2020-12-03 07:24:37,840 [PacketResponder: BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775791_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775791_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:37,839 [DataXceiver for client DFSClient_NONMAPREDUCE_-1548708192_1 at /127.0.0.1:42728 [Receiving block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775789_1001]] INFO  datanode.DataNode (BlockReceiver.java:receiveBlock(1010)) - Exception for BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775789_1001
java.io.IOException: Premature EOF from inputStream
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:212)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:908)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:37,839 [PacketResponder: BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775792_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1470)) - PacketResponder: BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775792_1001, type=LAST_IN_PIPELINE: Thread is interrupted.
2020-12-03 07:24:37,840 [PacketResponder: BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775792_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775792_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:37,840 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775790_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:38509,DS-bfb9e676-bcb3-4b9b-8b21-3adff7deb76f,DISK]], #2: blk_-9223372036854775790_1001
2020-12-03 07:24:37,839 [DataXceiver for client DFSClient_NONMAPREDUCE_-1548708192_1 at /127.0.0.1:47256 [Receiving block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775784_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(939)) - opWriteBlock BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775784_1001 received exception java.io.IOException: Premature EOF from inputStream
2020-12-03 07:24:37,839 [PacketResponder: BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775790_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1470)) - PacketResponder: BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775790_1001, type=LAST_IN_PIPELINE: Thread is interrupted.
2020-12-03 07:24:37,840 [PacketResponder: BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775790_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775790_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:37,832 [DataXceiver for client DFSClient_NONMAPREDUCE_-1548708192_1 at /127.0.0.1:38734 [Receiving block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775785_1001]] INFO  datanode.DataNode (BlockReceiver.java:receiveBlock(1010)) - Exception for BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775785_1001
java.io.IOException: Premature EOF from inputStream
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:212)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:908)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:37,841 [DataXceiver for client DFSClient_NONMAPREDUCE_-1548708192_1 at /127.0.0.1:34072 [Receiving block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775790_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(939)) - opWriteBlock BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775790_1001 received exception java.io.IOException: Premature EOF from inputStream
2020-12-03 07:24:37,840 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775790_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:38509
2020-12-03 07:24:37,840 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775784_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:39670,DS-301c141a-2a18-464c-bff6-f3cc085eb873,DISK]], #8: blk_-9223372036854775784_1001
2020-12-03 07:24:37,840 [DataXceiver for client DFSClient_NONMAPREDUCE_-1548708192_1 at /127.0.0.1:46792 [Receiving block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775792_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(939)) - opWriteBlock BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775792_1001 received exception java.io.IOException: Premature EOF from inputStream
2020-12-03 07:24:37,840 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775785_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:39536,DS-90decd12-583a-4d3d-8ffa-ff0c65a87d71,DISK]], #7: blk_-9223372036854775785_1001
2020-12-03 07:24:37,840 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775786_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:35478,DS-4a224303-3aff-47f8-9ce9-586dfad45f29,DISK]], #6: blk_-9223372036854775786_1001
2020-12-03 07:24:37,840 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775789_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:35995,DS-d72315d1-2ea3-44c3-ade3-d7b892bdf67f,DISK]], #3: blk_-9223372036854775789_1001
2020-12-03 07:24:37,840 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775791_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:45564,DS-780c3aad-5133-4c8c-a94b-8deef7fd424f,DISK]], #1: blk_-9223372036854775791_1001
2020-12-03 07:24:37,842 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775791_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:45564
2020-12-03 07:24:37,840 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775792_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:createBlockOutputStream(1712)) - pipeline = [DatanodeInfoWithStorage[127.0.0.1:40183,DS-aa276f62-89b9-45fb-b1dc-db56c85396ff,DISK]], #0: blk_-9223372036854775792_1001
2020-12-03 07:24:37,840 [PacketResponder: BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775789_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1470)) - PacketResponder: BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775789_1001, type=LAST_IN_PIPELINE: Thread is interrupted.
2020-12-03 07:24:37,842 [PacketResponder: BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775789_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775789_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:37,840 [DataXceiver for client DFSClient_NONMAPREDUCE_-1548708192_1 at /127.0.0.1:55700 [Receiving block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775791_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(939)) - opWriteBlock BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775791_1001 received exception java.io.IOException: Premature EOF from inputStream
2020-12-03 07:24:37,840 [DataXceiver for client DFSClient_NONMAPREDUCE_-1548708192_1 at /127.0.0.1:59588 [Receiving block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775786_1001]] INFO  datanode.DataNode (BlockReceiver.java:receiveBlock(1010)) - Exception for BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775786_1001
java.io.IOException: Premature EOF from inputStream
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:212)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:908)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:37,842 [DataXceiver for client DFSClient_NONMAPREDUCE_-1548708192_1 at /127.0.0.1:55700 [Receiving block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775791_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:45564:DataXceiver error processing WRITE_BLOCK operation  src: /127.0.0.1:55700 dst: /127.0.0.1:45564
java.io.IOException: Premature EOF from inputStream
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:212)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:908)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:37,842 [DataXceiver for client DFSClient_NONMAPREDUCE_-1548708192_1 at /127.0.0.1:42728 [Receiving block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775789_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(939)) - opWriteBlock BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775789_1001 received exception java.io.IOException: Premature EOF from inputStream
2020-12-03 07:24:37,842 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775791_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-12-03 07:24:37,842 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775792_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:40183
2020-12-03 07:24:37,841 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775789_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:35995
2020-12-03 07:24:37,841 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775786_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:35478
2020-12-03 07:24:37,841 [DataXceiver for client DFSClient_NONMAPREDUCE_-1548708192_1 at /127.0.0.1:46792 [Receiving block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775792_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:40183:DataXceiver error processing WRITE_BLOCK operation  src: /127.0.0.1:46792 dst: /127.0.0.1:40183
java.io.IOException: Premature EOF from inputStream
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:212)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:908)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:37,841 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775785_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:39536
2020-12-03 07:24:37,841 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775790_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-12-03 07:24:37,841 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775784_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(249)) - Connecting to datanode 127.0.0.1:39670
2020-12-03 07:24:37,841 [DataXceiver for client DFSClient_NONMAPREDUCE_-1548708192_1 at /127.0.0.1:34072 [Receiving block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775790_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:38509:DataXceiver error processing WRITE_BLOCK operation  src: /127.0.0.1:34072 dst: /127.0.0.1:38509
java.io.IOException: Premature EOF from inputStream
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:212)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:908)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:37,841 [PacketResponder: BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775785_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1470)) - PacketResponder: BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775785_1001, type=LAST_IN_PIPELINE: Thread is interrupted.
2020-12-03 07:24:37,844 [PacketResponder: BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775785_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775785_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:37,841 [DataXceiver for client DFSClient_NONMAPREDUCE_-1548708192_1 at /127.0.0.1:47256 [Receiving block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775784_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:39670:DataXceiver error processing WRITE_BLOCK operation  src: /127.0.0.1:47256 dst: /127.0.0.1:39670
java.io.IOException: Premature EOF from inputStream
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:212)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:908)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:37,844 [DataXceiver for client DFSClient_NONMAPREDUCE_-1548708192_1 at /127.0.0.1:38734 [Receiving block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775785_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(939)) - opWriteBlock BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775785_1001 received exception java.io.IOException: Premature EOF from inputStream
2020-12-03 07:24:37,844 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775784_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-12-03 07:24:37,843 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775785_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-12-03 07:24:37,845 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775785_1001] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:37,843 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775790_1001] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:37,843 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775786_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-12-03 07:24:37,843 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775789_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-12-03 07:24:37,843 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775792_1001] DEBUG hdfs.DataStreamer (DataStreamer.java:createSocketForPipeline(261)) - Send buf size 1313280
2020-12-03 07:24:37,843 [DataXceiver for client DFSClient_NONMAPREDUCE_-1548708192_1 at /127.0.0.1:42728 [Receiving block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775789_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:35995:DataXceiver error processing WRITE_BLOCK operation  src: /127.0.0.1:42728 dst: /127.0.0.1:35995
java.io.IOException: Premature EOF from inputStream
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:212)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:908)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:37,843 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775791_1001] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:37,842 [PacketResponder: BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775786_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1470)) - PacketResponder: BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775786_1001, type=LAST_IN_PIPELINE: Thread is interrupted.
2020-12-03 07:24:37,845 [PacketResponder: BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775786_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775786_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:37,845 [DataXceiver for client DFSClient_NONMAPREDUCE_-1548708192_1 at /127.0.0.1:38758 [Receiving block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775785_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775785_1001 src: /127.0.0.1:38758 dest: /127.0.0.1:39536
2020-12-03 07:24:37,845 [DataXceiver for client DFSClient_NONMAPREDUCE_-1548708192_1 at /127.0.0.1:34106 [Receiving block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775790_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775790_1001 src: /127.0.0.1:34106 dest: /127.0.0.1:38509
2020-12-03 07:24:37,845 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775792_1001] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:37,845 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775789_1001] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:37,845 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775786_1001] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:37,845 [DataXceiver for client DFSClient_NONMAPREDUCE_-1548708192_1 at /127.0.0.1:38734 [Receiving block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775785_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:39536:DataXceiver error processing WRITE_BLOCK operation  src: /127.0.0.1:38734 dst: /127.0.0.1:39536
java.io.IOException: Premature EOF from inputStream
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:212)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:908)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:37,846 [DataXceiver for client DFSClient_NONMAPREDUCE_-1548708192_1 at /127.0.0.1:46834 [Receiving block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775792_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775792_1001 src: /127.0.0.1:46834 dest: /127.0.0.1:40183
2020-12-03 07:24:37,844 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775784_1001] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:24:37,846 [DataXceiver for client DFSClient_NONMAPREDUCE_-1548708192_1 at /127.0.0.1:59614 [Receiving block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775786_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775786_1001 src: /127.0.0.1:59614 dest: /127.0.0.1:35478
2020-12-03 07:24:37,846 [DataXceiver for client DFSClient_NONMAPREDUCE_-1548708192_1 at /127.0.0.1:46834 [Receiving block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775792_1001]] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:recoverRbw(1443)) - Recover RBW replica BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775792_1001
2020-12-03 07:24:37,846 [DataXceiver for client DFSClient_NONMAPREDUCE_-1548708192_1 at /127.0.0.1:42758 [Receiving block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775789_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775789_1001 src: /127.0.0.1:42758 dest: /127.0.0.1:35995
2020-12-03 07:24:37,846 [DataXceiver for client DFSClient_NONMAPREDUCE_-1548708192_1 at /127.0.0.1:55738 [Receiving block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775791_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775791_1001 src: /127.0.0.1:55738 dest: /127.0.0.1:45564
2020-12-03 07:24:37,847 [DataXceiver for client DFSClient_NONMAPREDUCE_-1548708192_1 at /127.0.0.1:46834 [Receiving block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775792_1001]] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:recoverRbw(1459)) - At 127.0.0.1:40183, Recovering ReplicaBeingWritten, blk_-9223372036854775792_1001, RBW
  getNumBytes()     = 65536
  getBytesOnDisk()  = 65536
  getVisibleLength()= 65536
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1688424058-172.17.0.4-1606980274066/current/rbw/blk_-9223372036854775792
  bytesAcked=65536
  bytesOnDisk=65536
2020-12-03 07:24:37,847 [DataXceiver for client DFSClient_NONMAPREDUCE_-1548708192_1 at /127.0.0.1:47280 [Receiving block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775784_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775784_1001 src: /127.0.0.1:47280 dest: /127.0.0.1:39670
2020-12-03 07:24:37,846 [DataXceiver for client DFSClient_NONMAPREDUCE_-1548708192_1 at /127.0.0.1:34106 [Receiving block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775790_1001]] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:recoverRbw(1443)) - Recover RBW replica BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775790_1001
2020-12-03 07:24:37,846 [DataXceiver for client DFSClient_NONMAPREDUCE_-1548708192_1 at /127.0.0.1:38758 [Receiving block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775785_1001]] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:recoverRbw(1443)) - Recover RBW replica BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775785_1001
2020-12-03 07:24:37,845 [DataXceiver for client DFSClient_NONMAPREDUCE_-1548708192_1 at /127.0.0.1:59588 [Receiving block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775786_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(939)) - opWriteBlock BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775786_1001 received exception java.io.IOException: Premature EOF from inputStream
2020-12-03 07:24:37,849 [DataXceiver for client DFSClient_NONMAPREDUCE_-1548708192_1 at /127.0.0.1:34106 [Receiving block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775790_1001]] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:recoverRbw(1459)) - At 127.0.0.1:38509, Recovering ReplicaBeingWritten, blk_-9223372036854775790_1001, RBW
  getNumBytes()     = 65536
  getBytesOnDisk()  = 65536
  getVisibleLength()= 65536
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1688424058-172.17.0.4-1606980274066/current/rbw/blk_-9223372036854775790
  bytesAcked=65536
  bytesOnDisk=65536
2020-12-03 07:24:37,847 [DataXceiver for client DFSClient_NONMAPREDUCE_-1548708192_1 at /127.0.0.1:47280 [Receiving block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775784_1001]] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:recoverRbw(1443)) - Recover RBW replica BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775784_1001
2020-12-03 07:24:37,847 [DataXceiver for client DFSClient_NONMAPREDUCE_-1548708192_1 at /127.0.0.1:55738 [Receiving block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775791_1001]] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:recoverRbw(1443)) - Recover RBW replica BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775791_1001
2020-12-03 07:24:37,847 [DataXceiver for client DFSClient_NONMAPREDUCE_-1548708192_1 at /127.0.0.1:42758 [Receiving block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775789_1001]] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:recoverRbw(1443)) - Recover RBW replica BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775789_1001
2020-12-03 07:24:37,847 [DataXceiver for client DFSClient_NONMAPREDUCE_-1548708192_1 at /127.0.0.1:59614 [Receiving block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775786_1001]] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:recoverRbw(1443)) - Recover RBW replica BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775786_1001
2020-12-03 07:24:37,850 [DataXceiver for client DFSClient_NONMAPREDUCE_-1548708192_1 at /127.0.0.1:55738 [Receiving block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775791_1001]] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:recoverRbw(1459)) - At 127.0.0.1:45564, Recovering ReplicaBeingWritten, blk_-9223372036854775791_1001, RBW
  getNumBytes()     = 65536
  getBytesOnDisk()  = 65536
  getVisibleLength()= 65536
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1688424058-172.17.0.4-1606980274066/current/rbw/blk_-9223372036854775791
  bytesAcked=65536
  bytesOnDisk=65536
2020-12-03 07:24:37,849 [DataXceiver for client DFSClient_NONMAPREDUCE_-1548708192_1 at /127.0.0.1:59588 [Receiving block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775786_1001]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:35478:DataXceiver error processing WRITE_BLOCK operation  src: /127.0.0.1:59588 dst: /127.0.0.1:35478
java.io.IOException: Premature EOF from inputStream
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:212)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:908)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:24:37,850 [DataXceiver for client DFSClient_NONMAPREDUCE_-1548708192_1 at /127.0.0.1:47280 [Receiving block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775784_1001]] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:recoverRbw(1459)) - At 127.0.0.1:39670, Recovering ReplicaBeingWritten, blk_-9223372036854775784_1001, RBW
  getNumBytes()     = 65536
  getBytesOnDisk()  = 65536
  getVisibleLength()= 65536
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1688424058-172.17.0.4-1606980274066/current/rbw/blk_-9223372036854775784
  bytesAcked=65536
  bytesOnDisk=65536
2020-12-03 07:24:37,849 [DataXceiver for client DFSClient_NONMAPREDUCE_-1548708192_1 at /127.0.0.1:38758 [Receiving block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775785_1001]] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:recoverRbw(1459)) - At 127.0.0.1:39536, Recovering ReplicaBeingWritten, blk_-9223372036854775785_1001, RBW
  getNumBytes()     = 65536
  getBytesOnDisk()  = 65536
  getVisibleLength()= 65536
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1688424058-172.17.0.4-1606980274066/current/rbw/blk_-9223372036854775785
  bytesAcked=65536
  bytesOnDisk=65536
2020-12-03 07:24:37,852 [DataXceiver for client DFSClient_NONMAPREDUCE_-1548708192_1 at /127.0.0.1:59614 [Receiving block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775786_1001]] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:recoverRbw(1459)) - At 127.0.0.1:35478, Recovering ReplicaBeingWritten, blk_-9223372036854775786_1001, RBW
  getNumBytes()     = 65536
  getBytesOnDisk()  = 65536
  getVisibleLength()= 65536
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1688424058-172.17.0.4-1606980274066/current/rbw/blk_-9223372036854775786
  bytesAcked=65536
  bytesOnDisk=65536
2020-12-03 07:24:37,850 [DataXceiver for client DFSClient_NONMAPREDUCE_-1548708192_1 at /127.0.0.1:42758 [Receiving block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775789_1001]] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:recoverRbw(1459)) - At 127.0.0.1:35995, Recovering ReplicaBeingWritten, blk_-9223372036854775789_1001, RBW
  getNumBytes()     = 65536
  getBytesOnDisk()  = 65536
  getVisibleLength()= 65536
  getVolume()       = /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
  getBlockURI()     = file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1688424058-172.17.0.4-1606980274066/current/rbw/blk_-9223372036854775789
  bytesAcked=65536
  bytesOnDisk=65536
2020-12-03 07:24:37,865 [IPC Server handler 2 on default port 42543] INFO  namenode.FSNamesystem (FSNamesystem.java:updatePipeline(5430)) - updatePipeline(blk_-9223372036854775792_1001, newGS=1002, newLength=393216, newNodes=[127.0.0.1:40183, 127.0.0.1:45564, 127.0.0.1:38509, 127.0.0.1:35995, null:0, null:0, 127.0.0.1:35478, 127.0.0.1:39536, 127.0.0.1:39670], client=DFSClient_NONMAPREDUCE_-1548708192_1)
2020-12-03 07:24:37,867 [IPC Server handler 2 on default port 42543] INFO  namenode.FSNamesystem (FSNamesystem.java:updatePipeline(5448)) - updatePipeline(blk_-9223372036854775792_1001 => blk_-9223372036854775792_1002) success
2020-12-03 07:24:37,868 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:37,868 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775789_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:35995,DS-d72315d1-2ea3-44c3-ade3-d7b892bdf67f,DISK]] storageTypes [DISK] storageIDs [DS-d72315d1-2ea3-44c3-ade3-d7b892bdf67f]
2020-12-03 07:24:37,868 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775786_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:35478,DS-4a224303-3aff-47f8-9ce9-586dfad45f29,DISK]] storageTypes [DISK] storageIDs [DS-4a224303-3aff-47f8-9ce9-586dfad45f29]
2020-12-03 07:24:37,868 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775790_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:38509,DS-bfb9e676-bcb3-4b9b-8b21-3adff7deb76f,DISK]] storageTypes [DISK] storageIDs [DS-bfb9e676-bcb3-4b9b-8b21-3adff7deb76f]
2020-12-03 07:24:37,868 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775784_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:39670,DS-301c141a-2a18-464c-bff6-f3cc085eb873,DISK]] storageTypes [DISK] storageIDs [DS-301c141a-2a18-464c-bff6-f3cc085eb873]
2020-12-03 07:24:37,868 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775791_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:45564,DS-780c3aad-5133-4c8c-a94b-8deef7fd424f,DISK]] storageTypes [DISK] storageIDs [DS-780c3aad-5133-4c8c-a94b-8deef7fd424f]
2020-12-03 07:24:37,868 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775785_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:39536,DS-90decd12-583a-4d3d-8ffa-ff0c65a87d71,DISK]] storageTypes [DISK] storageIDs [DS-90decd12-583a-4d3d-8ffa-ff0c65a87d71]
2020-12-03 07:24:37,868 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775792_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:initDataStreaming(627)) - nodes [DatanodeInfoWithStorage[127.0.0.1:40183,DS-aa276f62-89b9-45fb-b1dc-db56c85396ff,DISK]] storageTypes [DISK] storageIDs [DS-aa276f62-89b9-45fb-b1dc-db56c85396ff]
2020-12-03 07:24:37,870 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=2, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], packetSize=65016, chunksPerPacket=126, bytesCurBlock=65536, DFSStripedOutputStream:#0: blk_-9223372036854775792_1002
2020-12-03 07:24:37,877 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:37,878 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=2, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], packetSize=65016, chunksPerPacket=126, bytesCurBlock=65536, DFSStripedOutputStream:#6: blk_-9223372036854775786_1002
2020-12-03 07:24:37,878 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:37,878 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=2, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], packetSize=65016, chunksPerPacket=126, bytesCurBlock=65536, DFSStripedOutputStream:#7: blk_-9223372036854775785_1002
2020-12-03 07:24:37,878 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:37,878 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:writeChunkPrepare(475)) - WriteChunk allocating new packet seqno=2, src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], packetSize=65016, chunksPerPacket=126, bytesCurBlock=65536, DFSStripedOutputStream:#8: blk_-9223372036854775784_1002
2020-12-03 07:24:37,878 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:37,878 [Listener at localhost/38811] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 2 offsetInBlock: 65536 lastPacketInBlock: false lastByteOffsetInBlock: 65659, #0: blk_-9223372036854775792_1002
2020-12-03 07:24:37,879 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:37,879 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775792_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, #0: blk_-9223372036854775792_1002
2020-12-03 07:24:37,879 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:37,879 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775792_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - #0: blk_-9223372036854775792_1002 sending packet seqno: 2 offsetInBlock: 65536 lastPacketInBlock: false lastByteOffsetInBlock: 65659
2020-12-03 07:24:37,879 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:37,879 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:37,879 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:37,880 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:37,883 [Listener at localhost/38811] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 2 offsetInBlock: 65536 lastPacketInBlock: false lastByteOffsetInBlock: 65659, #6: blk_-9223372036854775786_1002
2020-12-03 07:24:37,883 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:37,883 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775786_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, #6: blk_-9223372036854775786_1002
2020-12-03 07:24:37,883 [ResponseProcessor for block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775792_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 2 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2020-12-03 07:24:37,883 [Listener at localhost/38811] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 2 offsetInBlock: 65536 lastPacketInBlock: false lastByteOffsetInBlock: 65659, #7: blk_-9223372036854775785_1002
2020-12-03 07:24:37,883 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775786_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - #6: blk_-9223372036854775786_1002 sending packet seqno: 2 offsetInBlock: 65536 lastPacketInBlock: false lastByteOffsetInBlock: 65659
2020-12-03 07:24:37,883 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775785_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, #7: blk_-9223372036854775785_1002
2020-12-03 07:24:37,883 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:37,883 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775785_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - #7: blk_-9223372036854775785_1002 sending packet seqno: 2 offsetInBlock: 65536 lastPacketInBlock: false lastByteOffsetInBlock: 65659
2020-12-03 07:24:37,883 [Listener at localhost/38811] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 2 offsetInBlock: 65536 lastPacketInBlock: false lastByteOffsetInBlock: 65659, #8: blk_-9223372036854775784_1002
2020-12-03 07:24:37,887 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:37,887 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775784_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, #8: blk_-9223372036854775784_1002
2020-12-03 07:24:37,890 [ResponseProcessor for block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775786_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 2 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2020-12-03 07:24:37,890 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:37,890 [ResponseProcessor for block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775785_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 2 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2020-12-03 07:24:37,890 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775784_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - #8: blk_-9223372036854775784_1002 sending packet seqno: 2 offsetInBlock: 65536 lastPacketInBlock: false lastByteOffsetInBlock: 65659
2020-12-03 07:24:37,890 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:37,890 [pool-233-thread-8] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - #0: blk_-9223372036854775792_1002 waiting for ack for: 2
2020-12-03 07:24:37,891 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:37,892 [pool-233-thread-9] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - #1: blk_-9223372036854775791_1002 waiting for ack for: 1
2020-12-03 07:24:37,894 [pool-233-thread-1] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - #2: blk_-9223372036854775790_1002 waiting for ack for: 1
2020-12-03 07:24:37,894 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:37,894 [ResponseProcessor for block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775784_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 2 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2020-12-03 07:24:37,894 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:37,894 [pool-233-thread-2] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - #3: blk_-9223372036854775789_1002 waiting for ack for: 1
2020-12-03 07:24:37,894 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:37,895 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:37,895 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:37,895 [pool-233-thread-3] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - #6: blk_-9223372036854775786_1002 waiting for ack for: 2
2020-12-03 07:24:37,895 [pool-233-thread-4] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - #7: blk_-9223372036854775785_1002 waiting for ack for: 2
2020-12-03 07:24:37,895 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:37,895 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:37,895 [pool-233-thread-5] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - #8: blk_-9223372036854775784_1002 waiting for ack for: 2
2020-12-03 07:24:37,896 [Listener at localhost/38811] DEBUG hdfs.DFSOutputStream (DFSStripedOutputStream.java:checkStreamers(390)) - checkStreamers: [#0: blk_-9223372036854775792_1002, #1: blk_-9223372036854775791_1002, #2: blk_-9223372036854775790_1002, #3: blk_-9223372036854775789_1002, #4: failed, block==null, #5: failed, block==null, #6: blk_-9223372036854775786_1002, #7: blk_-9223372036854775785_1002, #8: blk_-9223372036854775784_1002]
2020-12-03 07:24:37,896 [Listener at localhost/38811] DEBUG hdfs.DFSOutputStream (DFSStripedOutputStream.java:checkStreamers(391)) - healthy streamer count=7
2020-12-03 07:24:37,896 [Listener at localhost/38811] DEBUG hdfs.DFSOutputStream (DFSStripedOutputStream.java:checkStreamers(392)) - original failed streamers: [#4: failed, block==null, #5: failed, block==null]
2020-12-03 07:24:37,896 [Listener at localhost/38811] DEBUG hdfs.DFSOutputStream (DFSStripedOutputStream.java:checkStreamers(393)) - newly failed streamers: []
2020-12-03 07:24:37,896 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:37,896 [Listener at localhost/38811] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 3 offsetInBlock: 65659 lastPacketInBlock: true lastByteOffsetInBlock: 65659, #0: blk_-9223372036854775792_1002
2020-12-03 07:24:37,896 [Listener at localhost/38811] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - #0: blk_-9223372036854775792_1002 waiting for ack for: 3
2020-12-03 07:24:37,896 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775792_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, #0: blk_-9223372036854775792_1002
2020-12-03 07:24:37,896 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775792_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - #0: blk_-9223372036854775792_1002 sending packet seqno: 3 offsetInBlock: 65659 lastPacketInBlock: true lastByteOffsetInBlock: 65659
2020-12-03 07:24:37,901 [PacketResponder: BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775792_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:46834, dest: /127.0.0.1:40183, bytes: 65659, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1548708192_1, offset: 0, srvID: fa199516-b4fb-46da-b156-01e59120b35f, blockid: BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775792_1002, duration(ns): 50365490
2020-12-03 07:24:37,902 [PacketResponder: BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775792_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775792_1002, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:37,902 [ResponseProcessor for block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775792_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 3 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2020-12-03 07:24:37,902 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775792_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775792_1002
2020-12-03 07:24:37,902 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:37,902 [Listener at localhost/38811] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 2 offsetInBlock: 65536 lastPacketInBlock: true lastByteOffsetInBlock: 65536, #1: blk_-9223372036854775791_1002
2020-12-03 07:24:37,902 [Listener at localhost/38811] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - #1: blk_-9223372036854775791_1002 waiting for ack for: 2
2020-12-03 07:24:37,902 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775791_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, #1: blk_-9223372036854775791_1002
2020-12-03 07:24:37,903 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775791_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - #1: blk_-9223372036854775791_1002 sending packet seqno: 2 offsetInBlock: 65536 lastPacketInBlock: true lastByteOffsetInBlock: 65536
2020-12-03 07:24:37,908 [PacketResponder: BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775791_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55738, dest: /127.0.0.1:45564, bytes: 65536, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1548708192_1, offset: 0, srvID: 98ea0ce4-a3b3-42e5-9bc8-9e81b791e85f, blockid: BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775791_1002, duration(ns): 52994494
2020-12-03 07:24:37,915 [PacketResponder: BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775791_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775791_1002, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:37,915 [ResponseProcessor for block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775791_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 2 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2020-12-03 07:24:37,915 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775791_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775791_1002
2020-12-03 07:24:37,915 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:37,915 [Listener at localhost/38811] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 2 offsetInBlock: 65536 lastPacketInBlock: true lastByteOffsetInBlock: 65536, #2: blk_-9223372036854775790_1002
2020-12-03 07:24:37,916 [Listener at localhost/38811] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - #2: blk_-9223372036854775790_1002 waiting for ack for: 2
2020-12-03 07:24:37,916 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775790_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, #2: blk_-9223372036854775790_1002
2020-12-03 07:24:37,916 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775790_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - #2: blk_-9223372036854775790_1002 sending packet seqno: 2 offsetInBlock: 65536 lastPacketInBlock: true lastByteOffsetInBlock: 65536
2020-12-03 07:24:37,920 [PacketResponder: BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775790_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:34106, dest: /127.0.0.1:38509, bytes: 65536, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1548708192_1, offset: 0, srvID: 0c6f8970-d7dd-48b5-8d5e-a875696526d2, blockid: BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775790_1002, duration(ns): 67738646
2020-12-03 07:24:37,921 [PacketResponder: BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775790_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775790_1002, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:37,922 [ResponseProcessor for block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775790_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 2 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2020-12-03 07:24:37,922 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775790_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775790_1002
2020-12-03 07:24:37,922 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:37,922 [Listener at localhost/38811] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 2 offsetInBlock: 65536 lastPacketInBlock: true lastByteOffsetInBlock: 65536, #3: blk_-9223372036854775789_1002
2020-12-03 07:24:37,922 [Listener at localhost/38811] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - #3: blk_-9223372036854775789_1002 waiting for ack for: 2
2020-12-03 07:24:37,922 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775789_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, #3: blk_-9223372036854775789_1002
2020-12-03 07:24:37,922 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775789_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - #3: blk_-9223372036854775789_1002 sending packet seqno: 2 offsetInBlock: 65536 lastPacketInBlock: true lastByteOffsetInBlock: 65536
2020-12-03 07:24:37,926 [PacketResponder: BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775789_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:42758, dest: /127.0.0.1:35995, bytes: 65536, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1548708192_1, offset: 0, srvID: c1d7d0bc-1e04-40b2-8bda-52556cd4f522, blockid: BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775789_1002, duration(ns): 61256744
2020-12-03 07:24:37,927 [PacketResponder: BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775789_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775789_1002, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:37,928 [ResponseProcessor for block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775789_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 2 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2020-12-03 07:24:37,928 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775789_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775789_1002
2020-12-03 07:24:37,928 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:37,928 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:37,928 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:37,928 [Listener at localhost/38811] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 3 offsetInBlock: 65659 lastPacketInBlock: true lastByteOffsetInBlock: 65659, #6: blk_-9223372036854775786_1002
2020-12-03 07:24:37,929 [Listener at localhost/38811] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - #6: blk_-9223372036854775786_1002 waiting for ack for: 3
2020-12-03 07:24:37,929 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775786_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, #6: blk_-9223372036854775786_1002
2020-12-03 07:24:37,929 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775786_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - #6: blk_-9223372036854775786_1002 sending packet seqno: 3 offsetInBlock: 65659 lastPacketInBlock: true lastByteOffsetInBlock: 65659
2020-12-03 07:24:37,932 [PacketResponder: BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775786_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59614, dest: /127.0.0.1:35478, bytes: 65659, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1548708192_1, offset: 0, srvID: b1a31110-b9aa-4184-8cd5-6778c3221b36, blockid: BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775786_1002, duration(ns): 67899469
2020-12-03 07:24:37,932 [PacketResponder: BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775786_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775786_1002, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:37,932 [ResponseProcessor for block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775786_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 3 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2020-12-03 07:24:37,932 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775786_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775786_1002
2020-12-03 07:24:37,932 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:37,932 [Listener at localhost/38811] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 3 offsetInBlock: 65659 lastPacketInBlock: true lastByteOffsetInBlock: 65659, #7: blk_-9223372036854775785_1002
2020-12-03 07:24:37,933 [Listener at localhost/38811] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - #7: blk_-9223372036854775785_1002 waiting for ack for: 3
2020-12-03 07:24:37,933 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775785_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, #7: blk_-9223372036854775785_1002
2020-12-03 07:24:37,933 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775785_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - #7: blk_-9223372036854775785_1002 sending packet seqno: 3 offsetInBlock: 65659 lastPacketInBlock: true lastByteOffsetInBlock: 65659
2020-12-03 07:24:37,936 [PacketResponder: BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775785_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38758, dest: /127.0.0.1:39536, bytes: 65659, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1548708192_1, offset: 0, srvID: 778e686f-955b-4664-b0d5-e7c9ffc5fcab, blockid: BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775785_1002, duration(ns): 71922162
2020-12-03 07:24:37,936 [PacketResponder: BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775785_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775785_1002, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:37,936 [ResponseProcessor for block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775785_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 3 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2020-12-03 07:24:37,936 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775785_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775785_1002
2020-12-03 07:24:37,936 [Listener at localhost/38811] DEBUG hdfs.DFSClient (DFSOutputStream.java:computePacketChunkSize(410)) - computePacketChunkSize: src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226], chunkSize=516, chunksPerPacket=126, packetSize=65016
2020-12-03 07:24:37,937 [Listener at localhost/38811] DEBUG hdfs.DataStreamer (DataStreamer.java:queuePacket(1954)) - Queued packet seqno: 3 offsetInBlock: 65659 lastPacketInBlock: true lastByteOffsetInBlock: 65659, #8: blk_-9223372036854775784_1002
2020-12-03 07:24:37,937 [Listener at localhost/38811] DEBUG hdfs.DataStreamer (DataStreamer.java:waitForAckedSeqno(876)) - #8: blk_-9223372036854775784_1002 waiting for ack for: 3
2020-12-03 07:24:37,941 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775784_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(712)) - stage=DATA_STREAMING, #8: blk_-9223372036854775784_1002
2020-12-03 07:24:37,941 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775784_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(769)) - #8: blk_-9223372036854775784_1002 sending packet seqno: 3 offsetInBlock: 65659 lastPacketInBlock: true lastByteOffsetInBlock: 65659
2020-12-03 07:24:37,949 [PacketResponder: BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775784_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:47280, dest: /127.0.0.1:39670, bytes: 65659, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1548708192_1, offset: 0, srvID: d5e826a6-bb6a-4355-9ce3-e94594fc7594, blockid: BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775784_1002, duration(ns): 86181191
2020-12-03 07:24:37,949 [PacketResponder: BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775784_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775784_1002, type=LAST_IN_PIPELINE terminating
2020-12-03 07:24:37,950 [ResponseProcessor for block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775784_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:run(1101)) - DFSClient seqno: 3 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
2020-12-03 07:24:37,950 [DataStreamer for file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775784_1002] DEBUG hdfs.DataStreamer (DataStreamer.java:endBlock(638)) - Closing old block BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775784_1002
2020-12-03 07:24:37,954 [IPC Server handler 0 on default port 42543] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] is closed by DFSClient_NONMAPREDUCE_-1548708192_1
2020-12-03 07:24:37,955 [Listener at localhost/38811] WARN  hdfs.DFSOutputStream (DFSStripedOutputStream.java:logCorruptBlocks(1308)) - Block group <1> failed to write 2 blocks.
2020-12-03 07:24:37,956 [IPC Server handler 1 on default port 42543] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getErasureCodingPolicy	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:37,958 [IPC Server handler 2 on default port 42543] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226]	dst=null	perm=null	proto=rpc
2020-12-03 07:24:37,962 [Listener at localhost/38811] INFO  hdfs.StripedFileTestUtil (StripedFileTestUtil.java:waitBlockGroupsReported(290)) - All blockGroups of file /TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226] verified to have all internalBlocks.
2020-12-03 07:24:37,963 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:42543
2020-12-03 07:24:37,964 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xc899c9ab5a38add5: from storage DS-780c3aad-5133-4c8c-a94b-8deef7fd424f node DatanodeRegistration(127.0.0.1:45564, datanodeUuid=98ea0ce4-a3b3-42e5-9bc8-9e81b791e85f, infoPort=41548, infoSecurePort=0, ipcPort=38030, storageInfo=lv=-57;cid=testClusterID;nsid=1090966717;c=1606980274066), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:37,965 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xc899c9ab5a38add5: from storage DS-e96c0c9c-1d9e-48ab-aefe-143fa18e9d0f node DatanodeRegistration(127.0.0.1:45564, datanodeUuid=98ea0ce4-a3b3-42e5-9bc8-9e81b791e85f, infoPort=41548, infoSecurePort=0, ipcPort=38030, storageInfo=lv=-57;cid=testClusterID;nsid=1090966717;c=1606980274066), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:37,965 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xc899c9ab5a38add5,  containing 2 storage report(s), of which we sent 2. The reports had 1 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:37,965 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:38,075 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:42543
2020-12-03 07:24:38,077 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x132cad7e090d09e0: from storage DS-d72315d1-2ea3-44c3-ade3-d7b892bdf67f node DatanodeRegistration(127.0.0.1:35995, datanodeUuid=c1d7d0bc-1e04-40b2-8bda-52556cd4f522, infoPort=46686, infoSecurePort=0, ipcPort=37909, storageInfo=lv=-57;cid=testClusterID;nsid=1090966717;c=1606980274066), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:38,077 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x132cad7e090d09e0: from storage DS-e1a62b65-ebd2-4b8a-8428-d9e31df860fe node DatanodeRegistration(127.0.0.1:35995, datanodeUuid=c1d7d0bc-1e04-40b2-8bda-52556cd4f522, infoPort=46686, infoSecurePort=0, ipcPort=37909, storageInfo=lv=-57;cid=testClusterID;nsid=1090966717;c=1606980274066), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:38,077 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x132cad7e090d09e0,  containing 2 storage report(s), of which we sent 2. The reports had 1 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:38,077 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:38,171 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:42543
2020-12-03 07:24:38,172 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xcac04d2855b46726: from storage DS-4a224303-3aff-47f8-9ce9-586dfad45f29 node DatanodeRegistration(127.0.0.1:35478, datanodeUuid=b1a31110-b9aa-4184-8cd5-6778c3221b36, infoPort=38411, infoSecurePort=0, ipcPort=40861, storageInfo=lv=-57;cid=testClusterID;nsid=1090966717;c=1606980274066), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:24:38,172 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xcac04d2855b46726: from storage DS-ad168160-c5a9-4603-8799-f50df9b59658 node DatanodeRegistration(127.0.0.1:35478, datanodeUuid=b1a31110-b9aa-4184-8cd5-6778c3221b36, infoPort=38411, infoSecurePort=0, ipcPort=40861, storageInfo=lv=-57;cid=testClusterID;nsid=1090966717;c=1606980274066), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:38,173 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xcac04d2855b46726,  containing 2 storage report(s), of which we sent 2. The reports had 1 total blocks and used 1 RPC(s). This took 1 msec to generate and 1 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:38,173 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:38,271 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:42543
2020-12-03 07:24:38,272 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x1a8006ff51ee4d28: from storage DS-90decd12-583a-4d3d-8ffa-ff0c65a87d71 node DatanodeRegistration(127.0.0.1:39536, datanodeUuid=778e686f-955b-4664-b0d5-e7c9ffc5fcab, infoPort=38347, infoSecurePort=0, ipcPort=39452, storageInfo=lv=-57;cid=testClusterID;nsid=1090966717;c=1606980274066), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:38,273 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x1a8006ff51ee4d28: from storage DS-532f25f9-06d4-4afd-8691-3f01f1faf6e8 node DatanodeRegistration(127.0.0.1:39536, datanodeUuid=778e686f-955b-4664-b0d5-e7c9ffc5fcab, infoPort=38347, infoSecurePort=0, ipcPort=39452, storageInfo=lv=-57;cid=testClusterID;nsid=1090966717;c=1606980274066), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:38,273 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x1a8006ff51ee4d28,  containing 2 storage report(s), of which we sent 2. The reports had 1 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:38,273 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:38,376 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:42543
2020-12-03 07:24:38,377 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xddbe9e8baf15def4: from storage DS-bfb9e676-bcb3-4b9b-8b21-3adff7deb76f node DatanodeRegistration(127.0.0.1:38509, datanodeUuid=0c6f8970-d7dd-48b5-8d5e-a875696526d2, infoPort=45134, infoSecurePort=0, ipcPort=39867, storageInfo=lv=-57;cid=testClusterID;nsid=1090966717;c=1606980274066), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:38,378 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xddbe9e8baf15def4: from storage DS-ec3d9943-1545-4cf6-b156-a296d9b5e16e node DatanodeRegistration(127.0.0.1:38509, datanodeUuid=0c6f8970-d7dd-48b5-8d5e-a875696526d2, infoPort=45134, infoSecurePort=0, ipcPort=39867, storageInfo=lv=-57;cid=testClusterID;nsid=1090966717;c=1606980274066), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:38,378 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xddbe9e8baf15def4,  containing 2 storage report(s), of which we sent 2. The reports had 1 total blocks and used 1 RPC(s). This took 1 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:38,378 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:38,468 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:42543
2020-12-03 07:24:38,469 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xe74c4a171fa4f826: from storage DS-aa276f62-89b9-45fb-b1dc-db56c85396ff node DatanodeRegistration(127.0.0.1:40183, datanodeUuid=fa199516-b4fb-46da-b156-01e59120b35f, infoPort=42328, infoSecurePort=0, ipcPort=37033, storageInfo=lv=-57;cid=testClusterID;nsid=1090966717;c=1606980274066), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:38,469 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xe74c4a171fa4f826: from storage DS-5435f169-1195-4ff2-be92-139ab30335f6 node DatanodeRegistration(127.0.0.1:40183, datanodeUuid=fa199516-b4fb-46da-b156-01e59120b35f, infoPort=42328, infoSecurePort=0, ipcPort=37033, storageInfo=lv=-57;cid=testClusterID;nsid=1090966717;c=1606980274066), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:38,470 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xe74c4a171fa4f826,  containing 2 storage report(s), of which we sent 2. The reports had 1 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:38,470 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:38,564 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:42543
2020-12-03 07:24:38,565 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x2a136109e6dc22fd: from storage DS-301c141a-2a18-464c-bff6-f3cc085eb873 node DatanodeRegistration(127.0.0.1:39670, datanodeUuid=d5e826a6-bb6a-4355-9ce3-e94594fc7594, infoPort=40910, infoSecurePort=0, ipcPort=38811, storageInfo=lv=-57;cid=testClusterID;nsid=1090966717;c=1606980274066), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:38,565 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x2a136109e6dc22fd: from storage DS-ccf36913-5b38-4a68-9d8f-bff774a3138d node DatanodeRegistration(127.0.0.1:39670, datanodeUuid=d5e826a6-bb6a-4355-9ce3-e94594fc7594, infoPort=40910, infoSecurePort=0, ipcPort=38811, storageInfo=lv=-57;cid=testClusterID;nsid=1090966717;c=1606980274066), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:24:38,566 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x2a136109e6dc22fd,  containing 2 storage report(s), of which we sent 2. The reports had 1 total blocks and used 1 RPC(s). This took 1 msec to generate and 1 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:24:38,566 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:38,665 [IPC Server handler 8 on default port 42543] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226]	dst=null	perm=null	proto=rpc
2020-12-03 07:24:38,668 [IPC Server handler 9 on default port 42543] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/TestDFSStripedOutputStreamWithFailureBase/dn[4, 5]len393339kill[131113, 262226]	dst=null	perm=null	proto=rpc
2020-12-03 07:24:38,670 [IPC Server handler 0 on default port 42543] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getErasureCodingPolicy	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:24:38,671 [Listener at localhost/38811] INFO  hdfs.StripedFileTestUtil (StripedFileTestUtil.java:checkData(385)) - gs=1002, oldGS=1001
2020-12-03 07:24:38,672 [Listener at localhost/38811] INFO  hdfs.StripedFileTestUtil (StripedFileTestUtil.java:checkData(425)) - i,j=0, 0, numCellInBlock=2, blockSize=65659, lb=LocatedBlock{BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775792_1002; getBlockSize()=65659; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40183,DS-aa276f62-89b9-45fb-b1dc-db56c85396ff,DISK]]}
2020-12-03 07:24:38,674 [Listener at localhost/38811] INFO  hdfs.StripedFileTestUtil (StripedFileTestUtil.java:checkData(425)) - i,j=1, 1, numCellInBlock=1, blockSize=65536, lb=LocatedBlock{BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775791_1002; getBlockSize()=65536; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45564,DS-e96c0c9c-1d9e-48ab-aefe-143fa18e9d0f,DISK]]}
2020-12-03 07:24:38,676 [Listener at localhost/38811] INFO  hdfs.StripedFileTestUtil (StripedFileTestUtil.java:checkData(425)) - i,j=2, 2, numCellInBlock=1, blockSize=65536, lb=LocatedBlock{BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775790_1002; getBlockSize()=65536; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38509,DS-bfb9e676-bcb3-4b9b-8b21-3adff7deb76f,DISK]]}
2020-12-03 07:24:38,677 [Listener at localhost/38811] INFO  hdfs.StripedFileTestUtil (StripedFileTestUtil.java:checkData(425)) - i,j=3, 3, numCellInBlock=1, blockSize=65536, lb=LocatedBlock{BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775789_1002; getBlockSize()=65536; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35995,DS-d72315d1-2ea3-44c3-ade3-d7b892bdf67f,DISK]]}
2020-12-03 07:24:38,680 [Listener at localhost/38811] INFO  hdfs.StripedFileTestUtil (StripedFileTestUtil.java:checkData(425)) - i,j=4, 4, numCellInBlock=1, blockSize=65536, lb=null
2020-12-03 07:24:38,680 [Listener at localhost/38811] INFO  hdfs.StripedFileTestUtil (StripedFileTestUtil.java:checkData(425)) - i,j=5, 5, numCellInBlock=1, blockSize=65536, lb=null
2020-12-03 07:24:38,680 [Listener at localhost/38811] INFO  hdfs.StripedFileTestUtil (StripedFileTestUtil.java:checkData(425)) - i,j=6, 0, numCellInBlock=2, blockSize=65659, lb=LocatedBlock{BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775786_1002; getBlockSize()=65659; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35478,DS-ad168160-c5a9-4603-8799-f50df9b59658,DISK]]}
2020-12-03 07:24:38,682 [Listener at localhost/38811] INFO  hdfs.StripedFileTestUtil (StripedFileTestUtil.java:checkData(425)) - i,j=7, 0, numCellInBlock=2, blockSize=65659, lb=LocatedBlock{BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775785_1002; getBlockSize()=65659; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39536,DS-532f25f9-06d4-4afd-8691-3f01f1faf6e8,DISK]]}
2020-12-03 07:24:38,684 [Listener at localhost/38811] INFO  hdfs.StripedFileTestUtil (StripedFileTestUtil.java:checkData(425)) - i,j=8, 0, numCellInBlock=2, blockSize=65659, lb=LocatedBlock{BP-1688424058-172.17.0.4-1606980274066:blk_-9223372036854775784_1002; getBlockSize()=65659; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39670,DS-301c141a-2a18-464c-bff6-f3cc085eb873,DISK]]}
2020-12-03 07:24:38,685 [Listener at localhost/38811] INFO  hdfs.StripedFileTestUtil (StripedFileTestUtil.java:checkData(446)) - Internal blocks to check: [0, 1, 2, 3, 6, 7, 8]
2020-12-03 07:24:38,758 [Listener at localhost/38811] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:24:38,758 [Listener at localhost/38811] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 6
2020-12-03 07:24:38,758 [Listener at localhost/38811] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:24:38,758 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@6401d0a0] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:24:38,761 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-301c141a-2a18-464c-bff6-f3cc085eb873) exiting.
2020-12-03 07:24:38,761 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-ccf36913-5b38-4a68-9d8f-bff774a3138d) exiting.
2020-12-03 07:24:38,774 [Listener at localhost/38811] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@58a63629{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:24:38,776 [Listener at localhost/38811] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7de843ef{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:38,777 [Listener at localhost/38811] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@289778cd{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:38,777 [Listener at localhost/38811] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@11e33bac{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:38,778 [Listener at localhost/38811] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 38811
2020-12-03 07:24:38,784 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:38,786 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:38,787 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:24:38,787 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1688424058-172.17.0.4-1606980274066 (Datanode Uuid d5e826a6-bb6a-4355-9ce3-e94594fc7594) service to localhost/127.0.0.1:42543
2020-12-03 07:24:38,787 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1688424058-172.17.0.4-1606980274066 (Datanode Uuid d5e826a6-bb6a-4355-9ce3-e94594fc7594)
2020-12-03 07:24:38,787 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:38,788 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1688424058-172.17.0.4-1606980274066] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:38,788 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1688424058-172.17.0.4-1606980274066] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:38,791 [Listener at localhost/38811] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:24:38,792 [Listener at localhost/38811] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:24:38,794 [Listener at localhost/38811] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:24:38,794 [Listener at localhost/38811] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:24:38,796 [Listener at localhost/38811] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:24:38,796 [Listener at localhost/38811] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 5
2020-12-03 07:24:38,797 [Listener at localhost/38811] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:24:38,797 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@64b70919] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:24:38,798 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-5435f169-1195-4ff2-be92-139ab30335f6) exiting.
2020-12-03 07:24:38,798 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-aa276f62-89b9-45fb-b1dc-db56c85396ff) exiting.
2020-12-03 07:24:38,812 [Listener at localhost/38811] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@29629fbb{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:24:38,812 [Listener at localhost/38811] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@681adc8f{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:38,813 [Listener at localhost/38811] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@77010a30{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:38,813 [Listener at localhost/38811] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@43034809{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:38,814 [Listener at localhost/38811] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 37033
2020-12-03 07:24:38,818 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:38,818 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:38,820 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:24:38,820 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1688424058-172.17.0.4-1606980274066 (Datanode Uuid fa199516-b4fb-46da-b156-01e59120b35f) service to localhost/127.0.0.1:42543
2020-12-03 07:24:38,820 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1688424058-172.17.0.4-1606980274066 (Datanode Uuid fa199516-b4fb-46da-b156-01e59120b35f)
2020-12-03 07:24:38,820 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:38,820 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1688424058-172.17.0.4-1606980274066] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:38,821 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1688424058-172.17.0.4-1606980274066] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:38,824 [Listener at localhost/38811] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:24:38,824 [Listener at localhost/38811] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:24:38,825 [Listener at localhost/38811] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:24:38,826 [Listener at localhost/38811] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:24:38,829 [Listener at localhost/38811] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:24:38,829 [Listener at localhost/38811] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 4
2020-12-03 07:24:38,829 [Listener at localhost/38811] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:24:38,829 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@20e6c4dc] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:24:38,831 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-ec3d9943-1545-4cf6-b156-a296d9b5e16e) exiting.
2020-12-03 07:24:38,831 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-bfb9e676-bcb3-4b9b-8b21-3adff7deb76f) exiting.
2020-12-03 07:24:38,847 [Listener at localhost/38811] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@4a8df3e2{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:24:38,847 [Listener at localhost/38811] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@3d98d138{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:38,848 [Listener at localhost/38811] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7e4d2287{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:38,848 [Listener at localhost/38811] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@b10a26d{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:38,849 [Listener at localhost/38811] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 39867
2020-12-03 07:24:38,854 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:38,854 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:38,854 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:24:38,855 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1688424058-172.17.0.4-1606980274066 (Datanode Uuid 0c6f8970-d7dd-48b5-8d5e-a875696526d2) service to localhost/127.0.0.1:42543
2020-12-03 07:24:38,856 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1688424058-172.17.0.4-1606980274066 (Datanode Uuid 0c6f8970-d7dd-48b5-8d5e-a875696526d2)
2020-12-03 07:24:38,856 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:38,856 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1688424058-172.17.0.4-1606980274066] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:38,856 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1688424058-172.17.0.4-1606980274066] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:38,861 [Listener at localhost/38811] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:24:38,861 [Listener at localhost/38811] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:24:38,862 [Listener at localhost/38811] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:24:38,862 [Listener at localhost/38811] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:24:38,865 [Listener at localhost/38811] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:24:38,865 [Listener at localhost/38811] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 3
2020-12-03 07:24:38,866 [Listener at localhost/38811] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:24:38,866 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@344426bf] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:24:38,867 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-532f25f9-06d4-4afd-8691-3f01f1faf6e8) exiting.
2020-12-03 07:24:38,867 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-90decd12-583a-4d3d-8ffa-ff0c65a87d71) exiting.
2020-12-03 07:24:38,882 [Listener at localhost/38811] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@67b7c170{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:24:38,883 [Listener at localhost/38811] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@67440de6{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:38,883 [Listener at localhost/38811] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@408b87aa{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:38,883 [Listener at localhost/38811] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2764c546{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:38,884 [Listener at localhost/38811] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 39452
2020-12-03 07:24:38,891 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:38,891 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:24:38,891 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:38,891 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1688424058-172.17.0.4-1606980274066 (Datanode Uuid 778e686f-955b-4664-b0d5-e7c9ffc5fcab) service to localhost/127.0.0.1:42543
2020-12-03 07:24:38,891 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1688424058-172.17.0.4-1606980274066 (Datanode Uuid 778e686f-955b-4664-b0d5-e7c9ffc5fcab)
2020-12-03 07:24:38,891 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:38,895 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1688424058-172.17.0.4-1606980274066] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:38,895 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1688424058-172.17.0.4-1606980274066] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:38,905 [Listener at localhost/38811] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:24:38,905 [Listener at localhost/38811] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:24:38,907 [Listener at localhost/38811] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:24:38,907 [Listener at localhost/38811] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:24:38,910 [Listener at localhost/38811] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:24:38,910 [Listener at localhost/38811] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 2
2020-12-03 07:24:38,910 [Listener at localhost/38811] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:24:38,910 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@58d63b16] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:24:38,912 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-ad168160-c5a9-4603-8799-f50df9b59658) exiting.
2020-12-03 07:24:38,912 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-4a224303-3aff-47f8-9ce9-586dfad45f29) exiting.
2020-12-03 07:24:38,932 [Listener at localhost/38811] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6f3f0fae{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:24:38,933 [Listener at localhost/38811] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@21a66d45{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:38,933 [Listener at localhost/38811] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@42b21d99{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:38,933 [Listener at localhost/38811] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@369c9bb{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:38,934 [Listener at localhost/38811] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 40861
2020-12-03 07:24:38,941 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:38,941 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:24:38,941 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1688424058-172.17.0.4-1606980274066 (Datanode Uuid b1a31110-b9aa-4184-8cd5-6778c3221b36) service to localhost/127.0.0.1:42543
2020-12-03 07:24:38,941 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1688424058-172.17.0.4-1606980274066 (Datanode Uuid b1a31110-b9aa-4184-8cd5-6778c3221b36)
2020-12-03 07:24:38,941 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:38,942 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1688424058-172.17.0.4-1606980274066] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:38,942 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1688424058-172.17.0.4-1606980274066] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:38,942 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:38,944 [Listener at localhost/38811] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:24:38,944 [Listener at localhost/38811] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:24:38,948 [Listener at localhost/38811] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:24:38,948 [Listener at localhost/38811] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:24:38,952 [Listener at localhost/38811] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:24:38,952 [Listener at localhost/38811] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 1
2020-12-03 07:24:38,952 [Listener at localhost/38811] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:24:38,952 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@5da7cee2] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:24:38,955 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-e1a62b65-ebd2-4b8a-8428-d9e31df860fe) exiting.
2020-12-03 07:24:38,955 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-d72315d1-2ea3-44c3-ade3-d7b892bdf67f) exiting.
2020-12-03 07:24:38,972 [Listener at localhost/38811] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@4d48bd85{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:24:38,973 [Listener at localhost/38811] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7bbbb6a8{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:38,973 [Listener at localhost/38811] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@73017a80{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:38,974 [Listener at localhost/38811] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6a9950f1{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:38,975 [Listener at localhost/38811] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 37909
2020-12-03 07:24:38,982 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:38,982 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:38,982 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:24:38,982 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1688424058-172.17.0.4-1606980274066 (Datanode Uuid c1d7d0bc-1e04-40b2-8bda-52556cd4f522) service to localhost/127.0.0.1:42543
2020-12-03 07:24:38,985 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1688424058-172.17.0.4-1606980274066 (Datanode Uuid c1d7d0bc-1e04-40b2-8bda-52556cd4f522)
2020-12-03 07:24:38,985 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:38,985 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1688424058-172.17.0.4-1606980274066] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:38,986 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1688424058-172.17.0.4-1606980274066] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:38,987 [Listener at localhost/38811] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:24:38,988 [Listener at localhost/38811] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:24:38,989 [Listener at localhost/38811] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:24:38,990 [Listener at localhost/38811] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:24:38,993 [Listener at localhost/38811] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:24:38,994 [Listener at localhost/38811] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:24:38,994 [Listener at localhost/38811] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:24:38,994 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@29a4f594] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:24:38,996 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-e96c0c9c-1d9e-48ab-aefe-143fa18e9d0f) exiting.
2020-12-03 07:24:38,996 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-780c3aad-5133-4c8c-a94b-8deef7fd424f) exiting.
2020-12-03 07:24:39,014 [Listener at localhost/38811] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@153d4abb{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:24:39,015 [Listener at localhost/38811] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6d4c273c{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:39,016 [Listener at localhost/38811] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2e3cdec2{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:39,016 [Listener at localhost/38811] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@44cb460e{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:39,017 [Listener at localhost/38811] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 38030
2020-12-03 07:24:39,024 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:39,024 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:39,025 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:24:39,025 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1688424058-172.17.0.4-1606980274066 (Datanode Uuid 98ea0ce4-a3b3-42e5-9bc8-9e81b791e85f) service to localhost/127.0.0.1:42543
2020-12-03 07:24:39,128 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1688424058-172.17.0.4-1606980274066 (Datanode Uuid 98ea0ce4-a3b3-42e5-9bc8-9e81b791e85f)
2020-12-03 07:24:39,128 [BP-1688424058-172.17.0.4-1606980274066 heartbeating to localhost/127.0.0.1:42543] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1688424058-172.17.0.4-1606980274066
2020-12-03 07:24:39,129 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1688424058-172.17.0.4-1606980274066] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:39,129 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1688424058-172.17.0.4-1606980274066] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:24:39,133 [Listener at localhost/38811] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:24:39,133 [Listener at localhost/38811] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:24:39,135 [Listener at localhost/38811] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:24:39,135 [Listener at localhost/38811] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:24:39,140 [Listener at localhost/38811] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:24:39,140 [Listener at localhost/38811] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:24:39,141 [Listener at localhost/38811] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:24:39,141 [Listener at localhost/38811] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 1, 17
2020-12-03 07:24:39,141 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@746b18fd] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:24:39,141 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@630d1b2f] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:24:39,141 [Listener at localhost/38811] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 18 Total time for transactions(ms): 9 Number of transactions batched in Syncs: 1 Number of syncs: 18 SyncTimes(ms): 4 2 
2020-12-03 07:24:39,142 [Listener at localhost/38811] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000018
2020-12-03 07:24:39,142 [Listener at localhost/38811] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000018
2020-12-03 07:24:39,143 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:24:39,143 [CacheReplicationMonitor(1458703896)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:24:39,146 [Listener at localhost/38811] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 42543
2020-12-03 07:24:39,149 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:24:39,163 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:24:39,164 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:24:39,175 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:24:39,185 [Listener at localhost/38811] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:24:39,186 [Listener at localhost/38811] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:24:39,187 [Listener at localhost/38811] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@38a1c423{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:24:39,188 [Listener at localhost/38811] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@336365bc{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:24:39,188 [Listener at localhost/38811] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@67403656{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:24:39,189 [Listener at localhost/38811] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@27c04377{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:24:39,189 [Listener at localhost/38811] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-12-03 07:24:39,205 [Listener at localhost/38811] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-12-03 07:24:39,205 [Listener at localhost/38811] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
msx-rc 0
