2020-12-03 07:19:31,134 [main] INFO  qjournal.MiniQJMHACluster (MiniQJMHACluster.java:<init>(113)) - Set MiniQJMHACluster basePort to 10352
2020-12-03 07:19:31,142 [main] INFO  qjournal.MiniJournalCluster (MiniJournalCluster.java:<init>(101)) - Starting MiniJournalCluster with 3 journal nodes
2020-12-03 07:19:31,322 [main] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:19:31,442 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:19:31,443 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - JournalNode metrics system started
2020-12-03 07:19:31,574 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for journal at: http://localhost:0
2020-12-03 07:19:31,589 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:31,604 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @1504ms
2020-12-03 07:19:31,737 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:19:31,778 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.journal is not defined
2020-12-03 07:19:31,779 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:31,796 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:19:31,801 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context journal
2020-12-03 07:19:31,801 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:19:31,802 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:19:31,831 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 34738
2020-12-03 07:19:31,836 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:19:31,882 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5ace1ed4{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:19:31,883 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@27ff5d15{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:19:31,921 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@65c7a252{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/journal/,AVAILABLE}{/journal}
2020-12-03 07:19:31,930 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1ffaf86{HTTP/1.1,[http/1.1]}{localhost:34738}
2020-12-03 07:19:31,930 [main] INFO  server.Server (Server.java:doStart(419)) - Started @1831ms
2020-12-03 07:19:31,932 [main] INFO  server.JournalNode (JournalNodeRpcServer.java:<init>(85)) - RPC server is binding to localhost:0
2020-12-03 07:19:31,976 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 500, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:19:31,989 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:19:32,276 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:19:32,276 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:19:32,279 [Listener at localhost/38894] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JournalNode metrics system started (again)
2020-12-03 07:19:32,282 [Listener at localhost/38894] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for journal at: http://localhost:0
2020-12-03 07:19:32,282 [Listener at localhost/38894] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:32,285 [Listener at localhost/38894] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:19:32,285 [Listener at localhost/38894] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.journal is not defined
2020-12-03 07:19:32,286 [Listener at localhost/38894] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:32,289 [Listener at localhost/38894] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:19:32,290 [Listener at localhost/38894] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context journal
2020-12-03 07:19:32,291 [Listener at localhost/38894] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:19:32,291 [Listener at localhost/38894] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:19:32,292 [Listener at localhost/38894] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 32893
2020-12-03 07:19:32,293 [Listener at localhost/38894] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:19:32,295 [Listener at localhost/38894] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7ceb3185{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:19:32,296 [Listener at localhost/38894] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3561c410{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:19:32,305 [Listener at localhost/38894] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3af0a9da{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/journal/,AVAILABLE}{/journal}
2020-12-03 07:19:32,306 [Listener at localhost/38894] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@43b9fd5{HTTP/1.1,[http/1.1]}{localhost:32893}
2020-12-03 07:19:32,306 [Listener at localhost/38894] INFO  server.Server (Server.java:doStart(419)) - Started @2207ms
2020-12-03 07:19:32,308 [Listener at localhost/38894] INFO  server.JournalNode (JournalNodeRpcServer.java:<init>(85)) - RPC server is binding to localhost:0
2020-12-03 07:19:32,308 [Listener at localhost/38894] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 500, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:19:32,309 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:19:32,313 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:19:32,313 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:19:32,342 [Listener at localhost/36507] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JournalNode metrics system started (again)
2020-12-03 07:19:32,345 [Listener at localhost/36507] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for journal at: http://localhost:0
2020-12-03 07:19:32,346 [Listener at localhost/36507] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:32,348 [Listener at localhost/36507] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:19:32,350 [Listener at localhost/36507] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.journal is not defined
2020-12-03 07:19:32,350 [Listener at localhost/36507] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:32,354 [Listener at localhost/36507] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:19:32,356 [Listener at localhost/36507] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context journal
2020-12-03 07:19:32,356 [Listener at localhost/36507] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:19:32,357 [Listener at localhost/36507] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:19:32,358 [Listener at localhost/36507] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 33481
2020-12-03 07:19:32,358 [Listener at localhost/36507] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:19:32,362 [Listener at localhost/36507] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4ebff610{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:19:32,363 [Listener at localhost/36507] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@44d52de2{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:19:32,376 [Listener at localhost/36507] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6bc407fd{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/journal/,AVAILABLE}{/journal}
2020-12-03 07:19:32,378 [Listener at localhost/36507] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@291f18{HTTP/1.1,[http/1.1]}{localhost:33481}
2020-12-03 07:19:32,378 [Listener at localhost/36507] INFO  server.Server (Server.java:doStart(419)) - Started @2279ms
2020-12-03 07:19:32,380 [Listener at localhost/36507] INFO  server.JournalNode (JournalNodeRpcServer.java:<init>(85)) - RPC server is binding to localhost:0
2020-12-03 07:19:32,380 [Listener at localhost/36507] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 500, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:19:32,382 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:19:32,387 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:19:32,389 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:19:33,060 [IPC Server handler 0 on default port 32907] INFO  server.JournalNode (JournalNode.java:getOrCreateJournal(101)) - Initializing journal in directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/waitactive
2020-12-03 07:19:33,060 [IPC Server handler 0 on default port 36507] INFO  server.JournalNode (JournalNode.java:getOrCreateJournal(101)) - Initializing journal in directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/waitactive
2020-12-03 07:19:33,060 [IPC Server handler 0 on default port 38894] INFO  server.JournalNode (JournalNode.java:getOrCreateJournal(101)) - Initializing journal in directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/waitactive
2020-12-03 07:19:33,076 [IPC Server handler 0 on default port 38894] WARN  common.Storage (Storage.java:analyzeStorage(671)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/waitactive does not exist
2020-12-03 07:19:33,076 [IPC Server handler 0 on default port 32907] WARN  common.Storage (Storage.java:analyzeStorage(671)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/waitactive does not exist
2020-12-03 07:19:33,076 [IPC Server handler 0 on default port 36507] WARN  common.Storage (Storage.java:analyzeStorage(671)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/waitactive does not exist
2020-12-03 07:19:33,080 [IPC Server handler 0 on default port 32907] INFO  server.Journal (JournaledEditsCache.java:<init>(132)) - Enabling the journaled edits cache with a capacity of bytes: 1048576
2020-12-03 07:19:33,080 [IPC Server handler 0 on default port 38894] INFO  server.Journal (JournaledEditsCache.java:<init>(132)) - Enabling the journaled edits cache with a capacity of bytes: 1048576
2020-12-03 07:19:33,080 [IPC Server handler 0 on default port 36507] INFO  server.Journal (JournaledEditsCache.java:<init>(132)) - Enabling the journaled edits cache with a capacity of bytes: 1048576
2020-12-03 07:19:33,106 [IPC Server handler 0 on default port 38894] ERROR server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeAddrs(298)) - Could not construct Shared Edits Uri
2020-12-03 07:19:33,106 [IPC Server handler 0 on default port 32907] ERROR server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeAddrs(298)) - Could not construct Shared Edits Uri
2020-12-03 07:19:33,106 [IPC Server handler 0 on default port 32907] WARN  server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeProxies(145)) - Other JournalNode addresses not available. Journal Syncing cannot be done
2020-12-03 07:19:33,106 [IPC Server handler 0 on default port 38894] WARN  server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeProxies(145)) - Other JournalNode addresses not available. Journal Syncing cannot be done
2020-12-03 07:19:33,109 [IPC Server handler 0 on default port 36507] ERROR server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeAddrs(298)) - Could not construct Shared Edits Uri
2020-12-03 07:19:33,109 [IPC Server handler 0 on default port 36507] WARN  server.JournalNodeSyncer (JournalNodeSyncer.java:getOtherJournalNodeProxies(145)) - Other JournalNode addresses not available. Journal Syncing cannot be done
2020-12-03 07:19:33,446 [Listener at localhost/32907] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=3, numDataNodes=1
Formatting using clusterid: testClusterID
2020-12-03 07:19:33,690 [Listener at localhost/32907] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:19:33,704 [Listener at localhost/32907] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:19:33,706 [Listener at localhost/32907] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:19:33,706 [Listener at localhost/32907] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:19:33,707 [Listener at localhost/32907] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:19:33,707 [Listener at localhost/32907] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:19:33,708 [Listener at localhost/32907] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:19:33,709 [Listener at localhost/32907] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns1
2020-12-03 07:19:33,709 [Listener at localhost/32907] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: true
2020-12-03 07:19:33,753 [Listener at localhost/32907] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:33,760 [Listener at localhost/32907] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2020-12-03 07:19:33,761 [Listener at localhost/32907] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:19:33,761 [Listener at localhost/32907] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:19:33,766 [Listener at localhost/32907] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:19:33,767 [Listener at localhost/32907] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:19:33
2020-12-03 07:19:33,769 [Listener at localhost/32907] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:19:33,770 [Listener at localhost/32907] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:19:33,772 [Listener at localhost/32907] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:19:33,772 [Listener at localhost/32907] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:19:33,785 [Listener at localhost/32907] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:19:33,786 [Listener at localhost/32907] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:19:33,794 [Listener at localhost/32907] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:19:33,795 [Listener at localhost/32907] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:19:33,795 [Listener at localhost/32907] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:19:33,795 [Listener at localhost/32907] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:19:33,797 [Listener at localhost/32907] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 1
2020-12-03 07:19:33,797 [Listener at localhost/32907] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:19:33,797 [Listener at localhost/32907] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:19:33,797 [Listener at localhost/32907] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:19:33,798 [Listener at localhost/32907] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:19:33,798 [Listener at localhost/32907] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:19:33,798 [Listener at localhost/32907] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:19:33,843 [Listener at localhost/32907] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GLOBAL serial map: bits=29 maxEntries=536870911
2020-12-03 07:19:33,844 [Listener at localhost/32907] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - USER serial map: bits=24 maxEntries=16777215
2020-12-03 07:19:33,844 [Listener at localhost/32907] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GROUP serial map: bits=24 maxEntries=16777215
2020-12-03 07:19:33,844 [Listener at localhost/32907] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - XATTR serial map: bits=24 maxEntries=16777215
2020-12-03 07:19:33,861 [Listener at localhost/32907] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:19:33,861 [Listener at localhost/32907] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:19:33,862 [Listener at localhost/32907] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:19:33,862 [Listener at localhost/32907] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:19:33,868 [Listener at localhost/32907] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:19:33,869 [Listener at localhost/32907] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:19:33,869 [Listener at localhost/32907] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:19:33,869 [Listener at localhost/32907] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:19:33,876 [Listener at localhost/32907] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:19:33,879 [Listener at localhost/32907] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:19:33,884 [Listener at localhost/32907] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:19:33,884 [Listener at localhost/32907] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:19:33,885 [Listener at localhost/32907] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:19:33,885 [Listener at localhost/32907] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:19:33,896 [Listener at localhost/32907] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:19:33,897 [Listener at localhost/32907] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:19:33,897 [Listener at localhost/32907] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:19:33,901 [Listener at localhost/32907] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:19:33,901 [Listener at localhost/32907] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:19:33,904 [Listener at localhost/32907] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:19:33,904 [Listener at localhost/32907] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:19:33,904 [Listener at localhost/32907] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:19:33,904 [Listener at localhost/32907] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:19:33,928 [IPC Server handler 0 on default port 32907] INFO  server.JournalNode (JournalNode.java:getOrCreateJournal(101)) - Initializing journal in directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1
2020-12-03 07:19:33,928 [IPC Server handler 1 on default port 38894] INFO  server.JournalNode (JournalNode.java:getOrCreateJournal(101)) - Initializing journal in directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1
2020-12-03 07:19:33,928 [IPC Server handler 0 on default port 36507] INFO  server.JournalNode (JournalNode.java:getOrCreateJournal(101)) - Initializing journal in directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1
2020-12-03 07:19:33,929 [IPC Server handler 0 on default port 32907] WARN  common.Storage (Storage.java:analyzeStorage(671)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1 does not exist
2020-12-03 07:19:33,929 [IPC Server handler 1 on default port 38894] WARN  common.Storage (Storage.java:analyzeStorage(671)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1 does not exist
2020-12-03 07:19:33,929 [IPC Server handler 0 on default port 32907] INFO  server.Journal (JournaledEditsCache.java:<init>(132)) - Enabling the journaled edits cache with a capacity of bytes: 1048576
2020-12-03 07:19:33,929 [IPC Server handler 0 on default port 36507] WARN  common.Storage (Storage.java:analyzeStorage(671)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1 does not exist
2020-12-03 07:19:33,929 [IPC Server handler 1 on default port 38894] INFO  server.Journal (JournaledEditsCache.java:<init>(132)) - Enabling the journaled edits cache with a capacity of bytes: 1048576
2020-12-03 07:19:33,929 [IPC Server handler 0 on default port 36507] INFO  server.Journal (JournaledEditsCache.java:<init>(132)) - Enabling the journaled edits cache with a capacity of bytes: 1048576
2020-12-03 07:19:33,940 [IPC Server handler 0 on default port 36507] INFO  server.JournalNodeSyncer (JournalNodeSyncer.java:start(122)) - Starting SyncJournal daemon for journal ns1
2020-12-03 07:19:33,940 [IPC Server handler 0 on default port 32907] INFO  server.JournalNodeSyncer (JournalNodeSyncer.java:start(122)) - Starting SyncJournal daemon for journal ns1
2020-12-03 07:19:33,941 [IPC Server handler 1 on default port 38894] INFO  server.JournalNodeSyncer (JournalNodeSyncer.java:start(122)) - Starting SyncJournal daemon for journal ns1
2020-12-03 07:19:33,945 [Listener at localhost/32907] INFO  namenode.FSImage (FSImage.java:format(185)) - Allocated new BlockPoolId: BP-1018250855-172.17.0.10-1606979973945
2020-12-03 07:19:34,030 [Listener at localhost/32907] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-12-03 07:19:34,098 [Listener at localhost/32907] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-12-03 07:19:34,125 [IPC Server handler 1 on default port 36507] INFO  server.Journal (Journal.java:format(256)) - Formatting journal id : ns1 with namespace info: lv=-65;cid=testClusterID;nsid=1847453481;c=1606979973945;bpid=BP-1018250855-172.17.0.10-1606979973945 and force: true
2020-12-03 07:19:34,125 [IPC Server handler 1 on default port 32907] INFO  server.Journal (Journal.java:format(256)) - Formatting journal id : ns1 with namespace info: lv=-65;cid=testClusterID;nsid=1847453481;c=1606979973945;bpid=BP-1018250855-172.17.0.10-1606979973945 and force: true
2020-12-03 07:19:34,125 [IPC Server handler 1 on default port 36507] INFO  common.Storage (Storage.java:analyzeStorage(674)) - /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1 does not exist. Creating ...
2020-12-03 07:19:34,125 [IPC Server handler 1 on default port 32907] INFO  common.Storage (Storage.java:analyzeStorage(674)) - /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1 does not exist. Creating ...
2020-12-03 07:19:34,125 [IPC Server handler 2 on default port 38894] INFO  server.Journal (Journal.java:format(256)) - Formatting journal id : ns1 with namespace info: lv=-65;cid=testClusterID;nsid=1847453481;c=1606979973945;bpid=BP-1018250855-172.17.0.10-1606979973945 and force: true
2020-12-03 07:19:34,126 [IPC Server handler 2 on default port 38894] INFO  common.Storage (Storage.java:analyzeStorage(674)) - /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1 does not exist. Creating ...
2020-12-03 07:19:34,166 [IPC Server handler 1 on default port 36507] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/in_use.lock acquired by nodename 330@f22db9385ba9
2020-12-03 07:19:34,166 [IPC Server handler 1 on default port 32907] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1/in_use.lock acquired by nodename 330@f22db9385ba9
2020-12-03 07:19:34,166 [IPC Server handler 2 on default port 38894] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1/in_use.lock acquired by nodename 330@f22db9385ba9
2020-12-03 07:19:34,167 [IPC Server handler 2 on default port 38894] INFO  common.Storage (JNStorage.java:format(225)) - Formatting journal Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1; location= null with nsid: 1847453481
2020-12-03 07:19:34,167 [IPC Server handler 1 on default port 36507] INFO  common.Storage (JNStorage.java:format(225)) - Formatting journal Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1; location= null with nsid: 1847453481
2020-12-03 07:19:34,167 [IPC Server handler 1 on default port 32907] INFO  common.Storage (JNStorage.java:format(225)) - Formatting journal Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1; location= null with nsid: 1847453481
2020-12-03 07:19:34,201 [IPC Server handler 1 on default port 32907] INFO  common.Storage (JNStorage.java:getOrCreatePaxosDir(162)) - Creating paxos dir: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1/current/paxos
2020-12-03 07:19:34,201 [IPC Server handler 1 on default port 36507] INFO  common.Storage (JNStorage.java:getOrCreatePaxosDir(162)) - Creating paxos dir: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/current/paxos
2020-12-03 07:19:34,201 [IPC Server handler 2 on default port 38894] INFO  common.Storage (JNStorage.java:getOrCreatePaxosDir(162)) - Creating paxos dir: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1/current/paxos
2020-12-03 07:19:34,259 [IPC Server handler 2 on default port 38894] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1/in_use.lock acquired by nodename 330@f22db9385ba9
2020-12-03 07:19:34,259 [IPC Server handler 1 on default port 32907] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1/in_use.lock acquired by nodename 330@f22db9385ba9
2020-12-03 07:19:34,259 [IPC Server handler 1 on default port 36507] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/in_use.lock acquired by nodename 330@f22db9385ba9
2020-12-03 07:19:34,260 [IPC Server handler 2 on default port 38894] INFO  server.Journal (JournaledEditsCache.java:<init>(132)) - Enabling the journaled edits cache with a capacity of bytes: 1048576
2020-12-03 07:19:34,260 [IPC Server handler 1 on default port 36507] INFO  server.Journal (JournaledEditsCache.java:<init>(132)) - Enabling the journaled edits cache with a capacity of bytes: 1048576
2020-12-03 07:19:34,260 [IPC Server handler 1 on default port 32907] INFO  server.Journal (JournaledEditsCache.java:<init>(132)) - Enabling the journaled edits cache with a capacity of bytes: 1048576
2020-12-03 07:19:34,294 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:19:34,294 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:19:34,425 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:19:34,426 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:19:34,477 [Listener at localhost/32907] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-12-03 07:19:34,561 [Listener at localhost/32907] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:copyNameDirs(1264)) - Copying namedir from primary node dir file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 to file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-3
2020-12-03 07:19:34,593 [Listener at localhost/32907] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:copyNameDirs(1264)) - Copying namedir from primary node dir file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 to file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-4
2020-12-03 07:19:34,607 [Listener at localhost/32907] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:copyNameDirs(1264)) - Copying namedir from primary node dir file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-3 to file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-5
2020-12-03 07:19:34,613 [Listener at localhost/32907] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:copyNameDirs(1264)) - Copying namedir from primary node dir file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-3 to file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-6
2020-12-03 07:19:34,622 [Listener at localhost/32907] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:19:34,632 [Listener at localhost/32907] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-12-03 07:19:34,636 [Listener at localhost/32907] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://ns1
2020-12-03 07:19:34,637 [Listener at localhost/32907] INFO  namenode.NameNode (NameNode.java:<init>(944)) - Clients should use ns1 to access this namenode/service.
2020-12-03 07:19:34,678 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3fb6cf60] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:19:34,688 [Listener at localhost/32907] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:10353
2020-12-03 07:19:34,689 [Listener at localhost/32907] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:34,691 [Listener at localhost/32907] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:19:34,692 [Listener at localhost/32907] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:19:34,692 [Listener at localhost/32907] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:34,695 [Listener at localhost/32907] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:19:34,697 [Listener at localhost/32907] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:19:34,697 [Listener at localhost/32907] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:19:34,697 [Listener at localhost/32907] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:19:34,708 [Listener at localhost/32907] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:19:34,709 [Listener at localhost/32907] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:19:34,716 [Listener at localhost/32907] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 10353
2020-12-03 07:19:34,716 [Listener at localhost/32907] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:19:34,720 [Listener at localhost/32907] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@aafcffa{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:19:34,720 [Listener at localhost/32907] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@235a0c16{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:19:34,736 [Listener at localhost/32907] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@696f0212{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:19:34,738 [Listener at localhost/32907] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@5733f295{HTTP/1.1,[http/1.1]}{localhost:10353}
2020-12-03 07:19:34,738 [Listener at localhost/32907] INFO  server.Server (Server.java:doStart(419)) - Started @4639ms
2020-12-03 07:19:34,821 [Listener at localhost/32907] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:19:34,822 [Listener at localhost/32907] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:19:34,822 [Listener at localhost/32907] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:19:34,822 [Listener at localhost/32907] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:19:34,823 [Listener at localhost/32907] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:19:34,823 [Listener at localhost/32907] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:19:34,823 [Listener at localhost/32907] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:19:34,824 [Listener at localhost/32907] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns1
2020-12-03 07:19:34,824 [Listener at localhost/32907] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: true
2020-12-03 07:19:34,826 [Listener at localhost/32907] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:34,826 [Listener at localhost/32907] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:19:34,828 [Listener at localhost/32907] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:19:34,828 [Listener at localhost/32907] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:19:34,829 [Listener at localhost/32907] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:19:34
2020-12-03 07:19:34,829 [Listener at localhost/32907] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:19:34,829 [Listener at localhost/32907] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:19:34,830 [Listener at localhost/32907] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:19:34,830 [Listener at localhost/32907] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:19:34,843 [Listener at localhost/32907] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:19:34,843 [Listener at localhost/32907] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:19:34,843 [Listener at localhost/32907] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:19:34,844 [Listener at localhost/32907] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:19:34,844 [Listener at localhost/32907] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:19:34,844 [Listener at localhost/32907] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:19:34,844 [Listener at localhost/32907] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 1
2020-12-03 07:19:34,844 [Listener at localhost/32907] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:19:34,845 [Listener at localhost/32907] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:19:34,845 [Listener at localhost/32907] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:19:34,845 [Listener at localhost/32907] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:19:34,845 [Listener at localhost/32907] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:19:34,845 [Listener at localhost/32907] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:19:34,846 [Listener at localhost/32907] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:19:34,846 [Listener at localhost/32907] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:19:34,846 [Listener at localhost/32907] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:19:34,847 [Listener at localhost/32907] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:19:34,853 [Listener at localhost/32907] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:19:34,853 [Listener at localhost/32907] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:19:34,853 [Listener at localhost/32907] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:19:34,854 [Listener at localhost/32907] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:19:34,854 [Listener at localhost/32907] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:19:34,854 [Listener at localhost/32907] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:19:34,855 [Listener at localhost/32907] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:19:34,856 [Listener at localhost/32907] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:19:34,857 [Listener at localhost/32907] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:19:34,857 [Listener at localhost/32907] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:19:34,860 [Listener at localhost/32907] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:19:34,860 [Listener at localhost/32907] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:19:34,860 [Listener at localhost/32907] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:19:34,861 [Listener at localhost/32907] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:19:34,861 [Listener at localhost/32907] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:19:34,861 [Listener at localhost/32907] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:19:34,861 [Listener at localhost/32907] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:19:34,862 [Listener at localhost/32907] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:19:34,862 [Listener at localhost/32907] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:19:34,905 [Listener at localhost/32907] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 330@f22db9385ba9
2020-12-03 07:19:34,931 [Listener at localhost/32907] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 330@f22db9385ba9
2020-12-03 07:19:34,946 [Listener at localhost/32907] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:19:34,947 [Listener at localhost/32907] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:19:34,982 [Listener at localhost/32907] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:19:34,990 [Listener at localhost/32907] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:19:34,990 [Listener at localhost/32907] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-12-03 07:19:34,995 [Listener at localhost/32907] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2020-12-03 07:19:34,996 [Listener at localhost/32907] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:19:34,996 [Listener at localhost/32907] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 132 msecs
2020-12-03 07:19:35,526 [Listener at localhost/32907] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:10352
2020-12-03 07:19:35,586 [Listener at localhost/32907] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:19:35,596 [Socket Reader #1 for port 10352] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 10352
2020-12-03 07:19:35,627 [Listener at localhost/10352] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:19:35,647 [Listener at localhost/10352] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:19:35,661 [Listener at localhost/10352] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:19:35,662 [Listener at localhost/10352] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:19:35,662 [Listener at localhost/10352] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:19:35,697 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:19:35,697 [IPC Server listener on 10352] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 10352: starting
2020-12-03 07:19:35,700 [Listener at localhost/10352] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:10352
2020-12-03 07:19:35,706 [Listener at localhost/10352] INFO  namenode.FSNamesystem (FSNamesystem.java:startStandbyServices(1391)) - Starting services required for standby state
2020-12-03 07:19:35,714 [Listener at localhost/10352] INFO  ha.EditLogTailer (EditLogTailer.java:<init>(205)) - Will roll logs on active node every 120 seconds.
2020-12-03 07:19:35,714 [Listener at localhost/10352] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.period.backoff-max(0) assuming SECONDS
2020-12-03 07:19:35,715 [Listener at localhost/10352] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.rolledits.timeout(60) assuming SECONDS
2020-12-03 07:19:35,724 [Listener at localhost/10352] INFO  ha.StandbyCheckpointer (StandbyCheckpointer.java:start(139)) - Starting standby checkpoint thread...
Checkpointing active NN to possible NNs: [http://127.0.0.1:10355, http://127.0.0.1:10357]
Serving checkpoints at http://localhost:10353
2020-12-03 07:19:35,726 [Listener at localhost/10352] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:19:35,726 [Listener at localhost/10352] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-12-03 07:19:35,727 [Listener at localhost/10352] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://ns1
2020-12-03 07:19:35,727 [Listener at localhost/10352] INFO  namenode.NameNode (NameNode.java:<init>(944)) - Clients should use ns1 to access this namenode/service.
2020-12-03 07:19:35,755 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@841e575] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:19:35,756 [Listener at localhost/10352] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:10355
2020-12-03 07:19:35,757 [Listener at localhost/10352] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:35,759 [Listener at localhost/10352] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:19:35,764 [Listener at localhost/10352] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:19:35,765 [Listener at localhost/10352] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:35,768 [Listener at localhost/10352] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:19:35,770 [Listener at localhost/10352] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:19:35,770 [Listener at localhost/10352] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:19:35,770 [Listener at localhost/10352] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:19:35,772 [Listener at localhost/10352] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:19:35,772 [Listener at localhost/10352] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:19:35,772 [Listener at localhost/10352] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 10355
2020-12-03 07:19:35,772 [Listener at localhost/10352] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:19:35,776 [Listener at localhost/10352] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1568159{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:19:35,777 [Listener at localhost/10352] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6f80fafe{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:19:35,784 [Listener at localhost/10352] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@591e58fa{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:19:35,785 [Listener at localhost/10352] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3954d008{HTTP/1.1,[http/1.1]}{localhost:10355}
2020-12-03 07:19:35,786 [Listener at localhost/10352] INFO  server.Server (Server.java:doStart(419)) - Started @5686ms
2020-12-03 07:19:35,791 [Listener at localhost/10352] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:19:35,791 [Listener at localhost/10352] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:19:35,791 [Listener at localhost/10352] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:19:35,792 [Listener at localhost/10352] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:19:35,792 [Listener at localhost/10352] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:19:35,792 [Listener at localhost/10352] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:19:35,792 [Listener at localhost/10352] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:19:35,792 [Listener at localhost/10352] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns1
2020-12-03 07:19:35,793 [Listener at localhost/10352] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: true
2020-12-03 07:19:35,793 [Listener at localhost/10352] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:35,793 [Listener at localhost/10352] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:19:35,794 [Listener at localhost/10352] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:19:35,794 [Listener at localhost/10352] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:19:35,794 [Listener at localhost/10352] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:19:35
2020-12-03 07:19:35,795 [Listener at localhost/10352] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:19:35,795 [Listener at localhost/10352] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:19:35,795 [Listener at localhost/10352] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:19:35,795 [Listener at localhost/10352] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:19:35,807 [Listener at localhost/10352] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:19:35,807 [Listener at localhost/10352] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:19:35,807 [Listener at localhost/10352] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:19:35,808 [Listener at localhost/10352] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:19:35,808 [Listener at localhost/10352] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:19:35,808 [Listener at localhost/10352] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:19:35,809 [Listener at localhost/10352] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 1
2020-12-03 07:19:35,811 [Listener at localhost/10352] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:19:35,811 [Listener at localhost/10352] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:19:35,811 [Listener at localhost/10352] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:19:35,811 [Listener at localhost/10352] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:19:35,815 [Listener at localhost/10352] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:19:35,816 [Listener at localhost/10352] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:19:35,816 [Listener at localhost/10352] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:19:35,817 [Listener at localhost/10352] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:19:35,817 [Listener at localhost/10352] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:19:35,817 [Listener at localhost/10352] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:19:35,822 [Listener at localhost/10352] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:19:35,822 [Listener at localhost/10352] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:19:35,822 [Listener at localhost/10352] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:19:35,822 [Listener at localhost/10352] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:19:35,823 [Listener at localhost/10352] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:19:35,823 [Listener at localhost/10352] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:19:35,823 [Listener at localhost/10352] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:19:35,823 [Listener at localhost/10352] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:19:35,824 [Listener at localhost/10352] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:19:35,824 [Listener at localhost/10352] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:19:35,825 [Listener at localhost/10352] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:19:35,825 [Listener at localhost/10352] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:19:35,825 [Listener at localhost/10352] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:19:35,825 [Listener at localhost/10352] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:19:35,826 [Listener at localhost/10352] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:19:35,826 [Listener at localhost/10352] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:19:35,826 [Listener at localhost/10352] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:19:35,826 [Listener at localhost/10352] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:19:35,827 [Listener at localhost/10352] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:19:35,863 [Listener at localhost/10352] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-3/in_use.lock acquired by nodename 330@f22db9385ba9
2020-12-03 07:19:35,923 [Listener at localhost/10352] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-4/in_use.lock acquired by nodename 330@f22db9385ba9
2020-12-03 07:19:35,944 [Listener at localhost/10352] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:19:35,944 [Listener at localhost/10352] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-3/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:19:35,947 [Listener at localhost/10352] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:19:35,948 [Listener at localhost/10352] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:19:35,949 [Listener at localhost/10352] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-3/current/fsimage_0000000000000000000
2020-12-03 07:19:35,950 [Listener at localhost/10352] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2020-12-03 07:19:35,950 [Listener at localhost/10352] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:19:35,950 [Listener at localhost/10352] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 123 msecs
2020-12-03 07:19:35,951 [Listener at localhost/10352] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:10354
2020-12-03 07:19:35,952 [Listener at localhost/10352] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:19:35,953 [Socket Reader #1 for port 10354] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 10354
2020-12-03 07:19:35,964 [Listener at localhost/10354] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:19:35,980 [Listener at localhost/10354] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:19:35,982 [Listener at localhost/10354] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:19:35,982 [Listener at localhost/10354] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:19:35,982 [Listener at localhost/10354] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:19:35,987 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:19:35,987 [IPC Server listener on 10354] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 10354: starting
2020-12-03 07:19:35,994 [Listener at localhost/10354] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:10354
2020-12-03 07:19:35,994 [Listener at localhost/10354] INFO  namenode.FSNamesystem (FSNamesystem.java:startStandbyServices(1391)) - Starting services required for standby state
2020-12-03 07:19:36,004 [Listener at localhost/10354] INFO  ha.EditLogTailer (EditLogTailer.java:<init>(205)) - Will roll logs on active node every 120 seconds.
2020-12-03 07:19:36,004 [Listener at localhost/10354] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.period.backoff-max(0) assuming SECONDS
2020-12-03 07:19:36,004 [Listener at localhost/10354] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.rolledits.timeout(60) assuming SECONDS
2020-12-03 07:19:36,007 [Listener at localhost/10354] INFO  ha.StandbyCheckpointer (StandbyCheckpointer.java:start(139)) - Starting standby checkpoint thread...
Checkpointing active NN to possible NNs: [http://localhost:10353, http://127.0.0.1:10357]
Serving checkpoints at http://localhost:10355
2020-12-03 07:19:36,014 [Listener at localhost/10354] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:19:36,014 [Listener at localhost/10354] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-12-03 07:19:36,015 [Listener at localhost/10354] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://ns1
2020-12-03 07:19:36,015 [Listener at localhost/10354] INFO  namenode.NameNode (NameNode.java:<init>(944)) - Clients should use ns1 to access this namenode/service.
2020-12-03 07:19:36,025 [Listener at localhost/10354] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:10357
2020-12-03 07:19:36,027 [Listener at localhost/10354] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:36,033 [Listener at localhost/10354] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:19:36,032 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5db4c359] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:19:36,036 [Listener at localhost/10354] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:19:36,038 [Listener at localhost/10354] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:36,040 [Listener at localhost/10354] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:19:36,041 [Listener at localhost/10354] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:19:36,041 [Listener at localhost/10354] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:19:36,042 [Listener at localhost/10354] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:19:36,057 [Listener at localhost/10354] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:19:36,057 [Listener at localhost/10354] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:19:36,058 [Listener at localhost/10354] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 10357
2020-12-03 07:19:36,059 [Listener at localhost/10354] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:19:36,073 [Listener at localhost/10354] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4f8969b0{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:19:36,074 [Listener at localhost/10354] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@192f2f27{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:19:36,080 [Listener at localhost/10354] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@b91d8c4{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:19:36,081 [Listener at localhost/10354] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4b6166aa{HTTP/1.1,[http/1.1]}{localhost:10357}
2020-12-03 07:19:36,082 [Listener at localhost/10354] INFO  server.Server (Server.java:doStart(419)) - Started @5982ms
2020-12-03 07:19:36,085 [Listener at localhost/10354] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:19:36,085 [Listener at localhost/10354] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:19:36,085 [Listener at localhost/10354] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:19:36,086 [Listener at localhost/10354] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:19:36,086 [Listener at localhost/10354] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:19:36,086 [Listener at localhost/10354] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:19:36,086 [Listener at localhost/10354] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:19:36,086 [Listener at localhost/10354] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns1
2020-12-03 07:19:36,087 [Listener at localhost/10354] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: true
2020-12-03 07:19:36,087 [Listener at localhost/10354] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:36,088 [Listener at localhost/10354] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:19:36,088 [Listener at localhost/10354] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:19:36,088 [Listener at localhost/10354] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:19:36,089 [Listener at localhost/10354] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:19:36
2020-12-03 07:19:36,089 [Listener at localhost/10354] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:19:36,089 [Listener at localhost/10354] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:19:36,089 [Listener at localhost/10354] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:19:36,089 [Listener at localhost/10354] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:19:36,095 [Listener at localhost/10354] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:19:36,095 [Listener at localhost/10354] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:19:36,096 [Listener at localhost/10354] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:19:36,096 [Listener at localhost/10354] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:19:36,096 [Listener at localhost/10354] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:19:36,097 [Listener at localhost/10354] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:19:36,097 [Listener at localhost/10354] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 1
2020-12-03 07:19:36,097 [Listener at localhost/10354] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:19:36,097 [Listener at localhost/10354] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:19:36,097 [Listener at localhost/10354] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:19:36,098 [Listener at localhost/10354] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:19:36,098 [Listener at localhost/10354] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:19:36,098 [Listener at localhost/10354] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:19:36,099 [Listener at localhost/10354] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:19:36,099 [Listener at localhost/10354] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:19:36,099 [Listener at localhost/10354] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:19:36,100 [Listener at localhost/10354] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:19:36,104 [Listener at localhost/10354] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:19:36,104 [Listener at localhost/10354] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:19:36,104 [Listener at localhost/10354] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:19:36,108 [Listener at localhost/10354] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:19:36,108 [Listener at localhost/10354] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:19:36,108 [Listener at localhost/10354] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:19:36,109 [Listener at localhost/10354] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:19:36,109 [Listener at localhost/10354] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:19:36,109 [Listener at localhost/10354] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:19:36,110 [Listener at localhost/10354] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:19:36,119 [Listener at localhost/10354] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:19:36,120 [Listener at localhost/10354] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:19:36,120 [Listener at localhost/10354] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:19:36,120 [Listener at localhost/10354] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:19:36,120 [Listener at localhost/10354] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:19:36,120 [Listener at localhost/10354] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:19:36,120 [Listener at localhost/10354] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:19:36,121 [Listener at localhost/10354] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:19:36,121 [Listener at localhost/10354] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:19:36,183 [Listener at localhost/10354] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-5/in_use.lock acquired by nodename 330@f22db9385ba9
2020-12-03 07:19:36,225 [Listener at localhost/10354] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-6/in_use.lock acquired by nodename 330@f22db9385ba9
2020-12-03 07:19:36,239 [Listener at localhost/10354] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:19:36,240 [Listener at localhost/10354] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-5/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:19:36,243 [Listener at localhost/10354] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:19:36,244 [Listener at localhost/10354] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:19:36,244 [Listener at localhost/10354] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-5/current/fsimage_0000000000000000000
2020-12-03 07:19:36,244 [Listener at localhost/10354] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2020-12-03 07:19:36,245 [Listener at localhost/10354] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:19:36,245 [Listener at localhost/10354] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 122 msecs
2020-12-03 07:19:36,245 [Listener at localhost/10354] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:10356
2020-12-03 07:19:36,246 [Listener at localhost/10354] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:19:36,247 [Socket Reader #1 for port 10356] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 10356
2020-12-03 07:19:36,256 [Listener at localhost/10356] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:19:36,270 [Listener at localhost/10356] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:19:36,271 [Listener at localhost/10356] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:19:36,271 [Listener at localhost/10356] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:19:36,272 [Listener at localhost/10356] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:19:36,288 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:19:36,288 [IPC Server listener on 10356] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 10356: starting
2020-12-03 07:19:36,295 [Listener at localhost/10356] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:10356
2020-12-03 07:19:36,295 [Listener at localhost/10356] INFO  namenode.FSNamesystem (FSNamesystem.java:startStandbyServices(1391)) - Starting services required for standby state
2020-12-03 07:19:36,305 [Listener at localhost/10356] INFO  ha.EditLogTailer (EditLogTailer.java:<init>(205)) - Will roll logs on active node every 120 seconds.
2020-12-03 07:19:36,306 [Listener at localhost/10356] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.period.backoff-max(0) assuming SECONDS
2020-12-03 07:19:36,306 [Listener at localhost/10356] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.rolledits.timeout(60) assuming SECONDS
2020-12-03 07:19:36,308 [Listener at localhost/10356] INFO  ha.StandbyCheckpointer (StandbyCheckpointer.java:start(139)) - Starting standby checkpoint thread...
Checkpointing active NN to possible NNs: [http://localhost:10353, http://localhost:10355]
Serving checkpoints at http://localhost:10357
2020-12-03 07:19:36,318 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:19:36,335 [Listener at localhost/10356] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:19:36,338 [Listener at localhost/10356] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:19:36,343 [Listener at localhost/10356] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:19:36,348 [Listener at localhost/10356] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:36,351 [Listener at localhost/10356] INFO  datanode.BlockScanner (BlockScanner.java:<init>(187)) - Disabled block scanner.
2020-12-03 07:19:36,355 [Listener at localhost/10356] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:19:36,356 [Listener at localhost/10356] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:36,361 [Listener at localhost/10356] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:19:36,370 [Listener at localhost/10356] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:38920
2020-12-03 07:19:36,373 [Listener at localhost/10356] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:19:36,373 [Listener at localhost/10356] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:19:36,393 [Listener at localhost/10356] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:36,395 [Listener at localhost/10356] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:19:36,396 [Listener at localhost/10356] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:19:36,396 [Listener at localhost/10356] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:36,399 [Listener at localhost/10356] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:19:36,399 [Listener at localhost/10356] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:19:36,400 [Listener at localhost/10356] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:19:36,401 [Listener at localhost/10356] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:19:36,403 [Listener at localhost/10356] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 46184
2020-12-03 07:19:36,404 [Listener at localhost/10356] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:19:36,406 [Listener at localhost/10356] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@e6516e{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:19:36,406 [Listener at localhost/10356] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@43ed0ff3{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:19:36,418 [Listener at localhost/10356] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@56db847e{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:19:36,420 [Listener at localhost/10356] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@740abb5{HTTP/1.1,[http/1.1]}{localhost:46184}
2020-12-03 07:19:36,420 [Listener at localhost/10356] INFO  server.Server (Server.java:doStart(419)) - Started @6321ms
2020-12-03 07:19:36,673 [Listener at localhost/10356] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:33835
2020-12-03 07:19:36,674 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@271f18d3] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:19:36,676 [Listener at localhost/10356] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:19:36,676 [Listener at localhost/10356] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:19:36,710 [Listener at localhost/10356] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:19:36,712 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:19:36,722 [Listener at localhost/44842] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:44842
2020-12-03 07:19:36,742 [Listener at localhost/44842] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns1
2020-12-03 07:19:36,745 [Listener at localhost/44842] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns1
2020-12-03 07:19:36,758 [Thread-187] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:10354 starting to offer service
2020-12-03 07:19:36,759 [Thread-188] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:10356 starting to offer service
2020-12-03 07:19:36,758 [Thread-186] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:10352 starting to offer service
2020-12-03 07:19:36,773 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:19:36,773 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:19:36,850 [Thread-187] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:19:36,912 [Thread-187] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 330@f22db9385ba9
2020-12-03 07:19:36,913 [Thread-187] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 1847453481. Formatting...
2020-12-03 07:19:36,915 [Thread-187] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-9cbebd93-291f-4507-adc6-5363d3f38b7d for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-12-03 07:19:37,048 [Thread-187] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 330@f22db9385ba9
2020-12-03 07:19:37,048 [Thread-187] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 1847453481. Formatting...
2020-12-03 07:19:37,049 [Thread-187] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-4e6b2f57-f556-4639-a9d7-8a7eb3280367 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-12-03 07:19:37,174 [Thread-187] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1018250855-172.17.0.10-1606979973945
2020-12-03 07:19:37,174 [Thread-187] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1018250855-172.17.0.10-1606979973945
2020-12-03 07:19:37,176 [Thread-187] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-1018250855-172.17.0.10-1606979973945 is not formatted. Formatting ...
2020-12-03 07:19:37,176 [Thread-187] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1018250855-172.17.0.10-1606979973945 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1018250855-172.17.0.10-1606979973945/current
2020-12-03 07:19:37,295 [Thread-187] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1018250855-172.17.0.10-1606979973945
2020-12-03 07:19:37,296 [Thread-187] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1018250855-172.17.0.10-1606979973945
2020-12-03 07:19:37,296 [Thread-187] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-1018250855-172.17.0.10-1606979973945 is not formatted. Formatting ...
2020-12-03 07:19:37,297 [Thread-187] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1018250855-172.17.0.10-1606979973945 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1018250855-172.17.0.10-1606979973945/current
2020-12-03 07:19:37,305 [IPC Server handler 1 on default port 10352] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:37,316 [Listener at localhost/44842] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:37,316 [Listener at localhost/44842] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:37,412 [Thread-187] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1847453481;bpid=BP-1018250855-172.17.0.10-1606979973945;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1847453481;c=1606979973945;bpid=BP-1018250855-172.17.0.10-1606979973945;dnuuid=null
2020-12-03 07:19:37,419 [IPC Server handler 3 on default port 10352] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:37,420 [Listener at localhost/44842] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:37,420 [Listener at localhost/44842] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:37,521 [IPC Server handler 2 on default port 10352] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:37,522 [Listener at localhost/44842] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:37,522 [Listener at localhost/44842] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:37,565 [Thread-187] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID ffc0a714-d6ed-4515-b5ec-f51ece94380e
2020-12-03 07:19:37,624 [IPC Server handler 5 on default port 10352] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:37,624 [Listener at localhost/44842] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:37,625 [Listener at localhost/44842] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:37,707 [Thread-187] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-9cbebd93-291f-4507-adc6-5363d3f38b7d
2020-12-03 07:19:37,708 [Thread-187] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-12-03 07:19:37,710 [Thread-187] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-4e6b2f57-f556-4639-a9d7-8a7eb3280367
2020-12-03 07:19:37,710 [Thread-187] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-12-03 07:19:37,716 [Thread-187] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:19:37,723 [Thread-187] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:19:37,728 [IPC Server handler 0 on default port 10352] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:37,729 [Listener at localhost/44842] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:37,729 [Listener at localhost/44842] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:37,733 [Thread-187] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:19:37,734 [Thread-187] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:19:37,734 [Thread-187] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:19:37,736 [Thread-187] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1018250855-172.17.0.10-1606979973945
2020-12-03 07:19:37,737 [Thread-206] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1018250855-172.17.0.10-1606979973945 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:19:37,737 [Thread-207] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1018250855-172.17.0.10-1606979973945 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:19:37,774 [Thread-207] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1018250855-172.17.0.10-1606979973945 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 36ms
2020-12-03 07:19:37,780 [Thread-206] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1018250855-172.17.0.10-1606979973945 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 42ms
2020-12-03 07:19:37,783 [Thread-187] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1018250855-172.17.0.10-1606979973945: 48ms
2020-12-03 07:19:37,786 [Thread-210] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1018250855-172.17.0.10-1606979973945 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:19:37,786 [Thread-211] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1018250855-172.17.0.10-1606979973945 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:19:37,786 [Thread-210] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1018250855-172.17.0.10-1606979973945/current/replicas doesn't exist 
2020-12-03 07:19:37,786 [Thread-211] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1018250855-172.17.0.10-1606979973945/current/replicas doesn't exist 
2020-12-03 07:19:37,789 [Thread-211] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1018250855-172.17.0.10-1606979973945 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 3ms
2020-12-03 07:19:37,791 [Thread-210] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1018250855-172.17.0.10-1606979973945 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 5ms
2020-12-03 07:19:37,793 [Thread-187] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1018250855-172.17.0.10-1606979973945: 8ms
2020-12-03 07:19:37,819 [Thread-187] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:19 AM with interval of 21600000ms
2020-12-03 07:19:37,834 [IPC Server handler 1 on default port 10352] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:37,835 [BP-1018250855-172.17.0.10-1606979973945 heartbeating to localhost/127.0.0.1:10354] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1018250855-172.17.0.10-1606979973945 (Datanode Uuid ffc0a714-d6ed-4515-b5ec-f51ece94380e) service to localhost/127.0.0.1:10354 beginning handshake with NN
2020-12-03 07:19:37,835 [BP-1018250855-172.17.0.10-1606979973945 heartbeating to localhost/127.0.0.1:10356] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1018250855-172.17.0.10-1606979973945 (Datanode Uuid ffc0a714-d6ed-4515-b5ec-f51ece94380e) service to localhost/127.0.0.1:10356 beginning handshake with NN
2020-12-03 07:19:37,835 [BP-1018250855-172.17.0.10-1606979973945 heartbeating to localhost/127.0.0.1:10352] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1018250855-172.17.0.10-1606979973945 (Datanode Uuid ffc0a714-d6ed-4515-b5ec-f51ece94380e) service to localhost/127.0.0.1:10352 beginning handshake with NN
2020-12-03 07:19:37,835 [Listener at localhost/44842] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:37,836 [Listener at localhost/44842] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:37,853 [IPC Server handler 3 on default port 10352] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:38920, datanodeUuid=ffc0a714-d6ed-4515-b5ec-f51ece94380e, infoPort=33835, infoSecurePort=0, ipcPort=44842, storageInfo=lv=-57;cid=testClusterID;nsid=1847453481;c=1606979973945) storage ffc0a714-d6ed-4515-b5ec-f51ece94380e
2020-12-03 07:19:37,856 [IPC Server handler 3 on default port 10352] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38920
2020-12-03 07:19:37,856 [IPC Server handler 3 on default port 10352] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN ffc0a714-d6ed-4515-b5ec-f51ece94380e (127.0.0.1:38920).
2020-12-03 07:19:37,859 [IPC Server handler 1 on default port 10356] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:38920, datanodeUuid=ffc0a714-d6ed-4515-b5ec-f51ece94380e, infoPort=33835, infoSecurePort=0, ipcPort=44842, storageInfo=lv=-57;cid=testClusterID;nsid=1847453481;c=1606979973945) storage ffc0a714-d6ed-4515-b5ec-f51ece94380e
2020-12-03 07:19:37,859 [IPC Server handler 2 on default port 10354] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:38920, datanodeUuid=ffc0a714-d6ed-4515-b5ec-f51ece94380e, infoPort=33835, infoSecurePort=0, ipcPort=44842, storageInfo=lv=-57;cid=testClusterID;nsid=1847453481;c=1606979973945) storage ffc0a714-d6ed-4515-b5ec-f51ece94380e
2020-12-03 07:19:37,860 [IPC Server handler 1 on default port 10356] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38920
2020-12-03 07:19:37,860 [IPC Server handler 1 on default port 10356] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN ffc0a714-d6ed-4515-b5ec-f51ece94380e (127.0.0.1:38920).
2020-12-03 07:19:37,861 [IPC Server handler 2 on default port 10354] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38920
2020-12-03 07:19:37,861 [IPC Server handler 2 on default port 10354] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN ffc0a714-d6ed-4515-b5ec-f51ece94380e (127.0.0.1:38920).
2020-12-03 07:19:37,885 [BP-1018250855-172.17.0.10-1606979973945 heartbeating to localhost/127.0.0.1:10352] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1018250855-172.17.0.10-1606979973945 (Datanode Uuid ffc0a714-d6ed-4515-b5ec-f51ece94380e) service to localhost/127.0.0.1:10352 successfully registered with NN
2020-12-03 07:19:37,885 [BP-1018250855-172.17.0.10-1606979973945 heartbeating to localhost/127.0.0.1:10352] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:10352 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:19:37,889 [BP-1018250855-172.17.0.10-1606979973945 heartbeating to localhost/127.0.0.1:10356] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1018250855-172.17.0.10-1606979973945 (Datanode Uuid ffc0a714-d6ed-4515-b5ec-f51ece94380e) service to localhost/127.0.0.1:10356 successfully registered with NN
2020-12-03 07:19:37,889 [BP-1018250855-172.17.0.10-1606979973945 heartbeating to localhost/127.0.0.1:10356] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:10356 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:19:37,896 [BP-1018250855-172.17.0.10-1606979973945 heartbeating to localhost/127.0.0.1:10354] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1018250855-172.17.0.10-1606979973945 (Datanode Uuid ffc0a714-d6ed-4515-b5ec-f51ece94380e) service to localhost/127.0.0.1:10354 successfully registered with NN
2020-12-03 07:19:37,896 [BP-1018250855-172.17.0.10-1606979973945 heartbeating to localhost/127.0.0.1:10354] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:10354 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:19:37,920 [IPC Server handler 5 on default port 10354] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-9cbebd93-291f-4507-adc6-5363d3f38b7d for DN 127.0.0.1:38920
2020-12-03 07:19:37,921 [IPC Server handler 5 on default port 10354] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-4e6b2f57-f556-4639-a9d7-8a7eb3280367 for DN 127.0.0.1:38920
2020-12-03 07:19:37,923 [IPC Server handler 2 on default port 10352] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-9cbebd93-291f-4507-adc6-5363d3f38b7d for DN 127.0.0.1:38920
2020-12-03 07:19:37,928 [IPC Server handler 2 on default port 10352] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-4e6b2f57-f556-4639-a9d7-8a7eb3280367 for DN 127.0.0.1:38920
2020-12-03 07:19:37,923 [IPC Server handler 2 on default port 10356] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-9cbebd93-291f-4507-adc6-5363d3f38b7d for DN 127.0.0.1:38920
2020-12-03 07:19:37,929 [IPC Server handler 2 on default port 10356] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-4e6b2f57-f556-4639-a9d7-8a7eb3280367 for DN 127.0.0.1:38920
2020-12-03 07:19:37,943 [IPC Server handler 5 on default port 10352] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:37,971 [IPC Server handler 3 on default port 10354] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:37,982 [IPC Server handler 3 on default port 10356] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:37,984 [Listener at localhost/44842] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:19:37,992 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x8937cfd2788d7973: Processing first storage report for DS-9cbebd93-291f-4507-adc6-5363d3f38b7d from datanode ffc0a714-d6ed-4515-b5ec-f51ece94380e
2020-12-03 07:19:38,003 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x8937cfd2788d7973: from storage DS-9cbebd93-291f-4507-adc6-5363d3f38b7d node DatanodeRegistration(127.0.0.1:38920, datanodeUuid=ffc0a714-d6ed-4515-b5ec-f51ece94380e, infoPort=33835, infoSecurePort=0, ipcPort=44842, storageInfo=lv=-57;cid=testClusterID;nsid=1847453481;c=1606979973945), blocks: 0, hasStaleStorage: true, processing time: 4 msecs, invalidatedBlocks: 0
2020-12-03 07:19:38,004 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x5ff3f5c88d26abd6: Processing first storage report for DS-9cbebd93-291f-4507-adc6-5363d3f38b7d from datanode ffc0a714-d6ed-4515-b5ec-f51ece94380e
2020-12-03 07:19:38,004 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x8937cfd2788d7973: Processing first storage report for DS-4e6b2f57-f556-4639-a9d7-8a7eb3280367 from datanode ffc0a714-d6ed-4515-b5ec-f51ece94380e
2020-12-03 07:19:38,006 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x281ddea22e87923b: Processing first storage report for DS-9cbebd93-291f-4507-adc6-5363d3f38b7d from datanode ffc0a714-d6ed-4515-b5ec-f51ece94380e
2020-12-03 07:19:38,006 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x5ff3f5c88d26abd6: from storage DS-9cbebd93-291f-4507-adc6-5363d3f38b7d node DatanodeRegistration(127.0.0.1:38920, datanodeUuid=ffc0a714-d6ed-4515-b5ec-f51ece94380e, infoPort=33835, infoSecurePort=0, ipcPort=44842, storageInfo=lv=-57;cid=testClusterID;nsid=1847453481;c=1606979973945), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:19:38,007 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x281ddea22e87923b: from storage DS-9cbebd93-291f-4507-adc6-5363d3f38b7d node DatanodeRegistration(127.0.0.1:38920, datanodeUuid=ffc0a714-d6ed-4515-b5ec-f51ece94380e, infoPort=33835, infoSecurePort=0, ipcPort=44842, storageInfo=lv=-57;cid=testClusterID;nsid=1847453481;c=1606979973945), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:19:38,007 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x8937cfd2788d7973: from storage DS-4e6b2f57-f556-4639-a9d7-8a7eb3280367 node DatanodeRegistration(127.0.0.1:38920, datanodeUuid=ffc0a714-d6ed-4515-b5ec-f51ece94380e, infoPort=33835, infoSecurePort=0, ipcPort=44842, storageInfo=lv=-57;cid=testClusterID;nsid=1847453481;c=1606979973945), blocks: 0, hasStaleStorage: false, processing time: 3 msecs, invalidatedBlocks: 0
2020-12-03 07:19:38,007 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x281ddea22e87923b: Processing first storage report for DS-4e6b2f57-f556-4639-a9d7-8a7eb3280367 from datanode ffc0a714-d6ed-4515-b5ec-f51ece94380e
2020-12-03 07:19:38,007 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x5ff3f5c88d26abd6: Processing first storage report for DS-4e6b2f57-f556-4639-a9d7-8a7eb3280367 from datanode ffc0a714-d6ed-4515-b5ec-f51ece94380e
2020-12-03 07:19:38,007 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x281ddea22e87923b: from storage DS-4e6b2f57-f556-4639-a9d7-8a7eb3280367 node DatanodeRegistration(127.0.0.1:38920, datanodeUuid=ffc0a714-d6ed-4515-b5ec-f51ece94380e, infoPort=33835, infoSecurePort=0, ipcPort=44842, storageInfo=lv=-57;cid=testClusterID;nsid=1847453481;c=1606979973945), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:19:38,008 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x5ff3f5c88d26abd6: from storage DS-4e6b2f57-f556-4639-a9d7-8a7eb3280367 node DatanodeRegistration(127.0.0.1:38920, datanodeUuid=ffc0a714-d6ed-4515-b5ec-f51ece94380e, infoPort=33835, infoSecurePort=0, ipcPort=44842, storageInfo=lv=-57;cid=testClusterID;nsid=1847453481;c=1606979973945), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:19:38,008 [IPC Server handler 4 on default port 10352] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:38,011 [IPC Server handler 0 on default port 10354] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:38,018 [IPC Server handler 4 on default port 10356] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:38,021 [Listener at localhost/44842] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:19:38,021 [Listener at localhost/44842] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:19:38,021 [Listener at localhost/44842] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:19:38,023 [Edit log tailer] WARN  ha.EditLogTailer (EditLogTailer.java:doWork(528)) - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.sleep(EditLogTailer.java:433)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:526)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:440)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:457)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:484)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:453)
2020-12-03 07:19:38,028 [Listener at localhost/44842] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 10352
2020-12-03 07:19:38,039 [IPC Server listener on 10352] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 10352
2020-12-03 07:19:38,039 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:19:38,040 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:19:38,042 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:19:38,042 [BP-1018250855-172.17.0.10-1606979973945 heartbeating to localhost/127.0.0.1:10354] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x5ff3f5c88d26abd6,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 14 msec to generate and 72 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:19:38,042 [IPC Server handler 6 on default port 10352] WARN  ipc.Server (Server.java:processResponse(1670)) - IPC Server handler 6 on default port 10352, call Call#213 Retry#0 org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol.blockReport from 127.0.0.1:56142: output error
2020-12-03 07:19:38,042 [IPC Server handler 6 on default port 10352] INFO  ipc.Server (Server.java:run(2928)) - IPC Server handler 6 on default port 10352 caught an exception
java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.ensureWriteOpen(SocketChannelImpl.java:267)
	at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:458)
	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:3550)
	at org.apache.hadoop.ipc.Server.access$1700(Server.java:139)
	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:1620)
	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1690)
	at org.apache.hadoop.ipc.Server$Connection.sendResponse(Server.java:2785)
	at org.apache.hadoop.ipc.Server$Connection.access$300(Server.java:1762)
	at org.apache.hadoop.ipc.Server$RpcCall.doResponse(Server.java:1081)
	at org.apache.hadoop.ipc.Server$Call.doResponse(Server.java:873)
	at org.apache.hadoop.ipc.Server$Call.sendResponse(Server.java:859)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1016)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
2020-12-03 07:19:38,043 [BP-1018250855-172.17.0.10-1606979973945 heartbeating to localhost/127.0.0.1:10356] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x281ddea22e87923b,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 15 msec to generate and 71 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:19:38,047 [BP-1018250855-172.17.0.10-1606979973945 heartbeating to localhost/127.0.0.1:10352] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Unsuccessfully sent block report 0x8937cfd2788d7973,  containing 2 storage report(s), of which we sent 0. The reports had 0 total blocks and used 0 RPC(s). This took 15 msec to generate and 75 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:19:38,047 [BP-1018250855-172.17.0.10-1606979973945 heartbeating to localhost/127.0.0.1:10352] WARN  datanode.DataNode (BPServiceActor.java:offerService(731)) - IOException in offerService
java.io.EOFException: End of File Exception between local host is: "f22db9385ba9/172.17.0.10"; destination host is: "localhost":10352; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:791)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
	at com.sun.proxy.$Proxy28.blockReport(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.blockReport(DatanodeProtocolClientSideTranslatorPB.java:218)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.blockReport(BPServiceActor.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:701)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:849)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
2020-12-03 07:19:38,083 [Listener at localhost/44842] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:19:38,088 [Listener at localhost/44842] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:19:38,093 [Listener at localhost/44842] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@696f0212{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:19:38,100 [Listener at localhost/44842] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@5733f295{HTTP/1.1,[http/1.1]}{localhost:10353}
2020-12-03 07:19:38,101 [Listener at localhost/44842] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@235a0c16{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:19:38,102 [Listener at localhost/44842] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@aafcffa{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:19:38,109 [Listener at localhost/44842] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:19:38,110 [Listener at localhost/44842] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:19:38,111 [Edit log tailer] WARN  ha.EditLogTailer (EditLogTailer.java:doWork(528)) - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.sleep(EditLogTailer.java:433)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:526)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:440)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:457)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:484)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:453)
2020-12-03 07:19:38,114 [Listener at localhost/44842] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 10354
2020-12-03 07:19:38,119 [IPC Server listener on 10354] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 10354
2020-12-03 07:19:38,124 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:19:38,125 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:19:38,124 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:19:38,136 [Listener at localhost/44842] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:19:38,138 [Listener at localhost/44842] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:19:38,140 [Listener at localhost/44842] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@591e58fa{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:19:38,142 [Listener at localhost/44842] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@3954d008{HTTP/1.1,[http/1.1]}{localhost:10355}
2020-12-03 07:19:38,142 [Listener at localhost/44842] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6f80fafe{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:19:38,143 [Listener at localhost/44842] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1568159{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:19:38,149 [Listener at localhost/44842] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:19:38,149 [Listener at localhost/44842] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:19:38,149 [Edit log tailer] WARN  ha.EditLogTailer (EditLogTailer.java:doWork(528)) - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.sleep(EditLogTailer.java:433)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:526)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:440)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:457)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:484)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:453)
2020-12-03 07:19:38,150 [Listener at localhost/44842] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 10356
2020-12-03 07:19:38,151 [IPC Server listener on 10356] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 10356
2020-12-03 07:19:38,153 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:19:38,153 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:19:38,153 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:19:38,164 [Listener at localhost/44842] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:19:38,174 [Listener at localhost/44842] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:19:38,176 [Listener at localhost/44842] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@b91d8c4{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:19:38,179 [Listener at localhost/44842] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4b6166aa{HTTP/1.1,[http/1.1]}{localhost:10357}
2020-12-03 07:19:38,180 [Listener at localhost/44842] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@192f2f27{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:19:38,180 [Listener at localhost/44842] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4f8969b0{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:19:38,190 [Listener at localhost/44842] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:19:38,191 [Listener at localhost/44842] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:19:38,191 [Listener at localhost/44842] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:19:38,192 [Listener at localhost/44842] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:19:38,192 [Listener at localhost/44842] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:19:38,192 [Listener at localhost/44842] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:19:38,192 [Listener at localhost/44842] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:19:38,193 [Listener at localhost/44842] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns1
2020-12-03 07:19:38,195 [Listener at localhost/44842] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: true
2020-12-03 07:19:38,196 [Listener at localhost/44842] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:38,196 [Listener at localhost/44842] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:19:38,196 [Listener at localhost/44842] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:19:38,196 [Listener at localhost/44842] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:19:38,197 [Listener at localhost/44842] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:19:38
2020-12-03 07:19:38,197 [Listener at localhost/44842] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:19:38,197 [Listener at localhost/44842] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:19:38,197 [Listener at localhost/44842] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:19:38,198 [Listener at localhost/44842] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:19:38,213 [Listener at localhost/44842] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:19:38,214 [Listener at localhost/44842] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:19:38,214 [Listener at localhost/44842] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:19:38,214 [Listener at localhost/44842] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:19:38,214 [Listener at localhost/44842] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:19:38,215 [Listener at localhost/44842] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:19:38,215 [Listener at localhost/44842] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 1
2020-12-03 07:19:38,215 [Listener at localhost/44842] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:19:38,215 [Listener at localhost/44842] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:19:38,215 [Listener at localhost/44842] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:19:38,215 [Listener at localhost/44842] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:19:38,215 [Listener at localhost/44842] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:19:38,215 [Listener at localhost/44842] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:19:38,216 [Listener at localhost/44842] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:19:38,216 [Listener at localhost/44842] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:19:38,216 [Listener at localhost/44842] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:19:38,217 [Listener at localhost/44842] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:19:38,224 [Listener at localhost/44842] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:19:38,224 [Listener at localhost/44842] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:19:38,224 [Listener at localhost/44842] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:19:38,224 [Listener at localhost/44842] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:19:38,224 [Listener at localhost/44842] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:19:38,225 [Listener at localhost/44842] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:19:38,225 [Listener at localhost/44842] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:19:38,225 [Listener at localhost/44842] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:19:38,225 [Listener at localhost/44842] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:19:38,225 [Listener at localhost/44842] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:19:38,227 [Listener at localhost/44842] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:19:38,227 [Listener at localhost/44842] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:19:38,227 [Listener at localhost/44842] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:19:38,228 [Listener at localhost/44842] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:19:38,228 [Listener at localhost/44842] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:19:38,228 [Listener at localhost/44842] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:19:38,228 [Listener at localhost/44842] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:19:38,228 [Listener at localhost/44842] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:19:38,228 [Listener at localhost/44842] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:19:38,262 [Listener at localhost/44842] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 330@f22db9385ba9
2020-12-03 07:19:38,288 [Listener at localhost/44842] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 330@f22db9385ba9
2020-12-03 07:19:38,291 [Listener at localhost/44842] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:19:38,291 [Listener at localhost/44842] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:19:38,294 [Listener at localhost/44842] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:19:38,295 [Listener at localhost/44842] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:19:38,295 [Listener at localhost/44842] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-12-03 07:19:38,296 [Listener at localhost/44842] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2020-12-03 07:19:38,296 [Listener at localhost/44842] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:19:38,296 [Listener at localhost/44842] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 66 msecs
2020-12-03 07:19:38,297 [Listener at localhost/44842] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
Data exists in QJM to [127.0.0.1:38894, 127.0.0.1:36507, 127.0.0.1:32907]. Formatting anyway.
2020-12-03 07:19:38,320 [IPC Server handler 3 on default port 38894] INFO  server.Journal (Journal.java:format(256)) - Formatting journal id : ns1 with namespace info: lv=-65;cid=testClusterID;nsid=1847453481;c=1606979973945;bpid=BP-1018250855-172.17.0.10-1606979973945 and force: true
2020-12-03 07:19:38,321 [IPC Server handler 0 on default port 32907] INFO  server.Journal (Journal.java:format(256)) - Formatting journal id : ns1 with namespace info: lv=-65;cid=testClusterID;nsid=1847453481;c=1606979973945;bpid=BP-1018250855-172.17.0.10-1606979973945 and force: true
2020-12-03 07:19:38,321 [IPC Server handler 2 on default port 36507] INFO  server.Journal (Journal.java:format(256)) - Formatting journal id : ns1 with namespace info: lv=-65;cid=testClusterID;nsid=1847453481;c=1606979973945;bpid=BP-1018250855-172.17.0.10-1606979973945 and force: true
2020-12-03 07:19:38,380 [IPC Server handler 0 on default port 32907] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1/in_use.lock acquired by nodename 330@f22db9385ba9
2020-12-03 07:19:38,380 [IPC Server handler 2 on default port 36507] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/in_use.lock acquired by nodename 330@f22db9385ba9
2020-12-03 07:19:38,381 [IPC Server handler 0 on default port 32907] INFO  common.Storage (JNStorage.java:format(225)) - Formatting journal Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1; location= null with nsid: 1847453481
2020-12-03 07:19:38,381 [IPC Server handler 2 on default port 36507] INFO  common.Storage (JNStorage.java:format(225)) - Formatting journal Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1; location= null with nsid: 1847453481
2020-12-03 07:19:38,381 [IPC Server handler 3 on default port 38894] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1/in_use.lock acquired by nodename 330@f22db9385ba9
2020-12-03 07:19:38,381 [IPC Server handler 2 on default port 36507] INFO  common.Storage (Storage.java:clearDirectory(442)) - Will remove files: [/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/current/VERSION, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/current/paxos, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/current/committed-txid]
2020-12-03 07:19:38,381 [IPC Server handler 3 on default port 38894] INFO  common.Storage (JNStorage.java:format(225)) - Formatting journal Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1; location= null with nsid: 1847453481
2020-12-03 07:19:38,381 [IPC Server handler 0 on default port 32907] INFO  common.Storage (Storage.java:clearDirectory(442)) - Will remove files: [/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1/current/VERSION, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1/current/paxos, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1/current/committed-txid]
2020-12-03 07:19:38,382 [IPC Server handler 3 on default port 38894] INFO  common.Storage (Storage.java:clearDirectory(442)) - Will remove files: [/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1/current/VERSION, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1/current/paxos, /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1/current/committed-txid]
2020-12-03 07:19:38,449 [IPC Server handler 0 on default port 32907] INFO  common.Storage (JNStorage.java:getOrCreatePaxosDir(162)) - Creating paxos dir: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1/current/paxos
2020-12-03 07:19:38,449 [IPC Server handler 3 on default port 38894] INFO  common.Storage (JNStorage.java:getOrCreatePaxosDir(162)) - Creating paxos dir: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1/current/paxos
2020-12-03 07:19:38,449 [IPC Server handler 2 on default port 36507] INFO  common.Storage (JNStorage.java:getOrCreatePaxosDir(162)) - Creating paxos dir: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/current/paxos
2020-12-03 07:19:38,516 [IPC Server handler 3 on default port 38894] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1/in_use.lock acquired by nodename 330@f22db9385ba9
2020-12-03 07:19:38,516 [IPC Server handler 2 on default port 36507] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/in_use.lock acquired by nodename 330@f22db9385ba9
2020-12-03 07:19:38,516 [IPC Server handler 0 on default port 32907] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1/in_use.lock acquired by nodename 330@f22db9385ba9
2020-12-03 07:19:38,517 [IPC Server handler 3 on default port 38894] INFO  server.Journal (JournaledEditsCache.java:<init>(132)) - Enabling the journaled edits cache with a capacity of bytes: 1048576
2020-12-03 07:19:38,517 [IPC Server handler 2 on default port 36507] INFO  server.Journal (JournaledEditsCache.java:<init>(132)) - Enabling the journaled edits cache with a capacity of bytes: 1048576
2020-12-03 07:19:38,517 [IPC Server handler 0 on default port 32907] INFO  server.Journal (JournaledEditsCache.java:<init>(132)) - Enabling the journaled edits cache with a capacity of bytes: 1048576
2020-12-03 07:19:38,526 [Listener at localhost/44842] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-12-03 07:19:38,526 [Listener at localhost/44842] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-12-03 07:19:38,529 [Listener at localhost/44842] INFO  client.QuorumJournalManager (QuorumJournalManager.java:recoverUnfinalizedSegments(477)) - Starting recovery process for unclosed journal segments...
2020-12-03 07:19:38,544 [IPC Server handler 3 on default port 36507] INFO  server.Journal (Journal.java:updateLastPromisedEpoch(369)) - Updating lastPromisedEpoch from 0 to 1 for client /127.0.0.1 ; journal id: ns1
2020-12-03 07:19:38,544 [IPC Server handler 3 on default port 32907] INFO  server.Journal (Journal.java:updateLastPromisedEpoch(369)) - Updating lastPromisedEpoch from 0 to 1 for client /127.0.0.1 ; journal id: ns1
2020-12-03 07:19:38,546 [IPC Server handler 4 on default port 38894] INFO  server.Journal (Journal.java:updateLastPromisedEpoch(369)) - Updating lastPromisedEpoch from 0 to 1 for client /127.0.0.1 ; journal id: ns1
2020-12-03 07:19:38,589 [IPC Server handler 3 on default port 32907] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(227)) - Scanning storage FileJournalManager(root=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1)
2020-12-03 07:19:38,591 [IPC Server handler 3 on default port 32907] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(245)) - No files in FileJournalManager(root=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1)
2020-12-03 07:19:38,592 [IPC Server handler 3 on default port 36507] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(227)) - Scanning storage FileJournalManager(root=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1)
2020-12-03 07:19:38,592 [IPC Server handler 3 on default port 36507] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(245)) - No files in FileJournalManager(root=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1)
2020-12-03 07:19:38,595 [Listener at localhost/44842] INFO  client.QuorumJournalManager (QuorumJournalManager.java:recoverUnfinalizedSegments(479)) - Successfully started new epoch 1
2020-12-03 07:19:38,596 [Listener at localhost/44842] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:19:38,596 [Listener at localhost/44842] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-12-03 07:19:38,597 [Listener at localhost/44842] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://localhost:10352
2020-12-03 07:19:38,597 [Listener at localhost/44842] INFO  namenode.NameNode (NameNode.java:<init>(944)) - Clients should use ns1 to access this namenode/service.
2020-12-03 07:19:38,603 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@878537d] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:19:38,603 [Listener at localhost/44842] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:10353
2020-12-03 07:19:38,604 [Listener at localhost/44842] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:38,607 [Listener at localhost/44842] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:19:38,608 [Listener at localhost/44842] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:19:38,608 [Listener at localhost/44842] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:38,611 [Listener at localhost/44842] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:19:38,612 [Listener at localhost/44842] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:19:38,616 [IPC Server handler 4 on default port 38894] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(227)) - Scanning storage FileJournalManager(root=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1)
2020-12-03 07:19:38,620 [Listener at localhost/44842] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:19:38,620 [IPC Server handler 4 on default port 38894] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(245)) - No files in FileJournalManager(root=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1)
2020-12-03 07:19:38,620 [Listener at localhost/44842] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:19:38,623 [Listener at localhost/44842] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:19:38,623 [Listener at localhost/44842] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:19:38,623 [Listener at localhost/44842] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 10353
2020-12-03 07:19:38,624 [Listener at localhost/44842] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:19:38,626 [Listener at localhost/44842] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@25d3cfc8{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:19:38,627 [Listener at localhost/44842] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2571066a{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:19:38,636 [Listener at localhost/44842] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@73a00e09{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:19:38,637 [Listener at localhost/44842] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@26dcd8c0{HTTP/1.1,[http/1.1]}{localhost:10353}
2020-12-03 07:19:38,637 [Listener at localhost/44842] INFO  server.Server (Server.java:doStart(419)) - Started @8538ms
2020-12-03 07:19:38,646 [Listener at localhost/44842] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:19:38,646 [Listener at localhost/44842] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:19:38,647 [Listener at localhost/44842] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:19:38,647 [Listener at localhost/44842] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:19:38,647 [Listener at localhost/44842] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:19:38,647 [Listener at localhost/44842] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:19:38,647 [Listener at localhost/44842] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:19:38,648 [Listener at localhost/44842] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns1
2020-12-03 07:19:38,648 [Listener at localhost/44842] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: true
2020-12-03 07:19:38,649 [Listener at localhost/44842] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:38,649 [Listener at localhost/44842] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:19:38,649 [Listener at localhost/44842] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:19:38,650 [Listener at localhost/44842] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:19:38,650 [Listener at localhost/44842] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:19:38
2020-12-03 07:19:38,650 [Listener at localhost/44842] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:19:38,651 [Listener at localhost/44842] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:19:38,651 [Listener at localhost/44842] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:19:38,651 [Listener at localhost/44842] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:19:38,666 [Listener at localhost/44842] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:19:38,666 [Listener at localhost/44842] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:19:38,667 [Listener at localhost/44842] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:19:38,667 [Listener at localhost/44842] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:19:38,667 [Listener at localhost/44842] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:19:38,667 [Listener at localhost/44842] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:19:38,667 [Listener at localhost/44842] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 1
2020-12-03 07:19:38,667 [Listener at localhost/44842] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:19:38,668 [Listener at localhost/44842] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:19:38,668 [Listener at localhost/44842] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:19:38,668 [Listener at localhost/44842] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:19:38,668 [Listener at localhost/44842] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:19:38,668 [Listener at localhost/44842] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:19:38,668 [Listener at localhost/44842] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:19:38,669 [Listener at localhost/44842] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:19:38,669 [Listener at localhost/44842] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:19:38,669 [Listener at localhost/44842] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:19:38,677 [Listener at localhost/44842] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:19:38,677 [Listener at localhost/44842] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:19:38,677 [Listener at localhost/44842] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:19:38,678 [Listener at localhost/44842] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:19:38,678 [Listener at localhost/44842] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:19:38,678 [Listener at localhost/44842] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:19:38,678 [Listener at localhost/44842] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:19:38,678 [Listener at localhost/44842] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:19:38,679 [Listener at localhost/44842] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:19:38,679 [Listener at localhost/44842] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:19:38,681 [Listener at localhost/44842] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:19:38,681 [Listener at localhost/44842] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:19:38,681 [Listener at localhost/44842] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:19:38,681 [Listener at localhost/44842] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:19:38,682 [Listener at localhost/44842] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:19:38,682 [Listener at localhost/44842] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:19:38,682 [Listener at localhost/44842] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:19:38,682 [Listener at localhost/44842] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:19:38,683 [Listener at localhost/44842] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:19:38,720 [Listener at localhost/44842] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 330@f22db9385ba9
2020-12-03 07:19:38,746 [Listener at localhost/44842] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 330@f22db9385ba9
2020-12-03 07:19:38,776 [Listener at localhost/44842] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:19:38,777 [Listener at localhost/44842] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:19:38,780 [Listener at localhost/44842] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:19:38,781 [Listener at localhost/44842] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:19:38,782 [Listener at localhost/44842] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-12-03 07:19:38,782 [Listener at localhost/44842] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2020-12-03 07:19:38,782 [Listener at localhost/44842] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:19:38,782 [Listener at localhost/44842] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 99 msecs
2020-12-03 07:19:38,783 [Listener at localhost/44842] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:10352
2020-12-03 07:19:38,784 [Listener at localhost/44842] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:19:38,785 [Socket Reader #1 for port 10352] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 10352
2020-12-03 07:19:38,804 [Listener at localhost/10352] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:19:38,836 [Listener at localhost/10352] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:19:38,838 [Listener at localhost/10352] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:19:38,838 [Listener at localhost/10352] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:19:38,838 [Listener at localhost/10352] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:19:38,857 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:19:38,858 [Listener at localhost/10352] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:10352
2020-12-03 07:19:38,862 [IPC Server listener on 10352] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 10352: starting
2020-12-03 07:19:38,863 [Listener at localhost/10352] INFO  namenode.FSNamesystem (FSNamesystem.java:startStandbyServices(1391)) - Starting services required for standby state
2020-12-03 07:19:38,866 [Listener at localhost/10352] INFO  ha.EditLogTailer (EditLogTailer.java:<init>(205)) - Will roll logs on active node every 120 seconds.
2020-12-03 07:19:38,866 [Listener at localhost/10352] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.period.backoff-max(0) assuming SECONDS
2020-12-03 07:19:38,867 [Listener at localhost/10352] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.rolledits.timeout(60) assuming SECONDS
2020-12-03 07:19:38,870 [Listener at localhost/10352] INFO  ha.StandbyCheckpointer (StandbyCheckpointer.java:start(139)) - Starting standby checkpoint thread...
Checkpointing active NN to possible NNs: [http://localhost:10355, http://localhost:10357]
Serving checkpoints at http://localhost:10353
2020-12-03 07:19:38,871 [Listener at localhost/10352] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:19:38,871 [Listener at localhost/10352] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-12-03 07:19:38,872 [Listener at localhost/10352] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://localhost:10354
2020-12-03 07:19:38,872 [Listener at localhost/10352] INFO  namenode.NameNode (NameNode.java:<init>(944)) - Clients should use ns1 to access this namenode/service.
2020-12-03 07:19:38,905 [Listener at localhost/10352] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:10355
2020-12-03 07:19:38,906 [Listener at localhost/10352] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:38,908 [Listener at localhost/10352] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:19:38,908 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4a7761b1] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:19:38,909 [Listener at localhost/10352] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:19:38,909 [Listener at localhost/10352] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:38,912 [Listener at localhost/10352] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:19:38,913 [Listener at localhost/10352] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:19:38,914 [Listener at localhost/10352] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:19:38,914 [Listener at localhost/10352] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:19:38,916 [Listener at localhost/10352] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:19:38,916 [Listener at localhost/10352] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:19:38,918 [Listener at localhost/10352] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 10355
2020-12-03 07:19:38,918 [Listener at localhost/10352] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:19:38,921 [Listener at localhost/10352] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4abf3f0{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:19:38,922 [Listener at localhost/10352] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@293cde83{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:19:38,930 [Listener at localhost/10352] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@49dbaaf3{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:19:38,931 [Listener at localhost/10352] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@22d9c961{HTTP/1.1,[http/1.1]}{localhost:10355}
2020-12-03 07:19:38,931 [Listener at localhost/10352] INFO  server.Server (Server.java:doStart(419)) - Started @8832ms
2020-12-03 07:19:38,933 [Listener at localhost/10352] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:19:38,934 [Listener at localhost/10352] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:19:38,934 [Listener at localhost/10352] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:19:38,936 [Listener at localhost/10352] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:19:38,936 [Listener at localhost/10352] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:19:38,936 [Listener at localhost/10352] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:19:38,936 [Listener at localhost/10352] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:19:38,937 [Listener at localhost/10352] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns1
2020-12-03 07:19:38,937 [Listener at localhost/10352] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: true
2020-12-03 07:19:38,938 [Listener at localhost/10352] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:38,938 [Listener at localhost/10352] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:19:38,938 [Listener at localhost/10352] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:19:38,939 [Listener at localhost/10352] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:19:38,939 [Listener at localhost/10352] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:19:38
2020-12-03 07:19:38,940 [Listener at localhost/10352] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:19:38,940 [Listener at localhost/10352] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:19:38,940 [Listener at localhost/10352] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:19:38,940 [Listener at localhost/10352] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:19:38,958 [Listener at localhost/10352] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:19:38,959 [Listener at localhost/10352] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:19:38,960 [Listener at localhost/10352] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:19:38,960 [Listener at localhost/10352] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:19:38,961 [Listener at localhost/10352] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:19:38,961 [Listener at localhost/10352] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:19:38,961 [Listener at localhost/10352] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 1
2020-12-03 07:19:38,961 [Listener at localhost/10352] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:19:38,962 [Listener at localhost/10352] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:19:38,962 [Listener at localhost/10352] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:19:38,962 [Listener at localhost/10352] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:19:38,962 [Listener at localhost/10352] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:19:38,963 [Listener at localhost/10352] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:19:38,963 [Listener at localhost/10352] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:19:38,964 [Listener at localhost/10352] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:19:38,964 [Listener at localhost/10352] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:19:38,964 [Listener at localhost/10352] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:19:38,973 [Listener at localhost/10352] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:19:38,973 [Listener at localhost/10352] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:19:38,974 [Listener at localhost/10352] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:19:38,974 [Listener at localhost/10352] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:19:38,974 [Listener at localhost/10352] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:19:38,974 [Listener at localhost/10352] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:19:38,974 [Listener at localhost/10352] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:19:38,974 [Listener at localhost/10352] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:19:38,975 [Listener at localhost/10352] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:19:38,975 [Listener at localhost/10352] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:19:38,978 [Listener at localhost/10352] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:19:38,978 [Listener at localhost/10352] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:19:38,978 [Listener at localhost/10352] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:19:38,978 [Listener at localhost/10352] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:19:38,978 [Listener at localhost/10352] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:19:38,979 [Listener at localhost/10352] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:19:38,979 [Listener at localhost/10352] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:19:38,979 [Listener at localhost/10352] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:19:38,979 [Listener at localhost/10352] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:19:39,033 [Listener at localhost/10352] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-3/in_use.lock acquired by nodename 330@f22db9385ba9
2020-12-03 07:19:39,054 [IPC Server handler 3 on default port 10352] WARN  ipc.Server (Server.java:logException(2974)) - IPC Server handler 3 on default port 10352, call Call#255 Retry#0 org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol.blockReport from 127.0.0.1:56224
java.lang.NullPointerException
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager.checkLease(BlockReportLeaseManager.java:304)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.checkBlockReportLease(BlockManager.java:2594)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.blockReport(NameNodeRpcServer.java:1572)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolServerSideTranslatorPB.blockReport(DatanodeProtocolServerSideTranslatorPB.java:181)
	at org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$DatanodeProtocolService$2.callBlockingMethod(DatanodeProtocolProtos.java:31664)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
2020-12-03 07:19:39,062 [BP-1018250855-172.17.0.10-1606979973945 heartbeating to localhost/127.0.0.1:10352] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Unsuccessfully sent block report 0x8937cfd2788d7974,  containing 2 storage report(s), of which we sent 0. The reports had 0 total blocks and used 0 RPC(s). This took 0 msec to generate and 13 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:19:39,062 [BP-1018250855-172.17.0.10-1606979973945 heartbeating to localhost/127.0.0.1:10352] WARN  datanode.DataNode (BPServiceActor.java:offerService(728)) - RemoteException in offerService
org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager.checkLease(BlockReportLeaseManager.java:304)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.checkBlockReportLease(BlockManager.java:2594)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.blockReport(NameNodeRpcServer.java:1572)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolServerSideTranslatorPB.blockReport(DatanodeProtocolServerSideTranslatorPB.java:181)
	at org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$DatanodeProtocolService$2.callBlockingMethod(DatanodeProtocolProtos.java:31664)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1545)
	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
	at com.sun.proxy.$Proxy28.blockReport(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.blockReport(DatanodeProtocolClientSideTranslatorPB.java:218)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.blockReport(BPServiceActor.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:701)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:849)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:39,074 [Listener at localhost/10352] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-4/in_use.lock acquired by nodename 330@f22db9385ba9
2020-12-03 07:19:39,096 [Listener at localhost/10352] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:19:39,096 [Listener at localhost/10352] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-3/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:19:39,106 [Listener at localhost/10352] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:19:39,108 [Listener at localhost/10352] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:19:39,108 [Listener at localhost/10352] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-3/current/fsimage_0000000000000000000
2020-12-03 07:19:39,109 [Listener at localhost/10352] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2020-12-03 07:19:39,109 [Listener at localhost/10352] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:19:39,109 [Listener at localhost/10352] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 127 msecs
2020-12-03 07:19:39,110 [Listener at localhost/10352] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:10354
2020-12-03 07:19:39,111 [Listener at localhost/10352] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:19:39,112 [Socket Reader #1 for port 10354] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 10354
2020-12-03 07:19:39,126 [Listener at localhost/10354] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:19:39,146 [Listener at localhost/10354] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:19:39,148 [Listener at localhost/10354] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:19:39,148 [Listener at localhost/10354] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:19:39,148 [Listener at localhost/10354] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:19:39,152 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:19:39,152 [IPC Server listener on 10354] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 10354: starting
2020-12-03 07:19:39,155 [Listener at localhost/10354] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:10354
2020-12-03 07:19:39,155 [Listener at localhost/10354] INFO  namenode.FSNamesystem (FSNamesystem.java:startStandbyServices(1391)) - Starting services required for standby state
2020-12-03 07:19:39,157 [Listener at localhost/10354] INFO  ha.EditLogTailer (EditLogTailer.java:<init>(205)) - Will roll logs on active node every 120 seconds.
2020-12-03 07:19:39,157 [Listener at localhost/10354] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.period.backoff-max(0) assuming SECONDS
2020-12-03 07:19:39,157 [Listener at localhost/10354] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.rolledits.timeout(60) assuming SECONDS
2020-12-03 07:19:39,159 [Listener at localhost/10354] INFO  ha.StandbyCheckpointer (StandbyCheckpointer.java:start(139)) - Starting standby checkpoint thread...
Checkpointing active NN to possible NNs: [http://localhost:10353, http://localhost:10357]
Serving checkpoints at http://localhost:10355
2020-12-03 07:19:39,160 [Listener at localhost/10354] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:19:39,160 [Listener at localhost/10354] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-12-03 07:19:39,160 [Listener at localhost/10354] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://localhost:10356
2020-12-03 07:19:39,161 [Listener at localhost/10354] INFO  namenode.NameNode (NameNode.java:<init>(944)) - Clients should use ns1 to access this namenode/service.
2020-12-03 07:19:39,168 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4e25147a] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:19:39,169 [Listener at localhost/10354] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:10357
2020-12-03 07:19:39,169 [Listener at localhost/10354] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:39,171 [Listener at localhost/10354] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:19:39,172 [Listener at localhost/10354] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:19:39,172 [Listener at localhost/10354] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:19:39,174 [Listener at localhost/10354] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:19:39,175 [Listener at localhost/10354] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:19:39,175 [Listener at localhost/10354] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:19:39,176 [Listener at localhost/10354] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:19:39,178 [Listener at localhost/10354] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:19:39,178 [Listener at localhost/10354] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:19:39,178 [Listener at localhost/10354] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 10357
2020-12-03 07:19:39,179 [Listener at localhost/10354] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:19:39,181 [Listener at localhost/10354] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5631962{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:19:39,182 [Listener at localhost/10354] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6124287a{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:19:39,188 [Listener at localhost/10354] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5c645b43{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:19:39,190 [Listener at localhost/10354] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6bd16207{HTTP/1.1,[http/1.1]}{localhost:10357}
2020-12-03 07:19:39,191 [Listener at localhost/10354] INFO  server.Server (Server.java:doStart(419)) - Started @9092ms
2020-12-03 07:19:39,193 [Listener at localhost/10354] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:19:39,194 [Listener at localhost/10354] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:19:39,194 [Listener at localhost/10354] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:19:39,194 [Listener at localhost/10354] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:19:39,195 [Listener at localhost/10354] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:19:39,195 [Listener at localhost/10354] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:19:39,195 [Listener at localhost/10354] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:19:39,196 [Listener at localhost/10354] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns1
2020-12-03 07:19:39,196 [Listener at localhost/10354] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: true
2020-12-03 07:19:39,198 [Listener at localhost/10354] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:19:39,198 [Listener at localhost/10354] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:19:39,198 [Listener at localhost/10354] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:19:39,199 [Listener at localhost/10354] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:19:39,199 [Listener at localhost/10354] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:19:39
2020-12-03 07:19:39,199 [Listener at localhost/10354] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:19:39,199 [Listener at localhost/10354] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:19:39,200 [Listener at localhost/10354] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:19:39,200 [Listener at localhost/10354] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:19:39,214 [Listener at localhost/10354] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:19:39,214 [Listener at localhost/10354] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:19:39,214 [Listener at localhost/10354] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:19:39,215 [Listener at localhost/10354] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:19:39,215 [Listener at localhost/10354] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:19:39,215 [Listener at localhost/10354] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:19:39,215 [Listener at localhost/10354] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 1
2020-12-03 07:19:39,215 [Listener at localhost/10354] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:19:39,215 [Listener at localhost/10354] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:19:39,215 [Listener at localhost/10354] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:19:39,216 [Listener at localhost/10354] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:19:39,216 [Listener at localhost/10354] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:19:39,216 [Listener at localhost/10354] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:19:39,216 [Listener at localhost/10354] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:19:39,216 [Listener at localhost/10354] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:19:39,217 [Listener at localhost/10354] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:19:39,217 [Listener at localhost/10354] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:19:39,223 [Listener at localhost/10354] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:19:39,223 [Listener at localhost/10354] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:19:39,223 [Listener at localhost/10354] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:19:39,223 [Listener at localhost/10354] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:19:39,223 [Listener at localhost/10354] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:19:39,223 [Listener at localhost/10354] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:19:39,224 [Listener at localhost/10354] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:19:39,224 [Listener at localhost/10354] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:19:39,224 [Listener at localhost/10354] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:19:39,224 [Listener at localhost/10354] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:19:39,226 [Listener at localhost/10354] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:19:39,226 [Listener at localhost/10354] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:19:39,226 [Listener at localhost/10354] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:19:39,226 [Listener at localhost/10354] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:19:39,226 [Listener at localhost/10354] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:19:39,227 [Listener at localhost/10354] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:19:39,227 [Listener at localhost/10354] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:19:39,227 [Listener at localhost/10354] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:19:39,227 [Listener at localhost/10354] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:19:39,252 [Listener at localhost/10354] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-5/in_use.lock acquired by nodename 330@f22db9385ba9
2020-12-03 07:19:39,287 [Listener at localhost/10354] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-6/in_use.lock acquired by nodename 330@f22db9385ba9
2020-12-03 07:19:39,392 [Listener at localhost/10354] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:19:39,393 [Listener at localhost/10354] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-5/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:19:39,394 [Listener at localhost/10354] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:19:39,398 [Listener at localhost/10354] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:19:39,398 [Listener at localhost/10354] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-5/current/fsimage_0000000000000000000
2020-12-03 07:19:39,405 [Listener at localhost/10354] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2020-12-03 07:19:39,412 [Listener at localhost/10354] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:19:39,412 [Listener at localhost/10354] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 184 msecs
2020-12-03 07:19:39,413 [Listener at localhost/10354] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:10356
2020-12-03 07:19:39,413 [Listener at localhost/10354] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:19:39,414 [Socket Reader #1 for port 10356] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 10356
2020-12-03 07:19:39,420 [Listener at localhost/10356] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:19:39,455 [Listener at localhost/10356] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:19:39,458 [Listener at localhost/10356] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:19:39,459 [Listener at localhost/10356] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:19:39,459 [Listener at localhost/10356] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:19:39,464 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:19:39,464 [IPC Server listener on 10356] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 10356: starting
2020-12-03 07:19:39,466 [Listener at localhost/10356] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:10356
2020-12-03 07:19:39,472 [Listener at localhost/10356] INFO  namenode.FSNamesystem (FSNamesystem.java:startStandbyServices(1391)) - Starting services required for standby state
2020-12-03 07:19:39,474 [Listener at localhost/10356] INFO  ha.EditLogTailer (EditLogTailer.java:<init>(205)) - Will roll logs on active node every 120 seconds.
2020-12-03 07:19:39,474 [Listener at localhost/10356] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.period.backoff-max(0) assuming SECONDS
2020-12-03 07:19:39,474 [Listener at localhost/10356] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.rolledits.timeout(60) assuming SECONDS
2020-12-03 07:19:39,476 [Listener at localhost/10356] INFO  ha.StandbyCheckpointer (StandbyCheckpointer.java:start(139)) - Starting standby checkpoint thread...
Checkpointing active NN to possible NNs: [http://localhost:10353, http://localhost:10355]
Serving checkpoints at http://localhost:10357
2020-12-03 07:19:39,490 [IPC Server handler 2 on default port 10352] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:39,491 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:39,492 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:39,594 [IPC Server handler 1 on default port 10352] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:39,596 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:39,596 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:39,698 [IPC Server handler 0 on default port 10352] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:39,699 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:39,699 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:39,800 [IPC Server handler 6 on default port 10352] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:39,801 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:39,801 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:39,902 [IPC Server handler 3 on default port 10352] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:39,903 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:39,903 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:40,004 [IPC Server handler 2 on default port 10352] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:40,005 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:40,005 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:40,065 [IPC Server handler 1 on default port 10352] WARN  ipc.Server (Server.java:logException(2974)) - IPC Server handler 1 on default port 10352, call Call#341 Retry#0 org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol.blockReport from 127.0.0.1:56224
java.lang.NullPointerException
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager.checkLease(BlockReportLeaseManager.java:304)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.checkBlockReportLease(BlockManager.java:2594)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.blockReport(NameNodeRpcServer.java:1572)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolServerSideTranslatorPB.blockReport(DatanodeProtocolServerSideTranslatorPB.java:181)
	at org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$DatanodeProtocolService$2.callBlockingMethod(DatanodeProtocolProtos.java:31664)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
2020-12-03 07:19:40,067 [BP-1018250855-172.17.0.10-1606979973945 heartbeating to localhost/127.0.0.1:10352] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Unsuccessfully sent block report 0x8937cfd2788d7975,  containing 2 storage report(s), of which we sent 0. The reports had 0 total blocks and used 0 RPC(s). This took 0 msec to generate and 4 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:19:40,067 [BP-1018250855-172.17.0.10-1606979973945 heartbeating to localhost/127.0.0.1:10352] WARN  datanode.DataNode (BPServiceActor.java:offerService(728)) - RemoteException in offerService
org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager.checkLease(BlockReportLeaseManager.java:304)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.checkBlockReportLease(BlockManager.java:2594)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.blockReport(NameNodeRpcServer.java:1572)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolServerSideTranslatorPB.blockReport(DatanodeProtocolServerSideTranslatorPB.java:181)
	at org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$DatanodeProtocolService$2.callBlockingMethod(DatanodeProtocolProtos.java:31664)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1545)
	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
	at com.sun.proxy.$Proxy28.blockReport(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.blockReport(DatanodeProtocolClientSideTranslatorPB.java:218)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.blockReport(BPServiceActor.java:390)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:701)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:849)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:40,106 [IPC Server handler 0 on default port 10352] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:40,107 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:40,107 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:40,208 [IPC Server handler 6 on default port 10352] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:40,209 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:40,209 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:40,310 [IPC Server handler 5 on default port 10352] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:40,310 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:40,310 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:40,411 [IPC Server handler 7 on default port 10352] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:40,412 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:40,412 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:40,513 [IPC Server handler 4 on default port 10352] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:40,514 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:40,514 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:40,616 [IPC Server handler 8 on default port 10352] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:40,616 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:40,616 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:40,717 [IPC Server handler 9 on default port 10352] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:40,718 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:40,718 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:40,819 [IPC Server handler 3 on default port 10352] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:40,820 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:40,820 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:40,891 [BP-1018250855-172.17.0.10-1606979973945 heartbeating to localhost/127.0.0.1:10356] WARN  datanode.DataNode (BPServiceActor.java:offerService(731)) - IOException in offerService
java.io.EOFException: End of File Exception between local host is: "f22db9385ba9/172.17.0.10"; destination host is: "localhost":10356; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:791)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
	at com.sun.proxy.$Proxy28.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:168)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:517)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:648)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:849)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
2020-12-03 07:19:40,898 [BP-1018250855-172.17.0.10-1606979973945 heartbeating to localhost/127.0.0.1:10354] WARN  datanode.DataNode (BPServiceActor.java:offerService(731)) - IOException in offerService
java.io.EOFException: End of File Exception between local host is: "f22db9385ba9/172.17.0.10"; destination host is: "localhost":10354; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:791)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
	at com.sun.proxy.$Proxy28.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:168)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:517)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:648)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:849)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1850)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1183)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1079)
2020-12-03 07:19:40,921 [IPC Server handler 2 on default port 10352] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:40,922 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:40,922 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:41,023 [IPC Server handler 1 on default port 10352] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:41,024 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:41,024 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:41,076 [BP-1018250855-172.17.0.10-1606979973945 heartbeating to localhost/127.0.0.1:10352] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActor(672)) - DatanodeCommand action : DNA_REGISTER from localhost/127.0.0.1:10352 with standby state
2020-12-03 07:19:41,077 [BP-1018250855-172.17.0.10-1606979973945 heartbeating to localhost/127.0.0.1:10352] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1018250855-172.17.0.10-1606979973945 (Datanode Uuid ffc0a714-d6ed-4515-b5ec-f51ece94380e) service to localhost/127.0.0.1:10352 beginning handshake with NN
2020-12-03 07:19:41,078 [IPC Server handler 5 on default port 10352] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:38920, datanodeUuid=ffc0a714-d6ed-4515-b5ec-f51ece94380e, infoPort=33835, infoSecurePort=0, ipcPort=44842, storageInfo=lv=-57;cid=testClusterID;nsid=1847453481;c=1606979973945) storage ffc0a714-d6ed-4515-b5ec-f51ece94380e
2020-12-03 07:19:41,079 [IPC Server handler 5 on default port 10352] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38920
2020-12-03 07:19:41,079 [IPC Server handler 5 on default port 10352] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN ffc0a714-d6ed-4515-b5ec-f51ece94380e (127.0.0.1:38920).
2020-12-03 07:19:41,081 [BP-1018250855-172.17.0.10-1606979973945 heartbeating to localhost/127.0.0.1:10352] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1018250855-172.17.0.10-1606979973945 (Datanode Uuid ffc0a714-d6ed-4515-b5ec-f51ece94380e) service to localhost/127.0.0.1:10352 successfully registered with NN
2020-12-03 07:19:41,082 [IPC Server handler 7 on default port 10352] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-9cbebd93-291f-4507-adc6-5363d3f38b7d for DN 127.0.0.1:38920
2020-12-03 07:19:41,083 [IPC Server handler 7 on default port 10352] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-4e6b2f57-f556-4639-a9d7-8a7eb3280367 for DN 127.0.0.1:38920
2020-12-03 07:19:41,085 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x8937cfd2788d7976: Processing first storage report for DS-9cbebd93-291f-4507-adc6-5363d3f38b7d from datanode ffc0a714-d6ed-4515-b5ec-f51ece94380e
2020-12-03 07:19:41,086 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x8937cfd2788d7976: from storage DS-9cbebd93-291f-4507-adc6-5363d3f38b7d node DatanodeRegistration(127.0.0.1:38920, datanodeUuid=ffc0a714-d6ed-4515-b5ec-f51ece94380e, infoPort=33835, infoSecurePort=0, ipcPort=44842, storageInfo=lv=-57;cid=testClusterID;nsid=1847453481;c=1606979973945), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:19:41,086 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x8937cfd2788d7976: Processing first storage report for DS-4e6b2f57-f556-4639-a9d7-8a7eb3280367 from datanode ffc0a714-d6ed-4515-b5ec-f51ece94380e
2020-12-03 07:19:41,086 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x8937cfd2788d7976: from storage DS-4e6b2f57-f556-4639-a9d7-8a7eb3280367 node DatanodeRegistration(127.0.0.1:38920, datanodeUuid=ffc0a714-d6ed-4515-b5ec-f51ece94380e, infoPort=33835, infoSecurePort=0, ipcPort=44842, storageInfo=lv=-57;cid=testClusterID;nsid=1847453481;c=1606979973945), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:19:41,087 [BP-1018250855-172.17.0.10-1606979973945 heartbeating to localhost/127.0.0.1:10352] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x8937cfd2788d7976,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 3 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:19:41,125 [IPC Server handler 8 on default port 10352] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:41,132 [IPC Server handler 0 on default port 10354] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:41,135 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:41,135 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:41,236 [IPC Server handler 0 on default port 10354] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:41,237 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:41,237 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:41,339 [IPC Server handler 1 on default port 10354] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:41,341 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:41,341 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:41,442 [IPC Server handler 2 on default port 10354] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:41,443 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:41,443 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:41,544 [IPC Server handler 3 on default port 10354] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:41,545 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:41,545 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:41,646 [IPC Server handler 4 on default port 10354] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:41,647 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:41,647 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:41,749 [IPC Server handler 5 on default port 10354] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:41,749 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:41,750 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:41,851 [IPC Server handler 6 on default port 10354] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:41,852 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:41,852 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:41,953 [IPC Server handler 7 on default port 10354] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:41,954 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:41,954 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:42,055 [IPC Server handler 8 on default port 10354] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:42,056 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:42,056 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:42,158 [IPC Server handler 0 on default port 10354] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:42,159 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:42,159 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:42,260 [IPC Server handler 1 on default port 10354] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:42,261 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:42,261 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:42,362 [IPC Server handler 2 on default port 10354] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:42,363 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:42,363 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:42,465 [IPC Server handler 3 on default port 10354] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:42,466 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:42,466 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:42,567 [IPC Server handler 4 on default port 10354] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:42,568 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:42,568 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:42,669 [IPC Server handler 5 on default port 10354] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:42,670 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:42,670 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:42,771 [IPC Server handler 6 on default port 10354] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:42,772 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:42,772 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:42,873 [IPC Server handler 7 on default port 10354] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:42,874 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:42,874 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:42,975 [IPC Server handler 8 on default port 10354] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:42,976 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:42,976 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:43,077 [IPC Server handler 9 on default port 10354] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:43,078 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:43,078 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:43,179 [IPC Server handler 1 on default port 10354] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:43,180 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:43,180 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:43,281 [IPC Server handler 2 on default port 10354] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:43,282 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:43,282 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:43,383 [IPC Server handler 3 on default port 10354] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:43,384 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:43,384 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:43,485 [IPC Server handler 4 on default port 10354] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:43,486 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:43,486 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:43,587 [IPC Server handler 5 on default port 10354] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:43,588 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:43,588 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:43,689 [IPC Server handler 6 on default port 10354] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:43,690 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:43,690 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:43,791 [IPC Server handler 7 on default port 10354] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:43,791 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:43,791 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:43,893 [IPC Server handler 8 on default port 10354] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:43,895 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:19:43,898 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:19:43,897 [BP-1018250855-172.17.0.10-1606979973945 heartbeating to localhost/127.0.0.1:10356] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActor(672)) - DatanodeCommand action : DNA_REGISTER from localhost/127.0.0.1:10356 with standby state
2020-12-03 07:19:43,900 [BP-1018250855-172.17.0.10-1606979973945 heartbeating to localhost/127.0.0.1:10356] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1018250855-172.17.0.10-1606979973945 (Datanode Uuid ffc0a714-d6ed-4515-b5ec-f51ece94380e) service to localhost/127.0.0.1:10356 beginning handshake with NN
2020-12-03 07:19:43,901 [BP-1018250855-172.17.0.10-1606979973945 heartbeating to localhost/127.0.0.1:10354] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActor(672)) - DatanodeCommand action : DNA_REGISTER from localhost/127.0.0.1:10354 with standby state
2020-12-03 07:19:43,902 [IPC Server handler 2 on default port 10356] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:38920, datanodeUuid=ffc0a714-d6ed-4515-b5ec-f51ece94380e, infoPort=33835, infoSecurePort=0, ipcPort=44842, storageInfo=lv=-57;cid=testClusterID;nsid=1847453481;c=1606979973945) storage ffc0a714-d6ed-4515-b5ec-f51ece94380e
2020-12-03 07:19:43,903 [IPC Server handler 2 on default port 10356] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38920
2020-12-03 07:19:43,903 [IPC Server handler 2 on default port 10356] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN ffc0a714-d6ed-4515-b5ec-f51ece94380e (127.0.0.1:38920).
2020-12-03 07:19:43,903 [BP-1018250855-172.17.0.10-1606979973945 heartbeating to localhost/127.0.0.1:10354] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1018250855-172.17.0.10-1606979973945 (Datanode Uuid ffc0a714-d6ed-4515-b5ec-f51ece94380e) service to localhost/127.0.0.1:10354 beginning handshake with NN
2020-12-03 07:19:43,904 [BP-1018250855-172.17.0.10-1606979973945 heartbeating to localhost/127.0.0.1:10356] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1018250855-172.17.0.10-1606979973945 (Datanode Uuid ffc0a714-d6ed-4515-b5ec-f51ece94380e) service to localhost/127.0.0.1:10356 successfully registered with NN
2020-12-03 07:19:43,905 [IPC Server handler 1 on default port 10354] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:38920, datanodeUuid=ffc0a714-d6ed-4515-b5ec-f51ece94380e, infoPort=33835, infoSecurePort=0, ipcPort=44842, storageInfo=lv=-57;cid=testClusterID;nsid=1847453481;c=1606979973945) storage ffc0a714-d6ed-4515-b5ec-f51ece94380e
2020-12-03 07:19:43,905 [IPC Server handler 1 on default port 10354] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38920
2020-12-03 07:19:43,905 [IPC Server handler 1 on default port 10354] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN ffc0a714-d6ed-4515-b5ec-f51ece94380e (127.0.0.1:38920).
2020-12-03 07:19:43,907 [IPC Server handler 3 on default port 10356] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-9cbebd93-291f-4507-adc6-5363d3f38b7d for DN 127.0.0.1:38920
2020-12-03 07:19:43,907 [IPC Server handler 3 on default port 10356] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-4e6b2f57-f556-4639-a9d7-8a7eb3280367 for DN 127.0.0.1:38920
2020-12-03 07:19:43,907 [BP-1018250855-172.17.0.10-1606979973945 heartbeating to localhost/127.0.0.1:10354] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1018250855-172.17.0.10-1606979973945 (Datanode Uuid ffc0a714-d6ed-4515-b5ec-f51ece94380e) service to localhost/127.0.0.1:10354 successfully registered with NN
2020-12-03 07:19:43,909 [IPC Server handler 2 on default port 10354] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-9cbebd93-291f-4507-adc6-5363d3f38b7d for DN 127.0.0.1:38920
2020-12-03 07:19:43,909 [IPC Server handler 2 on default port 10354] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-4e6b2f57-f556-4639-a9d7-8a7eb3280367 for DN 127.0.0.1:38920
2020-12-03 07:19:43,909 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x281ddea22e87923c: Processing first storage report for DS-9cbebd93-291f-4507-adc6-5363d3f38b7d from datanode ffc0a714-d6ed-4515-b5ec-f51ece94380e
2020-12-03 07:19:43,910 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x281ddea22e87923c: from storage DS-9cbebd93-291f-4507-adc6-5363d3f38b7d node DatanodeRegistration(127.0.0.1:38920, datanodeUuid=ffc0a714-d6ed-4515-b5ec-f51ece94380e, infoPort=33835, infoSecurePort=0, ipcPort=44842, storageInfo=lv=-57;cid=testClusterID;nsid=1847453481;c=1606979973945), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:19:43,910 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x281ddea22e87923c: Processing first storage report for DS-4e6b2f57-f556-4639-a9d7-8a7eb3280367 from datanode ffc0a714-d6ed-4515-b5ec-f51ece94380e
2020-12-03 07:19:43,910 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x281ddea22e87923c: from storage DS-4e6b2f57-f556-4639-a9d7-8a7eb3280367 node DatanodeRegistration(127.0.0.1:38920, datanodeUuid=ffc0a714-d6ed-4515-b5ec-f51ece94380e, infoPort=33835, infoSecurePort=0, ipcPort=44842, storageInfo=lv=-57;cid=testClusterID;nsid=1847453481;c=1606979973945), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:19:43,911 [BP-1018250855-172.17.0.10-1606979973945 heartbeating to localhost/127.0.0.1:10356] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x281ddea22e87923c,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:19:43,911 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x5ff3f5c88d26abd7: Processing first storage report for DS-9cbebd93-291f-4507-adc6-5363d3f38b7d from datanode ffc0a714-d6ed-4515-b5ec-f51ece94380e
2020-12-03 07:19:43,911 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x5ff3f5c88d26abd7: from storage DS-9cbebd93-291f-4507-adc6-5363d3f38b7d node DatanodeRegistration(127.0.0.1:38920, datanodeUuid=ffc0a714-d6ed-4515-b5ec-f51ece94380e, infoPort=33835, infoSecurePort=0, ipcPort=44842, storageInfo=lv=-57;cid=testClusterID;nsid=1847453481;c=1606979973945), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:19:43,911 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x5ff3f5c88d26abd7: Processing first storage report for DS-4e6b2f57-f556-4639-a9d7-8a7eb3280367 from datanode ffc0a714-d6ed-4515-b5ec-f51ece94380e
2020-12-03 07:19:43,912 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x5ff3f5c88d26abd7: from storage DS-4e6b2f57-f556-4639-a9d7-8a7eb3280367 node DatanodeRegistration(127.0.0.1:38920, datanodeUuid=ffc0a714-d6ed-4515-b5ec-f51ece94380e, infoPort=33835, infoSecurePort=0, ipcPort=44842, storageInfo=lv=-57;cid=testClusterID;nsid=1847453481;c=1606979973945), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:19:43,912 [BP-1018250855-172.17.0.10-1606979973945 heartbeating to localhost/127.0.0.1:10354] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x5ff3f5c88d26abd7,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:19:43,999 [IPC Server handler 4 on default port 10354] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:44,005 [IPC Server handler 5 on default port 10356] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:44,006 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:19:44,007 [Listener at localhost/10356] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:19:44,007 [Edit log tailer] WARN  ha.EditLogTailer (EditLogTailer.java:doWork(528)) - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.sleep(EditLogTailer.java:433)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:526)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:440)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:457)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:484)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:453)
2020-12-03 07:19:44,007 [Listener at localhost/10356] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:19:44,010 [Listener at localhost/10356] INFO  client.QuorumJournalManager (QuorumJournalManager.java:recoverUnfinalizedSegments(477)) - Starting recovery process for unclosed journal segments...
2020-12-03 07:19:44,013 [IPC Server handler 2 on default port 38894] INFO  server.Journal (Journal.java:updateLastPromisedEpoch(369)) - Updating lastPromisedEpoch from 1 to 2 for client /127.0.0.1 ; journal id: ns1
2020-12-03 07:19:44,013 [IPC Server handler 2 on default port 36507] INFO  server.Journal (Journal.java:updateLastPromisedEpoch(369)) - Updating lastPromisedEpoch from 1 to 2 for client /127.0.0.1 ; journal id: ns1
2020-12-03 07:19:44,013 [IPC Server handler 1 on default port 32907] INFO  server.Journal (Journal.java:updateLastPromisedEpoch(369)) - Updating lastPromisedEpoch from 1 to 2 for client /127.0.0.1 ; journal id: ns1
2020-12-03 07:19:44,062 [IPC Server handler 2 on default port 36507] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(227)) - Scanning storage FileJournalManager(root=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1)
2020-12-03 07:19:44,062 [IPC Server handler 2 on default port 38894] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(227)) - Scanning storage FileJournalManager(root=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1)
2020-12-03 07:19:44,062 [IPC Server handler 2 on default port 36507] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(245)) - No files in FileJournalManager(root=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1)
2020-12-03 07:19:44,062 [IPC Server handler 1 on default port 32907] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(227)) - Scanning storage FileJournalManager(root=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1)
2020-12-03 07:19:44,063 [IPC Server handler 1 on default port 32907] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(245)) - No files in FileJournalManager(root=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1)
2020-12-03 07:19:44,063 [IPC Server handler 2 on default port 38894] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(245)) - No files in FileJournalManager(root=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1)
2020-12-03 07:19:44,064 [Listener at localhost/10356] INFO  client.QuorumJournalManager (QuorumJournalManager.java:recoverUnfinalizedSegments(479)) - Successfully started new epoch 2
2020-12-03 07:19:44,064 [Listener at localhost/10356] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-12-03 07:19:44,064 [Listener at localhost/10356] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-12-03 07:19:44,064 [Listener at localhost/10356] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1233)) - Catching up to latest edits from old active before taking over writer role in edits logs
2020-12-03 07:19:44,067 [Listener at localhost/10356] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:markAllDatanodesStale(1840)) - Marking all datanodes as stale
2020-12-03 07:19:44,069 [Listener at localhost/10356] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1244)) - Reprocessing replication and invalidation queues
2020-12-03 07:19:44,069 [Listener at localhost/10356] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:19:44,070 [Listener at localhost/10356] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1255)) - Will take over writing edit logs at txnid 1
2020-12-03 07:19:44,071 [Listener at localhost/10356] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 1
2020-12-03 07:19:44,076 [IPC Server handler 1 on default port 32907] INFO  server.Journal (Journal.java:startLogSegment(609)) - Updating lastWriterEpoch from 0 to 2 for client /127.0.0.1 ; journal id: ns1
2020-12-03 07:19:44,076 [IPC Server handler 2 on default port 36507] INFO  server.Journal (Journal.java:startLogSegment(609)) - Updating lastWriterEpoch from 0 to 2 for client /127.0.0.1 ; journal id: ns1
2020-12-03 07:19:44,076 [IPC Server handler 2 on default port 38894] INFO  server.Journal (Journal.java:startLogSegment(609)) - Updating lastWriterEpoch from 0 to 2 for client /127.0.0.1 ; journal id: ns1
2020-12-03 07:19:44,145 [IPC Server handler 3 on default port 36507] INFO  server.Journal (JournaledEditsCache.java:updateLayoutVersion(342)) - Updating edits cache to use layout version -65 starting from txn ID 1
2020-12-03 07:19:44,145 [IPC Server handler 0 on default port 32907] INFO  server.Journal (JournaledEditsCache.java:updateLayoutVersion(342)) - Updating edits cache to use layout version -65 starting from txn ID 1
2020-12-03 07:19:44,145 [IPC Server handler 3 on default port 38894] INFO  server.Journal (JournaledEditsCache.java:updateLayoutVersion(342)) - Updating edits cache to use layout version -65 starting from txn ID 1
2020-12-03 07:19:44,149 [Listener at localhost/10356] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:19:44,154 [Listener at localhost/10356] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 4 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:19:44,158 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 0
2020-12-03 07:19:44,159 [CacheReplicationMonitor(1430983004)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:19:44,159 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:19:44,159 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:19:44,159 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:19:44,159 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:19:44,159 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 89 msec
2020-12-03 07:19:44,161 [BP-1018250855-172.17.0.10-1606979973945 heartbeating to localhost/127.0.0.1:10352] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-1018250855-172.17.0.10-1606979973945 (Datanode Uuid ffc0a714-d6ed-4515-b5ec-f51ece94380e) service to localhost/127.0.0.1:10352 trying to claim ACTIVE state with txid=1
2020-12-03 07:19:44,161 [BP-1018250855-172.17.0.10-1606979973945 heartbeating to localhost/127.0.0.1:10352] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-1018250855-172.17.0.10-1606979973945 (Datanode Uuid ffc0a714-d6ed-4515-b5ec-f51ece94380e) service to localhost/127.0.0.1:10352
2020-12-03 07:19:44,161 [IPC Server handler 9 on default port 10352] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:19:44,162 [Listener at localhost/10356] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:19:44,162 [Edit log tailer] WARN  ha.EditLogTailer (EditLogTailer.java:doWork(528)) - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.sleep(EditLogTailer.java:433)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:526)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:440)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:457)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:484)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:453)
2020-12-03 07:19:44,163 [Listener at localhost/10356] INFO  namenode.FSNamesystem (FSNamesystem.java:startStandbyServices(1391)) - Starting services required for observer state
2020-12-03 07:19:44,167 [Listener at localhost/10356] INFO  ha.EditLogTailer (EditLogTailer.java:<init>(205)) - Will roll logs on active node every 120 seconds.
2020-12-03 07:19:44,167 [Listener at localhost/10356] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.period.backoff-max(0) assuming SECONDS
2020-12-03 07:19:44,167 [Listener at localhost/10356] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.rolledits.timeout(60) assuming SECONDS
2020-12-03 07:19:44,189 [Edit log tailer] INFO  client.QuorumJournalManager (QuorumJournalManager.java:selectRpcInputStreams(592)) - Selected loggers with >= 1 transactions starting from lowest txn ID 1.0
2020-12-03 07:19:44,189 [Edit log tailer] INFO  client.QuorumJournalManager (QuorumJournalManager.java:selectRpcInputStreams(592)) - Selected loggers with >= 1 transactions starting from lowest txn ID 1.0
2020-12-03 07:19:44,196 [Edit log tailer] INFO  namenode.FSImage (FSImage.java:loadEdits(910)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@2277881e expecting start txid #1
2020-12-03 07:19:44,196 [Edit log tailer] INFO  namenode.FSImage (FSImage.java:loadEdits(910)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@37919f26 expecting start txid #1
2020-12-03 07:19:44,196 [Edit log tailer] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file ByteStringEditLog[1, 1], ByteStringEditLog[1, 1], ByteStringEditLog[1, 1] maxTxnsToRead = 9223372036854775807
2020-12-03 07:19:44,196 [Edit log tailer] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file ByteStringEditLog[1, 1], ByteStringEditLog[1, 1], ByteStringEditLog[1, 1] maxTxnsToRead = 9223372036854775807
2020-12-03 07:19:44,197 [Edit log tailer] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream 'ByteStringEditLog[1, 1], ByteStringEditLog[1, 1], ByteStringEditLog[1, 1]' to transaction ID 1
2020-12-03 07:19:44,197 [Edit log tailer] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream 'ByteStringEditLog[1, 1], ByteStringEditLog[1, 1], ByteStringEditLog[1, 1]' to transaction ID 1
2020-12-03 07:19:44,198 [Edit log tailer] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream 'ByteStringEditLog[1, 1]' to transaction ID 1
2020-12-03 07:19:44,198 [Edit log tailer] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream 'ByteStringEditLog[1, 1]' to transaction ID 1
2020-12-03 07:19:44,224 [Edit log tailer] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(188)) - Loaded 1 edits file(s) (the last named ByteStringEditLog[1, 1], ByteStringEditLog[1, 1], ByteStringEditLog[1, 1]) of total size 25.0, total edits 1.0, total load time 16.0 ms
2020-12-03 07:19:44,224 [Edit log tailer] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(188)) - Loaded 1 edits file(s) (the last named ByteStringEditLog[1, 1], ByteStringEditLog[1, 1], ByteStringEditLog[1, 1]) of total size 25.0, total edits 1.0, total load time 16.0 ms
2020-12-03 07:19:44,230 [IPC Server handler 8 on default port 10356] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/testFile1FO	dst=null	perm=null	proto=rpc
2020-12-03 07:19:44,267 [IPC Server handler 1 on default port 10352] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/testFile1FO	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:19:44,330 [IPC Server handler 0 on default port 10352] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:38920 for /testFile1FO
2020-12-03 07:19:44,347 [Edit log tailer] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file ByteStringEditLog[2, 5], ByteStringEditLog[2, 5] maxTxnsToRead = 9223372036854775807
2020-12-03 07:19:44,347 [Edit log tailer] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream 'ByteStringEditLog[2, 5], ByteStringEditLog[2, 5]' to transaction ID 2
2020-12-03 07:19:44,347 [Edit log tailer] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream 'ByteStringEditLog[2, 5]' to transaction ID 2
2020-12-03 07:19:44,353 [Edit log tailer] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file ByteStringEditLog[2, 4], ByteStringEditLog[2, 4] maxTxnsToRead = 9223372036854775807
2020-12-03 07:19:44,353 [Edit log tailer] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(188)) - Loaded 1 edits file(s) (the last named ByteStringEditLog[2, 5], ByteStringEditLog[2, 5]) of total size 273.0, total edits 4.0, total load time 6.0 ms
2020-12-03 07:19:44,353 [Edit log tailer] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream 'ByteStringEditLog[2, 4], ByteStringEditLog[2, 4]' to transaction ID 2
2020-12-03 07:19:44,353 [Edit log tailer] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream 'ByteStringEditLog[2, 4]' to transaction ID 2
2020-12-03 07:19:44,356 [Edit log tailer] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(188)) - Loaded 1 edits file(s) (the last named ByteStringEditLog[2, 4], ByteStringEditLog[2, 4]) of total size 273.0, total edits 3.0, total load time 3.0 ms
2020-12-03 07:19:44,362 [Thread-330] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:44,457 [Edit log tailer] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file ByteStringEditLog[5, 5], ByteStringEditLog[5, 5] maxTxnsToRead = 9223372036854775807
2020-12-03 07:19:44,457 [Edit log tailer] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream 'ByteStringEditLog[5, 5], ByteStringEditLog[5, 5]' to transaction ID 5
2020-12-03 07:19:44,458 [Edit log tailer] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream 'ByteStringEditLog[5, 5]' to transaction ID 5
2020-12-03 07:19:44,458 [Edit log tailer] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(188)) - Loaded 1 edits file(s) (the last named ByteStringEditLog[5, 5], ByteStringEditLog[5, 5]) of total size 58.0, total edits 1.0, total load time 1.0 ms
2020-12-03 07:19:44,520 [DataXceiver for client DFSClient_NONMAPREDUCE_2077342936_1 at /127.0.0.1:34358 [Receiving block BP-1018250855-172.17.0.10-1606979973945:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1018250855-172.17.0.10-1606979973945:blk_1073741825_1001 src: /127.0.0.1:34358 dest: /127.0.0.1:38920
2020-12-03 07:19:44,569 [PacketResponder: BP-1018250855-172.17.0.10-1606979973945:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:34358, dest: /127.0.0.1:38920, bytes: 3, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2077342936_1, offset: 0, srvID: ffc0a714-d6ed-4515-b5ec-f51ece94380e, blockid: BP-1018250855-172.17.0.10-1606979973945:blk_1073741825_1001, duration(ns): 11279227
2020-12-03 07:19:44,569 [PacketResponder: BP-1018250855-172.17.0.10-1606979973945:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1018250855-172.17.0.10-1606979973945:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:44,577 [IPC Server handler 6 on default port 10352] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2995)) - BLOCK* blk_1073741825_1001 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /testFile1FO
2020-12-03 07:19:44,982 [IPC Server handler 4 on default port 10352] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /testFile1FO is closed by DFSClient_NONMAPREDUCE_2077342936_1
2020-12-03 07:19:44,985 [Listener at localhost/10356] INFO  hdfs.TestStateAlignmentContextWithHA (TestStateAlignmentContextWithHA.java:failOver(257)) - Transitioning Active to Standby
2020-12-03 07:19:44,985 [Listener at localhost/10356] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:19:44,986 [Listener at localhost/10356] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 1, 6
2020-12-03 07:19:44,986 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@1b005a0b] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:19:44,989 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@795fd838] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:19:44,990 [Listener at localhost/10356] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 7 Total time for transactions(ms): 26 Number of transactions batched in Syncs: 1 Number of syncs: 6 SyncTimes(ms): 30 1 1 
2020-12-03 07:19:44,995 [IPC Server handler 4 on default port 32907] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1/current/edits_0000000000000000001-0000000000000000007
2020-12-03 07:19:44,995 [IPC Server handler 0 on default port 38894] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1/current/edits_0000000000000000001-0000000000000000007
2020-12-03 07:19:44,995 [IPC Server handler 4 on default port 36507] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/current/edits_0000000000000000001-0000000000000000007
2020-12-03 07:19:44,997 [Listener at localhost/10356] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000007
2020-12-03 07:19:44,998 [Listener at localhost/10356] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000007
2020-12-03 07:19:44,999 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:19:45,003 [CacheReplicationMonitor(1430983004)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:19:45,003 [Listener at localhost/10356] INFO  namenode.FSNamesystem (FSNamesystem.java:startStandbyServices(1391)) - Starting services required for standby state
2020-12-03 07:19:45,007 [Listener at localhost/10356] INFO  ha.EditLogTailer (EditLogTailer.java:<init>(205)) - Will roll logs on active node every 120 seconds.
2020-12-03 07:19:45,007 [Listener at localhost/10356] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.period.backoff-max(0) assuming SECONDS
2020-12-03 07:19:45,007 [Listener at localhost/10356] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.rolledits.timeout(60) assuming SECONDS
2020-12-03 07:19:45,008 [Listener at localhost/10356] INFO  ha.StandbyCheckpointer (StandbyCheckpointer.java:start(139)) - Starting standby checkpoint thread...
Checkpointing active NN to possible NNs: [http://localhost:10355, http://localhost:10357]
Serving checkpoints at http://localhost:10353
2020-12-03 07:19:45,009 [Listener at localhost/10356] INFO  hdfs.TestStateAlignmentContextWithHA (TestStateAlignmentContextWithHA.java:failOver(259)) - Transitioning Standby to Active
2020-12-03 07:19:45,009 [Listener at localhost/10356] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:19:45,009 [Edit log tailer] WARN  ha.EditLogTailer (EditLogTailer.java:doWork(528)) - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.sleep(EditLogTailer.java:433)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:526)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:440)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:457)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:484)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:453)
2020-12-03 07:19:45,010 [Listener at localhost/10356] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:19:45,012 [Listener at localhost/10356] INFO  client.QuorumJournalManager (QuorumJournalManager.java:recoverUnfinalizedSegments(477)) - Starting recovery process for unclosed journal segments...
2020-12-03 07:19:45,015 [IPC Server handler 3 on default port 38894] INFO  server.Journal (Journal.java:updateLastPromisedEpoch(369)) - Updating lastPromisedEpoch from 2 to 3 for client /127.0.0.1 ; journal id: ns1
2020-12-03 07:19:45,015 [IPC Server handler 3 on default port 36507] INFO  server.Journal (Journal.java:updateLastPromisedEpoch(369)) - Updating lastPromisedEpoch from 2 to 3 for client /127.0.0.1 ; journal id: ns1
2020-12-03 07:19:45,015 [IPC Server handler 0 on default port 32907] INFO  server.Journal (Journal.java:updateLastPromisedEpoch(369)) - Updating lastPromisedEpoch from 2 to 3 for client /127.0.0.1 ; journal id: ns1
2020-12-03 07:19:45,050 [IPC Server handler 3 on default port 38894] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(227)) - Scanning storage FileJournalManager(root=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1)
2020-12-03 07:19:45,050 [IPC Server handler 0 on default port 32907] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(227)) - Scanning storage FileJournalManager(root=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1)
2020-12-03 07:19:45,050 [IPC Server handler 3 on default port 36507] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(227)) - Scanning storage FileJournalManager(root=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1)
2020-12-03 07:19:45,052 [IPC Server handler 3 on default port 36507] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(233)) - Latest log is EditLogFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/current/edits_0000000000000000001-0000000000000000007,first=0000000000000000001,last=0000000000000000007,inProgress=false,hasCorruptHeader=false) ; journal id: ns1
2020-12-03 07:19:45,052 [IPC Server handler 0 on default port 32907] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(233)) - Latest log is EditLogFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1/current/edits_0000000000000000001-0000000000000000007,first=0000000000000000001,last=0000000000000000007,inProgress=false,hasCorruptHeader=false) ; journal id: ns1
2020-12-03 07:19:45,052 [IPC Server handler 3 on default port 38894] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(233)) - Latest log is EditLogFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1/current/edits_0000000000000000001-0000000000000000007,first=0000000000000000001,last=0000000000000000007,inProgress=false,hasCorruptHeader=false) ; journal id: ns1
2020-12-03 07:19:45,053 [Listener at localhost/10356] INFO  client.QuorumJournalManager (QuorumJournalManager.java:recoverUnfinalizedSegments(479)) - Successfully started new epoch 3
2020-12-03 07:19:45,053 [Listener at localhost/10356] INFO  client.QuorumJournalManager (QuorumJournalManager.java:recoverUnclosedSegment(313)) - Beginning recovery of unclosed segment starting at txid 1
2020-12-03 07:19:45,062 [IPC Server handler 3 on default port 32907] INFO  server.Journal (Journal.java:getSegmentInfo(807)) - getSegmentInfo(1): EditLogFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1/current/edits_0000000000000000001-0000000000000000007,first=0000000000000000001,last=0000000000000000007,inProgress=false,hasCorruptHeader=false) -> startTxId: 1 endTxId: 7 isInProgress: false ; journal id: ns1
2020-12-03 07:19:45,062 [IPC Server handler 4 on default port 38894] INFO  server.Journal (Journal.java:getSegmentInfo(807)) - getSegmentInfo(1): EditLogFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1/current/edits_0000000000000000001-0000000000000000007,first=0000000000000000001,last=0000000000000000007,inProgress=false,hasCorruptHeader=false) -> startTxId: 1 endTxId: 7 isInProgress: false ; journal id: ns1
2020-12-03 07:19:45,062 [IPC Server handler 1 on default port 36507] INFO  server.Journal (Journal.java:getSegmentInfo(807)) - getSegmentInfo(1): EditLogFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/current/edits_0000000000000000001-0000000000000000007,first=0000000000000000001,last=0000000000000000007,inProgress=false,hasCorruptHeader=false) -> startTxId: 1 endTxId: 7 isInProgress: false ; journal id: ns1
2020-12-03 07:19:45,063 [IPC Server handler 4 on default port 38894] INFO  server.Journal (Journal.java:prepareRecovery(851)) - Prepared recovery for segment 1: segmentState { startTxId: 1 endTxId: 7 isInProgress: false } lastWriterEpoch: 2 lastCommittedTxId: 7 ; journal id: ns1
2020-12-03 07:19:45,063 [IPC Server handler 1 on default port 36507] INFO  server.Journal (Journal.java:prepareRecovery(851)) - Prepared recovery for segment 1: segmentState { startTxId: 1 endTxId: 7 isInProgress: false } lastWriterEpoch: 2 lastCommittedTxId: 7 ; journal id: ns1
2020-12-03 07:19:45,063 [IPC Server handler 3 on default port 32907] INFO  server.Journal (Journal.java:prepareRecovery(851)) - Prepared recovery for segment 1: segmentState { startTxId: 1 endTxId: 7 isInProgress: false } lastWriterEpoch: 2 lastCommittedTxId: 7 ; journal id: ns1
2020-12-03 07:19:45,064 [Edit log tailer] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file ByteStringEditLog[6, 7], ByteStringEditLog[6, 7] maxTxnsToRead = 9223372036854775807
2020-12-03 07:19:45,065 [Edit log tailer] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream 'ByteStringEditLog[6, 7], ByteStringEditLog[6, 7]' to transaction ID 6
2020-12-03 07:19:45,065 [Listener at localhost/10356] INFO  client.QuorumJournalManager (QuorumJournalManager.java:recoverUnclosedSegment(322)) - Recovery prepare phase complete. Responses:
127.0.0.1:38894: segmentState { startTxId: 1 endTxId: 7 isInProgress: false } lastWriterEpoch: 2 lastCommittedTxId: 7
127.0.0.1:36507: segmentState { startTxId: 1 endTxId: 7 isInProgress: false } lastWriterEpoch: 2 lastCommittedTxId: 7
127.0.0.1:32907: segmentState { startTxId: 1 endTxId: 7 isInProgress: false } lastWriterEpoch: 2 lastCommittedTxId: 7
2020-12-03 07:19:45,065 [Edit log tailer] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream 'ByteStringEditLog[6, 7]' to transaction ID 6
2020-12-03 07:19:45,067 [Edit log tailer] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(188)) - Loaded 1 edits file(s) (the last named ByteStringEditLog[6, 7], ByteStringEditLog[6, 7]) of total size 136.0, total edits 2.0, total load time 2.0 ms
2020-12-03 07:19:45,067 [Listener at localhost/10356] INFO  client.QuorumJournalManager (QuorumJournalManager.java:recoverUnclosedSegment(346)) - Using longest log: 127.0.0.1:38894=segmentState {
  startTxId: 1
  endTxId: 7
  isInProgress: false
}
lastWriterEpoch: 2
lastCommittedTxId: 7

2020-12-03 07:19:45,076 [IPC Server handler 0 on default port 36507] INFO  server.Journal (Journal.java:getSegmentInfo(807)) - getSegmentInfo(1): EditLogFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/current/edits_0000000000000000001-0000000000000000007,first=0000000000000000001,last=0000000000000000007,inProgress=false,hasCorruptHeader=false) -> startTxId: 1 endTxId: 7 isInProgress: false ; journal id: ns1
2020-12-03 07:19:45,076 [IPC Server handler 2 on default port 32907] INFO  server.Journal (Journal.java:getSegmentInfo(807)) - getSegmentInfo(1): EditLogFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1/current/edits_0000000000000000001-0000000000000000007,first=0000000000000000001,last=0000000000000000007,inProgress=false,hasCorruptHeader=false) -> startTxId: 1 endTxId: 7 isInProgress: false ; journal id: ns1
2020-12-03 07:19:45,076 [IPC Server handler 1 on default port 38894] INFO  server.Journal (Journal.java:getSegmentInfo(807)) - getSegmentInfo(1): EditLogFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1/current/edits_0000000000000000001-0000000000000000007,first=0000000000000000001,last=0000000000000000007,inProgress=false,hasCorruptHeader=false) -> startTxId: 1 endTxId: 7 isInProgress: false ; journal id: ns1
2020-12-03 07:19:45,077 [IPC Server handler 0 on default port 36507] INFO  server.Journal (Journal.java:acceptRecovery(939)) - Skipping download of log startTxId: 1 endTxId: 7 isInProgress: false: already have up-to-date logs ; journal id: ns1
2020-12-03 07:19:45,078 [IPC Server handler 2 on default port 32907] INFO  server.Journal (Journal.java:acceptRecovery(939)) - Skipping download of log startTxId: 1 endTxId: 7 isInProgress: false: already have up-to-date logs ; journal id: ns1
2020-12-03 07:19:45,077 [IPC Server handler 1 on default port 38894] INFO  server.Journal (Journal.java:acceptRecovery(939)) - Skipping download of log startTxId: 1 endTxId: 7 isInProgress: false: already have up-to-date logs ; journal id: ns1
2020-12-03 07:19:45,127 [IPC Server handler 2 on default port 32907] INFO  server.Journal (Journal.java:acceptRecovery(972)) - Accepted recovery for segment 1: segmentState { startTxId: 1 endTxId: 7 isInProgress: false } acceptedInEpoch: 3 ; journal id: ns1
2020-12-03 07:19:45,127 [IPC Server handler 1 on default port 38894] INFO  server.Journal (Journal.java:acceptRecovery(972)) - Accepted recovery for segment 1: segmentState { startTxId: 1 endTxId: 7 isInProgress: false } acceptedInEpoch: 3 ; journal id: ns1
2020-12-03 07:19:45,127 [IPC Server handler 0 on default port 36507] INFO  server.Journal (Journal.java:acceptRecovery(972)) - Accepted recovery for segment 1: segmentState { startTxId: 1 endTxId: 7 isInProgress: false } acceptedInEpoch: 3 ; journal id: ns1
2020-12-03 07:19:45,131 [Listener at localhost/10356] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-3/current
2020-12-03 07:19:45,131 [Listener at localhost/10356] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-4/current
2020-12-03 07:19:45,131 [Listener at localhost/10356] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1233)) - Catching up to latest edits from old active before taking over writer role in edits logs
2020-12-03 07:19:45,134 [Listener at localhost/10356] INFO  client.QuorumJournalManager (QuorumJournalManager.java:selectRpcInputStreams(592)) - Selected loggers with >= 2 transactions starting from lowest txn ID 6.0
2020-12-03 07:19:45,135 [Listener at localhost/10356] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file ByteStringEditLog[6, 7], ByteStringEditLog[6, 7] maxTxnsToRead = 9223372036854775807
2020-12-03 07:19:45,135 [Listener at localhost/10356] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream 'ByteStringEditLog[6, 7], ByteStringEditLog[6, 7]' to transaction ID 6
2020-12-03 07:19:45,135 [Listener at localhost/10356] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream 'ByteStringEditLog[6, 7]' to transaction ID 6
2020-12-03 07:19:45,136 [Listener at localhost/10356] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(188)) - Loaded 1 edits file(s) (the last named ByteStringEditLog[6, 7], ByteStringEditLog[6, 7]) of total size 136.0, total edits 2.0, total load time 1.0 ms
2020-12-03 07:19:45,136 [Listener at localhost/10356] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:markAllDatanodesStale(1840)) - Marking all datanodes as stale
2020-12-03 07:19:45,140 [Listener at localhost/10356] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1244)) - Reprocessing replication and invalidation queues
2020-12-03 07:19:45,140 [Listener at localhost/10356] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:19:45,141 [Listener at localhost/10356] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1255)) - Will take over writing edit logs at txnid 8
2020-12-03 07:19:45,142 [Listener at localhost/10356] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 8
2020-12-03 07:19:45,143 [IPC Server handler 2 on default port 36507] INFO  server.Journal (Journal.java:startLogSegment(609)) - Updating lastWriterEpoch from 2 to 3 for client /127.0.0.1 ; journal id: ns1
2020-12-03 07:19:45,143 [IPC Server handler 1 on default port 32907] INFO  server.Journal (Journal.java:startLogSegment(609)) - Updating lastWriterEpoch from 2 to 3 for client /127.0.0.1 ; journal id: ns1
2020-12-03 07:19:45,143 [IPC Server handler 2 on default port 38894] INFO  server.Journal (Journal.java:startLogSegment(609)) - Updating lastWriterEpoch from 2 to 3 for client /127.0.0.1 ; journal id: ns1
2020-12-03 07:19:45,189 [Listener at localhost/10356] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:19:45,191 [Listener at localhost/10356] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 1 milliseconds
name space=2
storage space=3
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:19:45,193 [CacheReplicationMonitor(1738668828)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:19:45,194 [IPC Server handler 7 on default port 10356] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/testFile2FO	dst=null	perm=null	proto=rpc
2020-12-03 07:19:45,198 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 1
2020-12-03 07:19:45,198 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:19:45,198 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:19:45,198 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:19:45,198 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:19:45,198 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 57 msec
2020-12-03 07:19:45,198 [Listener at localhost/10356] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.StandbyException): Operation category WRITE is not supported in state standby. Visit https://s.apache.org/sbnn-error
	at org.apache.hadoop.hdfs.server.namenode.ha.StandbyState.checkOperation(StandbyState.java:98)
	at org.apache.hadoop.hdfs.server.namenode.NameNode$NameNodeHAContext.checkOperation(NameNode.java:2021)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkOperation(FSNamesystem.java:1449)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:781)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:475)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
, while invoking $Proxy30.create over [localhost/127.0.0.1:10352,localhost/127.0.0.1:10354,localhost/127.0.0.1:10356]. Trying to failover immediately.
2020-12-03 07:19:45,202 [IPC Server handler 6 on default port 10354] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/testFile2FO	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:19:45,208 [IPC Server handler 7 on default port 10354] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741826_1002, replicas=127.0.0.1:38920 for /testFile2FO
2020-12-03 07:19:45,214 [Thread-341] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:19:45,216 [DataXceiver for client DFSClient_NONMAPREDUCE_2077342936_1 at /127.0.0.1:34376 [Receiving block BP-1018250855-172.17.0.10-1606979973945:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1018250855-172.17.0.10-1606979973945:blk_1073741826_1002 src: /127.0.0.1:34376 dest: /127.0.0.1:38920
2020-12-03 07:19:45,223 [PacketResponder: BP-1018250855-172.17.0.10-1606979973945:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:34376, dest: /127.0.0.1:38920, bytes: 3, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2077342936_1, offset: 0, srvID: ffc0a714-d6ed-4515-b5ec-f51ece94380e, blockid: BP-1018250855-172.17.0.10-1606979973945:blk_1073741826_1002, duration(ns): 3785772
2020-12-03 07:19:45,224 [PacketResponder: BP-1018250855-172.17.0.10-1606979973945:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1018250855-172.17.0.10-1606979973945:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2020-12-03 07:19:45,226 [IPC Server handler 9 on default port 10354] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /testFile2FO is closed by DFSClient_NONMAPREDUCE_2077342936_1
2020-12-03 07:19:45,227 [Listener at localhost/10356] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:19:45,228 [Listener at localhost/10356] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 8, 13
2020-12-03 07:19:45,228 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@385ef531] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:19:45,228 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@7e75bf2d] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:19:45,230 [Edit log tailer] INFO  client.QuorumJournalManager (QuorumJournalManager.java:selectRpcInputStreams(592)) - Selected loggers with >= 6 transactions starting from lowest txn ID 8.0
2020-12-03 07:19:45,231 [Listener at localhost/10356] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 7 Total time for transactions(ms): 5 Number of transactions batched in Syncs: 8 Number of syncs: 6 SyncTimes(ms): 12 2 1 
2020-12-03 07:19:45,231 [Edit log tailer] INFO  namenode.FSImage (FSImage.java:loadEdits(910)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@fb54464 expecting start txid #8
2020-12-03 07:19:45,231 [Edit log tailer] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file ByteStringEditLog[8, 13], ByteStringEditLog[8, 13] maxTxnsToRead = 9223372036854775807
2020-12-03 07:19:45,231 [Edit log tailer] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream 'ByteStringEditLog[8, 13], ByteStringEditLog[8, 13]' to transaction ID 8
2020-12-03 07:19:45,231 [Edit log tailer] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream 'ByteStringEditLog[8, 13]' to transaction ID 8
2020-12-03 07:19:45,232 [IPC Server handler 4 on default port 36507] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/current/edits_inprogress_0000000000000000008 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/current/edits_0000000000000000008-0000000000000000014
2020-12-03 07:19:45,232 [IPC Server handler 0 on default port 38894] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1/current/edits_inprogress_0000000000000000008 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1/current/edits_0000000000000000008-0000000000000000014
2020-12-03 07:19:45,232 [IPC Server handler 4 on default port 32907] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1/current/edits_inprogress_0000000000000000008 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1/current/edits_0000000000000000008-0000000000000000014
2020-12-03 07:19:45,233 [Listener at localhost/10356] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-3/current/edits_inprogress_0000000000000000008 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-3/current/edits_0000000000000000008-0000000000000000014
2020-12-03 07:19:45,233 [Edit log tailer] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(188)) - Loaded 1 edits file(s) (the last named ByteStringEditLog[8, 13], ByteStringEditLog[8, 13]) of total size 401.0, total edits 6.0, total load time 2.0 ms
2020-12-03 07:19:45,234 [Listener at localhost/10356] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-4/current/edits_inprogress_0000000000000000008 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-4/current/edits_0000000000000000008-0000000000000000014
2020-12-03 07:19:45,234 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:19:45,235 [CacheReplicationMonitor(1738668828)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:19:45,235 [Listener at localhost/10356] INFO  namenode.FSNamesystem (FSNamesystem.java:startStandbyServices(1391)) - Starting services required for standby state
2020-12-03 07:19:45,239 [Listener at localhost/10356] INFO  ha.EditLogTailer (EditLogTailer.java:<init>(205)) - Will roll logs on active node every 120 seconds.
2020-12-03 07:19:45,239 [Listener at localhost/10356] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.period.backoff-max(0) assuming SECONDS
2020-12-03 07:19:45,239 [Listener at localhost/10356] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.rolledits.timeout(60) assuming SECONDS
2020-12-03 07:19:45,242 [Listener at localhost/10356] INFO  ha.StandbyCheckpointer (StandbyCheckpointer.java:start(139)) - Starting standby checkpoint thread...
Checkpointing active NN to possible NNs: [http://localhost:10353, http://localhost:10357]
Serving checkpoints at http://localhost:10355
2020-12-03 07:19:45,242 [Listener at localhost/10356] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:19:45,243 [Edit log tailer] WARN  ha.EditLogTailer (EditLogTailer.java:doWork(528)) - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.sleep(EditLogTailer.java:433)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:526)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:440)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:457)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:484)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:453)
2020-12-03 07:19:45,243 [Listener at localhost/10356] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:19:45,246 [Listener at localhost/10356] INFO  client.QuorumJournalManager (QuorumJournalManager.java:recoverUnfinalizedSegments(477)) - Starting recovery process for unclosed journal segments...
2020-12-03 07:19:45,248 [IPC Server handler 3 on default port 36507] INFO  server.Journal (Journal.java:updateLastPromisedEpoch(369)) - Updating lastPromisedEpoch from 3 to 4 for client /127.0.0.1 ; journal id: ns1
2020-12-03 07:19:45,248 [IPC Server handler 3 on default port 38894] INFO  server.Journal (Journal.java:updateLastPromisedEpoch(369)) - Updating lastPromisedEpoch from 3 to 4 for client /127.0.0.1 ; journal id: ns1
2020-12-03 07:19:45,249 [IPC Server handler 0 on default port 32907] INFO  server.Journal (Journal.java:updateLastPromisedEpoch(369)) - Updating lastPromisedEpoch from 3 to 4 for client /127.0.0.1 ; journal id: ns1
2020-12-03 07:19:45,315 [IPC Server handler 3 on default port 38894] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(227)) - Scanning storage FileJournalManager(root=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1)
2020-12-03 07:19:45,315 [IPC Server handler 3 on default port 36507] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(227)) - Scanning storage FileJournalManager(root=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1)
2020-12-03 07:19:45,315 [IPC Server handler 0 on default port 32907] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(227)) - Scanning storage FileJournalManager(root=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1)
2020-12-03 07:19:45,317 [IPC Server handler 0 on default port 32907] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(233)) - Latest log is EditLogFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1/current/edits_0000000000000000008-0000000000000000014,first=0000000000000000008,last=0000000000000000014,inProgress=false,hasCorruptHeader=false) ; journal id: ns1
2020-12-03 07:19:45,317 [IPC Server handler 3 on default port 38894] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(233)) - Latest log is EditLogFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1/current/edits_0000000000000000008-0000000000000000014,first=0000000000000000008,last=0000000000000000014,inProgress=false,hasCorruptHeader=false) ; journal id: ns1
2020-12-03 07:19:45,317 [IPC Server handler 3 on default port 36507] INFO  server.Journal (Journal.java:scanStorageForLatestEdits(233)) - Latest log is EditLogFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/current/edits_0000000000000000008-0000000000000000014,first=0000000000000000008,last=0000000000000000014,inProgress=false,hasCorruptHeader=false) ; journal id: ns1
2020-12-03 07:19:45,318 [Listener at localhost/10356] INFO  client.QuorumJournalManager (QuorumJournalManager.java:recoverUnfinalizedSegments(479)) - Successfully started new epoch 4
2020-12-03 07:19:45,319 [Listener at localhost/10356] INFO  client.QuorumJournalManager (QuorumJournalManager.java:recoverUnclosedSegment(313)) - Beginning recovery of unclosed segment starting at txid 8
2020-12-03 07:19:45,319 [Edit log tailer] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file ByteStringEditLog[8, 14], ByteStringEditLog[8, 14], ByteStringEditLog[8, 14] maxTxnsToRead = 9223372036854775807
2020-12-03 07:19:45,319 [Edit log tailer] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream 'ByteStringEditLog[8, 14], ByteStringEditLog[8, 14], ByteStringEditLog[8, 14]' to transaction ID 8
2020-12-03 07:19:45,319 [Edit log tailer] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream 'ByteStringEditLog[8, 14]' to transaction ID 8
2020-12-03 07:19:45,320 [IPC Server handler 4 on default port 32907] INFO  server.Journal (Journal.java:getSegmentInfo(807)) - getSegmentInfo(8): EditLogFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1/current/edits_0000000000000000008-0000000000000000014,first=0000000000000000008,last=0000000000000000014,inProgress=false,hasCorruptHeader=false) -> startTxId: 8 endTxId: 14 isInProgress: false ; journal id: ns1
2020-12-03 07:19:45,320 [IPC Server handler 0 on default port 38894] INFO  server.Journal (Journal.java:getSegmentInfo(807)) - getSegmentInfo(8): EditLogFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1/current/edits_0000000000000000008-0000000000000000014,first=0000000000000000008,last=0000000000000000014,inProgress=false,hasCorruptHeader=false) -> startTxId: 8 endTxId: 14 isInProgress: false ; journal id: ns1
2020-12-03 07:19:45,320 [IPC Server handler 4 on default port 36507] INFO  server.Journal (Journal.java:getSegmentInfo(807)) - getSegmentInfo(8): EditLogFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/current/edits_0000000000000000008-0000000000000000014,first=0000000000000000008,last=0000000000000000014,inProgress=false,hasCorruptHeader=false) -> startTxId: 8 endTxId: 14 isInProgress: false ; journal id: ns1
2020-12-03 07:19:45,320 [IPC Server handler 4 on default port 32907] INFO  server.Journal (Journal.java:prepareRecovery(851)) - Prepared recovery for segment 8: segmentState { startTxId: 8 endTxId: 14 isInProgress: false } lastWriterEpoch: 3 lastCommittedTxId: 14 ; journal id: ns1
2020-12-03 07:19:45,320 [IPC Server handler 0 on default port 38894] INFO  server.Journal (Journal.java:prepareRecovery(851)) - Prepared recovery for segment 8: segmentState { startTxId: 8 endTxId: 14 isInProgress: false } lastWriterEpoch: 3 lastCommittedTxId: 14 ; journal id: ns1
2020-12-03 07:19:45,320 [IPC Server handler 4 on default port 36507] INFO  server.Journal (Journal.java:prepareRecovery(851)) - Prepared recovery for segment 8: segmentState { startTxId: 8 endTxId: 14 isInProgress: false } lastWriterEpoch: 3 lastCommittedTxId: 14 ; journal id: ns1
2020-12-03 07:19:45,322 [Listener at localhost/10356] INFO  client.QuorumJournalManager (QuorumJournalManager.java:recoverUnclosedSegment(322)) - Recovery prepare phase complete. Responses:
127.0.0.1:32907: segmentState { startTxId: 8 endTxId: 14 isInProgress: false } lastWriterEpoch: 3 lastCommittedTxId: 14
127.0.0.1:36507: segmentState { startTxId: 8 endTxId: 14 isInProgress: false } lastWriterEpoch: 3 lastCommittedTxId: 14
2020-12-03 07:19:45,323 [Edit log tailer] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(188)) - Loaded 1 edits file(s) (the last named ByteStringEditLog[8, 14], ByteStringEditLog[8, 14], ByteStringEditLog[8, 14]) of total size 418.0, total edits 7.0, total load time 4.0 ms
2020-12-03 07:19:45,323 [Listener at localhost/10356] INFO  client.QuorumJournalManager (QuorumJournalManager.java:recoverUnclosedSegment(346)) - Using longest log: 127.0.0.1:32907=segmentState {
  startTxId: 8
  endTxId: 14
  isInProgress: false
}
lastWriterEpoch: 3
lastCommittedTxId: 14

2020-12-03 07:19:45,324 [IPC Server handler 1 on default port 32907] INFO  server.Journal (Journal.java:getSegmentInfo(807)) - getSegmentInfo(8): EditLogFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1/current/edits_0000000000000000008-0000000000000000014,first=0000000000000000008,last=0000000000000000014,inProgress=false,hasCorruptHeader=false) -> startTxId: 8 endTxId: 14 isInProgress: false ; journal id: ns1
2020-12-03 07:19:45,324 [IPC Server handler 2 on default port 38894] INFO  server.Journal (Journal.java:getSegmentInfo(807)) - getSegmentInfo(8): EditLogFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1/current/edits_0000000000000000008-0000000000000000014,first=0000000000000000008,last=0000000000000000014,inProgress=false,hasCorruptHeader=false) -> startTxId: 8 endTxId: 14 isInProgress: false ; journal id: ns1
2020-12-03 07:19:45,324 [IPC Server handler 2 on default port 36507] INFO  server.Journal (Journal.java:getSegmentInfo(807)) - getSegmentInfo(8): EditLogFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/current/edits_0000000000000000008-0000000000000000014,first=0000000000000000008,last=0000000000000000014,inProgress=false,hasCorruptHeader=false) -> startTxId: 8 endTxId: 14 isInProgress: false ; journal id: ns1
2020-12-03 07:19:45,325 [IPC Server handler 2 on default port 38894] INFO  server.Journal (Journal.java:acceptRecovery(939)) - Skipping download of log startTxId: 8 endTxId: 14 isInProgress: false: already have up-to-date logs ; journal id: ns1
2020-12-03 07:19:45,324 [IPC Server handler 1 on default port 32907] INFO  server.Journal (Journal.java:acceptRecovery(939)) - Skipping download of log startTxId: 8 endTxId: 14 isInProgress: false: already have up-to-date logs ; journal id: ns1
2020-12-03 07:19:45,325 [IPC Server handler 2 on default port 36507] INFO  server.Journal (Journal.java:acceptRecovery(939)) - Skipping download of log startTxId: 8 endTxId: 14 isInProgress: false: already have up-to-date logs ; journal id: ns1
2020-12-03 07:19:45,357 [IPC Server handler 1 on default port 32907] INFO  server.Journal (Journal.java:acceptRecovery(972)) - Accepted recovery for segment 8: segmentState { startTxId: 8 endTxId: 14 isInProgress: false } acceptedInEpoch: 4 ; journal id: ns1
2020-12-03 07:19:45,357 [IPC Server handler 2 on default port 36507] INFO  server.Journal (Journal.java:acceptRecovery(972)) - Accepted recovery for segment 8: segmentState { startTxId: 8 endTxId: 14 isInProgress: false } acceptedInEpoch: 4 ; journal id: ns1
2020-12-03 07:19:45,357 [IPC Server handler 2 on default port 38894] INFO  server.Journal (Journal.java:acceptRecovery(972)) - Accepted recovery for segment 8: segmentState { startTxId: 8 endTxId: 14 isInProgress: false } acceptedInEpoch: 4 ; journal id: ns1
2020-12-03 07:19:45,359 [Listener at localhost/10356] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-12-03 07:19:45,360 [Listener at localhost/10356] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-12-03 07:19:45,360 [Listener at localhost/10356] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1233)) - Catching up to latest edits from old active before taking over writer role in edits logs
2020-12-03 07:19:45,362 [Listener at localhost/10356] INFO  client.QuorumJournalManager (QuorumJournalManager.java:selectRpcInputStreams(592)) - Selected loggers with >= 1 transactions starting from lowest txn ID 14.0
2020-12-03 07:19:45,362 [Listener at localhost/10356] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file ByteStringEditLog[14, 14], ByteStringEditLog[14, 14] maxTxnsToRead = 9223372036854775807
2020-12-03 07:19:45,363 [Listener at localhost/10356] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream 'ByteStringEditLog[14, 14], ByteStringEditLog[14, 14]' to transaction ID 14
2020-12-03 07:19:45,363 [Listener at localhost/10356] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream 'ByteStringEditLog[14, 14]' to transaction ID 14
2020-12-03 07:19:45,363 [Listener at localhost/10356] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(188)) - Loaded 1 edits file(s) (the last named ByteStringEditLog[14, 14], ByteStringEditLog[14, 14]) of total size 25.0, total edits 1.0, total load time 0.0 ms
2020-12-03 07:19:45,364 [Listener at localhost/10356] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:markAllDatanodesStale(1840)) - Marking all datanodes as stale
2020-12-03 07:19:45,364 [Listener at localhost/10356] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1244)) - Reprocessing replication and invalidation queues
2020-12-03 07:19:45,364 [Listener at localhost/10356] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:19:45,364 [Listener at localhost/10356] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1255)) - Will take over writing edit logs at txnid 15
2020-12-03 07:19:45,365 [Listener at localhost/10356] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 15
2020-12-03 07:19:45,366 [IPC Server handler 1 on default port 32907] INFO  server.Journal (Journal.java:startLogSegment(609)) - Updating lastWriterEpoch from 3 to 4 for client /127.0.0.1 ; journal id: ns1
2020-12-03 07:19:45,366 [IPC Server handler 2 on default port 38894] INFO  server.Journal (Journal.java:startLogSegment(609)) - Updating lastWriterEpoch from 3 to 4 for client /127.0.0.1 ; journal id: ns1
2020-12-03 07:19:45,366 [IPC Server handler 2 on default port 36507] INFO  server.Journal (Journal.java:startLogSegment(609)) - Updating lastWriterEpoch from 3 to 4 for client /127.0.0.1 ; journal id: ns1
2020-12-03 07:19:45,421 [Listener at localhost/10356] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:19:45,422 [Listener at localhost/10356] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 1 milliseconds
name space=3
storage space=6
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:19:45,424 [CacheReplicationMonitor(2097924469)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:19:45,425 [Edit log tailer] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file ByteStringEditLog[15, 15], ByteStringEditLog[15, 15], ByteStringEditLog[15, 15] maxTxnsToRead = 9223372036854775807
2020-12-03 07:19:45,425 [Edit log tailer] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream 'ByteStringEditLog[15, 15], ByteStringEditLog[15, 15], ByteStringEditLog[15, 15]' to transaction ID 15
2020-12-03 07:19:45,425 [Edit log tailer] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream 'ByteStringEditLog[15, 15]' to transaction ID 15
2020-12-03 07:19:45,426 [Edit log tailer] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(188)) - Loaded 1 edits file(s) (the last named ByteStringEditLog[15, 15], ByteStringEditLog[15, 15], ByteStringEditLog[15, 15]) of total size 25.0, total edits 1.0, total load time 1.0 ms
2020-12-03 07:19:45,426 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:19:45,426 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:19:45,427 [Listener at localhost/10356] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:19:45,429 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@2a2da905] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:19:45,429 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 2
2020-12-03 07:19:45,431 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:19:45,431 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:19:45,431 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:19:45,431 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:19:45,431 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 66 msec
2020-12-03 07:19:45,453 [Listener at localhost/10356] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@56db847e{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:19:45,454 [Listener at localhost/10356] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@740abb5{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:19:45,454 [Listener at localhost/10356] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@43ed0ff3{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:19:45,455 [Listener at localhost/10356] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@e6516e{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:19:45,456 [Listener at localhost/10356] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 44842
2020-12-03 07:19:45,457 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:19:45,457 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:19:45,458 [BP-1018250855-172.17.0.10-1606979973945 heartbeating to localhost/127.0.0.1:10356] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:19:45,458 [BP-1018250855-172.17.0.10-1606979973945 heartbeating to localhost/127.0.0.1:10354] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:19:45,458 [BP-1018250855-172.17.0.10-1606979973945 heartbeating to localhost/127.0.0.1:10352] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:19:45,459 [BP-1018250855-172.17.0.10-1606979973945 heartbeating to localhost/127.0.0.1:10354] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1018250855-172.17.0.10-1606979973945 (Datanode Uuid ffc0a714-d6ed-4515-b5ec-f51ece94380e) service to localhost/127.0.0.1:10354
2020-12-03 07:19:45,459 [BP-1018250855-172.17.0.10-1606979973945 heartbeating to localhost/127.0.0.1:10356] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1018250855-172.17.0.10-1606979973945 (Datanode Uuid ffc0a714-d6ed-4515-b5ec-f51ece94380e) service to localhost/127.0.0.1:10356
2020-12-03 07:19:45,459 [BP-1018250855-172.17.0.10-1606979973945 heartbeating to localhost/127.0.0.1:10352] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1018250855-172.17.0.10-1606979973945 (Datanode Uuid ffc0a714-d6ed-4515-b5ec-f51ece94380e) service to localhost/127.0.0.1:10352
2020-12-03 07:19:45,460 [BP-1018250855-172.17.0.10-1606979973945 heartbeating to localhost/127.0.0.1:10352] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1018250855-172.17.0.10-1606979973945 (Datanode Uuid ffc0a714-d6ed-4515-b5ec-f51ece94380e)
2020-12-03 07:19:45,460 [BP-1018250855-172.17.0.10-1606979973945 heartbeating to localhost/127.0.0.1:10352] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1018250855-172.17.0.10-1606979973945
2020-12-03 07:19:45,460 [Edit log tailer] INFO  client.QuorumJournalManager (QuorumJournalManager.java:selectRpcInputStreams(592)) - Selected loggers with >= 1 transactions starting from lowest txn ID 15.0
2020-12-03 07:19:45,461 [Edit log tailer] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file ByteStringEditLog[15, 15], ByteStringEditLog[15, 15] maxTxnsToRead = 9223372036854775807
2020-12-03 07:19:45,461 [Edit log tailer] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream 'ByteStringEditLog[15, 15], ByteStringEditLog[15, 15]' to transaction ID 15
2020-12-03 07:19:45,461 [Edit log tailer] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream 'ByteStringEditLog[15, 15]' to transaction ID 15
2020-12-03 07:19:45,462 [Edit log tailer] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(188)) - Loaded 1 edits file(s) (the last named ByteStringEditLog[15, 15], ByteStringEditLog[15, 15]) of total size 25.0, total edits 1.0, total load time 1.0 ms
2020-12-03 07:19:45,462 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1018250855-172.17.0.10-1606979973945] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:19:45,462 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1018250855-172.17.0.10-1606979973945] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:19:45,467 [Listener at localhost/10356] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:19:45,467 [Listener at localhost/10356] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:19:45,468 [Listener at localhost/10356] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:19:45,468 [Listener at localhost/10356] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:19:45,470 [Listener at localhost/10356] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:19:45,471 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:19:45,471 [Listener at localhost/10356] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:19:45,471 [Listener at localhost/10356] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 15, 15
2020-12-03 07:19:45,471 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@256a1825] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:19:45,471 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@29a4f594] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:19:45,476 [Listener at localhost/10356] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 2 Total time for transactions(ms): 4 Number of transactions batched in Syncs: 7 Number of syncs: 2 SyncTimes(ms): 4 2 1 
2020-12-03 07:19:45,477 [IPC Server handler 2 on default port 36507] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/current/edits_inprogress_0000000000000000015 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1/current/edits_0000000000000000015-0000000000000000016
2020-12-03 07:19:45,477 [IPC Server handler 1 on default port 32907] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1/current/edits_inprogress_0000000000000000015 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1/current/edits_0000000000000000015-0000000000000000016
2020-12-03 07:19:45,477 [IPC Server handler 2 on default port 38894] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1/current/edits_inprogress_0000000000000000015 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1/current/edits_0000000000000000015-0000000000000000016
2020-12-03 07:19:45,478 [Listener at localhost/10356] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000015 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000015-0000000000000000016
2020-12-03 07:19:45,479 [Listener at localhost/10356] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000015 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000015-0000000000000000016
2020-12-03 07:19:45,479 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:19:45,479 [CacheReplicationMonitor(2097924469)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:19:45,480 [Listener at localhost/10356] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 10352
2020-12-03 07:19:45,483 [IPC Server listener on 10352] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 10352
2020-12-03 07:19:45,483 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:19:45,484 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:19:45,484 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:19:45,492 [Listener at localhost/10356] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:19:45,493 [Listener at localhost/10356] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:19:45,494 [Listener at localhost/10356] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@73a00e09{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:19:45,496 [Listener at localhost/10356] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@26dcd8c0{HTTP/1.1,[http/1.1]}{localhost:10353}
2020-12-03 07:19:45,496 [Listener at localhost/10356] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2571066a{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:19:45,497 [Listener at localhost/10356] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@25d3cfc8{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:19:45,501 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:19:45,501 [Listener at localhost/10356] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:19:45,502 [Edit log tailer] WARN  ha.EditLogTailer (EditLogTailer.java:doWork(528)) - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.sleep(EditLogTailer.java:433)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:526)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:440)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:457)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:484)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:453)
2020-12-03 07:19:45,502 [Listener at localhost/10356] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 10354
2020-12-03 07:19:45,510 [IPC Server listener on 10354] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 10354
2020-12-03 07:19:45,510 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:19:45,513 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:19:45,513 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:19:45,524 [Listener at localhost/10356] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:19:45,524 [Listener at localhost/10356] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:19:45,528 [Listener at localhost/10356] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@49dbaaf3{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:19:45,528 [Edit log tailer] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file ByteStringEditLog[16, 16], ByteStringEditLog[16, 16] maxTxnsToRead = 9223372036854775807
2020-12-03 07:19:45,528 [Edit log tailer] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream 'ByteStringEditLog[16, 16], ByteStringEditLog[16, 16]' to transaction ID 16
2020-12-03 07:19:45,528 [Edit log tailer] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream 'ByteStringEditLog[16, 16]' to transaction ID 16
2020-12-03 07:19:45,529 [Edit log tailer] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(188)) - Loaded 1 edits file(s) (the last named ByteStringEditLog[16, 16], ByteStringEditLog[16, 16]) of total size 25.0, total edits 1.0, total load time 1.0 ms
2020-12-03 07:19:45,529 [Listener at localhost/10356] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@22d9c961{HTTP/1.1,[http/1.1]}{localhost:10355}
2020-12-03 07:19:45,530 [Listener at localhost/10356] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@293cde83{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:19:45,530 [Listener at localhost/10356] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4abf3f0{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:19:45,535 [Listener at localhost/10356] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:19:45,535 [Listener at localhost/10356] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:19:45,536 [Edit log tailer] WARN  ha.EditLogTailer (EditLogTailer.java:doWork(528)) - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.sleep(EditLogTailer.java:433)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:526)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:440)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:457)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:484)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:453)
2020-12-03 07:19:45,537 [Listener at localhost/10356] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 10356
2020-12-03 07:19:45,539 [IPC Server listener on 10356] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 10356
2020-12-03 07:19:45,539 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:19:45,539 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:19:45,539 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:19:45,550 [Listener at localhost/10356] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:19:45,552 [Listener at localhost/10356] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:19:45,554 [Listener at localhost/10356] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5c645b43{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:19:45,555 [Listener at localhost/10356] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6bd16207{HTTP/1.1,[http/1.1]}{localhost:10357}
2020-12-03 07:19:45,556 [Listener at localhost/10356] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6124287a{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:19:45,556 [Listener at localhost/10356] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5631962{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:19:45,566 [Listener at localhost/10356] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 38894
2020-12-03 07:19:45,567 [org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer$$Lambda$29/1889663586@262e5319] ERROR server.JournalNodeSyncer (JournalNodeSyncer.java:lambda$startSyncJournalsDaemon$0(171)) - JournalNodeSyncer daemon received Runtime exception.
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer.lambda$startSyncJournalsDaemon$0(JournalNodeSyncer.java:169)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:45,567 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:19:45,567 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:19:45,568 [Listener at localhost/10356] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@65c7a252{/,null,UNAVAILABLE}{/journal}
2020-12-03 07:19:45,570 [Listener at localhost/10356] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@1ffaf86{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:19:45,570 [Listener at localhost/10356] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@27ff5d15{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:19:45,570 [Listener at localhost/10356] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5ace1ed4{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:19:45,571 [Listener at localhost/10356] INFO  common.Storage (JNStorage.java:close(283)) - Closing journal storage for Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/waitactive; location= null
2020-12-03 07:19:45,571 [Listener at localhost/10356] INFO  common.Storage (JNStorage.java:close(283)) - Closing journal storage for Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-0/ns1; location= null
2020-12-03 07:19:45,572 [Listener at localhost/10356] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 36507
2020-12-03 07:19:45,572 [org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer$$Lambda$29/1889663586@4418d306] ERROR server.JournalNodeSyncer (JournalNodeSyncer.java:lambda$startSyncJournalsDaemon$0(171)) - JournalNodeSyncer daemon received Runtime exception.
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer.lambda$startSyncJournalsDaemon$0(JournalNodeSyncer.java:169)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:45,572 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:19:45,573 [Listener at localhost/10356] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@3af0a9da{/,null,UNAVAILABLE}{/journal}
2020-12-03 07:19:45,573 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:19:45,575 [Listener at localhost/10356] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@43b9fd5{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:19:45,575 [Listener at localhost/10356] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3561c410{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:19:45,575 [Listener at localhost/10356] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7ceb3185{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:19:45,576 [Listener at localhost/10356] INFO  common.Storage (JNStorage.java:close(283)) - Closing journal storage for Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/waitactive; location= null
2020-12-03 07:19:45,576 [Listener at localhost/10356] INFO  common.Storage (JNStorage.java:close(283)) - Closing journal storage for Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-1/ns1; location= null
2020-12-03 07:19:45,576 [Listener at localhost/10356] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 32907
2020-12-03 07:19:45,577 [org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer$$Lambda$29/1889663586@2fccbc7d] ERROR server.JournalNodeSyncer (JournalNodeSyncer.java:lambda$startSyncJournalsDaemon$0(171)) - JournalNodeSyncer daemon received Runtime exception.
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.qjournal.server.JournalNodeSyncer.lambda$startSyncJournalsDaemon$0(JournalNodeSyncer.java:169)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:19:45,577 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:19:45,577 [Listener at localhost/10356] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6bc407fd{/,null,UNAVAILABLE}{/journal}
2020-12-03 07:19:45,578 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:19:45,579 [Listener at localhost/10356] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@291f18{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:19:45,579 [Listener at localhost/10356] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@44d52de2{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:19:45,580 [Listener at localhost/10356] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4ebff610{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:19:45,580 [Listener at localhost/10356] INFO  common.Storage (JNStorage.java:close(283)) - Closing journal storage for Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/waitactive; location= null
2020-12-03 07:19:45,580 [Listener at localhost/10356] INFO  common.Storage (JNStorage.java:close(283)) - Closing journal storage for Storage Directory root= /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/journalnode-2/ns1; location= null
2020-12-03 07:19:45,582 [Listener at localhost/10356] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping NameNode metrics system...
2020-12-03 07:19:45,584 [Listener at localhost/10356] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - NameNode metrics system stopped.
2020-12-03 07:19:45,584 [Listener at localhost/10356] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - NameNode metrics system shutdown complete.
msx-rc 0
