2020-12-03 07:23:15,012 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=4, numDataNodes=4
2020-12-03 07:23:15,049 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:initMiniDFSCluster(875)) - MiniDFSCluster disabling checkpointing in the Standby node since no HTTP ports have been specified.
2020-12-03 07:23:15,050 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:initMiniDFSCluster(881)) - MiniDFSCluster disabling log-roll triggering in the Standby node since no IPC ports have been specified.
Formatting using clusterid: testClusterID
2020-12-03 07:23:15,796 [JUnit] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:23:15,811 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:23:15,813 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:23:15,814 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:23:15,822 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:23:15,822 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:23:15,822 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:23:15,827 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns0
2020-12-03 07:23:15,828 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: true
2020-12-03 07:23:15,887 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:15,893 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2020-12-03 07:23:15,893 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:23:15,894 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:23:15,901 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:23:15,902 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:23:15
2020-12-03 07:23:15,904 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:23:15,905 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:15,907 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-12-03 07:23:15,907 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:23:15,930 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:23:15,931 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:23:15,940 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:23:15,941 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:23:15,941 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:23:15,941 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:23:15,942 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:23:15,942 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:23:15,943 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:23:15,943 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:23:15,943 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:23:15,944 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:23:15,944 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:23:15,984 [JUnit] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GLOBAL serial map: bits=29 maxEntries=536870911
2020-12-03 07:23:15,985 [JUnit] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - USER serial map: bits=24 maxEntries=16777215
2020-12-03 07:23:15,985 [JUnit] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GROUP serial map: bits=24 maxEntries=16777215
2020-12-03 07:23:15,986 [JUnit] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - XATTR serial map: bits=24 maxEntries=16777215
2020-12-03 07:23:16,008 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:23:16,009 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:16,010 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-12-03 07:23:16,010 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:23:16,018 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:23:16,018 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:23:16,019 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:23:16,019 [JUnit] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:23:16,028 [JUnit] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:23:16,031 [JUnit] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:23:16,037 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:23:16,037 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:16,038 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-12-03 07:23:16,038 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:23:16,053 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:23:16,054 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:23:16,054 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:23:16,061 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:23:16,062 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:23:16,066 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:23:16,066 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:16,067 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-12-03 07:23:16,067 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:23:16,110 [JUnit] INFO  namenode.FSImage (FSImage.java:format(185)) - Allocated new BlockPoolId: BP-2036634619-172.17.0.2-1606980196096
2020-12-03 07:23:16,224 [JUnit] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-12-03 07:23:16,300 [JUnit] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-12-03 07:23:16,352 [JUnit] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-0-through-1 has been successfully formatted.
2020-12-03 07:23:16,399 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:23:16,399 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:23:16,551 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:23:16,551 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:23:16,628 [JUnit] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-12-03 07:23:16,709 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:copyNameDirs(1264)) - Copying namedir from primary node dir file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1 to file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-3
2020-12-03 07:23:16,732 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:copyNameDirs(1264)) - Copying namedir from primary node dir file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1 to file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-4
2020-12-03 07:23:16,739 [JUnit] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:23:16,962 [JUnit] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-namenode.properties,hadoop-metrics2.properties
2020-12-03 07:23:17,052 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2020-12-03 07:23:17,052 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:23:17,060 [JUnit] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://ns0
2020-12-03 07:23:17,060 [JUnit] INFO  namenode.NameNode (NameNode.java:<init>(944)) - Clients should use ns0 to access this namenode/service.
2020-12-03 07:23:17,102 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@239105a8] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:17,117 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:23:17,137 [JUnit] INFO  util.log (Log.java:initialized(192)) - Logging initialized @3162ms
2020-12-03 07:23:17,252 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:17,256 [JUnit] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:23:17,266 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:17,269 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:23:17,270 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:17,270 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:17,301 [JUnit] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:23:17,301 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:23:17,312 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 37939
2020-12-03 07:23:17,314 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:17,361 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@78d6692f{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:23:17,362 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@27216cd{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:23:17,684 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@71529963{/,file:///tmp/jetty-localhost-37939-hdfs-_-any-2643863139052326460.dir/webapp/,AVAILABLE}{/hdfs}
2020-12-03 07:23:17,692 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@41d426b5{HTTP/1.1,[http/1.1]}{localhost:37939}
2020-12-03 07:23:17,693 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @3717ms
2020-12-03 07:23:17,703 [JUnit] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:23:17,704 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:23:17,704 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:23:17,704 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:23:17,704 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:23:17,705 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:23:17,705 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:23:17,706 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns0
2020-12-03 07:23:17,706 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: true
2020-12-03 07:23:17,706 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:17,707 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:23:17,707 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:23:17,708 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:23:17,708 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:23:17
2020-12-03 07:23:17,708 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:23:17,709 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:17,709 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:23:17,709 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:23:17,715 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:23:17,716 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:23:17,716 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:23:17,717 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:23:17,717 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:23:17,717 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:23:17,718 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:23:17,718 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:23:17,718 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:23:17,718 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:23:17,718 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:23:17,718 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:23:17,719 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:23:17,719 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:23:17,720 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:17,720 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:23:17,720 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:23:17,723 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:23:17,723 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:23:17,723 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:23:17,723 [JUnit] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:23:17,724 [JUnit] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:23:17,724 [JUnit] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:23:17,724 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:23:17,724 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:17,724 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:23:17,725 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:23:17,727 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:23:17,727 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:23:17,727 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:23:17,728 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:23:17,728 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:23:17,728 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:23:17,728 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:17,729 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:23:17,729 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:23:17,787 [JUnit] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 9387@7a5505b8915a
2020-12-03 07:23:17,893 [JUnit] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 9387@7a5505b8915a
2020-12-03 07:23:17,894 [JUnit] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-0-through-1
2020-12-03 07:23:17,898 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:23:17,898 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:23:17,930 [JUnit] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:23:17,937 [JUnit] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:23:17,937 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-12-03 07:23:17,943 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2020-12-03 07:23:17,943 [JUnit] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:23:17,943 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 212 msecs
2020-12-03 07:23:18,134 [JUnit] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to 0.0.0.0:0
2020-12-03 07:23:18,185 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:18,200 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:18,494 [Listener at 0.0.0.0/42380] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:23:18,517 [Listener at 0.0.0.0/42380] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:23:18,532 [Listener at 0.0.0.0/42380] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:23:18,532 [Listener at 0.0.0.0/42380] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:23:18,533 [Listener at 0.0.0.0/42380] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:23:18,567 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:18,568 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:18,571 [Listener at 0.0.0.0/42380] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:42380
2020-12-03 07:23:18,573 [Listener at 0.0.0.0/42380] INFO  namenode.FSNamesystem (FSNamesystem.java:startStandbyServices(1391)) - Starting services required for standby state
2020-12-03 07:23:18,575 [Listener at 0.0.0.0/42380] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.log-roll.period(-1) assuming SECONDS
2020-12-03 07:23:18,575 [Listener at 0.0.0.0/42380] INFO  ha.EditLogTailer (EditLogTailer.java:<init>(208)) - Not going to trigger log rolls on active node because dfs.ha.log-roll.period is negative.
2020-12-03 07:23:18,575 [Listener at 0.0.0.0/42380] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.period.backoff-max(0) assuming SECONDS
2020-12-03 07:23:18,575 [Listener at 0.0.0.0/42380] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.rolledits.timeout(60) assuming SECONDS
2020-12-03 07:23:18,578 [Listener at 0.0.0.0/42380] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:23:18,578 [Listener at 0.0.0.0/42380] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-12-03 07:23:18,579 [Listener at 0.0.0.0/42380] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://ns0
2020-12-03 07:23:18,579 [Listener at 0.0.0.0/42380] INFO  namenode.NameNode (NameNode.java:<init>(944)) - Clients should use ns0 to access this namenode/service.
2020-12-03 07:23:18,590 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5af9926a] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:18,590 [Listener at 0.0.0.0/42380] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:23:18,593 [Listener at 0.0.0.0/42380] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:18,594 [Listener at 0.0.0.0/42380] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:23:18,597 [Listener at 0.0.0.0/42380] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:18,598 [Listener at 0.0.0.0/42380] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:23:18,598 [Listener at 0.0.0.0/42380] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:18,598 [Listener at 0.0.0.0/42380] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:18,601 [Listener at 0.0.0.0/42380] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:23:18,601 [Listener at 0.0.0.0/42380] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:23:18,602 [Listener at 0.0.0.0/42380] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 43596
2020-12-03 07:23:18,603 [Listener at 0.0.0.0/42380] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:18,624 [Listener at 0.0.0.0/42380] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@69adf72c{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:23:18,625 [Listener at 0.0.0.0/42380] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1a15b789{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:23:18,816 [Listener at 0.0.0.0/42380] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@70e0accd{/,file:///tmp/jetty-localhost-43596-hdfs-_-any-3883674758233725816.dir/webapp/,AVAILABLE}{/hdfs}
2020-12-03 07:23:18,818 [Listener at 0.0.0.0/42380] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7957dc72{HTTP/1.1,[http/1.1]}{localhost:43596}
2020-12-03 07:23:18,818 [Listener at 0.0.0.0/42380] INFO  server.Server (Server.java:doStart(419)) - Started @4843ms
2020-12-03 07:23:18,824 [Listener at 0.0.0.0/42380] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:23:18,825 [Listener at 0.0.0.0/42380] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:23:18,825 [Listener at 0.0.0.0/42380] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:23:18,825 [Listener at 0.0.0.0/42380] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:23:18,826 [Listener at 0.0.0.0/42380] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:23:18,826 [Listener at 0.0.0.0/42380] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:23:18,826 [Listener at 0.0.0.0/42380] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:23:18,827 [Listener at 0.0.0.0/42380] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns0
2020-12-03 07:23:18,827 [Listener at 0.0.0.0/42380] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: true
2020-12-03 07:23:18,828 [Listener at 0.0.0.0/42380] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:18,828 [Listener at 0.0.0.0/42380] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:23:18,829 [Listener at 0.0.0.0/42380] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:23:18,829 [Listener at 0.0.0.0/42380] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:23:18,830 [Listener at 0.0.0.0/42380] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:23:18
2020-12-03 07:23:18,830 [Listener at 0.0.0.0/42380] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:23:18,830 [Listener at 0.0.0.0/42380] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:18,831 [Listener at 0.0.0.0/42380] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:23:18,831 [Listener at 0.0.0.0/42380] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:23:18,843 [Listener at 0.0.0.0/42380] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:23:18,843 [Listener at 0.0.0.0/42380] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:23:18,844 [Listener at 0.0.0.0/42380] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:23:18,844 [Listener at 0.0.0.0/42380] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:23:18,844 [Listener at 0.0.0.0/42380] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:23:18,845 [Listener at 0.0.0.0/42380] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:23:18,845 [Listener at 0.0.0.0/42380] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:23:18,845 [Listener at 0.0.0.0/42380] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:23:18,845 [Listener at 0.0.0.0/42380] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:23:18,846 [Listener at 0.0.0.0/42380] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:23:18,847 [Listener at 0.0.0.0/42380] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:23:18,847 [Listener at 0.0.0.0/42380] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:23:18,847 [Listener at 0.0.0.0/42380] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:23:18,848 [Listener at 0.0.0.0/42380] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:23:18,848 [Listener at 0.0.0.0/42380] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:18,848 [Listener at 0.0.0.0/42380] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:23:18,849 [Listener at 0.0.0.0/42380] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:23:18,856 [Listener at 0.0.0.0/42380] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:23:18,857 [Listener at 0.0.0.0/42380] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:23:18,857 [Listener at 0.0.0.0/42380] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:23:18,857 [Listener at 0.0.0.0/42380] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:23:18,857 [Listener at 0.0.0.0/42380] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:23:18,858 [Listener at 0.0.0.0/42380] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:23:18,858 [Listener at 0.0.0.0/42380] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:23:18,858 [Listener at 0.0.0.0/42380] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:18,859 [Listener at 0.0.0.0/42380] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:23:18,859 [Listener at 0.0.0.0/42380] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:23:18,861 [Listener at 0.0.0.0/42380] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:23:18,862 [Listener at 0.0.0.0/42380] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:23:18,862 [Listener at 0.0.0.0/42380] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:23:18,862 [Listener at 0.0.0.0/42380] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:23:18,862 [Listener at 0.0.0.0/42380] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:23:18,863 [Listener at 0.0.0.0/42380] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:23:18,863 [Listener at 0.0.0.0/42380] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:18,864 [Listener at 0.0.0.0/42380] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:23:18,864 [Listener at 0.0.0.0/42380] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:23:18,893 [Listener at 0.0.0.0/42380] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-3/in_use.lock acquired by nodename 9387@7a5505b8915a
2020-12-03 07:23:18,935 [Listener at 0.0.0.0/42380] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-4/in_use.lock acquired by nodename 9387@7a5505b8915a
2020-12-03 07:23:18,936 [Listener at 0.0.0.0/42380] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-0-through-1
2020-12-03 07:23:18,939 [Listener at 0.0.0.0/42380] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:23:18,939 [Listener at 0.0.0.0/42380] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-3/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:23:18,941 [Listener at 0.0.0.0/42380] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:23:18,943 [Listener at 0.0.0.0/42380] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:23:18,943 [Listener at 0.0.0.0/42380] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-3/current/fsimage_0000000000000000000
2020-12-03 07:23:18,943 [Listener at 0.0.0.0/42380] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2020-12-03 07:23:18,944 [Listener at 0.0.0.0/42380] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:23:18,944 [Listener at 0.0.0.0/42380] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 77 msecs
2020-12-03 07:23:18,944 [Listener at 0.0.0.0/42380] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to 0.0.0.0:0
2020-12-03 07:23:18,945 [Listener at 0.0.0.0/42380] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:18,946 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:18,951 [Listener at 0.0.0.0/41178] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:23:18,973 [Listener at 0.0.0.0/41178] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:23:18,976 [Listener at 0.0.0.0/41178] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:23:18,976 [Listener at 0.0.0.0/41178] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:23:18,976 [Listener at 0.0.0.0/41178] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:23:18,991 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:18,991 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:18,996 [Listener at 0.0.0.0/41178] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:41178
2020-12-03 07:23:18,997 [Listener at 0.0.0.0/41178] INFO  namenode.FSNamesystem (FSNamesystem.java:startStandbyServices(1391)) - Starting services required for standby state
2020-12-03 07:23:18,997 [Listener at 0.0.0.0/41178] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.log-roll.period(-1) assuming SECONDS
2020-12-03 07:23:18,998 [Listener at 0.0.0.0/41178] INFO  ha.EditLogTailer (EditLogTailer.java:<init>(208)) - Not going to trigger log rolls on active node because dfs.ha.log-roll.period is negative.
2020-12-03 07:23:18,998 [Listener at 0.0.0.0/41178] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.period.backoff-max(0) assuming SECONDS
2020-12-03 07:23:18,998 [Listener at 0.0.0.0/41178] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.rolledits.timeout(60) assuming SECONDS
Formatting using clusterid: testClusterID
2020-12-03 07:23:19,014 [Listener at 0.0.0.0/41178] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:23:19,015 [Listener at 0.0.0.0/41178] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:23:19,015 [Listener at 0.0.0.0/41178] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:23:19,015 [Listener at 0.0.0.0/41178] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:23:19,016 [Listener at 0.0.0.0/41178] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:23:19,016 [Listener at 0.0.0.0/41178] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:23:19,016 [Listener at 0.0.0.0/41178] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:23:19,017 [Listener at 0.0.0.0/41178] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns1
2020-12-03 07:23:19,017 [Listener at 0.0.0.0/41178] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: true
2020-12-03 07:23:19,018 [Listener at 0.0.0.0/41178] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:19,019 [Listener at 0.0.0.0/41178] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:23:19,019 [Listener at 0.0.0.0/41178] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:23:19,020 [Listener at 0.0.0.0/41178] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:23:19,020 [Listener at 0.0.0.0/41178] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:23:19
2020-12-03 07:23:19,021 [Listener at 0.0.0.0/41178] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:23:19,021 [Listener at 0.0.0.0/41178] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:19,021 [Listener at 0.0.0.0/41178] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:23:19,021 [Listener at 0.0.0.0/41178] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:23:19,034 [Listener at 0.0.0.0/41178] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:23:19,034 [Listener at 0.0.0.0/41178] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:23:19,035 [Listener at 0.0.0.0/41178] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:23:19,035 [Listener at 0.0.0.0/41178] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:23:19,035 [Listener at 0.0.0.0/41178] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:23:19,036 [Listener at 0.0.0.0/41178] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:23:19,036 [Listener at 0.0.0.0/41178] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:23:19,036 [Listener at 0.0.0.0/41178] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:23:19,036 [Listener at 0.0.0.0/41178] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:23:19,036 [Listener at 0.0.0.0/41178] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:23:19,036 [Listener at 0.0.0.0/41178] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:23:19,037 [Listener at 0.0.0.0/41178] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:23:19,037 [Listener at 0.0.0.0/41178] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:23:19,037 [Listener at 0.0.0.0/41178] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:23:19,038 [Listener at 0.0.0.0/41178] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:19,038 [Listener at 0.0.0.0/41178] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:23:19,038 [Listener at 0.0.0.0/41178] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:23:19,044 [Listener at 0.0.0.0/41178] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:23:19,045 [Listener at 0.0.0.0/41178] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:23:19,045 [Listener at 0.0.0.0/41178] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:23:19,045 [Listener at 0.0.0.0/41178] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:23:19,045 [Listener at 0.0.0.0/41178] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:23:19,045 [Listener at 0.0.0.0/41178] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:23:19,046 [Listener at 0.0.0.0/41178] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:23:19,046 [Listener at 0.0.0.0/41178] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:19,046 [Listener at 0.0.0.0/41178] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:23:19,046 [Listener at 0.0.0.0/41178] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:23:19,048 [Listener at 0.0.0.0/41178] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:23:19,048 [Listener at 0.0.0.0/41178] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:23:19,049 [Listener at 0.0.0.0/41178] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:23:19,049 [Listener at 0.0.0.0/41178] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:23:19,049 [Listener at 0.0.0.0/41178] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:23:19,049 [Listener at 0.0.0.0/41178] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:23:19,049 [Listener at 0.0.0.0/41178] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:19,050 [Listener at 0.0.0.0/41178] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:23:19,050 [Listener at 0.0.0.0/41178] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:23:19,054 [Listener at 0.0.0.0/41178] INFO  namenode.FSImage (FSImage.java:format(185)) - Allocated new BlockPoolId: BP-286010920-172.17.0.2-1606980199054
2020-12-03 07:23:19,103 [Listener at 0.0.0.0/41178] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5 has been successfully formatted.
2020-12-03 07:23:19,163 [Listener at 0.0.0.0/41178] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6 has been successfully formatted.
2020-12-03 07:23:19,223 [Listener at 0.0.0.0/41178] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-2-through-3 has been successfully formatted.
2020-12-03 07:23:19,236 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:23:19,236 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:23:19,242 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:23:19,242 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:23:19,284 [Listener at 0.0.0.0/41178] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-12-03 07:23:19,287 [Listener at 0.0.0.0/41178] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:copyNameDirs(1264)) - Copying namedir from primary node dir file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5 to file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-7
2020-12-03 07:23:19,291 [Listener at 0.0.0.0/41178] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:copyNameDirs(1264)) - Copying namedir from primary node dir file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5 to file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-8
2020-12-03 07:23:19,301 [Listener at 0.0.0.0/41178] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:23:19,301 [Listener at 0.0.0.0/41178] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-12-03 07:23:19,303 [Listener at 0.0.0.0/41178] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://ns0
2020-12-03 07:23:19,303 [Listener at 0.0.0.0/41178] INFO  namenode.NameNode (NameNode.java:<init>(944)) - Clients should use ns1 to access this namenode/service.
2020-12-03 07:23:19,311 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1edb61b1] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:19,312 [Listener at 0.0.0.0/41178] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:23:19,316 [Listener at 0.0.0.0/41178] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:19,317 [Listener at 0.0.0.0/41178] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:23:19,320 [Listener at 0.0.0.0/41178] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:19,321 [Listener at 0.0.0.0/41178] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:23:19,322 [Listener at 0.0.0.0/41178] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:19,322 [Listener at 0.0.0.0/41178] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:19,324 [Listener at 0.0.0.0/41178] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:23:19,324 [Listener at 0.0.0.0/41178] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:23:19,326 [Listener at 0.0.0.0/41178] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 43406
2020-12-03 07:23:19,326 [Listener at 0.0.0.0/41178] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:19,330 [Listener at 0.0.0.0/41178] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@f5c79a6{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:23:19,331 [Listener at 0.0.0.0/41178] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5305c37d{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:23:19,551 [Listener at 0.0.0.0/41178] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@22db8f4{/,file:///tmp/jetty-localhost-43406-hdfs-_-any-3044297876141446935.dir/webapp/,AVAILABLE}{/hdfs}
2020-12-03 07:23:19,553 [Listener at 0.0.0.0/41178] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2b46a8c1{HTTP/1.1,[http/1.1]}{localhost:43406}
2020-12-03 07:23:19,554 [Listener at 0.0.0.0/41178] INFO  server.Server (Server.java:doStart(419)) - Started @5579ms
2020-12-03 07:23:19,557 [Listener at 0.0.0.0/41178] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:23:19,558 [Listener at 0.0.0.0/41178] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:23:19,558 [Listener at 0.0.0.0/41178] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:23:19,558 [Listener at 0.0.0.0/41178] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:23:19,559 [Listener at 0.0.0.0/41178] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:23:19,559 [Listener at 0.0.0.0/41178] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:23:19,559 [Listener at 0.0.0.0/41178] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:23:19,560 [Listener at 0.0.0.0/41178] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns1
2020-12-03 07:23:19,560 [Listener at 0.0.0.0/41178] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: true
2020-12-03 07:23:19,561 [Listener at 0.0.0.0/41178] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:19,563 [Listener at 0.0.0.0/41178] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:23:19,563 [Listener at 0.0.0.0/41178] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:23:19,563 [Listener at 0.0.0.0/41178] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:23:19,564 [Listener at 0.0.0.0/41178] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:23:19
2020-12-03 07:23:19,564 [Listener at 0.0.0.0/41178] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:23:19,564 [Listener at 0.0.0.0/41178] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:19,565 [Listener at 0.0.0.0/41178] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:23:19,565 [Listener at 0.0.0.0/41178] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:23:19,582 [Listener at 0.0.0.0/41178] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:23:19,582 [Listener at 0.0.0.0/41178] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:23:19,583 [Listener at 0.0.0.0/41178] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:23:19,583 [Listener at 0.0.0.0/41178] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:23:19,583 [Listener at 0.0.0.0/41178] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:23:19,583 [Listener at 0.0.0.0/41178] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:23:19,583 [Listener at 0.0.0.0/41178] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:23:19,584 [Listener at 0.0.0.0/41178] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:23:19,584 [Listener at 0.0.0.0/41178] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:23:19,584 [Listener at 0.0.0.0/41178] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:23:19,584 [Listener at 0.0.0.0/41178] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:23:19,584 [Listener at 0.0.0.0/41178] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:23:19,584 [Listener at 0.0.0.0/41178] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:23:19,585 [Listener at 0.0.0.0/41178] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:23:19,585 [Listener at 0.0.0.0/41178] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:19,585 [Listener at 0.0.0.0/41178] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:23:19,585 [Listener at 0.0.0.0/41178] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:23:19,591 [Listener at 0.0.0.0/41178] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:23:19,592 [Listener at 0.0.0.0/41178] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:23:19,592 [Listener at 0.0.0.0/41178] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:23:19,592 [Listener at 0.0.0.0/41178] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:23:19,592 [Listener at 0.0.0.0/41178] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:23:19,592 [Listener at 0.0.0.0/41178] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:23:19,592 [Listener at 0.0.0.0/41178] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:23:19,593 [Listener at 0.0.0.0/41178] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:19,593 [Listener at 0.0.0.0/41178] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:23:19,593 [Listener at 0.0.0.0/41178] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:23:19,595 [Listener at 0.0.0.0/41178] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:23:19,595 [Listener at 0.0.0.0/41178] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:23:19,595 [Listener at 0.0.0.0/41178] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:23:19,596 [Listener at 0.0.0.0/41178] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:23:19,596 [Listener at 0.0.0.0/41178] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:23:19,596 [Listener at 0.0.0.0/41178] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:23:19,596 [Listener at 0.0.0.0/41178] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:19,597 [Listener at 0.0.0.0/41178] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:23:19,597 [Listener at 0.0.0.0/41178] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:23:19,626 [Listener at 0.0.0.0/41178] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/in_use.lock acquired by nodename 9387@7a5505b8915a
2020-12-03 07:23:19,661 [Listener at 0.0.0.0/41178] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6/in_use.lock acquired by nodename 9387@7a5505b8915a
2020-12-03 07:23:19,662 [Listener at 0.0.0.0/41178] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-2-through-3
2020-12-03 07:23:19,667 [Listener at 0.0.0.0/41178] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:23:19,667 [Listener at 0.0.0.0/41178] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:23:19,673 [Listener at 0.0.0.0/41178] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:23:19,674 [Listener at 0.0.0.0/41178] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:23:19,674 [Listener at 0.0.0.0/41178] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/current/fsimage_0000000000000000000
2020-12-03 07:23:19,675 [Listener at 0.0.0.0/41178] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2020-12-03 07:23:19,675 [Listener at 0.0.0.0/41178] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:23:19,675 [Listener at 0.0.0.0/41178] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 76 msecs
2020-12-03 07:23:19,676 [Listener at 0.0.0.0/41178] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to 0.0.0.0:0
2020-12-03 07:23:19,676 [Listener at 0.0.0.0/41178] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:19,678 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:19,684 [Listener at 0.0.0.0/42106] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:23:19,705 [Listener at 0.0.0.0/42106] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:23:19,707 [Listener at 0.0.0.0/42106] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:23:19,708 [Listener at 0.0.0.0/42106] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:23:19,708 [Listener at 0.0.0.0/42106] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:23:19,713 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:19,713 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:19,715 [Listener at 0.0.0.0/42106] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:42106
2020-12-03 07:23:19,716 [Listener at 0.0.0.0/42106] INFO  namenode.FSNamesystem (FSNamesystem.java:startStandbyServices(1391)) - Starting services required for standby state
2020-12-03 07:23:19,716 [Listener at 0.0.0.0/42106] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.log-roll.period(-1) assuming SECONDS
2020-12-03 07:23:19,716 [Listener at 0.0.0.0/42106] INFO  ha.EditLogTailer (EditLogTailer.java:<init>(208)) - Not going to trigger log rolls on active node because dfs.ha.log-roll.period is negative.
2020-12-03 07:23:19,716 [Listener at 0.0.0.0/42106] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.period.backoff-max(0) assuming SECONDS
2020-12-03 07:23:19,716 [Listener at 0.0.0.0/42106] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.rolledits.timeout(60) assuming SECONDS
2020-12-03 07:23:19,720 [Listener at 0.0.0.0/42106] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:23:19,720 [Listener at 0.0.0.0/42106] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-12-03 07:23:19,721 [Listener at 0.0.0.0/42106] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://ns0
2020-12-03 07:23:19,721 [Listener at 0.0.0.0/42106] INFO  namenode.NameNode (NameNode.java:<init>(944)) - Clients should use ns1 to access this namenode/service.
2020-12-03 07:23:19,739 [Listener at 0.0.0.0/42106] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:23:19,742 [Listener at 0.0.0.0/42106] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:19,743 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2c444798] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:19,743 [Listener at 0.0.0.0/42106] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:23:19,746 [Listener at 0.0.0.0/42106] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:19,748 [Listener at 0.0.0.0/42106] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:23:19,748 [Listener at 0.0.0.0/42106] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:19,748 [Listener at 0.0.0.0/42106] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:19,750 [Listener at 0.0.0.0/42106] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:23:19,751 [Listener at 0.0.0.0/42106] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:23:19,751 [Listener at 0.0.0.0/42106] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 36951
2020-12-03 07:23:19,751 [Listener at 0.0.0.0/42106] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:19,774 [Listener at 0.0.0.0/42106] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3228d990{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:23:19,788 [Listener at 0.0.0.0/42106] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@50b8ae8d{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:23:19,978 [Listener at 0.0.0.0/42106] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3c321bdb{/,file:///tmp/jetty-localhost-36951-hdfs-_-any-8961851865482240079.dir/webapp/,AVAILABLE}{/hdfs}
2020-12-03 07:23:19,980 [Listener at 0.0.0.0/42106] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@24855019{HTTP/1.1,[http/1.1]}{localhost:36951}
2020-12-03 07:23:19,981 [Listener at 0.0.0.0/42106] INFO  server.Server (Server.java:doStart(419)) - Started @6006ms
2020-12-03 07:23:19,983 [Listener at 0.0.0.0/42106] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:23:19,983 [Listener at 0.0.0.0/42106] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:23:19,984 [Listener at 0.0.0.0/42106] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:23:19,984 [Listener at 0.0.0.0/42106] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:23:19,984 [Listener at 0.0.0.0/42106] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:23:19,984 [Listener at 0.0.0.0/42106] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:23:19,984 [Listener at 0.0.0.0/42106] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:23:19,985 [Listener at 0.0.0.0/42106] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns1
2020-12-03 07:23:19,985 [Listener at 0.0.0.0/42106] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: true
2020-12-03 07:23:19,985 [Listener at 0.0.0.0/42106] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:19,986 [Listener at 0.0.0.0/42106] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:23:19,986 [Listener at 0.0.0.0/42106] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:23:19,986 [Listener at 0.0.0.0/42106] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:23:19,987 [Listener at 0.0.0.0/42106] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:23:19
2020-12-03 07:23:19,987 [Listener at 0.0.0.0/42106] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:23:19,987 [Listener at 0.0.0.0/42106] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:19,987 [Listener at 0.0.0.0/42106] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:23:19,987 [Listener at 0.0.0.0/42106] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:23:19,999 [Listener at 0.0.0.0/42106] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:23:20,000 [Listener at 0.0.0.0/42106] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:23:20,000 [Listener at 0.0.0.0/42106] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:23:20,000 [Listener at 0.0.0.0/42106] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:23:20,001 [Listener at 0.0.0.0/42106] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:23:20,001 [Listener at 0.0.0.0/42106] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:23:20,001 [Listener at 0.0.0.0/42106] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:23:20,001 [Listener at 0.0.0.0/42106] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:23:20,001 [Listener at 0.0.0.0/42106] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:23:20,001 [Listener at 0.0.0.0/42106] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:23:20,002 [Listener at 0.0.0.0/42106] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:23:20,002 [Listener at 0.0.0.0/42106] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:23:20,002 [Listener at 0.0.0.0/42106] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:23:20,002 [Listener at 0.0.0.0/42106] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:23:20,002 [Listener at 0.0.0.0/42106] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:20,003 [Listener at 0.0.0.0/42106] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:23:20,003 [Listener at 0.0.0.0/42106] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:23:20,009 [Listener at 0.0.0.0/42106] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:23:20,009 [Listener at 0.0.0.0/42106] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:23:20,009 [Listener at 0.0.0.0/42106] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:23:20,009 [Listener at 0.0.0.0/42106] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:23:20,010 [Listener at 0.0.0.0/42106] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:23:20,010 [Listener at 0.0.0.0/42106] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:23:20,010 [Listener at 0.0.0.0/42106] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:23:20,010 [Listener at 0.0.0.0/42106] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:20,010 [Listener at 0.0.0.0/42106] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:23:20,010 [Listener at 0.0.0.0/42106] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:23:20,012 [Listener at 0.0.0.0/42106] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:23:20,012 [Listener at 0.0.0.0/42106] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:23:20,013 [Listener at 0.0.0.0/42106] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:23:20,013 [Listener at 0.0.0.0/42106] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:23:20,013 [Listener at 0.0.0.0/42106] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:23:20,013 [Listener at 0.0.0.0/42106] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:23:20,013 [Listener at 0.0.0.0/42106] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:20,013 [Listener at 0.0.0.0/42106] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:23:20,014 [Listener at 0.0.0.0/42106] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:23:20,038 [Listener at 0.0.0.0/42106] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-7/in_use.lock acquired by nodename 9387@7a5505b8915a
2020-12-03 07:23:20,064 [Listener at 0.0.0.0/42106] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-8/in_use.lock acquired by nodename 9387@7a5505b8915a
2020-12-03 07:23:20,064 [Listener at 0.0.0.0/42106] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-2-through-3
2020-12-03 07:23:20,067 [Listener at 0.0.0.0/42106] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:23:20,067 [Listener at 0.0.0.0/42106] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-7/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:23:20,069 [Listener at 0.0.0.0/42106] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:23:20,070 [Listener at 0.0.0.0/42106] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:23:20,070 [Listener at 0.0.0.0/42106] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-7/current/fsimage_0000000000000000000
2020-12-03 07:23:20,071 [Listener at 0.0.0.0/42106] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2020-12-03 07:23:20,071 [Listener at 0.0.0.0/42106] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:23:20,071 [Listener at 0.0.0.0/42106] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 55 msecs
2020-12-03 07:23:20,071 [Listener at 0.0.0.0/42106] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to 0.0.0.0:0
2020-12-03 07:23:20,072 [Listener at 0.0.0.0/42106] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:20,238 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:20,245 [Listener at 0.0.0.0/41220] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:23:20,270 [Listener at 0.0.0.0/41220] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:23:20,272 [Listener at 0.0.0.0/41220] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:23:20,273 [Listener at 0.0.0.0/41220] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:23:20,273 [Listener at 0.0.0.0/41220] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:23:20,283 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:20,283 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:20,286 [Listener at 0.0.0.0/41220] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:41220
2020-12-03 07:23:20,286 [Listener at 0.0.0.0/41220] INFO  namenode.FSNamesystem (FSNamesystem.java:startStandbyServices(1391)) - Starting services required for standby state
2020-12-03 07:23:20,287 [Listener at 0.0.0.0/41220] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.log-roll.period(-1) assuming SECONDS
2020-12-03 07:23:20,287 [Listener at 0.0.0.0/41220] INFO  ha.EditLogTailer (EditLogTailer.java:<init>(208)) - Not going to trigger log rolls on active node because dfs.ha.log-roll.period is negative.
2020-12-03 07:23:20,287 [Listener at 0.0.0.0/41220] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.period.backoff-max(0) assuming SECONDS
2020-12-03 07:23:20,287 [Listener at 0.0.0.0/41220] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.rolledits.timeout(60) assuming SECONDS
2020-12-03 07:23:20,301 [Listener at 0.0.0.0/41220] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-12-03 07:23:20,322 [Listener at 0.0.0.0/41220] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-12-03 07:23:20,335 [Listener at 0.0.0.0/41220] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-12-03 07:23:20,340 [Listener at 0.0.0.0/41220] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:23:20,346 [Listener at 0.0.0.0/41220] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:20,349 [Listener at 0.0.0.0/41220] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:23:20,354 [Listener at 0.0.0.0/41220] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:23:20,355 [Listener at 0.0.0.0/41220] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:20,360 [Listener at 0.0.0.0/41220] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:23:20,367 [Listener at 0.0.0.0/41220] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:39171
2020-12-03 07:23:20,369 [Listener at 0.0.0.0/41220] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:23:20,370 [Listener at 0.0.0.0/41220] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:23:20,390 [Listener at 0.0.0.0/41220] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:20,391 [Listener at 0.0.0.0/41220] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:23:20,394 [Listener at 0.0.0.0/41220] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:20,395 [Listener at 0.0.0.0/41220] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:23:20,395 [Listener at 0.0.0.0/41220] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:20,396 [Listener at 0.0.0.0/41220] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:20,401 [Listener at 0.0.0.0/41220] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 34206
2020-12-03 07:23:20,401 [Listener at 0.0.0.0/41220] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:20,404 [Listener at 0.0.0.0/41220] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2472c7d8{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:23:20,405 [Listener at 0.0.0.0/41220] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@22175d4f{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:23:20,595 [Listener at 0.0.0.0/41220] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@38600b{/,file:///tmp/jetty-localhost-34206-datanode-_-any-70474788912400988.dir/webapp/,AVAILABLE}{/datanode}
2020-12-03 07:23:20,597 [Listener at 0.0.0.0/41220] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@669d2b1b{HTTP/1.1,[http/1.1]}{localhost:34206}
2020-12-03 07:23:20,597 [Listener at 0.0.0.0/41220] INFO  server.Server (Server.java:doStart(419)) - Started @6622ms
2020-12-03 07:23:21,126 [Listener at 0.0.0.0/41220] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:39808
2020-12-03 07:23:21,128 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1f12e153] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:21,129 [Listener at 0.0.0.0/41220] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:23:21,129 [Listener at 0.0.0.0/41220] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:23:21,147 [Listener at 0.0.0.0/41220] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:21,148 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:21,157 [Listener at localhost/44521] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:44521
2020-12-03 07:23:21,178 [Listener at localhost/44521] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns0,ns1
2020-12-03 07:23:21,180 [Listener at localhost/44521] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns0,ns1
2020-12-03 07:23:21,193 [Thread-156] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42380 starting to offer service
2020-12-03 07:23:21,194 [Thread-159] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:41220 starting to offer service
2020-12-03 07:23:21,193 [Thread-158] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42106 starting to offer service
2020-12-03 07:23:21,193 [Thread-157] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:41178 starting to offer service
2020-12-03 07:23:21,208 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:21,208 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:21,223 [Listener at localhost/44521] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-12-03 07:23:21,226 [Listener at localhost/44521] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-12-03 07:23:21,227 [Listener at localhost/44521] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-12-03 07:23:21,231 [Listener at localhost/44521] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:23:21,232 [Listener at localhost/44521] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:21,232 [Listener at localhost/44521] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:23:21,235 [Listener at localhost/44521] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:23:21,236 [Listener at localhost/44521] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:21,236 [Listener at localhost/44521] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:23:21,237 [Listener at localhost/44521] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:44600
2020-12-03 07:23:21,237 [Listener at localhost/44521] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:23:21,237 [Listener at localhost/44521] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:23:21,241 [Listener at localhost/44521] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:21,241 [Listener at localhost/44521] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:23:21,245 [Listener at localhost/44521] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:21,247 [Listener at localhost/44521] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:23:21,247 [Listener at localhost/44521] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:21,248 [Listener at localhost/44521] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:21,249 [Listener at localhost/44521] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 43939
2020-12-03 07:23:21,249 [Listener at localhost/44521] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:21,254 [Listener at localhost/44521] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2e3a5237{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:23:21,255 [Listener at localhost/44521] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6ac97b84{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:23:21,527 [Listener at localhost/44521] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5cbb84b1{/,file:///tmp/jetty-localhost-43939-datanode-_-any-5335604122986142056.dir/webapp/,AVAILABLE}{/datanode}
2020-12-03 07:23:21,529 [Listener at localhost/44521] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2c779e5{HTTP/1.1,[http/1.1]}{localhost:43939}
2020-12-03 07:23:21,529 [Listener at localhost/44521] INFO  server.Server (Server.java:doStart(419)) - Started @7554ms
2020-12-03 07:23:21,609 [Thread-159] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:23:21,630 [Listener at localhost/44521] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:40111
2020-12-03 07:23:21,631 [Listener at localhost/44521] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:23:21,631 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5183d589] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:21,631 [Listener at localhost/44521] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:23:21,632 [Listener at localhost/44521] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:21,633 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:21,637 [Listener at localhost/40840] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:40840
2020-12-03 07:23:21,644 [Listener at localhost/40840] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns0,ns1
2020-12-03 07:23:21,645 [Listener at localhost/40840] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns0,ns1
2020-12-03 07:23:21,646 [Thread-185] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42380 starting to offer service
2020-12-03 07:23:21,646 [Thread-186] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:41178 starting to offer service
2020-12-03 07:23:21,647 [Thread-187] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42106 starting to offer service
2020-12-03 07:23:21,647 [Thread-188] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:41220 starting to offer service
2020-12-03 07:23:21,657 [Thread-159] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 9387@7a5505b8915a
2020-12-03 07:23:21,659 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:21,660 [Thread-159] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1 is not formatted for namespace 1100938544. Formatting...
2020-12-03 07:23:21,659 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:21,661 [Thread-159] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-d5770dd2-4b97-4a60-8165-e6f7485bd547 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1 
2020-12-03 07:23:21,662 [Listener at localhost/40840] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-12-03 07:23:21,664 [Listener at localhost/40840] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-12-03 07:23:21,664 [Listener at localhost/40840] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-12-03 07:23:21,666 [Listener at localhost/40840] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:23:21,666 [Listener at localhost/40840] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:21,667 [Listener at localhost/40840] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:23:21,668 [Listener at localhost/40840] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:23:21,669 [Listener at localhost/40840] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:21,669 [Listener at localhost/40840] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:23:21,670 [Listener at localhost/40840] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:34378
2020-12-03 07:23:21,670 [Listener at localhost/40840] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:23:21,671 [Listener at localhost/40840] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:23:21,673 [Thread-186] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:23:21,676 [Listener at localhost/40840] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:21,677 [Listener at localhost/40840] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:23:21,679 [Listener at localhost/40840] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:21,680 [Listener at localhost/40840] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:23:21,680 [Listener at localhost/40840] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:21,680 [Listener at localhost/40840] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:21,681 [Listener at localhost/40840] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 45004
2020-12-03 07:23:21,681 [Listener at localhost/40840] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:21,683 [Listener at localhost/40840] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@588ffeb{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:23:21,684 [Listener at localhost/40840] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@baf1bb3{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:23:21,728 [Thread-186] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 9387@7a5505b8915a
2020-12-03 07:23:21,729 [Thread-186] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3 is not formatted for namespace 415304149. Formatting...
2020-12-03 07:23:21,729 [Thread-186] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-93ea001c-b6e4-4144-83cf-5e00deaaa577 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3 
2020-12-03 07:23:21,828 [Thread-159] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 9387@7a5505b8915a
2020-12-03 07:23:21,829 [Thread-159] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2 is not formatted for namespace 1100938544. Formatting...
2020-12-03 07:23:21,829 [Thread-159] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-5e7b33bf-2080-44f8-ba26-78c5f795a346 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2 
2020-12-03 07:23:21,900 [Listener at localhost/40840] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@69cac930{/,file:///tmp/jetty-localhost-45004-datanode-_-any-2265495402617252182.dir/webapp/,AVAILABLE}{/datanode}
2020-12-03 07:23:21,901 [Listener at localhost/40840] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@19593091{HTTP/1.1,[http/1.1]}{localhost:45004}
2020-12-03 07:23:21,901 [Listener at localhost/40840] INFO  server.Server (Server.java:doStart(419)) - Started @7926ms
2020-12-03 07:23:21,913 [Thread-186] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 9387@7a5505b8915a
2020-12-03 07:23:21,914 [Thread-186] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4 is not formatted for namespace 415304149. Formatting...
2020-12-03 07:23:21,914 [Thread-186] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-8ae2d45d-3ea1-4fcf-936e-d146876566da for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4 
2020-12-03 07:23:21,928 [Listener at localhost/40840] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:37952
2020-12-03 07:23:21,928 [Listener at localhost/40840] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:23:21,928 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6ad6fa53] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:21,928 [Listener at localhost/40840] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:23:21,929 [Listener at localhost/40840] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:21,930 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:21,934 [Listener at localhost/39589] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:39589
2020-12-03 07:23:21,938 [Listener at localhost/39589] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns0,ns1
2020-12-03 07:23:21,939 [Listener at localhost/39589] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns0,ns1
2020-12-03 07:23:21,941 [Thread-210] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42380 starting to offer service
2020-12-03 07:23:21,941 [Thread-211] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:41178 starting to offer service
2020-12-03 07:23:21,960 [Thread-212] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42106 starting to offer service
2020-12-03 07:23:21,971 [Thread-213] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:41220 starting to offer service
2020-12-03 07:23:21,977 [Thread-159] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-286010920-172.17.0.2-1606980199054
2020-12-03 07:23:21,977 [Thread-159] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-286010920-172.17.0.2-1606980199054
2020-12-03 07:23:21,978 [Thread-159] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1 and block pool id BP-286010920-172.17.0.2-1606980199054 is not formatted. Formatting ...
2020-12-03 07:23:21,979 [Thread-159] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-286010920-172.17.0.2-1606980199054 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-286010920-172.17.0.2-1606980199054/current
2020-12-03 07:23:21,979 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:21,988 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:22,021 [Thread-186] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2036634619-172.17.0.2-1606980196096
2020-12-03 07:23:22,021 [Thread-186] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-2036634619-172.17.0.2-1606980196096
2020-12-03 07:23:22,022 [Thread-186] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3 and block pool id BP-2036634619-172.17.0.2-1606980196096 is not formatted. Formatting ...
2020-12-03 07:23:22,022 [Thread-186] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2036634619-172.17.0.2-1606980196096 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-2036634619-172.17.0.2-1606980196096/current
2020-12-03 07:23:22,053 [Listener at localhost/39589] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 3 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-12-03 07:23:22,055 [Listener at localhost/39589] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7
2020-12-03 07:23:22,059 [Thread-159] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-286010920-172.17.0.2-1606980199054
2020-12-03 07:23:22,059 [Thread-159] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-286010920-172.17.0.2-1606980199054
2020-12-03 07:23:22,060 [Thread-159] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2 and block pool id BP-286010920-172.17.0.2-1606980199054 is not formatted. Formatting ...
2020-12-03 07:23:22,060 [Thread-159] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-286010920-172.17.0.2-1606980199054 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-286010920-172.17.0.2-1606980199054/current
2020-12-03 07:23:22,063 [Listener at localhost/39589] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-12-03 07:23:22,091 [Thread-211] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:23:22,092 [Listener at localhost/39589] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:23:22,131 [Listener at localhost/39589] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:22,132 [Listener at localhost/39589] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:23:22,133 [Listener at localhost/39589] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:23:22,133 [Listener at localhost/39589] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:22,134 [Listener at localhost/39589] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:23:22,135 [Listener at localhost/39589] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:33622
2020-12-03 07:23:22,135 [Listener at localhost/39589] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:23:22,135 [Listener at localhost/39589] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:23:22,138 [Listener at localhost/39589] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:22,139 [Listener at localhost/39589] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:23:22,141 [Listener at localhost/39589] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:22,142 [Listener at localhost/39589] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:23:22,142 [Listener at localhost/39589] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:22,142 [Listener at localhost/39589] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:22,143 [Listener at localhost/39589] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 45039
2020-12-03 07:23:22,143 [Listener at localhost/39589] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:22,145 [Listener at localhost/39589] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@25b865b5{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:23:22,145 [Listener at localhost/39589] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6872f9c8{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:23:22,150 [Thread-186] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2036634619-172.17.0.2-1606980196096
2020-12-03 07:23:22,150 [Thread-186] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-2036634619-172.17.0.2-1606980196096
2020-12-03 07:23:22,151 [Thread-186] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4 and block pool id BP-2036634619-172.17.0.2-1606980196096 is not formatted. Formatting ...
2020-12-03 07:23:22,151 [Thread-186] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2036634619-172.17.0.2-1606980196096 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-2036634619-172.17.0.2-1606980196096/current
2020-12-03 07:23:22,158 [Thread-211] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 9387@7a5505b8915a
2020-12-03 07:23:22,159 [Thread-211] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5 is not formatted for namespace 415304149. Formatting...
2020-12-03 07:23:22,160 [Thread-211] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-c7fc4836-6abf-432b-835a-5c81775ebbd5 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5 
2020-12-03 07:23:22,256 [Thread-159] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1100938544;bpid=BP-286010920-172.17.0.2-1606980199054;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1100938544;c=1606980199054;bpid=BP-286010920-172.17.0.2-1606980199054;dnuuid=null
2020-12-03 07:23:22,257 [Thread-157] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:23:22,257 [Thread-157] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1 has already been used.
2020-12-03 07:23:22,257 [Thread-157] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2 has already been used.
2020-12-03 07:23:22,271 [Thread-157] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2036634619-172.17.0.2-1606980196096
2020-12-03 07:23:22,271 [Thread-157] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-2036634619-172.17.0.2-1606980196096
2020-12-03 07:23:22,271 [Thread-157] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1 and block pool id BP-2036634619-172.17.0.2-1606980196096 is not formatted. Formatting ...
2020-12-03 07:23:22,271 [Thread-157] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2036634619-172.17.0.2-1606980196096 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-2036634619-172.17.0.2-1606980196096/current
2020-12-03 07:23:22,289 [Thread-186] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=415304149;bpid=BP-2036634619-172.17.0.2-1606980196096;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=415304149;c=1606980196097;bpid=BP-2036634619-172.17.0.2-1606980196096;dnuuid=null
2020-12-03 07:23:22,290 [Thread-187] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:23:22,291 [Thread-187] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3 has already been used.
2020-12-03 07:23:22,291 [Thread-187] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4 has already been used.
2020-12-03 07:23:22,303 [Thread-187] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-286010920-172.17.0.2-1606980199054
2020-12-03 07:23:22,303 [Thread-187] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-286010920-172.17.0.2-1606980199054
2020-12-03 07:23:22,303 [Thread-187] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3 and block pool id BP-286010920-172.17.0.2-1606980199054 is not formatted. Formatting ...
2020-12-03 07:23:22,303 [Thread-187] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-286010920-172.17.0.2-1606980199054 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-286010920-172.17.0.2-1606980199054/current
2020-12-03 07:23:22,345 [Listener at localhost/39589] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6edc4161{/,file:///tmp/jetty-localhost-45039-datanode-_-any-5781015011269286077.dir/webapp/,AVAILABLE}{/datanode}
2020-12-03 07:23:22,350 [Listener at localhost/39589] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@5486887b{HTTP/1.1,[http/1.1]}{localhost:45039}
2020-12-03 07:23:22,350 [Listener at localhost/39589] INFO  server.Server (Server.java:doStart(419)) - Started @8375ms
2020-12-03 07:23:22,389 [Thread-211] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 9387@7a5505b8915a
2020-12-03 07:23:22,389 [Thread-211] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6 is not formatted for namespace 415304149. Formatting...
2020-12-03 07:23:22,390 [Thread-211] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-9dc1839e-cbff-43d6-ae19-9f469f186f57 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6 
2020-12-03 07:23:22,405 [Thread-157] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2036634619-172.17.0.2-1606980196096
2020-12-03 07:23:22,406 [Thread-157] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-2036634619-172.17.0.2-1606980196096
2020-12-03 07:23:22,406 [Thread-157] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2 and block pool id BP-2036634619-172.17.0.2-1606980196096 is not formatted. Formatting ...
2020-12-03 07:23:22,406 [Thread-157] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2036634619-172.17.0.2-1606980196096 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-2036634619-172.17.0.2-1606980196096/current
2020-12-03 07:23:22,413 [Listener at localhost/39589] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:46034
2020-12-03 07:23:22,413 [Listener at localhost/39589] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:23:22,413 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1440c311] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:22,414 [Listener at localhost/39589] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:23:22,414 [Listener at localhost/39589] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:22,415 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:22,423 [Listener at localhost/45068] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:45068
2020-12-03 07:23:22,424 [Thread-187] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-286010920-172.17.0.2-1606980199054
2020-12-03 07:23:22,424 [Thread-187] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-286010920-172.17.0.2-1606980199054
2020-12-03 07:23:22,424 [Thread-187] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4 and block pool id BP-286010920-172.17.0.2-1606980199054 is not formatted. Formatting ...
2020-12-03 07:23:22,424 [Thread-187] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-286010920-172.17.0.2-1606980199054 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-286010920-172.17.0.2-1606980199054/current
2020-12-03 07:23:22,430 [Listener at localhost/45068] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns0,ns1
2020-12-03 07:23:22,431 [Listener at localhost/45068] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns0,ns1
2020-12-03 07:23:22,432 [Thread-235] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42380 starting to offer service
2020-12-03 07:23:22,433 [Thread-236] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:41178 starting to offer service
2020-12-03 07:23:22,434 [Thread-237] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42106 starting to offer service
2020-12-03 07:23:22,434 [Thread-238] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:41220 starting to offer service
2020-12-03 07:23:22,435 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:22,435 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:22,445 [Thread-236] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:23:22,505 [Thread-236] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/in_use.lock acquired by nodename 9387@7a5505b8915a
2020-12-03 07:23:22,505 [Thread-236] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7 is not formatted for namespace 415304149. Formatting...
2020-12-03 07:23:22,506 [Thread-236] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-32ee6b6e-ecea-462a-922f-e3967ffcb365 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7 
2020-12-03 07:23:22,569 [Thread-211] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2036634619-172.17.0.2-1606980196096
2020-12-03 07:23:22,569 [Thread-211] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-2036634619-172.17.0.2-1606980196096
2020-12-03 07:23:22,569 [Thread-211] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5 and block pool id BP-2036634619-172.17.0.2-1606980196096 is not formatted. Formatting ...
2020-12-03 07:23:22,569 [Thread-211] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2036634619-172.17.0.2-1606980196096 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-2036634619-172.17.0.2-1606980196096/current
2020-12-03 07:23:22,576 [Thread-187] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1100938544;bpid=BP-286010920-172.17.0.2-1606980199054;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1100938544;c=1606980199054;bpid=BP-286010920-172.17.0.2-1606980199054;dnuuid=null
2020-12-03 07:23:22,577 [Thread-157] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=415304149;bpid=BP-2036634619-172.17.0.2-1606980196096;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=415304149;c=1606980196097;bpid=BP-2036634619-172.17.0.2-1606980196096;dnuuid=null
2020-12-03 07:23:22,720 [Thread-187] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 8f01febb-1c2e-4617-a206-a73518a9f66d
2020-12-03 07:23:22,738 [Thread-211] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2036634619-172.17.0.2-1606980196096
2020-12-03 07:23:22,738 [Thread-211] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-2036634619-172.17.0.2-1606980196096
2020-12-03 07:23:22,739 [Thread-211] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6 and block pool id BP-2036634619-172.17.0.2-1606980196096 is not formatted. Formatting ...
2020-12-03 07:23:22,739 [Thread-211] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2036634619-172.17.0.2-1606980196096 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-2036634619-172.17.0.2-1606980196096/current
2020-12-03 07:23:22,763 [Thread-236] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/in_use.lock acquired by nodename 9387@7a5505b8915a
2020-12-03 07:23:22,763 [Thread-236] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8 is not formatted for namespace 415304149. Formatting...
2020-12-03 07:23:22,764 [Thread-157] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID b9a147fb-134d-449d-b6a4-64a8ee59436a
2020-12-03 07:23:22,764 [Thread-236] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-f1560c54-0c7f-451c-ade4-648ed1535376 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8 
2020-12-03 07:23:22,855 [Thread-211] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=415304149;bpid=BP-2036634619-172.17.0.2-1606980196096;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=415304149;c=1606980196097;bpid=BP-2036634619-172.17.0.2-1606980196096;dnuuid=null
2020-12-03 07:23:22,868 [Thread-212] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:23:22,875 [Thread-212] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5 has already been used.
2020-12-03 07:23:22,876 [Thread-212] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6 has already been used.
2020-12-03 07:23:22,914 [Thread-236] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2036634619-172.17.0.2-1606980196096
2020-12-03 07:23:22,914 [Thread-236] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-2036634619-172.17.0.2-1606980196096
2020-12-03 07:23:22,915 [Thread-236] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7 and block pool id BP-2036634619-172.17.0.2-1606980196096 is not formatted. Formatting ...
2020-12-03 07:23:22,915 [Thread-236] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2036634619-172.17.0.2-1606980196096 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-2036634619-172.17.0.2-1606980196096/current
2020-12-03 07:23:22,927 [Thread-212] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-286010920-172.17.0.2-1606980199054
2020-12-03 07:23:22,927 [Thread-212] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-286010920-172.17.0.2-1606980199054
2020-12-03 07:23:22,927 [Thread-212] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5 and block pool id BP-286010920-172.17.0.2-1606980199054 is not formatted. Formatting ...
2020-12-03 07:23:22,927 [Thread-212] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-286010920-172.17.0.2-1606980199054 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-286010920-172.17.0.2-1606980199054/current
2020-12-03 07:23:22,964 [Thread-187] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-93ea001c-b6e4-4144-83cf-5e00deaaa577
2020-12-03 07:23:22,964 [Thread-157] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-d5770dd2-4b97-4a60-8165-e6f7485bd547
2020-12-03 07:23:22,966 [Thread-187] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, StorageType: DISK
2020-12-03 07:23:22,966 [Thread-157] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, StorageType: DISK
2020-12-03 07:23:22,968 [Thread-187] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-8ae2d45d-3ea1-4fcf-936e-d146876566da
2020-12-03 07:23:22,969 [Thread-187] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, StorageType: DISK
2020-12-03 07:23:22,970 [Thread-157] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-5e7b33bf-2080-44f8-ba26-78c5f795a346
2020-12-03 07:23:22,975 [Thread-157] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, StorageType: DISK
2020-12-03 07:23:22,977 [Thread-187] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:23:22,977 [Thread-157] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:23:22,985 [Thread-187] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-12-03 07:23:22,985 [Thread-186] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-12-03 07:23:22,988 [Thread-157] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-12-03 07:23:22,988 [Thread-159] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-286010920-172.17.0.2-1606980199054
2020-12-03 07:23:22,989 [Thread-253] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-286010920-172.17.0.2-1606980199054 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1...
2020-12-03 07:23:22,989 [Thread-254] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-286010920-172.17.0.2-1606980199054 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2...
2020-12-03 07:23:22,997 [Thread-187] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-12-03 07:23:22,998 [Thread-186] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-12-03 07:23:22,998 [Thread-157] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-12-03 07:23:23,001 [Thread-187] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-12-03 07:23:23,001 [Thread-157] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-12-03 07:23:23,001 [Thread-186] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-12-03 07:23:23,002 [Thread-157] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-12-03 07:23:23,001 [Thread-187] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-12-03 07:23:23,002 [Thread-186] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-12-03 07:23:23,002 [Thread-187] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-286010920-172.17.0.2-1606980199054
2020-12-03 07:23:23,003 [Thread-157] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-2036634619-172.17.0.2-1606980196096
2020-12-03 07:23:23,002 [Thread-186] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-2036634619-172.17.0.2-1606980196096
2020-12-03 07:23:23,009 [Thread-255] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-286010920-172.17.0.2-1606980199054 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3...
2020-12-03 07:23:23,009 [Thread-256] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-286010920-172.17.0.2-1606980199054 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4...
2020-12-03 07:23:23,039 [Thread-236] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2036634619-172.17.0.2-1606980196096
2020-12-03 07:23:23,039 [Thread-236] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-2036634619-172.17.0.2-1606980196096
2020-12-03 07:23:23,040 [Thread-236] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8 and block pool id BP-2036634619-172.17.0.2-1606980196096 is not formatted. Formatting ...
2020-12-03 07:23:23,040 [Thread-236] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2036634619-172.17.0.2-1606980196096 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-2036634619-172.17.0.2-1606980196096/current
2020-12-03 07:23:23,051 [Thread-253] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-286010920-172.17.0.2-1606980199054 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1: 61ms
2020-12-03 07:23:23,052 [Thread-255] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-286010920-172.17.0.2-1606980199054 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3: 43ms
2020-12-03 07:23:23,054 [Thread-254] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-286010920-172.17.0.2-1606980199054 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2: 64ms
2020-12-03 07:23:23,054 [Thread-159] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-286010920-172.17.0.2-1606980199054: 66ms
2020-12-03 07:23:23,058 [Thread-212] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-286010920-172.17.0.2-1606980199054
2020-12-03 07:23:23,058 [Thread-256] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-286010920-172.17.0.2-1606980199054 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4: 49ms
2020-12-03 07:23:23,058 [Thread-187] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-286010920-172.17.0.2-1606980199054: 56ms
2020-12-03 07:23:23,059 [Thread-212] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-286010920-172.17.0.2-1606980199054
2020-12-03 07:23:23,059 [Thread-212] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6 and block pool id BP-286010920-172.17.0.2-1606980199054 is not formatted. Formatting ...
2020-12-03 07:23:23,059 [Thread-212] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-286010920-172.17.0.2-1606980199054 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-286010920-172.17.0.2-1606980199054/current
2020-12-03 07:23:23,060 [Thread-261] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-2036634619-172.17.0.2-1606980196096 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1...
2020-12-03 07:23:23,060 [Thread-262] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-2036634619-172.17.0.2-1606980196096 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3...
2020-12-03 07:23:23,060 [Thread-265] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-2036634619-172.17.0.2-1606980196096 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2...
2020-12-03 07:23:23,060 [Thread-264] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-286010920-172.17.0.2-1606980199054 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1...
2020-12-03 07:23:23,063 [Thread-263] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-286010920-172.17.0.2-1606980199054 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3...
2020-12-03 07:23:23,063 [Thread-264] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-286010920-172.17.0.2-1606980199054/current/replicas doesn't exist 
2020-12-03 07:23:23,064 [Thread-268] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-286010920-172.17.0.2-1606980199054 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4...
2020-12-03 07:23:23,064 [Thread-266] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-2036634619-172.17.0.2-1606980196096 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4...
2020-12-03 07:23:23,064 [Thread-267] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-286010920-172.17.0.2-1606980199054 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2...
2020-12-03 07:23:23,064 [Thread-263] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-286010920-172.17.0.2-1606980199054/current/replicas doesn't exist 
2020-12-03 07:23:23,064 [Thread-268] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-286010920-172.17.0.2-1606980199054/current/replicas doesn't exist 
2020-12-03 07:23:23,064 [Thread-267] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-286010920-172.17.0.2-1606980199054/current/replicas doesn't exist 
2020-12-03 07:23:23,068 [Thread-264] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-286010920-172.17.0.2-1606980199054 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1: 7ms
2020-12-03 07:23:23,068 [Thread-263] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-286010920-172.17.0.2-1606980199054 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3: 4ms
2020-12-03 07:23:23,068 [Thread-267] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-286010920-172.17.0.2-1606980199054 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2: 3ms
2020-12-03 07:23:23,068 [Thread-159] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-286010920-172.17.0.2-1606980199054: 9ms
2020-12-03 07:23:23,071 [Thread-268] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-286010920-172.17.0.2-1606980199054 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4: 6ms
2020-12-03 07:23:23,071 [Thread-187] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-286010920-172.17.0.2-1606980199054: 12ms
2020-12-03 07:23:23,072 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-286010920-172.17.0.2-1606980199054 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-12-03 07:23:23,072 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-286010920-172.17.0.2-1606980199054 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-12-03 07:23:23,072 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-286010920-172.17.0.2-1606980199054 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-12-03 07:23:23,084 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, DS-5e7b33bf-2080-44f8-ba26-78c5f795a346): finished scanning block pool BP-286010920-172.17.0.2-1606980199054
2020-12-03 07:23:23,096 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-286010920-172.17.0.2-1606980199054 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-12-03 07:23:23,096 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, DS-8ae2d45d-3ea1-4fcf-936e-d146876566da): finished scanning block pool BP-286010920-172.17.0.2-1606980199054
2020-12-03 07:23:23,105 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, DS-93ea001c-b6e4-4144-83cf-5e00deaaa577): finished scanning block pool BP-286010920-172.17.0.2-1606980199054
2020-12-03 07:23:23,109 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, DS-d5770dd2-4b97-4a60-8165-e6f7485bd547): finished scanning block pool BP-286010920-172.17.0.2-1606980199054
2020-12-03 07:23:23,114 [Thread-261] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-2036634619-172.17.0.2-1606980196096 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1: 54ms
2020-12-03 07:23:23,156 [Thread-236] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=415304149;bpid=BP-2036634619-172.17.0.2-1606980196096;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=415304149;c=1606980196097;bpid=BP-2036634619-172.17.0.2-1606980196096;dnuuid=null
2020-12-03 07:23:23,156 [Thread-212] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1100938544;bpid=BP-286010920-172.17.0.2-1606980199054;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1100938544;c=1606980199054;bpid=BP-286010920-172.17.0.2-1606980199054;dnuuid=null
2020-12-03 07:23:23,158 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, DS-5e7b33bf-2080-44f8-ba26-78c5f795a346): no suitable block pools found to scan.  Waiting 1814399913 ms.
2020-12-03 07:23:23,158 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, DS-93ea001c-b6e4-4144-83cf-5e00deaaa577): no suitable block pools found to scan.  Waiting 1814399914 ms.
2020-12-03 07:23:23,158 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, DS-8ae2d45d-3ea1-4fcf-936e-d146876566da): no suitable block pools found to scan.  Waiting 1814399914 ms.
2020-12-03 07:23:23,158 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, DS-d5770dd2-4b97-4a60-8165-e6f7485bd547): no suitable block pools found to scan.  Waiting 1814399938 ms.
2020-12-03 07:23:23,159 [Thread-266] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-2036634619-172.17.0.2-1606980196096 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4: 94ms
2020-12-03 07:23:23,174 [Thread-262] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-2036634619-172.17.0.2-1606980196096 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3: 113ms
2020-12-03 07:23:23,188 [Thread-186] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-2036634619-172.17.0.2-1606980196096: 129ms
2020-12-03 07:23:23,189 [Thread-279] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-2036634619-172.17.0.2-1606980196096 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3...
2020-12-03 07:23:23,190 [Thread-280] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-2036634619-172.17.0.2-1606980196096 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4...
2020-12-03 07:23:23,190 [Thread-279] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-2036634619-172.17.0.2-1606980196096/current/replicas doesn't exist 
2020-12-03 07:23:23,190 [Thread-280] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-2036634619-172.17.0.2-1606980196096/current/replicas doesn't exist 
2020-12-03 07:23:23,190 [Thread-265] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-2036634619-172.17.0.2-1606980196096 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2: 130ms
2020-12-03 07:23:23,190 [Thread-280] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-2036634619-172.17.0.2-1606980196096 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4: 1ms
2020-12-03 07:23:23,191 [Thread-157] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-2036634619-172.17.0.2-1606980196096: 131ms
2020-12-03 07:23:23,200 [Thread-281] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-2036634619-172.17.0.2-1606980196096 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1...
2020-12-03 07:23:23,200 [Thread-282] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-2036634619-172.17.0.2-1606980196096 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2...
2020-12-03 07:23:23,200 [Thread-281] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-2036634619-172.17.0.2-1606980196096/current/replicas doesn't exist 
2020-12-03 07:23:23,200 [Thread-279] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-2036634619-172.17.0.2-1606980196096 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3: 11ms
2020-12-03 07:23:23,200 [Thread-282] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-2036634619-172.17.0.2-1606980196096/current/replicas doesn't exist 
2020-12-03 07:23:23,201 [Thread-281] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-2036634619-172.17.0.2-1606980196096 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1: 1ms
2020-12-03 07:23:23,201 [Thread-282] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-2036634619-172.17.0.2-1606980196096 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2: 0ms
2020-12-03 07:23:23,201 [Thread-186] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-2036634619-172.17.0.2-1606980196096: 12ms
2020-12-03 07:23:23,201 [Thread-157] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-2036634619-172.17.0.2-1606980196096: 2ms
2020-12-03 07:23:23,203 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-2036634619-172.17.0.2-1606980196096 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-12-03 07:23:23,203 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-2036634619-172.17.0.2-1606980196096 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-12-03 07:23:23,203 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-2036634619-172.17.0.2-1606980196096 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-12-03 07:23:23,203 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, DS-93ea001c-b6e4-4144-83cf-5e00deaaa577): finished scanning block pool BP-2036634619-172.17.0.2-1606980196096
2020-12-03 07:23:23,203 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, DS-5e7b33bf-2080-44f8-ba26-78c5f795a346): finished scanning block pool BP-2036634619-172.17.0.2-1606980196096
2020-12-03 07:23:23,203 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-2036634619-172.17.0.2-1606980196096 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-12-03 07:23:23,203 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, DS-8ae2d45d-3ea1-4fcf-936e-d146876566da): finished scanning block pool BP-2036634619-172.17.0.2-1606980196096
2020-12-03 07:23:23,204 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, DS-93ea001c-b6e4-4144-83cf-5e00deaaa577): no suitable block pools found to scan.  Waiting 1814399868 ms.
2020-12-03 07:23:23,204 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, DS-5e7b33bf-2080-44f8-ba26-78c5f795a346): no suitable block pools found to scan.  Waiting 1814399867 ms.
2020-12-03 07:23:23,205 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, DS-8ae2d45d-3ea1-4fcf-936e-d146876566da): no suitable block pools found to scan.  Waiting 1814399867 ms.
2020-12-03 07:23:23,205 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, DS-d5770dd2-4b97-4a60-8165-e6f7485bd547): finished scanning block pool BP-2036634619-172.17.0.2-1606980196096
2020-12-03 07:23:23,207 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, DS-d5770dd2-4b97-4a60-8165-e6f7485bd547): no suitable block pools found to scan.  Waiting 1814399889 ms.
2020-12-03 07:23:23,218 [Thread-187] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 7:56 AM with interval of 21600000ms
2020-12-03 07:23:23,229 [Thread-159] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 10:30 AM with interval of 21600000ms
2020-12-03 07:23:23,233 [BP-2036634619-172.17.0.2-1606980196096 heartbeating to localhost/127.0.0.1:41178] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-2036634619-172.17.0.2-1606980196096 (Datanode Uuid 8f01febb-1c2e-4617-a206-a73518a9f66d) service to localhost/127.0.0.1:41178 beginning handshake with NN
2020-12-03 07:23:23,233 [BP-2036634619-172.17.0.2-1606980196096 heartbeating to localhost/127.0.0.1:41178] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-2036634619-172.17.0.2-1606980196096 (Datanode Uuid b9a147fb-134d-449d-b6a4-64a8ee59436a) service to localhost/127.0.0.1:41178 beginning handshake with NN
2020-12-03 07:23:23,233 [BP-2036634619-172.17.0.2-1606980196096 heartbeating to localhost/127.0.0.1:42380] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-2036634619-172.17.0.2-1606980196096 (Datanode Uuid 8f01febb-1c2e-4617-a206-a73518a9f66d) service to localhost/127.0.0.1:42380 beginning handshake with NN
2020-12-03 07:23:23,233 [BP-2036634619-172.17.0.2-1606980196096 heartbeating to localhost/127.0.0.1:42380] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-2036634619-172.17.0.2-1606980196096 (Datanode Uuid b9a147fb-134d-449d-b6a4-64a8ee59436a) service to localhost/127.0.0.1:42380 beginning handshake with NN
2020-12-03 07:23:23,234 [BP-286010920-172.17.0.2-1606980199054 heartbeating to localhost/127.0.0.1:42106] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-286010920-172.17.0.2-1606980199054 (Datanode Uuid 8f01febb-1c2e-4617-a206-a73518a9f66d) service to localhost/127.0.0.1:42106 beginning handshake with NN
2020-12-03 07:23:23,234 [BP-286010920-172.17.0.2-1606980199054 heartbeating to localhost/127.0.0.1:41220] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-286010920-172.17.0.2-1606980199054 (Datanode Uuid 8f01febb-1c2e-4617-a206-a73518a9f66d) service to localhost/127.0.0.1:41220 beginning handshake with NN
2020-12-03 07:23:23,235 [BP-286010920-172.17.0.2-1606980199054 heartbeating to localhost/127.0.0.1:41220] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-286010920-172.17.0.2-1606980199054 (Datanode Uuid b9a147fb-134d-449d-b6a4-64a8ee59436a) service to localhost/127.0.0.1:41220 beginning handshake with NN
2020-12-03 07:23:23,235 [BP-286010920-172.17.0.2-1606980199054 heartbeating to localhost/127.0.0.1:42106] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-286010920-172.17.0.2-1606980199054 (Datanode Uuid b9a147fb-134d-449d-b6a4-64a8ee59436a) service to localhost/127.0.0.1:42106 beginning handshake with NN
2020-12-03 07:23:23,250 [IPC Server handler 6 on default port 42380] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:44600, datanodeUuid=8f01febb-1c2e-4617-a206-a73518a9f66d, infoPort=40111, infoSecurePort=0, ipcPort=40840, storageInfo=lv=-57;cid=testClusterID;nsid=415304149;c=1606980196097) storage 8f01febb-1c2e-4617-a206-a73518a9f66d
2020-12-03 07:23:23,250 [IPC Server handler 8 on default port 41178] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:39171, datanodeUuid=b9a147fb-134d-449d-b6a4-64a8ee59436a, infoPort=39808, infoSecurePort=0, ipcPort=44521, storageInfo=lv=-57;cid=testClusterID;nsid=415304149;c=1606980196097) storage b9a147fb-134d-449d-b6a4-64a8ee59436a
2020-12-03 07:23:23,250 [IPC Server handler 1 on default port 42106] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:39171, datanodeUuid=b9a147fb-134d-449d-b6a4-64a8ee59436a, infoPort=39808, infoSecurePort=0, ipcPort=44521, storageInfo=lv=-57;cid=testClusterID;nsid=1100938544;c=1606980199054) storage b9a147fb-134d-449d-b6a4-64a8ee59436a
2020-12-03 07:23:23,257 [IPC Server handler 4 on default port 41220] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:44600, datanodeUuid=8f01febb-1c2e-4617-a206-a73518a9f66d, infoPort=40111, infoSecurePort=0, ipcPort=40840, storageInfo=lv=-57;cid=testClusterID;nsid=1100938544;c=1606980199054) storage 8f01febb-1c2e-4617-a206-a73518a9f66d
2020-12-03 07:23:23,259 [IPC Server handler 4 on default port 41220] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:44600
2020-12-03 07:23:23,259 [IPC Server handler 1 on default port 42106] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:39171
2020-12-03 07:23:23,259 [IPC Server handler 6 on default port 42380] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:44600
2020-12-03 07:23:23,260 [IPC Server handler 4 on default port 41220] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 8f01febb-1c2e-4617-a206-a73518a9f66d (127.0.0.1:44600).
2020-12-03 07:23:23,259 [IPC Server handler 8 on default port 41178] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:39171
2020-12-03 07:23:23,260 [IPC Server handler 6 on default port 42380] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 8f01febb-1c2e-4617-a206-a73518a9f66d (127.0.0.1:44600).
2020-12-03 07:23:23,260 [IPC Server handler 1 on default port 42106] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN b9a147fb-134d-449d-b6a4-64a8ee59436a (127.0.0.1:39171).
2020-12-03 07:23:23,262 [IPC Server handler 8 on default port 41178] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN b9a147fb-134d-449d-b6a4-64a8ee59436a (127.0.0.1:39171).
2020-12-03 07:23:23,265 [IPC Server handler 7 on default port 41178] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:44600, datanodeUuid=8f01febb-1c2e-4617-a206-a73518a9f66d, infoPort=40111, infoSecurePort=0, ipcPort=40840, storageInfo=lv=-57;cid=testClusterID;nsid=415304149;c=1606980196097) storage 8f01febb-1c2e-4617-a206-a73518a9f66d
2020-12-03 07:23:23,265 [IPC Server handler 7 on default port 41178] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:44600
2020-12-03 07:23:23,266 [IPC Server handler 7 on default port 41178] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 8f01febb-1c2e-4617-a206-a73518a9f66d (127.0.0.1:44600).
2020-12-03 07:23:23,267 [IPC Server handler 6 on default port 41220] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:39171, datanodeUuid=b9a147fb-134d-449d-b6a4-64a8ee59436a, infoPort=39808, infoSecurePort=0, ipcPort=44521, storageInfo=lv=-57;cid=testClusterID;nsid=1100938544;c=1606980199054) storage b9a147fb-134d-449d-b6a4-64a8ee59436a
2020-12-03 07:23:23,268 [IPC Server handler 6 on default port 41220] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:39171
2020-12-03 07:23:23,268 [IPC Server handler 6 on default port 41220] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN b9a147fb-134d-449d-b6a4-64a8ee59436a (127.0.0.1:39171).
2020-12-03 07:23:23,269 [IPC Server handler 3 on default port 42106] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:44600, datanodeUuid=8f01febb-1c2e-4617-a206-a73518a9f66d, infoPort=40111, infoSecurePort=0, ipcPort=40840, storageInfo=lv=-57;cid=testClusterID;nsid=1100938544;c=1606980199054) storage 8f01febb-1c2e-4617-a206-a73518a9f66d
2020-12-03 07:23:23,269 [IPC Server handler 3 on default port 42106] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:44600
2020-12-03 07:23:23,269 [IPC Server handler 5 on default port 42380] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:39171, datanodeUuid=b9a147fb-134d-449d-b6a4-64a8ee59436a, infoPort=39808, infoSecurePort=0, ipcPort=44521, storageInfo=lv=-57;cid=testClusterID;nsid=415304149;c=1606980196097) storage b9a147fb-134d-449d-b6a4-64a8ee59436a
2020-12-03 07:23:23,269 [IPC Server handler 5 on default port 42380] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:39171
2020-12-03 07:23:23,269 [BP-286010920-172.17.0.2-1606980199054 heartbeating to localhost/127.0.0.1:42106] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-286010920-172.17.0.2-1606980199054 (Datanode Uuid b9a147fb-134d-449d-b6a4-64a8ee59436a) service to localhost/127.0.0.1:42106 successfully registered with NN
2020-12-03 07:23:23,270 [BP-286010920-172.17.0.2-1606980199054 heartbeating to localhost/127.0.0.1:42106] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:42106 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:23,270 [BP-286010920-172.17.0.2-1606980199054 heartbeating to localhost/127.0.0.1:41220] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-286010920-172.17.0.2-1606980199054 (Datanode Uuid 8f01febb-1c2e-4617-a206-a73518a9f66d) service to localhost/127.0.0.1:41220 successfully registered with NN
2020-12-03 07:23:23,270 [BP-2036634619-172.17.0.2-1606980196096 heartbeating to localhost/127.0.0.1:41178] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-2036634619-172.17.0.2-1606980196096 (Datanode Uuid 8f01febb-1c2e-4617-a206-a73518a9f66d) service to localhost/127.0.0.1:41178 successfully registered with NN
2020-12-03 07:23:23,270 [BP-2036634619-172.17.0.2-1606980196096 heartbeating to localhost/127.0.0.1:41178] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:41178 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:23,270 [BP-2036634619-172.17.0.2-1606980196096 heartbeating to localhost/127.0.0.1:41178] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-2036634619-172.17.0.2-1606980196096 (Datanode Uuid b9a147fb-134d-449d-b6a4-64a8ee59436a) service to localhost/127.0.0.1:41178 successfully registered with NN
2020-12-03 07:23:23,270 [BP-2036634619-172.17.0.2-1606980196096 heartbeating to localhost/127.0.0.1:41178] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:41178 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:23,270 [IPC Server handler 5 on default port 42380] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN b9a147fb-134d-449d-b6a4-64a8ee59436a (127.0.0.1:39171).
2020-12-03 07:23:23,270 [BP-286010920-172.17.0.2-1606980199054 heartbeating to localhost/127.0.0.1:41220] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-286010920-172.17.0.2-1606980199054 (Datanode Uuid b9a147fb-134d-449d-b6a4-64a8ee59436a) service to localhost/127.0.0.1:41220 successfully registered with NN
2020-12-03 07:23:23,270 [BP-286010920-172.17.0.2-1606980199054 heartbeating to localhost/127.0.0.1:41220] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:41220 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:23,270 [BP-2036634619-172.17.0.2-1606980196096 heartbeating to localhost/127.0.0.1:42380] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-2036634619-172.17.0.2-1606980196096 (Datanode Uuid 8f01febb-1c2e-4617-a206-a73518a9f66d) service to localhost/127.0.0.1:42380 successfully registered with NN
2020-12-03 07:23:23,274 [BP-2036634619-172.17.0.2-1606980196096 heartbeating to localhost/127.0.0.1:42380] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-2036634619-172.17.0.2-1606980196096 (Datanode Uuid b9a147fb-134d-449d-b6a4-64a8ee59436a) service to localhost/127.0.0.1:42380 successfully registered with NN
2020-12-03 07:23:23,274 [BP-2036634619-172.17.0.2-1606980196096 heartbeating to localhost/127.0.0.1:42380] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:42380 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:23,273 [BP-286010920-172.17.0.2-1606980199054 heartbeating to localhost/127.0.0.1:41220] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:41220 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:23,272 [IPC Server handler 3 on default port 42106] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 8f01febb-1c2e-4617-a206-a73518a9f66d (127.0.0.1:44600).
2020-12-03 07:23:23,274 [BP-2036634619-172.17.0.2-1606980196096 heartbeating to localhost/127.0.0.1:42380] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:42380 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:23,277 [BP-286010920-172.17.0.2-1606980199054 heartbeating to localhost/127.0.0.1:42106] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-286010920-172.17.0.2-1606980199054 (Datanode Uuid 8f01febb-1c2e-4617-a206-a73518a9f66d) service to localhost/127.0.0.1:42106 successfully registered with NN
2020-12-03 07:23:23,277 [BP-286010920-172.17.0.2-1606980199054 heartbeating to localhost/127.0.0.1:42106] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:42106 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:23,308 [IPC Server handler 6 on default port 42106] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d5770dd2-4b97-4a60-8165-e6f7485bd547 for DN 127.0.0.1:39171
2020-12-03 07:23:23,309 [IPC Server handler 6 on default port 42106] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-5e7b33bf-2080-44f8-ba26-78c5f795a346 for DN 127.0.0.1:39171
2020-12-03 07:23:23,318 [IPC Server handler 2 on default port 41220] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-93ea001c-b6e4-4144-83cf-5e00deaaa577 for DN 127.0.0.1:44600
2020-12-03 07:23:23,310 [IPC Server handler 5 on default port 41178] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d5770dd2-4b97-4a60-8165-e6f7485bd547 for DN 127.0.0.1:39171
2020-12-03 07:23:23,318 [IPC Server handler 7 on default port 42106] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-93ea001c-b6e4-4144-83cf-5e00deaaa577 for DN 127.0.0.1:44600
2020-12-03 07:23:23,318 [IPC Server handler 4 on default port 42380] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-93ea001c-b6e4-4144-83cf-5e00deaaa577 for DN 127.0.0.1:44600
2020-12-03 07:23:23,320 [IPC Server handler 7 on default port 42106] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-8ae2d45d-3ea1-4fcf-936e-d146876566da for DN 127.0.0.1:44600
2020-12-03 07:23:23,318 [IPC Server handler 5 on default port 41178] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-5e7b33bf-2080-44f8-ba26-78c5f795a346 for DN 127.0.0.1:39171
2020-12-03 07:23:23,318 [IPC Server handler 2 on default port 41220] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-8ae2d45d-3ea1-4fcf-936e-d146876566da for DN 127.0.0.1:44600
2020-12-03 07:23:23,320 [IPC Server handler 4 on default port 42380] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-8ae2d45d-3ea1-4fcf-936e-d146876566da for DN 127.0.0.1:44600
2020-12-03 07:23:23,321 [IPC Server handler 6 on default port 41178] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-93ea001c-b6e4-4144-83cf-5e00deaaa577 for DN 127.0.0.1:44600
2020-12-03 07:23:23,321 [IPC Server handler 1 on default port 41220] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d5770dd2-4b97-4a60-8165-e6f7485bd547 for DN 127.0.0.1:39171
2020-12-03 07:23:23,327 [IPC Server handler 6 on default port 41178] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-8ae2d45d-3ea1-4fcf-936e-d146876566da for DN 127.0.0.1:44600
2020-12-03 07:23:23,325 [IPC Server handler 9 on default port 42380] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d5770dd2-4b97-4a60-8165-e6f7485bd547 for DN 127.0.0.1:39171
2020-12-03 07:23:23,328 [IPC Server handler 1 on default port 41220] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-5e7b33bf-2080-44f8-ba26-78c5f795a346 for DN 127.0.0.1:39171
2020-12-03 07:23:23,328 [IPC Server handler 9 on default port 42380] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-5e7b33bf-2080-44f8-ba26-78c5f795a346 for DN 127.0.0.1:39171
2020-12-03 07:23:23,351 [Thread-236] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 1917c584-39c3-42c1-87c7-45983f4c84fe
2020-12-03 07:23:23,355 [Thread-236] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-32ee6b6e-ecea-462a-922f-e3967ffcb365
2020-12-03 07:23:23,355 [Thread-236] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, StorageType: DISK
2020-12-03 07:23:23,351 [Thread-211] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID b997f6ab-56cf-4acb-b159-8dac72f89a15
2020-12-03 07:23:23,357 [Thread-236] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-f1560c54-0c7f-451c-ade4-648ed1535376
2020-12-03 07:23:23,363 [Thread-236] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, StorageType: DISK
2020-12-03 07:23:23,366 [Thread-236] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:23:23,369 [Thread-236] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7
2020-12-03 07:23:23,379 [IPC Server handler 0 on default port 42380] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:23,389 [Thread-212] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-c7fc4836-6abf-432b-835a-5c81775ebbd5
2020-12-03 07:23:23,389 [Thread-212] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, StorageType: DISK
2020-12-03 07:23:23,391 [Thread-238] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:23:23,391 [Thread-238] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7 has already been used.
2020-12-03 07:23:23,391 [Thread-238] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8 has already been used.
2020-12-03 07:23:23,401 [Thread-236] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7
2020-12-03 07:23:23,401 [Thread-236] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-12-03 07:23:23,402 [Thread-236] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-12-03 07:23:23,402 [Thread-236] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-2036634619-172.17.0.2-1606980196096
2020-12-03 07:23:23,402 [Thread-289] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-2036634619-172.17.0.2-1606980196096 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7...
2020-12-03 07:23:23,402 [Thread-290] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-2036634619-172.17.0.2-1606980196096 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8...
2020-12-03 07:23:23,404 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xb23f4b4cdc0248e: Processing first storage report for DS-d5770dd2-4b97-4a60-8165-e6f7485bd547 from datanode b9a147fb-134d-449d-b6a4-64a8ee59436a
2020-12-03 07:23:23,406 [Listener at localhost/45068] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:23,406 [Listener at localhost/45068] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:23,407 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xb23f4b4cdc0248e: from storage DS-d5770dd2-4b97-4a60-8165-e6f7485bd547 node DatanodeRegistration(127.0.0.1:39171, datanodeUuid=b9a147fb-134d-449d-b6a4-64a8ee59436a, infoPort=39808, infoSecurePort=0, ipcPort=44521, storageInfo=lv=-57;cid=testClusterID;nsid=1100938544;c=1606980199054), blocks: 0, hasStaleStorage: true, processing time: 2 msecs, invalidatedBlocks: 0
2020-12-03 07:23:23,407 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x7e853c270fc24320: Processing first storage report for DS-93ea001c-b6e4-4144-83cf-5e00deaaa577 from datanode 8f01febb-1c2e-4617-a206-a73518a9f66d
2020-12-03 07:23:23,407 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x7e853c270fc24320: from storage DS-93ea001c-b6e4-4144-83cf-5e00deaaa577 node DatanodeRegistration(127.0.0.1:44600, datanodeUuid=8f01febb-1c2e-4617-a206-a73518a9f66d, infoPort=40111, infoSecurePort=0, ipcPort=40840, storageInfo=lv=-57;cid=testClusterID;nsid=1100938544;c=1606980199054), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:23,407 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xb23f4b4cdc0248e: Processing first storage report for DS-5e7b33bf-2080-44f8-ba26-78c5f795a346 from datanode b9a147fb-134d-449d-b6a4-64a8ee59436a
2020-12-03 07:23:23,409 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x24188e96c8c663e1: Processing first storage report for DS-93ea001c-b6e4-4144-83cf-5e00deaaa577 from datanode 8f01febb-1c2e-4617-a206-a73518a9f66d
2020-12-03 07:23:23,409 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xb23f4b4cdc0248e: from storage DS-5e7b33bf-2080-44f8-ba26-78c5f795a346 node DatanodeRegistration(127.0.0.1:39171, datanodeUuid=b9a147fb-134d-449d-b6a4-64a8ee59436a, infoPort=39808, infoSecurePort=0, ipcPort=44521, storageInfo=lv=-57;cid=testClusterID;nsid=1100938544;c=1606980199054), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:23,410 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x6a03416172b672c3: Processing first storage report for DS-93ea001c-b6e4-4144-83cf-5e00deaaa577 from datanode 8f01febb-1c2e-4617-a206-a73518a9f66d
2020-12-03 07:23:23,411 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x852e6bd003e07f43: Processing first storage report for DS-d5770dd2-4b97-4a60-8165-e6f7485bd547 from datanode b9a147fb-134d-449d-b6a4-64a8ee59436a
2020-12-03 07:23:23,411 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x24188e96c8c663e1: from storage DS-93ea001c-b6e4-4144-83cf-5e00deaaa577 node DatanodeRegistration(127.0.0.1:44600, datanodeUuid=8f01febb-1c2e-4617-a206-a73518a9f66d, infoPort=40111, infoSecurePort=0, ipcPort=40840, storageInfo=lv=-57;cid=testClusterID;nsid=415304149;c=1606980196097), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:23:23,412 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x83055befc013a00f: Processing first storage report for DS-d5770dd2-4b97-4a60-8165-e6f7485bd547 from datanode b9a147fb-134d-449d-b6a4-64a8ee59436a
2020-12-03 07:23:23,412 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x83055befc013a00f: from storage DS-d5770dd2-4b97-4a60-8165-e6f7485bd547 node DatanodeRegistration(127.0.0.1:39171, datanodeUuid=b9a147fb-134d-449d-b6a4-64a8ee59436a, infoPort=39808, infoSecurePort=0, ipcPort=44521, storageInfo=lv=-57;cid=testClusterID;nsid=415304149;c=1606980196097), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:23,412 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x24188e96c8c663e1: Processing first storage report for DS-8ae2d45d-3ea1-4fcf-936e-d146876566da from datanode 8f01febb-1c2e-4617-a206-a73518a9f66d
2020-12-03 07:23:23,412 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x24188e96c8c663e1: from storage DS-8ae2d45d-3ea1-4fcf-936e-d146876566da node DatanodeRegistration(127.0.0.1:44600, datanodeUuid=8f01febb-1c2e-4617-a206-a73518a9f66d, infoPort=40111, infoSecurePort=0, ipcPort=40840, storageInfo=lv=-57;cid=testClusterID;nsid=415304149;c=1606980196097), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:23,412 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x83055befc013a00f: Processing first storage report for DS-5e7b33bf-2080-44f8-ba26-78c5f795a346 from datanode b9a147fb-134d-449d-b6a4-64a8ee59436a
2020-12-03 07:23:23,412 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x83055befc013a00f: from storage DS-5e7b33bf-2080-44f8-ba26-78c5f795a346 node DatanodeRegistration(127.0.0.1:39171, datanodeUuid=b9a147fb-134d-449d-b6a4-64a8ee59436a, infoPort=39808, infoSecurePort=0, ipcPort=44521, storageInfo=lv=-57;cid=testClusterID;nsid=415304149;c=1606980196097), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:23,411 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x852e6bd003e07f43: from storage DS-d5770dd2-4b97-4a60-8165-e6f7485bd547 node DatanodeRegistration(127.0.0.1:39171, datanodeUuid=b9a147fb-134d-449d-b6a4-64a8ee59436a, infoPort=39808, infoSecurePort=0, ipcPort=44521, storageInfo=lv=-57;cid=testClusterID;nsid=415304149;c=1606980196097), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:23,421 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x9ae09fb47d09529f: Processing first storage report for DS-93ea001c-b6e4-4144-83cf-5e00deaaa577 from datanode 8f01febb-1c2e-4617-a206-a73518a9f66d
2020-12-03 07:23:23,421 [Thread-212] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-9dc1839e-cbff-43d6-ae19-9f469f186f57
2020-12-03 07:23:23,411 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x6a03416172b672c3: from storage DS-93ea001c-b6e4-4144-83cf-5e00deaaa577 node DatanodeRegistration(127.0.0.1:44600, datanodeUuid=8f01febb-1c2e-4617-a206-a73518a9f66d, infoPort=40111, infoSecurePort=0, ipcPort=40840, storageInfo=lv=-57;cid=testClusterID;nsid=1100938544;c=1606980199054), blocks: 0, hasStaleStorage: true, processing time: 2 msecs, invalidatedBlocks: 0
2020-12-03 07:23:23,423 [Thread-212] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, StorageType: DISK
2020-12-03 07:23:23,423 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xe7c7252f58b9331e: Processing first storage report for DS-d5770dd2-4b97-4a60-8165-e6f7485bd547 from datanode b9a147fb-134d-449d-b6a4-64a8ee59436a
2020-12-03 07:23:23,423 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xe7c7252f58b9331e: from storage DS-d5770dd2-4b97-4a60-8165-e6f7485bd547 node DatanodeRegistration(127.0.0.1:39171, datanodeUuid=b9a147fb-134d-449d-b6a4-64a8ee59436a, infoPort=39808, infoSecurePort=0, ipcPort=44521, storageInfo=lv=-57;cid=testClusterID;nsid=1100938544;c=1606980199054), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:23:23,423 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xe7c7252f58b9331e: Processing first storage report for DS-5e7b33bf-2080-44f8-ba26-78c5f795a346 from datanode b9a147fb-134d-449d-b6a4-64a8ee59436a
2020-12-03 07:23:23,424 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xe7c7252f58b9331e: from storage DS-5e7b33bf-2080-44f8-ba26-78c5f795a346 node DatanodeRegistration(127.0.0.1:39171, datanodeUuid=b9a147fb-134d-449d-b6a4-64a8ee59436a, infoPort=39808, infoSecurePort=0, ipcPort=44521, storageInfo=lv=-57;cid=testClusterID;nsid=1100938544;c=1606980199054), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:23,424 [Thread-212] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:23:23,425 [Thread-212] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-12-03 07:23:23,425 [Thread-238] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-286010920-172.17.0.2-1606980199054
2020-12-03 07:23:23,421 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x9ae09fb47d09529f: from storage DS-93ea001c-b6e4-4144-83cf-5e00deaaa577 node DatanodeRegistration(127.0.0.1:44600, datanodeUuid=8f01febb-1c2e-4617-a206-a73518a9f66d, infoPort=40111, infoSecurePort=0, ipcPort=40840, storageInfo=lv=-57;cid=testClusterID;nsid=415304149;c=1606980196097), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:23,412 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x7e853c270fc24320: Processing first storage report for DS-8ae2d45d-3ea1-4fcf-936e-d146876566da from datanode 8f01febb-1c2e-4617-a206-a73518a9f66d
2020-12-03 07:23:23,426 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x9ae09fb47d09529f: Processing first storage report for DS-8ae2d45d-3ea1-4fcf-936e-d146876566da from datanode 8f01febb-1c2e-4617-a206-a73518a9f66d
2020-12-03 07:23:23,425 [Thread-238] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-286010920-172.17.0.2-1606980199054
2020-12-03 07:23:23,425 [Thread-211] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-12-03 07:23:23,426 [Thread-238] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7 and block pool id BP-286010920-172.17.0.2-1606980199054 is not formatted. Formatting ...
2020-12-03 07:23:23,427 [Thread-238] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-286010920-172.17.0.2-1606980199054 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-286010920-172.17.0.2-1606980199054/current
2020-12-03 07:23:23,427 [Thread-211] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-12-03 07:23:23,427 [Thread-211] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-12-03 07:23:23,427 [Thread-211] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-12-03 07:23:23,426 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x7e853c270fc24320: from storage DS-8ae2d45d-3ea1-4fcf-936e-d146876566da node DatanodeRegistration(127.0.0.1:44600, datanodeUuid=8f01febb-1c2e-4617-a206-a73518a9f66d, infoPort=40111, infoSecurePort=0, ipcPort=40840, storageInfo=lv=-57;cid=testClusterID;nsid=1100938544;c=1606980199054), blocks: 0, hasStaleStorage: false, processing time: 14 msecs, invalidatedBlocks: 0
2020-12-03 07:23:23,426 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x9ae09fb47d09529f: from storage DS-8ae2d45d-3ea1-4fcf-936e-d146876566da node DatanodeRegistration(127.0.0.1:44600, datanodeUuid=8f01febb-1c2e-4617-a206-a73518a9f66d, infoPort=40111, infoSecurePort=0, ipcPort=40840, storageInfo=lv=-57;cid=testClusterID;nsid=415304149;c=1606980196097), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:23:23,430 [Thread-211] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-2036634619-172.17.0.2-1606980196096
2020-12-03 07:23:23,429 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x6a03416172b672c3: Processing first storage report for DS-8ae2d45d-3ea1-4fcf-936e-d146876566da from datanode 8f01febb-1c2e-4617-a206-a73518a9f66d
2020-12-03 07:23:23,430 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x852e6bd003e07f43: Processing first storage report for DS-5e7b33bf-2080-44f8-ba26-78c5f795a346 from datanode b9a147fb-134d-449d-b6a4-64a8ee59436a
2020-12-03 07:23:23,430 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x6a03416172b672c3: from storage DS-8ae2d45d-3ea1-4fcf-936e-d146876566da node DatanodeRegistration(127.0.0.1:44600, datanodeUuid=8f01febb-1c2e-4617-a206-a73518a9f66d, infoPort=40111, infoSecurePort=0, ipcPort=40840, storageInfo=lv=-57;cid=testClusterID;nsid=1100938544;c=1606980199054), blocks: 0, hasStaleStorage: false, processing time: 2 msecs, invalidatedBlocks: 0
2020-12-03 07:23:23,431 [Thread-294] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-2036634619-172.17.0.2-1606980196096 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5...
2020-12-03 07:23:23,430 [Thread-212] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-12-03 07:23:23,431 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x852e6bd003e07f43: from storage DS-5e7b33bf-2080-44f8-ba26-78c5f795a346 node DatanodeRegistration(127.0.0.1:39171, datanodeUuid=b9a147fb-134d-449d-b6a4-64a8ee59436a, infoPort=39808, infoSecurePort=0, ipcPort=44521, storageInfo=lv=-57;cid=testClusterID;nsid=415304149;c=1606980196097), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:23,431 [Thread-295] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-2036634619-172.17.0.2-1606980196096 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6...
2020-12-03 07:23:23,431 [Thread-212] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-12-03 07:23:23,431 [Thread-212] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-286010920-172.17.0.2-1606980199054
2020-12-03 07:23:23,439 [Thread-290] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-2036634619-172.17.0.2-1606980196096 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8: 36ms
2020-12-03 07:23:23,439 [Thread-289] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-2036634619-172.17.0.2-1606980196096 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7: 36ms
2020-12-03 07:23:23,440 [Thread-236] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-2036634619-172.17.0.2-1606980196096: 38ms
2020-12-03 07:23:23,442 [Thread-298] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-2036634619-172.17.0.2-1606980196096 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7...
2020-12-03 07:23:23,442 [Thread-299] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-2036634619-172.17.0.2-1606980196096 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8...
2020-12-03 07:23:23,443 [Thread-298] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-2036634619-172.17.0.2-1606980196096/current/replicas doesn't exist 
2020-12-03 07:23:23,443 [Thread-299] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-2036634619-172.17.0.2-1606980196096/current/replicas doesn't exist 
2020-12-03 07:23:23,443 [Thread-298] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-2036634619-172.17.0.2-1606980196096 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7: 0ms
2020-12-03 07:23:23,443 [Thread-299] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-2036634619-172.17.0.2-1606980196096 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8: 1ms
2020-12-03 07:23:23,445 [Thread-236] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-2036634619-172.17.0.2-1606980196096: 4ms
2020-12-03 07:23:23,447 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-2036634619-172.17.0.2-1606980196096 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7
2020-12-03 07:23:23,447 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-2036634619-172.17.0.2-1606980196096 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-12-03 07:23:23,447 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, DS-32ee6b6e-ecea-462a-922f-e3967ffcb365): finished scanning block pool BP-2036634619-172.17.0.2-1606980196096
2020-12-03 07:23:23,447 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, DS-f1560c54-0c7f-451c-ade4-648ed1535376): finished scanning block pool BP-2036634619-172.17.0.2-1606980196096
2020-12-03 07:23:23,448 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, DS-32ee6b6e-ecea-462a-922f-e3967ffcb365): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:23:23,448 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, DS-f1560c54-0c7f-451c-ade4-648ed1535376): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:23:23,454 [BP-286010920-172.17.0.2-1606980199054 heartbeating to localhost/127.0.0.1:41220] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xb23f4b4cdc0248e,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 7 msec to generate and 100 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:23:23,454 [BP-2036634619-172.17.0.2-1606980196096 heartbeating to localhost/127.0.0.1:42380] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x24188e96c8c663e1,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 99 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:23:23,454 [BP-2036634619-172.17.0.2-1606980196096 heartbeating to localhost/127.0.0.1:41178] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x9ae09fb47d09529f,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 7 msec to generate and 101 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:23:23,454 [BP-2036634619-172.17.0.2-1606980196096 heartbeating to localhost/127.0.0.1:41178] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x852e6bd003e07f43,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 7 msec to generate and 101 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:23:23,454 [BP-286010920-172.17.0.2-1606980199054 heartbeating to localhost/127.0.0.1:42106] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x6a03416172b672c3,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 8 msec to generate and 100 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:23:23,454 [BP-286010920-172.17.0.2-1606980199054 heartbeating to localhost/127.0.0.1:42106] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xe7c7252f58b9331e,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 5 msec to generate and 100 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:23:23,455 [BP-286010920-172.17.0.2-1606980199054 heartbeating to localhost/127.0.0.1:41220] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x7e853c270fc24320,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 7 msec to generate and 102 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:23:23,454 [BP-2036634619-172.17.0.2-1606980196096 heartbeating to localhost/127.0.0.1:42380] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x83055befc013a00f,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 8 msec to generate and 101 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:23:23,456 [Thread-294] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-2036634619-172.17.0.2-1606980196096 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5: 26ms
2020-12-03 07:23:23,457 [Thread-295] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-2036634619-172.17.0.2-1606980196096 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6: 26ms
2020-12-03 07:23:23,457 [Thread-211] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-2036634619-172.17.0.2-1606980196096: 27ms
2020-12-03 07:23:23,458 [Thread-300] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-2036634619-172.17.0.2-1606980196096 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5...
2020-12-03 07:23:23,458 [Thread-300] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-2036634619-172.17.0.2-1606980196096/current/replicas doesn't exist 
2020-12-03 07:23:23,458 [Thread-301] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-286010920-172.17.0.2-1606980199054 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5...
2020-12-03 07:23:23,458 [Thread-300] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-2036634619-172.17.0.2-1606980196096 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5: 1ms
2020-12-03 07:23:23,458 [Thread-303] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-286010920-172.17.0.2-1606980199054 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6...
2020-12-03 07:23:23,459 [Thread-302] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-2036634619-172.17.0.2-1606980196096 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6...
2020-12-03 07:23:23,459 [Thread-302] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-2036634619-172.17.0.2-1606980196096/current/replicas doesn't exist 
2020-12-03 07:23:23,460 [Thread-302] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-2036634619-172.17.0.2-1606980196096 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6: 0ms
2020-12-03 07:23:23,460 [Thread-211] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-2036634619-172.17.0.2-1606980196096: 2ms
2020-12-03 07:23:23,461 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-2036634619-172.17.0.2-1606980196096 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-12-03 07:23:23,461 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-2036634619-172.17.0.2-1606980196096 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-12-03 07:23:23,461 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, DS-9dc1839e-cbff-43d6-ae19-9f469f186f57): finished scanning block pool BP-2036634619-172.17.0.2-1606980196096
2020-12-03 07:23:23,461 [Thread-211] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 7:58 AM with interval of 21600000ms
2020-12-03 07:23:23,461 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, DS-c7fc4836-6abf-432b-835a-5c81775ebbd5): finished scanning block pool BP-2036634619-172.17.0.2-1606980196096
2020-12-03 07:23:23,463 [BP-2036634619-172.17.0.2-1606980196096 heartbeating to localhost/127.0.0.1:41178] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-2036634619-172.17.0.2-1606980196096 (Datanode Uuid b997f6ab-56cf-4acb-b159-8dac72f89a15) service to localhost/127.0.0.1:41178 beginning handshake with NN
2020-12-03 07:23:23,463 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, DS-c7fc4836-6abf-432b-835a-5c81775ebbd5): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-12-03 07:23:23,463 [BP-2036634619-172.17.0.2-1606980196096 heartbeating to localhost/127.0.0.1:42380] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-2036634619-172.17.0.2-1606980196096 (Datanode Uuid b997f6ab-56cf-4acb-b159-8dac72f89a15) service to localhost/127.0.0.1:42380 beginning handshake with NN
2020-12-03 07:23:23,463 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, DS-9dc1839e-cbff-43d6-ae19-9f469f186f57): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:23:23,464 [IPC Server handler 1 on default port 42380] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34378, datanodeUuid=b997f6ab-56cf-4acb-b159-8dac72f89a15, infoPort=37952, infoSecurePort=0, ipcPort=39589, storageInfo=lv=-57;cid=testClusterID;nsid=415304149;c=1606980196097) storage b997f6ab-56cf-4acb-b159-8dac72f89a15
2020-12-03 07:23:23,465 [IPC Server handler 1 on default port 42380] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:34378
2020-12-03 07:23:23,465 [IPC Server handler 1 on default port 42380] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN b997f6ab-56cf-4acb-b159-8dac72f89a15 (127.0.0.1:34378).
2020-12-03 07:23:23,465 [IPC Server handler 1 on default port 41178] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34378, datanodeUuid=b997f6ab-56cf-4acb-b159-8dac72f89a15, infoPort=37952, infoSecurePort=0, ipcPort=39589, storageInfo=lv=-57;cid=testClusterID;nsid=415304149;c=1606980196097) storage b997f6ab-56cf-4acb-b159-8dac72f89a15
2020-12-03 07:23:23,466 [IPC Server handler 1 on default port 41178] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:34378
2020-12-03 07:23:23,466 [IPC Server handler 1 on default port 41178] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN b997f6ab-56cf-4acb-b159-8dac72f89a15 (127.0.0.1:34378).
2020-12-03 07:23:23,482 [BP-2036634619-172.17.0.2-1606980196096 heartbeating to localhost/127.0.0.1:42380] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-2036634619-172.17.0.2-1606980196096 (Datanode Uuid b997f6ab-56cf-4acb-b159-8dac72f89a15) service to localhost/127.0.0.1:42380 successfully registered with NN
2020-12-03 07:23:23,482 [BP-2036634619-172.17.0.2-1606980196096 heartbeating to localhost/127.0.0.1:42380] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:42380 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:23,482 [BP-2036634619-172.17.0.2-1606980196096 heartbeating to localhost/127.0.0.1:41178] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-2036634619-172.17.0.2-1606980196096 (Datanode Uuid b997f6ab-56cf-4acb-b159-8dac72f89a15) service to localhost/127.0.0.1:41178 successfully registered with NN
2020-12-03 07:23:23,482 [BP-2036634619-172.17.0.2-1606980196096 heartbeating to localhost/127.0.0.1:41178] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:41178 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:23,487 [IPC Server handler 0 on default port 41178] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c7fc4836-6abf-432b-835a-5c81775ebbd5 for DN 127.0.0.1:34378
2020-12-03 07:23:23,487 [IPC Server handler 3 on default port 42380] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c7fc4836-6abf-432b-835a-5c81775ebbd5 for DN 127.0.0.1:34378
2020-12-03 07:23:23,487 [IPC Server handler 0 on default port 41178] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-9dc1839e-cbff-43d6-ae19-9f469f186f57 for DN 127.0.0.1:34378
2020-12-03 07:23:23,487 [IPC Server handler 3 on default port 42380] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-9dc1839e-cbff-43d6-ae19-9f469f186f57 for DN 127.0.0.1:34378
2020-12-03 07:23:23,494 [Thread-301] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-286010920-172.17.0.2-1606980199054 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5: 35ms
2020-12-03 07:23:23,494 [Thread-303] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-286010920-172.17.0.2-1606980199054 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6: 35ms
2020-12-03 07:23:23,494 [Thread-212] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-286010920-172.17.0.2-1606980199054: 36ms
2020-12-03 07:23:23,495 [Thread-309] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-286010920-172.17.0.2-1606980199054 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5...
2020-12-03 07:23:23,495 [Thread-309] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-286010920-172.17.0.2-1606980199054/current/replicas doesn't exist 
2020-12-03 07:23:23,495 [Thread-310] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-286010920-172.17.0.2-1606980199054 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6...
2020-12-03 07:23:23,495 [Thread-310] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-286010920-172.17.0.2-1606980199054/current/replicas doesn't exist 
2020-12-03 07:23:23,495 [Thread-309] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-286010920-172.17.0.2-1606980199054 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5: 1ms
2020-12-03 07:23:23,496 [Thread-310] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-286010920-172.17.0.2-1606980199054 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6: 0ms
2020-12-03 07:23:23,496 [Thread-212] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-286010920-172.17.0.2-1606980199054: 1ms
2020-12-03 07:23:23,496 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-286010920-172.17.0.2-1606980199054 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-12-03 07:23:23,496 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x67d358ca475c8541: Processing first storage report for DS-c7fc4836-6abf-432b-835a-5c81775ebbd5 from datanode b997f6ab-56cf-4acb-b159-8dac72f89a15
2020-12-03 07:23:23,496 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-286010920-172.17.0.2-1606980199054 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-12-03 07:23:23,496 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x67d358ca475c8541: from storage DS-c7fc4836-6abf-432b-835a-5c81775ebbd5 node DatanodeRegistration(127.0.0.1:34378, datanodeUuid=b997f6ab-56cf-4acb-b159-8dac72f89a15, infoPort=37952, infoSecurePort=0, ipcPort=39589, storageInfo=lv=-57;cid=testClusterID;nsid=415304149;c=1606980196097), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:23,497 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, DS-c7fc4836-6abf-432b-835a-5c81775ebbd5): finished scanning block pool BP-286010920-172.17.0.2-1606980199054
2020-12-03 07:23:23,496 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, DS-9dc1839e-cbff-43d6-ae19-9f469f186f57): finished scanning block pool BP-286010920-172.17.0.2-1606980199054
2020-12-03 07:23:23,496 [BP-286010920-172.17.0.2-1606980199054 heartbeating to localhost/127.0.0.1:42106] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-286010920-172.17.0.2-1606980199054 (Datanode Uuid b997f6ab-56cf-4acb-b159-8dac72f89a15) service to localhost/127.0.0.1:42106 beginning handshake with NN
2020-12-03 07:23:23,496 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x6dbfe8cb2dfd7177: Processing first storage report for DS-c7fc4836-6abf-432b-835a-5c81775ebbd5 from datanode b997f6ab-56cf-4acb-b159-8dac72f89a15
2020-12-03 07:23:23,497 [BP-286010920-172.17.0.2-1606980199054 heartbeating to localhost/127.0.0.1:41220] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-286010920-172.17.0.2-1606980199054 (Datanode Uuid b997f6ab-56cf-4acb-b159-8dac72f89a15) service to localhost/127.0.0.1:41220 beginning handshake with NN
2020-12-03 07:23:23,497 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x6dbfe8cb2dfd7177: from storage DS-c7fc4836-6abf-432b-835a-5c81775ebbd5 node DatanodeRegistration(127.0.0.1:34378, datanodeUuid=b997f6ab-56cf-4acb-b159-8dac72f89a15, infoPort=37952, infoSecurePort=0, ipcPort=39589, storageInfo=lv=-57;cid=testClusterID;nsid=415304149;c=1606980196097), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:23,497 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, DS-c7fc4836-6abf-432b-835a-5c81775ebbd5): no suitable block pools found to scan.  Waiting 1814399964 ms.
2020-12-03 07:23:23,497 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, DS-9dc1839e-cbff-43d6-ae19-9f469f186f57): no suitable block pools found to scan.  Waiting 1814399964 ms.
2020-12-03 07:23:23,497 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x6dbfe8cb2dfd7177: Processing first storage report for DS-9dc1839e-cbff-43d6-ae19-9f469f186f57 from datanode b997f6ab-56cf-4acb-b159-8dac72f89a15
2020-12-03 07:23:23,498 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x6dbfe8cb2dfd7177: from storage DS-9dc1839e-cbff-43d6-ae19-9f469f186f57 node DatanodeRegistration(127.0.0.1:34378, datanodeUuid=b997f6ab-56cf-4acb-b159-8dac72f89a15, infoPort=37952, infoSecurePort=0, ipcPort=39589, storageInfo=lv=-57;cid=testClusterID;nsid=415304149;c=1606980196097), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:23,498 [IPC Server handler 4 on default port 42106] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34378, datanodeUuid=b997f6ab-56cf-4acb-b159-8dac72f89a15, infoPort=37952, infoSecurePort=0, ipcPort=39589, storageInfo=lv=-57;cid=testClusterID;nsid=1100938544;c=1606980199054) storage b997f6ab-56cf-4acb-b159-8dac72f89a15
2020-12-03 07:23:23,500 [IPC Server handler 4 on default port 42106] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:34378
2020-12-03 07:23:23,500 [IPC Server handler 4 on default port 42106] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN b997f6ab-56cf-4acb-b159-8dac72f89a15 (127.0.0.1:34378).
2020-12-03 07:23:23,499 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x67d358ca475c8541: Processing first storage report for DS-9dc1839e-cbff-43d6-ae19-9f469f186f57 from datanode b997f6ab-56cf-4acb-b159-8dac72f89a15
2020-12-03 07:23:23,499 [BP-2036634619-172.17.0.2-1606980196096 heartbeating to localhost/127.0.0.1:42380] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x6dbfe8cb2dfd7177,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 6 msec to generate and 4 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:23:23,498 [IPC Server handler 6 on default port 41220] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34378, datanodeUuid=b997f6ab-56cf-4acb-b159-8dac72f89a15, infoPort=37952, infoSecurePort=0, ipcPort=39589, storageInfo=lv=-57;cid=testClusterID;nsid=1100938544;c=1606980199054) storage b997f6ab-56cf-4acb-b159-8dac72f89a15
2020-12-03 07:23:23,501 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x67d358ca475c8541: from storage DS-9dc1839e-cbff-43d6-ae19-9f469f186f57 node DatanodeRegistration(127.0.0.1:34378, datanodeUuid=b997f6ab-56cf-4acb-b159-8dac72f89a15, infoPort=37952, infoSecurePort=0, ipcPort=39589, storageInfo=lv=-57;cid=testClusterID;nsid=415304149;c=1606980196097), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:23:23,501 [BP-286010920-172.17.0.2-1606980199054 heartbeating to localhost/127.0.0.1:42106] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-286010920-172.17.0.2-1606980199054 (Datanode Uuid b997f6ab-56cf-4acb-b159-8dac72f89a15) service to localhost/127.0.0.1:42106 successfully registered with NN
2020-12-03 07:23:23,502 [IPC Server handler 6 on default port 41220] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:34378
2020-12-03 07:23:23,502 [BP-286010920-172.17.0.2-1606980199054 heartbeating to localhost/127.0.0.1:42106] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:42106 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:23,502 [IPC Server handler 6 on default port 41220] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN b997f6ab-56cf-4acb-b159-8dac72f89a15 (127.0.0.1:34378).
2020-12-03 07:23:23,502 [BP-2036634619-172.17.0.2-1606980196096 heartbeating to localhost/127.0.0.1:41178] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x67d358ca475c8541,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 6 msec to generate and 8 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:23:23,503 [BP-286010920-172.17.0.2-1606980199054 heartbeating to localhost/127.0.0.1:41220] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-286010920-172.17.0.2-1606980199054 (Datanode Uuid b997f6ab-56cf-4acb-b159-8dac72f89a15) service to localhost/127.0.0.1:41220 successfully registered with NN
2020-12-03 07:23:23,503 [BP-286010920-172.17.0.2-1606980199054 heartbeating to localhost/127.0.0.1:41220] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:41220 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:23,504 [IPC Server handler 8 on default port 42106] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c7fc4836-6abf-432b-835a-5c81775ebbd5 for DN 127.0.0.1:34378
2020-12-03 07:23:23,505 [IPC Server handler 8 on default port 42106] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-9dc1839e-cbff-43d6-ae19-9f469f186f57 for DN 127.0.0.1:34378
2020-12-03 07:23:23,514 [IPC Server handler 7 on default port 41220] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c7fc4836-6abf-432b-835a-5c81775ebbd5 for DN 127.0.0.1:34378
2020-12-03 07:23:23,514 [IPC Server handler 7 on default port 41220] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-9dc1839e-cbff-43d6-ae19-9f469f186f57 for DN 127.0.0.1:34378
2020-12-03 07:23:23,516 [IPC Server handler 6 on default port 42380] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:23,517 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x14bb8ea42247c847: Processing first storage report for DS-c7fc4836-6abf-432b-835a-5c81775ebbd5 from datanode b997f6ab-56cf-4acb-b159-8dac72f89a15
2020-12-03 07:23:23,517 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x14bb8ea42247c847: from storage DS-c7fc4836-6abf-432b-835a-5c81775ebbd5 node DatanodeRegistration(127.0.0.1:34378, datanodeUuid=b997f6ab-56cf-4acb-b159-8dac72f89a15, infoPort=37952, infoSecurePort=0, ipcPort=39589, storageInfo=lv=-57;cid=testClusterID;nsid=1100938544;c=1606980199054), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:23,518 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x14bb8ea42247c847: Processing first storage report for DS-9dc1839e-cbff-43d6-ae19-9f469f186f57 from datanode b997f6ab-56cf-4acb-b159-8dac72f89a15
2020-12-03 07:23:23,518 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x14bb8ea42247c847: from storage DS-9dc1839e-cbff-43d6-ae19-9f469f186f57 node DatanodeRegistration(127.0.0.1:34378, datanodeUuid=b997f6ab-56cf-4acb-b159-8dac72f89a15, infoPort=37952, infoSecurePort=0, ipcPort=39589, storageInfo=lv=-57;cid=testClusterID;nsid=1100938544;c=1606980199054), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:23,519 [BP-286010920-172.17.0.2-1606980199054 heartbeating to localhost/127.0.0.1:42106] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x14bb8ea42247c847,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 4 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:23:23,520 [Listener at localhost/45068] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:23,521 [Listener at localhost/45068] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:23,533 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xf037bd9e0429ef97: Processing first storage report for DS-c7fc4836-6abf-432b-835a-5c81775ebbd5 from datanode b997f6ab-56cf-4acb-b159-8dac72f89a15
2020-12-03 07:23:23,534 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xf037bd9e0429ef97: from storage DS-c7fc4836-6abf-432b-835a-5c81775ebbd5 node DatanodeRegistration(127.0.0.1:34378, datanodeUuid=b997f6ab-56cf-4acb-b159-8dac72f89a15, infoPort=37952, infoSecurePort=0, ipcPort=39589, storageInfo=lv=-57;cid=testClusterID;nsid=1100938544;c=1606980199054), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:23,534 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xf037bd9e0429ef97: Processing first storage report for DS-9dc1839e-cbff-43d6-ae19-9f469f186f57 from datanode b997f6ab-56cf-4acb-b159-8dac72f89a15
2020-12-03 07:23:23,534 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xf037bd9e0429ef97: from storage DS-9dc1839e-cbff-43d6-ae19-9f469f186f57 node DatanodeRegistration(127.0.0.1:34378, datanodeUuid=b997f6ab-56cf-4acb-b159-8dac72f89a15, infoPort=37952, infoSecurePort=0, ipcPort=39589, storageInfo=lv=-57;cid=testClusterID;nsid=1100938544;c=1606980199054), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:23,535 [BP-286010920-172.17.0.2-1606980199054 heartbeating to localhost/127.0.0.1:41220] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xf037bd9e0429ef97,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 15 msec to generate and 3 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:23:23,555 [Thread-238] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-286010920-172.17.0.2-1606980199054
2020-12-03 07:23:23,555 [Thread-238] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-286010920-172.17.0.2-1606980199054
2020-12-03 07:23:23,556 [Thread-238] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8 and block pool id BP-286010920-172.17.0.2-1606980199054 is not formatted. Formatting ...
2020-12-03 07:23:23,556 [Thread-238] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-286010920-172.17.0.2-1606980199054 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-286010920-172.17.0.2-1606980199054/current
2020-12-03 07:23:23,623 [IPC Server handler 5 on default port 42380] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:23,625 [Listener at localhost/45068] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:23:23,625 [Listener at localhost/45068] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:23:23,640 [Thread-238] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=1100938544;bpid=BP-286010920-172.17.0.2-1606980199054;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=1100938544;c=1606980199054;bpid=BP-286010920-172.17.0.2-1606980199054;dnuuid=1917c584-39c3-42c1-87c7-45983f4c84fe
2020-12-03 07:23:23,641 [Thread-236] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:02 AM with interval of 21600000ms
2020-12-03 07:23:23,643 [Thread-238] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-286010920-172.17.0.2-1606980199054
2020-12-03 07:23:23,643 [Thread-314] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-286010920-172.17.0.2-1606980199054 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7...
2020-12-03 07:23:23,643 [Thread-315] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-286010920-172.17.0.2-1606980199054 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8...
2020-12-03 07:23:23,645 [BP-2036634619-172.17.0.2-1606980196096 heartbeating to localhost/127.0.0.1:41178] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-2036634619-172.17.0.2-1606980196096 (Datanode Uuid 1917c584-39c3-42c1-87c7-45983f4c84fe) service to localhost/127.0.0.1:41178 beginning handshake with NN
2020-12-03 07:23:23,645 [BP-2036634619-172.17.0.2-1606980196096 heartbeating to localhost/127.0.0.1:42380] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-2036634619-172.17.0.2-1606980196096 (Datanode Uuid 1917c584-39c3-42c1-87c7-45983f4c84fe) service to localhost/127.0.0.1:42380 beginning handshake with NN
2020-12-03 07:23:23,646 [IPC Server handler 4 on default port 42380] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:33622, datanodeUuid=1917c584-39c3-42c1-87c7-45983f4c84fe, infoPort=46034, infoSecurePort=0, ipcPort=45068, storageInfo=lv=-57;cid=testClusterID;nsid=415304149;c=1606980196097) storage 1917c584-39c3-42c1-87c7-45983f4c84fe
2020-12-03 07:23:23,647 [IPC Server handler 3 on default port 41178] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:33622, datanodeUuid=1917c584-39c3-42c1-87c7-45983f4c84fe, infoPort=46034, infoSecurePort=0, ipcPort=45068, storageInfo=lv=-57;cid=testClusterID;nsid=415304149;c=1606980196097) storage 1917c584-39c3-42c1-87c7-45983f4c84fe
2020-12-03 07:23:23,647 [IPC Server handler 4 on default port 42380] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:33622
2020-12-03 07:23:23,647 [IPC Server handler 3 on default port 41178] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:33622
2020-12-03 07:23:23,647 [IPC Server handler 3 on default port 41178] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 1917c584-39c3-42c1-87c7-45983f4c84fe (127.0.0.1:33622).
2020-12-03 07:23:23,647 [IPC Server handler 4 on default port 42380] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 1917c584-39c3-42c1-87c7-45983f4c84fe (127.0.0.1:33622).
2020-12-03 07:23:23,648 [BP-2036634619-172.17.0.2-1606980196096 heartbeating to localhost/127.0.0.1:41178] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-2036634619-172.17.0.2-1606980196096 (Datanode Uuid 1917c584-39c3-42c1-87c7-45983f4c84fe) service to localhost/127.0.0.1:41178 successfully registered with NN
2020-12-03 07:23:23,648 [BP-2036634619-172.17.0.2-1606980196096 heartbeating to localhost/127.0.0.1:41178] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:41178 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:23,649 [BP-2036634619-172.17.0.2-1606980196096 heartbeating to localhost/127.0.0.1:42380] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-2036634619-172.17.0.2-1606980196096 (Datanode Uuid 1917c584-39c3-42c1-87c7-45983f4c84fe) service to localhost/127.0.0.1:42380 successfully registered with NN
2020-12-03 07:23:23,650 [BP-2036634619-172.17.0.2-1606980196096 heartbeating to localhost/127.0.0.1:42380] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:42380 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:23,652 [IPC Server handler 7 on default port 41178] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-32ee6b6e-ecea-462a-922f-e3967ffcb365 for DN 127.0.0.1:33622
2020-12-03 07:23:23,652 [IPC Server handler 7 on default port 41178] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-f1560c54-0c7f-451c-ade4-648ed1535376 for DN 127.0.0.1:33622
2020-12-03 07:23:23,652 [IPC Server handler 9 on default port 42380] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-32ee6b6e-ecea-462a-922f-e3967ffcb365 for DN 127.0.0.1:33622
2020-12-03 07:23:23,653 [IPC Server handler 9 on default port 42380] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-f1560c54-0c7f-451c-ade4-648ed1535376 for DN 127.0.0.1:33622
2020-12-03 07:23:23,676 [Thread-315] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-286010920-172.17.0.2-1606980199054 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8: 33ms
2020-12-03 07:23:23,687 [Thread-314] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-286010920-172.17.0.2-1606980199054 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7: 43ms
2020-12-03 07:23:23,687 [Thread-238] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-286010920-172.17.0.2-1606980199054: 44ms
2020-12-03 07:23:23,688 [Thread-318] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-286010920-172.17.0.2-1606980199054 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7...
2020-12-03 07:23:23,688 [Thread-318] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-286010920-172.17.0.2-1606980199054/current/replicas doesn't exist 
2020-12-03 07:23:23,689 [Thread-318] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-286010920-172.17.0.2-1606980199054 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7: 1ms
2020-12-03 07:23:23,689 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x1e66006aa056554b: Processing first storage report for DS-f1560c54-0c7f-451c-ade4-648ed1535376 from datanode 1917c584-39c3-42c1-87c7-45983f4c84fe
2020-12-03 07:23:23,689 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x1e66006aa056554b: from storage DS-f1560c54-0c7f-451c-ade4-648ed1535376 node DatanodeRegistration(127.0.0.1:33622, datanodeUuid=1917c584-39c3-42c1-87c7-45983f4c84fe, infoPort=46034, infoSecurePort=0, ipcPort=45068, storageInfo=lv=-57;cid=testClusterID;nsid=415304149;c=1606980196097), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:23,690 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x1e66006aa056554b: Processing first storage report for DS-32ee6b6e-ecea-462a-922f-e3967ffcb365 from datanode 1917c584-39c3-42c1-87c7-45983f4c84fe
2020-12-03 07:23:23,690 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x1e66006aa056554b: from storage DS-32ee6b6e-ecea-462a-922f-e3967ffcb365 node DatanodeRegistration(127.0.0.1:33622, datanodeUuid=1917c584-39c3-42c1-87c7-45983f4c84fe, infoPort=46034, infoSecurePort=0, ipcPort=45068, storageInfo=lv=-57;cid=testClusterID;nsid=415304149;c=1606980196097), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:23,692 [BP-2036634619-172.17.0.2-1606980196096 heartbeating to localhost/127.0.0.1:41178] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x1e66006aa056554b,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 10 msec to generate and 4 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:23:23,693 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x1a97e2717ff6130e: Processing first storage report for DS-f1560c54-0c7f-451c-ade4-648ed1535376 from datanode 1917c584-39c3-42c1-87c7-45983f4c84fe
2020-12-03 07:23:23,693 [Thread-319] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-286010920-172.17.0.2-1606980199054 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8...
2020-12-03 07:23:23,693 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x1a97e2717ff6130e: from storage DS-f1560c54-0c7f-451c-ade4-648ed1535376 node DatanodeRegistration(127.0.0.1:33622, datanodeUuid=1917c584-39c3-42c1-87c7-45983f4c84fe, infoPort=46034, infoSecurePort=0, ipcPort=45068, storageInfo=lv=-57;cid=testClusterID;nsid=415304149;c=1606980196097), blocks: 0, hasStaleStorage: true, processing time: 2 msecs, invalidatedBlocks: 0
2020-12-03 07:23:23,693 [Thread-319] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-286010920-172.17.0.2-1606980199054/current/replicas doesn't exist 
2020-12-03 07:23:23,694 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x1a97e2717ff6130e: Processing first storage report for DS-32ee6b6e-ecea-462a-922f-e3967ffcb365 from datanode 1917c584-39c3-42c1-87c7-45983f4c84fe
2020-12-03 07:23:23,694 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x1a97e2717ff6130e: from storage DS-32ee6b6e-ecea-462a-922f-e3967ffcb365 node DatanodeRegistration(127.0.0.1:33622, datanodeUuid=1917c584-39c3-42c1-87c7-45983f4c84fe, infoPort=46034, infoSecurePort=0, ipcPort=45068, storageInfo=lv=-57;cid=testClusterID;nsid=415304149;c=1606980196097), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:23,694 [Thread-319] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-286010920-172.17.0.2-1606980199054 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8: 1ms
2020-12-03 07:23:23,695 [Thread-238] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-286010920-172.17.0.2-1606980199054: 7ms
2020-12-03 07:23:23,695 [BP-2036634619-172.17.0.2-1606980196096 heartbeating to localhost/127.0.0.1:42380] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x1a97e2717ff6130e,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 10 msec to generate and 7 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:23:23,696 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-286010920-172.17.0.2-1606980199054 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-12-03 07:23:23,696 [BP-286010920-172.17.0.2-1606980199054 heartbeating to localhost/127.0.0.1:41220] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-286010920-172.17.0.2-1606980199054 (Datanode Uuid 1917c584-39c3-42c1-87c7-45983f4c84fe) service to localhost/127.0.0.1:41220 beginning handshake with NN
2020-12-03 07:23:23,696 [BP-286010920-172.17.0.2-1606980199054 heartbeating to localhost/127.0.0.1:42106] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-286010920-172.17.0.2-1606980199054 (Datanode Uuid 1917c584-39c3-42c1-87c7-45983f4c84fe) service to localhost/127.0.0.1:42106 beginning handshake with NN
2020-12-03 07:23:23,696 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, DS-f1560c54-0c7f-451c-ade4-648ed1535376): finished scanning block pool BP-286010920-172.17.0.2-1606980199054
2020-12-03 07:23:23,697 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, DS-f1560c54-0c7f-451c-ade4-648ed1535376): no suitable block pools found to scan.  Waiting 1814399750 ms.
2020-12-03 07:23:23,697 [IPC Server handler 5 on default port 41220] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:33622, datanodeUuid=1917c584-39c3-42c1-87c7-45983f4c84fe, infoPort=46034, infoSecurePort=0, ipcPort=45068, storageInfo=lv=-57;cid=testClusterID;nsid=1100938544;c=1606980199054) storage 1917c584-39c3-42c1-87c7-45983f4c84fe
2020-12-03 07:23:23,697 [IPC Server handler 5 on default port 41220] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:33622
2020-12-03 07:23:23,698 [IPC Server handler 5 on default port 41220] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 1917c584-39c3-42c1-87c7-45983f4c84fe (127.0.0.1:33622).
2020-12-03 07:23:23,697 [IPC Server handler 0 on default port 42106] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:33622, datanodeUuid=1917c584-39c3-42c1-87c7-45983f4c84fe, infoPort=46034, infoSecurePort=0, ipcPort=45068, storageInfo=lv=-57;cid=testClusterID;nsid=1100938544;c=1606980199054) storage 1917c584-39c3-42c1-87c7-45983f4c84fe
2020-12-03 07:23:23,699 [IPC Server handler 0 on default port 42106] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:33622
2020-12-03 07:23:23,699 [IPC Server handler 0 on default port 42106] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 1917c584-39c3-42c1-87c7-45983f4c84fe (127.0.0.1:33622).
2020-12-03 07:23:23,699 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-286010920-172.17.0.2-1606980199054 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7
2020-12-03 07:23:23,699 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, DS-32ee6b6e-ecea-462a-922f-e3967ffcb365): finished scanning block pool BP-286010920-172.17.0.2-1606980199054
2020-12-03 07:23:23,700 [BP-286010920-172.17.0.2-1606980199054 heartbeating to localhost/127.0.0.1:41220] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-286010920-172.17.0.2-1606980199054 (Datanode Uuid 1917c584-39c3-42c1-87c7-45983f4c84fe) service to localhost/127.0.0.1:41220 successfully registered with NN
2020-12-03 07:23:23,700 [BP-286010920-172.17.0.2-1606980199054 heartbeating to localhost/127.0.0.1:41220] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:41220 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:23,700 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, DS-32ee6b6e-ecea-462a-922f-e3967ffcb365): no suitable block pools found to scan.  Waiting 1814399747 ms.
2020-12-03 07:23:23,705 [BP-286010920-172.17.0.2-1606980199054 heartbeating to localhost/127.0.0.1:42106] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-286010920-172.17.0.2-1606980199054 (Datanode Uuid 1917c584-39c3-42c1-87c7-45983f4c84fe) service to localhost/127.0.0.1:42106 successfully registered with NN
2020-12-03 07:23:23,705 [BP-286010920-172.17.0.2-1606980199054 heartbeating to localhost/127.0.0.1:42106] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:42106 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:23,715 [IPC Server handler 1 on default port 42106] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-32ee6b6e-ecea-462a-922f-e3967ffcb365 for DN 127.0.0.1:33622
2020-12-03 07:23:23,716 [IPC Server handler 1 on default port 42106] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-f1560c54-0c7f-451c-ade4-648ed1535376 for DN 127.0.0.1:33622
2020-12-03 07:23:23,719 [IPC Server handler 8 on default port 41220] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-32ee6b6e-ecea-462a-922f-e3967ffcb365 for DN 127.0.0.1:33622
2020-12-03 07:23:23,719 [IPC Server handler 8 on default port 41220] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-f1560c54-0c7f-451c-ade4-648ed1535376 for DN 127.0.0.1:33622
2020-12-03 07:23:23,723 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xc83d7dabdc46ed0f: Processing first storage report for DS-f1560c54-0c7f-451c-ade4-648ed1535376 from datanode 1917c584-39c3-42c1-87c7-45983f4c84fe
2020-12-03 07:23:23,723 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xc83d7dabdc46ed0f: from storage DS-f1560c54-0c7f-451c-ade4-648ed1535376 node DatanodeRegistration(127.0.0.1:33622, datanodeUuid=1917c584-39c3-42c1-87c7-45983f4c84fe, infoPort=46034, infoSecurePort=0, ipcPort=45068, storageInfo=lv=-57;cid=testClusterID;nsid=1100938544;c=1606980199054), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:23,724 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xc83d7dabdc46ed0f: Processing first storage report for DS-32ee6b6e-ecea-462a-922f-e3967ffcb365 from datanode 1917c584-39c3-42c1-87c7-45983f4c84fe
2020-12-03 07:23:23,724 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xc83d7dabdc46ed0f: from storage DS-32ee6b6e-ecea-462a-922f-e3967ffcb365 node DatanodeRegistration(127.0.0.1:33622, datanodeUuid=1917c584-39c3-42c1-87c7-45983f4c84fe, infoPort=46034, infoSecurePort=0, ipcPort=45068, storageInfo=lv=-57;cid=testClusterID;nsid=1100938544;c=1606980199054), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:23,731 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xe210bc9c932bce46: Processing first storage report for DS-f1560c54-0c7f-451c-ade4-648ed1535376 from datanode 1917c584-39c3-42c1-87c7-45983f4c84fe
2020-12-03 07:23:23,732 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xe210bc9c932bce46: from storage DS-f1560c54-0c7f-451c-ade4-648ed1535376 node DatanodeRegistration(127.0.0.1:33622, datanodeUuid=1917c584-39c3-42c1-87c7-45983f4c84fe, infoPort=46034, infoSecurePort=0, ipcPort=45068, storageInfo=lv=-57;cid=testClusterID;nsid=1100938544;c=1606980199054), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:23,735 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xe210bc9c932bce46: Processing first storage report for DS-32ee6b6e-ecea-462a-922f-e3967ffcb365 from datanode 1917c584-39c3-42c1-87c7-45983f4c84fe
2020-12-03 07:23:23,735 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xe210bc9c932bce46: from storage DS-32ee6b6e-ecea-462a-922f-e3967ffcb365 node DatanodeRegistration(127.0.0.1:33622, datanodeUuid=1917c584-39c3-42c1-87c7-45983f4c84fe, infoPort=46034, infoSecurePort=0, ipcPort=45068, storageInfo=lv=-57;cid=testClusterID;nsid=1100938544;c=1606980199054), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:23,735 [BP-286010920-172.17.0.2-1606980199054 heartbeating to localhost/127.0.0.1:41220] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xc83d7dabdc46ed0f,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 15 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:23:23,736 [IPC Server handler 7 on default port 42380] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:23,744 [BP-286010920-172.17.0.2-1606980199054 heartbeating to localhost/127.0.0.1:42106] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xe210bc9c932bce46,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 25 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:23:23,758 [IPC Server handler 5 on default port 41178] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:23,789 [IPC Server handler 7 on default port 42106] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:23,808 [IPC Server handler 1 on default port 41220] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:23,810 [Listener at localhost/45068] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:23:23,818 [IPC Server handler 8 on default port 42380] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:23,822 [IPC Server handler 6 on default port 41178] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:23,839 [IPC Server handler 6 on default port 42106] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:23,845 [IPC Server handler 2 on default port 41220] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:23,847 [Listener at localhost/45068] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:23:23,896 [Listener at localhost/45068] INFO  router.RouterRpcServer (RouterRpcServer.java:<init>(251)) - RPC server binding to /0.0.0.0:0 with 10 handlers for Router null
2020-12-03 07:23:23,897 [Listener at localhost/45068] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:23,898 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:23,913 [Listener at 0.0.0.0/39419] INFO  router.ConnectionManager (ConnectionManager.java:<init>(120)) - Cleaning connection pools every 60 seconds
2020-12-03 07:23:23,913 [Listener at 0.0.0.0/39419] INFO  router.ConnectionManager (ConnectionManager.java:<init>(125)) - Cleaning connections every 10 seconds
2020-12-03 07:23:23,913 [Listener at 0.0.0.0/39419] INFO  router.ConnectionManager (ConnectionManager.java:start(139)) - Cleaning every 10 seconds
2020-12-03 07:23:23,942 [Listener at 0.0.0.0/39419] INFO  router.RouterAdminServer (RouterAdminServer.java:<init>(132)) - Admin server binding to 0.0.0.0:0
2020-12-03 07:23:23,942 [Listener at 0.0.0.0/39419] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 100, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:23,945 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:23,952 [Listener at 0.0.0.0/32876] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns0
2020-12-03 07:23:23,955 [Listener at 0.0.0.0/32876] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns0
2020-12-03 07:23:23,959 [Listener at 0.0.0.0/32876] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns0
2020-12-03 07:23:23,959 [Listener at 0.0.0.0/32876] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns1
2020-12-03 07:23:23,960 [Listener at 0.0.0.0/32876] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns1
2020-12-03 07:23:23,961 [Listener at 0.0.0.0/32876] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - Router metrics system started (again)
2020-12-03 07:23:24,004 [Listener at 0.0.0.0/32876] INFO  store.StateStoreService (StateStoreService.java:serviceInit(185)) - Registered StateStoreMBean: Hadoop:service=Router,name=StateStore
2020-12-03 07:23:24,004 [Listener at 0.0.0.0/32876] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.federation.router.cache.ttl(5000) assuming MILLISECONDS
2020-12-03 07:23:24,008 [Listener at 0.0.0.0/32876] INFO  metrics.FederationRPCPerformanceMonitor (FederationRPCPerformanceMonitor.java:init(91)) - Registered FederationRPCMBean: Hadoop:service=Router,name=FederationRPC
2020-12-03 07:23:24,013 [Listener at 0.0.0.0/32876] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn0 RPC address: 127.0.0.1:42106
2020-12-03 07:23:24,013 [Listener at 0.0.0.0/32876] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn0 Service RPC address: 127.0.0.1:42106
2020-12-03 07:23:24,013 [Listener at 0.0.0.0/32876] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn0 Lifeline RPC address: 127.0.0.1:42106
2020-12-03 07:23:24,014 [Listener at 0.0.0.0/32876] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn0 Web address: 127.0.0.1:43406
2020-12-03 07:23:24,014 [Listener at 0.0.0.0/32876] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn0 RPC address: 127.0.0.1:42380
2020-12-03 07:23:24,014 [Listener at 0.0.0.0/32876] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn0 Service RPC address: 127.0.0.1:42380
2020-12-03 07:23:24,014 [Listener at 0.0.0.0/32876] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn0 Lifeline RPC address: 127.0.0.1:42380
2020-12-03 07:23:24,014 [Listener at 0.0.0.0/32876] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn0 Web address: 127.0.0.1:37939
2020-12-03 07:23:24,015 [Listener at 0.0.0.0/32876] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn1 RPC address: 127.0.0.1:41220
2020-12-03 07:23:24,015 [Listener at 0.0.0.0/32876] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn1 Service RPC address: 127.0.0.1:41220
2020-12-03 07:23:24,015 [Listener at 0.0.0.0/32876] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn1 Lifeline RPC address: 127.0.0.1:41220
2020-12-03 07:23:24,015 [Listener at 0.0.0.0/32876] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn1 Web address: 127.0.0.1:36951
2020-12-03 07:23:24,016 [Listener at 0.0.0.0/32876] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn1 RPC address: 127.0.0.1:41178
2020-12-03 07:23:24,016 [Listener at 0.0.0.0/32876] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn1 Service RPC address: 127.0.0.1:41178
2020-12-03 07:23:24,016 [Listener at 0.0.0.0/32876] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn1 Lifeline RPC address: 127.0.0.1:41178
2020-12-03 07:23:24,016 [Listener at 0.0.0.0/32876] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn1 Web address: 127.0.0.1:43596
2020-12-03 07:23:24,030 [Listener at 0.0.0.0/32876] INFO  router.RouterRpcServer (RouterRpcServer.java:<init>(251)) - RPC server binding to /0.0.0.0:0 with 10 handlers for Router null
2020-12-03 07:23:24,031 [Listener at 0.0.0.0/32876] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:24,032 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:24,035 [Listener at 0.0.0.0/45083] INFO  router.ConnectionManager (ConnectionManager.java:<init>(120)) - Cleaning connection pools every 60 seconds
2020-12-03 07:23:24,036 [Listener at 0.0.0.0/45083] INFO  router.ConnectionManager (ConnectionManager.java:<init>(125)) - Cleaning connections every 10 seconds
2020-12-03 07:23:24,036 [Listener at 0.0.0.0/45083] INFO  router.ConnectionManager (ConnectionManager.java:start(139)) - Cleaning every 10 seconds
2020-12-03 07:23:24,037 [Listener at 0.0.0.0/45083] INFO  router.RouterAdminServer (RouterAdminServer.java:<init>(132)) - Admin server binding to 0.0.0.0:0
2020-12-03 07:23:24,038 [Listener at 0.0.0.0/45083] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 100, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:24,038 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:24,044 [Listener at 0.0.0.0/39072] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns0
2020-12-03 07:23:24,045 [Listener at 0.0.0.0/39072] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns0
2020-12-03 07:23:24,045 [Listener at 0.0.0.0/39072] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns0
2020-12-03 07:23:24,045 [Listener at 0.0.0.0/39072] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns1
2020-12-03 07:23:24,045 [Listener at 0.0.0.0/39072] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns1
2020-12-03 07:23:24,046 [Listener at 0.0.0.0/39072] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - Router metrics system started (again)
2020-12-03 07:23:24,048 [Listener at 0.0.0.0/39072] INFO  store.StateStoreService (StateStoreService.java:serviceInit(185)) - Registered StateStoreMBean: Hadoop:service=Router,name=StateStore-1
2020-12-03 07:23:24,048 [Listener at 0.0.0.0/39072] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.federation.router.cache.ttl(5000) assuming MILLISECONDS
2020-12-03 07:23:24,050 [Listener at 0.0.0.0/39072] INFO  metrics.FederationRPCPerformanceMonitor (FederationRPCPerformanceMonitor.java:init(91)) - Registered FederationRPCMBean: Hadoop:service=Router,name=FederationRPC-1
2020-12-03 07:23:24,051 [Listener at 0.0.0.0/39072] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn0 RPC address: 127.0.0.1:42106
2020-12-03 07:23:24,051 [Listener at 0.0.0.0/39072] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn0 Service RPC address: 127.0.0.1:42106
2020-12-03 07:23:24,051 [Listener at 0.0.0.0/39072] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn0 Lifeline RPC address: 127.0.0.1:42106
2020-12-03 07:23:24,051 [Listener at 0.0.0.0/39072] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn0 Web address: 127.0.0.1:43406
2020-12-03 07:23:24,052 [Listener at 0.0.0.0/39072] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn0 RPC address: 127.0.0.1:42380
2020-12-03 07:23:24,052 [Listener at 0.0.0.0/39072] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn0 Service RPC address: 127.0.0.1:42380
2020-12-03 07:23:24,052 [Listener at 0.0.0.0/39072] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn0 Lifeline RPC address: 127.0.0.1:42380
2020-12-03 07:23:24,052 [Listener at 0.0.0.0/39072] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn0 Web address: 127.0.0.1:37939
2020-12-03 07:23:24,053 [Listener at 0.0.0.0/39072] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn1 RPC address: 127.0.0.1:41220
2020-12-03 07:23:24,053 [Listener at 0.0.0.0/39072] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn1 Service RPC address: 127.0.0.1:41220
2020-12-03 07:23:24,053 [Listener at 0.0.0.0/39072] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn1 Lifeline RPC address: 127.0.0.1:41220
2020-12-03 07:23:24,054 [Listener at 0.0.0.0/39072] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn1 Web address: 127.0.0.1:36951
2020-12-03 07:23:24,054 [Listener at 0.0.0.0/39072] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn1 RPC address: 127.0.0.1:41178
2020-12-03 07:23:24,055 [Listener at 0.0.0.0/39072] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn1 Service RPC address: 127.0.0.1:41178
2020-12-03 07:23:24,055 [Listener at 0.0.0.0/39072] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn1 Lifeline RPC address: 127.0.0.1:41178
2020-12-03 07:23:24,055 [Listener at 0.0.0.0/39072] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn1 Web address: 127.0.0.1:43596
2020-12-03 07:23:24,074 [Listener at 0.0.0.0/39072] INFO  router.RouterRpcServer (RouterRpcServer.java:<init>(251)) - RPC server binding to /0.0.0.0:0 with 10 handlers for Router null
2020-12-03 07:23:24,077 [Listener at 0.0.0.0/39072] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:24,087 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:24,092 [Listener at 0.0.0.0/38866] INFO  router.ConnectionManager (ConnectionManager.java:<init>(120)) - Cleaning connection pools every 60 seconds
2020-12-03 07:23:24,092 [Listener at 0.0.0.0/38866] INFO  router.ConnectionManager (ConnectionManager.java:<init>(125)) - Cleaning connections every 10 seconds
2020-12-03 07:23:24,092 [Listener at 0.0.0.0/38866] INFO  router.ConnectionManager (ConnectionManager.java:start(139)) - Cleaning every 10 seconds
2020-12-03 07:23:24,094 [Listener at 0.0.0.0/38866] INFO  router.RouterAdminServer (RouterAdminServer.java:<init>(132)) - Admin server binding to 0.0.0.0:0
2020-12-03 07:23:24,094 [Listener at 0.0.0.0/38866] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 100, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:24,095 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:24,098 [Listener at 0.0.0.0/33327] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns1
2020-12-03 07:23:24,099 [Listener at 0.0.0.0/33327] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns0
2020-12-03 07:23:24,099 [Listener at 0.0.0.0/33327] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns0
2020-12-03 07:23:24,099 [Listener at 0.0.0.0/33327] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns1
2020-12-03 07:23:24,121 [Listener at 0.0.0.0/33327] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns1
2020-12-03 07:23:24,121 [Listener at 0.0.0.0/33327] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - Router metrics system started (again)
2020-12-03 07:23:24,123 [Listener at 0.0.0.0/33327] INFO  store.StateStoreService (StateStoreService.java:serviceInit(185)) - Registered StateStoreMBean: Hadoop:service=Router,name=StateStore-2
2020-12-03 07:23:24,123 [Listener at 0.0.0.0/33327] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.federation.router.cache.ttl(5000) assuming MILLISECONDS
2020-12-03 07:23:24,124 [Listener at 0.0.0.0/33327] INFO  metrics.FederationRPCPerformanceMonitor (FederationRPCPerformanceMonitor.java:init(91)) - Registered FederationRPCMBean: Hadoop:service=Router,name=FederationRPC-2
2020-12-03 07:23:24,125 [Listener at 0.0.0.0/33327] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn0 RPC address: 127.0.0.1:42106
2020-12-03 07:23:24,126 [Listener at 0.0.0.0/33327] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn0 Service RPC address: 127.0.0.1:42106
2020-12-03 07:23:24,126 [Listener at 0.0.0.0/33327] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn0 Lifeline RPC address: 127.0.0.1:42106
2020-12-03 07:23:24,126 [Listener at 0.0.0.0/33327] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn0 Web address: 127.0.0.1:43406
2020-12-03 07:23:24,127 [Listener at 0.0.0.0/33327] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn0 RPC address: 127.0.0.1:42380
2020-12-03 07:23:24,127 [Listener at 0.0.0.0/33327] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn0 Service RPC address: 127.0.0.1:42380
2020-12-03 07:23:24,127 [Listener at 0.0.0.0/33327] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn0 Lifeline RPC address: 127.0.0.1:42380
2020-12-03 07:23:24,127 [Listener at 0.0.0.0/33327] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn0 Web address: 127.0.0.1:37939
2020-12-03 07:23:24,128 [Listener at 0.0.0.0/33327] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn1 RPC address: 127.0.0.1:41220
2020-12-03 07:23:24,128 [Listener at 0.0.0.0/33327] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn1 Service RPC address: 127.0.0.1:41220
2020-12-03 07:23:24,128 [Listener at 0.0.0.0/33327] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn1 Lifeline RPC address: 127.0.0.1:41220
2020-12-03 07:23:24,128 [Listener at 0.0.0.0/33327] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn1 Web address: 127.0.0.1:36951
2020-12-03 07:23:24,140 [Listener at 0.0.0.0/33327] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn1 RPC address: 127.0.0.1:41178
2020-12-03 07:23:24,140 [Listener at 0.0.0.0/33327] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn1 Service RPC address: 127.0.0.1:41178
2020-12-03 07:23:24,140 [Listener at 0.0.0.0/33327] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn1 Lifeline RPC address: 127.0.0.1:41178
2020-12-03 07:23:24,141 [Listener at 0.0.0.0/33327] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn1 Web address: 127.0.0.1:43596
2020-12-03 07:23:24,156 [Listener at 0.0.0.0/33327] INFO  router.RouterRpcServer (RouterRpcServer.java:<init>(251)) - RPC server binding to /0.0.0.0:0 with 10 handlers for Router null
2020-12-03 07:23:24,157 [Listener at 0.0.0.0/33327] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:24,161 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:24,166 [Listener at 0.0.0.0/44401] INFO  router.ConnectionManager (ConnectionManager.java:<init>(120)) - Cleaning connection pools every 60 seconds
2020-12-03 07:23:24,166 [Listener at 0.0.0.0/44401] INFO  router.ConnectionManager (ConnectionManager.java:<init>(125)) - Cleaning connections every 10 seconds
2020-12-03 07:23:24,167 [Listener at 0.0.0.0/44401] INFO  router.ConnectionManager (ConnectionManager.java:start(139)) - Cleaning every 10 seconds
2020-12-03 07:23:24,168 [Listener at 0.0.0.0/44401] INFO  router.RouterAdminServer (RouterAdminServer.java:<init>(132)) - Admin server binding to 0.0.0.0:0
2020-12-03 07:23:24,171 [Listener at 0.0.0.0/44401] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 100, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:24,173 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:24,179 [Listener at 0.0.0.0/39019] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns1
2020-12-03 07:23:24,179 [Listener at 0.0.0.0/39019] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns0
2020-12-03 07:23:24,180 [Listener at 0.0.0.0/39019] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns0
2020-12-03 07:23:24,180 [Listener at 0.0.0.0/39019] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns1
2020-12-03 07:23:24,180 [Listener at 0.0.0.0/39019] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns1
2020-12-03 07:23:24,180 [Listener at 0.0.0.0/39019] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - Router metrics system started (again)
2020-12-03 07:23:24,183 [Listener at 0.0.0.0/39019] INFO  store.StateStoreService (StateStoreService.java:serviceInit(185)) - Registered StateStoreMBean: Hadoop:service=Router,name=StateStore-3
2020-12-03 07:23:24,183 [Listener at 0.0.0.0/39019] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.federation.router.cache.ttl(5000) assuming MILLISECONDS
2020-12-03 07:23:24,184 [Listener at 0.0.0.0/39019] INFO  metrics.FederationRPCPerformanceMonitor (FederationRPCPerformanceMonitor.java:init(91)) - Registered FederationRPCMBean: Hadoop:service=Router,name=FederationRPC-3
2020-12-03 07:23:24,185 [Listener at 0.0.0.0/39019] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn0 RPC address: 127.0.0.1:42106
2020-12-03 07:23:24,185 [Listener at 0.0.0.0/39019] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn0 Service RPC address: 127.0.0.1:42106
2020-12-03 07:23:24,185 [Listener at 0.0.0.0/39019] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn0 Lifeline RPC address: 127.0.0.1:42106
2020-12-03 07:23:24,185 [Listener at 0.0.0.0/39019] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn0 Web address: 127.0.0.1:43406
2020-12-03 07:23:24,186 [Listener at 0.0.0.0/39019] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn1 RPC address: 127.0.0.1:41220
2020-12-03 07:23:24,186 [Listener at 0.0.0.0/39019] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn1 Service RPC address: 127.0.0.1:41220
2020-12-03 07:23:24,186 [Listener at 0.0.0.0/39019] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn1 Lifeline RPC address: 127.0.0.1:41220
2020-12-03 07:23:24,186 [Listener at 0.0.0.0/39019] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn1 Web address: 127.0.0.1:36951
2020-12-03 07:23:24,187 [Listener at 0.0.0.0/39019] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn0 RPC address: 127.0.0.1:42380
2020-12-03 07:23:24,187 [Listener at 0.0.0.0/39019] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn0 Service RPC address: 127.0.0.1:42380
2020-12-03 07:23:24,187 [Listener at 0.0.0.0/39019] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn0 Lifeline RPC address: 127.0.0.1:42380
2020-12-03 07:23:24,187 [Listener at 0.0.0.0/39019] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn0 Web address: 127.0.0.1:37939
2020-12-03 07:23:24,188 [Listener at 0.0.0.0/39019] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn1 RPC address: 127.0.0.1:41178
2020-12-03 07:23:24,188 [Listener at 0.0.0.0/39019] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn1 Service RPC address: 127.0.0.1:41178
2020-12-03 07:23:24,188 [Listener at 0.0.0.0/39019] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn1 Lifeline RPC address: 127.0.0.1:41178
2020-12-03 07:23:24,188 [Listener at 0.0.0.0/39019] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn1 Web address: 127.0.0.1:43596
2020-12-03 07:23:24,195 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 7a5505b8915a:39419: State Store unavailable
2020-12-03 07:23:24,196 [Listener at 0.0.0.0/39019] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-12-03 07:23:24,195 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1de9d54] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:24,200 [Listener at 0.0.0.0/39019] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.serviceStart(StateStoreService.java:197)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.service.CompositeService.serviceStart(CompositeService.java:121)
	at org.apache.hadoop.hdfs.server.federation.router.Router.serviceStart(Router.java:265)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.hdfs.server.federation.MiniRouterDFSCluster.startRouters(MiniRouterDFSCluster.java:757)
	at org.apache.hadoop.fs.contract.router.web.RouterWebHDFSContract.createCluster(RouterWebHDFSContract.java:69)
	at org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractSeek.createCluster(TestRouterWebHDFSContractSeek.java:36)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2020-12-03 07:23:24,208 [Listener at 0.0.0.0/39019] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-12-03 07:23:24,209 [Listener at 0.0.0.0/39019] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-12-03 07:23:24,209 [Listener at 0.0.0.0/39019] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreConnectionMonitorService
2020-12-03 07:23:24,210 [Listener at 0.0.0.0/39019] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreCacheUpdateService
2020-12-03 07:23:24,210 [StateStoreConnectionMonitorService-0] INFO  store.StateStoreConnectionMonitorService (StateStoreConnectionMonitorService.java:periodicInvoke(63)) - Attempting to open state store driver.
2020-12-03 07:23:24,224 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:24,225 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:24,226 [Listener at 0.0.0.0/39019] INFO  router.RouterRpcServer (RouterRpcServer.java:serviceStart(322)) - Router RPC up at: /0.0.0.0:39419
2020-12-03 07:23:24,226 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:24,227 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:24,228 [Listener at 0.0.0.0/39019] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for router at: http://0.0.0.0:0
2020-12-03 07:23:24,228 [Listener at 0.0.0.0/39019] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:24,224 [StateStoreConnectionMonitorService-0] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-12-03 07:23:24,239 [Listener at 0.0.0.0/39019] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:24,233 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-12-03 07:23:24,241 [StateStoreConnectionMonitorService-0] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreConnectionMonitorService.periodicInvoke(StateStoreConnectionMonitorService.java:64)
	at org.apache.hadoop.hdfs.server.federation.router.PeriodicService$1.run(PeriodicService.java:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:23:24,247 [Listener at 0.0.0.0/39019] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.router is not defined
2020-12-03 07:23:24,248 [Listener at 0.0.0.0/39019] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:24,251 [Listener at 0.0.0.0/39019] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:24,241 [StateStoreConnectionMonitorService-0] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-12-03 07:23:24,256 [Listener at 0.0.0.0/39019] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context router
2020-12-03 07:23:24,256 [Listener at 0.0.0.0/39019] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:24,256 [Listener at 0.0.0.0/39019] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:24,256 [StateStoreConnectionMonitorService-0] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-12-03 07:23:24,268 [Listener at 0.0.0.0/39019] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:23:24,269 [Listener at 0.0.0.0/39019] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.federation.router;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:23:24,270 [Listener at 0.0.0.0/39019] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 39607
2020-12-03 07:23:24,270 [Listener at 0.0.0.0/39019] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:24,284 [Listener at 0.0.0.0/39019] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6bf13698{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:23:24,285 [Listener at 0.0.0.0/39019] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3b90a30a{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:24,293 [Listener at 0.0.0.0/39019] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@174e1b69{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/router/,AVAILABLE}{/router}
2020-12-03 07:23:24,295 [Listener at 0.0.0.0/39019] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1046498a{HTTP/1.1,[http/1.1]}{0.0.0.0:39607}
2020-12-03 07:23:24,295 [Listener at 0.0.0.0/39019] INFO  server.Server (Server.java:doStart(419)) - Started @10320ms
2020-12-03 07:23:24,297 [Listener at 0.0.0.0/39019] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn0
2020-12-03 07:23:24,297 [Listener at 0.0.0.0/39019] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn0
2020-12-03 07:23:24,298 [Listener at 0.0.0.0/39019] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn1
2020-12-03 07:23:24,298 [Listener at 0.0.0.0/39019] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn1
2020-12-03 07:23:24,298 [Listener at 0.0.0.0/39019] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service RouterHeartbeatService
2020-12-03 07:23:24,300 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 7a5505b8915a:39419: State Store unavailable
2020-12-03 07:23:24,307 [Listener at 0.0.0.0/39019] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(117)) - Registered FSNamesystem MBean: Hadoop:service=NameNode,name=FSNamesystem-4
2020-12-03 07:23:24,308 [Listener at 0.0.0.0/39019] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(126)) - Registered FSNamesystemState MBean: Hadoop:service=NameNode,name=FSNamesystemState-4
2020-12-03 07:23:24,339 [Listener at 0.0.0.0/39019] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(134)) - Registered NameNodeInfo MBean: Hadoop:service=NameNode,name=NameNodeInfo-4
2020-12-03 07:23:24,340 [Listener at 0.0.0.0/39019] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(143)) - Registered NameNodeStatus MBean: Hadoop:service=NameNode,name=NameNodeStatus-4
2020-12-03 07:23:24,355 [Listener at 0.0.0.0/39019] INFO  metrics.FederationMetrics (FederationMetrics.java:<init>(126)) - Registered Router MBean: Hadoop:service=Router,name=FederationState
2020-12-03 07:23:24,359 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 7a5505b8915a:45083: State Store unavailable
2020-12-03 07:23:24,360 [Listener at 0.0.0.0/39019] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-12-03 07:23:24,360 [Listener at 0.0.0.0/39019] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.serviceStart(StateStoreService.java:197)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.service.CompositeService.serviceStart(CompositeService.java:121)
	at org.apache.hadoop.hdfs.server.federation.router.Router.serviceStart(Router.java:265)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.hdfs.server.federation.MiniRouterDFSCluster.startRouters(MiniRouterDFSCluster.java:757)
	at org.apache.hadoop.fs.contract.router.web.RouterWebHDFSContract.createCluster(RouterWebHDFSContract.java:69)
	at org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractSeek.createCluster(TestRouterWebHDFSContractSeek.java:36)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2020-12-03 07:23:24,361 [Listener at 0.0.0.0/39019] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-12-03 07:23:24,361 [Listener at 0.0.0.0/39019] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-12-03 07:23:24,361 [Listener at 0.0.0.0/39019] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreConnectionMonitorService
2020-12-03 07:23:24,361 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@53dad875] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:24,362 [Listener at 0.0.0.0/39019] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreCacheUpdateService
2020-12-03 07:23:24,362 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-12-03 07:23:24,366 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:24,368 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:24,377 [Listener at 0.0.0.0/39019] INFO  router.RouterRpcServer (RouterRpcServer.java:serviceStart(322)) - Router RPC up at: /0.0.0.0:45083
2020-12-03 07:23:24,379 [Listener at 0.0.0.0/39019] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for router at: http://0.0.0.0:0
2020-12-03 07:23:24,379 [Listener at 0.0.0.0/39019] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:24,395 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:24,397 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:24,362 [StateStoreConnectionMonitorService-0] INFO  store.StateStoreConnectionMonitorService (StateStoreConnectionMonitorService.java:periodicInvoke(63)) - Attempting to open state store driver.
2020-12-03 07:23:24,399 [Listener at 0.0.0.0/39019] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:24,401 [Listener at 0.0.0.0/39019] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.router is not defined
2020-12-03 07:23:24,401 [Listener at 0.0.0.0/39019] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:24,406 [Listener at 0.0.0.0/39019] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:24,406 [Listener at 0.0.0.0/39019] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context router
2020-12-03 07:23:24,406 [Listener at 0.0.0.0/39019] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:24,406 [Listener at 0.0.0.0/39019] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:24,408 [Listener at 0.0.0.0/39019] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:23:24,409 [Listener at 0.0.0.0/39019] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.federation.router;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:23:24,409 [Listener at 0.0.0.0/39019] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 39047
2020-12-03 07:23:24,409 [Listener at 0.0.0.0/39019] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:24,410 [StateStoreConnectionMonitorService-0] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-12-03 07:23:24,464 [StateStoreConnectionMonitorService-0] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreConnectionMonitorService.periodicInvoke(StateStoreConnectionMonitorService.java:64)
	at org.apache.hadoop.hdfs.server.federation.router.PeriodicService$1.run(PeriodicService.java:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:23:24,464 [StateStoreConnectionMonitorService-0] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-12-03 07:23:24,464 [StateStoreConnectionMonitorService-0] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-12-03 07:23:24,465 [Listener at 0.0.0.0/39019] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@56681eaf{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:23:24,466 [Listener at 0.0.0.0/39019] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6d2dc9d2{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:24,475 [Listener at 0.0.0.0/39019] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@783115d9{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/router/,AVAILABLE}{/router}
2020-12-03 07:23:24,476 [Listener at 0.0.0.0/39019] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3402b4c9{HTTP/1.1,[http/1.1]}{0.0.0.0:39047}
2020-12-03 07:23:24,476 [Listener at 0.0.0.0/39019] INFO  server.Server (Server.java:doStart(419)) - Started @10501ms
2020-12-03 07:23:24,476 [Listener at 0.0.0.0/39019] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn0
2020-12-03 07:23:24,477 [Listener at 0.0.0.0/39019] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn0
2020-12-03 07:23:24,477 [Listener at 0.0.0.0/39019] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn1
2020-12-03 07:23:24,478 [Listener at 0.0.0.0/39019] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn1
2020-12-03 07:23:24,478 [Listener at 0.0.0.0/39019] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service RouterHeartbeatService
2020-12-03 07:23:24,481 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 7a5505b8915a:45083: State Store unavailable
2020-12-03 07:23:24,481 [Listener at 0.0.0.0/39019] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(117)) - Registered FSNamesystem MBean: Hadoop:service=NameNode,name=FSNamesystem-5
2020-12-03 07:23:24,481 [Listener at 0.0.0.0/39019] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(126)) - Registered FSNamesystemState MBean: Hadoop:service=NameNode,name=FSNamesystemState-5
2020-12-03 07:23:24,482 [Listener at 0.0.0.0/39019] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(134)) - Registered NameNodeInfo MBean: Hadoop:service=NameNode,name=NameNodeInfo-5
2020-12-03 07:23:24,482 [Listener at 0.0.0.0/39019] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(143)) - Registered NameNodeStatus MBean: Hadoop:service=NameNode,name=NameNodeStatus-5
2020-12-03 07:23:24,483 [Listener at 0.0.0.0/39019] INFO  metrics.FederationMetrics (FederationMetrics.java:<init>(126)) - Registered Router MBean: Hadoop:service=Router,name=FederationState-1
2020-12-03 07:23:24,483 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 7a5505b8915a:38866: State Store unavailable
2020-12-03 07:23:24,483 [Listener at 0.0.0.0/39019] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-12-03 07:23:24,483 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2e23c180] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:24,483 [Listener at 0.0.0.0/39019] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.serviceStart(StateStoreService.java:197)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.service.CompositeService.serviceStart(CompositeService.java:121)
	at org.apache.hadoop.hdfs.server.federation.router.Router.serviceStart(Router.java:265)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.hdfs.server.federation.MiniRouterDFSCluster.startRouters(MiniRouterDFSCluster.java:757)
	at org.apache.hadoop.fs.contract.router.web.RouterWebHDFSContract.createCluster(RouterWebHDFSContract.java:69)
	at org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractSeek.createCluster(TestRouterWebHDFSContractSeek.java:36)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2020-12-03 07:23:24,484 [Listener at 0.0.0.0/39019] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-12-03 07:23:24,484 [Listener at 0.0.0.0/39019] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-12-03 07:23:24,484 [Listener at 0.0.0.0/39019] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreConnectionMonitorService
2020-12-03 07:23:24,485 [Listener at 0.0.0.0/39019] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreCacheUpdateService
2020-12-03 07:23:24,485 [StateStoreConnectionMonitorService-0] INFO  store.StateStoreConnectionMonitorService (StateStoreConnectionMonitorService.java:periodicInvoke(63)) - Attempting to open state store driver.
2020-12-03 07:23:24,487 [StateStoreConnectionMonitorService-0] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-12-03 07:23:24,487 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-12-03 07:23:24,487 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:24,488 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:24,493 [StateStoreConnectionMonitorService-0] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreConnectionMonitorService.periodicInvoke(StateStoreConnectionMonitorService.java:64)
	at org.apache.hadoop.hdfs.server.federation.router.PeriodicService$1.run(PeriodicService.java:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:23:24,493 [StateStoreConnectionMonitorService-0] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-12-03 07:23:24,494 [StateStoreConnectionMonitorService-0] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-12-03 07:23:24,498 [Listener at 0.0.0.0/39019] INFO  router.RouterRpcServer (RouterRpcServer.java:serviceStart(322)) - Router RPC up at: /0.0.0.0:38866
2020-12-03 07:23:24,498 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:24,499 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:24,500 [Listener at 0.0.0.0/39019] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for router at: http://0.0.0.0:0
2020-12-03 07:23:24,500 [Listener at 0.0.0.0/39019] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:24,504 [Listener at 0.0.0.0/39019] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:24,505 [Listener at 0.0.0.0/39019] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.router is not defined
2020-12-03 07:23:24,506 [Listener at 0.0.0.0/39019] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:24,508 [Listener at 0.0.0.0/39019] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:24,509 [Listener at 0.0.0.0/39019] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context router
2020-12-03 07:23:24,509 [Listener at 0.0.0.0/39019] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:24,509 [Listener at 0.0.0.0/39019] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:24,523 [Listener at 0.0.0.0/39019] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:23:24,524 [Listener at 0.0.0.0/39019] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.federation.router;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:23:24,524 [Listener at 0.0.0.0/39019] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 42912
2020-12-03 07:23:24,524 [Listener at 0.0.0.0/39019] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:24,527 [Listener at 0.0.0.0/39019] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7fb33394{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:23:24,528 [Listener at 0.0.0.0/39019] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1a891add{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:24,565 [IPC Server handler 9 on default port 42380] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:24,566 [IPC Server handler 1 on default port 42106] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:24,568 [IPC Server handler 8 on default port 41178] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:24,569 [IPC Server handler 5 on default port 41178] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:24,596 [IPC Server handler 7 on default port 42106] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:24,596 [IPC Server handler 0 on default port 41220] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:24,609 [IPC Server handler 0 on default port 42380] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:24,609 [Listener at 0.0.0.0/39019] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@664e5dee{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/router/,AVAILABLE}{/router}
2020-12-03 07:23:24,610 [Listener at 0.0.0.0/39019] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@431f1eaf{HTTP/1.1,[http/1.1]}{0.0.0.0:42912}
2020-12-03 07:23:24,611 [Listener at 0.0.0.0/39019] INFO  server.Server (Server.java:doStart(419)) - Started @10635ms
2020-12-03 07:23:24,611 [Listener at 0.0.0.0/39019] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn0
2020-12-03 07:23:24,611 [Listener at 0.0.0.0/39019] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn0
2020-12-03 07:23:24,617 [Listener at 0.0.0.0/39019] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn1
2020-12-03 07:23:24,630 [Listener at 0.0.0.0/39019] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn1
2020-12-03 07:23:24,632 [Listener at 0.0.0.0/39019] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service RouterHeartbeatService
2020-12-03 07:23:24,634 [IPC Server handler 4 on default port 41178] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:24,636 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 7a5505b8915a:38866: State Store unavailable
2020-12-03 07:23:24,636 [Listener at 0.0.0.0/39019] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(117)) - Registered FSNamesystem MBean: Hadoop:service=NameNode,name=FSNamesystem-6
2020-12-03 07:23:24,637 [Listener at 0.0.0.0/39019] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(126)) - Registered FSNamesystemState MBean: Hadoop:service=NameNode,name=FSNamesystemState-6
2020-12-03 07:23:24,637 [Listener at 0.0.0.0/39019] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(134)) - Registered NameNodeInfo MBean: Hadoop:service=NameNode,name=NameNodeInfo-6
2020-12-03 07:23:24,638 [Listener at 0.0.0.0/39019] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(143)) - Registered NameNodeStatus MBean: Hadoop:service=NameNode,name=NameNodeStatus-6
2020-12-03 07:23:24,638 [IPC Server handler 1 on default port 41220] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:24,638 [Listener at 0.0.0.0/39019] INFO  metrics.FederationMetrics (FederationMetrics.java:<init>(126)) - Registered Router MBean: Hadoop:service=Router,name=FederationState-2
2020-12-03 07:23:24,639 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 7a5505b8915a:44401: State Store unavailable
2020-12-03 07:23:24,648 [IPC Server handler 3 on default port 41220] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:24,647 [IPC Server handler 8 on default port 42380] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:24,644 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6dd82486] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:24,639 [Listener at 0.0.0.0/39019] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-12-03 07:23:24,655 [Listener at 0.0.0.0/39019] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.serviceStart(StateStoreService.java:197)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.service.CompositeService.serviceStart(CompositeService.java:121)
	at org.apache.hadoop.hdfs.server.federation.router.Router.serviceStart(Router.java:265)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.hdfs.server.federation.MiniRouterDFSCluster.startRouters(MiniRouterDFSCluster.java:757)
	at org.apache.hadoop.fs.contract.router.web.RouterWebHDFSContract.createCluster(RouterWebHDFSContract.java:69)
	at org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractSeek.createCluster(TestRouterWebHDFSContractSeek.java:36)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2020-12-03 07:23:24,662 [IPC Server handler 9 on default port 42106] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:24,662 [Listener at 0.0.0.0/39019] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-12-03 07:23:24,665 [Listener at 0.0.0.0/39019] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-12-03 07:23:24,665 [Listener at 0.0.0.0/39019] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreConnectionMonitorService
2020-12-03 07:23:24,665 [Listener at 0.0.0.0/39019] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreCacheUpdateService
2020-12-03 07:23:24,665 [StateStoreConnectionMonitorService-0] INFO  store.StateStoreConnectionMonitorService (StateStoreConnectionMonitorService.java:periodicInvoke(63)) - Attempting to open state store driver.
2020-12-03 07:23:24,679 [StateStoreConnectionMonitorService-0] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-12-03 07:23:24,689 [StateStoreConnectionMonitorService-0] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreConnectionMonitorService.periodicInvoke(StateStoreConnectionMonitorService.java:64)
	at org.apache.hadoop.hdfs.server.federation.router.PeriodicService$1.run(PeriodicService.java:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:23:24,690 [StateStoreConnectionMonitorService-0] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-12-03 07:23:24,690 [StateStoreConnectionMonitorService-0] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-12-03 07:23:24,692 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:24,692 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:24,712 [Listener at 0.0.0.0/39019] INFO  router.RouterRpcServer (RouterRpcServer.java:serviceStart(322)) - Router RPC up at: /0.0.0.0:44401
2020-12-03 07:23:24,713 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:24,714 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-12-03 07:23:24,725 [Listener at 0.0.0.0/39019] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for router at: http://0.0.0.0:0
2020-12-03 07:23:24,726 [Listener at 0.0.0.0/39019] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:24,725 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:24,736 [Listener at 0.0.0.0/39019] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:24,737 [Listener at 0.0.0.0/39019] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.router is not defined
2020-12-03 07:23:24,737 [Listener at 0.0.0.0/39019] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:24,762 [Listener at 0.0.0.0/39019] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:24,763 [Listener at 0.0.0.0/39019] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context router
2020-12-03 07:23:24,763 [Listener at 0.0.0.0/39019] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:24,763 [Listener at 0.0.0.0/39019] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:24,765 [Listener at 0.0.0.0/39019] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:23:24,766 [Listener at 0.0.0.0/39019] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.federation.router;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:23:24,767 [Listener at 0.0.0.0/39019] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 40821
2020-12-03 07:23:24,767 [Listener at 0.0.0.0/39019] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:24,779 [Listener at 0.0.0.0/39019] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@713064e8{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:23:24,858 [Listener at 0.0.0.0/39019] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1bf39d06{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:24,866 [Listener at 0.0.0.0/39019] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@514cd540{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/router/,AVAILABLE}{/router}
2020-12-03 07:23:24,885 [Listener at 0.0.0.0/39019] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@11d4dbd6{HTTP/1.1,[http/1.1]}{0.0.0.0:40821}
2020-12-03 07:23:24,885 [Listener at 0.0.0.0/39019] INFO  server.Server (Server.java:doStart(419)) - Started @10910ms
2020-12-03 07:23:24,887 [Listener at 0.0.0.0/39019] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn0
2020-12-03 07:23:24,887 [Listener at 0.0.0.0/39019] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn1
2020-12-03 07:23:24,888 [Listener at 0.0.0.0/39019] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn0
2020-12-03 07:23:24,888 [Listener at 0.0.0.0/39019] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn1
2020-12-03 07:23:24,888 [Listener at 0.0.0.0/39019] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service RouterHeartbeatService
2020-12-03 07:23:24,890 [IPC Server handler 3 on default port 42380] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:24,893 [IPC Server handler 1 on default port 41178] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:24,900 [IPC Server handler 6 on default port 41220] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:24,903 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 7a5505b8915a:44401: State Store unavailable
2020-12-03 07:23:24,903 [Listener at 0.0.0.0/39019] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(117)) - Registered FSNamesystem MBean: Hadoop:service=NameNode,name=FSNamesystem-7
2020-12-03 07:23:24,903 [Listener at 0.0.0.0/39019] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(126)) - Registered FSNamesystemState MBean: Hadoop:service=NameNode,name=FSNamesystemState-7
2020-12-03 07:23:24,904 [Listener at 0.0.0.0/39019] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(134)) - Registered NameNodeInfo MBean: Hadoop:service=NameNode,name=NameNodeInfo-7
2020-12-03 07:23:24,904 [Listener at 0.0.0.0/39019] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(143)) - Registered NameNodeStatus MBean: Hadoop:service=NameNode,name=NameNodeStatus-7
2020-12-03 07:23:24,910 [Listener at 0.0.0.0/39019] INFO  metrics.FederationMetrics (FederationMetrics.java:<init>(126)) - Registered Router MBean: Hadoop:service=Router,name=FederationState-3
2020-12-03 07:23:24,921 [IPC Server handler 4 on default port 42106] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:25,003 [Listener at 0.0.0.0/39019] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:23:25,003 [Edit log tailer] WARN  ha.EditLogTailer (EditLogTailer.java:doWork(528)) - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.sleep(EditLogTailer.java:433)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:526)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:440)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:457)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:484)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:453)
2020-12-03 07:23:25,018 [Listener at 0.0.0.0/39019] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:23:25,024 [Listener at 0.0.0.0/39019] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-0-through-1/current
2020-12-03 07:23:25,025 [Listener at 0.0.0.0/39019] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current
2020-12-03 07:23:25,025 [Listener at 0.0.0.0/39019] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/current
2020-12-03 07:23:25,025 [Listener at 0.0.0.0/39019] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1233)) - Catching up to latest edits from old active before taking over writer role in edits logs
2020-12-03 07:23:25,026 [Listener at 0.0.0.0/39019] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:markAllDatanodesStale(1840)) - Marking all datanodes as stale
2020-12-03 07:23:25,045 [Listener at 0.0.0.0/39019] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1244)) - Reprocessing replication and invalidation queues
2020-12-03 07:23:25,045 [Listener at 0.0.0.0/39019] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:23:25,045 [Listener at 0.0.0.0/39019] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1255)) - Will take over writing edit logs at txnid 1
2020-12-03 07:23:25,046 [Listener at 0.0.0.0/39019] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 1
2020-12-03 07:23:25,156 [Listener at 0.0.0.0/39019] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:23:25,164 [Listener at 0.0.0.0/39019] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 9 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:23:25,179 [CacheReplicationMonitor(147343281)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:23:25,179 [Listener at 0.0.0.0/39019] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:23:25,180 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 0
2020-12-03 07:23:25,180 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:23:25,180 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:23:25,180 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:23:25,181 [Edit log tailer] WARN  ha.EditLogTailer (EditLogTailer.java:doWork(528)) - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.sleep(EditLogTailer.java:433)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:526)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:440)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:457)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:484)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:453)
2020-12-03 07:23:25,187 [Listener at 0.0.0.0/39019] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:23:25,186 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:23:25,188 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 142 msec
2020-12-03 07:23:25,189 [Listener at 0.0.0.0/39019] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-2-through-3/current
2020-12-03 07:23:25,189 [Listener at 0.0.0.0/39019] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/current
2020-12-03 07:23:25,189 [Listener at 0.0.0.0/39019] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6/current
2020-12-03 07:23:25,190 [Listener at 0.0.0.0/39019] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1233)) - Catching up to latest edits from old active before taking over writer role in edits logs
2020-12-03 07:23:25,195 [Listener at 0.0.0.0/39019] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:markAllDatanodesStale(1840)) - Marking all datanodes as stale
2020-12-03 07:23:25,218 [Listener at 0.0.0.0/39019] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1244)) - Reprocessing replication and invalidation queues
2020-12-03 07:23:25,218 [Listener at 0.0.0.0/39019] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:23:25,218 [Listener at 0.0.0.0/39019] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1255)) - Will take over writing edit logs at txnid 1
2020-12-03 07:23:25,219 [Listener at 0.0.0.0/39019] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 1
2020-12-03 07:23:25,239 [Listener at 0.0.0.0/39019] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:23:25,240 [Listener at 0.0.0.0/39019] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 1 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:23:25,242 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 0
2020-12-03 07:23:25,242 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:23:25,242 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:23:25,245 [CacheReplicationMonitor(2142337660)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:23:25,251 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:23:25,251 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:23:25,251 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 33 msec
2020-12-03 07:23:26,286 [BP-286010920-172.17.0.2-1606980199054 heartbeating to localhost/127.0.0.1:42106] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-286010920-172.17.0.2-1606980199054 (Datanode Uuid b9a147fb-134d-449d-b6a4-64a8ee59436a) service to localhost/127.0.0.1:42106 trying to claim ACTIVE state with txid=1
2020-12-03 07:23:26,286 [BP-286010920-172.17.0.2-1606980199054 heartbeating to localhost/127.0.0.1:42106] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-286010920-172.17.0.2-1606980199054 (Datanode Uuid b9a147fb-134d-449d-b6a4-64a8ee59436a) service to localhost/127.0.0.1:42106
2020-12-03 07:23:26,300 [BP-286010920-172.17.0.2-1606980199054 heartbeating to localhost/127.0.0.1:42106] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-286010920-172.17.0.2-1606980199054 (Datanode Uuid 8f01febb-1c2e-4617-a206-a73518a9f66d) service to localhost/127.0.0.1:42106 trying to claim ACTIVE state with txid=1
2020-12-03 07:23:26,303 [BP-286010920-172.17.0.2-1606980199054 heartbeating to localhost/127.0.0.1:42106] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-286010920-172.17.0.2-1606980199054 (Datanode Uuid 8f01febb-1c2e-4617-a206-a73518a9f66d) service to localhost/127.0.0.1:42106
2020-12-03 07:23:26,313 [BP-2036634619-172.17.0.2-1606980196096 heartbeating to localhost/127.0.0.1:42380] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-2036634619-172.17.0.2-1606980196096 (Datanode Uuid b9a147fb-134d-449d-b6a4-64a8ee59436a) service to localhost/127.0.0.1:42380 trying to claim ACTIVE state with txid=1
2020-12-03 07:23:26,314 [BP-2036634619-172.17.0.2-1606980196096 heartbeating to localhost/127.0.0.1:42380] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-2036634619-172.17.0.2-1606980196096 (Datanode Uuid b9a147fb-134d-449d-b6a4-64a8ee59436a) service to localhost/127.0.0.1:42380
2020-12-03 07:23:26,314 [BP-2036634619-172.17.0.2-1606980196096 heartbeating to localhost/127.0.0.1:42380] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-2036634619-172.17.0.2-1606980196096 (Datanode Uuid 8f01febb-1c2e-4617-a206-a73518a9f66d) service to localhost/127.0.0.1:42380 trying to claim ACTIVE state with txid=1
2020-12-03 07:23:26,314 [BP-2036634619-172.17.0.2-1606980196096 heartbeating to localhost/127.0.0.1:42380] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-2036634619-172.17.0.2-1606980196096 (Datanode Uuid 8f01febb-1c2e-4617-a206-a73518a9f66d) service to localhost/127.0.0.1:42380
2020-12-03 07:23:26,318 [Thread-472] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = webhdfs://0.0.0.0:39607 implemented by org.apache.hadoop.hdfs.web.WebHdfsFileSystem@9215a60
Dec 03, 2020 7:23:26 AM com.sun.jersey.api.core.PackagesResourceConfig init
INFO: Scanning for root resource and provider classes in the packages:
  org.apache.hadoop.hdfs.server.federation.router
  org.apache.hadoop.hdfs.web.resources
2020-12-03 07:23:26,486 [BP-2036634619-172.17.0.2-1606980196096 heartbeating to localhost/127.0.0.1:42380] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-2036634619-172.17.0.2-1606980196096 (Datanode Uuid b997f6ab-56cf-4acb-b159-8dac72f89a15) service to localhost/127.0.0.1:42380 trying to claim ACTIVE state with txid=1
2020-12-03 07:23:26,491 [BP-2036634619-172.17.0.2-1606980196096 heartbeating to localhost/127.0.0.1:42380] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-2036634619-172.17.0.2-1606980196096 (Datanode Uuid b997f6ab-56cf-4acb-b159-8dac72f89a15) service to localhost/127.0.0.1:42380
2020-12-03 07:23:26,522 [BP-286010920-172.17.0.2-1606980199054 heartbeating to localhost/127.0.0.1:42106] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-286010920-172.17.0.2-1606980199054 (Datanode Uuid b997f6ab-56cf-4acb-b159-8dac72f89a15) service to localhost/127.0.0.1:42106 trying to claim ACTIVE state with txid=1
2020-12-03 07:23:26,522 [BP-286010920-172.17.0.2-1606980199054 heartbeating to localhost/127.0.0.1:42106] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-286010920-172.17.0.2-1606980199054 (Datanode Uuid b997f6ab-56cf-4acb-b159-8dac72f89a15) service to localhost/127.0.0.1:42106
2020-12-03 07:23:26,656 [BP-2036634619-172.17.0.2-1606980196096 heartbeating to localhost/127.0.0.1:42380] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-2036634619-172.17.0.2-1606980196096 (Datanode Uuid 1917c584-39c3-42c1-87c7-45983f4c84fe) service to localhost/127.0.0.1:42380 trying to claim ACTIVE state with txid=1
2020-12-03 07:23:26,657 [BP-2036634619-172.17.0.2-1606980196096 heartbeating to localhost/127.0.0.1:42380] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-2036634619-172.17.0.2-1606980196096 (Datanode Uuid 1917c584-39c3-42c1-87c7-45983f4c84fe) service to localhost/127.0.0.1:42380
2020-12-03 07:23:26,709 [BP-286010920-172.17.0.2-1606980199054 heartbeating to localhost/127.0.0.1:42106] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-286010920-172.17.0.2-1606980199054 (Datanode Uuid 1917c584-39c3-42c1-87c7-45983f4c84fe) service to localhost/127.0.0.1:42106 trying to claim ACTIVE state with txid=1
2020-12-03 07:23:26,709 [BP-286010920-172.17.0.2-1606980199054 heartbeating to localhost/127.0.0.1:42106] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-286010920-172.17.0.2-1606980199054 (Datanode Uuid 1917c584-39c3-42c1-87c7-45983f4c84fe) service to localhost/127.0.0.1:42106
Dec 03, 2020 7:23:27 AM com.sun.jersey.api.core.ScanningResourceConfig logClasses
INFO: Root resource classes found:
  class org.apache.hadoop.hdfs.server.federation.router.RouterWebHdfsMethods
Dec 03, 2020 7:23:27 AM com.sun.jersey.api.core.ScanningResourceConfig logClasses
INFO: Provider classes found:
  class org.apache.hadoop.hdfs.web.resources.UserProvider
  class org.apache.hadoop.hdfs.web.resources.ExceptionHandler
Dec 03, 2020 7:23:27 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
Dec 03, 2020 7:23:28 AM com.sun.jersey.spi.inject.Errors processErrorMessages
WARNING: The following warnings have been detected with resource and/or provider classes:
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.deleteRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.DeleteOpParam,org.apache.hadoop.hdfs.web.resources.RecursiveParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.putRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.PutOpParam,org.apache.hadoop.hdfs.web.resources.DestinationParam,org.apache.hadoop.hdfs.web.resources.OwnerParam,org.apache.hadoop.hdfs.web.resources.GroupParam,org.apache.hadoop.hdfs.web.resources.PermissionParam,org.apache.hadoop.hdfs.web.resources.UnmaskedPermissionParam,org.apache.hadoop.hdfs.web.resources.OverwriteParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,org.apache.hadoop.hdfs.web.resources.ReplicationParam,org.apache.hadoop.hdfs.web.resources.BlockSizeParam,org.apache.hadoop.hdfs.web.resources.ModificationTimeParam,org.apache.hadoop.hdfs.web.resources.AccessTimeParam,org.apache.hadoop.hdfs.web.resources.RenameOptionSetParam,org.apache.hadoop.hdfs.web.resources.CreateParentParam,org.apache.hadoop.hdfs.web.resources.TokenArgumentParam,org.apache.hadoop.hdfs.web.resources.AclPermissionParam,org.apache.hadoop.hdfs.web.resources.XAttrNameParam,org.apache.hadoop.hdfs.web.resources.XAttrValueParam,org.apache.hadoop.hdfs.web.resources.XAttrSetFlagParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam,org.apache.hadoop.hdfs.web.resources.OldSnapshotNameParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.CreateFlagParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam,org.apache.hadoop.hdfs.web.resources.StoragePolicyParam,org.apache.hadoop.hdfs.web.resources.ECPolicyParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.postRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.PostOpParam,org.apache.hadoop.hdfs.web.resources.ConcatSourcesParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.NewLengthParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.getRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.GetOpParam,org.apache.hadoop.hdfs.web.resources.OffsetParam,org.apache.hadoop.hdfs.web.resources.LengthParam,org.apache.hadoop.hdfs.web.resources.RenewerParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,java.util.List,org.apache.hadoop.hdfs.web.resources.XAttrEncodingParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.FsActionParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam,org.apache.hadoop.hdfs.web.resources.OldSnapshotNameParam,org.apache.hadoop.hdfs.web.resources.TokenKindParam,org.apache.hadoop.hdfs.web.resources.TokenServiceParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam,org.apache.hadoop.hdfs.web.resources.StartAfterParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
2020-12-03 07:23:28,454 [IPC Server handler 5 on default port 42380] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
Dec 03, 2020 7:23:28 AM com.sun.jersey.api.core.PackagesResourceConfig init
INFO: Scanning for root resource and provider classes in the packages:
  org.apache.hadoop.hdfs.server.namenode.web.resources
  org.apache.hadoop.hdfs.web.resources
2020-12-03 07:23:29,241 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-12-03 07:23:29,301 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 7a5505b8915a:39419: State Store unavailable
2020-12-03 07:23:29,363 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-12-03 07:23:29,481 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 7a5505b8915a:45083: State Store unavailable
2020-12-03 07:23:29,488 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
Dec 03, 2020 7:23:29 AM com.sun.jersey.api.core.ScanningResourceConfig logClasses
INFO: Root resource classes found:
  class org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods
Dec 03, 2020 7:23:29 AM com.sun.jersey.api.core.ScanningResourceConfig logClasses
INFO: Provider classes found:
  class org.apache.hadoop.hdfs.web.resources.UserProvider
  class org.apache.hadoop.hdfs.web.resources.ExceptionHandler
Dec 03, 2020 7:23:29 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
2020-12-03 07:23:29,637 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 7a5505b8915a:38866: State Store unavailable
2020-12-03 07:23:29,733 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-12-03 07:23:29,904 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 7a5505b8915a:44401: State Store unavailable
Dec 03, 2020 7:23:29 AM com.sun.jersey.spi.inject.Errors processErrorMessages
WARNING: The following warnings have been detected with resource and/or provider classes:
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.deleteRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.DeleteOpParam,org.apache.hadoop.hdfs.web.resources.RecursiveParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.putRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.PutOpParam,org.apache.hadoop.hdfs.web.resources.DestinationParam,org.apache.hadoop.hdfs.web.resources.OwnerParam,org.apache.hadoop.hdfs.web.resources.GroupParam,org.apache.hadoop.hdfs.web.resources.PermissionParam,org.apache.hadoop.hdfs.web.resources.UnmaskedPermissionParam,org.apache.hadoop.hdfs.web.resources.OverwriteParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,org.apache.hadoop.hdfs.web.resources.ReplicationParam,org.apache.hadoop.hdfs.web.resources.BlockSizeParam,org.apache.hadoop.hdfs.web.resources.ModificationTimeParam,org.apache.hadoop.hdfs.web.resources.AccessTimeParam,org.apache.hadoop.hdfs.web.resources.RenameOptionSetParam,org.apache.hadoop.hdfs.web.resources.CreateParentParam,org.apache.hadoop.hdfs.web.resources.TokenArgumentParam,org.apache.hadoop.hdfs.web.resources.AclPermissionParam,org.apache.hadoop.hdfs.web.resources.XAttrNameParam,org.apache.hadoop.hdfs.web.resources.XAttrValueParam,org.apache.hadoop.hdfs.web.resources.XAttrSetFlagParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam,org.apache.hadoop.hdfs.web.resources.OldSnapshotNameParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.CreateFlagParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam,org.apache.hadoop.hdfs.web.resources.StoragePolicyParam,org.apache.hadoop.hdfs.web.resources.ECPolicyParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.postRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.PostOpParam,org.apache.hadoop.hdfs.web.resources.ConcatSourcesParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.NewLengthParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.getRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.GetOpParam,org.apache.hadoop.hdfs.web.resources.OffsetParam,org.apache.hadoop.hdfs.web.resources.LengthParam,org.apache.hadoop.hdfs.web.resources.RenewerParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,java.util.List,org.apache.hadoop.hdfs.web.resources.XAttrEncodingParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.FsActionParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam,org.apache.hadoop.hdfs.web.resources.OldSnapshotNameParam,org.apache.hadoop.hdfs.web.resources.TokenKindParam,org.apache.hadoop.hdfs.web.resources.TokenServiceParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam,org.apache.hadoop.hdfs.web.resources.StartAfterParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
2020-12-03 07:23:30,097 [IPC Server handler 4 on default port 42380] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/test/seekfile.txt	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:23:30,568 [nioEventLoopGroup-7-1] INFO  datanode.webhdfs (WebHdfsHandler.java:run(147)) - 127.0.0.1 PUT /webhdfs/v1/test/seekfile.txt?op=CREATE&user.name=root&namenoderpcaddress=7a5505b8915a:39419&blocksize=134217728&buffersize=4096&createflag=&createparent=true&overwrite=true&permission=644&replication=3&unmaskedpermission=666 201
2020-12-03 07:23:30,628 [IPC Server handler 7 on default port 42380] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:39171, 127.0.0.1:44600, 127.0.0.1:34378 for /test/seekfile.txt
2020-12-03 07:23:30,648 [Thread-476] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:30,738 [DataXceiver for client DFSClient_NONMAPREDUCE_-1902892770_699 at /127.0.0.1:53778 [Receiving block BP-2036634619-172.17.0.2-1606980196096:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2036634619-172.17.0.2-1606980196096:blk_1073741825_1001 src: /127.0.0.1:53778 dest: /127.0.0.1:39171
2020-12-03 07:23:30,772 [DataXceiver for client DFSClient_NONMAPREDUCE_-1902892770_699 at /127.0.0.1:53778 [Receiving block BP-2036634619-172.17.0.2-1606980196096:blk_1073741825_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:30,784 [DataXceiver for client DFSClient_NONMAPREDUCE_-1902892770_699 at /127.0.0.1:54138 [Receiving block BP-2036634619-172.17.0.2-1606980196096:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2036634619-172.17.0.2-1606980196096:blk_1073741825_1001 src: /127.0.0.1:54138 dest: /127.0.0.1:44600
2020-12-03 07:23:30,787 [DataXceiver for client DFSClient_NONMAPREDUCE_-1902892770_699 at /127.0.0.1:54138 [Receiving block BP-2036634619-172.17.0.2-1606980196096:blk_1073741825_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:30,796 [DataXceiver for client DFSClient_NONMAPREDUCE_-1902892770_699 at /127.0.0.1:39978 [Receiving block BP-2036634619-172.17.0.2-1606980196096:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-2036634619-172.17.0.2-1606980196096:blk_1073741825_1001 src: /127.0.0.1:39978 dest: /127.0.0.1:34378
2020-12-03 07:23:30,882 [PacketResponder: BP-2036634619-172.17.0.2-1606980196096:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39978, dest: /127.0.0.1:34378, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1902892770_699, offset: 0, srvID: b997f6ab-56cf-4acb-b159-8dac72f89a15, blockid: BP-2036634619-172.17.0.2-1606980196096:blk_1073741825_1001, duration(ns): 32508478
2020-12-03 07:23:30,883 [PacketResponder: BP-2036634619-172.17.0.2-1606980196096:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2036634619-172.17.0.2-1606980196096:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:23:30,890 [PacketResponder: BP-2036634619-172.17.0.2-1606980196096:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34378]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54138, dest: /127.0.0.1:44600, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1902892770_699, offset: 0, srvID: 8f01febb-1c2e-4617-a206-a73518a9f66d, blockid: BP-2036634619-172.17.0.2-1606980196096:blk_1073741825_1001, duration(ns): 39168169
2020-12-03 07:23:30,901 [PacketResponder: BP-2036634619-172.17.0.2-1606980196096:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34378]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2036634619-172.17.0.2-1606980196096:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34378] terminating
2020-12-03 07:23:30,922 [IPC Server handler 1 on default port 42106] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:30,922 [IPC Server handler 5 on default port 42380] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:30,923 [IPC Server handler 5 on default port 42380] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:30,940 [IPC Server handler 6 on default port 42380] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:30,941 [IPC Server handler 3 on default port 41178] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:30,941 [IPC Server handler 6 on default port 42106] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:30,941 [IPC Server handler 6 on default port 42106] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:30,943 [IPC Server handler 6 on default port 41178] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:30,944 [IPC Server handler 4 on default port 41178] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:30,944 [IPC Server handler 9 on default port 41178] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:30,952 [PacketResponder: BP-2036634619-172.17.0.2-1606980196096:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:44600, 127.0.0.1:34378]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:53778, dest: /127.0.0.1:39171, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1902892770_699, offset: 0, srvID: b9a147fb-134d-449d-b6a4-64a8ee59436a, blockid: BP-2036634619-172.17.0.2-1606980196096:blk_1073741825_1001, duration(ns): 66081208
2020-12-03 07:23:30,953 [PacketResponder: BP-2036634619-172.17.0.2-1606980196096:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:44600, 127.0.0.1:34378]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2036634619-172.17.0.2-1606980196096:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:44600, 127.0.0.1:34378] terminating
2020-12-03 07:23:30,953 [IPC Server handler 8 on default port 42106] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:30,959 [IPC Server handler 2 on default port 41220] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:30,959 [IPC Server handler 5 on default port 41220] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:30,956 [IPC Server handler 3 on default port 42380] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:30,968 [IPC Server handler 8 on default port 41220] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:30,968 [IPC Server handler 9 on default port 41220] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:31,048 [IPC Server handler 1 on default port 42380] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2995)) - BLOCK* blk_1073741825_1001 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /test/seekfile.txt
2020-12-03 07:23:31,456 [IPC Server handler 9 on default port 42380] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /test/seekfile.txt is closed by DFSClient_NONMAPREDUCE_-1902892770_699
2020-12-03 07:23:31,547 [IPC Server handler 2 on default port 42380] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/test/zero.txt	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:23:31,553 [nioEventLoopGroup-3-1] INFO  datanode.webhdfs (WebHdfsHandler.java:run(147)) - 127.0.0.1 PUT /webhdfs/v1/test/zero.txt?op=CREATE&user.name=root&namenoderpcaddress=7a5505b8915a:39419&blocksize=134217728&buffersize=4096&createflag=&createparent=true&overwrite=true&permission=644&replication=3&unmaskedpermission=666 201
2020-12-03 07:23:31,558 [IPC Server handler 0 on default port 42380] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /test/zero.txt is closed by DFSClient_NONMAPREDUCE_1978660794_303
2020-12-03 07:23:31,561 [Thread-472] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - do a block read on a 0 byte file
2020-12-03 07:23:31,591 [IPC Server handler 4 on default port 42380] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:31,608 [IPC Server handler 5 on default port 42106] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:31,619 [IPC Server handler 1 on default port 42380] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/zero.txt	dst=null	perm=null	proto=rpc
2020-12-03 07:23:31,645 [IPC Server handler 5 on default port 42380] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/test/zero.txt	dst=null	perm=null	proto=rpc
2020-12-03 07:23:31,670 [nioEventLoopGroup-5-1] INFO  datanode.webhdfs (WebHdfsHandler.java:run(147)) - 127.0.0.1 GET /webhdfs/v1/test/zero.txt?op=OPEN&user.name=root&namenoderpcaddress=7a5505b8915a:39419&buffersize=4096&offset=0 200
2020-12-03 07:23:31,684 [IPC Server handler 7 on default port 42380] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test	dst=null	perm=null	proto=rpc
2020-12-03 07:23:31,737 [IPC Server handler 8 on default port 42380] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/test	dst=null	perm=null	proto=rpc
2020-12-03 07:23:31,747 [Listener at 0.0.0.0/39019] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:23:31,748 [Listener at 0.0.0.0/39019] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 3
2020-12-03 07:23:31,748 [Listener at 0.0.0.0/39019] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:23:31,749 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@47b2e9e1] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:31,768 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, DS-f1560c54-0c7f-451c-ade4-648ed1535376) exiting.
2020-12-03 07:23:31,768 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, DS-32ee6b6e-ecea-462a-922f-e3967ffcb365) exiting.
2020-12-03 07:23:31,834 [Listener at 0.0.0.0/39019] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6edc4161{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:31,867 [Listener at 0.0.0.0/39019] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@5486887b{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:31,873 [Listener at 0.0.0.0/39019] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6872f9c8{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:23:31,874 [Listener at 0.0.0.0/39019] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@25b865b5{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:23:31,886 [Listener at 0.0.0.0/39019] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 45068
2020-12-03 07:23:31,907 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:31,910 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:31,911 [BP-2036634619-172.17.0.2-1606980196096 heartbeating to localhost/127.0.0.1:42380] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:31,911 [BP-2036634619-172.17.0.2-1606980196096 heartbeating to localhost/127.0.0.1:42380] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-2036634619-172.17.0.2-1606980196096 (Datanode Uuid 1917c584-39c3-42c1-87c7-45983f4c84fe) service to localhost/127.0.0.1:42380
2020-12-03 07:23:31,913 [BP-286010920-172.17.0.2-1606980199054 heartbeating to localhost/127.0.0.1:41220] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:31,914 [BP-286010920-172.17.0.2-1606980199054 heartbeating to localhost/127.0.0.1:41220] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-286010920-172.17.0.2-1606980199054 (Datanode Uuid 1917c584-39c3-42c1-87c7-45983f4c84fe) service to localhost/127.0.0.1:41220
2020-12-03 07:23:31,912 [BP-2036634619-172.17.0.2-1606980196096 heartbeating to localhost/127.0.0.1:41178] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:31,914 [BP-2036634619-172.17.0.2-1606980196096 heartbeating to localhost/127.0.0.1:41178] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-2036634619-172.17.0.2-1606980196096 (Datanode Uuid 1917c584-39c3-42c1-87c7-45983f4c84fe) service to localhost/127.0.0.1:41178
2020-12-03 07:23:31,914 [BP-2036634619-172.17.0.2-1606980196096 heartbeating to localhost/127.0.0.1:41178] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-2036634619-172.17.0.2-1606980196096 (Datanode Uuid 1917c584-39c3-42c1-87c7-45983f4c84fe)
2020-12-03 07:23:31,914 [BP-2036634619-172.17.0.2-1606980196096 heartbeating to localhost/127.0.0.1:41178] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-2036634619-172.17.0.2-1606980196096
2020-12-03 07:23:31,916 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-2036634619-172.17.0.2-1606980196096] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:31,912 [BP-286010920-172.17.0.2-1606980199054 heartbeating to localhost/127.0.0.1:42106] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:31,916 [BP-286010920-172.17.0.2-1606980199054 heartbeating to localhost/127.0.0.1:42106] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-286010920-172.17.0.2-1606980199054 (Datanode Uuid 1917c584-39c3-42c1-87c7-45983f4c84fe) service to localhost/127.0.0.1:42106
2020-12-03 07:23:31,916 [BP-286010920-172.17.0.2-1606980199054 heartbeating to localhost/127.0.0.1:42106] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-286010920-172.17.0.2-1606980199054 (Datanode Uuid 1917c584-39c3-42c1-87c7-45983f4c84fe)
2020-12-03 07:23:31,916 [BP-286010920-172.17.0.2-1606980199054 heartbeating to localhost/127.0.0.1:42106] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-286010920-172.17.0.2-1606980199054
2020-12-03 07:23:31,916 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-2036634619-172.17.0.2-1606980196096] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:31,917 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-286010920-172.17.0.2-1606980199054] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:31,917 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-286010920-172.17.0.2-1606980199054] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:31,931 [Listener at 0.0.0.0/39019] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:23:31,931 [Listener at 0.0.0.0/39019] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:23:31,932 [Listener at 0.0.0.0/39019] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:23:31,933 [Listener at 0.0.0.0/39019] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:23:31,945 [Listener at 0.0.0.0/39019] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:31,946 [Listener at 0.0.0.0/39019] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 2
2020-12-03 07:23:31,946 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@34b9fc7d] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:31,947 [Listener at 0.0.0.0/39019] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:23:31,949 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, DS-9dc1839e-cbff-43d6-ae19-9f469f186f57) exiting.
2020-12-03 07:23:31,951 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, DS-c7fc4836-6abf-432b-835a-5c81775ebbd5) exiting.
2020-12-03 07:23:31,994 [Listener at 0.0.0.0/39019] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@69cac930{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:31,995 [Listener at 0.0.0.0/39019] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@19593091{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:31,995 [Listener at 0.0.0.0/39019] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@baf1bb3{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:23:31,996 [Listener at 0.0.0.0/39019] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@588ffeb{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:23:32,002 [Listener at 0.0.0.0/39019] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 39589
2020-12-03 07:23:32,076 [BP-2036634619-172.17.0.2-1606980196096 heartbeating to localhost/127.0.0.1:41178] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:32,076 [BP-286010920-172.17.0.2-1606980199054 heartbeating to localhost/127.0.0.1:41220] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:32,077 [BP-286010920-172.17.0.2-1606980199054 heartbeating to localhost/127.0.0.1:41220] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-286010920-172.17.0.2-1606980199054 (Datanode Uuid b997f6ab-56cf-4acb-b159-8dac72f89a15) service to localhost/127.0.0.1:41220
2020-12-03 07:23:32,076 [BP-286010920-172.17.0.2-1606980199054 heartbeating to localhost/127.0.0.1:42106] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:32,077 [BP-286010920-172.17.0.2-1606980199054 heartbeating to localhost/127.0.0.1:42106] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-286010920-172.17.0.2-1606980199054 (Datanode Uuid b997f6ab-56cf-4acb-b159-8dac72f89a15) service to localhost/127.0.0.1:42106
2020-12-03 07:23:32,077 [BP-286010920-172.17.0.2-1606980199054 heartbeating to localhost/127.0.0.1:42106] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-286010920-172.17.0.2-1606980199054 (Datanode Uuid b997f6ab-56cf-4acb-b159-8dac72f89a15)
2020-12-03 07:23:32,077 [BP-286010920-172.17.0.2-1606980199054 heartbeating to localhost/127.0.0.1:42106] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-286010920-172.17.0.2-1606980199054
2020-12-03 07:23:32,078 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-286010920-172.17.0.2-1606980199054] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:32,077 [BP-2036634619-172.17.0.2-1606980196096 heartbeating to localhost/127.0.0.1:41178] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-2036634619-172.17.0.2-1606980196096 (Datanode Uuid b997f6ab-56cf-4acb-b159-8dac72f89a15) service to localhost/127.0.0.1:41178
2020-12-03 07:23:32,078 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:32,080 [BP-2036634619-172.17.0.2-1606980196096 heartbeating to localhost/127.0.0.1:42380] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:32,080 [BP-2036634619-172.17.0.2-1606980196096 heartbeating to localhost/127.0.0.1:42380] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-2036634619-172.17.0.2-1606980196096 (Datanode Uuid b997f6ab-56cf-4acb-b159-8dac72f89a15) service to localhost/127.0.0.1:42380
2020-12-03 07:23:32,080 [BP-2036634619-172.17.0.2-1606980196096 heartbeating to localhost/127.0.0.1:42380] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-2036634619-172.17.0.2-1606980196096 (Datanode Uuid b997f6ab-56cf-4acb-b159-8dac72f89a15)
2020-12-03 07:23:32,112 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:32,113 [BP-2036634619-172.17.0.2-1606980196096 heartbeating to localhost/127.0.0.1:42380] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-2036634619-172.17.0.2-1606980196096
2020-12-03 07:23:32,115 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-286010920-172.17.0.2-1606980199054] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:32,116 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-2036634619-172.17.0.2-1606980196096] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:32,116 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-2036634619-172.17.0.2-1606980196096] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:32,142 [Listener at 0.0.0.0/39019] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:23:32,143 [Listener at 0.0.0.0/39019] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:23:32,145 [Listener at 0.0.0.0/39019] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:23:32,145 [Listener at 0.0.0.0/39019] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:23:32,150 [Listener at 0.0.0.0/39019] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:32,150 [Listener at 0.0.0.0/39019] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 1
2020-12-03 07:23:32,151 [Listener at 0.0.0.0/39019] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:23:32,151 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@72458efc] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:32,151 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, DS-8ae2d45d-3ea1-4fcf-936e-d146876566da) exiting.
2020-12-03 07:23:32,155 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, DS-93ea001c-b6e4-4144-83cf-5e00deaaa577) exiting.
2020-12-03 07:23:32,223 [Listener at 0.0.0.0/39019] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5cbb84b1{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:32,227 [Listener at 0.0.0.0/39019] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2c779e5{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:32,228 [Listener at 0.0.0.0/39019] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6ac97b84{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:23:32,228 [Listener at 0.0.0.0/39019] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2e3a5237{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:23:32,273 [BP-2036634619-172.17.0.2-1606980196096 heartbeating to localhost/127.0.0.1:41178] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-2036634619-172.17.0.2-1606980196096 (Datanode Uuid 8f01febb-1c2e-4617-a206-a73518a9f66d) service to localhost/127.0.0.1:41178
2020-12-03 07:23:32,275 [BP-286010920-172.17.0.2-1606980199054 heartbeating to localhost/127.0.0.1:41220] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-286010920-172.17.0.2-1606980199054 (Datanode Uuid 8f01febb-1c2e-4617-a206-a73518a9f66d) service to localhost/127.0.0.1:41220
2020-12-03 07:23:32,276 [BP-2036634619-172.17.0.2-1606980196096 heartbeating to localhost/127.0.0.1:42380] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-2036634619-172.17.0.2-1606980196096 (Datanode Uuid 8f01febb-1c2e-4617-a206-a73518a9f66d) service to localhost/127.0.0.1:42380
2020-12-03 07:23:32,276 [BP-2036634619-172.17.0.2-1606980196096 heartbeating to localhost/127.0.0.1:42380] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-2036634619-172.17.0.2-1606980196096 (Datanode Uuid 8f01febb-1c2e-4617-a206-a73518a9f66d)
2020-12-03 07:23:32,277 [BP-2036634619-172.17.0.2-1606980196096 heartbeating to localhost/127.0.0.1:42380] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-2036634619-172.17.0.2-1606980196096
2020-12-03 07:23:32,278 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-2036634619-172.17.0.2-1606980196096] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:32,278 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-2036634619-172.17.0.2-1606980196096] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:32,275 [Listener at 0.0.0.0/39019] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 40840
2020-12-03 07:23:32,296 [BP-286010920-172.17.0.2-1606980199054 heartbeating to localhost/127.0.0.1:42106] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-286010920-172.17.0.2-1606980199054 (Datanode Uuid 8f01febb-1c2e-4617-a206-a73518a9f66d) service to localhost/127.0.0.1:42106
2020-12-03 07:23:32,297 [BP-286010920-172.17.0.2-1606980199054 heartbeating to localhost/127.0.0.1:42106] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-286010920-172.17.0.2-1606980199054 (Datanode Uuid 8f01febb-1c2e-4617-a206-a73518a9f66d)
2020-12-03 07:23:32,297 [BP-286010920-172.17.0.2-1606980199054 heartbeating to localhost/127.0.0.1:42106] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-286010920-172.17.0.2-1606980199054
2020-12-03 07:23:32,303 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-286010920-172.17.0.2-1606980199054] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:32,304 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-286010920-172.17.0.2-1606980199054] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:32,340 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:32,340 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:32,359 [Listener at 0.0.0.0/39019] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:23:32,359 [Listener at 0.0.0.0/39019] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:23:32,363 [Listener at 0.0.0.0/39019] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:23:32,363 [Listener at 0.0.0.0/39019] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:23:32,370 [Listener at 0.0.0.0/39019] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:32,370 [Listener at 0.0.0.0/39019] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:23:32,370 [Listener at 0.0.0.0/39019] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:23:32,371 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@273c947f] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:32,371 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, DS-5e7b33bf-2080-44f8-ba26-78c5f795a346) exiting.
2020-12-03 07:23:32,375 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, DS-d5770dd2-4b97-4a60-8165-e6f7485bd547) exiting.
2020-12-03 07:23:32,447 [Listener at 0.0.0.0/39019] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@38600b{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:32,448 [Listener at 0.0.0.0/39019] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@669d2b1b{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:32,449 [Listener at 0.0.0.0/39019] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@22175d4f{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:23:32,449 [Listener at 0.0.0.0/39019] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2472c7d8{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:23:32,451 [Listener at 0.0.0.0/39019] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 44521
2020-12-03 07:23:32,463 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:32,463 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:32,467 [BP-2036634619-172.17.0.2-1606980196096 heartbeating to localhost/127.0.0.1:41178] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:32,467 [BP-286010920-172.17.0.2-1606980199054 heartbeating to localhost/127.0.0.1:41220] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:32,467 [BP-2036634619-172.17.0.2-1606980196096 heartbeating to localhost/127.0.0.1:41178] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-2036634619-172.17.0.2-1606980196096 (Datanode Uuid b9a147fb-134d-449d-b6a4-64a8ee59436a) service to localhost/127.0.0.1:41178
2020-12-03 07:23:32,467 [BP-2036634619-172.17.0.2-1606980196096 heartbeating to localhost/127.0.0.1:42380] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:32,467 [BP-2036634619-172.17.0.2-1606980196096 heartbeating to localhost/127.0.0.1:42380] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-2036634619-172.17.0.2-1606980196096 (Datanode Uuid b9a147fb-134d-449d-b6a4-64a8ee59436a) service to localhost/127.0.0.1:42380
2020-12-03 07:23:32,467 [BP-2036634619-172.17.0.2-1606980196096 heartbeating to localhost/127.0.0.1:42380] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-2036634619-172.17.0.2-1606980196096 (Datanode Uuid b9a147fb-134d-449d-b6a4-64a8ee59436a)
2020-12-03 07:23:32,468 [BP-2036634619-172.17.0.2-1606980196096 heartbeating to localhost/127.0.0.1:42380] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-2036634619-172.17.0.2-1606980196096
2020-12-03 07:23:32,468 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-2036634619-172.17.0.2-1606980196096] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:32,469 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-2036634619-172.17.0.2-1606980196096] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:32,467 [BP-286010920-172.17.0.2-1606980199054 heartbeating to localhost/127.0.0.1:42106] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:32,469 [BP-286010920-172.17.0.2-1606980199054 heartbeating to localhost/127.0.0.1:42106] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-286010920-172.17.0.2-1606980199054 (Datanode Uuid b9a147fb-134d-449d-b6a4-64a8ee59436a) service to localhost/127.0.0.1:42106
2020-12-03 07:23:32,467 [BP-286010920-172.17.0.2-1606980199054 heartbeating to localhost/127.0.0.1:41220] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-286010920-172.17.0.2-1606980199054 (Datanode Uuid b9a147fb-134d-449d-b6a4-64a8ee59436a) service to localhost/127.0.0.1:41220
2020-12-03 07:23:32,469 [BP-286010920-172.17.0.2-1606980199054 heartbeating to localhost/127.0.0.1:41220] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-286010920-172.17.0.2-1606980199054 (Datanode Uuid b9a147fb-134d-449d-b6a4-64a8ee59436a)
2020-12-03 07:23:32,469 [BP-286010920-172.17.0.2-1606980199054 heartbeating to localhost/127.0.0.1:41220] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-286010920-172.17.0.2-1606980199054
2020-12-03 07:23:32,470 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-286010920-172.17.0.2-1606980199054] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:32,470 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-286010920-172.17.0.2-1606980199054] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:32,500 [Listener at 0.0.0.0/39019] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:23:32,500 [Listener at 0.0.0.0/39019] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:23:32,502 [Listener at 0.0.0.0/39019] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:23:32,503 [Listener at 0.0.0.0/39019] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:23:32,508 [Listener at 0.0.0.0/39019] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:32,508 [Listener at 0.0.0.0/39019] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:23:32,508 [Listener at 0.0.0.0/39019] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:32,511 [Listener at 0.0.0.0/39019] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 1, 10
2020-12-03 07:23:32,511 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@7afb1741] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:23:32,529 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@6ec65b5e] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:23:32,531 [Listener at 0.0.0.0/39019] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 11 Total time for transactions(ms): 51 Number of transactions batched in Syncs: 0 Number of syncs: 12 SyncTimes(ms): 44 6 26 
2020-12-03 07:23:32,533 [Listener at 0.0.0.0/39019] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-0-through-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-0-through-1/current/edits_0000000000000000001-0000000000000000011
2020-12-03 07:23:32,534 [Listener at 0.0.0.0/39019] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000011
2020-12-03 07:23:32,534 [Listener at 0.0.0.0/39019] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000011
2020-12-03 07:23:32,549 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:23:32,549 [Listener at 0.0.0.0/39019] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 42380
2020-12-03 07:23:32,550 [CacheReplicationMonitor(147343281)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:23:32,556 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:32,556 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:32,557 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:23:32,557 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:23:32,657 [Listener at 0.0.0.0/39019] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:32,657 [Listener at 0.0.0.0/39019] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:23:32,660 [Listener at 0.0.0.0/39019] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@71529963{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:23:32,664 [Listener at 0.0.0.0/39019] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@41d426b5{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:32,665 [Listener at 0.0.0.0/39019] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@27216cd{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:23:32,665 [Listener at 0.0.0.0/39019] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@78d6692f{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:23:32,681 [Listener at 0.0.0.0/39019] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:23:32,681 [Listener at 0.0.0.0/39019] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:23:32,681 [Edit log tailer] WARN  ha.EditLogTailer (EditLogTailer.java:doWork(528)) - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.sleep(EditLogTailer.java:433)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:526)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:440)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:457)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:484)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:453)
2020-12-03 07:23:32,682 [Listener at 0.0.0.0/39019] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 41178
2020-12-03 07:23:32,687 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:32,687 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:32,690 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:23:32,692 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:23:32,711 [Listener at 0.0.0.0/39019] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:32,739 [Listener at 0.0.0.0/39019] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:23:32,751 [Listener at 0.0.0.0/39019] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@70e0accd{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:23:32,754 [Listener at 0.0.0.0/39019] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7957dc72{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:32,754 [Listener at 0.0.0.0/39019] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1a15b789{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:23:32,755 [Listener at 0.0.0.0/39019] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@69adf72c{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:23:32,771 [Listener at 0.0.0.0/39019] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:23:32,772 [Listener at 0.0.0.0/39019] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:32,775 [Listener at 0.0.0.0/39019] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 1, 1
2020-12-03 07:23:32,776 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@45bb2aa1] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:23:32,775 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@67d86804] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:23:32,789 [Listener at 0.0.0.0/39019] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 2 Total time for transactions(ms): 13 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 7 2 2 
2020-12-03 07:23:32,789 [Listener at 0.0.0.0/39019] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-2-through-3/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-2-through-3/current/edits_0000000000000000001-0000000000000000002
2020-12-03 07:23:32,790 [Listener at 0.0.0.0/39019] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/current/edits_0000000000000000001-0000000000000000002
2020-12-03 07:23:32,791 [Listener at 0.0.0.0/39019] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6/current/edits_0000000000000000001-0000000000000000002
2020-12-03 07:23:32,791 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:23:32,791 [CacheReplicationMonitor(2142337660)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:23:32,792 [Listener at 0.0.0.0/39019] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 42106
2020-12-03 07:23:32,797 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:32,797 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:32,797 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:23:32,797 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:23:32,835 [Listener at 0.0.0.0/39019] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:32,836 [Listener at 0.0.0.0/39019] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:23:32,838 [Listener at 0.0.0.0/39019] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@22db8f4{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:23:32,841 [Listener at 0.0.0.0/39019] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2b46a8c1{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:32,841 [Listener at 0.0.0.0/39019] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5305c37d{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:23:32,842 [Listener at 0.0.0.0/39019] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@f5c79a6{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:23:32,856 [Listener at 0.0.0.0/39019] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:23:32,856 [Listener at 0.0.0.0/39019] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:23:32,857 [Edit log tailer] WARN  ha.EditLogTailer (EditLogTailer.java:doWork(528)) - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.sleep(EditLogTailer.java:433)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:526)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:440)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:457)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:484)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:453)
2020-12-03 07:23:32,857 [Listener at 0.0.0.0/39019] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 41220
2020-12-03 07:23:32,861 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:32,861 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:32,861 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:23:32,862 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:23:32,880 [Listener at 0.0.0.0/39019] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:32,893 [Listener at 0.0.0.0/39019] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:23:32,900 [Listener at 0.0.0.0/39019] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@3c321bdb{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:23:32,910 [Listener at 0.0.0.0/39019] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@24855019{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:32,910 [Listener at 0.0.0.0/39019] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@50b8ae8d{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:23:32,911 [Listener at 0.0.0.0/39019] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3228d990{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:23:32,969 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 7a5505b8915a:39419: State Store unavailable
2020-12-03 07:23:32,977 [Thread-487] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - RouterHeartbeatService is shutting down
2020-12-03 07:23:32,980 [Thread-487] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service RouterHeartbeatService
2020-12-03 07:23:32,994 [Thread-487] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn1 is shutting down
2020-12-03 07:23:32,994 [Thread-487] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn1
2020-12-03 07:23:33,019 [Thread-487] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn1 is shutting down
2020-12-03 07:23:33,020 [Thread-487] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn1
2020-12-03 07:23:33,043 [Thread-487] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn0 is shutting down
2020-12-03 07:23:33,043 [Thread-487] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn0
2020-12-03 07:23:33,048 [Thread-487] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn0 is shutting down
2020-12-03 07:23:33,048 [Thread-487] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn0
2020-12-03 07:23:33,060 [Thread-487] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@174e1b69{/,null,UNAVAILABLE}{/router}
2020-12-03 07:23:33,075 [Thread-487] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@1046498a{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2020-12-03 07:23:33,079 [Thread-487] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3b90a30a{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:33,082 [Thread-487] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6bf13698{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:23:33,103 [Thread-487] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 32876
2020-12-03 07:23:33,115 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:33,127 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:33,139 [Thread-487] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 39419
2020-12-03 07:23:33,146 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:33,151 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:33,167 [Thread-487] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreCacheUpdateService is shutting down
2020-12-03 07:23:33,168 [Thread-487] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreCacheUpdateService
2020-12-03 07:23:33,175 [Thread-487] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreConnectionMonitorService is shutting down
2020-12-03 07:23:33,175 [Thread-487] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreConnectionMonitorService
2020-12-03 07:23:33,962 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 7a5505b8915a:45083: State Store unavailable
2020-12-03 07:23:33,974 [Thread-492] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - RouterHeartbeatService is shutting down
2020-12-03 07:23:33,974 [Thread-492] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service RouterHeartbeatService
2020-12-03 07:23:33,980 [Thread-492] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn1 is shutting down
2020-12-03 07:23:33,981 [Thread-492] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn1
2020-12-03 07:23:34,056 [Thread-492] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn1 is shutting down
2020-12-03 07:23:34,057 [Thread-492] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn1
2020-12-03 07:23:34,068 [Thread-492] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn0 is shutting down
2020-12-03 07:23:34,068 [Thread-492] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn0
2020-12-03 07:23:34,077 [Thread-492] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn0 is shutting down
2020-12-03 07:23:34,077 [Thread-492] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn0
2020-12-03 07:23:34,087 [Thread-492] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@783115d9{/,null,UNAVAILABLE}{/router}
2020-12-03 07:23:34,088 [Thread-492] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@3402b4c9{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2020-12-03 07:23:34,091 [Thread-492] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6d2dc9d2{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:34,092 [Thread-492] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@56681eaf{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:23:34,095 [Thread-492] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 39072
2020-12-03 07:23:34,098 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:34,098 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:34,106 [Thread-492] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 45083
2020-12-03 07:23:34,110 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:34,118 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:34,122 [Thread-492] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping Router metrics system...
2020-12-03 07:23:34,124 [Thread-492] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - Router metrics system stopped.
2020-12-03 07:23:34,125 [Thread-492] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - Router metrics system shutdown complete.
2020-12-03 07:23:34,130 [Thread-492] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreCacheUpdateService is shutting down
2020-12-03 07:23:34,130 [Thread-492] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreCacheUpdateService
2020-12-03 07:23:34,139 [Thread-492] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreConnectionMonitorService is shutting down
2020-12-03 07:23:34,139 [Thread-492] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreConnectionMonitorService
2020-12-03 07:23:34,488 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-12-03 07:23:34,637 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 7a5505b8915a:38866: State Store unavailable
2020-12-03 07:23:34,733 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-12-03 07:23:34,905 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 7a5505b8915a:44401: State Store unavailable
2020-12-03 07:23:34,958 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 7a5505b8915a:38866: State Store unavailable
2020-12-03 07:23:34,959 [Thread-493] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - RouterHeartbeatService is shutting down
2020-12-03 07:23:34,959 [Thread-493] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service RouterHeartbeatService
2020-12-03 07:23:34,959 [Thread-493] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn1 is shutting down
2020-12-03 07:23:34,959 [Thread-493] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn1
2020-12-03 07:23:34,960 [Thread-493] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn1 is shutting down
2020-12-03 07:23:34,960 [Thread-493] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn1
2020-12-03 07:23:34,960 [Thread-493] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn0 is shutting down
2020-12-03 07:23:34,960 [Thread-493] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn0
2020-12-03 07:23:34,961 [Thread-493] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn0 is shutting down
2020-12-03 07:23:34,961 [Thread-493] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn0
2020-12-03 07:23:34,963 [Thread-493] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@664e5dee{/,null,UNAVAILABLE}{/router}
2020-12-03 07:23:34,964 [Thread-493] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@431f1eaf{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2020-12-03 07:23:34,965 [Thread-493] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1a891add{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:34,970 [Thread-493] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7fb33394{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:23:34,971 [Thread-493] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 33327
2020-12-03 07:23:34,972 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:34,972 [Thread-493] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 38866
2020-12-03 07:23:34,972 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:34,973 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:34,973 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:34,974 [Thread-493] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreCacheUpdateService is shutting down
2020-12-03 07:23:34,974 [Thread-493] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreCacheUpdateService
2020-12-03 07:23:34,974 [Thread-493] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreConnectionMonitorService is shutting down
2020-12-03 07:23:34,975 [Thread-493] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreConnectionMonitorService
2020-12-03 07:23:35,956 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 7a5505b8915a:44401: State Store unavailable
2020-12-03 07:23:35,958 [Thread-494] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - RouterHeartbeatService is shutting down
2020-12-03 07:23:35,958 [Thread-494] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service RouterHeartbeatService
2020-12-03 07:23:35,958 [Thread-494] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn1 is shutting down
2020-12-03 07:23:35,958 [Thread-494] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn1
2020-12-03 07:23:35,959 [Thread-494] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn0 is shutting down
2020-12-03 07:23:35,959 [Thread-494] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn0
2020-12-03 07:23:35,960 [Thread-494] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn1 is shutting down
2020-12-03 07:23:35,960 [Thread-494] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn1
2020-12-03 07:23:35,960 [Thread-494] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn0 is shutting down
2020-12-03 07:23:35,960 [Thread-494] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn0
2020-12-03 07:23:35,962 [Thread-494] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@514cd540{/,null,UNAVAILABLE}{/router}
2020-12-03 07:23:35,964 [Thread-494] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@11d4dbd6{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2020-12-03 07:23:35,971 [Thread-494] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1bf39d06{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:35,972 [Thread-494] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@713064e8{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:23:35,973 [Thread-494] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 39019
2020-12-03 07:23:35,973 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:35,973 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:35,974 [Thread-494] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 44401
2020-12-03 07:23:35,975 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:35,976 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:35,977 [Thread-494] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreCacheUpdateService is shutting down
2020-12-03 07:23:35,977 [Thread-494] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreCacheUpdateService
2020-12-03 07:23:35,978 [Thread-494] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreConnectionMonitorService is shutting down
2020-12-03 07:23:35,978 [Thread-494] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreConnectionMonitorService
msx-rc 0
