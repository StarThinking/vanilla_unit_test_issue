2020-12-03 07:23:16,873 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=4, numDataNodes=4
2020-12-03 07:23:16,911 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:initMiniDFSCluster(875)) - MiniDFSCluster disabling checkpointing in the Standby node since no HTTP ports have been specified.
2020-12-03 07:23:16,912 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:initMiniDFSCluster(881)) - MiniDFSCluster disabling log-roll triggering in the Standby node since no IPC ports have been specified.
Formatting using clusterid: testClusterID
2020-12-03 07:23:17,599 [JUnit] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:23:17,616 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:23:17,617 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:23:17,618 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:23:17,626 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:23:17,627 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:23:17,627 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:23:17,632 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns0
2020-12-03 07:23:17,632 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: true
2020-12-03 07:23:17,694 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:17,699 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2020-12-03 07:23:17,700 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:23:17,700 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:23:17,708 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:23:17,709 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:23:17
2020-12-03 07:23:17,711 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:23:17,711 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:17,713 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-12-03 07:23:17,714 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:23:17,735 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:23:17,735 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:23:17,744 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:23:17,744 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:23:17,745 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:23:17,745 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:23:17,746 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:23:17,746 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:23:17,746 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:23:17,747 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:23:17,747 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:23:17,747 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:23:17,748 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:23:17,781 [JUnit] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GLOBAL serial map: bits=29 maxEntries=536870911
2020-12-03 07:23:17,781 [JUnit] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - USER serial map: bits=24 maxEntries=16777215
2020-12-03 07:23:17,781 [JUnit] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GROUP serial map: bits=24 maxEntries=16777215
2020-12-03 07:23:17,782 [JUnit] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - XATTR serial map: bits=24 maxEntries=16777215
2020-12-03 07:23:17,800 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:23:17,801 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:17,801 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-12-03 07:23:17,801 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:23:17,808 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:23:17,808 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:23:17,808 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:23:17,809 [JUnit] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:23:17,815 [JUnit] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:23:17,817 [JUnit] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:23:17,823 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:23:17,823 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:17,824 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-12-03 07:23:17,824 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:23:17,835 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:23:17,835 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:23:17,835 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:23:17,840 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:23:17,841 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:23:17,843 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:23:17,844 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:17,844 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-12-03 07:23:17,844 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:23:17,880 [JUnit] INFO  namenode.FSImage (FSImage.java:format(185)) - Allocated new BlockPoolId: BP-364049187-172.17.0.4-1606980197868
2020-12-03 07:23:18,022 [JUnit] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-12-03 07:23:18,164 [JUnit] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-12-03 07:23:18,257 [JUnit] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-0-through-1 has been successfully formatted.
2020-12-03 07:23:18,293 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:23:18,293 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:23:18,459 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:23:18,459 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:23:18,513 [JUnit] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-12-03 07:23:18,594 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:copyNameDirs(1264)) - Copying namedir from primary node dir file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1 to file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-3
2020-12-03 07:23:18,618 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:copyNameDirs(1264)) - Copying namedir from primary node dir file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1 to file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-4
2020-12-03 07:23:18,625 [JUnit] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:23:18,844 [JUnit] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-namenode.properties,hadoop-metrics2.properties
2020-12-03 07:23:18,945 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2020-12-03 07:23:18,945 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:23:18,954 [JUnit] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://ns0
2020-12-03 07:23:18,955 [JUnit] INFO  namenode.NameNode (NameNode.java:<init>(944)) - Clients should use ns0 to access this namenode/service.
2020-12-03 07:23:19,007 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@239105a8] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:19,022 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:23:19,041 [JUnit] INFO  util.log (Log.java:initialized(192)) - Logging initialized @3083ms
2020-12-03 07:23:19,178 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:19,183 [JUnit] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:23:19,195 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:19,197 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:23:19,197 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:19,198 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:19,226 [JUnit] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:23:19,227 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:23:19,237 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 42523
2020-12-03 07:23:19,239 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:19,281 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@78d6692f{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:23:19,283 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@27216cd{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:23:19,606 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@71529963{/,file:///tmp/jetty-localhost-42523-hdfs-_-any-7441576961513140416.dir/webapp/,AVAILABLE}{/hdfs}
2020-12-03 07:23:19,616 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@73e3c5f2{HTTP/1.1,[http/1.1]}{localhost:42523}
2020-12-03 07:23:19,617 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @3659ms
2020-12-03 07:23:19,629 [JUnit] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:23:19,630 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:23:19,630 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:23:19,631 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:23:19,631 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:23:19,631 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:23:19,632 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:23:19,633 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns0
2020-12-03 07:23:19,633 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: true
2020-12-03 07:23:19,634 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:19,635 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:23:19,635 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:23:19,636 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:23:19,637 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:23:19
2020-12-03 07:23:19,637 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:23:19,638 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:19,638 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:23:19,638 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:23:19,645 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:23:19,645 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:23:19,646 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:23:19,646 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:23:19,647 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:23:19,647 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:23:19,647 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:23:19,648 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:23:19,648 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:23:19,648 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:23:19,648 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:23:19,649 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:23:19,649 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:23:19,650 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:23:19,650 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:19,650 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:23:19,651 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:23:19,653 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:23:19,654 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:23:19,654 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:23:19,654 [JUnit] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:23:19,655 [JUnit] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:23:19,655 [JUnit] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:23:19,655 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:23:19,655 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:19,656 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:23:19,656 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:23:19,658 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:23:19,659 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:23:19,659 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:23:19,660 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:23:19,660 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:23:19,660 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:23:19,661 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:19,661 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:23:19,661 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:23:19,732 [JUnit] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 9751@aa329fbd28a4
2020-12-03 07:23:19,798 [JUnit] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 9751@aa329fbd28a4
2020-12-03 07:23:19,799 [JUnit] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-0-through-1
2020-12-03 07:23:19,804 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:23:19,804 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:23:19,844 [JUnit] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:23:19,852 [JUnit] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:23:19,852 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-12-03 07:23:19,857 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2020-12-03 07:23:19,858 [JUnit] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:23:19,858 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 192 msecs
2020-12-03 07:23:20,065 [JUnit] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to 0.0.0.0:0
2020-12-03 07:23:20,122 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:20,139 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:20,514 [Listener at 0.0.0.0/37672] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:23:20,539 [Listener at 0.0.0.0/37672] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:23:20,554 [Listener at 0.0.0.0/37672] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:23:20,555 [Listener at 0.0.0.0/37672] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:23:20,555 [Listener at 0.0.0.0/37672] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:23:20,593 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:20,593 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:20,597 [Listener at 0.0.0.0/37672] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:37672
2020-12-03 07:23:20,599 [Listener at 0.0.0.0/37672] INFO  namenode.FSNamesystem (FSNamesystem.java:startStandbyServices(1391)) - Starting services required for standby state
2020-12-03 07:23:20,601 [Listener at 0.0.0.0/37672] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.log-roll.period(-1) assuming SECONDS
2020-12-03 07:23:20,601 [Listener at 0.0.0.0/37672] INFO  ha.EditLogTailer (EditLogTailer.java:<init>(208)) - Not going to trigger log rolls on active node because dfs.ha.log-roll.period is negative.
2020-12-03 07:23:20,602 [Listener at 0.0.0.0/37672] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.period.backoff-max(0) assuming SECONDS
2020-12-03 07:23:20,602 [Listener at 0.0.0.0/37672] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.rolledits.timeout(60) assuming SECONDS
2020-12-03 07:23:20,605 [Listener at 0.0.0.0/37672] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:23:20,606 [Listener at 0.0.0.0/37672] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-12-03 07:23:20,606 [Listener at 0.0.0.0/37672] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://ns0
2020-12-03 07:23:20,607 [Listener at 0.0.0.0/37672] INFO  namenode.NameNode (NameNode.java:<init>(944)) - Clients should use ns0 to access this namenode/service.
2020-12-03 07:23:20,617 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@15bcf458] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:20,617 [Listener at 0.0.0.0/37672] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:23:20,620 [Listener at 0.0.0.0/37672] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:20,621 [Listener at 0.0.0.0/37672] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:23:20,623 [Listener at 0.0.0.0/37672] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:20,624 [Listener at 0.0.0.0/37672] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:23:20,625 [Listener at 0.0.0.0/37672] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:20,625 [Listener at 0.0.0.0/37672] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:20,628 [Listener at 0.0.0.0/37672] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:23:20,628 [Listener at 0.0.0.0/37672] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:23:20,629 [Listener at 0.0.0.0/37672] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 34569
2020-12-03 07:23:20,630 [Listener at 0.0.0.0/37672] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:20,634 [Listener at 0.0.0.0/37672] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@14bb2297{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:23:20,635 [Listener at 0.0.0.0/37672] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@797501a{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:23:21,067 [Listener at 0.0.0.0/37672] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7544a1e4{/,file:///tmp/jetty-localhost-34569-hdfs-_-any-5488281314895463089.dir/webapp/,AVAILABLE}{/hdfs}
2020-12-03 07:23:21,070 [Listener at 0.0.0.0/37672] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@70e0accd{HTTP/1.1,[http/1.1]}{localhost:34569}
2020-12-03 07:23:21,074 [Listener at 0.0.0.0/37672] INFO  server.Server (Server.java:doStart(419)) - Started @5113ms
2020-12-03 07:23:21,080 [Listener at 0.0.0.0/37672] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:23:21,081 [Listener at 0.0.0.0/37672] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:23:21,081 [Listener at 0.0.0.0/37672] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:23:21,082 [Listener at 0.0.0.0/37672] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:23:21,082 [Listener at 0.0.0.0/37672] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:23:21,082 [Listener at 0.0.0.0/37672] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:23:21,082 [Listener at 0.0.0.0/37672] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:23:21,083 [Listener at 0.0.0.0/37672] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns0
2020-12-03 07:23:21,083 [Listener at 0.0.0.0/37672] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: true
2020-12-03 07:23:21,084 [Listener at 0.0.0.0/37672] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:21,084 [Listener at 0.0.0.0/37672] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:23:21,084 [Listener at 0.0.0.0/37672] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:23:21,085 [Listener at 0.0.0.0/37672] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:23:21,085 [Listener at 0.0.0.0/37672] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:23:21
2020-12-03 07:23:21,085 [Listener at 0.0.0.0/37672] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:23:21,085 [Listener at 0.0.0.0/37672] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:21,086 [Listener at 0.0.0.0/37672] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:23:21,086 [Listener at 0.0.0.0/37672] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:23:21,099 [Listener at 0.0.0.0/37672] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:23:21,099 [Listener at 0.0.0.0/37672] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:23:21,100 [Listener at 0.0.0.0/37672] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:23:21,100 [Listener at 0.0.0.0/37672] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:23:21,100 [Listener at 0.0.0.0/37672] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:23:21,101 [Listener at 0.0.0.0/37672] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:23:21,101 [Listener at 0.0.0.0/37672] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:23:21,101 [Listener at 0.0.0.0/37672] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:23:21,101 [Listener at 0.0.0.0/37672] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:23:21,102 [Listener at 0.0.0.0/37672] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:23:21,102 [Listener at 0.0.0.0/37672] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:23:21,102 [Listener at 0.0.0.0/37672] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:23:21,102 [Listener at 0.0.0.0/37672] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:23:21,103 [Listener at 0.0.0.0/37672] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:23:21,103 [Listener at 0.0.0.0/37672] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:21,104 [Listener at 0.0.0.0/37672] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:23:21,104 [Listener at 0.0.0.0/37672] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:23:21,112 [Listener at 0.0.0.0/37672] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:23:21,112 [Listener at 0.0.0.0/37672] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:23:21,112 [Listener at 0.0.0.0/37672] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:23:21,112 [Listener at 0.0.0.0/37672] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:23:21,113 [Listener at 0.0.0.0/37672] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:23:21,113 [Listener at 0.0.0.0/37672] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:23:21,113 [Listener at 0.0.0.0/37672] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:23:21,113 [Listener at 0.0.0.0/37672] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:21,114 [Listener at 0.0.0.0/37672] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:23:21,114 [Listener at 0.0.0.0/37672] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:23:21,116 [Listener at 0.0.0.0/37672] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:23:21,116 [Listener at 0.0.0.0/37672] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:23:21,116 [Listener at 0.0.0.0/37672] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:23:21,117 [Listener at 0.0.0.0/37672] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:23:21,117 [Listener at 0.0.0.0/37672] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:23:21,117 [Listener at 0.0.0.0/37672] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:23:21,117 [Listener at 0.0.0.0/37672] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:21,117 [Listener at 0.0.0.0/37672] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:23:21,118 [Listener at 0.0.0.0/37672] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:23:21,289 [Listener at 0.0.0.0/37672] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-3/in_use.lock acquired by nodename 9751@aa329fbd28a4
2020-12-03 07:23:21,317 [Listener at 0.0.0.0/37672] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-4/in_use.lock acquired by nodename 9751@aa329fbd28a4
2020-12-03 07:23:21,318 [Listener at 0.0.0.0/37672] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-0-through-1
2020-12-03 07:23:21,323 [Listener at 0.0.0.0/37672] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:23:21,323 [Listener at 0.0.0.0/37672] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-3/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:23:21,328 [Listener at 0.0.0.0/37672] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:23:21,330 [Listener at 0.0.0.0/37672] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:23:21,330 [Listener at 0.0.0.0/37672] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-3/current/fsimage_0000000000000000000
2020-12-03 07:23:21,330 [Listener at 0.0.0.0/37672] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2020-12-03 07:23:21,331 [Listener at 0.0.0.0/37672] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:23:21,331 [Listener at 0.0.0.0/37672] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 211 msecs
2020-12-03 07:23:21,332 [Listener at 0.0.0.0/37672] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to 0.0.0.0:0
2020-12-03 07:23:21,333 [Listener at 0.0.0.0/37672] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:21,334 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:21,341 [Listener at 0.0.0.0/43715] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:23:21,367 [Listener at 0.0.0.0/43715] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:23:21,370 [Listener at 0.0.0.0/43715] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:23:21,371 [Listener at 0.0.0.0/43715] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:23:21,371 [Listener at 0.0.0.0/43715] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:23:21,378 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:21,378 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:21,385 [Listener at 0.0.0.0/43715] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:43715
2020-12-03 07:23:21,386 [Listener at 0.0.0.0/43715] INFO  namenode.FSNamesystem (FSNamesystem.java:startStandbyServices(1391)) - Starting services required for standby state
2020-12-03 07:23:21,386 [Listener at 0.0.0.0/43715] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.log-roll.period(-1) assuming SECONDS
2020-12-03 07:23:21,387 [Listener at 0.0.0.0/43715] INFO  ha.EditLogTailer (EditLogTailer.java:<init>(208)) - Not going to trigger log rolls on active node because dfs.ha.log-roll.period is negative.
2020-12-03 07:23:21,387 [Listener at 0.0.0.0/43715] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.period.backoff-max(0) assuming SECONDS
2020-12-03 07:23:21,387 [Listener at 0.0.0.0/43715] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.rolledits.timeout(60) assuming SECONDS
Formatting using clusterid: testClusterID
2020-12-03 07:23:21,394 [Listener at 0.0.0.0/43715] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:23:21,394 [Listener at 0.0.0.0/43715] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:23:21,395 [Listener at 0.0.0.0/43715] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:23:21,395 [Listener at 0.0.0.0/43715] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:23:21,398 [Listener at 0.0.0.0/43715] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:23:21,399 [Listener at 0.0.0.0/43715] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:23:21,399 [Listener at 0.0.0.0/43715] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:23:21,400 [Listener at 0.0.0.0/43715] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns1
2020-12-03 07:23:21,400 [Listener at 0.0.0.0/43715] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: true
2020-12-03 07:23:21,401 [Listener at 0.0.0.0/43715] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:21,401 [Listener at 0.0.0.0/43715] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:23:21,401 [Listener at 0.0.0.0/43715] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:23:21,402 [Listener at 0.0.0.0/43715] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:23:21,402 [Listener at 0.0.0.0/43715] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:23:21
2020-12-03 07:23:21,402 [Listener at 0.0.0.0/43715] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:23:21,402 [Listener at 0.0.0.0/43715] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:21,403 [Listener at 0.0.0.0/43715] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:23:21,403 [Listener at 0.0.0.0/43715] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:23:21,417 [Listener at 0.0.0.0/43715] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:23:21,418 [Listener at 0.0.0.0/43715] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:23:21,418 [Listener at 0.0.0.0/43715] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:23:21,418 [Listener at 0.0.0.0/43715] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:23:21,418 [Listener at 0.0.0.0/43715] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:23:21,419 [Listener at 0.0.0.0/43715] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:23:21,419 [Listener at 0.0.0.0/43715] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:23:21,419 [Listener at 0.0.0.0/43715] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:23:21,419 [Listener at 0.0.0.0/43715] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:23:21,419 [Listener at 0.0.0.0/43715] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:23:21,420 [Listener at 0.0.0.0/43715] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:23:21,420 [Listener at 0.0.0.0/43715] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:23:21,420 [Listener at 0.0.0.0/43715] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:23:21,421 [Listener at 0.0.0.0/43715] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:23:21,421 [Listener at 0.0.0.0/43715] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:21,421 [Listener at 0.0.0.0/43715] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:23:21,422 [Listener at 0.0.0.0/43715] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:23:21,428 [Listener at 0.0.0.0/43715] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:23:21,429 [Listener at 0.0.0.0/43715] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:23:21,429 [Listener at 0.0.0.0/43715] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:23:21,429 [Listener at 0.0.0.0/43715] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:23:21,429 [Listener at 0.0.0.0/43715] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:23:21,430 [Listener at 0.0.0.0/43715] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:23:21,430 [Listener at 0.0.0.0/43715] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:23:21,430 [Listener at 0.0.0.0/43715] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:21,431 [Listener at 0.0.0.0/43715] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:23:21,431 [Listener at 0.0.0.0/43715] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:23:21,433 [Listener at 0.0.0.0/43715] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:23:21,433 [Listener at 0.0.0.0/43715] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:23:21,433 [Listener at 0.0.0.0/43715] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:23:21,434 [Listener at 0.0.0.0/43715] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:23:21,434 [Listener at 0.0.0.0/43715] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:23:21,434 [Listener at 0.0.0.0/43715] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:23:21,434 [Listener at 0.0.0.0/43715] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:21,435 [Listener at 0.0.0.0/43715] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:23:21,435 [Listener at 0.0.0.0/43715] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:23:21,438 [Listener at 0.0.0.0/43715] INFO  namenode.FSImage (FSImage.java:format(185)) - Allocated new BlockPoolId: BP-339648640-172.17.0.4-1606980201438
2020-12-03 07:23:21,513 [Listener at 0.0.0.0/43715] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5 has been successfully formatted.
2020-12-03 07:23:21,573 [Listener at 0.0.0.0/43715] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6 has been successfully formatted.
2020-12-03 07:23:21,640 [Listener at 0.0.0.0/43715] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-2-through-3 has been successfully formatted.
2020-12-03 07:23:21,658 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:23:21,658 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:23:21,667 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/current/fsimage.ckpt_0000000000000000000 of size 396 bytes saved in 0 seconds .
2020-12-03 07:23:21,667 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6/current/fsimage.ckpt_0000000000000000000 of size 396 bytes saved in 0 seconds .
2020-12-03 07:23:21,733 [Listener at 0.0.0.0/43715] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-12-03 07:23:21,737 [Listener at 0.0.0.0/43715] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:copyNameDirs(1264)) - Copying namedir from primary node dir file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5 to file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-7
2020-12-03 07:23:21,742 [Listener at 0.0.0.0/43715] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:copyNameDirs(1264)) - Copying namedir from primary node dir file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5 to file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-8
2020-12-03 07:23:21,750 [Listener at 0.0.0.0/43715] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:23:21,750 [Listener at 0.0.0.0/43715] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-12-03 07:23:21,751 [Listener at 0.0.0.0/43715] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://ns0
2020-12-03 07:23:21,752 [Listener at 0.0.0.0/43715] INFO  namenode.NameNode (NameNode.java:<init>(944)) - Clients should use ns1 to access this namenode/service.
2020-12-03 07:23:21,761 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1a6f5124] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:21,762 [Listener at 0.0.0.0/43715] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:23:21,765 [Listener at 0.0.0.0/43715] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:21,766 [Listener at 0.0.0.0/43715] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:23:21,768 [Listener at 0.0.0.0/43715] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:21,769 [Listener at 0.0.0.0/43715] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:23:21,769 [Listener at 0.0.0.0/43715] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:21,769 [Listener at 0.0.0.0/43715] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:21,771 [Listener at 0.0.0.0/43715] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:23:21,771 [Listener at 0.0.0.0/43715] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:23:21,772 [Listener at 0.0.0.0/43715] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 33934
2020-12-03 07:23:21,772 [Listener at 0.0.0.0/43715] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:21,794 [Listener at 0.0.0.0/43715] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@32f61a31{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:23:21,795 [Listener at 0.0.0.0/43715] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@669253b7{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:23:22,028 [Listener at 0.0.0.0/43715] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@581d969c{/,file:///tmp/jetty-localhost-33934-hdfs-_-any-788567084399565747.dir/webapp/,AVAILABLE}{/hdfs}
2020-12-03 07:23:22,031 [Listener at 0.0.0.0/43715] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@22db8f4{HTTP/1.1,[http/1.1]}{localhost:33934}
2020-12-03 07:23:22,032 [Listener at 0.0.0.0/43715] INFO  server.Server (Server.java:doStart(419)) - Started @6074ms
2020-12-03 07:23:22,036 [Listener at 0.0.0.0/43715] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:23:22,038 [Listener at 0.0.0.0/43715] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:23:22,038 [Listener at 0.0.0.0/43715] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:23:22,038 [Listener at 0.0.0.0/43715] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:23:22,039 [Listener at 0.0.0.0/43715] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:23:22,039 [Listener at 0.0.0.0/43715] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:23:22,040 [Listener at 0.0.0.0/43715] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:23:22,041 [Listener at 0.0.0.0/43715] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns1
2020-12-03 07:23:22,041 [Listener at 0.0.0.0/43715] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: true
2020-12-03 07:23:22,043 [Listener at 0.0.0.0/43715] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:22,056 [Listener at 0.0.0.0/43715] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:23:22,057 [Listener at 0.0.0.0/43715] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:23:22,057 [Listener at 0.0.0.0/43715] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:23:22,058 [Listener at 0.0.0.0/43715] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:23:22
2020-12-03 07:23:22,058 [Listener at 0.0.0.0/43715] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:23:22,058 [Listener at 0.0.0.0/43715] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:22,063 [Listener at 0.0.0.0/43715] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:23:22,064 [Listener at 0.0.0.0/43715] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:23:22,081 [Listener at 0.0.0.0/43715] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:23:22,087 [Listener at 0.0.0.0/43715] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:23:22,088 [Listener at 0.0.0.0/43715] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:23:22,089 [Listener at 0.0.0.0/43715] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:23:22,089 [Listener at 0.0.0.0/43715] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:23:22,089 [Listener at 0.0.0.0/43715] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:23:22,094 [Listener at 0.0.0.0/43715] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:23:22,094 [Listener at 0.0.0.0/43715] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:23:22,094 [Listener at 0.0.0.0/43715] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:23:22,095 [Listener at 0.0.0.0/43715] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:23:22,095 [Listener at 0.0.0.0/43715] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:23:22,095 [Listener at 0.0.0.0/43715] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:23:22,095 [Listener at 0.0.0.0/43715] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:23:22,097 [Listener at 0.0.0.0/43715] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:23:22,098 [Listener at 0.0.0.0/43715] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:22,098 [Listener at 0.0.0.0/43715] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:23:22,098 [Listener at 0.0.0.0/43715] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:23:22,115 [Listener at 0.0.0.0/43715] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:23:22,115 [Listener at 0.0.0.0/43715] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:23:22,115 [Listener at 0.0.0.0/43715] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:23:22,115 [Listener at 0.0.0.0/43715] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:23:22,116 [Listener at 0.0.0.0/43715] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:23:22,116 [Listener at 0.0.0.0/43715] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:23:22,116 [Listener at 0.0.0.0/43715] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:23:22,116 [Listener at 0.0.0.0/43715] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:22,117 [Listener at 0.0.0.0/43715] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:23:22,117 [Listener at 0.0.0.0/43715] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:23:22,120 [Listener at 0.0.0.0/43715] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:23:22,120 [Listener at 0.0.0.0/43715] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:23:22,120 [Listener at 0.0.0.0/43715] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:23:22,121 [Listener at 0.0.0.0/43715] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:23:22,121 [Listener at 0.0.0.0/43715] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:23:22,121 [Listener at 0.0.0.0/43715] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:23:22,121 [Listener at 0.0.0.0/43715] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:22,122 [Listener at 0.0.0.0/43715] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:23:22,122 [Listener at 0.0.0.0/43715] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:23:22,159 [Listener at 0.0.0.0/43715] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/in_use.lock acquired by nodename 9751@aa329fbd28a4
2020-12-03 07:23:22,255 [Listener at 0.0.0.0/43715] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6/in_use.lock acquired by nodename 9751@aa329fbd28a4
2020-12-03 07:23:22,256 [Listener at 0.0.0.0/43715] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-2-through-3
2020-12-03 07:23:22,261 [Listener at 0.0.0.0/43715] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:23:22,261 [Listener at 0.0.0.0/43715] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:23:22,265 [Listener at 0.0.0.0/43715] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:23:22,267 [Listener at 0.0.0.0/43715] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:23:22,267 [Listener at 0.0.0.0/43715] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/current/fsimage_0000000000000000000
2020-12-03 07:23:22,267 [Listener at 0.0.0.0/43715] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2020-12-03 07:23:22,268 [Listener at 0.0.0.0/43715] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:23:22,268 [Listener at 0.0.0.0/43715] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 143 msecs
2020-12-03 07:23:22,269 [Listener at 0.0.0.0/43715] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to 0.0.0.0:0
2020-12-03 07:23:22,270 [Listener at 0.0.0.0/43715] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:22,271 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:22,278 [Listener at 0.0.0.0/46572] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:23:22,301 [Listener at 0.0.0.0/46572] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:23:22,303 [Listener at 0.0.0.0/46572] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:23:22,304 [Listener at 0.0.0.0/46572] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:23:22,304 [Listener at 0.0.0.0/46572] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:23:22,309 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:22,309 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:22,313 [Listener at 0.0.0.0/46572] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:46572
2020-12-03 07:23:22,314 [Listener at 0.0.0.0/46572] INFO  namenode.FSNamesystem (FSNamesystem.java:startStandbyServices(1391)) - Starting services required for standby state
2020-12-03 07:23:22,314 [Listener at 0.0.0.0/46572] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.log-roll.period(-1) assuming SECONDS
2020-12-03 07:23:22,314 [Listener at 0.0.0.0/46572] INFO  ha.EditLogTailer (EditLogTailer.java:<init>(208)) - Not going to trigger log rolls on active node because dfs.ha.log-roll.period is negative.
2020-12-03 07:23:22,314 [Listener at 0.0.0.0/46572] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.period.backoff-max(0) assuming SECONDS
2020-12-03 07:23:22,314 [Listener at 0.0.0.0/46572] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.rolledits.timeout(60) assuming SECONDS
2020-12-03 07:23:22,321 [Listener at 0.0.0.0/46572] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:23:22,321 [Listener at 0.0.0.0/46572] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-12-03 07:23:22,322 [Listener at 0.0.0.0/46572] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://ns0
2020-12-03 07:23:22,322 [Listener at 0.0.0.0/46572] INFO  namenode.NameNode (NameNode.java:<init>(944)) - Clients should use ns1 to access this namenode/service.
2020-12-03 07:23:22,337 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@28c0b664] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:22,338 [Listener at 0.0.0.0/46572] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:23:22,341 [Listener at 0.0.0.0/46572] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:22,343 [Listener at 0.0.0.0/46572] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:23:22,346 [Listener at 0.0.0.0/46572] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:22,347 [Listener at 0.0.0.0/46572] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:23:22,347 [Listener at 0.0.0.0/46572] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:22,348 [Listener at 0.0.0.0/46572] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:22,350 [Listener at 0.0.0.0/46572] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:23:22,350 [Listener at 0.0.0.0/46572] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:23:22,351 [Listener at 0.0.0.0/46572] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 41423
2020-12-03 07:23:22,352 [Listener at 0.0.0.0/46572] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:22,355 [Listener at 0.0.0.0/46572] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6d1310f6{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:23:22,356 [Listener at 0.0.0.0/46572] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@54e7391d{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:23:22,558 [Listener at 0.0.0.0/46572] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1dfd5f51{/,file:///tmp/jetty-localhost-41423-hdfs-_-any-6451283240678575350.dir/webapp/,AVAILABLE}{/hdfs}
2020-12-03 07:23:22,560 [Listener at 0.0.0.0/46572] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3c321bdb{HTTP/1.1,[http/1.1]}{localhost:41423}
2020-12-03 07:23:22,560 [Listener at 0.0.0.0/46572] INFO  server.Server (Server.java:doStart(419)) - Started @6602ms
2020-12-03 07:23:22,572 [Listener at 0.0.0.0/46572] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:23:22,580 [Listener at 0.0.0.0/46572] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:23:22,580 [Listener at 0.0.0.0/46572] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:23:22,581 [Listener at 0.0.0.0/46572] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:23:22,581 [Listener at 0.0.0.0/46572] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:23:22,581 [Listener at 0.0.0.0/46572] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:23:22,582 [Listener at 0.0.0.0/46572] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:23:22,583 [Listener at 0.0.0.0/46572] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: ns1
2020-12-03 07:23:22,583 [Listener at 0.0.0.0/46572] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: true
2020-12-03 07:23:22,584 [Listener at 0.0.0.0/46572] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:22,584 [Listener at 0.0.0.0/46572] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:23:22,585 [Listener at 0.0.0.0/46572] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:23:22,585 [Listener at 0.0.0.0/46572] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:23:22,586 [Listener at 0.0.0.0/46572] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:23:22
2020-12-03 07:23:22,586 [Listener at 0.0.0.0/46572] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:23:22,587 [Listener at 0.0.0.0/46572] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:22,587 [Listener at 0.0.0.0/46572] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:23:22,587 [Listener at 0.0.0.0/46572] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:23:22,603 [Listener at 0.0.0.0/46572] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:23:22,603 [Listener at 0.0.0.0/46572] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:23:22,604 [Listener at 0.0.0.0/46572] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:23:22,604 [Listener at 0.0.0.0/46572] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:23:22,604 [Listener at 0.0.0.0/46572] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:23:22,605 [Listener at 0.0.0.0/46572] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:23:22,605 [Listener at 0.0.0.0/46572] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:23:22,605 [Listener at 0.0.0.0/46572] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:23:22,605 [Listener at 0.0.0.0/46572] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:23:22,605 [Listener at 0.0.0.0/46572] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:23:22,606 [Listener at 0.0.0.0/46572] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:23:22,606 [Listener at 0.0.0.0/46572] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:23:22,606 [Listener at 0.0.0.0/46572] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:23:22,607 [Listener at 0.0.0.0/46572] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:23:22,607 [Listener at 0.0.0.0/46572] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:22,607 [Listener at 0.0.0.0/46572] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:23:22,608 [Listener at 0.0.0.0/46572] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:23:22,614 [Listener at 0.0.0.0/46572] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:23:22,614 [Listener at 0.0.0.0/46572] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:23:22,615 [Listener at 0.0.0.0/46572] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:23:22,615 [Listener at 0.0.0.0/46572] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:23:22,615 [Listener at 0.0.0.0/46572] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:23:22,615 [Listener at 0.0.0.0/46572] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:23:22,615 [Listener at 0.0.0.0/46572] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:23:22,615 [Listener at 0.0.0.0/46572] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:22,616 [Listener at 0.0.0.0/46572] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:23:22,616 [Listener at 0.0.0.0/46572] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:23:22,618 [Listener at 0.0.0.0/46572] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:23:22,618 [Listener at 0.0.0.0/46572] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:23:22,618 [Listener at 0.0.0.0/46572] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:23:22,618 [Listener at 0.0.0.0/46572] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:23:22,619 [Listener at 0.0.0.0/46572] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:23:22,619 [Listener at 0.0.0.0/46572] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:23:22,619 [Listener at 0.0.0.0/46572] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:23:22,619 [Listener at 0.0.0.0/46572] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:23:22,620 [Listener at 0.0.0.0/46572] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:23:22,690 [Listener at 0.0.0.0/46572] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-7/in_use.lock acquired by nodename 9751@aa329fbd28a4
2020-12-03 07:23:22,763 [Listener at 0.0.0.0/46572] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-8/in_use.lock acquired by nodename 9751@aa329fbd28a4
2020-12-03 07:23:22,763 [Listener at 0.0.0.0/46572] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-2-through-3
2020-12-03 07:23:22,767 [Listener at 0.0.0.0/46572] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:23:22,767 [Listener at 0.0.0.0/46572] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-7/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:23:22,769 [Listener at 0.0.0.0/46572] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:23:22,770 [Listener at 0.0.0.0/46572] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:23:22,770 [Listener at 0.0.0.0/46572] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-7/current/fsimage_0000000000000000000
2020-12-03 07:23:22,771 [Listener at 0.0.0.0/46572] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2020-12-03 07:23:22,771 [Listener at 0.0.0.0/46572] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:23:22,771 [Listener at 0.0.0.0/46572] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 150 msecs
2020-12-03 07:23:22,772 [Listener at 0.0.0.0/46572] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to 0.0.0.0:0
2020-12-03 07:23:22,772 [Listener at 0.0.0.0/46572] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:22,773 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:22,780 [Listener at 0.0.0.0/46481] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:23:23,015 [Listener at 0.0.0.0/46481] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:23:23,018 [Listener at 0.0.0.0/46481] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:23:23,018 [Listener at 0.0.0.0/46481] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:23:23,019 [Listener at 0.0.0.0/46481] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:23:23,024 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:23,024 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:23,031 [Listener at 0.0.0.0/46481] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:46481
2020-12-03 07:23:23,031 [Listener at 0.0.0.0/46481] INFO  namenode.FSNamesystem (FSNamesystem.java:startStandbyServices(1391)) - Starting services required for standby state
2020-12-03 07:23:23,031 [Listener at 0.0.0.0/46481] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.log-roll.period(-1) assuming SECONDS
2020-12-03 07:23:23,031 [Listener at 0.0.0.0/46481] INFO  ha.EditLogTailer (EditLogTailer.java:<init>(208)) - Not going to trigger log rolls on active node because dfs.ha.log-roll.period is negative.
2020-12-03 07:23:23,032 [Listener at 0.0.0.0/46481] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.period.backoff-max(0) assuming SECONDS
2020-12-03 07:23:23,032 [Listener at 0.0.0.0/46481] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.rolledits.timeout(60) assuming SECONDS
2020-12-03 07:23:23,048 [Listener at 0.0.0.0/46481] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-12-03 07:23:23,074 [Listener at 0.0.0.0/46481] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-12-03 07:23:23,093 [Listener at 0.0.0.0/46481] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-12-03 07:23:23,097 [Listener at 0.0.0.0/46481] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:23:23,103 [Listener at 0.0.0.0/46481] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:23,107 [Listener at 0.0.0.0/46481] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:23:23,112 [Listener at 0.0.0.0/46481] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:23:23,114 [Listener at 0.0.0.0/46481] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:23,118 [Listener at 0.0.0.0/46481] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:23:23,129 [Listener at 0.0.0.0/46481] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:36468
2020-12-03 07:23:23,132 [Listener at 0.0.0.0/46481] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:23:23,132 [Listener at 0.0.0.0/46481] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:23:23,160 [Listener at 0.0.0.0/46481] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:23,173 [Listener at 0.0.0.0/46481] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:23:23,179 [Listener at 0.0.0.0/46481] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:23,180 [Listener at 0.0.0.0/46481] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:23:23,181 [Listener at 0.0.0.0/46481] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:23,181 [Listener at 0.0.0.0/46481] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:23,186 [Listener at 0.0.0.0/46481] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 36148
2020-12-03 07:23:23,187 [Listener at 0.0.0.0/46481] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:23,190 [Listener at 0.0.0.0/46481] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2472c7d8{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:23:23,191 [Listener at 0.0.0.0/46481] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@22175d4f{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:23:23,394 [Listener at 0.0.0.0/46481] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@38600b{/,file:///tmp/jetty-localhost-36148-datanode-_-any-836848537570497421.dir/webapp/,AVAILABLE}{/datanode}
2020-12-03 07:23:23,395 [Listener at 0.0.0.0/46481] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@669d2b1b{HTTP/1.1,[http/1.1]}{localhost:36148}
2020-12-03 07:23:23,397 [Listener at 0.0.0.0/46481] INFO  server.Server (Server.java:doStart(419)) - Started @7439ms
2020-12-03 07:23:24,140 [Listener at 0.0.0.0/46481] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:36258
2020-12-03 07:23:24,164 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1f12e153] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:24,166 [Listener at 0.0.0.0/46481] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:23:24,166 [Listener at 0.0.0.0/46481] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:23:24,189 [Listener at 0.0.0.0/46481] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:24,190 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:24,216 [Listener at localhost/39779] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:39779
2020-12-03 07:23:24,242 [Listener at localhost/39779] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns0,ns1
2020-12-03 07:23:24,244 [Listener at localhost/39779] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns0,ns1
2020-12-03 07:23:24,259 [Thread-156] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37672 starting to offer service
2020-12-03 07:23:24,259 [Thread-159] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46481 starting to offer service
2020-12-03 07:23:24,259 [Thread-158] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46572 starting to offer service
2020-12-03 07:23:24,259 [Thread-157] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43715 starting to offer service
2020-12-03 07:23:24,274 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:24,274 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:24,292 [Listener at localhost/39779] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-12-03 07:23:24,294 [Listener at localhost/39779] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-12-03 07:23:24,295 [Listener at localhost/39779] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-12-03 07:23:24,297 [Listener at localhost/39779] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:23:24,298 [Listener at localhost/39779] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:24,299 [Listener at localhost/39779] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:23:24,299 [Listener at localhost/39779] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:23:24,300 [Listener at localhost/39779] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:24,300 [Listener at localhost/39779] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:23:24,301 [Listener at localhost/39779] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:34145
2020-12-03 07:23:24,301 [Listener at localhost/39779] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:23:24,301 [Listener at localhost/39779] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:23:24,306 [Listener at localhost/39779] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:24,308 [Listener at localhost/39779] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:23:24,311 [Listener at localhost/39779] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:24,314 [Listener at localhost/39779] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:23:24,314 [Listener at localhost/39779] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:24,315 [Listener at localhost/39779] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:24,316 [Listener at localhost/39779] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 45870
2020-12-03 07:23:24,316 [Listener at localhost/39779] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:24,352 [Listener at localhost/39779] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2e3a5237{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:23:24,361 [Listener at localhost/39779] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6ac97b84{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:23:24,633 [Listener at localhost/39779] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5cbb84b1{/,file:///tmp/jetty-localhost-45870-datanode-_-any-5159731669941799216.dir/webapp/,AVAILABLE}{/datanode}
2020-12-03 07:23:24,634 [Listener at localhost/39779] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2c779e5{HTTP/1.1,[http/1.1]}{localhost:45870}
2020-12-03 07:23:24,634 [Listener at localhost/39779] INFO  server.Server (Server.java:doStart(419)) - Started @8676ms
2020-12-03 07:23:24,741 [Thread-156] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:23:24,762 [Listener at localhost/39779] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:37346
2020-12-03 07:23:24,763 [Listener at localhost/39779] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:23:24,764 [Listener at localhost/39779] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:23:24,763 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5183d589] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:24,764 [Listener at localhost/39779] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:24,766 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:24,772 [Listener at localhost/36168] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:36168
2020-12-03 07:23:24,784 [Listener at localhost/36168] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns0,ns1
2020-12-03 07:23:24,785 [Listener at localhost/36168] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns0,ns1
2020-12-03 07:23:24,786 [Thread-185] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37672 starting to offer service
2020-12-03 07:23:24,786 [Thread-186] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43715 starting to offer service
2020-12-03 07:23:24,792 [Thread-156] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 9751@aa329fbd28a4
2020-12-03 07:23:24,796 [Thread-188] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46481 starting to offer service
2020-12-03 07:23:24,797 [Thread-156] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1 is not formatted for namespace 819413304. Formatting...
2020-12-03 07:23:24,797 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:24,797 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:24,797 [Thread-187] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46572 starting to offer service
2020-12-03 07:23:24,804 [Thread-156] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-e38d9717-2172-454d-9795-4324f28c8bf6 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1 
2020-12-03 07:23:24,829 [Listener at localhost/36168] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-12-03 07:23:24,837 [Listener at localhost/36168] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-12-03 07:23:24,842 [Listener at localhost/36168] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-12-03 07:23:24,844 [Thread-186] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:23:24,854 [Listener at localhost/36168] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:23:24,855 [Listener at localhost/36168] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:24,855 [Listener at localhost/36168] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:23:24,856 [Listener at localhost/36168] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:23:24,856 [Listener at localhost/36168] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:24,857 [Listener at localhost/36168] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:23:24,857 [Listener at localhost/36168] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:40556
2020-12-03 07:23:24,858 [Listener at localhost/36168] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:23:24,858 [Listener at localhost/36168] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:23:24,862 [Listener at localhost/36168] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:24,863 [Listener at localhost/36168] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:23:24,866 [Listener at localhost/36168] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:24,868 [Listener at localhost/36168] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:23:24,868 [Listener at localhost/36168] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:24,868 [Listener at localhost/36168] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:24,870 [Listener at localhost/36168] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 44876
2020-12-03 07:23:24,870 [Listener at localhost/36168] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:24,877 [Listener at localhost/36168] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@588ffeb{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:23:24,878 [Listener at localhost/36168] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@baf1bb3{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:23:24,887 [Thread-186] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 9751@aa329fbd28a4
2020-12-03 07:23:24,888 [Thread-186] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3 is not formatted for namespace 819413304. Formatting...
2020-12-03 07:23:24,888 [Thread-186] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-764dc4eb-6996-475b-8f6e-ebef4cfc3e28 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3 
2020-12-03 07:23:25,004 [Thread-156] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 9751@aa329fbd28a4
2020-12-03 07:23:25,005 [Thread-156] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2 is not formatted for namespace 819413304. Formatting...
2020-12-03 07:23:25,005 [Thread-156] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-a79da8de-3edc-4788-ab8e-fc5b8e383ab7 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2 
2020-12-03 07:23:25,107 [Listener at localhost/36168] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@69cac930{/,file:///tmp/jetty-localhost-44876-datanode-_-any-2814948649990193280.dir/webapp/,AVAILABLE}{/datanode}
2020-12-03 07:23:25,108 [Listener at localhost/36168] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@19593091{HTTP/1.1,[http/1.1]}{localhost:44876}
2020-12-03 07:23:25,109 [Listener at localhost/36168] INFO  server.Server (Server.java:doStart(419)) - Started @9151ms
2020-12-03 07:23:25,116 [Thread-186] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 9751@aa329fbd28a4
2020-12-03 07:23:25,116 [Thread-186] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4 is not formatted for namespace 819413304. Formatting...
2020-12-03 07:23:25,117 [Thread-186] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-8efb34cb-f56a-46ed-b949-44b9d1babbf4 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4 
2020-12-03 07:23:25,131 [Listener at localhost/36168] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:37471
2020-12-03 07:23:25,131 [Listener at localhost/36168] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:23:25,131 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6ad6fa53] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:25,131 [Listener at localhost/36168] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:23:25,132 [Listener at localhost/36168] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:25,133 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:25,159 [Thread-156] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-364049187-172.17.0.4-1606980197868
2020-12-03 07:23:25,159 [Thread-156] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-364049187-172.17.0.4-1606980197868
2020-12-03 07:23:25,160 [Thread-156] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1 and block pool id BP-364049187-172.17.0.4-1606980197868 is not formatted. Formatting ...
2020-12-03 07:23:25,160 [Thread-156] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-364049187-172.17.0.4-1606980197868 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-364049187-172.17.0.4-1606980197868/current
2020-12-03 07:23:25,163 [Listener at localhost/35876] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:35876
2020-12-03 07:23:25,168 [Listener at localhost/35876] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns0,ns1
2020-12-03 07:23:25,169 [Listener at localhost/35876] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns0,ns1
2020-12-03 07:23:25,170 [Thread-210] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37672 starting to offer service
2020-12-03 07:23:25,170 [Thread-212] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46572 starting to offer service
2020-12-03 07:23:25,172 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:25,170 [Thread-213] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46481 starting to offer service
2020-12-03 07:23:25,172 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:25,170 [Thread-211] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43715 starting to offer service
2020-12-03 07:23:25,177 [Listener at localhost/35876] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 3 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-12-03 07:23:25,178 [Listener at localhost/35876] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7
2020-12-03 07:23:25,179 [Listener at localhost/35876] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-12-03 07:23:25,190 [Listener at localhost/35876] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:23:25,190 [Listener at localhost/35876] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:25,191 [Listener at localhost/35876] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:23:25,191 [Listener at localhost/35876] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:23:25,191 [Listener at localhost/35876] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:23:25,192 [Listener at localhost/35876] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:23:25,193 [Listener at localhost/35876] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:32817
2020-12-03 07:23:25,193 [Listener at localhost/35876] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:23:25,193 [Listener at localhost/35876] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:23:25,199 [Listener at localhost/35876] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:25,200 [Listener at localhost/35876] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:23:25,202 [Thread-210] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:23:25,203 [Listener at localhost/35876] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:25,204 [Listener at localhost/35876] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:23:25,204 [Listener at localhost/35876] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:25,204 [Listener at localhost/35876] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:25,205 [Listener at localhost/35876] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 46753
2020-12-03 07:23:25,205 [Listener at localhost/35876] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:25,207 [Listener at localhost/35876] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@25b865b5{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:23:25,207 [Listener at localhost/35876] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6872f9c8{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,AVAILABLE}
2020-12-03 07:23:25,212 [Thread-186] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-364049187-172.17.0.4-1606980197868
2020-12-03 07:23:25,213 [Thread-186] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-364049187-172.17.0.4-1606980197868
2020-12-03 07:23:25,213 [Thread-186] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3 and block pool id BP-364049187-172.17.0.4-1606980197868 is not formatted. Formatting ...
2020-12-03 07:23:25,213 [Thread-186] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-364049187-172.17.0.4-1606980197868 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-364049187-172.17.0.4-1606980197868/current
2020-12-03 07:23:25,261 [Thread-210] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 9751@aa329fbd28a4
2020-12-03 07:23:25,261 [Thread-210] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5 is not formatted for namespace 819413304. Formatting...
2020-12-03 07:23:25,262 [Thread-210] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-af989f10-524a-4fdf-bcbd-c3442592547a for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5 
2020-12-03 07:23:25,298 [Thread-156] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-364049187-172.17.0.4-1606980197868
2020-12-03 07:23:25,299 [Thread-156] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-364049187-172.17.0.4-1606980197868
2020-12-03 07:23:25,299 [Thread-156] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2 and block pool id BP-364049187-172.17.0.4-1606980197868 is not formatted. Formatting ...
2020-12-03 07:23:25,300 [Thread-156] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-364049187-172.17.0.4-1606980197868 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-364049187-172.17.0.4-1606980197868/current
2020-12-03 07:23:25,313 [Thread-186] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-364049187-172.17.0.4-1606980197868
2020-12-03 07:23:25,313 [Thread-186] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-364049187-172.17.0.4-1606980197868
2020-12-03 07:23:25,314 [Thread-186] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4 and block pool id BP-364049187-172.17.0.4-1606980197868 is not formatted. Formatting ...
2020-12-03 07:23:25,315 [Thread-186] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-364049187-172.17.0.4-1606980197868 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-364049187-172.17.0.4-1606980197868/current
2020-12-03 07:23:25,397 [Thread-156] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=819413304;bpid=BP-364049187-172.17.0.4-1606980197868;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=819413304;c=1606980197868;bpid=BP-364049187-172.17.0.4-1606980197868;dnuuid=null
2020-12-03 07:23:25,398 [Thread-159] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:23:25,398 [Thread-159] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1 has already been used.
2020-12-03 07:23:25,398 [Thread-159] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2 has already been used.
2020-12-03 07:23:25,410 [Thread-159] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-339648640-172.17.0.4-1606980201438
2020-12-03 07:23:25,410 [Thread-159] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-339648640-172.17.0.4-1606980201438
2020-12-03 07:23:25,411 [Thread-159] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1 and block pool id BP-339648640-172.17.0.4-1606980201438 is not formatted. Formatting ...
2020-12-03 07:23:25,411 [Thread-159] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-339648640-172.17.0.4-1606980201438 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-339648640-172.17.0.4-1606980201438/current
2020-12-03 07:23:25,429 [Thread-210] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 9751@aa329fbd28a4
2020-12-03 07:23:25,430 [Thread-210] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6 is not formatted for namespace 819413304. Formatting...
2020-12-03 07:23:25,430 [Thread-210] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-69da2731-18b4-472d-af70-d73a4d269712 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6 
2020-12-03 07:23:25,431 [Thread-186] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=819413304;bpid=BP-364049187-172.17.0.4-1606980197868;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=819413304;c=1606980197868;bpid=BP-364049187-172.17.0.4-1606980197868;dnuuid=null
2020-12-03 07:23:25,455 [Listener at localhost/35876] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6edc4161{/,file:///tmp/jetty-localhost-46753-datanode-_-any-6471525956187881901.dir/webapp/,AVAILABLE}{/datanode}
2020-12-03 07:23:25,461 [Listener at localhost/35876] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@5486887b{HTTP/1.1,[http/1.1]}{localhost:46753}
2020-12-03 07:23:25,461 [Listener at localhost/35876] INFO  server.Server (Server.java:doStart(419)) - Started @9503ms
2020-12-03 07:23:25,570 [Thread-159] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-339648640-172.17.0.4-1606980201438
2020-12-03 07:23:25,571 [Thread-159] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-339648640-172.17.0.4-1606980201438
2020-12-03 07:23:25,571 [Thread-159] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2 and block pool id BP-339648640-172.17.0.4-1606980201438 is not formatted. Formatting ...
2020-12-03 07:23:25,571 [Thread-159] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-339648640-172.17.0.4-1606980201438 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-339648640-172.17.0.4-1606980201438/current
2020-12-03 07:23:25,583 [Listener at localhost/35876] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:37472
2020-12-03 07:23:25,593 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1440c311] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:25,593 [Listener at localhost/35876] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:23:25,593 [Listener at localhost/35876] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:23:25,594 [Listener at localhost/35876] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:25,599 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:25,607 [Listener at localhost/45538] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:45538
2020-12-03 07:23:25,614 [Listener at localhost/45538] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns0,ns1
2020-12-03 07:23:25,615 [Listener at localhost/45538] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns0,ns1
2020-12-03 07:23:25,616 [Thread-186] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID f6670a8c-a905-4867-80f3-0620636ed3de
2020-12-03 07:23:25,623 [Thread-235] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37672 starting to offer service
2020-12-03 07:23:25,624 [Thread-236] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43715 starting to offer service
2020-12-03 07:23:25,647 [Thread-210] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-364049187-172.17.0.4-1606980197868
2020-12-03 07:23:25,641 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:25,641 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:25,676 [Thread-210] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-364049187-172.17.0.4-1606980197868
2020-12-03 07:23:25,677 [Thread-210] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5 and block pool id BP-364049187-172.17.0.4-1606980197868 is not formatted. Formatting ...
2020-12-03 07:23:25,677 [Thread-210] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-364049187-172.17.0.4-1606980197868 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-364049187-172.17.0.4-1606980197868/current
2020-12-03 07:23:25,640 [Thread-238] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46481 starting to offer service
2020-12-03 07:23:25,640 [Thread-237] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46572 starting to offer service
2020-12-03 07:23:25,701 [Thread-235] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:23:25,702 [Thread-159] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=249675482;bpid=BP-339648640-172.17.0.4-1606980201438;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=249675482;c=1606980201438;bpid=BP-339648640-172.17.0.4-1606980201438;dnuuid=f14979ca-3b14-42d2-8cb7-2d3c00ca4270
2020-12-03 07:23:25,759 [Thread-235] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/in_use.lock acquired by nodename 9751@aa329fbd28a4
2020-12-03 07:23:25,760 [Thread-235] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7 is not formatted for namespace 819413304. Formatting...
2020-12-03 07:23:25,760 [Thread-235] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-66f4b598-9e1f-40c2-953a-7cb1d43b2313 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7 
2020-12-03 07:23:25,827 [Thread-156] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID f14979ca-3b14-42d2-8cb7-2d3c00ca4270
2020-12-03 07:23:25,837 [Thread-210] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-364049187-172.17.0.4-1606980197868
2020-12-03 07:23:25,838 [Thread-210] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-364049187-172.17.0.4-1606980197868
2020-12-03 07:23:25,838 [Thread-210] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6 and block pool id BP-364049187-172.17.0.4-1606980197868 is not formatted. Formatting ...
2020-12-03 07:23:25,838 [Thread-210] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-364049187-172.17.0.4-1606980197868 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-364049187-172.17.0.4-1606980197868/current
2020-12-03 07:23:25,912 [Thread-156] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-e38d9717-2172-454d-9795-4324f28c8bf6
2020-12-03 07:23:25,912 [Thread-186] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-764dc4eb-6996-475b-8f6e-ebef4cfc3e28
2020-12-03 07:23:25,920 [Thread-186] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, StorageType: DISK
2020-12-03 07:23:25,919 [Thread-156] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, StorageType: DISK
2020-12-03 07:23:25,927 [Thread-186] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-8efb34cb-f56a-46ed-b949-44b9d1babbf4
2020-12-03 07:23:25,927 [Thread-186] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, StorageType: DISK
2020-12-03 07:23:25,933 [Thread-156] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-a79da8de-3edc-4788-ab8e-fc5b8e383ab7
2020-12-03 07:23:25,935 [Thread-156] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, StorageType: DISK
2020-12-03 07:23:25,960 [Thread-186] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:23:25,963 [Thread-156] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:23:25,969 [Thread-186] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-12-03 07:23:25,972 [Thread-187] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:23:25,973 [Thread-187] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3 has already been used.
2020-12-03 07:23:25,973 [Thread-187] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4 has already been used.
2020-12-03 07:23:25,974 [Thread-156] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-12-03 07:23:25,974 [Thread-159] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-339648640-172.17.0.4-1606980201438
2020-12-03 07:23:25,976 [Thread-253] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-339648640-172.17.0.4-1606980201438 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1...
2020-12-03 07:23:25,991 [Thread-254] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-339648640-172.17.0.4-1606980201438 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2...
2020-12-03 07:23:26,012 [Thread-187] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-339648640-172.17.0.4-1606980201438
2020-12-03 07:23:26,012 [Thread-156] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-12-03 07:23:26,012 [Thread-187] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-339648640-172.17.0.4-1606980201438
2020-12-03 07:23:26,012 [Thread-187] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3 and block pool id BP-339648640-172.17.0.4-1606980201438 is not formatted. Formatting ...
2020-12-03 07:23:26,012 [Thread-187] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-339648640-172.17.0.4-1606980201438 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-339648640-172.17.0.4-1606980201438/current
2020-12-03 07:23:26,014 [Thread-156] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-12-03 07:23:26,014 [Thread-156] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-12-03 07:23:26,015 [Thread-186] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-12-03 07:23:26,016 [Thread-186] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-12-03 07:23:26,016 [Thread-186] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-12-03 07:23:26,018 [Thread-156] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-364049187-172.17.0.4-1606980197868
2020-12-03 07:23:26,020 [Thread-186] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-364049187-172.17.0.4-1606980197868
2020-12-03 07:23:26,021 [Thread-255] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-364049187-172.17.0.4-1606980197868 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3...
2020-12-03 07:23:26,021 [Thread-256] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-364049187-172.17.0.4-1606980197868 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4...
2020-12-03 07:23:26,048 [Thread-235] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/in_use.lock acquired by nodename 9751@aa329fbd28a4
2020-12-03 07:23:26,049 [Thread-235] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8 is not formatted for namespace 819413304. Formatting...
2020-12-03 07:23:26,052 [Thread-235] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-62001e65-5365-4f09-80bb-cbaab70b49b7 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8 
2020-12-03 07:23:26,079 [Thread-210] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=819413304;bpid=BP-364049187-172.17.0.4-1606980197868;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=819413304;c=1606980197868;bpid=BP-364049187-172.17.0.4-1606980197868;dnuuid=null
2020-12-03 07:23:26,095 [Thread-253] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-339648640-172.17.0.4-1606980201438 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1: 119ms
2020-12-03 07:23:26,087 [Thread-212] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:23:26,098 [Thread-212] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5 has already been used.
2020-12-03 07:23:26,098 [Thread-212] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6 has already been used.
2020-12-03 07:23:26,106 [Thread-255] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-364049187-172.17.0.4-1606980197868 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3: 85ms
2020-12-03 07:23:26,108 [Thread-256] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-364049187-172.17.0.4-1606980197868 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4: 87ms
2020-12-03 07:23:26,110 [Thread-186] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-364049187-172.17.0.4-1606980197868: 89ms
2020-12-03 07:23:26,113 [Thread-261] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-364049187-172.17.0.4-1606980197868 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3...
2020-12-03 07:23:26,113 [Thread-262] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-364049187-172.17.0.4-1606980197868 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4...
2020-12-03 07:23:26,114 [Thread-261] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-364049187-172.17.0.4-1606980197868/current/replicas doesn't exist 
2020-12-03 07:23:26,114 [Thread-254] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-339648640-172.17.0.4-1606980201438 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2: 123ms
2020-12-03 07:23:26,114 [Thread-159] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-339648640-172.17.0.4-1606980201438: 140ms
2020-12-03 07:23:26,114 [Thread-262] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-364049187-172.17.0.4-1606980197868/current/replicas doesn't exist 
2020-12-03 07:23:26,139 [Thread-263] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-339648640-172.17.0.4-1606980201438 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1...
2020-12-03 07:23:26,140 [Thread-263] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-339648640-172.17.0.4-1606980201438/current/replicas doesn't exist 
2020-12-03 07:23:26,142 [Thread-265] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-339648640-172.17.0.4-1606980201438 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2...
2020-12-03 07:23:26,143 [Thread-265] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-339648640-172.17.0.4-1606980201438/current/replicas doesn't exist 
2020-12-03 07:23:26,144 [Thread-265] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-339648640-172.17.0.4-1606980201438 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2: 1ms
2020-12-03 07:23:26,148 [Thread-264] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-364049187-172.17.0.4-1606980197868 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1...
2020-12-03 07:23:26,149 [Thread-212] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-339648640-172.17.0.4-1606980201438
2020-12-03 07:23:26,149 [Thread-262] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-364049187-172.17.0.4-1606980197868 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4: 35ms
2020-12-03 07:23:26,149 [Thread-212] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-339648640-172.17.0.4-1606980201438
2020-12-03 07:23:26,161 [Thread-261] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-364049187-172.17.0.4-1606980197868 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3: 47ms
2020-12-03 07:23:26,161 [Thread-212] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5 and block pool id BP-339648640-172.17.0.4-1606980201438 is not formatted. Formatting ...
2020-12-03 07:23:26,161 [Thread-186] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-364049187-172.17.0.4-1606980197868: 48ms
2020-12-03 07:23:26,161 [Thread-266] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-364049187-172.17.0.4-1606980197868 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2...
2020-12-03 07:23:26,164 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-364049187-172.17.0.4-1606980197868 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-12-03 07:23:26,161 [Thread-263] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-339648640-172.17.0.4-1606980201438 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1: 21ms
2020-12-03 07:23:26,166 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, DS-764dc4eb-6996-475b-8f6e-ebef4cfc3e28): finished scanning block pool BP-364049187-172.17.0.4-1606980197868
2020-12-03 07:23:26,161 [Thread-212] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-339648640-172.17.0.4-1606980201438 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-339648640-172.17.0.4-1606980201438/current
2020-12-03 07:23:26,167 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-364049187-172.17.0.4-1606980197868 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-12-03 07:23:26,167 [Thread-159] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-339648640-172.17.0.4-1606980201438: 53ms
2020-12-03 07:23:26,196 [Thread-187] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-339648640-172.17.0.4-1606980201438
2020-12-03 07:23:26,197 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, DS-8efb34cb-f56a-46ed-b949-44b9d1babbf4): finished scanning block pool BP-364049187-172.17.0.4-1606980197868
2020-12-03 07:23:26,198 [Thread-187] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-339648640-172.17.0.4-1606980201438
2020-12-03 07:23:26,198 [Thread-187] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4 and block pool id BP-339648640-172.17.0.4-1606980201438 is not formatted. Formatting ...
2020-12-03 07:23:26,198 [Thread-187] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-339648640-172.17.0.4-1606980201438 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-339648640-172.17.0.4-1606980201438/current
2020-12-03 07:23:26,204 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-339648640-172.17.0.4-1606980201438 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-12-03 07:23:26,204 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-339648640-172.17.0.4-1606980201438 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-12-03 07:23:26,204 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, DS-e38d9717-2172-454d-9795-4324f28c8bf6): finished scanning block pool BP-339648640-172.17.0.4-1606980201438
2020-12-03 07:23:26,205 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, DS-a79da8de-3edc-4788-ab8e-fc5b8e383ab7): finished scanning block pool BP-339648640-172.17.0.4-1606980201438
2020-12-03 07:23:26,215 [Thread-264] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-364049187-172.17.0.4-1606980197868 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1: 66ms
2020-12-03 07:23:26,221 [Thread-266] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-364049187-172.17.0.4-1606980197868 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2: 59ms
2020-12-03 07:23:26,221 [Thread-156] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-364049187-172.17.0.4-1606980197868: 107ms
2020-12-03 07:23:26,223 [Thread-271] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-364049187-172.17.0.4-1606980197868 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1...
2020-12-03 07:23:26,223 [Thread-271] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-364049187-172.17.0.4-1606980197868/current/replicas doesn't exist 
2020-12-03 07:23:26,223 [Thread-272] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-364049187-172.17.0.4-1606980197868 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2...
2020-12-03 07:23:26,224 [Thread-272] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-364049187-172.17.0.4-1606980197868/current/replicas doesn't exist 
2020-12-03 07:23:26,224 [Thread-272] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-364049187-172.17.0.4-1606980197868 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2: 0ms
2020-12-03 07:23:26,231 [Thread-271] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-364049187-172.17.0.4-1606980197868 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1: 8ms
2020-12-03 07:23:26,233 [Thread-235] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-364049187-172.17.0.4-1606980197868
2020-12-03 07:23:26,234 [Thread-156] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-364049187-172.17.0.4-1606980197868: 12ms
2020-12-03 07:23:26,234 [Thread-235] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-364049187-172.17.0.4-1606980197868
2020-12-03 07:23:26,234 [Thread-235] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7 and block pool id BP-364049187-172.17.0.4-1606980197868 is not formatted. Formatting ...
2020-12-03 07:23:26,234 [Thread-235] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-364049187-172.17.0.4-1606980197868 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-364049187-172.17.0.4-1606980197868/current
2020-12-03 07:23:26,234 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, DS-8efb34cb-f56a-46ed-b949-44b9d1babbf4): no suitable block pools found to scan.  Waiting 1814399930 ms.
2020-12-03 07:23:26,234 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, DS-764dc4eb-6996-475b-8f6e-ebef4cfc3e28): no suitable block pools found to scan.  Waiting 1814399930 ms.
2020-12-03 07:23:26,238 [Thread-159] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 10:29 AM with interval of 21600000ms
2020-12-03 07:23:26,248 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-364049187-172.17.0.4-1606980197868 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-12-03 07:23:26,249 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, DS-e38d9717-2172-454d-9795-4324f28c8bf6): finished scanning block pool BP-364049187-172.17.0.4-1606980197868
2020-12-03 07:23:26,250 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, DS-e38d9717-2172-454d-9795-4324f28c8bf6): no suitable block pools found to scan.  Waiting 1814399954 ms.
2020-12-03 07:23:26,251 [BP-364049187-172.17.0.4-1606980197868 heartbeating to localhost/127.0.0.1:37672] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-364049187-172.17.0.4-1606980197868 (Datanode Uuid f14979ca-3b14-42d2-8cb7-2d3c00ca4270) service to localhost/127.0.0.1:37672 beginning handshake with NN
2020-12-03 07:23:26,251 [BP-364049187-172.17.0.4-1606980197868 heartbeating to localhost/127.0.0.1:43715] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-364049187-172.17.0.4-1606980197868 (Datanode Uuid f14979ca-3b14-42d2-8cb7-2d3c00ca4270) service to localhost/127.0.0.1:43715 beginning handshake with NN
2020-12-03 07:23:26,251 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-364049187-172.17.0.4-1606980197868 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-12-03 07:23:26,252 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, DS-a79da8de-3edc-4788-ab8e-fc5b8e383ab7): finished scanning block pool BP-364049187-172.17.0.4-1606980197868
2020-12-03 07:23:26,252 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, DS-a79da8de-3edc-4788-ab8e-fc5b8e383ab7): no suitable block pools found to scan.  Waiting 1814399951 ms.
2020-12-03 07:23:26,269 [BP-339648640-172.17.0.4-1606980201438 heartbeating to localhost/127.0.0.1:46572] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-339648640-172.17.0.4-1606980201438 (Datanode Uuid f14979ca-3b14-42d2-8cb7-2d3c00ca4270) service to localhost/127.0.0.1:46572 beginning handshake with NN
2020-12-03 07:23:26,269 [BP-339648640-172.17.0.4-1606980201438 heartbeating to localhost/127.0.0.1:46481] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-339648640-172.17.0.4-1606980201438 (Datanode Uuid f14979ca-3b14-42d2-8cb7-2d3c00ca4270) service to localhost/127.0.0.1:46481 beginning handshake with NN
2020-12-03 07:23:26,275 [IPC Server handler 5 on default port 46572] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:36468, datanodeUuid=f14979ca-3b14-42d2-8cb7-2d3c00ca4270, infoPort=36258, infoSecurePort=0, ipcPort=39779, storageInfo=lv=-57;cid=testClusterID;nsid=249675482;c=1606980201438) storage f14979ca-3b14-42d2-8cb7-2d3c00ca4270
2020-12-03 07:23:26,280 [IPC Server handler 3 on default port 43715] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:36468, datanodeUuid=f14979ca-3b14-42d2-8cb7-2d3c00ca4270, infoPort=36258, infoSecurePort=0, ipcPort=39779, storageInfo=lv=-57;cid=testClusterID;nsid=819413304;c=1606980197868) storage f14979ca-3b14-42d2-8cb7-2d3c00ca4270
2020-12-03 07:23:26,282 [IPC Server handler 5 on default port 46572] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36468
2020-12-03 07:23:26,282 [IPC Server handler 5 on default port 46572] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN f14979ca-3b14-42d2-8cb7-2d3c00ca4270 (127.0.0.1:36468).
2020-12-03 07:23:26,282 [IPC Server handler 3 on default port 43715] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36468
2020-12-03 07:23:26,283 [IPC Server handler 3 on default port 43715] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN f14979ca-3b14-42d2-8cb7-2d3c00ca4270 (127.0.0.1:36468).
2020-12-03 07:23:26,283 [IPC Server handler 5 on default port 46481] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:36468, datanodeUuid=f14979ca-3b14-42d2-8cb7-2d3c00ca4270, infoPort=36258, infoSecurePort=0, ipcPort=39779, storageInfo=lv=-57;cid=testClusterID;nsid=249675482;c=1606980201438) storage f14979ca-3b14-42d2-8cb7-2d3c00ca4270
2020-12-03 07:23:26,285 [IPC Server handler 5 on default port 46481] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36468
2020-12-03 07:23:26,286 [IPC Server handler 5 on default port 46481] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN f14979ca-3b14-42d2-8cb7-2d3c00ca4270 (127.0.0.1:36468).
2020-12-03 07:23:26,298 [IPC Server handler 9 on default port 37672] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:36468, datanodeUuid=f14979ca-3b14-42d2-8cb7-2d3c00ca4270, infoPort=36258, infoSecurePort=0, ipcPort=39779, storageInfo=lv=-57;cid=testClusterID;nsid=819413304;c=1606980197868) storage f14979ca-3b14-42d2-8cb7-2d3c00ca4270
2020-12-03 07:23:26,298 [IPC Server handler 9 on default port 37672] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36468
2020-12-03 07:23:26,299 [IPC Server handler 9 on default port 37672] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN f14979ca-3b14-42d2-8cb7-2d3c00ca4270 (127.0.0.1:36468).
2020-12-03 07:23:26,301 [BP-339648640-172.17.0.4-1606980201438 heartbeating to localhost/127.0.0.1:46572] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-339648640-172.17.0.4-1606980201438 (Datanode Uuid f14979ca-3b14-42d2-8cb7-2d3c00ca4270) service to localhost/127.0.0.1:46572 successfully registered with NN
2020-12-03 07:23:26,302 [BP-339648640-172.17.0.4-1606980201438 heartbeating to localhost/127.0.0.1:46481] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-339648640-172.17.0.4-1606980201438 (Datanode Uuid f14979ca-3b14-42d2-8cb7-2d3c00ca4270) service to localhost/127.0.0.1:46481 successfully registered with NN
2020-12-03 07:23:26,302 [BP-364049187-172.17.0.4-1606980197868 heartbeating to localhost/127.0.0.1:37672] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-364049187-172.17.0.4-1606980197868 (Datanode Uuid f14979ca-3b14-42d2-8cb7-2d3c00ca4270) service to localhost/127.0.0.1:37672 successfully registered with NN
2020-12-03 07:23:26,302 [BP-339648640-172.17.0.4-1606980201438 heartbeating to localhost/127.0.0.1:46572] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:46572 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:26,302 [BP-339648640-172.17.0.4-1606980201438 heartbeating to localhost/127.0.0.1:46481] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:46481 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:26,304 [BP-364049187-172.17.0.4-1606980197868 heartbeating to localhost/127.0.0.1:37672] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:37672 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:26,305 [BP-364049187-172.17.0.4-1606980197868 heartbeating to localhost/127.0.0.1:43715] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-364049187-172.17.0.4-1606980197868 (Datanode Uuid f14979ca-3b14-42d2-8cb7-2d3c00ca4270) service to localhost/127.0.0.1:43715 successfully registered with NN
2020-12-03 07:23:26,306 [BP-364049187-172.17.0.4-1606980197868 heartbeating to localhost/127.0.0.1:43715] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:43715 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:26,329 [Thread-187] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=249675482;bpid=BP-339648640-172.17.0.4-1606980201438;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=249675482;c=1606980201438;bpid=BP-339648640-172.17.0.4-1606980201438;dnuuid=f6670a8c-a905-4867-80f3-0620636ed3de
2020-12-03 07:23:26,329 [Thread-187] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-339648640-172.17.0.4-1606980201438
2020-12-03 07:23:26,330 [Thread-212] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-339648640-172.17.0.4-1606980201438
2020-12-03 07:23:26,330 [Thread-212] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-339648640-172.17.0.4-1606980201438
2020-12-03 07:23:26,331 [Thread-212] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6 and block pool id BP-339648640-172.17.0.4-1606980201438 is not formatted. Formatting ...
2020-12-03 07:23:26,331 [Thread-212] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-339648640-172.17.0.4-1606980201438 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-339648640-172.17.0.4-1606980201438/current
2020-12-03 07:23:26,335 [Thread-274] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-339648640-172.17.0.4-1606980201438 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3...
2020-12-03 07:23:26,338 [Thread-186] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:34 AM with interval of 21600000ms
2020-12-03 07:23:26,350 [BP-364049187-172.17.0.4-1606980197868 heartbeating to localhost/127.0.0.1:43715] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-364049187-172.17.0.4-1606980197868 (Datanode Uuid f6670a8c-a905-4867-80f3-0620636ed3de) service to localhost/127.0.0.1:43715 beginning handshake with NN
2020-12-03 07:23:26,337 [Thread-276] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-339648640-172.17.0.4-1606980201438 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4...
2020-12-03 07:23:26,350 [BP-364049187-172.17.0.4-1606980197868 heartbeating to localhost/127.0.0.1:37672] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-364049187-172.17.0.4-1606980197868 (Datanode Uuid f6670a8c-a905-4867-80f3-0620636ed3de) service to localhost/127.0.0.1:37672 beginning handshake with NN
2020-12-03 07:23:26,356 [IPC Server handler 9 on default port 43715] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34145, datanodeUuid=f6670a8c-a905-4867-80f3-0620636ed3de, infoPort=37346, infoSecurePort=0, ipcPort=36168, storageInfo=lv=-57;cid=testClusterID;nsid=819413304;c=1606980197868) storage f6670a8c-a905-4867-80f3-0620636ed3de
2020-12-03 07:23:26,357 [IPC Server handler 9 on default port 43715] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:34145
2020-12-03 07:23:26,360 [IPC Server handler 1 on default port 37672] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34145, datanodeUuid=f6670a8c-a905-4867-80f3-0620636ed3de, infoPort=37346, infoSecurePort=0, ipcPort=36168, storageInfo=lv=-57;cid=testClusterID;nsid=819413304;c=1606980197868) storage f6670a8c-a905-4867-80f3-0620636ed3de
2020-12-03 07:23:26,360 [IPC Server handler 1 on default port 37672] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:34145
2020-12-03 07:23:26,361 [IPC Server handler 1 on default port 37672] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN f6670a8c-a905-4867-80f3-0620636ed3de (127.0.0.1:34145).
2020-12-03 07:23:26,362 [BP-364049187-172.17.0.4-1606980197868 heartbeating to localhost/127.0.0.1:37672] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-364049187-172.17.0.4-1606980197868 (Datanode Uuid f6670a8c-a905-4867-80f3-0620636ed3de) service to localhost/127.0.0.1:37672 successfully registered with NN
2020-12-03 07:23:26,362 [BP-364049187-172.17.0.4-1606980197868 heartbeating to localhost/127.0.0.1:37672] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:37672 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:26,367 [IPC Server handler 9 on default port 43715] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN f6670a8c-a905-4867-80f3-0620636ed3de (127.0.0.1:34145).
2020-12-03 07:23:26,387 [BP-364049187-172.17.0.4-1606980197868 heartbeating to localhost/127.0.0.1:43715] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-364049187-172.17.0.4-1606980197868 (Datanode Uuid f6670a8c-a905-4867-80f3-0620636ed3de) service to localhost/127.0.0.1:43715 successfully registered with NN
2020-12-03 07:23:26,388 [BP-364049187-172.17.0.4-1606980197868 heartbeating to localhost/127.0.0.1:43715] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:43715 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:26,402 [Thread-235] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-364049187-172.17.0.4-1606980197868
2020-12-03 07:23:26,402 [Thread-235] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-364049187-172.17.0.4-1606980197868
2020-12-03 07:23:26,402 [Thread-235] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8 and block pool id BP-364049187-172.17.0.4-1606980197868 is not formatted. Formatting ...
2020-12-03 07:23:26,403 [Thread-235] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-364049187-172.17.0.4-1606980197868 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-364049187-172.17.0.4-1606980197868/current
2020-12-03 07:23:26,427 [Thread-212] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=249675482;bpid=BP-339648640-172.17.0.4-1606980201438;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=249675482;c=1606980201438;bpid=BP-339648640-172.17.0.4-1606980201438;dnuuid=null
2020-12-03 07:23:26,437 [IPC Server handler 3 on default port 37672] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-764dc4eb-6996-475b-8f6e-ebef4cfc3e28 for DN 127.0.0.1:34145
2020-12-03 07:23:26,437 [IPC Server handler 2 on default port 43715] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-e38d9717-2172-454d-9795-4324f28c8bf6 for DN 127.0.0.1:36468
2020-12-03 07:23:26,439 [IPC Server handler 3 on default port 37672] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-8efb34cb-f56a-46ed-b949-44b9d1babbf4 for DN 127.0.0.1:34145
2020-12-03 07:23:26,439 [IPC Server handler 2 on default port 43715] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-a79da8de-3edc-4788-ab8e-fc5b8e383ab7 for DN 127.0.0.1:36468
2020-12-03 07:23:26,442 [IPC Server handler 7 on default port 37672] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-e38d9717-2172-454d-9795-4324f28c8bf6 for DN 127.0.0.1:36468
2020-12-03 07:23:26,443 [IPC Server handler 3 on default port 46481] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-e38d9717-2172-454d-9795-4324f28c8bf6 for DN 127.0.0.1:36468
2020-12-03 07:23:26,443 [IPC Server handler 3 on default port 46481] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-a79da8de-3edc-4788-ab8e-fc5b8e383ab7 for DN 127.0.0.1:36468
2020-12-03 07:23:26,444 [IPC Server handler 0 on default port 43715] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-764dc4eb-6996-475b-8f6e-ebef4cfc3e28 for DN 127.0.0.1:34145
2020-12-03 07:23:26,447 [IPC Server handler 7 on default port 37672] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-a79da8de-3edc-4788-ab8e-fc5b8e383ab7 for DN 127.0.0.1:36468
2020-12-03 07:23:26,451 [IPC Server handler 0 on default port 43715] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-8efb34cb-f56a-46ed-b949-44b9d1babbf4 for DN 127.0.0.1:34145
2020-12-03 07:23:26,463 [Thread-276] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-339648640-172.17.0.4-1606980201438 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4: 111ms
2020-12-03 07:23:26,464 [Thread-274] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-339648640-172.17.0.4-1606980201438 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3: 116ms
2020-12-03 07:23:26,467 [Thread-187] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-339648640-172.17.0.4-1606980201438: 138ms
2020-12-03 07:23:26,470 [Thread-281] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-339648640-172.17.0.4-1606980201438 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3...
2020-12-03 07:23:26,471 [Thread-282] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-339648640-172.17.0.4-1606980201438 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4...
2020-12-03 07:23:26,471 [Thread-282] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-339648640-172.17.0.4-1606980201438/current/replicas doesn't exist 
2020-12-03 07:23:26,471 [Thread-282] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-339648640-172.17.0.4-1606980201438 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4: 1ms
2020-12-03 07:23:26,471 [Thread-281] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-339648640-172.17.0.4-1606980201438/current/replicas doesn't exist 
2020-12-03 07:23:26,477 [Thread-281] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-339648640-172.17.0.4-1606980201438 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3: 6ms
2020-12-03 07:23:26,478 [IPC Server handler 0 on default port 46572] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-e38d9717-2172-454d-9795-4324f28c8bf6 for DN 127.0.0.1:36468
2020-12-03 07:23:26,479 [IPC Server handler 0 on default port 46572] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-a79da8de-3edc-4788-ab8e-fc5b8e383ab7 for DN 127.0.0.1:36468
2020-12-03 07:23:26,480 [Thread-187] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-339648640-172.17.0.4-1606980201438: 13ms
2020-12-03 07:23:26,482 [BP-339648640-172.17.0.4-1606980201438 heartbeating to localhost/127.0.0.1:46572] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-339648640-172.17.0.4-1606980201438 (Datanode Uuid f6670a8c-a905-4867-80f3-0620636ed3de) service to localhost/127.0.0.1:46572 beginning handshake with NN
2020-12-03 07:23:26,482 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-339648640-172.17.0.4-1606980201438 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-12-03 07:23:26,482 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, DS-764dc4eb-6996-475b-8f6e-ebef4cfc3e28): finished scanning block pool BP-339648640-172.17.0.4-1606980201438
2020-12-03 07:23:26,483 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, DS-764dc4eb-6996-475b-8f6e-ebef4cfc3e28): no suitable block pools found to scan.  Waiting 1814399681 ms.
2020-12-03 07:23:26,483 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-339648640-172.17.0.4-1606980201438 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-12-03 07:23:26,489 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, DS-8efb34cb-f56a-46ed-b949-44b9d1babbf4): finished scanning block pool BP-339648640-172.17.0.4-1606980201438
2020-12-03 07:23:26,489 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, DS-8efb34cb-f56a-46ed-b949-44b9d1babbf4): no suitable block pools found to scan.  Waiting 1814399675 ms.
2020-12-03 07:23:26,490 [BP-339648640-172.17.0.4-1606980201438 heartbeating to localhost/127.0.0.1:46481] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-339648640-172.17.0.4-1606980201438 (Datanode Uuid f6670a8c-a905-4867-80f3-0620636ed3de) service to localhost/127.0.0.1:46481 beginning handshake with NN
2020-12-03 07:23:26,490 [IPC Server handler 1 on default port 46572] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34145, datanodeUuid=f6670a8c-a905-4867-80f3-0620636ed3de, infoPort=37346, infoSecurePort=0, ipcPort=36168, storageInfo=lv=-57;cid=testClusterID;nsid=249675482;c=1606980201438) storage f6670a8c-a905-4867-80f3-0620636ed3de
2020-12-03 07:23:26,508 [Thread-235] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=819413304;bpid=BP-364049187-172.17.0.4-1606980197868;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=819413304;c=1606980197868;bpid=BP-364049187-172.17.0.4-1606980197868;dnuuid=null
2020-12-03 07:23:26,508 [IPC Server handler 1 on default port 46572] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:34145
2020-12-03 07:23:26,509 [IPC Server handler 1 on default port 46572] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN f6670a8c-a905-4867-80f3-0620636ed3de (127.0.0.1:34145).
2020-12-03 07:23:26,504 [Thread-237] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:23:26,509 [IPC Server handler 4 on default port 46481] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34145, datanodeUuid=f6670a8c-a905-4867-80f3-0620636ed3de, infoPort=37346, infoSecurePort=0, ipcPort=36168, storageInfo=lv=-57;cid=testClusterID;nsid=249675482;c=1606980201438) storage f6670a8c-a905-4867-80f3-0620636ed3de
2020-12-03 07:23:26,510 [Thread-237] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7 has already been used.
2020-12-03 07:23:26,510 [BP-339648640-172.17.0.4-1606980201438 heartbeating to localhost/127.0.0.1:46572] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-339648640-172.17.0.4-1606980201438 (Datanode Uuid f6670a8c-a905-4867-80f3-0620636ed3de) service to localhost/127.0.0.1:46572 successfully registered with NN
2020-12-03 07:23:26,510 [BP-339648640-172.17.0.4-1606980201438 heartbeating to localhost/127.0.0.1:46572] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:46572 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:26,511 [Thread-237] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8 has already been used.
2020-12-03 07:23:26,511 [IPC Server handler 4 on default port 46481] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:34145
2020-12-03 07:23:26,511 [IPC Server handler 4 on default port 46481] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN f6670a8c-a905-4867-80f3-0620636ed3de (127.0.0.1:34145).
2020-12-03 07:23:26,513 [BP-339648640-172.17.0.4-1606980201438 heartbeating to localhost/127.0.0.1:46481] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-339648640-172.17.0.4-1606980201438 (Datanode Uuid f6670a8c-a905-4867-80f3-0620636ed3de) service to localhost/127.0.0.1:46481 successfully registered with NN
2020-12-03 07:23:26,514 [BP-339648640-172.17.0.4-1606980201438 heartbeating to localhost/127.0.0.1:46481] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:46481 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:26,533 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xd96665355f61f975: Processing first storage report for DS-764dc4eb-6996-475b-8f6e-ebef4cfc3e28 from datanode f6670a8c-a905-4867-80f3-0620636ed3de
2020-12-03 07:23:26,536 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xd96665355f61f975: from storage DS-764dc4eb-6996-475b-8f6e-ebef4cfc3e28 node DatanodeRegistration(127.0.0.1:34145, datanodeUuid=f6670a8c-a905-4867-80f3-0620636ed3de, infoPort=37346, infoSecurePort=0, ipcPort=36168, storageInfo=lv=-57;cid=testClusterID;nsid=819413304;c=1606980197868), blocks: 0, hasStaleStorage: true, processing time: 3 msecs, invalidatedBlocks: 0
2020-12-03 07:23:26,536 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xd96665355f61f975: Processing first storage report for DS-8efb34cb-f56a-46ed-b949-44b9d1babbf4 from datanode f6670a8c-a905-4867-80f3-0620636ed3de
2020-12-03 07:23:26,536 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xd96665355f61f975: from storage DS-8efb34cb-f56a-46ed-b949-44b9d1babbf4 node DatanodeRegistration(127.0.0.1:34145, datanodeUuid=f6670a8c-a905-4867-80f3-0620636ed3de, infoPort=37346, infoSecurePort=0, ipcPort=36168, storageInfo=lv=-57;cid=testClusterID;nsid=819413304;c=1606980197868), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:23:26,539 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xc8687a56037584e9: Processing first storage report for DS-e38d9717-2172-454d-9795-4324f28c8bf6 from datanode f14979ca-3b14-42d2-8cb7-2d3c00ca4270
2020-12-03 07:23:26,540 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xc8687a56037584e9: from storage DS-e38d9717-2172-454d-9795-4324f28c8bf6 node DatanodeRegistration(127.0.0.1:36468, datanodeUuid=f14979ca-3b14-42d2-8cb7-2d3c00ca4270, infoPort=36258, infoSecurePort=0, ipcPort=39779, storageInfo=lv=-57;cid=testClusterID;nsid=819413304;c=1606980197868), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:26,541 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xd9b03b4477a0cda7: Processing first storage report for DS-e38d9717-2172-454d-9795-4324f28c8bf6 from datanode f14979ca-3b14-42d2-8cb7-2d3c00ca4270
2020-12-03 07:23:26,546 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xc8687a56037584e9: Processing first storage report for DS-a79da8de-3edc-4788-ab8e-fc5b8e383ab7 from datanode f14979ca-3b14-42d2-8cb7-2d3c00ca4270
2020-12-03 07:23:26,546 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xd9b03b4477a0cda7: from storage DS-e38d9717-2172-454d-9795-4324f28c8bf6 node DatanodeRegistration(127.0.0.1:36468, datanodeUuid=f14979ca-3b14-42d2-8cb7-2d3c00ca4270, infoPort=36258, infoSecurePort=0, ipcPort=39779, storageInfo=lv=-57;cid=testClusterID;nsid=249675482;c=1606980201438), blocks: 0, hasStaleStorage: true, processing time: 6 msecs, invalidatedBlocks: 0
2020-12-03 07:23:26,542 [IPC Server handler 2 on default port 46572] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-764dc4eb-6996-475b-8f6e-ebef4cfc3e28 for DN 127.0.0.1:34145
2020-12-03 07:23:26,557 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xc8687a56037584e9: from storage DS-a79da8de-3edc-4788-ab8e-fc5b8e383ab7 node DatanodeRegistration(127.0.0.1:36468, datanodeUuid=f14979ca-3b14-42d2-8cb7-2d3c00ca4270, infoPort=36258, infoSecurePort=0, ipcPort=39779, storageInfo=lv=-57;cid=testClusterID;nsid=819413304;c=1606980197868), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:23:26,558 [IPC Server handler 9 on default port 46481] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-764dc4eb-6996-475b-8f6e-ebef4cfc3e28 for DN 127.0.0.1:34145
2020-12-03 07:23:26,542 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x8580bece42c1ec77: Processing first storage report for DS-e38d9717-2172-454d-9795-4324f28c8bf6 from datanode f14979ca-3b14-42d2-8cb7-2d3c00ca4270
2020-12-03 07:23:26,560 [IPC Server handler 9 on default port 46481] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-8efb34cb-f56a-46ed-b949-44b9d1babbf4 for DN 127.0.0.1:34145
2020-12-03 07:23:26,559 [IPC Server handler 2 on default port 46572] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-8efb34cb-f56a-46ed-b949-44b9d1babbf4 for DN 127.0.0.1:34145
2020-12-03 07:23:26,564 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xd9b03b4477a0cda7: Processing first storage report for DS-a79da8de-3edc-4788-ab8e-fc5b8e383ab7 from datanode f14979ca-3b14-42d2-8cb7-2d3c00ca4270
2020-12-03 07:23:26,564 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xd9b03b4477a0cda7: from storage DS-a79da8de-3edc-4788-ab8e-fc5b8e383ab7 node DatanodeRegistration(127.0.0.1:36468, datanodeUuid=f14979ca-3b14-42d2-8cb7-2d3c00ca4270, infoPort=36258, infoSecurePort=0, ipcPort=39779, storageInfo=lv=-57;cid=testClusterID;nsid=249675482;c=1606980201438), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:26,551 [Thread-210] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 8269cf1e-183a-448f-93f1-8184271cbc73
2020-12-03 07:23:26,549 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-339648640-172.17.0.4-1606980201438
2020-12-03 07:23:26,564 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xbf9cf213f2338aad: Processing first storage report for DS-e38d9717-2172-454d-9795-4324f28c8bf6 from datanode f14979ca-3b14-42d2-8cb7-2d3c00ca4270
2020-12-03 07:23:26,571 [Thread-237] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-339648640-172.17.0.4-1606980201438
2020-12-03 07:23:26,564 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x8580bece42c1ec77: from storage DS-e38d9717-2172-454d-9795-4324f28c8bf6 node DatanodeRegistration(127.0.0.1:36468, datanodeUuid=f14979ca-3b14-42d2-8cb7-2d3c00ca4270, infoPort=36258, infoSecurePort=0, ipcPort=39779, storageInfo=lv=-57;cid=testClusterID;nsid=819413304;c=1606980197868), blocks: 0, hasStaleStorage: true, processing time: 22 msecs, invalidatedBlocks: 0
2020-12-03 07:23:26,571 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7 and block pool id BP-339648640-172.17.0.4-1606980201438 is not formatted. Formatting ...
2020-12-03 07:23:26,572 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-339648640-172.17.0.4-1606980201438 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-339648640-172.17.0.4-1606980201438/current
2020-12-03 07:23:26,571 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xbf9cf213f2338aad: from storage DS-e38d9717-2172-454d-9795-4324f28c8bf6 node DatanodeRegistration(127.0.0.1:36468, datanodeUuid=f14979ca-3b14-42d2-8cb7-2d3c00ca4270, infoPort=36258, infoSecurePort=0, ipcPort=39779, storageInfo=lv=-57;cid=testClusterID;nsid=249675482;c=1606980201438), blocks: 0, hasStaleStorage: true, processing time: 7 msecs, invalidatedBlocks: 0
2020-12-03 07:23:26,572 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x8580bece42c1ec77: Processing first storage report for DS-a79da8de-3edc-4788-ab8e-fc5b8e383ab7 from datanode f14979ca-3b14-42d2-8cb7-2d3c00ca4270
2020-12-03 07:23:26,572 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xbf9cf213f2338aad: Processing first storage report for DS-a79da8de-3edc-4788-ab8e-fc5b8e383ab7 from datanode f14979ca-3b14-42d2-8cb7-2d3c00ca4270
2020-12-03 07:23:26,572 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x8580bece42c1ec77: from storage DS-a79da8de-3edc-4788-ab8e-fc5b8e383ab7 node DatanodeRegistration(127.0.0.1:36468, datanodeUuid=f14979ca-3b14-42d2-8cb7-2d3c00ca4270, infoPort=36258, infoSecurePort=0, ipcPort=39779, storageInfo=lv=-57;cid=testClusterID;nsid=819413304;c=1606980197868), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:23:26,572 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xbf9cf213f2338aad: from storage DS-a79da8de-3edc-4788-ab8e-fc5b8e383ab7 node DatanodeRegistration(127.0.0.1:36468, datanodeUuid=f14979ca-3b14-42d2-8cb7-2d3c00ca4270, infoPort=36258, infoSecurePort=0, ipcPort=39779, storageInfo=lv=-57;cid=testClusterID;nsid=249675482;c=1606980201438), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:23:26,572 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xc4019a1e3ebbc24a: Processing first storage report for DS-764dc4eb-6996-475b-8f6e-ebef4cfc3e28 from datanode f6670a8c-a905-4867-80f3-0620636ed3de
2020-12-03 07:23:26,573 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xc4019a1e3ebbc24a: from storage DS-764dc4eb-6996-475b-8f6e-ebef4cfc3e28 node DatanodeRegistration(127.0.0.1:34145, datanodeUuid=f6670a8c-a905-4867-80f3-0620636ed3de, infoPort=37346, infoSecurePort=0, ipcPort=36168, storageInfo=lv=-57;cid=testClusterID;nsid=819413304;c=1606980197868), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:26,573 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xc4019a1e3ebbc24a: Processing first storage report for DS-8efb34cb-f56a-46ed-b949-44b9d1babbf4 from datanode f6670a8c-a905-4867-80f3-0620636ed3de
2020-12-03 07:23:26,573 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xc4019a1e3ebbc24a: from storage DS-8efb34cb-f56a-46ed-b949-44b9d1babbf4 node DatanodeRegistration(127.0.0.1:34145, datanodeUuid=f6670a8c-a905-4867-80f3-0620636ed3de, infoPort=37346, infoSecurePort=0, ipcPort=36168, storageInfo=lv=-57;cid=testClusterID;nsid=819413304;c=1606980197868), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:23:26,573 [Thread-210] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-af989f10-524a-4fdf-bcbd-c3442592547a
2020-12-03 07:23:26,574 [Thread-210] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, StorageType: DISK
2020-12-03 07:23:26,576 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xd66dfd365ffb7458: Processing first storage report for DS-764dc4eb-6996-475b-8f6e-ebef4cfc3e28 from datanode f6670a8c-a905-4867-80f3-0620636ed3de
2020-12-03 07:23:26,575 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xf53cb48f05461e30: Processing first storage report for DS-764dc4eb-6996-475b-8f6e-ebef4cfc3e28 from datanode f6670a8c-a905-4867-80f3-0620636ed3de
2020-12-03 07:23:26,577 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xd66dfd365ffb7458: from storage DS-764dc4eb-6996-475b-8f6e-ebef4cfc3e28 node DatanodeRegistration(127.0.0.1:34145, datanodeUuid=f6670a8c-a905-4867-80f3-0620636ed3de, infoPort=37346, infoSecurePort=0, ipcPort=36168, storageInfo=lv=-57;cid=testClusterID;nsid=249675482;c=1606980201438), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:23:26,577 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xf53cb48f05461e30: from storage DS-764dc4eb-6996-475b-8f6e-ebef4cfc3e28 node DatanodeRegistration(127.0.0.1:34145, datanodeUuid=f6670a8c-a905-4867-80f3-0620636ed3de, infoPort=37346, infoSecurePort=0, ipcPort=36168, storageInfo=lv=-57;cid=testClusterID;nsid=249675482;c=1606980201438), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:23:26,577 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xf53cb48f05461e30: Processing first storage report for DS-8efb34cb-f56a-46ed-b949-44b9d1babbf4 from datanode f6670a8c-a905-4867-80f3-0620636ed3de
2020-12-03 07:23:26,577 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xf53cb48f05461e30: from storage DS-8efb34cb-f56a-46ed-b949-44b9d1babbf4 node DatanodeRegistration(127.0.0.1:34145, datanodeUuid=f6670a8c-a905-4867-80f3-0620636ed3de, infoPort=37346, infoSecurePort=0, ipcPort=36168, storageInfo=lv=-57;cid=testClusterID;nsid=249675482;c=1606980201438), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:26,579 [Thread-210] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-69da2731-18b4-472d-af70-d73a4d269712
2020-12-03 07:23:26,579 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xd66dfd365ffb7458: Processing first storage report for DS-8efb34cb-f56a-46ed-b949-44b9d1babbf4 from datanode f6670a8c-a905-4867-80f3-0620636ed3de
2020-12-03 07:23:26,589 [Thread-210] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, StorageType: DISK
2020-12-03 07:23:26,589 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xd66dfd365ffb7458: from storage DS-8efb34cb-f56a-46ed-b949-44b9d1babbf4 node DatanodeRegistration(127.0.0.1:34145, datanodeUuid=f6670a8c-a905-4867-80f3-0620636ed3de, infoPort=37346, infoSecurePort=0, ipcPort=36168, storageInfo=lv=-57;cid=testClusterID;nsid=249675482;c=1606980201438), blocks: 0, hasStaleStorage: false, processing time: 9 msecs, invalidatedBlocks: 0
2020-12-03 07:23:26,590 [Thread-210] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:23:26,592 [BP-364049187-172.17.0.4-1606980197868 heartbeating to localhost/127.0.0.1:37672] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xd96665355f61f975,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 114 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:23:26,592 [BP-339648640-172.17.0.4-1606980201438 heartbeating to localhost/127.0.0.1:46481] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xd9b03b4477a0cda7,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 5 msec to generate and 113 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:23:26,595 [BP-364049187-172.17.0.4-1606980197868 heartbeating to localhost/127.0.0.1:43715] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xc4019a1e3ebbc24a,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 116 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:23:26,602 [Thread-212] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-12-03 07:23:26,603 [Thread-212] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-12-03 07:23:26,603 [Thread-212] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-12-03 07:23:26,595 [BP-339648640-172.17.0.4-1606980201438 heartbeating to localhost/127.0.0.1:46481] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xf53cb48f05461e30,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 25 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:23:26,594 [BP-339648640-172.17.0.4-1606980201438 heartbeating to localhost/127.0.0.1:46572] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xd66dfd365ffb7458,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 25 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:23:26,603 [Thread-212] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-12-03 07:23:26,602 [Thread-210] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-12-03 07:23:26,595 [BP-364049187-172.17.0.4-1606980197868 heartbeating to localhost/127.0.0.1:43715] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xc8687a56037584e9,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 114 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:23:26,600 [BP-364049187-172.17.0.4-1606980197868 heartbeating to localhost/127.0.0.1:37672] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x8580bece42c1ec77,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 120 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:23:26,595 [BP-339648640-172.17.0.4-1606980201438 heartbeating to localhost/127.0.0.1:46572] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xbf9cf213f2338aad,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 110 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:23:26,617 [Thread-210] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-12-03 07:23:26,611 [Thread-212] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-339648640-172.17.0.4-1606980201438
2020-12-03 07:23:26,617 [Thread-210] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-12-03 07:23:26,617 [Thread-285] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-339648640-172.17.0.4-1606980201438 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5...
2020-12-03 07:23:26,617 [Thread-286] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-339648640-172.17.0.4-1606980201438 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6...
2020-12-03 07:23:26,621 [Thread-210] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-364049187-172.17.0.4-1606980197868
2020-12-03 07:23:26,668 [Thread-285] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-339648640-172.17.0.4-1606980201438 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5: 51ms
2020-12-03 07:23:26,671 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-339648640-172.17.0.4-1606980201438
2020-12-03 07:23:26,672 [Thread-237] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-339648640-172.17.0.4-1606980201438
2020-12-03 07:23:26,672 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8 and block pool id BP-339648640-172.17.0.4-1606980201438 is not formatted. Formatting ...
2020-12-03 07:23:26,672 [Thread-237] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-339648640-172.17.0.4-1606980201438 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-339648640-172.17.0.4-1606980201438/current
2020-12-03 07:23:26,689 [Thread-286] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-339648640-172.17.0.4-1606980201438 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6: 71ms
2020-12-03 07:23:26,691 [Thread-212] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-339648640-172.17.0.4-1606980201438: 75ms
2020-12-03 07:23:26,692 [Thread-289] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-339648640-172.17.0.4-1606980201438 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5...
2020-12-03 07:23:26,692 [Thread-289] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-339648640-172.17.0.4-1606980201438/current/replicas doesn't exist 
2020-12-03 07:23:26,692 [Thread-290] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-364049187-172.17.0.4-1606980197868 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5...
2020-12-03 07:23:26,693 [Thread-291] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-339648640-172.17.0.4-1606980201438 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6...
2020-12-03 07:23:26,693 [Thread-291] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-339648640-172.17.0.4-1606980201438/current/replicas doesn't exist 
2020-12-03 07:23:26,693 [Thread-289] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-339648640-172.17.0.4-1606980201438 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5: 1ms
2020-12-03 07:23:26,694 [Thread-291] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-339648640-172.17.0.4-1606980201438 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6: 1ms
2020-12-03 07:23:26,694 [Thread-212] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-339648640-172.17.0.4-1606980201438: 2ms
2020-12-03 07:23:26,704 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-339648640-172.17.0.4-1606980201438 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-12-03 07:23:26,704 [Thread-212] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 12:04 PM with interval of 21600000ms
2020-12-03 07:23:26,705 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, DS-69da2731-18b4-472d-af70-d73a4d269712): finished scanning block pool BP-339648640-172.17.0.4-1606980201438
2020-12-03 07:23:26,705 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-339648640-172.17.0.4-1606980201438 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-12-03 07:23:26,705 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, DS-af989f10-524a-4fdf-bcbd-c3442592547a): finished scanning block pool BP-339648640-172.17.0.4-1606980201438
2020-12-03 07:23:26,705 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, DS-69da2731-18b4-472d-af70-d73a4d269712): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:23:26,706 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, DS-af989f10-524a-4fdf-bcbd-c3442592547a): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-12-03 07:23:26,707 [Thread-292] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-364049187-172.17.0.4-1606980197868 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6...
2020-12-03 07:23:26,713 [BP-339648640-172.17.0.4-1606980201438 heartbeating to localhost/127.0.0.1:46572] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-339648640-172.17.0.4-1606980201438 (Datanode Uuid 8269cf1e-183a-448f-93f1-8184271cbc73) service to localhost/127.0.0.1:46572 beginning handshake with NN
2020-12-03 07:23:26,713 [BP-339648640-172.17.0.4-1606980201438 heartbeating to localhost/127.0.0.1:46481] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-339648640-172.17.0.4-1606980201438 (Datanode Uuid 8269cf1e-183a-448f-93f1-8184271cbc73) service to localhost/127.0.0.1:46481 beginning handshake with NN
2020-12-03 07:23:26,715 [IPC Server handler 6 on default port 46481] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:40556, datanodeUuid=8269cf1e-183a-448f-93f1-8184271cbc73, infoPort=37471, infoSecurePort=0, ipcPort=35876, storageInfo=lv=-57;cid=testClusterID;nsid=249675482;c=1606980201438) storage 8269cf1e-183a-448f-93f1-8184271cbc73
2020-12-03 07:23:26,715 [IPC Server handler 6 on default port 46481] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:40556
2020-12-03 07:23:26,715 [IPC Server handler 6 on default port 46481] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 8269cf1e-183a-448f-93f1-8184271cbc73 (127.0.0.1:40556).
2020-12-03 07:23:26,715 [IPC Server handler 7 on default port 46572] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:40556, datanodeUuid=8269cf1e-183a-448f-93f1-8184271cbc73, infoPort=37471, infoSecurePort=0, ipcPort=35876, storageInfo=lv=-57;cid=testClusterID;nsid=249675482;c=1606980201438) storage 8269cf1e-183a-448f-93f1-8184271cbc73
2020-12-03 07:23:26,723 [IPC Server handler 7 on default port 46572] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:40556
2020-12-03 07:23:26,723 [IPC Server handler 7 on default port 46572] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 8269cf1e-183a-448f-93f1-8184271cbc73 (127.0.0.1:40556).
2020-12-03 07:23:26,724 [BP-339648640-172.17.0.4-1606980201438 heartbeating to localhost/127.0.0.1:46481] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-339648640-172.17.0.4-1606980201438 (Datanode Uuid 8269cf1e-183a-448f-93f1-8184271cbc73) service to localhost/127.0.0.1:46481 successfully registered with NN
2020-12-03 07:23:26,724 [BP-339648640-172.17.0.4-1606980201438 heartbeating to localhost/127.0.0.1:46481] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:46481 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:26,732 [BP-339648640-172.17.0.4-1606980201438 heartbeating to localhost/127.0.0.1:46572] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-339648640-172.17.0.4-1606980201438 (Datanode Uuid 8269cf1e-183a-448f-93f1-8184271cbc73) service to localhost/127.0.0.1:46572 successfully registered with NN
2020-12-03 07:23:26,732 [BP-339648640-172.17.0.4-1606980201438 heartbeating to localhost/127.0.0.1:46572] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:46572 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:26,742 [Thread-237] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=249675482;bpid=BP-339648640-172.17.0.4-1606980201438;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=249675482;c=1606980201438;bpid=BP-339648640-172.17.0.4-1606980201438;dnuuid=null
2020-12-03 07:23:26,745 [IPC Server handler 2 on default port 46481] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-af989f10-524a-4fdf-bcbd-c3442592547a for DN 127.0.0.1:40556
2020-12-03 07:23:26,745 [IPC Server handler 2 on default port 46481] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-69da2731-18b4-472d-af70-d73a4d269712 for DN 127.0.0.1:40556
2020-12-03 07:23:26,748 [IPC Server handler 9 on default port 46572] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-af989f10-524a-4fdf-bcbd-c3442592547a for DN 127.0.0.1:40556
2020-12-03 07:23:26,748 [IPC Server handler 9 on default port 46572] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-69da2731-18b4-472d-af70-d73a4d269712 for DN 127.0.0.1:40556
2020-12-03 07:23:26,757 [Thread-292] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-364049187-172.17.0.4-1606980197868 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6: 49ms
2020-12-03 07:23:26,772 [Thread-290] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-364049187-172.17.0.4-1606980197868 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5: 80ms
2020-12-03 07:23:26,772 [Thread-210] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-364049187-172.17.0.4-1606980197868: 81ms
2020-12-03 07:23:26,773 [Thread-298] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-364049187-172.17.0.4-1606980197868 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5...
2020-12-03 07:23:26,773 [Thread-299] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-364049187-172.17.0.4-1606980197868 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6...
2020-12-03 07:23:26,773 [Thread-298] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-364049187-172.17.0.4-1606980197868/current/replicas doesn't exist 
2020-12-03 07:23:26,773 [Thread-299] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-364049187-172.17.0.4-1606980197868/current/replicas doesn't exist 
2020-12-03 07:23:26,774 [Thread-298] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-364049187-172.17.0.4-1606980197868 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5: 0ms
2020-12-03 07:23:26,775 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x3ba73c38f3b5fe09: Processing first storage report for DS-69da2731-18b4-472d-af70-d73a4d269712 from datanode 8269cf1e-183a-448f-93f1-8184271cbc73
2020-12-03 07:23:26,775 [Thread-299] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-364049187-172.17.0.4-1606980197868 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6: 1ms
2020-12-03 07:23:26,775 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x3ba73c38f3b5fe09: from storage DS-69da2731-18b4-472d-af70-d73a4d269712 node DatanodeRegistration(127.0.0.1:40556, datanodeUuid=8269cf1e-183a-448f-93f1-8184271cbc73, infoPort=37471, infoSecurePort=0, ipcPort=35876, storageInfo=lv=-57;cid=testClusterID;nsid=249675482;c=1606980201438), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:26,776 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x3ba73c38f3b5fe09: Processing first storage report for DS-af989f10-524a-4fdf-bcbd-c3442592547a from datanode 8269cf1e-183a-448f-93f1-8184271cbc73
2020-12-03 07:23:26,776 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x3ba73c38f3b5fe09: from storage DS-af989f10-524a-4fdf-bcbd-c3442592547a node DatanodeRegistration(127.0.0.1:40556, datanodeUuid=8269cf1e-183a-448f-93f1-8184271cbc73, infoPort=37471, infoSecurePort=0, ipcPort=35876, storageInfo=lv=-57;cid=testClusterID;nsid=249675482;c=1606980201438), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:23:26,776 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xf964418829cf8bec: Processing first storage report for DS-69da2731-18b4-472d-af70-d73a4d269712 from datanode 8269cf1e-183a-448f-93f1-8184271cbc73
2020-12-03 07:23:26,777 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xf964418829cf8bec: from storage DS-69da2731-18b4-472d-af70-d73a4d269712 node DatanodeRegistration(127.0.0.1:40556, datanodeUuid=8269cf1e-183a-448f-93f1-8184271cbc73, infoPort=37471, infoSecurePort=0, ipcPort=35876, storageInfo=lv=-57;cid=testClusterID;nsid=249675482;c=1606980201438), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:26,779 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xf964418829cf8bec: Processing first storage report for DS-af989f10-524a-4fdf-bcbd-c3442592547a from datanode 8269cf1e-183a-448f-93f1-8184271cbc73
2020-12-03 07:23:26,779 [Thread-210] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-364049187-172.17.0.4-1606980197868: 7ms
2020-12-03 07:23:26,780 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xf964418829cf8bec: from storage DS-af989f10-524a-4fdf-bcbd-c3442592547a node DatanodeRegistration(127.0.0.1:40556, datanodeUuid=8269cf1e-183a-448f-93f1-8184271cbc73, infoPort=37471, infoSecurePort=0, ipcPort=35876, storageInfo=lv=-57;cid=testClusterID;nsid=249675482;c=1606980201438), blocks: 0, hasStaleStorage: false, processing time: 3 msecs, invalidatedBlocks: 0
2020-12-03 07:23:26,780 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-364049187-172.17.0.4-1606980197868 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-12-03 07:23:26,780 [BP-364049187-172.17.0.4-1606980197868 heartbeating to localhost/127.0.0.1:37672] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-364049187-172.17.0.4-1606980197868 (Datanode Uuid 8269cf1e-183a-448f-93f1-8184271cbc73) service to localhost/127.0.0.1:37672 beginning handshake with NN
2020-12-03 07:23:26,780 [BP-364049187-172.17.0.4-1606980197868 heartbeating to localhost/127.0.0.1:43715] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-364049187-172.17.0.4-1606980197868 (Datanode Uuid 8269cf1e-183a-448f-93f1-8184271cbc73) service to localhost/127.0.0.1:43715 beginning handshake with NN
2020-12-03 07:23:26,780 [BP-339648640-172.17.0.4-1606980201438 heartbeating to localhost/127.0.0.1:46481] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x3ba73c38f3b5fe09,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 21 msec to generate and 4 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:23:26,781 [BP-339648640-172.17.0.4-1606980201438 heartbeating to localhost/127.0.0.1:46572] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xf964418829cf8bec,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 24 msec to generate and 7 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:23:26,781 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-364049187-172.17.0.4-1606980197868 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-12-03 07:23:26,780 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, DS-69da2731-18b4-472d-af70-d73a4d269712): finished scanning block pool BP-364049187-172.17.0.4-1606980197868
2020-12-03 07:23:26,782 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, DS-af989f10-524a-4fdf-bcbd-c3442592547a): finished scanning block pool BP-364049187-172.17.0.4-1606980197868
2020-12-03 07:23:26,783 [IPC Server handler 6 on default port 37672] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:40556, datanodeUuid=8269cf1e-183a-448f-93f1-8184271cbc73, infoPort=37471, infoSecurePort=0, ipcPort=35876, storageInfo=lv=-57;cid=testClusterID;nsid=819413304;c=1606980197868) storage 8269cf1e-183a-448f-93f1-8184271cbc73
2020-12-03 07:23:26,783 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, DS-af989f10-524a-4fdf-bcbd-c3442592547a): no suitable block pools found to scan.  Waiting 1814399921 ms.
2020-12-03 07:23:26,783 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, DS-69da2731-18b4-472d-af70-d73a4d269712): no suitable block pools found to scan.  Waiting 1814399921 ms.
2020-12-03 07:23:26,783 [IPC Server handler 6 on default port 37672] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:40556
2020-12-03 07:23:26,783 [IPC Server handler 6 on default port 37672] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 8269cf1e-183a-448f-93f1-8184271cbc73 (127.0.0.1:40556).
2020-12-03 07:23:26,784 [IPC Server handler 9 on default port 43715] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:40556, datanodeUuid=8269cf1e-183a-448f-93f1-8184271cbc73, infoPort=37471, infoSecurePort=0, ipcPort=35876, storageInfo=lv=-57;cid=testClusterID;nsid=819413304;c=1606980197868) storage 8269cf1e-183a-448f-93f1-8184271cbc73
2020-12-03 07:23:26,784 [BP-364049187-172.17.0.4-1606980197868 heartbeating to localhost/127.0.0.1:37672] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-364049187-172.17.0.4-1606980197868 (Datanode Uuid 8269cf1e-183a-448f-93f1-8184271cbc73) service to localhost/127.0.0.1:37672 successfully registered with NN
2020-12-03 07:23:26,784 [BP-364049187-172.17.0.4-1606980197868 heartbeating to localhost/127.0.0.1:37672] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:37672 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:26,784 [IPC Server handler 9 on default port 43715] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:40556
2020-12-03 07:23:26,786 [IPC Server handler 9 on default port 43715] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 8269cf1e-183a-448f-93f1-8184271cbc73 (127.0.0.1:40556).
2020-12-03 07:23:26,789 [IPC Server handler 8 on default port 37672] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-af989f10-524a-4fdf-bcbd-c3442592547a for DN 127.0.0.1:40556
2020-12-03 07:23:26,790 [IPC Server handler 8 on default port 37672] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-69da2731-18b4-472d-af70-d73a4d269712 for DN 127.0.0.1:40556
2020-12-03 07:23:26,790 [BP-364049187-172.17.0.4-1606980197868 heartbeating to localhost/127.0.0.1:43715] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-364049187-172.17.0.4-1606980197868 (Datanode Uuid 8269cf1e-183a-448f-93f1-8184271cbc73) service to localhost/127.0.0.1:43715 successfully registered with NN
2020-12-03 07:23:26,794 [BP-364049187-172.17.0.4-1606980197868 heartbeating to localhost/127.0.0.1:43715] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:43715 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:26,797 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x702a9eee70542100: Processing first storage report for DS-69da2731-18b4-472d-af70-d73a4d269712 from datanode 8269cf1e-183a-448f-93f1-8184271cbc73
2020-12-03 07:23:26,797 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x702a9eee70542100: from storage DS-69da2731-18b4-472d-af70-d73a4d269712 node DatanodeRegistration(127.0.0.1:40556, datanodeUuid=8269cf1e-183a-448f-93f1-8184271cbc73, infoPort=37471, infoSecurePort=0, ipcPort=35876, storageInfo=lv=-57;cid=testClusterID;nsid=819413304;c=1606980197868), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:26,802 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x702a9eee70542100: Processing first storage report for DS-af989f10-524a-4fdf-bcbd-c3442592547a from datanode 8269cf1e-183a-448f-93f1-8184271cbc73
2020-12-03 07:23:26,802 [IPC Server handler 4 on default port 43715] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-af989f10-524a-4fdf-bcbd-c3442592547a for DN 127.0.0.1:40556
2020-12-03 07:23:26,802 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x702a9eee70542100: from storage DS-af989f10-524a-4fdf-bcbd-c3442592547a node DatanodeRegistration(127.0.0.1:40556, datanodeUuid=8269cf1e-183a-448f-93f1-8184271cbc73, infoPort=37471, infoSecurePort=0, ipcPort=35876, storageInfo=lv=-57;cid=testClusterID;nsid=819413304;c=1606980197868), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:26,802 [IPC Server handler 4 on default port 43715] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-69da2731-18b4-472d-af70-d73a4d269712 for DN 127.0.0.1:40556
2020-12-03 07:23:26,803 [BP-364049187-172.17.0.4-1606980197868 heartbeating to localhost/127.0.0.1:37672] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x702a9eee70542100,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 8 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:23:26,805 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x35f0fd00a59daea3: Processing first storage report for DS-69da2731-18b4-472d-af70-d73a4d269712 from datanode 8269cf1e-183a-448f-93f1-8184271cbc73
2020-12-03 07:23:26,806 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x35f0fd00a59daea3: from storage DS-69da2731-18b4-472d-af70-d73a4d269712 node DatanodeRegistration(127.0.0.1:40556, datanodeUuid=8269cf1e-183a-448f-93f1-8184271cbc73, infoPort=37471, infoSecurePort=0, ipcPort=35876, storageInfo=lv=-57;cid=testClusterID;nsid=819413304;c=1606980197868), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:26,806 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x35f0fd00a59daea3: Processing first storage report for DS-af989f10-524a-4fdf-bcbd-c3442592547a from datanode 8269cf1e-183a-448f-93f1-8184271cbc73
2020-12-03 07:23:26,806 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x35f0fd00a59daea3: from storage DS-af989f10-524a-4fdf-bcbd-c3442592547a node DatanodeRegistration(127.0.0.1:40556, datanodeUuid=8269cf1e-183a-448f-93f1-8184271cbc73, infoPort=37471, infoSecurePort=0, ipcPort=35876, storageInfo=lv=-57;cid=testClusterID;nsid=819413304;c=1606980197868), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:26,807 [BP-364049187-172.17.0.4-1606980197868 heartbeating to localhost/127.0.0.1:43715] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x35f0fd00a59daea3,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:23:26,816 [Thread-235] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 422a8715-c24d-4fa3-b4bc-e1d088dbe0b9
2020-12-03 07:23:26,820 [Thread-235] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-66f4b598-9e1f-40c2-953a-7cb1d43b2313
2020-12-03 07:23:26,825 [Thread-235] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, StorageType: DISK
2020-12-03 07:23:26,827 [Thread-235] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-62001e65-5365-4f09-80bb-cbaab70b49b7
2020-12-03 07:23:26,827 [Thread-235] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, StorageType: DISK
2020-12-03 07:23:26,827 [Thread-235] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:23:26,828 [Thread-237] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7
2020-12-03 07:23:26,828 [Thread-235] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7
2020-12-03 07:23:26,830 [Thread-237] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7
2020-12-03 07:23:26,830 [Thread-237] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-12-03 07:23:26,831 [Thread-237] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-12-03 07:23:26,832 [Thread-235] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7
2020-12-03 07:23:26,833 [Thread-235] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-12-03 07:23:26,833 [Thread-237] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-339648640-172.17.0.4-1606980201438
2020-12-03 07:23:26,833 [Thread-235] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-364049187-172.17.0.4-1606980197868
2020-12-03 07:23:26,833 [Thread-302] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-339648640-172.17.0.4-1606980201438 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7...
2020-12-03 07:23:26,833 [Thread-303] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-339648640-172.17.0.4-1606980201438 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8...
2020-12-03 07:23:26,887 [Thread-303] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-339648640-172.17.0.4-1606980201438 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8: 54ms
2020-12-03 07:23:26,888 [Thread-302] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-339648640-172.17.0.4-1606980201438 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7: 55ms
2020-12-03 07:23:26,890 [Thread-237] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-339648640-172.17.0.4-1606980201438: 58ms
2020-12-03 07:23:26,891 [Thread-307] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-339648640-172.17.0.4-1606980201438 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7...
2020-12-03 07:23:26,891 [Thread-307] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-339648640-172.17.0.4-1606980201438/current/replicas doesn't exist 
2020-12-03 07:23:26,891 [Thread-308] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-364049187-172.17.0.4-1606980197868 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7...
2020-12-03 07:23:26,891 [Thread-310] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-364049187-172.17.0.4-1606980197868 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8...
2020-12-03 07:23:26,891 [Thread-307] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-339648640-172.17.0.4-1606980201438 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7: 1ms
2020-12-03 07:23:26,892 [Thread-309] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-339648640-172.17.0.4-1606980201438 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8...
2020-12-03 07:23:26,892 [Thread-309] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-339648640-172.17.0.4-1606980201438/current/replicas doesn't exist 
2020-12-03 07:23:26,893 [Thread-309] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-339648640-172.17.0.4-1606980201438 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8: 1ms
2020-12-03 07:23:26,893 [Thread-237] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-339648640-172.17.0.4-1606980201438: 2ms
2020-12-03 07:23:26,895 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-339648640-172.17.0.4-1606980201438 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7
2020-12-03 07:23:26,896 [Thread-237] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 1:12 PM with interval of 21600000ms
2020-12-03 07:23:26,896 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, DS-66f4b598-9e1f-40c2-953a-7cb1d43b2313): finished scanning block pool BP-339648640-172.17.0.4-1606980201438
2020-12-03 07:23:26,897 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, DS-66f4b598-9e1f-40c2-953a-7cb1d43b2313): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-12-03 07:23:26,897 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-339648640-172.17.0.4-1606980201438 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-12-03 07:23:26,897 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, DS-62001e65-5365-4f09-80bb-cbaab70b49b7): finished scanning block pool BP-339648640-172.17.0.4-1606980201438
2020-12-03 07:23:26,898 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, DS-62001e65-5365-4f09-80bb-cbaab70b49b7): no suitable block pools found to scan.  Waiting 1814399997 ms.
2020-12-03 07:23:26,914 [BP-339648640-172.17.0.4-1606980201438 heartbeating to localhost/127.0.0.1:46481] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-339648640-172.17.0.4-1606980201438 (Datanode Uuid 422a8715-c24d-4fa3-b4bc-e1d088dbe0b9) service to localhost/127.0.0.1:46481 beginning handshake with NN
2020-12-03 07:23:26,915 [BP-339648640-172.17.0.4-1606980201438 heartbeating to localhost/127.0.0.1:46572] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-339648640-172.17.0.4-1606980201438 (Datanode Uuid 422a8715-c24d-4fa3-b4bc-e1d088dbe0b9) service to localhost/127.0.0.1:46572 beginning handshake with NN
2020-12-03 07:23:26,916 [IPC Server handler 1 on default port 46481] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:32817, datanodeUuid=422a8715-c24d-4fa3-b4bc-e1d088dbe0b9, infoPort=37472, infoSecurePort=0, ipcPort=45538, storageInfo=lv=-57;cid=testClusterID;nsid=249675482;c=1606980201438) storage 422a8715-c24d-4fa3-b4bc-e1d088dbe0b9
2020-12-03 07:23:26,926 [IPC Server handler 1 on default port 46481] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:32817
2020-12-03 07:23:26,926 [IPC Server handler 1 on default port 46481] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 422a8715-c24d-4fa3-b4bc-e1d088dbe0b9 (127.0.0.1:32817).
2020-12-03 07:23:26,926 [IPC Server handler 4 on default port 46572] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:32817, datanodeUuid=422a8715-c24d-4fa3-b4bc-e1d088dbe0b9, infoPort=37472, infoSecurePort=0, ipcPort=45538, storageInfo=lv=-57;cid=testClusterID;nsid=249675482;c=1606980201438) storage 422a8715-c24d-4fa3-b4bc-e1d088dbe0b9
2020-12-03 07:23:26,926 [IPC Server handler 4 on default port 46572] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:32817
2020-12-03 07:23:26,927 [IPC Server handler 4 on default port 46572] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 422a8715-c24d-4fa3-b4bc-e1d088dbe0b9 (127.0.0.1:32817).
2020-12-03 07:23:26,927 [BP-339648640-172.17.0.4-1606980201438 heartbeating to localhost/127.0.0.1:46481] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-339648640-172.17.0.4-1606980201438 (Datanode Uuid 422a8715-c24d-4fa3-b4bc-e1d088dbe0b9) service to localhost/127.0.0.1:46481 successfully registered with NN
2020-12-03 07:23:26,927 [BP-339648640-172.17.0.4-1606980201438 heartbeating to localhost/127.0.0.1:46481] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:46481 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:26,928 [BP-339648640-172.17.0.4-1606980201438 heartbeating to localhost/127.0.0.1:46572] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-339648640-172.17.0.4-1606980201438 (Datanode Uuid 422a8715-c24d-4fa3-b4bc-e1d088dbe0b9) service to localhost/127.0.0.1:46572 successfully registered with NN
2020-12-03 07:23:26,928 [BP-339648640-172.17.0.4-1606980201438 heartbeating to localhost/127.0.0.1:46572] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:46572 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:26,948 [IPC Server handler 5 on default port 46481] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-66f4b598-9e1f-40c2-953a-7cb1d43b2313 for DN 127.0.0.1:32817
2020-12-03 07:23:26,949 [IPC Server handler 5 on default port 46481] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-62001e65-5365-4f09-80bb-cbaab70b49b7 for DN 127.0.0.1:32817
2020-12-03 07:23:26,952 [IPC Server handler 6 on default port 46572] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-66f4b598-9e1f-40c2-953a-7cb1d43b2313 for DN 127.0.0.1:32817
2020-12-03 07:23:26,952 [IPC Server handler 6 on default port 46572] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-62001e65-5365-4f09-80bb-cbaab70b49b7 for DN 127.0.0.1:32817
2020-12-03 07:23:26,953 [Thread-308] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-364049187-172.17.0.4-1606980197868 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7: 61ms
2020-12-03 07:23:26,962 [Thread-310] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-364049187-172.17.0.4-1606980197868 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8: 71ms
2020-12-03 07:23:26,963 [Thread-235] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-364049187-172.17.0.4-1606980197868: 72ms
2020-12-03 07:23:26,964 [Thread-318] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-364049187-172.17.0.4-1606980197868 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7...
2020-12-03 07:23:26,964 [Thread-318] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-364049187-172.17.0.4-1606980197868/current/replicas doesn't exist 
2020-12-03 07:23:26,964 [Thread-319] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-364049187-172.17.0.4-1606980197868 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8...
2020-12-03 07:23:26,965 [Thread-319] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-364049187-172.17.0.4-1606980197868/current/replicas doesn't exist 
2020-12-03 07:23:26,965 [Thread-318] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-364049187-172.17.0.4-1606980197868 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7: 1ms
2020-12-03 07:23:26,965 [Thread-319] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-364049187-172.17.0.4-1606980197868 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8: 1ms
2020-12-03 07:23:26,965 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xa2e4dcfcd0a357c8: Processing first storage report for DS-66f4b598-9e1f-40c2-953a-7cb1d43b2313 from datanode 422a8715-c24d-4fa3-b4bc-e1d088dbe0b9
2020-12-03 07:23:26,966 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xa2e4dcfcd0a357c8: from storage DS-66f4b598-9e1f-40c2-953a-7cb1d43b2313 node DatanodeRegistration(127.0.0.1:32817, datanodeUuid=422a8715-c24d-4fa3-b4bc-e1d088dbe0b9, infoPort=37472, infoSecurePort=0, ipcPort=45538, storageInfo=lv=-57;cid=testClusterID;nsid=249675482;c=1606980201438), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:26,965 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x5db5494422557c50: Processing first storage report for DS-66f4b598-9e1f-40c2-953a-7cb1d43b2313 from datanode 422a8715-c24d-4fa3-b4bc-e1d088dbe0b9
2020-12-03 07:23:26,966 [Thread-235] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-364049187-172.17.0.4-1606980197868: 2ms
2020-12-03 07:23:26,966 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x5db5494422557c50: from storage DS-66f4b598-9e1f-40c2-953a-7cb1d43b2313 node DatanodeRegistration(127.0.0.1:32817, datanodeUuid=422a8715-c24d-4fa3-b4bc-e1d088dbe0b9, infoPort=37472, infoSecurePort=0, ipcPort=45538, storageInfo=lv=-57;cid=testClusterID;nsid=249675482;c=1606980201438), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:26,966 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-364049187-172.17.0.4-1606980197868 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-12-03 07:23:26,966 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-364049187-172.17.0.4-1606980197868 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7
2020-12-03 07:23:26,966 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x5db5494422557c50: Processing first storage report for DS-62001e65-5365-4f09-80bb-cbaab70b49b7 from datanode 422a8715-c24d-4fa3-b4bc-e1d088dbe0b9
2020-12-03 07:23:26,967 [BP-364049187-172.17.0.4-1606980197868 heartbeating to localhost/127.0.0.1:37672] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-364049187-172.17.0.4-1606980197868 (Datanode Uuid 422a8715-c24d-4fa3-b4bc-e1d088dbe0b9) service to localhost/127.0.0.1:37672 beginning handshake with NN
2020-12-03 07:23:26,967 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xa2e4dcfcd0a357c8: Processing first storage report for DS-62001e65-5365-4f09-80bb-cbaab70b49b7 from datanode 422a8715-c24d-4fa3-b4bc-e1d088dbe0b9
2020-12-03 07:23:26,967 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xa2e4dcfcd0a357c8: from storage DS-62001e65-5365-4f09-80bb-cbaab70b49b7 node DatanodeRegistration(127.0.0.1:32817, datanodeUuid=422a8715-c24d-4fa3-b4bc-e1d088dbe0b9, infoPort=37472, infoSecurePort=0, ipcPort=45538, storageInfo=lv=-57;cid=testClusterID;nsid=249675482;c=1606980201438), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:26,967 [BP-364049187-172.17.0.4-1606980197868 heartbeating to localhost/127.0.0.1:43715] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-364049187-172.17.0.4-1606980197868 (Datanode Uuid 422a8715-c24d-4fa3-b4bc-e1d088dbe0b9) service to localhost/127.0.0.1:43715 beginning handshake with NN
2020-12-03 07:23:26,967 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x5db5494422557c50: from storage DS-62001e65-5365-4f09-80bb-cbaab70b49b7 node DatanodeRegistration(127.0.0.1:32817, datanodeUuid=422a8715-c24d-4fa3-b4bc-e1d088dbe0b9, infoPort=37472, infoSecurePort=0, ipcPort=45538, storageInfo=lv=-57;cid=testClusterID;nsid=249675482;c=1606980201438), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:26,968 [IPC Server handler 7 on default port 37672] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:32817, datanodeUuid=422a8715-c24d-4fa3-b4bc-e1d088dbe0b9, infoPort=37472, infoSecurePort=0, ipcPort=45538, storageInfo=lv=-57;cid=testClusterID;nsid=819413304;c=1606980197868) storage 422a8715-c24d-4fa3-b4bc-e1d088dbe0b9
2020-12-03 07:23:26,967 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, DS-66f4b598-9e1f-40c2-953a-7cb1d43b2313): finished scanning block pool BP-364049187-172.17.0.4-1606980197868
2020-12-03 07:23:26,967 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, DS-62001e65-5365-4f09-80bb-cbaab70b49b7): finished scanning block pool BP-364049187-172.17.0.4-1606980197868
2020-12-03 07:23:26,969 [BP-339648640-172.17.0.4-1606980201438 heartbeating to localhost/127.0.0.1:46481] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x5db5494422557c50,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 13 msec to generate and 5 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:23:26,969 [BP-339648640-172.17.0.4-1606980201438 heartbeating to localhost/127.0.0.1:46572] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xa2e4dcfcd0a357c8,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 10 msec to generate and 6 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:23:26,969 [IPC Server handler 7 on default port 37672] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:32817
2020-12-03 07:23:26,979 [IPC Server handler 7 on default port 37672] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 422a8715-c24d-4fa3-b4bc-e1d088dbe0b9 (127.0.0.1:32817).
2020-12-03 07:23:26,981 [BP-364049187-172.17.0.4-1606980197868 heartbeating to localhost/127.0.0.1:37672] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-364049187-172.17.0.4-1606980197868 (Datanode Uuid 422a8715-c24d-4fa3-b4bc-e1d088dbe0b9) service to localhost/127.0.0.1:37672 successfully registered with NN
2020-12-03 07:23:26,981 [BP-364049187-172.17.0.4-1606980197868 heartbeating to localhost/127.0.0.1:37672] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:37672 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:26,984 [IPC Server handler 7 on default port 43715] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:32817, datanodeUuid=422a8715-c24d-4fa3-b4bc-e1d088dbe0b9, infoPort=37472, infoSecurePort=0, ipcPort=45538, storageInfo=lv=-57;cid=testClusterID;nsid=819413304;c=1606980197868) storage 422a8715-c24d-4fa3-b4bc-e1d088dbe0b9
2020-12-03 07:23:26,984 [IPC Server handler 7 on default port 43715] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:32817
2020-12-03 07:23:26,985 [IPC Server handler 7 on default port 43715] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 422a8715-c24d-4fa3-b4bc-e1d088dbe0b9 (127.0.0.1:32817).
2020-12-03 07:23:26,986 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, DS-62001e65-5365-4f09-80bb-cbaab70b49b7): no suitable block pools found to scan.  Waiting 1814399909 ms.
2020-12-03 07:23:26,986 [BP-364049187-172.17.0.4-1606980197868 heartbeating to localhost/127.0.0.1:43715] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-364049187-172.17.0.4-1606980197868 (Datanode Uuid 422a8715-c24d-4fa3-b4bc-e1d088dbe0b9) service to localhost/127.0.0.1:43715 successfully registered with NN
2020-12-03 07:23:26,986 [BP-364049187-172.17.0.4-1606980197868 heartbeating to localhost/127.0.0.1:43715] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:43715 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:23:26,992 [IPC Server handler 3 on default port 37672] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-66f4b598-9e1f-40c2-953a-7cb1d43b2313 for DN 127.0.0.1:32817
2020-12-03 07:23:26,992 [IPC Server handler 3 on default port 37672] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-62001e65-5365-4f09-80bb-cbaab70b49b7 for DN 127.0.0.1:32817
2020-12-03 07:23:26,992 [IPC Server handler 5 on default port 43715] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-66f4b598-9e1f-40c2-953a-7cb1d43b2313 for DN 127.0.0.1:32817
2020-12-03 07:23:26,993 [IPC Server handler 5 on default port 43715] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-62001e65-5365-4f09-80bb-cbaab70b49b7 for DN 127.0.0.1:32817
2020-12-03 07:23:26,994 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, DS-66f4b598-9e1f-40c2-953a-7cb1d43b2313): no suitable block pools found to scan.  Waiting 1814399901 ms.
2020-12-03 07:23:27,004 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x3b84a5cd5dc4f52: Processing first storage report for DS-66f4b598-9e1f-40c2-953a-7cb1d43b2313 from datanode 422a8715-c24d-4fa3-b4bc-e1d088dbe0b9
2020-12-03 07:23:27,004 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x3b84a5cd5dc4f52: from storage DS-66f4b598-9e1f-40c2-953a-7cb1d43b2313 node DatanodeRegistration(127.0.0.1:32817, datanodeUuid=422a8715-c24d-4fa3-b4bc-e1d088dbe0b9, infoPort=37472, infoSecurePort=0, ipcPort=45538, storageInfo=lv=-57;cid=testClusterID;nsid=819413304;c=1606980197868), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:27,004 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x3b84a5cd5dc4f52: Processing first storage report for DS-62001e65-5365-4f09-80bb-cbaab70b49b7 from datanode 422a8715-c24d-4fa3-b4bc-e1d088dbe0b9
2020-12-03 07:23:27,004 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x3b84a5cd5dc4f52: from storage DS-62001e65-5365-4f09-80bb-cbaab70b49b7 node DatanodeRegistration(127.0.0.1:32817, datanodeUuid=422a8715-c24d-4fa3-b4bc-e1d088dbe0b9, infoPort=37472, infoSecurePort=0, ipcPort=45538, storageInfo=lv=-57;cid=testClusterID;nsid=819413304;c=1606980197868), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:27,005 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xfffb2ddda0a71b7a: Processing first storage report for DS-66f4b598-9e1f-40c2-953a-7cb1d43b2313 from datanode 422a8715-c24d-4fa3-b4bc-e1d088dbe0b9
2020-12-03 07:23:27,005 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xfffb2ddda0a71b7a: from storage DS-66f4b598-9e1f-40c2-953a-7cb1d43b2313 node DatanodeRegistration(127.0.0.1:32817, datanodeUuid=422a8715-c24d-4fa3-b4bc-e1d088dbe0b9, infoPort=37472, infoSecurePort=0, ipcPort=45538, storageInfo=lv=-57;cid=testClusterID;nsid=819413304;c=1606980197868), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:27,005 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xfffb2ddda0a71b7a: Processing first storage report for DS-62001e65-5365-4f09-80bb-cbaab70b49b7 from datanode 422a8715-c24d-4fa3-b4bc-e1d088dbe0b9
2020-12-03 07:23:27,005 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xfffb2ddda0a71b7a: from storage DS-62001e65-5365-4f09-80bb-cbaab70b49b7 node DatanodeRegistration(127.0.0.1:32817, datanodeUuid=422a8715-c24d-4fa3-b4bc-e1d088dbe0b9, infoPort=37472, infoSecurePort=0, ipcPort=45538, storageInfo=lv=-57;cid=testClusterID;nsid=819413304;c=1606980197868), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:23:27,006 [BP-364049187-172.17.0.4-1606980197868 heartbeating to localhost/127.0.0.1:43715] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x3b84a5cd5dc4f52,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 12 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:23:27,006 [BP-364049187-172.17.0.4-1606980197868 heartbeating to localhost/127.0.0.1:37672] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xfffb2ddda0a71b7a,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 12 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:23:27,043 [IPC Server handler 1 on default port 37672] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:27,092 [IPC Server handler 0 on default port 43715] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:27,101 [IPC Server handler 1 on default port 46572] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:27,117 [IPC Server handler 4 on default port 46481] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:27,119 [Listener at localhost/45538] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:23:27,137 [IPC Server handler 4 on default port 37672] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:27,142 [IPC Server handler 2 on default port 43715] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:27,151 [IPC Server handler 2 on default port 46572] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:27,170 [IPC Server handler 9 on default port 46481] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:27,181 [Listener at localhost/45538] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:23:27,238 [Listener at localhost/45538] INFO  router.RouterRpcServer (RouterRpcServer.java:<init>(251)) - RPC server binding to /0.0.0.0:0 with 10 handlers for Router null
2020-12-03 07:23:27,240 [Listener at localhost/45538] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:27,240 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:27,250 [Listener at 0.0.0.0/37854] INFO  router.ConnectionManager (ConnectionManager.java:<init>(120)) - Cleaning connection pools every 60 seconds
2020-12-03 07:23:27,251 [Listener at 0.0.0.0/37854] INFO  router.ConnectionManager (ConnectionManager.java:<init>(125)) - Cleaning connections every 10 seconds
2020-12-03 07:23:27,251 [Listener at 0.0.0.0/37854] INFO  router.ConnectionManager (ConnectionManager.java:start(139)) - Cleaning every 10 seconds
2020-12-03 07:23:27,275 [Listener at 0.0.0.0/37854] INFO  router.RouterAdminServer (RouterAdminServer.java:<init>(132)) - Admin server binding to 0.0.0.0:0
2020-12-03 07:23:27,276 [Listener at 0.0.0.0/37854] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 100, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:27,276 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:27,282 [Listener at 0.0.0.0/40841] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns0
2020-12-03 07:23:27,285 [Listener at 0.0.0.0/40841] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns0
2020-12-03 07:23:27,285 [Listener at 0.0.0.0/40841] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns0
2020-12-03 07:23:27,285 [Listener at 0.0.0.0/40841] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns1
2020-12-03 07:23:27,285 [Listener at 0.0.0.0/40841] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns1
2020-12-03 07:23:27,287 [Listener at 0.0.0.0/40841] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - Router metrics system started (again)
2020-12-03 07:23:27,303 [Listener at 0.0.0.0/40841] INFO  store.StateStoreService (StateStoreService.java:serviceInit(185)) - Registered StateStoreMBean: Hadoop:service=Router,name=StateStore
2020-12-03 07:23:27,303 [Listener at 0.0.0.0/40841] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.federation.router.cache.ttl(5000) assuming MILLISECONDS
2020-12-03 07:23:27,311 [Listener at 0.0.0.0/40841] INFO  metrics.FederationRPCPerformanceMonitor (FederationRPCPerformanceMonitor.java:init(91)) - Registered FederationRPCMBean: Hadoop:service=Router,name=FederationRPC
2020-12-03 07:23:27,318 [Listener at 0.0.0.0/40841] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn0 RPC address: 127.0.0.1:46572
2020-12-03 07:23:27,319 [Listener at 0.0.0.0/40841] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn0 Service RPC address: 127.0.0.1:46572
2020-12-03 07:23:27,319 [Listener at 0.0.0.0/40841] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn0 Lifeline RPC address: 127.0.0.1:46572
2020-12-03 07:23:27,319 [Listener at 0.0.0.0/40841] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn0 Web address: 127.0.0.1:33934
2020-12-03 07:23:27,320 [Listener at 0.0.0.0/40841] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn0 RPC address: 127.0.0.1:37672
2020-12-03 07:23:27,321 [Listener at 0.0.0.0/40841] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn0 Service RPC address: 127.0.0.1:37672
2020-12-03 07:23:27,321 [Listener at 0.0.0.0/40841] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn0 Lifeline RPC address: 127.0.0.1:37672
2020-12-03 07:23:27,321 [Listener at 0.0.0.0/40841] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn0 Web address: 127.0.0.1:42523
2020-12-03 07:23:27,322 [Listener at 0.0.0.0/40841] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn1 RPC address: 127.0.0.1:46481
2020-12-03 07:23:27,322 [Listener at 0.0.0.0/40841] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn1 Service RPC address: 127.0.0.1:46481
2020-12-03 07:23:27,322 [Listener at 0.0.0.0/40841] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn1 Lifeline RPC address: 127.0.0.1:46481
2020-12-03 07:23:27,322 [Listener at 0.0.0.0/40841] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn1 Web address: 127.0.0.1:41423
2020-12-03 07:23:27,323 [Listener at 0.0.0.0/40841] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn1 RPC address: 127.0.0.1:43715
2020-12-03 07:23:27,323 [Listener at 0.0.0.0/40841] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn1 Service RPC address: 127.0.0.1:43715
2020-12-03 07:23:27,323 [Listener at 0.0.0.0/40841] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn1 Lifeline RPC address: 127.0.0.1:43715
2020-12-03 07:23:27,323 [Listener at 0.0.0.0/40841] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn1 Web address: 127.0.0.1:34569
2020-12-03 07:23:27,339 [Listener at 0.0.0.0/40841] INFO  router.RouterRpcServer (RouterRpcServer.java:<init>(251)) - RPC server binding to /0.0.0.0:0 with 10 handlers for Router null
2020-12-03 07:23:27,340 [Listener at 0.0.0.0/40841] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:27,341 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:27,345 [Listener at 0.0.0.0/46386] INFO  router.ConnectionManager (ConnectionManager.java:<init>(120)) - Cleaning connection pools every 60 seconds
2020-12-03 07:23:27,345 [Listener at 0.0.0.0/46386] INFO  router.ConnectionManager (ConnectionManager.java:<init>(125)) - Cleaning connections every 10 seconds
2020-12-03 07:23:27,345 [Listener at 0.0.0.0/46386] INFO  router.ConnectionManager (ConnectionManager.java:start(139)) - Cleaning every 10 seconds
2020-12-03 07:23:27,347 [Listener at 0.0.0.0/46386] INFO  router.RouterAdminServer (RouterAdminServer.java:<init>(132)) - Admin server binding to 0.0.0.0:0
2020-12-03 07:23:27,347 [Listener at 0.0.0.0/46386] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 100, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:27,348 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:27,359 [Listener at 0.0.0.0/40156] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns0
2020-12-03 07:23:27,359 [Listener at 0.0.0.0/40156] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns0
2020-12-03 07:23:27,359 [Listener at 0.0.0.0/40156] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns0
2020-12-03 07:23:27,359 [Listener at 0.0.0.0/40156] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns1
2020-12-03 07:23:27,360 [Listener at 0.0.0.0/40156] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns1
2020-12-03 07:23:27,360 [Listener at 0.0.0.0/40156] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - Router metrics system started (again)
2020-12-03 07:23:27,362 [Listener at 0.0.0.0/40156] INFO  store.StateStoreService (StateStoreService.java:serviceInit(185)) - Registered StateStoreMBean: Hadoop:service=Router,name=StateStore-1
2020-12-03 07:23:27,362 [Listener at 0.0.0.0/40156] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.federation.router.cache.ttl(5000) assuming MILLISECONDS
2020-12-03 07:23:27,364 [Listener at 0.0.0.0/40156] INFO  metrics.FederationRPCPerformanceMonitor (FederationRPCPerformanceMonitor.java:init(91)) - Registered FederationRPCMBean: Hadoop:service=Router,name=FederationRPC-1
2020-12-03 07:23:27,365 [Listener at 0.0.0.0/40156] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn0 RPC address: 127.0.0.1:46572
2020-12-03 07:23:27,365 [Listener at 0.0.0.0/40156] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn0 Service RPC address: 127.0.0.1:46572
2020-12-03 07:23:27,365 [Listener at 0.0.0.0/40156] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn0 Lifeline RPC address: 127.0.0.1:46572
2020-12-03 07:23:27,365 [Listener at 0.0.0.0/40156] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn0 Web address: 127.0.0.1:33934
2020-12-03 07:23:27,366 [Listener at 0.0.0.0/40156] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn0 RPC address: 127.0.0.1:37672
2020-12-03 07:23:27,366 [Listener at 0.0.0.0/40156] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn0 Service RPC address: 127.0.0.1:37672
2020-12-03 07:23:27,366 [Listener at 0.0.0.0/40156] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn0 Lifeline RPC address: 127.0.0.1:37672
2020-12-03 07:23:27,367 [Listener at 0.0.0.0/40156] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn0 Web address: 127.0.0.1:42523
2020-12-03 07:23:27,367 [Listener at 0.0.0.0/40156] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn1 RPC address: 127.0.0.1:46481
2020-12-03 07:23:27,367 [Listener at 0.0.0.0/40156] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn1 Service RPC address: 127.0.0.1:46481
2020-12-03 07:23:27,368 [Listener at 0.0.0.0/40156] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn1 Lifeline RPC address: 127.0.0.1:46481
2020-12-03 07:23:27,368 [Listener at 0.0.0.0/40156] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn1 Web address: 127.0.0.1:41423
2020-12-03 07:23:27,369 [Listener at 0.0.0.0/40156] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn1 RPC address: 127.0.0.1:43715
2020-12-03 07:23:27,369 [Listener at 0.0.0.0/40156] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn1 Service RPC address: 127.0.0.1:43715
2020-12-03 07:23:27,369 [Listener at 0.0.0.0/40156] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn1 Lifeline RPC address: 127.0.0.1:43715
2020-12-03 07:23:27,369 [Listener at 0.0.0.0/40156] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn1 Web address: 127.0.0.1:34569
2020-12-03 07:23:27,389 [Listener at 0.0.0.0/40156] INFO  router.RouterRpcServer (RouterRpcServer.java:<init>(251)) - RPC server binding to /0.0.0.0:0 with 10 handlers for Router null
2020-12-03 07:23:27,391 [Listener at 0.0.0.0/40156] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:27,392 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:27,412 [Listener at 0.0.0.0/46735] INFO  router.ConnectionManager (ConnectionManager.java:<init>(120)) - Cleaning connection pools every 60 seconds
2020-12-03 07:23:27,412 [Listener at 0.0.0.0/46735] INFO  router.ConnectionManager (ConnectionManager.java:<init>(125)) - Cleaning connections every 10 seconds
2020-12-03 07:23:27,415 [Listener at 0.0.0.0/46735] INFO  router.ConnectionManager (ConnectionManager.java:start(139)) - Cleaning every 10 seconds
2020-12-03 07:23:27,417 [Listener at 0.0.0.0/46735] INFO  router.RouterAdminServer (RouterAdminServer.java:<init>(132)) - Admin server binding to 0.0.0.0:0
2020-12-03 07:23:27,417 [Listener at 0.0.0.0/46735] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 100, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:27,418 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:27,424 [Listener at 0.0.0.0/41625] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns1
2020-12-03 07:23:27,424 [Listener at 0.0.0.0/41625] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns0
2020-12-03 07:23:27,424 [Listener at 0.0.0.0/41625] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns0
2020-12-03 07:23:27,425 [Listener at 0.0.0.0/41625] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns1
2020-12-03 07:23:27,425 [Listener at 0.0.0.0/41625] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns1
2020-12-03 07:23:27,425 [Listener at 0.0.0.0/41625] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - Router metrics system started (again)
2020-12-03 07:23:27,427 [Listener at 0.0.0.0/41625] INFO  store.StateStoreService (StateStoreService.java:serviceInit(185)) - Registered StateStoreMBean: Hadoop:service=Router,name=StateStore-2
2020-12-03 07:23:27,427 [Listener at 0.0.0.0/41625] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.federation.router.cache.ttl(5000) assuming MILLISECONDS
2020-12-03 07:23:27,429 [Listener at 0.0.0.0/41625] INFO  metrics.FederationRPCPerformanceMonitor (FederationRPCPerformanceMonitor.java:init(91)) - Registered FederationRPCMBean: Hadoop:service=Router,name=FederationRPC-2
2020-12-03 07:23:27,430 [Listener at 0.0.0.0/41625] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn0 RPC address: 127.0.0.1:46572
2020-12-03 07:23:27,430 [Listener at 0.0.0.0/41625] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn0 Service RPC address: 127.0.0.1:46572
2020-12-03 07:23:27,430 [Listener at 0.0.0.0/41625] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn0 Lifeline RPC address: 127.0.0.1:46572
2020-12-03 07:23:27,430 [Listener at 0.0.0.0/41625] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn0 Web address: 127.0.0.1:33934
2020-12-03 07:23:27,431 [Listener at 0.0.0.0/41625] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn0 RPC address: 127.0.0.1:37672
2020-12-03 07:23:27,431 [Listener at 0.0.0.0/41625] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn0 Service RPC address: 127.0.0.1:37672
2020-12-03 07:23:27,431 [Listener at 0.0.0.0/41625] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn0 Lifeline RPC address: 127.0.0.1:37672
2020-12-03 07:23:27,431 [Listener at 0.0.0.0/41625] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn0 Web address: 127.0.0.1:42523
2020-12-03 07:23:27,432 [Listener at 0.0.0.0/41625] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn1 RPC address: 127.0.0.1:46481
2020-12-03 07:23:27,432 [Listener at 0.0.0.0/41625] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn1 Service RPC address: 127.0.0.1:46481
2020-12-03 07:23:27,433 [Listener at 0.0.0.0/41625] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn1 Lifeline RPC address: 127.0.0.1:46481
2020-12-03 07:23:27,433 [Listener at 0.0.0.0/41625] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn1 Web address: 127.0.0.1:41423
2020-12-03 07:23:27,434 [Listener at 0.0.0.0/41625] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn1 RPC address: 127.0.0.1:43715
2020-12-03 07:23:27,434 [Listener at 0.0.0.0/41625] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn1 Service RPC address: 127.0.0.1:43715
2020-12-03 07:23:27,435 [Listener at 0.0.0.0/41625] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn1 Lifeline RPC address: 127.0.0.1:43715
2020-12-03 07:23:27,435 [Listener at 0.0.0.0/41625] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn1 Web address: 127.0.0.1:34569
2020-12-03 07:23:27,457 [Listener at 0.0.0.0/41625] INFO  router.RouterRpcServer (RouterRpcServer.java:<init>(251)) - RPC server binding to /0.0.0.0:0 with 10 handlers for Router null
2020-12-03 07:23:27,458 [Listener at 0.0.0.0/41625] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:27,460 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:27,465 [Listener at 0.0.0.0/43531] INFO  router.ConnectionManager (ConnectionManager.java:<init>(120)) - Cleaning connection pools every 60 seconds
2020-12-03 07:23:27,465 [Listener at 0.0.0.0/43531] INFO  router.ConnectionManager (ConnectionManager.java:<init>(125)) - Cleaning connections every 10 seconds
2020-12-03 07:23:27,466 [Listener at 0.0.0.0/43531] INFO  router.ConnectionManager (ConnectionManager.java:start(139)) - Cleaning every 10 seconds
2020-12-03 07:23:27,467 [Listener at 0.0.0.0/43531] INFO  router.RouterAdminServer (RouterAdminServer.java:<init>(132)) - Admin server binding to 0.0.0.0:0
2020-12-03 07:23:27,469 [Listener at 0.0.0.0/43531] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 100, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:23:27,470 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:23:27,476 [Listener at 0.0.0.0/43610] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns1
2020-12-03 07:23:27,476 [Listener at 0.0.0.0/43610] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns0
2020-12-03 07:23:27,476 [Listener at 0.0.0.0/43610] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns0
2020-12-03 07:23:27,477 [Listener at 0.0.0.0/43610] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns1
2020-12-03 07:23:27,477 [Listener at 0.0.0.0/43610] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns1
2020-12-03 07:23:27,477 [Listener at 0.0.0.0/43610] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - Router metrics system started (again)
2020-12-03 07:23:27,479 [Listener at 0.0.0.0/43610] INFO  store.StateStoreService (StateStoreService.java:serviceInit(185)) - Registered StateStoreMBean: Hadoop:service=Router,name=StateStore-3
2020-12-03 07:23:27,479 [Listener at 0.0.0.0/43610] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.federation.router.cache.ttl(5000) assuming MILLISECONDS
2020-12-03 07:23:27,481 [Listener at 0.0.0.0/43610] INFO  metrics.FederationRPCPerformanceMonitor (FederationRPCPerformanceMonitor.java:init(91)) - Registered FederationRPCMBean: Hadoop:service=Router,name=FederationRPC-3
2020-12-03 07:23:27,482 [Listener at 0.0.0.0/43610] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn0 RPC address: 127.0.0.1:46572
2020-12-03 07:23:27,482 [Listener at 0.0.0.0/43610] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn0 Service RPC address: 127.0.0.1:46572
2020-12-03 07:23:27,482 [Listener at 0.0.0.0/43610] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn0 Lifeline RPC address: 127.0.0.1:46572
2020-12-03 07:23:27,482 [Listener at 0.0.0.0/43610] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn0 Web address: 127.0.0.1:33934
2020-12-03 07:23:27,483 [Listener at 0.0.0.0/43610] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn1 RPC address: 127.0.0.1:46481
2020-12-03 07:23:27,483 [Listener at 0.0.0.0/43610] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn1 Service RPC address: 127.0.0.1:46481
2020-12-03 07:23:27,483 [Listener at 0.0.0.0/43610] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn1 Lifeline RPC address: 127.0.0.1:46481
2020-12-03 07:23:27,484 [Listener at 0.0.0.0/43610] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn1 Web address: 127.0.0.1:41423
2020-12-03 07:23:27,484 [Listener at 0.0.0.0/43610] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn0 RPC address: 127.0.0.1:37672
2020-12-03 07:23:27,484 [Listener at 0.0.0.0/43610] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn0 Service RPC address: 127.0.0.1:37672
2020-12-03 07:23:27,485 [Listener at 0.0.0.0/43610] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn0 Lifeline RPC address: 127.0.0.1:37672
2020-12-03 07:23:27,485 [Listener at 0.0.0.0/43610] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn0 Web address: 127.0.0.1:42523
2020-12-03 07:23:27,485 [Listener at 0.0.0.0/43610] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn1 RPC address: 127.0.0.1:43715
2020-12-03 07:23:27,485 [Listener at 0.0.0.0/43610] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn1 Service RPC address: 127.0.0.1:43715
2020-12-03 07:23:27,486 [Listener at 0.0.0.0/43610] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn1 Lifeline RPC address: 127.0.0.1:43715
2020-12-03 07:23:27,486 [Listener at 0.0.0.0/43610] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn1 Web address: 127.0.0.1:34569
2020-12-03 07:23:27,493 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router aa329fbd28a4:37854: State Store unavailable
2020-12-03 07:23:27,493 [Listener at 0.0.0.0/43610] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-12-03 07:23:27,497 [Listener at 0.0.0.0/43610] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.serviceStart(StateStoreService.java:197)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.service.CompositeService.serviceStart(CompositeService.java:121)
	at org.apache.hadoop.hdfs.server.federation.router.Router.serviceStart(Router.java:265)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.hdfs.server.federation.MiniRouterDFSCluster.startRouters(MiniRouterDFSCluster.java:757)
	at org.apache.hadoop.fs.contract.router.web.RouterWebHDFSContract.createCluster(RouterWebHDFSContract.java:69)
	at org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractSeek.createCluster(TestRouterWebHDFSContractSeek.java:36)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2020-12-03 07:23:27,493 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@68c7ef83] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:27,502 [Listener at 0.0.0.0/43610] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-12-03 07:23:27,503 [Listener at 0.0.0.0/43610] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-12-03 07:23:27,503 [Listener at 0.0.0.0/43610] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreConnectionMonitorService
2020-12-03 07:23:27,505 [Listener at 0.0.0.0/43610] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreCacheUpdateService
2020-12-03 07:23:27,505 [StateStoreConnectionMonitorService-0] INFO  store.StateStoreConnectionMonitorService (StateStoreConnectionMonitorService.java:periodicInvoke(63)) - Attempting to open state store driver.
2020-12-03 07:23:27,506 [StateStoreConnectionMonitorService-0] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-12-03 07:23:27,509 [StateStoreConnectionMonitorService-0] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreConnectionMonitorService.periodicInvoke(StateStoreConnectionMonitorService.java:64)
	at org.apache.hadoop.hdfs.server.federation.router.PeriodicService$1.run(PeriodicService.java:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:23:27,509 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:27,509 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-12-03 07:23:27,509 [StateStoreConnectionMonitorService-0] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-12-03 07:23:27,525 [StateStoreConnectionMonitorService-0] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-12-03 07:23:27,528 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:27,530 [Listener at 0.0.0.0/43610] INFO  router.RouterRpcServer (RouterRpcServer.java:serviceStart(322)) - Router RPC up at: /0.0.0.0:37854
2020-12-03 07:23:27,532 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:27,532 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:27,551 [Listener at 0.0.0.0/43610] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for router at: http://0.0.0.0:0
2020-12-03 07:23:27,552 [Listener at 0.0.0.0/43610] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:27,554 [Listener at 0.0.0.0/43610] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:27,555 [Listener at 0.0.0.0/43610] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.router is not defined
2020-12-03 07:23:27,555 [Listener at 0.0.0.0/43610] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:27,558 [Listener at 0.0.0.0/43610] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:27,559 [Listener at 0.0.0.0/43610] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context router
2020-12-03 07:23:27,559 [Listener at 0.0.0.0/43610] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:27,559 [Listener at 0.0.0.0/43610] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:27,563 [Listener at 0.0.0.0/43610] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:23:27,564 [Listener at 0.0.0.0/43610] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.federation.router;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:23:27,565 [Listener at 0.0.0.0/43610] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 41072
2020-12-03 07:23:27,565 [Listener at 0.0.0.0/43610] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:27,573 [Listener at 0.0.0.0/43610] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@66153688{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:23:27,574 [Listener at 0.0.0.0/43610] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7318daf8{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:27,582 [Listener at 0.0.0.0/43610] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@99407c2{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/router/,AVAILABLE}{/router}
2020-12-03 07:23:27,588 [Listener at 0.0.0.0/43610] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6c796cc1{HTTP/1.1,[http/1.1]}{0.0.0.0:41072}
2020-12-03 07:23:27,588 [Listener at 0.0.0.0/43610] INFO  server.Server (Server.java:doStart(419)) - Started @11630ms
2020-12-03 07:23:27,589 [Listener at 0.0.0.0/43610] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn0
2020-12-03 07:23:27,589 [Listener at 0.0.0.0/43610] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn0
2020-12-03 07:23:27,589 [Listener at 0.0.0.0/43610] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn1
2020-12-03 07:23:27,590 [Listener at 0.0.0.0/43610] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn1
2020-12-03 07:23:27,590 [Listener at 0.0.0.0/43610] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service RouterHeartbeatService
2020-12-03 07:23:27,592 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router aa329fbd28a4:37854: State Store unavailable
2020-12-03 07:23:27,596 [Listener at 0.0.0.0/43610] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(117)) - Registered FSNamesystem MBean: Hadoop:service=NameNode,name=FSNamesystem-4
2020-12-03 07:23:27,597 [Listener at 0.0.0.0/43610] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(126)) - Registered FSNamesystemState MBean: Hadoop:service=NameNode,name=FSNamesystemState-4
2020-12-03 07:23:27,598 [Listener at 0.0.0.0/43610] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(134)) - Registered NameNodeInfo MBean: Hadoop:service=NameNode,name=NameNodeInfo-4
2020-12-03 07:23:27,598 [Listener at 0.0.0.0/43610] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(143)) - Registered NameNodeStatus MBean: Hadoop:service=NameNode,name=NameNodeStatus-4
2020-12-03 07:23:27,604 [Listener at 0.0.0.0/43610] INFO  metrics.FederationMetrics (FederationMetrics.java:<init>(126)) - Registered Router MBean: Hadoop:service=Router,name=FederationState
2020-12-03 07:23:27,605 [Listener at 0.0.0.0/43610] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-12-03 07:23:27,605 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router aa329fbd28a4:46386: State Store unavailable
2020-12-03 07:23:27,605 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@77a2aa4a] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:27,605 [Listener at 0.0.0.0/43610] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.serviceStart(StateStoreService.java:197)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.service.CompositeService.serviceStart(CompositeService.java:121)
	at org.apache.hadoop.hdfs.server.federation.router.Router.serviceStart(Router.java:265)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.hdfs.server.federation.MiniRouterDFSCluster.startRouters(MiniRouterDFSCluster.java:757)
	at org.apache.hadoop.fs.contract.router.web.RouterWebHDFSContract.createCluster(RouterWebHDFSContract.java:69)
	at org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractSeek.createCluster(TestRouterWebHDFSContractSeek.java:36)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2020-12-03 07:23:27,607 [Listener at 0.0.0.0/43610] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-12-03 07:23:27,607 [Listener at 0.0.0.0/43610] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-12-03 07:23:27,607 [Listener at 0.0.0.0/43610] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreConnectionMonitorService
2020-12-03 07:23:27,608 [Listener at 0.0.0.0/43610] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreCacheUpdateService
2020-12-03 07:23:27,608 [StateStoreConnectionMonitorService-0] INFO  store.StateStoreConnectionMonitorService (StateStoreConnectionMonitorService.java:periodicInvoke(63)) - Attempting to open state store driver.
2020-12-03 07:23:27,620 [StateStoreConnectionMonitorService-0] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-12-03 07:23:27,621 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:27,620 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-12-03 07:23:27,623 [Listener at 0.0.0.0/43610] INFO  router.RouterRpcServer (RouterRpcServer.java:serviceStart(322)) - Router RPC up at: /0.0.0.0:46386
2020-12-03 07:23:27,626 [StateStoreConnectionMonitorService-0] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreConnectionMonitorService.periodicInvoke(StateStoreConnectionMonitorService.java:64)
	at org.apache.hadoop.hdfs.server.federation.router.PeriodicService$1.run(PeriodicService.java:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:23:27,623 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:27,628 [StateStoreConnectionMonitorService-0] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-12-03 07:23:27,631 [StateStoreConnectionMonitorService-0] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-12-03 07:23:27,627 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:27,627 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:27,629 [Listener at 0.0.0.0/43610] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for router at: http://0.0.0.0:0
2020-12-03 07:23:27,637 [Listener at 0.0.0.0/43610] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:27,639 [Listener at 0.0.0.0/43610] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:27,656 [Listener at 0.0.0.0/43610] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.router is not defined
2020-12-03 07:23:27,657 [Listener at 0.0.0.0/43610] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:27,660 [Listener at 0.0.0.0/43610] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:27,661 [Listener at 0.0.0.0/43610] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context router
2020-12-03 07:23:27,661 [Listener at 0.0.0.0/43610] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:27,661 [Listener at 0.0.0.0/43610] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:27,663 [Listener at 0.0.0.0/43610] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:23:27,664 [Listener at 0.0.0.0/43610] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.federation.router;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:23:27,664 [Listener at 0.0.0.0/43610] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 38196
2020-12-03 07:23:27,664 [Listener at 0.0.0.0/43610] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:27,668 [Listener at 0.0.0.0/43610] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@629adce{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:23:27,668 [Listener at 0.0.0.0/43610] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@743c6ce4{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:27,676 [Listener at 0.0.0.0/43610] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@4315e9af{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/router/,AVAILABLE}{/router}
2020-12-03 07:23:27,684 [Listener at 0.0.0.0/43610] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@42210be1{HTTP/1.1,[http/1.1]}{0.0.0.0:38196}
2020-12-03 07:23:27,684 [Listener at 0.0.0.0/43610] INFO  server.Server (Server.java:doStart(419)) - Started @11726ms
2020-12-03 07:23:27,685 [Listener at 0.0.0.0/43610] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn0
2020-12-03 07:23:27,685 [Listener at 0.0.0.0/43610] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn0
2020-12-03 07:23:27,686 [Listener at 0.0.0.0/43610] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn1
2020-12-03 07:23:27,686 [Listener at 0.0.0.0/43610] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn1
2020-12-03 07:23:27,686 [Listener at 0.0.0.0/43610] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service RouterHeartbeatService
2020-12-03 07:23:27,688 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router aa329fbd28a4:46386: State Store unavailable
2020-12-03 07:23:27,689 [Listener at 0.0.0.0/43610] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(117)) - Registered FSNamesystem MBean: Hadoop:service=NameNode,name=FSNamesystem-5
2020-12-03 07:23:27,689 [Listener at 0.0.0.0/43610] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(126)) - Registered FSNamesystemState MBean: Hadoop:service=NameNode,name=FSNamesystemState-5
2020-12-03 07:23:27,689 [Listener at 0.0.0.0/43610] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(134)) - Registered NameNodeInfo MBean: Hadoop:service=NameNode,name=NameNodeInfo-5
2020-12-03 07:23:27,689 [Listener at 0.0.0.0/43610] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(143)) - Registered NameNodeStatus MBean: Hadoop:service=NameNode,name=NameNodeStatus-5
2020-12-03 07:23:27,691 [Listener at 0.0.0.0/43610] INFO  metrics.FederationMetrics (FederationMetrics.java:<init>(126)) - Registered Router MBean: Hadoop:service=Router,name=FederationState-1
2020-12-03 07:23:27,696 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router aa329fbd28a4:46735: State Store unavailable
2020-12-03 07:23:27,697 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7159a5cd] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:27,696 [Listener at 0.0.0.0/43610] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-12-03 07:23:27,697 [Listener at 0.0.0.0/43610] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.serviceStart(StateStoreService.java:197)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.service.CompositeService.serviceStart(CompositeService.java:121)
	at org.apache.hadoop.hdfs.server.federation.router.Router.serviceStart(Router.java:265)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.hdfs.server.federation.MiniRouterDFSCluster.startRouters(MiniRouterDFSCluster.java:757)
	at org.apache.hadoop.fs.contract.router.web.RouterWebHDFSContract.createCluster(RouterWebHDFSContract.java:69)
	at org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractSeek.createCluster(TestRouterWebHDFSContractSeek.java:36)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2020-12-03 07:23:27,698 [Listener at 0.0.0.0/43610] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-12-03 07:23:27,698 [Listener at 0.0.0.0/43610] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-12-03 07:23:27,699 [Listener at 0.0.0.0/43610] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreConnectionMonitorService
2020-12-03 07:23:27,699 [Listener at 0.0.0.0/43610] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreCacheUpdateService
2020-12-03 07:23:27,699 [StateStoreConnectionMonitorService-0] INFO  store.StateStoreConnectionMonitorService (StateStoreConnectionMonitorService.java:periodicInvoke(63)) - Attempting to open state store driver.
2020-12-03 07:23:27,709 [StateStoreConnectionMonitorService-0] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-12-03 07:23:27,710 [StateStoreConnectionMonitorService-0] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreConnectionMonitorService.periodicInvoke(StateStoreConnectionMonitorService.java:64)
	at org.apache.hadoop.hdfs.server.federation.router.PeriodicService$1.run(PeriodicService.java:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:23:27,730 [StateStoreConnectionMonitorService-0] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-12-03 07:23:27,725 [Listener at 0.0.0.0/43610] INFO  router.RouterRpcServer (RouterRpcServer.java:serviceStart(322)) - Router RPC up at: /0.0.0.0:46735
2020-12-03 07:23:27,718 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:27,717 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:27,715 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-12-03 07:23:27,743 [Listener at 0.0.0.0/43610] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for router at: http://0.0.0.0:0
2020-12-03 07:23:27,744 [Listener at 0.0.0.0/43610] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:27,739 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:27,731 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:27,731 [StateStoreConnectionMonitorService-0] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-12-03 07:23:27,763 [Listener at 0.0.0.0/43610] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:27,767 [Listener at 0.0.0.0/43610] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.router is not defined
2020-12-03 07:23:27,767 [Listener at 0.0.0.0/43610] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:27,787 [IPC Server handler 6 on default port 46572] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:27,788 [IPC Server handler 9 on default port 37672] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:27,789 [IPC Server handler 4 on default port 43715] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:27,789 [IPC Server handler 5 on default port 46481] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:27,790 [Listener at 0.0.0.0/43610] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:27,790 [Listener at 0.0.0.0/43610] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context router
2020-12-03 07:23:27,791 [Listener at 0.0.0.0/43610] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:27,791 [Listener at 0.0.0.0/43610] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:27,792 [IPC Server handler 3 on default port 46481] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:27,793 [Listener at 0.0.0.0/43610] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:23:27,793 [Listener at 0.0.0.0/43610] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.federation.router;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:23:27,793 [IPC Server handler 7 on default port 37672] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:27,803 [Listener at 0.0.0.0/43610] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 37862
2020-12-03 07:23:27,803 [Listener at 0.0.0.0/43610] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:27,804 [IPC Server handler 0 on default port 46572] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:27,813 [Listener at 0.0.0.0/43610] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@243f003c{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:23:27,814 [Listener at 0.0.0.0/43610] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1639f93a{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:27,831 [Listener at 0.0.0.0/43610] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@a33b4e3{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/router/,AVAILABLE}{/router}
2020-12-03 07:23:27,832 [Listener at 0.0.0.0/43610] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@c6da8bb{HTTP/1.1,[http/1.1]}{0.0.0.0:37862}
2020-12-03 07:23:27,833 [Listener at 0.0.0.0/43610] INFO  server.Server (Server.java:doStart(419)) - Started @11874ms
2020-12-03 07:23:27,833 [Listener at 0.0.0.0/43610] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn0
2020-12-03 07:23:27,833 [Listener at 0.0.0.0/43610] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn0
2020-12-03 07:23:27,833 [IPC Server handler 7 on default port 43715] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:27,834 [Listener at 0.0.0.0/43610] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn1
2020-12-03 07:23:27,834 [Listener at 0.0.0.0/43610] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn1
2020-12-03 07:23:27,855 [Listener at 0.0.0.0/43610] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service RouterHeartbeatService
2020-12-03 07:23:27,860 [IPC Server handler 8 on default port 43715] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:27,860 [IPC Server handler 2 on default port 46572] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:27,861 [IPC Server handler 9 on default port 46481] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:27,862 [IPC Server handler 2 on default port 37672] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:27,896 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router aa329fbd28a4:46735: State Store unavailable
2020-12-03 07:23:27,896 [Listener at 0.0.0.0/43610] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(117)) - Registered FSNamesystem MBean: Hadoop:service=NameNode,name=FSNamesystem-6
2020-12-03 07:23:27,899 [Listener at 0.0.0.0/43610] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(126)) - Registered FSNamesystemState MBean: Hadoop:service=NameNode,name=FSNamesystemState-6
2020-12-03 07:23:27,900 [Listener at 0.0.0.0/43610] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(134)) - Registered NameNodeInfo MBean: Hadoop:service=NameNode,name=NameNodeInfo-6
2020-12-03 07:23:27,900 [Listener at 0.0.0.0/43610] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(143)) - Registered NameNodeStatus MBean: Hadoop:service=NameNode,name=NameNodeStatus-6
2020-12-03 07:23:27,900 [Listener at 0.0.0.0/43610] INFO  metrics.FederationMetrics (FederationMetrics.java:<init>(126)) - Registered Router MBean: Hadoop:service=Router,name=FederationState-2
2020-12-03 07:23:27,901 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router aa329fbd28a4:43531: State Store unavailable
2020-12-03 07:23:27,905 [Listener at 0.0.0.0/43610] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-12-03 07:23:27,905 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@76c387f9] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:23:27,905 [Listener at 0.0.0.0/43610] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.serviceStart(StateStoreService.java:197)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.service.CompositeService.serviceStart(CompositeService.java:121)
	at org.apache.hadoop.hdfs.server.federation.router.Router.serviceStart(Router.java:265)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.hdfs.server.federation.MiniRouterDFSCluster.startRouters(MiniRouterDFSCluster.java:757)
	at org.apache.hadoop.fs.contract.router.web.RouterWebHDFSContract.createCluster(RouterWebHDFSContract.java:69)
	at org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractSeek.createCluster(TestRouterWebHDFSContractSeek.java:36)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
2020-12-03 07:23:27,916 [Listener at 0.0.0.0/43610] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-12-03 07:23:27,916 [Listener at 0.0.0.0/43610] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-12-03 07:23:27,916 [Listener at 0.0.0.0/43610] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreConnectionMonitorService
2020-12-03 07:23:27,917 [Listener at 0.0.0.0/43610] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreCacheUpdateService
2020-12-03 07:23:27,917 [StateStoreConnectionMonitorService-0] INFO  store.StateStoreConnectionMonitorService (StateStoreConnectionMonitorService.java:periodicInvoke(63)) - Attempting to open state store driver.
2020-12-03 07:23:27,918 [StateStoreConnectionMonitorService-0] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-12-03 07:23:27,920 [StateStoreConnectionMonitorService-0] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreConnectionMonitorService.periodicInvoke(StateStoreConnectionMonitorService.java:64)
	at org.apache.hadoop.hdfs.server.federation.router.PeriodicService$1.run(PeriodicService.java:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:23:27,921 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:27,921 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:27,921 [StateStoreConnectionMonitorService-0] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-12-03 07:23:27,921 [StateStoreConnectionMonitorService-0] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-12-03 07:23:27,922 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-12-03 07:23:27,928 [Listener at 0.0.0.0/43610] INFO  router.RouterRpcServer (RouterRpcServer.java:serviceStart(322)) - Router RPC up at: /0.0.0.0:43531
2020-12-03 07:23:27,929 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:23:27,931 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:23:27,931 [Listener at 0.0.0.0/43610] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for router at: http://0.0.0.0:0
2020-12-03 07:23:27,938 [Listener at 0.0.0.0/43610] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:27,940 [Listener at 0.0.0.0/43610] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:23:27,941 [Listener at 0.0.0.0/43610] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.router is not defined
2020-12-03 07:23:27,942 [Listener at 0.0.0.0/43610] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:23:27,945 [Listener at 0.0.0.0/43610] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:23:27,960 [Listener at 0.0.0.0/43610] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context router
2020-12-03 07:23:27,960 [Listener at 0.0.0.0/43610] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:23:27,961 [Listener at 0.0.0.0/43610] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:23:27,963 [Listener at 0.0.0.0/43610] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:23:27,963 [Listener at 0.0.0.0/43610] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.federation.router;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:23:27,966 [Listener at 0.0.0.0/43610] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 36666
2020-12-03 07:23:27,966 [Listener at 0.0.0.0/43610] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:23:27,969 [Listener at 0.0.0.0/43610] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@162b3d47{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-12-03 07:23:27,970 [Listener at 0.0.0.0/43610] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3402b4c9{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:23:27,978 [Listener at 0.0.0.0/43610] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5533dc72{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/router/,AVAILABLE}{/router}
2020-12-03 07:23:27,981 [Listener at 0.0.0.0/43610] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7c447c76{HTTP/1.1,[http/1.1]}{0.0.0.0:36666}
2020-12-03 07:23:27,981 [Listener at 0.0.0.0/43610] INFO  server.Server (Server.java:doStart(419)) - Started @12023ms
2020-12-03 07:23:27,981 [Listener at 0.0.0.0/43610] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn0
2020-12-03 07:23:27,982 [Listener at 0.0.0.0/43610] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn1
2020-12-03 07:23:27,982 [Listener at 0.0.0.0/43610] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn0
2020-12-03 07:23:27,983 [Listener at 0.0.0.0/43610] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn1
2020-12-03 07:23:28,066 [Listener at 0.0.0.0/43610] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service RouterHeartbeatService
2020-12-03 07:23:28,084 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router aa329fbd28a4:43531: State Store unavailable
2020-12-03 07:23:28,087 [IPC Server handler 7 on default port 46481] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:28,088 [IPC Server handler 2 on default port 43715] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:28,087 [IPC Server handler 5 on default port 37672] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:28,086 [Listener at 0.0.0.0/43610] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(117)) - Registered FSNamesystem MBean: Hadoop:service=NameNode,name=FSNamesystem-7
2020-12-03 07:23:28,086 [IPC Server handler 3 on default port 46572] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:28,089 [Listener at 0.0.0.0/43610] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(126)) - Registered FSNamesystemState MBean: Hadoop:service=NameNode,name=FSNamesystemState-7
2020-12-03 07:23:28,090 [Listener at 0.0.0.0/43610] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(134)) - Registered NameNodeInfo MBean: Hadoop:service=NameNode,name=NameNodeInfo-7
2020-12-03 07:23:28,090 [Listener at 0.0.0.0/43610] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(143)) - Registered NameNodeStatus MBean: Hadoop:service=NameNode,name=NameNodeStatus-7
2020-12-03 07:23:28,090 [Listener at 0.0.0.0/43610] INFO  metrics.FederationMetrics (FederationMetrics.java:<init>(126)) - Registered Router MBean: Hadoop:service=Router,name=FederationState-3
2020-12-03 07:23:28,169 [Listener at 0.0.0.0/43610] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:23:28,170 [Edit log tailer] WARN  ha.EditLogTailer (EditLogTailer.java:doWork(528)) - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.sleep(EditLogTailer.java:433)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:526)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:440)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:457)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:484)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:453)
2020-12-03 07:23:28,228 [Listener at 0.0.0.0/43610] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:23:28,240 [Listener at 0.0.0.0/43610] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-0-through-1/current
2020-12-03 07:23:28,242 [Listener at 0.0.0.0/43610] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current
2020-12-03 07:23:28,250 [Listener at 0.0.0.0/43610] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/current
2020-12-03 07:23:28,251 [Listener at 0.0.0.0/43610] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1233)) - Catching up to latest edits from old active before taking over writer role in edits logs
2020-12-03 07:23:28,261 [Listener at 0.0.0.0/43610] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:markAllDatanodesStale(1840)) - Marking all datanodes as stale
2020-12-03 07:23:28,323 [Listener at 0.0.0.0/43610] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1244)) - Reprocessing replication and invalidation queues
2020-12-03 07:23:28,324 [Listener at 0.0.0.0/43610] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:23:28,327 [Listener at 0.0.0.0/43610] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1255)) - Will take over writing edit logs at txnid 1
2020-12-03 07:23:28,328 [Listener at 0.0.0.0/43610] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 1
2020-12-03 07:23:28,380 [Listener at 0.0.0.0/43610] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:23:28,436 [Listener at 0.0.0.0/43610] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 54 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:23:28,446 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 0
2020-12-03 07:23:28,446 [Listener at 0.0.0.0/43610] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:23:28,446 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:23:28,446 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:23:28,450 [Edit log tailer] WARN  ha.EditLogTailer (EditLogTailer.java:doWork(528)) - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.sleep(EditLogTailer.java:433)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:526)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:440)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:457)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:484)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:453)
2020-12-03 07:23:28,450 [CacheReplicationMonitor(1587849279)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:23:28,455 [Listener at 0.0.0.0/43610] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:23:28,456 [Listener at 0.0.0.0/43610] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-2-through-3/current
2020-12-03 07:23:28,456 [Listener at 0.0.0.0/43610] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/current
2020-12-03 07:23:28,456 [Listener at 0.0.0.0/43610] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6/current
2020-12-03 07:23:28,456 [Listener at 0.0.0.0/43610] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1233)) - Catching up to latest edits from old active before taking over writer role in edits logs
2020-12-03 07:23:28,474 [Listener at 0.0.0.0/43610] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:markAllDatanodesStale(1840)) - Marking all datanodes as stale
2020-12-03 07:23:28,478 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:23:28,478 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:23:28,478 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 151 msec
2020-12-03 07:23:28,527 [Listener at 0.0.0.0/43610] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1244)) - Reprocessing replication and invalidation queues
2020-12-03 07:23:28,528 [Listener at 0.0.0.0/43610] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:23:28,528 [Listener at 0.0.0.0/43610] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1255)) - Will take over writing edit logs at txnid 1
2020-12-03 07:23:28,531 [Listener at 0.0.0.0/43610] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 1
2020-12-03 07:23:28,553 [Listener at 0.0.0.0/43610] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:23:28,555 [Listener at 0.0.0.0/43610] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 1 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:23:28,573 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 0
2020-12-03 07:23:28,578 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:23:28,579 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:23:28,582 [CacheReplicationMonitor(1015311131)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:23:28,584 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:23:28,584 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:23:28,592 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 64 msec
2020-12-03 07:23:29,309 [BP-339648640-172.17.0.4-1606980201438 heartbeating to localhost/127.0.0.1:46572] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-339648640-172.17.0.4-1606980201438 (Datanode Uuid f14979ca-3b14-42d2-8cb7-2d3c00ca4270) service to localhost/127.0.0.1:46572 trying to claim ACTIVE state with txid=1
2020-12-03 07:23:29,310 [BP-339648640-172.17.0.4-1606980201438 heartbeating to localhost/127.0.0.1:46572] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-339648640-172.17.0.4-1606980201438 (Datanode Uuid f14979ca-3b14-42d2-8cb7-2d3c00ca4270) service to localhost/127.0.0.1:46572
2020-12-03 07:23:29,313 [BP-364049187-172.17.0.4-1606980197868 heartbeating to localhost/127.0.0.1:37672] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-364049187-172.17.0.4-1606980197868 (Datanode Uuid f14979ca-3b14-42d2-8cb7-2d3c00ca4270) service to localhost/127.0.0.1:37672 trying to claim ACTIVE state with txid=1
2020-12-03 07:23:29,313 [BP-364049187-172.17.0.4-1606980197868 heartbeating to localhost/127.0.0.1:37672] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-364049187-172.17.0.4-1606980197868 (Datanode Uuid f14979ca-3b14-42d2-8cb7-2d3c00ca4270) service to localhost/127.0.0.1:37672
2020-12-03 07:23:29,366 [BP-364049187-172.17.0.4-1606980197868 heartbeating to localhost/127.0.0.1:37672] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-364049187-172.17.0.4-1606980197868 (Datanode Uuid f6670a8c-a905-4867-80f3-0620636ed3de) service to localhost/127.0.0.1:37672 trying to claim ACTIVE state with txid=1
2020-12-03 07:23:29,366 [BP-364049187-172.17.0.4-1606980197868 heartbeating to localhost/127.0.0.1:37672] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-364049187-172.17.0.4-1606980197868 (Datanode Uuid f6670a8c-a905-4867-80f3-0620636ed3de) service to localhost/127.0.0.1:37672
2020-12-03 07:23:29,516 [BP-339648640-172.17.0.4-1606980201438 heartbeating to localhost/127.0.0.1:46572] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-339648640-172.17.0.4-1606980201438 (Datanode Uuid f6670a8c-a905-4867-80f3-0620636ed3de) service to localhost/127.0.0.1:46572 trying to claim ACTIVE state with txid=1
2020-12-03 07:23:29,516 [BP-339648640-172.17.0.4-1606980201438 heartbeating to localhost/127.0.0.1:46572] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-339648640-172.17.0.4-1606980201438 (Datanode Uuid f6670a8c-a905-4867-80f3-0620636ed3de) service to localhost/127.0.0.1:46572
2020-12-03 07:23:29,624 [Thread-477] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = webhdfs://0.0.0.0:41072 implemented by org.apache.hadoop.hdfs.web.WebHdfsFileSystem@2fd8ce45
Dec 03, 2020 7:23:29 AM com.sun.jersey.api.core.PackagesResourceConfig init
INFO: Scanning for root resource and provider classes in the packages:
  org.apache.hadoop.hdfs.server.federation.router
  org.apache.hadoop.hdfs.web.resources
2020-12-03 07:23:29,746 [BP-339648640-172.17.0.4-1606980201438 heartbeating to localhost/127.0.0.1:46572] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-339648640-172.17.0.4-1606980201438 (Datanode Uuid 8269cf1e-183a-448f-93f1-8184271cbc73) service to localhost/127.0.0.1:46572 trying to claim ACTIVE state with txid=1
2020-12-03 07:23:29,746 [BP-339648640-172.17.0.4-1606980201438 heartbeating to localhost/127.0.0.1:46572] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-339648640-172.17.0.4-1606980201438 (Datanode Uuid 8269cf1e-183a-448f-93f1-8184271cbc73) service to localhost/127.0.0.1:46572
2020-12-03 07:23:29,799 [BP-364049187-172.17.0.4-1606980197868 heartbeating to localhost/127.0.0.1:37672] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-364049187-172.17.0.4-1606980197868 (Datanode Uuid 8269cf1e-183a-448f-93f1-8184271cbc73) service to localhost/127.0.0.1:37672 trying to claim ACTIVE state with txid=1
2020-12-03 07:23:29,800 [BP-364049187-172.17.0.4-1606980197868 heartbeating to localhost/127.0.0.1:37672] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-364049187-172.17.0.4-1606980197868 (Datanode Uuid 8269cf1e-183a-448f-93f1-8184271cbc73) service to localhost/127.0.0.1:37672
2020-12-03 07:23:29,941 [BP-339648640-172.17.0.4-1606980201438 heartbeating to localhost/127.0.0.1:46572] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-339648640-172.17.0.4-1606980201438 (Datanode Uuid 422a8715-c24d-4fa3-b4bc-e1d088dbe0b9) service to localhost/127.0.0.1:46572 trying to claim ACTIVE state with txid=1
2020-12-03 07:23:29,941 [BP-339648640-172.17.0.4-1606980201438 heartbeating to localhost/127.0.0.1:46572] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-339648640-172.17.0.4-1606980201438 (Datanode Uuid 422a8715-c24d-4fa3-b4bc-e1d088dbe0b9) service to localhost/127.0.0.1:46572
2020-12-03 07:23:29,985 [BP-364049187-172.17.0.4-1606980197868 heartbeating to localhost/127.0.0.1:37672] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-364049187-172.17.0.4-1606980197868 (Datanode Uuid 422a8715-c24d-4fa3-b4bc-e1d088dbe0b9) service to localhost/127.0.0.1:37672 trying to claim ACTIVE state with txid=1
2020-12-03 07:23:29,985 [BP-364049187-172.17.0.4-1606980197868 heartbeating to localhost/127.0.0.1:37672] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-364049187-172.17.0.4-1606980197868 (Datanode Uuid 422a8715-c24d-4fa3-b4bc-e1d088dbe0b9) service to localhost/127.0.0.1:37672
Dec 03, 2020 7:23:30 AM com.sun.jersey.api.core.ScanningResourceConfig logClasses
INFO: Root resource classes found:
  class org.apache.hadoop.hdfs.server.federation.router.RouterWebHdfsMethods
Dec 03, 2020 7:23:30 AM com.sun.jersey.api.core.ScanningResourceConfig logClasses
INFO: Provider classes found:
  class org.apache.hadoop.hdfs.web.resources.UserProvider
  class org.apache.hadoop.hdfs.web.resources.ExceptionHandler
Dec 03, 2020 7:23:30 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
Dec 03, 2020 7:23:31 AM com.sun.jersey.spi.inject.Errors processErrorMessages
WARNING: The following warnings have been detected with resource and/or provider classes:
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.putRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.PutOpParam,org.apache.hadoop.hdfs.web.resources.DestinationParam,org.apache.hadoop.hdfs.web.resources.OwnerParam,org.apache.hadoop.hdfs.web.resources.GroupParam,org.apache.hadoop.hdfs.web.resources.PermissionParam,org.apache.hadoop.hdfs.web.resources.UnmaskedPermissionParam,org.apache.hadoop.hdfs.web.resources.OverwriteParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,org.apache.hadoop.hdfs.web.resources.ReplicationParam,org.apache.hadoop.hdfs.web.resources.BlockSizeParam,org.apache.hadoop.hdfs.web.resources.ModificationTimeParam,org.apache.hadoop.hdfs.web.resources.AccessTimeParam,org.apache.hadoop.hdfs.web.resources.RenameOptionSetParam,org.apache.hadoop.hdfs.web.resources.CreateParentParam,org.apache.hadoop.hdfs.web.resources.TokenArgumentParam,org.apache.hadoop.hdfs.web.resources.AclPermissionParam,org.apache.hadoop.hdfs.web.resources.XAttrNameParam,org.apache.hadoop.hdfs.web.resources.XAttrValueParam,org.apache.hadoop.hdfs.web.resources.XAttrSetFlagParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam,org.apache.hadoop.hdfs.web.resources.OldSnapshotNameParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.CreateFlagParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam,org.apache.hadoop.hdfs.web.resources.StoragePolicyParam,org.apache.hadoop.hdfs.web.resources.ECPolicyParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.postRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.PostOpParam,org.apache.hadoop.hdfs.web.resources.ConcatSourcesParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.NewLengthParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.deleteRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.DeleteOpParam,org.apache.hadoop.hdfs.web.resources.RecursiveParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.getRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.GetOpParam,org.apache.hadoop.hdfs.web.resources.OffsetParam,org.apache.hadoop.hdfs.web.resources.LengthParam,org.apache.hadoop.hdfs.web.resources.RenewerParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,java.util.List,org.apache.hadoop.hdfs.web.resources.XAttrEncodingParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.FsActionParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam,org.apache.hadoop.hdfs.web.resources.OldSnapshotNameParam,org.apache.hadoop.hdfs.web.resources.TokenKindParam,org.apache.hadoop.hdfs.web.resources.TokenServiceParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam,org.apache.hadoop.hdfs.web.resources.StartAfterParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
2020-12-03 07:23:31,798 [IPC Server handler 9 on default port 37672] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
Dec 03, 2020 7:23:31 AM com.sun.jersey.api.core.PackagesResourceConfig init
INFO: Scanning for root resource and provider classes in the packages:
  org.apache.hadoop.hdfs.server.namenode.web.resources
  org.apache.hadoop.hdfs.web.resources
2020-12-03 07:23:32,525 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-12-03 07:23:32,593 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router aa329fbd28a4:37854: State Store unavailable
2020-12-03 07:23:32,622 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-12-03 07:23:32,689 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router aa329fbd28a4:46386: State Store unavailable
2020-12-03 07:23:32,741 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-12-03 07:23:32,897 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router aa329fbd28a4:46735: State Store unavailable
2020-12-03 07:23:32,923 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
Dec 03, 2020 7:23:32 AM com.sun.jersey.api.core.ScanningResourceConfig logClasses
INFO: Root resource classes found:
  class org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods
Dec 03, 2020 7:23:32 AM com.sun.jersey.api.core.ScanningResourceConfig logClasses
INFO: Provider classes found:
  class org.apache.hadoop.hdfs.web.resources.UserProvider
  class org.apache.hadoop.hdfs.web.resources.ExceptionHandler
Dec 03, 2020 7:23:33 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
2020-12-03 07:23:33,088 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router aa329fbd28a4:43531: State Store unavailable
Dec 03, 2020 7:23:33 AM com.sun.jersey.spi.inject.Errors processErrorMessages
WARNING: The following warnings have been detected with resource and/or provider classes:
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.putRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.PutOpParam,org.apache.hadoop.hdfs.web.resources.DestinationParam,org.apache.hadoop.hdfs.web.resources.OwnerParam,org.apache.hadoop.hdfs.web.resources.GroupParam,org.apache.hadoop.hdfs.web.resources.PermissionParam,org.apache.hadoop.hdfs.web.resources.UnmaskedPermissionParam,org.apache.hadoop.hdfs.web.resources.OverwriteParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,org.apache.hadoop.hdfs.web.resources.ReplicationParam,org.apache.hadoop.hdfs.web.resources.BlockSizeParam,org.apache.hadoop.hdfs.web.resources.ModificationTimeParam,org.apache.hadoop.hdfs.web.resources.AccessTimeParam,org.apache.hadoop.hdfs.web.resources.RenameOptionSetParam,org.apache.hadoop.hdfs.web.resources.CreateParentParam,org.apache.hadoop.hdfs.web.resources.TokenArgumentParam,org.apache.hadoop.hdfs.web.resources.AclPermissionParam,org.apache.hadoop.hdfs.web.resources.XAttrNameParam,org.apache.hadoop.hdfs.web.resources.XAttrValueParam,org.apache.hadoop.hdfs.web.resources.XAttrSetFlagParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam,org.apache.hadoop.hdfs.web.resources.OldSnapshotNameParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.CreateFlagParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam,org.apache.hadoop.hdfs.web.resources.StoragePolicyParam,org.apache.hadoop.hdfs.web.resources.ECPolicyParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.postRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.PostOpParam,org.apache.hadoop.hdfs.web.resources.ConcatSourcesParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.NewLengthParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.deleteRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.DeleteOpParam,org.apache.hadoop.hdfs.web.resources.RecursiveParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.getRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.GetOpParam,org.apache.hadoop.hdfs.web.resources.OffsetParam,org.apache.hadoop.hdfs.web.resources.LengthParam,org.apache.hadoop.hdfs.web.resources.RenewerParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,java.util.List,org.apache.hadoop.hdfs.web.resources.XAttrEncodingParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.FsActionParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam,org.apache.hadoop.hdfs.web.resources.OldSnapshotNameParam,org.apache.hadoop.hdfs.web.resources.TokenKindParam,org.apache.hadoop.hdfs.web.resources.TokenServiceParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam,org.apache.hadoop.hdfs.web.resources.StartAfterParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
2020-12-03 07:23:33,557 [IPC Server handler 7 on default port 37672] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/test/seekfile.txt	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:23:33,600 [nioEventLoopGroup-3-1] INFO  datanode.webhdfs (WebHdfsHandler.java:run(147)) - 127.0.0.1 PUT /webhdfs/v1/test/seekfile.txt?op=CREATE&user.name=root&namenoderpcaddress=aa329fbd28a4:37854&blocksize=134217728&buffersize=4096&createflag=&createparent=true&overwrite=true&permission=644&replication=3&unmaskedpermission=666 201
2020-12-03 07:23:34,083 [IPC Server handler 6 on default port 37672] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:34,083 [IPC Server handler 4 on default port 37672] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:34,084 [IPC Server handler 9 on default port 43715] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:34,083 [IPC Server handler 0 on default port 37672] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:34,083 [IPC Server handler 5 on default port 37672] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:34,084 [IPC Server handler 1 on default port 43715] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:34,084 [IPC Server handler 5 on default port 46572] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:34,084 [IPC Server handler 0 on default port 43715] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:34,084 [IPC Server handler 2 on default port 43715] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:34,140 [IPC Server handler 7 on default port 46481] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:34,143 [IPC Server handler 6 on default port 46481] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:34,155 [IPC Server handler 3 on default port 46572] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:34,155 [IPC Server handler 0 on default port 46572] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:34,155 [IPC Server handler 3 on default port 46572] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:34,166 [IPC Server handler 4 on default port 46481] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:34,170 [IPC Server handler 8 on default port 37672] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:34145, 127.0.0.1:36468, 127.0.0.1:32817 for /test/seekfile.txt
2020-12-03 07:23:34,235 [IPC Server handler 8 on default port 46481] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:34,237 [Thread-481] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:34,375 [DataXceiver for client DFSClient_NONMAPREDUCE_-1196307952_304 at /127.0.0.1:50908 [Receiving block BP-364049187-172.17.0.4-1606980197868:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-364049187-172.17.0.4-1606980197868:blk_1073741825_1001 src: /127.0.0.1:50908 dest: /127.0.0.1:34145
2020-12-03 07:23:34,414 [DataXceiver for client DFSClient_NONMAPREDUCE_-1196307952_304 at /127.0.0.1:50908 [Receiving block BP-364049187-172.17.0.4-1606980197868:blk_1073741825_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:34,416 [DataXceiver for client DFSClient_NONMAPREDUCE_-1196307952_304 at /127.0.0.1:41888 [Receiving block BP-364049187-172.17.0.4-1606980197868:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-364049187-172.17.0.4-1606980197868:blk_1073741825_1001 src: /127.0.0.1:41888 dest: /127.0.0.1:36468
2020-12-03 07:23:34,419 [DataXceiver for client DFSClient_NONMAPREDUCE_-1196307952_304 at /127.0.0.1:41888 [Receiving block BP-364049187-172.17.0.4-1606980197868:blk_1073741825_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:34,423 [DataXceiver for client DFSClient_NONMAPREDUCE_-1196307952_304 at /127.0.0.1:56614 [Receiving block BP-364049187-172.17.0.4-1606980197868:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-364049187-172.17.0.4-1606980197868:blk_1073741825_1001 src: /127.0.0.1:56614 dest: /127.0.0.1:32817
2020-12-03 07:23:34,475 [PacketResponder: BP-364049187-172.17.0.4-1606980197868:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56614, dest: /127.0.0.1:32817, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1196307952_304, offset: 0, srvID: 422a8715-c24d-4fa3-b4bc-e1d088dbe0b9, blockid: BP-364049187-172.17.0.4-1606980197868:blk_1073741825_1001, duration(ns): 28575930
2020-12-03 07:23:34,476 [PacketResponder: BP-364049187-172.17.0.4-1606980197868:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-364049187-172.17.0.4-1606980197868:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:23:34,480 [PacketResponder: BP-364049187-172.17.0.4-1606980197868:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:32817]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41888, dest: /127.0.0.1:36468, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1196307952_304, offset: 0, srvID: f14979ca-3b14-42d2-8cb7-2d3c00ca4270, blockid: BP-364049187-172.17.0.4-1606980197868:blk_1073741825_1001, duration(ns): 30167012
2020-12-03 07:23:34,485 [PacketResponder: BP-364049187-172.17.0.4-1606980197868:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:32817]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-364049187-172.17.0.4-1606980197868:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:32817] terminating
2020-12-03 07:23:34,489 [PacketResponder: BP-364049187-172.17.0.4-1606980197868:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:36468, 127.0.0.1:32817]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:50908, dest: /127.0.0.1:34145, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1196307952_304, offset: 0, srvID: f6670a8c-a905-4867-80f3-0620636ed3de, blockid: BP-364049187-172.17.0.4-1606980197868:blk_1073741825_1001, duration(ns): 40934171
2020-12-03 07:23:34,492 [PacketResponder: BP-364049187-172.17.0.4-1606980197868:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:36468, 127.0.0.1:32817]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-364049187-172.17.0.4-1606980197868:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:36468, 127.0.0.1:32817] terminating
2020-12-03 07:23:34,501 [IPC Server handler 6 on default port 37672] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2995)) - BLOCK* blk_1073741825_1001 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /test/seekfile.txt
2020-12-03 07:23:34,908 [IPC Server handler 8 on default port 37672] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /test/seekfile.txt is closed by DFSClient_NONMAPREDUCE_-1196307952_304
2020-12-03 07:23:34,943 [IPC Server handler 1 on default port 37672] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/test/zero.txt	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:23:34,947 [nioEventLoopGroup-5-1] INFO  datanode.webhdfs (WebHdfsHandler.java:run(147)) - 127.0.0.1 PUT /webhdfs/v1/test/zero.txt?op=CREATE&user.name=root&namenoderpcaddress=aa329fbd28a4:37854&blocksize=134217728&buffersize=4096&createflag=&createparent=true&overwrite=true&permission=644&replication=3&unmaskedpermission=666 201
2020-12-03 07:23:34,950 [IPC Server handler 7 on default port 37672] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /test/zero.txt is closed by DFSClient_NONMAPREDUCE_1739779832_506
2020-12-03 07:23:34,956 [Thread-477] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - verify that a positioned read does not change the getPos() value
2020-12-03 07:23:34,986 [IPC Server handler 2 on default port 37672] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/test/bigseekfile.txt	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:23:34,989 [nioEventLoopGroup-3-2] INFO  datanode.webhdfs (WebHdfsHandler.java:run(147)) - 127.0.0.1 PUT /webhdfs/v1/test/bigseekfile.txt?op=CREATE&user.name=root&namenoderpcaddress=aa329fbd28a4:37854&blocksize=134217728&buffersize=4096&createflag=&createparent=true&overwrite=true&permission=644&replication=3&unmaskedpermission=666 201
2020-12-03 07:23:35,002 [IPC Server handler 6 on default port 37672] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741826_1002, replicas=127.0.0.1:36468, 127.0.0.1:34145, 127.0.0.1:32817 for /test/bigseekfile.txt
2020-12-03 07:23:35,006 [Thread-494] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:35,010 [DataXceiver for client DFSClient_NONMAPREDUCE_585773098_305 at /127.0.0.1:41896 [Receiving block BP-364049187-172.17.0.4-1606980197868:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-364049187-172.17.0.4-1606980197868:blk_1073741826_1002 src: /127.0.0.1:41896 dest: /127.0.0.1:36468
2020-12-03 07:23:35,011 [DataXceiver for client DFSClient_NONMAPREDUCE_585773098_305 at /127.0.0.1:41896 [Receiving block BP-364049187-172.17.0.4-1606980197868:blk_1073741826_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:35,013 [DataXceiver for client DFSClient_NONMAPREDUCE_585773098_305 at /127.0.0.1:50922 [Receiving block BP-364049187-172.17.0.4-1606980197868:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-364049187-172.17.0.4-1606980197868:blk_1073741826_1002 src: /127.0.0.1:50922 dest: /127.0.0.1:34145
2020-12-03 07:23:35,015 [DataXceiver for client DFSClient_NONMAPREDUCE_585773098_305 at /127.0.0.1:50922 [Receiving block BP-364049187-172.17.0.4-1606980197868:blk_1073741826_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:35,016 [DataXceiver for client DFSClient_NONMAPREDUCE_585773098_305 at /127.0.0.1:56624 [Receiving block BP-364049187-172.17.0.4-1606980197868:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-364049187-172.17.0.4-1606980197868:blk_1073741826_1002 src: /127.0.0.1:56624 dest: /127.0.0.1:32817
2020-12-03 07:23:35,032 [PacketResponder: BP-364049187-172.17.0.4-1606980197868:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56624, dest: /127.0.0.1:32817, bytes: 65536, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_585773098_305, offset: 0, srvID: 422a8715-c24d-4fa3-b4bc-e1d088dbe0b9, blockid: BP-364049187-172.17.0.4-1606980197868:blk_1073741826_1002, duration(ns): 13600375
2020-12-03 07:23:35,033 [PacketResponder: BP-364049187-172.17.0.4-1606980197868:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-364049187-172.17.0.4-1606980197868:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2020-12-03 07:23:35,035 [PacketResponder: BP-364049187-172.17.0.4-1606980197868:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:32817]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:50922, dest: /127.0.0.1:34145, bytes: 65536, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_585773098_305, offset: 0, srvID: f6670a8c-a905-4867-80f3-0620636ed3de, blockid: BP-364049187-172.17.0.4-1606980197868:blk_1073741826_1002, duration(ns): 16043119
2020-12-03 07:23:35,035 [PacketResponder: BP-364049187-172.17.0.4-1606980197868:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:32817]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-364049187-172.17.0.4-1606980197868:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:32817] terminating
2020-12-03 07:23:35,038 [PacketResponder: BP-364049187-172.17.0.4-1606980197868:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34145, 127.0.0.1:32817]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41896, dest: /127.0.0.1:36468, bytes: 65536, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_585773098_305, offset: 0, srvID: f14979ca-3b14-42d2-8cb7-2d3c00ca4270, blockid: BP-364049187-172.17.0.4-1606980197868:blk_1073741826_1002, duration(ns): 17295687
2020-12-03 07:23:35,038 [PacketResponder: BP-364049187-172.17.0.4-1606980197868:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34145, 127.0.0.1:32817]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-364049187-172.17.0.4-1606980197868:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34145, 127.0.0.1:32817] terminating
2020-12-03 07:23:35,041 [IPC Server handler 3 on default port 37672] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /test/bigseekfile.txt is closed by DFSClient_NONMAPREDUCE_585773098_305
2020-12-03 07:23:35,068 [IPC Server handler 1 on default port 37672] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:35,072 [IPC Server handler 2 on default port 46572] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:23:35,076 [IPC Server handler 7 on default port 37672] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/bigseekfile.txt	dst=null	perm=null	proto=rpc
2020-12-03 07:23:35,084 [IPC Server handler 9 on default port 37672] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/test/bigseekfile.txt	dst=null	perm=null	proto=rpc
2020-12-03 07:23:35,101 [IPC Server handler 2 on default port 37672] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/test/bigseekfile.txt	dst=null	perm=null	proto=rpc
2020-12-03 07:23:35,147 [nioEventLoopGroup-5-2] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:35,195 [nioEventLoopGroup-5-2] INFO  datanode.webhdfs (WebHdfsHandler.java:run(147)) - 127.0.0.1 GET /webhdfs/v1/test/bigseekfile.txt?op=OPEN&user.name=root&namenoderpcaddress=aa329fbd28a4:37854&buffersize=4096&offset=39999 200
2020-12-03 07:23:35,213 [IPC Server handler 4 on default port 37672] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/test/bigseekfile.txt	dst=null	perm=null	proto=rpc
2020-12-03 07:23:35,218 [nioEventLoopGroup-5-3] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:35,225 [nioEventLoopGroup-5-3] INFO  datanode.webhdfs (WebHdfsHandler.java:run(147)) - 127.0.0.1 GET /webhdfs/v1/test/bigseekfile.txt?op=OPEN&user.name=root&namenoderpcaddress=aa329fbd28a4:37854&buffersize=4096&offset=128 200
2020-12-03 07:23:35,230 [IPC Server handler 0 on default port 37672] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/test/bigseekfile.txt	dst=null	perm=null	proto=rpc
2020-12-03 07:23:35,236 [nioEventLoopGroup-5-4] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:23:35,257 [nioEventLoopGroup-5-4] INFO  datanode.webhdfs (WebHdfsHandler.java:run(147)) - 127.0.0.1 GET /webhdfs/v1/test/bigseekfile.txt?op=OPEN&user.name=root&namenoderpcaddress=aa329fbd28a4:37854&buffersize=4096&offset=40000 200
2020-12-03 07:23:35,269 [IPC Server handler 3 on default port 37672] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test	dst=null	perm=null	proto=rpc
2020-12-03 07:23:35,308 [IPC Server handler 1 on default port 37672] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/test	dst=null	perm=null	proto=rpc
2020-12-03 07:23:35,325 [Listener at 0.0.0.0/43610] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:23:35,325 [Listener at 0.0.0.0/43610] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 3
2020-12-03 07:23:35,326 [Listener at 0.0.0.0/43610] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:23:35,326 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@47b2e9e1] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:35,328 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, DS-66f4b598-9e1f-40c2-953a-7cb1d43b2313) exiting.
2020-12-03 07:23:35,328 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, DS-62001e65-5365-4f09-80bb-cbaab70b49b7) exiting.
2020-12-03 07:23:35,358 [Listener at 0.0.0.0/43610] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6edc4161{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:35,362 [Listener at 0.0.0.0/43610] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@5486887b{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:35,362 [Listener at 0.0.0.0/43610] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6872f9c8{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:23:35,363 [Listener at 0.0.0.0/43610] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@25b865b5{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:23:35,368 [Listener at 0.0.0.0/43610] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 45538
2020-12-03 07:23:35,377 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:35,378 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:35,379 [BP-364049187-172.17.0.4-1606980197868 heartbeating to localhost/127.0.0.1:43715] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:35,379 [BP-339648640-172.17.0.4-1606980201438 heartbeating to localhost/127.0.0.1:46572] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:35,380 [BP-364049187-172.17.0.4-1606980197868 heartbeating to localhost/127.0.0.1:43715] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-364049187-172.17.0.4-1606980197868 (Datanode Uuid 422a8715-c24d-4fa3-b4bc-e1d088dbe0b9) service to localhost/127.0.0.1:43715
2020-12-03 07:23:35,379 [BP-364049187-172.17.0.4-1606980197868 heartbeating to localhost/127.0.0.1:37672] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:35,379 [BP-339648640-172.17.0.4-1606980201438 heartbeating to localhost/127.0.0.1:46481] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:35,380 [BP-364049187-172.17.0.4-1606980197868 heartbeating to localhost/127.0.0.1:37672] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-364049187-172.17.0.4-1606980197868 (Datanode Uuid 422a8715-c24d-4fa3-b4bc-e1d088dbe0b9) service to localhost/127.0.0.1:37672
2020-12-03 07:23:35,380 [BP-339648640-172.17.0.4-1606980201438 heartbeating to localhost/127.0.0.1:46572] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-339648640-172.17.0.4-1606980201438 (Datanode Uuid 422a8715-c24d-4fa3-b4bc-e1d088dbe0b9) service to localhost/127.0.0.1:46572
2020-12-03 07:23:35,381 [BP-339648640-172.17.0.4-1606980201438 heartbeating to localhost/127.0.0.1:46481] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-339648640-172.17.0.4-1606980201438 (Datanode Uuid 422a8715-c24d-4fa3-b4bc-e1d088dbe0b9) service to localhost/127.0.0.1:46481
2020-12-03 07:23:35,381 [BP-364049187-172.17.0.4-1606980197868 heartbeating to localhost/127.0.0.1:37672] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-364049187-172.17.0.4-1606980197868 (Datanode Uuid 422a8715-c24d-4fa3-b4bc-e1d088dbe0b9)
2020-12-03 07:23:35,381 [BP-339648640-172.17.0.4-1606980201438 heartbeating to localhost/127.0.0.1:46481] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-339648640-172.17.0.4-1606980201438 (Datanode Uuid 422a8715-c24d-4fa3-b4bc-e1d088dbe0b9)
2020-12-03 07:23:35,381 [BP-364049187-172.17.0.4-1606980197868 heartbeating to localhost/127.0.0.1:37672] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-364049187-172.17.0.4-1606980197868
2020-12-03 07:23:35,383 [BP-339648640-172.17.0.4-1606980201438 heartbeating to localhost/127.0.0.1:46481] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-339648640-172.17.0.4-1606980201438
2020-12-03 07:23:35,383 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-364049187-172.17.0.4-1606980197868] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:35,383 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-364049187-172.17.0.4-1606980197868] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:35,388 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-339648640-172.17.0.4-1606980201438] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:35,390 [Listener at 0.0.0.0/43610] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:23:35,390 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-339648640-172.17.0.4-1606980201438] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:35,390 [Listener at 0.0.0.0/43610] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:23:35,392 [Listener at 0.0.0.0/43610] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:23:35,392 [Listener at 0.0.0.0/43610] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:23:35,396 [Listener at 0.0.0.0/43610] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:35,396 [Listener at 0.0.0.0/43610] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 2
2020-12-03 07:23:35,396 [Listener at 0.0.0.0/43610] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:23:35,396 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@34b9fc7d] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:35,402 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, DS-69da2731-18b4-472d-af70-d73a4d269712) exiting.
2020-12-03 07:23:35,402 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, DS-af989f10-524a-4fdf-bcbd-c3442592547a) exiting.
2020-12-03 07:23:35,425 [Listener at 0.0.0.0/43610] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@69cac930{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:35,426 [Listener at 0.0.0.0/43610] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@19593091{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:35,426 [Listener at 0.0.0.0/43610] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@baf1bb3{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:23:35,426 [Listener at 0.0.0.0/43610] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@588ffeb{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:23:35,431 [Listener at 0.0.0.0/43610] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 35876
2020-12-03 07:23:35,441 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:35,441 [BP-339648640-172.17.0.4-1606980201438 heartbeating to localhost/127.0.0.1:46572] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:35,441 [BP-364049187-172.17.0.4-1606980197868 heartbeating to localhost/127.0.0.1:43715] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:35,441 [BP-364049187-172.17.0.4-1606980197868 heartbeating to localhost/127.0.0.1:43715] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-364049187-172.17.0.4-1606980197868 (Datanode Uuid 8269cf1e-183a-448f-93f1-8184271cbc73) service to localhost/127.0.0.1:43715
2020-12-03 07:23:35,441 [BP-339648640-172.17.0.4-1606980201438 heartbeating to localhost/127.0.0.1:46572] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-339648640-172.17.0.4-1606980201438 (Datanode Uuid 8269cf1e-183a-448f-93f1-8184271cbc73) service to localhost/127.0.0.1:46572
2020-12-03 07:23:35,441 [BP-364049187-172.17.0.4-1606980197868 heartbeating to localhost/127.0.0.1:37672] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:35,441 [BP-339648640-172.17.0.4-1606980201438 heartbeating to localhost/127.0.0.1:46481] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:35,442 [BP-364049187-172.17.0.4-1606980197868 heartbeating to localhost/127.0.0.1:37672] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-364049187-172.17.0.4-1606980197868 (Datanode Uuid 8269cf1e-183a-448f-93f1-8184271cbc73) service to localhost/127.0.0.1:37672
2020-12-03 07:23:35,442 [BP-339648640-172.17.0.4-1606980201438 heartbeating to localhost/127.0.0.1:46481] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-339648640-172.17.0.4-1606980201438 (Datanode Uuid 8269cf1e-183a-448f-93f1-8184271cbc73) service to localhost/127.0.0.1:46481
2020-12-03 07:23:35,442 [BP-364049187-172.17.0.4-1606980197868 heartbeating to localhost/127.0.0.1:37672] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-364049187-172.17.0.4-1606980197868 (Datanode Uuid 8269cf1e-183a-448f-93f1-8184271cbc73)
2020-12-03 07:23:35,442 [BP-339648640-172.17.0.4-1606980201438 heartbeating to localhost/127.0.0.1:46481] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-339648640-172.17.0.4-1606980201438 (Datanode Uuid 8269cf1e-183a-448f-93f1-8184271cbc73)
2020-12-03 07:23:35,442 [BP-364049187-172.17.0.4-1606980197868 heartbeating to localhost/127.0.0.1:37672] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-364049187-172.17.0.4-1606980197868
2020-12-03 07:23:35,449 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:35,450 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-364049187-172.17.0.4-1606980197868] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:35,452 [BP-339648640-172.17.0.4-1606980201438 heartbeating to localhost/127.0.0.1:46481] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-339648640-172.17.0.4-1606980201438
2020-12-03 07:23:35,452 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-364049187-172.17.0.4-1606980197868] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:35,452 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-339648640-172.17.0.4-1606980201438] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:35,457 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-339648640-172.17.0.4-1606980201438] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:35,458 [Listener at 0.0.0.0/43610] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:23:35,459 [Listener at 0.0.0.0/43610] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:23:35,460 [Listener at 0.0.0.0/43610] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:23:35,460 [Listener at 0.0.0.0/43610] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:23:35,463 [Listener at 0.0.0.0/43610] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:35,463 [Listener at 0.0.0.0/43610] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 1
2020-12-03 07:23:35,463 [Listener at 0.0.0.0/43610] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:23:35,463 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@72458efc] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:35,467 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, DS-764dc4eb-6996-475b-8f6e-ebef4cfc3e28) exiting.
2020-12-03 07:23:35,481 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, DS-8efb34cb-f56a-46ed-b949-44b9d1babbf4) exiting.
2020-12-03 07:23:35,511 [BP-339648640-172.17.0.4-1606980201438 heartbeating to localhost/127.0.0.1:46572] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-339648640-172.17.0.4-1606980201438 (Datanode Uuid f6670a8c-a905-4867-80f3-0620636ed3de) service to localhost/127.0.0.1:46572
2020-12-03 07:23:35,515 [BP-339648640-172.17.0.4-1606980201438 heartbeating to localhost/127.0.0.1:46481] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-339648640-172.17.0.4-1606980201438 (Datanode Uuid f6670a8c-a905-4867-80f3-0620636ed3de) service to localhost/127.0.0.1:46481
2020-12-03 07:23:35,515 [BP-339648640-172.17.0.4-1606980201438 heartbeating to localhost/127.0.0.1:46481] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-339648640-172.17.0.4-1606980201438 (Datanode Uuid f6670a8c-a905-4867-80f3-0620636ed3de)
2020-12-03 07:23:35,515 [BP-339648640-172.17.0.4-1606980201438 heartbeating to localhost/127.0.0.1:46481] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-339648640-172.17.0.4-1606980201438
2020-12-03 07:23:35,522 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-339648640-172.17.0.4-1606980201438] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:35,523 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-339648640-172.17.0.4-1606980201438] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:35,539 [Listener at 0.0.0.0/43610] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5cbb84b1{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:35,540 [Listener at 0.0.0.0/43610] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2c779e5{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:35,541 [Listener at 0.0.0.0/43610] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6ac97b84{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:23:35,541 [Listener at 0.0.0.0/43610] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2e3a5237{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:23:35,543 [Listener at 0.0.0.0/43610] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 36168
2020-12-03 07:23:35,569 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:35,569 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:35,570 [BP-364049187-172.17.0.4-1606980197868 heartbeating to localhost/127.0.0.1:43715] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:35,570 [BP-364049187-172.17.0.4-1606980197868 heartbeating to localhost/127.0.0.1:37672] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:35,570 [BP-364049187-172.17.0.4-1606980197868 heartbeating to localhost/127.0.0.1:43715] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-364049187-172.17.0.4-1606980197868 (Datanode Uuid f6670a8c-a905-4867-80f3-0620636ed3de) service to localhost/127.0.0.1:43715
2020-12-03 07:23:35,570 [BP-364049187-172.17.0.4-1606980197868 heartbeating to localhost/127.0.0.1:37672] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-364049187-172.17.0.4-1606980197868 (Datanode Uuid f6670a8c-a905-4867-80f3-0620636ed3de) service to localhost/127.0.0.1:37672
2020-12-03 07:23:35,573 [BP-364049187-172.17.0.4-1606980197868 heartbeating to localhost/127.0.0.1:37672] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-364049187-172.17.0.4-1606980197868 (Datanode Uuid f6670a8c-a905-4867-80f3-0620636ed3de)
2020-12-03 07:23:35,573 [BP-364049187-172.17.0.4-1606980197868 heartbeating to localhost/127.0.0.1:37672] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-364049187-172.17.0.4-1606980197868
2020-12-03 07:23:35,574 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-364049187-172.17.0.4-1606980197868] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:35,576 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-364049187-172.17.0.4-1606980197868] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:35,587 [Listener at 0.0.0.0/43610] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:23:35,587 [Listener at 0.0.0.0/43610] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:23:35,589 [Listener at 0.0.0.0/43610] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:23:35,589 [Listener at 0.0.0.0/43610] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:23:35,592 [Listener at 0.0.0.0/43610] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:35,592 [Listener at 0.0.0.0/43610] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:23:35,593 [Listener at 0.0.0.0/43610] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:23:35,593 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@273c947f] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:23:35,595 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, DS-a79da8de-3edc-4788-ab8e-fc5b8e383ab7) exiting.
2020-12-03 07:23:35,595 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, DS-e38d9717-2172-454d-9795-4324f28c8bf6) exiting.
2020-12-03 07:23:35,635 [Listener at 0.0.0.0/43610] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@38600b{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:23:35,635 [Listener at 0.0.0.0/43610] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@669d2b1b{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:35,636 [Listener at 0.0.0.0/43610] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@22175d4f{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:23:35,636 [Listener at 0.0.0.0/43610] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2472c7d8{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:23:35,637 [Listener at 0.0.0.0/43610] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 39779
2020-12-03 07:23:35,644 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:35,644 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:35,645 [BP-364049187-172.17.0.4-1606980197868 heartbeating to localhost/127.0.0.1:43715] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:35,645 [BP-339648640-172.17.0.4-1606980201438 heartbeating to localhost/127.0.0.1:46572] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:35,645 [BP-364049187-172.17.0.4-1606980197868 heartbeating to localhost/127.0.0.1:43715] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-364049187-172.17.0.4-1606980197868 (Datanode Uuid f14979ca-3b14-42d2-8cb7-2d3c00ca4270) service to localhost/127.0.0.1:43715
2020-12-03 07:23:35,645 [BP-339648640-172.17.0.4-1606980201438 heartbeating to localhost/127.0.0.1:46481] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:35,647 [BP-339648640-172.17.0.4-1606980201438 heartbeating to localhost/127.0.0.1:46481] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-339648640-172.17.0.4-1606980201438 (Datanode Uuid f14979ca-3b14-42d2-8cb7-2d3c00ca4270) service to localhost/127.0.0.1:46481
2020-12-03 07:23:35,645 [BP-364049187-172.17.0.4-1606980197868 heartbeating to localhost/127.0.0.1:37672] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:23:35,647 [BP-339648640-172.17.0.4-1606980201438 heartbeating to localhost/127.0.0.1:46572] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-339648640-172.17.0.4-1606980201438 (Datanode Uuid f14979ca-3b14-42d2-8cb7-2d3c00ca4270) service to localhost/127.0.0.1:46572
2020-12-03 07:23:35,647 [BP-364049187-172.17.0.4-1606980197868 heartbeating to localhost/127.0.0.1:37672] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-364049187-172.17.0.4-1606980197868 (Datanode Uuid f14979ca-3b14-42d2-8cb7-2d3c00ca4270) service to localhost/127.0.0.1:37672
2020-12-03 07:23:35,647 [BP-339648640-172.17.0.4-1606980201438 heartbeating to localhost/127.0.0.1:46572] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-339648640-172.17.0.4-1606980201438 (Datanode Uuid f14979ca-3b14-42d2-8cb7-2d3c00ca4270)
2020-12-03 07:23:35,647 [BP-364049187-172.17.0.4-1606980197868 heartbeating to localhost/127.0.0.1:37672] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-364049187-172.17.0.4-1606980197868 (Datanode Uuid f14979ca-3b14-42d2-8cb7-2d3c00ca4270)
2020-12-03 07:23:35,647 [BP-339648640-172.17.0.4-1606980201438 heartbeating to localhost/127.0.0.1:46572] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-339648640-172.17.0.4-1606980201438
2020-12-03 07:23:35,648 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-339648640-172.17.0.4-1606980201438] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:35,648 [BP-364049187-172.17.0.4-1606980197868 heartbeating to localhost/127.0.0.1:37672] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-364049187-172.17.0.4-1606980197868
2020-12-03 07:23:35,648 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-339648640-172.17.0.4-1606980201438] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:35,649 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-364049187-172.17.0.4-1606980197868] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:35,649 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-364049187-172.17.0.4-1606980197868] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:23:35,671 [Listener at 0.0.0.0/43610] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:23:35,671 [Listener at 0.0.0.0/43610] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:23:35,673 [Listener at 0.0.0.0/43610] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:23:35,673 [Listener at 0.0.0.0/43610] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:23:35,677 [Listener at 0.0.0.0/43610] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:23:35,677 [Listener at 0.0.0.0/43610] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:23:35,677 [Listener at 0.0.0.0/43610] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:35,679 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@36ddaebf] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:23:35,679 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@670ce331] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:23:35,680 [Listener at 0.0.0.0/43610] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 1, 15
2020-12-03 07:23:35,681 [Listener at 0.0.0.0/43610] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 16 Total time for transactions(ms): 44 Number of transactions batched in Syncs: 1 Number of syncs: 16 SyncTimes(ms): 13 2 3 
2020-12-03 07:23:35,682 [Listener at 0.0.0.0/43610] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-0-through-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-0-through-1/current/edits_0000000000000000001-0000000000000000016
2020-12-03 07:23:35,683 [Listener at 0.0.0.0/43610] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000016
2020-12-03 07:23:35,683 [Listener at 0.0.0.0/43610] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000016
2020-12-03 07:23:35,684 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:23:35,684 [CacheReplicationMonitor(1587849279)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:23:35,684 [Listener at 0.0.0.0/43610] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 37672
2020-12-03 07:23:35,686 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:35,692 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:35,693 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:23:35,693 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:23:35,734 [Listener at 0.0.0.0/43610] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:35,734 [Listener at 0.0.0.0/43610] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:23:35,737 [Listener at 0.0.0.0/43610] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@71529963{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:23:35,740 [Listener at 0.0.0.0/43610] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@73e3c5f2{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:35,741 [Listener at 0.0.0.0/43610] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@27216cd{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:23:35,741 [Listener at 0.0.0.0/43610] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@78d6692f{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:23:35,747 [Listener at 0.0.0.0/43610] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:23:35,747 [Listener at 0.0.0.0/43610] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:23:35,748 [Edit log tailer] WARN  ha.EditLogTailer (EditLogTailer.java:doWork(528)) - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.sleep(EditLogTailer.java:433)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:526)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:440)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:457)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:484)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:453)
2020-12-03 07:23:35,748 [Listener at 0.0.0.0/43610] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 43715
2020-12-03 07:23:35,752 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:35,752 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:35,752 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:23:35,752 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:23:35,764 [Listener at 0.0.0.0/43610] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:35,767 [Listener at 0.0.0.0/43610] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:23:35,770 [Listener at 0.0.0.0/43610] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@7544a1e4{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:23:35,773 [Listener at 0.0.0.0/43610] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@70e0accd{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:35,774 [Listener at 0.0.0.0/43610] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@797501a{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:23:35,774 [Listener at 0.0.0.0/43610] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@14bb2297{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:23:35,781 [Listener at 0.0.0.0/43610] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:23:35,781 [Listener at 0.0.0.0/43610] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:35,781 [Listener at 0.0.0.0/43610] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 1, 1
2020-12-03 07:23:35,782 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@4b2e3e8f] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:23:35,782 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@4bbb49b0] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:23:35,788 [Listener at 0.0.0.0/43610] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 2 Total time for transactions(ms): 17 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 4 3 2 
2020-12-03 07:23:35,789 [Listener at 0.0.0.0/43610] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-2-through-3/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-2-through-3/current/edits_0000000000000000001-0000000000000000002
2020-12-03 07:23:35,789 [Listener at 0.0.0.0/43610] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/current/edits_0000000000000000001-0000000000000000002
2020-12-03 07:23:35,790 [Listener at 0.0.0.0/43610] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6/current/edits_0000000000000000001-0000000000000000002
2020-12-03 07:23:35,790 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:23:35,791 [CacheReplicationMonitor(1015311131)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:23:35,791 [Listener at 0.0.0.0/43610] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 46572
2020-12-03 07:23:35,794 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:35,795 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:35,795 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:23:35,795 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:23:35,808 [Listener at 0.0.0.0/43610] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:35,809 [Listener at 0.0.0.0/43610] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:23:35,812 [Listener at 0.0.0.0/43610] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@581d969c{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:23:35,814 [Listener at 0.0.0.0/43610] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@22db8f4{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:35,814 [Listener at 0.0.0.0/43610] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@669253b7{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:23:35,815 [Listener at 0.0.0.0/43610] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@32f61a31{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:23:35,821 [Listener at 0.0.0.0/43610] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:23:35,821 [Listener at 0.0.0.0/43610] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:23:35,821 [Edit log tailer] WARN  ha.EditLogTailer (EditLogTailer.java:doWork(528)) - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.sleep(EditLogTailer.java:433)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:526)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:440)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:457)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:484)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:453)
2020-12-03 07:23:35,822 [Listener at 0.0.0.0/43610] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 46481
2020-12-03 07:23:35,826 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:35,826 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:35,827 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:23:35,830 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:23:35,843 [Listener at 0.0.0.0/43610] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:23:35,876 [Listener at 0.0.0.0/43610] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:23:35,899 [Listener at 0.0.0.0/43610] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1dfd5f51{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:23:35,902 [Listener at 0.0.0.0/43610] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@3c321bdb{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:23:35,903 [Listener at 0.0.0.0/43610] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@54e7391d{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.2.1/hadoop-hdfs-3.2.1-tests.jar!/webapps/static,UNAVAILABLE}
2020-12-03 07:23:35,903 [Listener at 0.0.0.0/43610] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6d1310f6{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:23:35,932 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router aa329fbd28a4:37854: State Store unavailable
2020-12-03 07:23:35,943 [Thread-507] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - RouterHeartbeatService is shutting down
2020-12-03 07:23:35,943 [Thread-507] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service RouterHeartbeatService
2020-12-03 07:23:35,961 [Thread-507] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn1 is shutting down
2020-12-03 07:23:35,961 [Thread-507] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn1
2020-12-03 07:23:35,968 [Thread-507] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn1 is shutting down
2020-12-03 07:23:35,968 [Thread-507] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn1
2020-12-03 07:23:35,974 [Thread-507] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn0 is shutting down
2020-12-03 07:23:35,974 [Thread-507] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn0
2020-12-03 07:23:35,980 [Thread-507] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn0 is shutting down
2020-12-03 07:23:35,980 [Thread-507] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn0
2020-12-03 07:23:35,990 [Thread-507] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@99407c2{/,null,UNAVAILABLE}{/router}
2020-12-03 07:23:35,991 [Thread-507] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6c796cc1{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2020-12-03 07:23:35,993 [Thread-507] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7318daf8{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:35,995 [Thread-507] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@66153688{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:23:36,001 [Thread-507] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 40841
2020-12-03 07:23:36,003 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:36,006 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:36,014 [Thread-507] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 37854
2020-12-03 07:23:36,017 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:36,022 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:36,030 [Thread-507] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreCacheUpdateService is shutting down
2020-12-03 07:23:36,030 [Thread-507] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreCacheUpdateService
2020-12-03 07:23:36,034 [Thread-507] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreConnectionMonitorService is shutting down
2020-12-03 07:23:36,035 [Thread-507] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreConnectionMonitorService
2020-12-03 07:23:36,930 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router aa329fbd28a4:46386: State Store unavailable
2020-12-03 07:23:36,937 [Thread-508] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - RouterHeartbeatService is shutting down
2020-12-03 07:23:36,939 [Thread-508] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service RouterHeartbeatService
2020-12-03 07:23:36,943 [Thread-508] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn1 is shutting down
2020-12-03 07:23:36,943 [Thread-508] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn1
2020-12-03 07:23:36,954 [Thread-508] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn1 is shutting down
2020-12-03 07:23:36,954 [Thread-508] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn1
2020-12-03 07:23:36,958 [Thread-508] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn0 is shutting down
2020-12-03 07:23:36,958 [Thread-508] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn0
2020-12-03 07:23:36,968 [Thread-508] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn0 is shutting down
2020-12-03 07:23:36,969 [Thread-508] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn0
2020-12-03 07:23:36,976 [Thread-508] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@4315e9af{/,null,UNAVAILABLE}{/router}
2020-12-03 07:23:36,978 [Thread-508] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@42210be1{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2020-12-03 07:23:36,981 [Thread-508] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@743c6ce4{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:36,984 [Thread-508] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@629adce{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:23:36,988 [Thread-508] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 40156
2020-12-03 07:23:36,992 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:37,015 [Thread-508] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 46386
2020-12-03 07:23:37,012 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:37,020 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:37,022 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:37,036 [Thread-508] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping Router metrics system...
2020-12-03 07:23:37,038 [Thread-508] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - Router metrics system stopped.
2020-12-03 07:23:37,038 [Thread-508] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - Router metrics system shutdown complete.
2020-12-03 07:23:37,042 [Thread-508] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreCacheUpdateService is shutting down
2020-12-03 07:23:37,043 [Thread-508] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreCacheUpdateService
2020-12-03 07:23:37,044 [Thread-508] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreConnectionMonitorService is shutting down
2020-12-03 07:23:37,045 [Thread-508] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreConnectionMonitorService
2020-12-03 07:23:37,741 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-12-03 07:23:37,897 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router aa329fbd28a4:46735: State Store unavailable
2020-12-03 07:23:37,924 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-12-03 07:23:37,927 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router aa329fbd28a4:46735: State Store unavailable
2020-12-03 07:23:37,928 [Thread-509] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - RouterHeartbeatService is shutting down
2020-12-03 07:23:37,928 [Thread-509] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service RouterHeartbeatService
2020-12-03 07:23:37,929 [Thread-509] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn1 is shutting down
2020-12-03 07:23:37,929 [Thread-509] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn1
2020-12-03 07:23:37,929 [Thread-509] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn1 is shutting down
2020-12-03 07:23:37,929 [Thread-509] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn1
2020-12-03 07:23:37,930 [Thread-509] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn0 is shutting down
2020-12-03 07:23:37,930 [Thread-509] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn0
2020-12-03 07:23:37,930 [Thread-509] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn0 is shutting down
2020-12-03 07:23:37,930 [Thread-509] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn0
2020-12-03 07:23:37,932 [Thread-509] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@a33b4e3{/,null,UNAVAILABLE}{/router}
2020-12-03 07:23:37,933 [Thread-509] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@c6da8bb{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2020-12-03 07:23:37,934 [Thread-509] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1639f93a{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:37,934 [Thread-509] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@243f003c{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:23:37,935 [Thread-509] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 41625
2020-12-03 07:23:37,935 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:37,935 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:37,936 [Thread-509] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 46735
2020-12-03 07:23:37,937 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:37,937 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:37,938 [Thread-509] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreCacheUpdateService is shutting down
2020-12-03 07:23:37,938 [Thread-509] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreCacheUpdateService
2020-12-03 07:23:37,938 [Thread-509] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreConnectionMonitorService is shutting down
2020-12-03 07:23:37,938 [Thread-509] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreConnectionMonitorService
2020-12-03 07:23:38,089 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router aa329fbd28a4:43531: State Store unavailable
2020-12-03 07:23:38,927 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router aa329fbd28a4:43531: State Store unavailable
2020-12-03 07:23:38,929 [Thread-510] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - RouterHeartbeatService is shutting down
2020-12-03 07:23:38,929 [Thread-510] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service RouterHeartbeatService
2020-12-03 07:23:38,929 [Thread-510] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn1 is shutting down
2020-12-03 07:23:38,930 [Thread-510] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn1
2020-12-03 07:23:38,930 [Thread-510] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn0 is shutting down
2020-12-03 07:23:38,930 [Thread-510] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn0
2020-12-03 07:23:38,930 [Thread-510] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn1 is shutting down
2020-12-03 07:23:38,930 [Thread-510] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn1
2020-12-03 07:23:38,931 [Thread-510] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn0 is shutting down
2020-12-03 07:23:38,931 [Thread-510] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn0
2020-12-03 07:23:38,932 [Thread-510] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5533dc72{/,null,UNAVAILABLE}{/router}
2020-12-03 07:23:38,933 [Thread-510] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7c447c76{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2020-12-03 07:23:38,934 [Thread-510] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3402b4c9{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:23:38,934 [Thread-510] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@162b3d47{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-12-03 07:23:38,935 [Thread-510] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 43610
2020-12-03 07:23:38,936 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:38,936 [Thread-510] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 43531
2020-12-03 07:23:38,936 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:38,938 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:23:38,938 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:23:38,938 [Thread-510] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreCacheUpdateService is shutting down
2020-12-03 07:23:38,939 [Thread-510] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreCacheUpdateService
2020-12-03 07:23:38,940 [Thread-510] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreConnectionMonitorService is shutting down
2020-12-03 07:23:38,940 [Thread-510] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreConnectionMonitorService
msx-rc 0
