2020-12-03 07:21:47,108 [main] INFO  mover.TestStorageMover (TestStorageMover.java:testMoveSpecificPaths(501)) - testMoveSpecificPaths
2020-12-03 07:21:47,179 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=1, numDataNodes=6
Formatting using clusterid: testClusterID
2020-12-03 07:21:47,971 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:21:47,986 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:21:47,988 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:21:47,988 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:21:47,996 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:21:47,996 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:21:47,997 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:21:47,997 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:21:48,037 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:48,042 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2020-12-03 07:21:48,042 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:48,043 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=20, effected=1000
2020-12-03 07:21:48,043 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:21:48,043 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:48,050 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:21:48,051 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:21:48
2020-12-03 07:21:48,053 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:21:48,053 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:48,055 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-12-03 07:21:48,055 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:21:48,072 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:48,073 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:48,074 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:21:48,075 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:21:48,077 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.redundancy.interval.seconds(2) assuming SECONDS
2020-12-03 07:21:48,078 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:48,082 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:21:48,083 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:21:48,083 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:21:48,083 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:21:48,084 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:21:48,084 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:21:48,085 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:21:48,085 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:21:48,085 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 2000ms
2020-12-03 07:21:48,085 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:21:48,086 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:21:48,121 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GLOBAL serial map: bits=29 maxEntries=536870911
2020-12-03 07:21:48,122 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - USER serial map: bits=24 maxEntries=16777215
2020-12-03 07:21:48,122 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GROUP serial map: bits=24 maxEntries=16777215
2020-12-03 07:21:48,122 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - XATTR serial map: bits=24 maxEntries=16777215
2020-12-03 07:21:48,141 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:21:48,142 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:48,143 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-12-03 07:21:48,143 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:21:48,151 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:21:48,151 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:21:48,152 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:21:48,152 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:21:48,161 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:21:48,165 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:21:48,170 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:21:48,170 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:48,171 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-12-03 07:21:48,171 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:21:48,183 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:21:48,183 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:21:48,183 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:21:48,188 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:21:48,188 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:21:48,191 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:21:48,191 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:48,191 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-12-03 07:21:48,192 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:21:48,227 [main] INFO  namenode.FSImage (FSImage.java:format(185)) - Allocated new BlockPoolId: BP-1100016829-172.17.0.10-1606980108214
2020-12-03 07:21:48,447 [main] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-12-03 07:21:48,722 [main] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-12-03 07:21:48,759 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:21:48,759 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:21:48,914 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:21:48,914 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:21:49,010 [main] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-12-03 07:21:49,014 [main] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:21:49,125 [main] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:21:49,477 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:21:49,478 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:21:49,511 [main] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-12-03 07:21:49,563 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1de76cc7] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:21:49,580 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:21:49,585 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:49,601 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @3525ms
2020-12-03 07:21:49,771 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:21:49,776 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:21:49,777 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:49,792 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:21:49,795 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:21:49,796 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:21:49,796 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:21:49,833 [main] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:21:49,833 [main] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:21:49,847 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 33768
2020-12-03 07:21:49,850 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:21:49,980 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5c7bfdc1{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:21:49,985 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@71687585{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:21:50,043 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7a3793c7{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:21:50,054 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4c012563{HTTP/1.1,[http/1.1]}{localhost:33768}
2020-12-03 07:21:50,055 [main] INFO  server.Server (Server.java:doStart(419)) - Started @3979ms
2020-12-03 07:21:50,073 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:21:50,074 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:21:50,074 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:21:50,075 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:21:50,075 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:21:50,075 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:21:50,075 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:21:50,076 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: false
2020-12-03 07:21:50,076 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:50,077 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:50,077 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=20, effected=1000
2020-12-03 07:21:50,077 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:21:50,078 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:50,078 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:21:50,079 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:21:50
2020-12-03 07:21:50,079 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:21:50,079 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:50,079 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:21:50,080 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:21:50,083 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:50,084 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:50,084 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:21:50,084 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:21:50,085 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.redundancy.interval.seconds(2) assuming SECONDS
2020-12-03 07:21:50,085 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:50,085 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:21:50,086 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:21:50,086 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:21:50,086 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:21:50,087 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:21:50,087 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:21:50,088 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:21:50,088 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:21:50,088 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 2000ms
2020-12-03 07:21:50,088 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:21:50,088 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:21:50,089 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:21:50,089 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:50,090 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:21:50,090 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:21:50,092 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? false
2020-12-03 07:21:50,092 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:21:50,092 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:21:50,093 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:21:50,093 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:21:50,093 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:21:50,093 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:21:50,093 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:50,094 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:21:50,094 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:21:50,095 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:21:50,095 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:21:50,095 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:21:50,096 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:21:50,096 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:21:50,096 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:21:50,096 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:21:50,097 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:21:50,097 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:21:50,257 [main] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 5887@f865fdeb6a4d
2020-12-03 07:21:50,376 [main] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 5887@f865fdeb6a4d
2020-12-03 07:21:50,380 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-12-03 07:21:50,380 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-12-03 07:21:50,380 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:21:50,381 [main] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:21:50,417 [main] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:21:50,425 [main] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:21:50,425 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-12-03 07:21:50,430 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-12-03 07:21:50,431 [main] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 1
2020-12-03 07:21:50,761 [main] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:21:50,761 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 661 msecs
2020-12-03 07:21:50,960 [main] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:21:51,013 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:21:51,031 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:21:51,339 [Listener at localhost/45230] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:45230 to access this namenode/service.
2020-12-03 07:21:51,343 [Listener at localhost/45230] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:21:51,360 [Listener at localhost/45230] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:21:51,377 [Listener at localhost/45230] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:21:51,378 [Listener at localhost/45230] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:21:51,378 [Listener at localhost/45230] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:21:51,378 [Listener at localhost/45230] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:21:51,383 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 0
2020-12-03 07:21:51,383 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:21:51,383 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:21:51,383 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:21:51,384 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:21:51,384 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 6 msec
2020-12-03 07:21:51,413 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:21:51,414 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:21:51,424 [Listener at localhost/45230] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:45230
2020-12-03 07:21:51,428 [Listener at localhost/45230] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:21:51,428 [Listener at localhost/45230] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:21:51,437 [Listener at localhost/45230] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 8 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:21:51,442 [CacheReplicationMonitor(523546785)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:21:51,446 [Listener at localhost/45230] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:21:51,514 [Listener at localhost/45230] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:21:51,531 [Listener at localhost/45230] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:21:51,556 [Listener at localhost/45230] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:21:51,560 [Listener at localhost/45230] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:51,564 [Listener at localhost/45230] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:21:51,568 [Listener at localhost/45230] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:21:51,570 [Listener at localhost/45230] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:51,570 [Listener at localhost/45230] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:51,570 [Listener at localhost/45230] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:51,576 [Listener at localhost/45230] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:21:51,587 [Listener at localhost/45230] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:38111
2020-12-03 07:21:51,590 [Listener at localhost/45230] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:21:51,590 [Listener at localhost/45230] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:21:51,616 [Listener at localhost/45230] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:51,620 [Listener at localhost/45230] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:21:51,621 [Listener at localhost/45230] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:21:51,621 [Listener at localhost/45230] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:51,625 [Listener at localhost/45230] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:21:51,626 [Listener at localhost/45230] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:21:51,627 [Listener at localhost/45230] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:21:51,627 [Listener at localhost/45230] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:21:51,630 [Listener at localhost/45230] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 38977
2020-12-03 07:21:51,631 [Listener at localhost/45230] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:21:51,633 [Listener at localhost/45230] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7a7471ce{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:21:51,633 [Listener at localhost/45230] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@62e70ea3{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:21:52,148 [Listener at localhost/45230] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@61526469{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:21:52,149 [Listener at localhost/45230] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@274872f8{HTTP/1.1,[http/1.1]}{localhost:38977}
2020-12-03 07:21:52,150 [Listener at localhost/45230] INFO  server.Server (Server.java:doStart(419)) - Started @6074ms
2020-12-03 07:21:52,420 [Listener at localhost/45230] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:38160
2020-12-03 07:21:52,421 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@200a26bc] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:21:52,423 [Listener at localhost/45230] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:21:52,423 [Listener at localhost/45230] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:21:52,610 [Listener at localhost/45230] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:21:52,611 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:21:52,620 [Listener at localhost/39899] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:39899
2020-12-03 07:21:52,636 [Listener at localhost/39899] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:21:52,637 [Listener at localhost/39899] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:21:52,648 [Thread-59] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45230 starting to offer service
2020-12-03 07:21:52,654 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:21:52,654 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:21:52,659 [Listener at localhost/39899] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3,[ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:21:52,661 [Listener at localhost/39899] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:21:52,684 [Listener at localhost/39899] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:21:52,686 [Listener at localhost/39899] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:21:52,687 [Listener at localhost/39899] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:52,687 [Listener at localhost/39899] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:21:52,688 [Listener at localhost/39899] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:21:52,688 [Listener at localhost/39899] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:52,688 [Listener at localhost/39899] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:52,688 [Listener at localhost/39899] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:52,689 [Listener at localhost/39899] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:21:52,690 [Listener at localhost/39899] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:33473
2020-12-03 07:21:52,690 [Listener at localhost/39899] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:21:52,690 [Listener at localhost/39899] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:21:52,691 [Listener at localhost/39899] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:52,694 [Listener at localhost/39899] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:21:52,695 [Listener at localhost/39899] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:21:52,695 [Listener at localhost/39899] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:52,698 [Listener at localhost/39899] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:21:52,699 [Listener at localhost/39899] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:21:52,700 [Listener at localhost/39899] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:21:52,700 [Listener at localhost/39899] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:21:52,702 [Listener at localhost/39899] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 38834
2020-12-03 07:21:52,702 [Listener at localhost/39899] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:21:52,704 [Listener at localhost/39899] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@24be2d9c{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:21:52,705 [Listener at localhost/39899] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@aec50a1{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:21:52,712 [Listener at localhost/39899] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@29ad44e3{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:21:52,714 [Listener at localhost/39899] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@15bcf458{HTTP/1.1,[http/1.1]}{localhost:38834}
2020-12-03 07:21:52,715 [Listener at localhost/39899] INFO  server.Server (Server.java:doStart(419)) - Started @6639ms
2020-12-03 07:21:52,859 [Listener at localhost/39899] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:45306
2020-12-03 07:21:52,859 [Listener at localhost/39899] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:21:52,859 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@43c67247] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:21:52,860 [Listener at localhost/39899] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:21:52,861 [Listener at localhost/39899] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:21:52,863 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:21:52,870 [Listener at localhost/46034] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:46034
2020-12-03 07:21:52,882 [Listener at localhost/46034] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:21:52,883 [Listener at localhost/46034] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:21:52,884 [Thread-83] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45230 starting to offer service
2020-12-03 07:21:52,886 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:21:52,888 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:21:52,891 [Listener at localhost/46034] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5,[ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:21:52,894 [Listener at localhost/46034] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:21:52,895 [Listener at localhost/46034] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:21:52,898 [Listener at localhost/46034] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:21:52,898 [Listener at localhost/46034] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:52,899 [Listener at localhost/46034] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:21:52,899 [Listener at localhost/46034] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:21:52,900 [Listener at localhost/46034] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:52,900 [Listener at localhost/46034] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:52,900 [Listener at localhost/46034] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:52,901 [Listener at localhost/46034] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:21:52,907 [Listener at localhost/46034] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:37814
2020-12-03 07:21:52,908 [Listener at localhost/46034] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:21:52,908 [Listener at localhost/46034] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:21:52,910 [Listener at localhost/46034] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:52,912 [Listener at localhost/46034] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:21:52,914 [Listener at localhost/46034] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:21:52,914 [Listener at localhost/46034] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:52,917 [Listener at localhost/46034] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:21:52,919 [Listener at localhost/46034] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:21:52,919 [Listener at localhost/46034] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:21:52,919 [Listener at localhost/46034] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:21:52,921 [Listener at localhost/46034] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 41327
2020-12-03 07:21:52,921 [Listener at localhost/46034] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:21:52,923 [Listener at localhost/46034] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1e11bc55{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:21:52,924 [Listener at localhost/46034] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@70e0accd{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:21:52,932 [Listener at localhost/46034] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3d4d3fe7{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:21:52,933 [Listener at localhost/46034] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@65f87a2c{HTTP/1.1,[http/1.1]}{localhost:41327}
2020-12-03 07:21:52,933 [Listener at localhost/46034] INFO  server.Server (Server.java:doStart(419)) - Started @6857ms
2020-12-03 07:21:52,963 [Listener at localhost/46034] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:36606
2020-12-03 07:21:52,964 [Listener at localhost/46034] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:21:52,964 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6ce1f601] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:21:52,964 [Listener at localhost/46034] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:21:52,965 [Listener at localhost/46034] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:21:52,966 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:21:52,973 [Listener at localhost/45822] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:45822
2020-12-03 07:21:52,981 [Listener at localhost/45822] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:21:52,981 [Listener at localhost/45822] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:21:52,982 [Thread-105] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45230 starting to offer service
2020-12-03 07:21:52,990 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:21:52,990 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:21:52,993 [Listener at localhost/45822] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 3 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7,[ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:21:53,001 [Listener at localhost/45822] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:21:53,002 [Listener at localhost/45822] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:21:53,003 [Listener at localhost/45822] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:21:53,007 [Listener at localhost/45822] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:53,007 [Listener at localhost/45822] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:21:53,008 [Listener at localhost/45822] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:21:53,008 [Listener at localhost/45822] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:53,009 [Listener at localhost/45822] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:53,009 [Listener at localhost/45822] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:53,009 [Listener at localhost/45822] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:21:53,010 [Listener at localhost/45822] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:32984
2020-12-03 07:21:53,011 [Listener at localhost/45822] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:21:53,011 [Listener at localhost/45822] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:21:53,013 [Listener at localhost/45822] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:53,015 [Listener at localhost/45822] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:21:53,019 [Listener at localhost/45822] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:21:53,019 [Listener at localhost/45822] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:53,023 [Listener at localhost/45822] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:21:53,024 [Listener at localhost/45822] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:21:53,024 [Listener at localhost/45822] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:21:53,025 [Listener at localhost/45822] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:21:53,026 [Listener at localhost/45822] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 35805
2020-12-03 07:21:53,026 [Listener at localhost/45822] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:21:53,029 [Listener at localhost/45822] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@49a64d82{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:21:53,030 [Listener at localhost/45822] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@66d23e4a{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:21:53,037 [Listener at localhost/45822] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@37d3d232{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:21:53,038 [Listener at localhost/45822] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@30c0ccff{HTTP/1.1,[http/1.1]}{localhost:35805}
2020-12-03 07:21:53,039 [Listener at localhost/45822] INFO  server.Server (Server.java:doStart(419)) - Started @6963ms
2020-12-03 07:21:53,127 [Listener at localhost/45822] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:36618
2020-12-03 07:21:53,128 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@22db8f4] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:21:53,128 [Listener at localhost/45822] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:21:53,128 [Listener at localhost/45822] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:21:53,129 [Listener at localhost/45822] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:21:53,130 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:21:53,138 [Listener at localhost/44632] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:44632
2020-12-03 07:21:53,143 [Listener at localhost/44632] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:21:53,144 [Listener at localhost/44632] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:21:53,150 [Thread-127] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45230 starting to offer service
2020-12-03 07:21:53,157 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:21:53,157 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:21:53,160 [Listener at localhost/44632] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 4 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9,[ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:21:53,162 [Listener at localhost/44632] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:21:53,166 [Listener at localhost/44632] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:21:53,168 [Thread-83] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45230
2020-12-03 07:21:53,168 [Thread-105] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45230
2020-12-03 07:21:53,168 [Thread-59] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45230
2020-12-03 07:21:53,169 [Listener at localhost/44632] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:21:53,174 [Listener at localhost/44632] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:53,174 [Listener at localhost/44632] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:21:53,174 [Thread-83] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:21:53,174 [Thread-59] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:21:53,175 [Listener at localhost/44632] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:21:53,175 [Thread-105] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:21:53,176 [Listener at localhost/44632] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:53,176 [Listener at localhost/44632] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:53,176 [Listener at localhost/44632] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:53,177 [Listener at localhost/44632] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:21:53,177 [Thread-127] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45230
2020-12-03 07:21:53,178 [Listener at localhost/44632] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:41579
2020-12-03 07:21:53,179 [Thread-127] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:21:53,179 [Listener at localhost/44632] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:21:53,179 [Listener at localhost/44632] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:21:53,181 [Listener at localhost/44632] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:53,184 [Listener at localhost/44632] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:21:53,185 [Listener at localhost/44632] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:21:53,185 [Listener at localhost/44632] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:53,188 [Listener at localhost/44632] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:21:53,189 [Listener at localhost/44632] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:21:53,190 [Listener at localhost/44632] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:21:53,190 [Listener at localhost/44632] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:21:53,192 [Listener at localhost/44632] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 38533
2020-12-03 07:21:53,192 [Listener at localhost/44632] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:21:53,197 [Listener at localhost/44632] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7728643a{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:21:53,198 [Listener at localhost/44632] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5167268{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:21:53,206 [Listener at localhost/44632] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1bc53649{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:21:53,207 [Listener at localhost/44632] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@88d6f9b{HTTP/1.1,[http/1.1]}{localhost:38533}
2020-12-03 07:21:53,207 [Listener at localhost/44632] INFO  server.Server (Server.java:doStart(419)) - Started @7132ms
2020-12-03 07:21:53,224 [Listener at localhost/44632] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:34104
2020-12-03 07:21:53,224 [Listener at localhost/44632] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:21:53,225 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@475b7792] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:21:53,225 [Listener at localhost/44632] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:21:53,225 [Listener at localhost/44632] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:21:53,226 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:21:53,233 [Listener at localhost/35306] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:35306
2020-12-03 07:21:53,238 [Listener at localhost/35306] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:21:53,238 [Listener at localhost/35306] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:21:53,239 [Thread-149] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45230 starting to offer service
2020-12-03 07:21:53,240 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:21:53,241 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:21:53,244 [Listener at localhost/35306] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 5 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11,[ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:21:53,244 [Thread-149] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45230
2020-12-03 07:21:53,245 [Thread-149] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:21:53,246 [Listener at localhost/35306] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:21:53,246 [Listener at localhost/35306] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:21:53,247 [Listener at localhost/35306] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:21:53,248 [Listener at localhost/35306] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:53,249 [Listener at localhost/35306] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:21:53,249 [Listener at localhost/35306] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:21:53,249 [Listener at localhost/35306] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:21:53,249 [Listener at localhost/35306] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:53,250 [Listener at localhost/35306] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:53,250 [Listener at localhost/35306] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:21:53,251 [Listener at localhost/35306] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:45300
2020-12-03 07:21:53,251 [Listener at localhost/35306] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:21:53,251 [Listener at localhost/35306] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:21:53,252 [Listener at localhost/35306] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:53,254 [Listener at localhost/35306] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:21:53,255 [Listener at localhost/35306] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:21:53,255 [Listener at localhost/35306] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:21:53,257 [Listener at localhost/35306] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:21:53,258 [Listener at localhost/35306] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:21:53,258 [Listener at localhost/35306] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:21:53,258 [Listener at localhost/35306] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:21:53,259 [Listener at localhost/35306] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 32929
2020-12-03 07:21:53,259 [Listener at localhost/35306] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:21:53,261 [Listener at localhost/35306] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@27dc79f7{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:21:53,262 [Listener at localhost/35306] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3aaf4f07{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:21:53,269 [Listener at localhost/35306] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@a23a01d{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:21:53,270 [Listener at localhost/35306] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4acf72b6{HTTP/1.1,[http/1.1]}{localhost:32929}
2020-12-03 07:21:53,270 [Listener at localhost/35306] INFO  server.Server (Server.java:doStart(419)) - Started @7195ms
2020-12-03 07:21:53,287 [Listener at localhost/35306] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:44463
2020-12-03 07:21:53,288 [Listener at localhost/35306] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:21:53,288 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3301500b] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:21:53,288 [Listener at localhost/35306] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:21:53,288 [Listener at localhost/35306] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:21:53,289 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:21:53,293 [Listener at localhost/42839] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:42839
2020-12-03 07:21:53,298 [Listener at localhost/42839] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-12-03 07:21:53,299 [Listener at localhost/42839] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-12-03 07:21:53,300 [Thread-171] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45230 starting to offer service
2020-12-03 07:21:53,301 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:21:53,301 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:21:53,305 [Thread-171] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45230
2020-12-03 07:21:53,305 [Thread-171] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:21:53,388 [Thread-59] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 5887@f865fdeb6a4d
2020-12-03 07:21:53,388 [Thread-105] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 5887@f865fdeb6a4d
2020-12-03 07:21:53,388 [Thread-83] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 5887@f865fdeb6a4d
2020-12-03 07:21:53,388 [Thread-127] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/in_use.lock acquired by nodename 5887@f865fdeb6a4d
2020-12-03 07:21:53,388 [Thread-149] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/in_use.lock acquired by nodename 5887@f865fdeb6a4d
2020-12-03 07:21:53,389 [Thread-127] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 is not formatted for namespace 842850756. Formatting...
2020-12-03 07:21:53,390 [Thread-149] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 is not formatted for namespace 842850756. Formatting...
2020-12-03 07:21:53,389 [Thread-83] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 is not formatted for namespace 842850756. Formatting...
2020-12-03 07:21:53,389 [Thread-105] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 is not formatted for namespace 842850756. Formatting...
2020-12-03 07:21:53,389 [Thread-59] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 842850756. Formatting...
2020-12-03 07:21:53,391 [Thread-59] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-1c271b4a-d89b-4e1c-a0ff-ab9324fd2701 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-12-03 07:21:53,391 [Thread-105] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-72955610-3c7e-4c7c-951e-a6a14c5e58c7 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 
2020-12-03 07:21:53,391 [Thread-149] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-f315ba39-e731-4476-b158-45472322d819 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 
2020-12-03 07:21:53,391 [Thread-83] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-67b68069-6b27-4918-9b5e-0a7ff02f0fbb for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 
2020-12-03 07:21:53,391 [Thread-127] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-663ecb93-4311-4d45-8b9d-dda56e688031 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 
2020-12-03 07:21:53,514 [Thread-171] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/in_use.lock acquired by nodename 5887@f865fdeb6a4d
2020-12-03 07:21:53,515 [Thread-171] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 is not formatted for namespace 842850756. Formatting...
2020-12-03 07:21:53,517 [Thread-171] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-4043d8ae-e217-4451-b41b-c6f4a1d90932 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 
2020-12-03 07:21:53,785 [IPC Server handler 2 on default port 45230] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:53,795 [Listener at localhost/42839] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:53,795 [Listener at localhost/42839] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:53,898 [IPC Server handler 1 on default port 45230] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:53,899 [Listener at localhost/42839] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:53,900 [Listener at localhost/42839] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:54,002 [IPC Server handler 0 on default port 45230] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:54,003 [Listener at localhost/42839] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:54,003 [Listener at localhost/42839] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:54,076 [Thread-127] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/in_use.lock acquired by nodename 5887@f865fdeb6a4d
2020-12-03 07:21:54,076 [Thread-149] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/in_use.lock acquired by nodename 5887@f865fdeb6a4d
2020-12-03 07:21:54,076 [Thread-83] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 5887@f865fdeb6a4d
2020-12-03 07:21:54,076 [Thread-105] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 5887@f865fdeb6a4d
2020-12-03 07:21:54,077 [Thread-83] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 is not formatted for namespace 842850756. Formatting...
2020-12-03 07:21:54,077 [Thread-59] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 5887@f865fdeb6a4d
2020-12-03 07:21:54,077 [Thread-149] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 is not formatted for namespace 842850756. Formatting...
2020-12-03 07:21:54,077 [Thread-127] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 is not formatted for namespace 842850756. Formatting...
2020-12-03 07:21:54,077 [Thread-105] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 is not formatted for namespace 842850756. Formatting...
2020-12-03 07:21:54,078 [Thread-59] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 842850756. Formatting...
2020-12-03 07:21:54,079 [Thread-149] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-026e13dd-35d5-4adf-8b07-491909e719d2 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 
2020-12-03 07:21:54,079 [Thread-105] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-3fc583cb-7f40-46a3-bfbe-cbc88b91b532 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 
2020-12-03 07:21:54,079 [Thread-59] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-d8b288e5-db08-432f-b76c-3eca5f9e8bde for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-12-03 07:21:54,079 [Thread-127] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-b23c426a-754c-4393-8696-07f4de19fa1c for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 
2020-12-03 07:21:54,079 [Thread-83] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-f4ef0132-50b8-4d37-ba1f-ef3ba0c4480e for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 
2020-12-03 07:21:54,105 [IPC Server handler 3 on default port 45230] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:54,106 [Listener at localhost/42839] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:54,106 [Listener at localhost/42839] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:54,181 [Thread-171] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/in_use.lock acquired by nodename 5887@f865fdeb6a4d
2020-12-03 07:21:54,181 [Thread-171] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 is not formatted for namespace 842850756. Formatting...
2020-12-03 07:21:54,184 [Thread-171] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-2737b381-4945-4d6f-abf9-74d86f4ee894 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 
2020-12-03 07:21:54,209 [IPC Server handler 4 on default port 45230] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:54,209 [Listener at localhost/42839] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:54,210 [Listener at localhost/42839] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:54,311 [IPC Server handler 6 on default port 45230] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:54,312 [Listener at localhost/42839] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:54,312 [Listener at localhost/42839] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:54,415 [IPC Server handler 7 on default port 45230] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:54,415 [Listener at localhost/42839] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:54,415 [Listener at localhost/42839] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:54,494 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1100016829-172.17.0.10-1606980108214
2020-12-03 07:21:54,495 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1100016829-172.17.0.10-1606980108214
2020-12-03 07:21:54,495 [Thread-59] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1100016829-172.17.0.10-1606980108214
2020-12-03 07:21:54,495 [Thread-149] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1100016829-172.17.0.10-1606980108214
2020-12-03 07:21:54,495 [Thread-127] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1100016829-172.17.0.10-1606980108214
2020-12-03 07:21:54,496 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1100016829-172.17.0.10-1606980108214
2020-12-03 07:21:54,496 [Thread-127] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1100016829-172.17.0.10-1606980108214
2020-12-03 07:21:54,496 [Thread-105] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1100016829-172.17.0.10-1606980108214
2020-12-03 07:21:54,496 [Thread-127] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 and block pool id BP-1100016829-172.17.0.10-1606980108214 is not formatted. Formatting ...
2020-12-03 07:21:54,496 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-1100016829-172.17.0.10-1606980108214 is not formatted. Formatting ...
2020-12-03 07:21:54,496 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 and block pool id BP-1100016829-172.17.0.10-1606980108214 is not formatted. Formatting ...
2020-12-03 07:21:54,496 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1100016829-172.17.0.10-1606980108214
2020-12-03 07:21:54,496 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1100016829-172.17.0.10-1606980108214 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1100016829-172.17.0.10-1606980108214/current
2020-12-03 07:21:54,496 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1100016829-172.17.0.10-1606980108214 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1100016829-172.17.0.10-1606980108214/current
2020-12-03 07:21:54,496 [Thread-127] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1100016829-172.17.0.10-1606980108214 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1100016829-172.17.0.10-1606980108214/current
2020-12-03 07:21:54,496 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 and block pool id BP-1100016829-172.17.0.10-1606980108214 is not formatted. Formatting ...
2020-12-03 07:21:54,497 [Thread-83] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1100016829-172.17.0.10-1606980108214
2020-12-03 07:21:54,497 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1100016829-172.17.0.10-1606980108214 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1100016829-172.17.0.10-1606980108214/current
2020-12-03 07:21:54,497 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 and block pool id BP-1100016829-172.17.0.10-1606980108214 is not formatted. Formatting ...
2020-12-03 07:21:54,497 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1100016829-172.17.0.10-1606980108214 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1100016829-172.17.0.10-1606980108214/current
2020-12-03 07:21:54,518 [IPC Server handler 2 on default port 45230] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:54,519 [Listener at localhost/42839] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:54,519 [Listener at localhost/42839] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:54,531 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1100016829-172.17.0.10-1606980108214
2020-12-03 07:21:54,531 [Thread-171] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1100016829-172.17.0.10-1606980108214
2020-12-03 07:21:54,531 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 and block pool id BP-1100016829-172.17.0.10-1606980108214 is not formatted. Formatting ...
2020-12-03 07:21:54,531 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1100016829-172.17.0.10-1606980108214 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1100016829-172.17.0.10-1606980108214/current
2020-12-03 07:21:54,621 [IPC Server handler 1 on default port 45230] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:54,622 [Listener at localhost/42839] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:54,622 [Listener at localhost/42839] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:54,724 [IPC Server handler 0 on default port 45230] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:54,726 [Listener at localhost/42839] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:54,726 [Listener at localhost/42839] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:54,818 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1100016829-172.17.0.10-1606980108214
2020-12-03 07:21:54,818 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1100016829-172.17.0.10-1606980108214
2020-12-03 07:21:54,818 [Thread-127] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1100016829-172.17.0.10-1606980108214
2020-12-03 07:21:54,818 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1100016829-172.17.0.10-1606980108214
2020-12-03 07:21:54,819 [Thread-83] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1100016829-172.17.0.10-1606980108214
2020-12-03 07:21:54,818 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1100016829-172.17.0.10-1606980108214
2020-12-03 07:21:54,819 [Thread-59] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1100016829-172.17.0.10-1606980108214
2020-12-03 07:21:54,819 [Thread-127] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1100016829-172.17.0.10-1606980108214
2020-12-03 07:21:54,819 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-1100016829-172.17.0.10-1606980108214 is not formatted. Formatting ...
2020-12-03 07:21:54,819 [Thread-127] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 and block pool id BP-1100016829-172.17.0.10-1606980108214 is not formatted. Formatting ...
2020-12-03 07:21:54,819 [Thread-149] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1100016829-172.17.0.10-1606980108214
2020-12-03 07:21:54,819 [Thread-105] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1100016829-172.17.0.10-1606980108214
2020-12-03 07:21:54,819 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 and block pool id BP-1100016829-172.17.0.10-1606980108214 is not formatted. Formatting ...
2020-12-03 07:21:54,820 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 and block pool id BP-1100016829-172.17.0.10-1606980108214 is not formatted. Formatting ...
2020-12-03 07:21:54,819 [Thread-127] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1100016829-172.17.0.10-1606980108214 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1100016829-172.17.0.10-1606980108214/current
2020-12-03 07:21:54,819 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1100016829-172.17.0.10-1606980108214 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1100016829-172.17.0.10-1606980108214/current
2020-12-03 07:21:54,820 [Thread-149] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1100016829-172.17.0.10-1606980108214 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1100016829-172.17.0.10-1606980108214/current
2020-12-03 07:21:54,820 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 and block pool id BP-1100016829-172.17.0.10-1606980108214 is not formatted. Formatting ...
2020-12-03 07:21:54,820 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1100016829-172.17.0.10-1606980108214 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1100016829-172.17.0.10-1606980108214/current
2020-12-03 07:21:54,820 [Thread-105] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1100016829-172.17.0.10-1606980108214 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1100016829-172.17.0.10-1606980108214/current
2020-12-03 07:21:54,828 [IPC Server handler 3 on default port 45230] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:54,828 [Listener at localhost/42839] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:54,829 [Listener at localhost/42839] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:54,900 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1100016829-172.17.0.10-1606980108214
2020-12-03 07:21:54,901 [Thread-171] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1100016829-172.17.0.10-1606980108214
2020-12-03 07:21:54,901 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 and block pool id BP-1100016829-172.17.0.10-1606980108214 is not formatted. Formatting ...
2020-12-03 07:21:54,901 [Thread-171] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1100016829-172.17.0.10-1606980108214 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1100016829-172.17.0.10-1606980108214/current
2020-12-03 07:21:54,931 [IPC Server handler 4 on default port 45230] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:54,931 [Listener at localhost/42839] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:54,932 [Listener at localhost/42839] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:55,034 [IPC Server handler 5 on default port 45230] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:55,035 [Listener at localhost/42839] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:55,035 [Listener at localhost/42839] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:55,140 [IPC Server handler 6 on default port 45230] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:55,140 [Listener at localhost/42839] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:55,141 [Listener at localhost/42839] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:55,156 [Thread-59] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=842850756;bpid=BP-1100016829-172.17.0.10-1606980108214;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=842850756;c=1606980108214;bpid=BP-1100016829-172.17.0.10-1606980108214;dnuuid=null
2020-12-03 07:21:55,156 [Thread-105] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=842850756;bpid=BP-1100016829-172.17.0.10-1606980108214;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=842850756;c=1606980108214;bpid=BP-1100016829-172.17.0.10-1606980108214;dnuuid=null
2020-12-03 07:21:55,157 [Thread-83] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=842850756;bpid=BP-1100016829-172.17.0.10-1606980108214;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=842850756;c=1606980108214;bpid=BP-1100016829-172.17.0.10-1606980108214;dnuuid=null
2020-12-03 07:21:55,157 [Thread-127] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=842850756;bpid=BP-1100016829-172.17.0.10-1606980108214;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=842850756;c=1606980108214;bpid=BP-1100016829-172.17.0.10-1606980108214;dnuuid=null
2020-12-03 07:21:55,161 [Thread-149] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=842850756;bpid=BP-1100016829-172.17.0.10-1606980108214;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=842850756;c=1606980108214;bpid=BP-1100016829-172.17.0.10-1606980108214;dnuuid=null
2020-12-03 07:21:55,223 [Thread-171] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=842850756;bpid=BP-1100016829-172.17.0.10-1606980108214;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=842850756;c=1606980108214;bpid=BP-1100016829-172.17.0.10-1606980108214;dnuuid=null
2020-12-03 07:21:55,243 [IPC Server handler 7 on default port 45230] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:55,244 [Listener at localhost/42839] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:55,244 [Listener at localhost/42839] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:55,347 [IPC Server handler 8 on default port 45230] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:55,348 [Listener at localhost/42839] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:55,349 [Listener at localhost/42839] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:55,451 [IPC Server handler 2 on default port 45230] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:55,452 [Listener at localhost/42839] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:55,452 [Listener at localhost/42839] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:55,500 [Thread-105] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 0c65a2b8-68d6-499f-9b6a-8441c2d9c440
2020-12-03 07:21:55,500 [Thread-83] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 0b683f72-a473-4822-835d-d3119cedc5f6
2020-12-03 07:21:55,500 [Thread-149] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 0844a5a5-9438-4d1d-94ac-28a738487d03
2020-12-03 07:21:55,500 [Thread-59] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID b66a2e06-3db7-4022-a57e-b577adcd540b
2020-12-03 07:21:55,500 [Thread-127] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 9b8e6ff5-6652-42d9-b0e3-a3e292609b38
2020-12-03 07:21:55,554 [IPC Server handler 1 on default port 45230] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:55,555 [Listener at localhost/42839] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:55,556 [Listener at localhost/42839] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:55,557 [Thread-171] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID ab8189f6-cdba-42cf-9d11-d75b6c95a9c7
2020-12-03 07:21:55,626 [Thread-127] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-663ecb93-4311-4d45-8b9d-dda56e688031
2020-12-03 07:21:55,626 [Thread-127] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, StorageType: DISK
2020-12-03 07:21:55,626 [Thread-105] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-72955610-3c7e-4c7c-951e-a6a14c5e58c7
2020-12-03 07:21:55,626 [Thread-171] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-4043d8ae-e217-4451-b41b-c6f4a1d90932
2020-12-03 07:21:55,626 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-67b68069-6b27-4918-9b5e-0a7ff02f0fbb
2020-12-03 07:21:55,628 [Thread-171] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, StorageType: DISK
2020-12-03 07:21:55,626 [Thread-149] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-f315ba39-e731-4476-b158-45472322d819
2020-12-03 07:21:55,626 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-1c271b4a-d89b-4e1c-a0ff-ab9324fd2701
2020-12-03 07:21:55,628 [Thread-105] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, StorageType: DISK
2020-12-03 07:21:55,629 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-12-03 07:21:55,629 [Thread-149] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, StorageType: DISK
2020-12-03 07:21:55,628 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: DISK
2020-12-03 07:21:55,630 [Thread-127] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-b23c426a-754c-4393-8696-07f4de19fa1c
2020-12-03 07:21:55,630 [Thread-127] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, StorageType: ARCHIVE
2020-12-03 07:21:55,630 [Thread-171] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-2737b381-4945-4d6f-abf9-74d86f4ee894
2020-12-03 07:21:55,631 [Thread-171] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, StorageType: ARCHIVE
2020-12-03 07:21:55,632 [Thread-105] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-3fc583cb-7f40-46a3-bfbe-cbc88b91b532
2020-12-03 07:21:55,632 [Thread-105] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, StorageType: ARCHIVE
2020-12-03 07:21:55,633 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-f4ef0132-50b8-4d37-ba1f-ef3ba0c4480e
2020-12-03 07:21:55,633 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: ARCHIVE
2020-12-03 07:21:55,637 [Thread-149] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-026e13dd-35d5-4adf-8b07-491909e719d2
2020-12-03 07:21:55,637 [Thread-149] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, StorageType: ARCHIVE
2020-12-03 07:21:55,638 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-d8b288e5-db08-432f-b76c-3eca5f9e8bde
2020-12-03 07:21:55,638 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [ARCHIVE]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: ARCHIVE
2020-12-03 07:21:55,639 [Thread-149] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:21:55,639 [Thread-127] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:21:55,639 [Thread-171] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:21:55,639 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:21:55,639 [Thread-105] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:21:55,639 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:21:55,645 [Thread-149] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:21:55,646 [Thread-59] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:21:55,647 [Thread-105] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:21:55,648 [Thread-83] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:21:55,648 [Thread-171] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:21:55,649 [Thread-127] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:21:55,654 [Thread-83] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:21:55,654 [Thread-171] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:21:55,654 [Thread-105] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:21:55,654 [Thread-149] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:21:55,654 [Thread-127] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:21:55,654 [Thread-59] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:21:55,656 [Thread-59] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:21:55,656 [Thread-127] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:21:55,656 [Thread-105] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:21:55,656 [Thread-127] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:21:55,656 [Thread-149] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:21:55,656 [Thread-171] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:21:55,656 [Thread-83] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:21:55,658 [Thread-171] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:21:55,657 [Thread-149] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:21:55,657 [Thread-127] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1100016829-172.17.0.10-1606980108214
2020-12-03 07:21:55,657 [Thread-105] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:21:55,656 [Thread-59] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:21:55,659 [IPC Server handler 0 on default port 45230] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:55,659 [Thread-105] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1100016829-172.17.0.10-1606980108214
2020-12-03 07:21:55,659 [Thread-149] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1100016829-172.17.0.10-1606980108214
2020-12-03 07:21:55,659 [Thread-171] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1100016829-172.17.0.10-1606980108214
2020-12-03 07:21:55,658 [Thread-83] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:21:55,659 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1100016829-172.17.0.10-1606980108214
2020-12-03 07:21:55,660 [Thread-198] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1100016829-172.17.0.10-1606980108214 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:21:55,660 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1100016829-172.17.0.10-1606980108214
2020-12-03 07:21:55,660 [Thread-201] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1100016829-172.17.0.10-1606980108214 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11...
2020-12-03 07:21:55,660 [Thread-197] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1100016829-172.17.0.10-1606980108214 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-12-03 07:21:55,660 [Thread-202] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1100016829-172.17.0.10-1606980108214 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:21:55,660 [Listener at localhost/42839] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:55,661 [Listener at localhost/42839] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:55,661 [Thread-203] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1100016829-172.17.0.10-1606980108214 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12...
2020-12-03 07:21:55,661 [Thread-199] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1100016829-172.17.0.10-1606980108214 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-12-03 07:21:55,661 [Thread-205] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1100016829-172.17.0.10-1606980108214 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:21:55,660 [Thread-200] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1100016829-172.17.0.10-1606980108214 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-12-03 07:21:55,662 [Thread-208] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1100016829-172.17.0.10-1606980108214 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:21:55,661 [Thread-207] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1100016829-172.17.0.10-1606980108214 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-12-03 07:21:55,661 [Thread-206] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1100016829-172.17.0.10-1606980108214 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:21:55,661 [Thread-204] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-1100016829-172.17.0.10-1606980108214 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:21:55,719 [Thread-197] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1100016829-172.17.0.10-1606980108214 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 59ms
2020-12-03 07:21:55,719 [Thread-202] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1100016829-172.17.0.10-1606980108214 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 58ms
2020-12-03 07:21:55,720 [Thread-206] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1100016829-172.17.0.10-1606980108214 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 58ms
2020-12-03 07:21:55,723 [Thread-198] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1100016829-172.17.0.10-1606980108214 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 63ms
2020-12-03 07:21:55,723 [Thread-105] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1100016829-172.17.0.10-1606980108214: 64ms
2020-12-03 07:21:55,723 [Thread-205] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1100016829-172.17.0.10-1606980108214 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 62ms
2020-12-03 07:21:55,723 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1100016829-172.17.0.10-1606980108214: 63ms
2020-12-03 07:21:55,724 [Thread-208] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1100016829-172.17.0.10-1606980108214 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 62ms
2020-12-03 07:21:55,725 [Thread-221] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1100016829-172.17.0.10-1606980108214 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:21:55,725 [Thread-223] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1100016829-172.17.0.10-1606980108214 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:21:55,725 [Thread-201] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1100016829-172.17.0.10-1606980108214 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11: 65ms
2020-12-03 07:21:55,726 [Thread-221] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1100016829-172.17.0.10-1606980108214/current/replicas doesn't exist 
2020-12-03 07:21:55,726 [Thread-223] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1100016829-172.17.0.10-1606980108214/current/replicas doesn't exist 
2020-12-03 07:21:55,728 [Thread-224] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1100016829-172.17.0.10-1606980108214 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:21:55,728 [Thread-224] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1100016829-172.17.0.10-1606980108214/current/replicas doesn't exist 
2020-12-03 07:21:55,728 [Thread-222] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1100016829-172.17.0.10-1606980108214 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:21:55,729 [Thread-203] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1100016829-172.17.0.10-1606980108214 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12: 67ms
2020-12-03 07:21:55,729 [Thread-222] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1100016829-172.17.0.10-1606980108214/current/replicas doesn't exist 
2020-12-03 07:21:55,729 [Thread-221] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1100016829-172.17.0.10-1606980108214 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 4ms
2020-12-03 07:21:55,729 [Thread-171] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1100016829-172.17.0.10-1606980108214: 69ms
2020-12-03 07:21:55,729 [Thread-224] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1100016829-172.17.0.10-1606980108214 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 1ms
2020-12-03 07:21:55,729 [Thread-223] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1100016829-172.17.0.10-1606980108214 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 4ms
2020-12-03 07:21:55,730 [Thread-222] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1100016829-172.17.0.10-1606980108214 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 1ms
2020-12-03 07:21:55,731 [Thread-105] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1100016829-172.17.0.10-1606980108214: 6ms
2020-12-03 07:21:55,731 [Thread-199] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1100016829-172.17.0.10-1606980108214 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 70ms
2020-12-03 07:21:55,731 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1100016829-172.17.0.10-1606980108214: 6ms
2020-12-03 07:21:55,731 [Thread-225] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1100016829-172.17.0.10-1606980108214 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11...
2020-12-03 07:21:55,731 [Thread-226] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1100016829-172.17.0.10-1606980108214 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12...
2020-12-03 07:21:55,731 [Thread-207] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1100016829-172.17.0.10-1606980108214 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 69ms
2020-12-03 07:21:55,731 [Thread-226] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1100016829-172.17.0.10-1606980108214/current/replicas doesn't exist 
2020-12-03 07:21:55,731 [Thread-149] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1100016829-172.17.0.10-1606980108214: 71ms
2020-12-03 07:21:55,731 [Thread-200] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1100016829-172.17.0.10-1606980108214 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 69ms
2020-12-03 07:21:55,731 [Thread-225] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1100016829-172.17.0.10-1606980108214/current/replicas doesn't exist 
2020-12-03 07:21:55,732 [Thread-127] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1100016829-172.17.0.10-1606980108214: 73ms
2020-12-03 07:21:55,732 [Thread-226] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1100016829-172.17.0.10-1606980108214 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12: 1ms
2020-12-03 07:21:55,732 [Thread-228] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1100016829-172.17.0.10-1606980108214 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-12-03 07:21:55,732 [Thread-227] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1100016829-172.17.0.10-1606980108214 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-12-03 07:21:55,732 [Thread-204] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-1100016829-172.17.0.10-1606980108214 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 70ms
2020-12-03 07:21:55,732 [Thread-225] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1100016829-172.17.0.10-1606980108214 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11: 1ms
2020-12-03 07:21:55,733 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-1100016829-172.17.0.10-1606980108214: 73ms
2020-12-03 07:21:55,733 [Thread-228] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1100016829-172.17.0.10-1606980108214/current/replicas doesn't exist 
2020-12-03 07:21:55,733 [Thread-227] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1100016829-172.17.0.10-1606980108214/current/replicas doesn't exist 
2020-12-03 07:21:55,733 [Thread-229] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1100016829-172.17.0.10-1606980108214 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-12-03 07:21:55,734 [Thread-231] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1100016829-172.17.0.10-1606980108214 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:21:55,735 [Thread-227] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1100016829-172.17.0.10-1606980108214 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 2ms
2020-12-03 07:21:55,733 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1100016829-172.17.0.10-1606980108214 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:21:55,733 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1100016829-172.17.0.10-1606980108214 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:21:55,733 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1100016829-172.17.0.10-1606980108214 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:21:55,733 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1100016829-172.17.0.10-1606980108214 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:21:55,733 [Thread-171] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1100016829-172.17.0.10-1606980108214: 3ms
2020-12-03 07:21:55,733 [Thread-230] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1100016829-172.17.0.10-1606980108214 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-12-03 07:21:55,735 [Thread-228] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1100016829-172.17.0.10-1606980108214 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 3ms
2020-12-03 07:21:55,735 [Thread-231] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1100016829-172.17.0.10-1606980108214/current/replicas doesn't exist 
2020-12-03 07:21:55,735 [Thread-232] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-1100016829-172.17.0.10-1606980108214 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:21:55,736 [Thread-232] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1100016829-172.17.0.10-1606980108214/current/replicas doesn't exist 
2020-12-03 07:21:55,736 [Thread-231] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1100016829-172.17.0.10-1606980108214 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 1ms
2020-12-03 07:21:55,736 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-67b68069-6b27-4918-9b5e-0a7ff02f0fbb): finished scanning block pool BP-1100016829-172.17.0.10-1606980108214
2020-12-03 07:21:55,735 [Thread-229] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1100016829-172.17.0.10-1606980108214/current/replicas doesn't exist 
2020-12-03 07:21:55,736 [Thread-232] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1100016829-172.17.0.10-1606980108214 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 0ms
2020-12-03 07:21:55,736 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-f4ef0132-50b8-4d37-ba1f-ef3ba0c4480e): finished scanning block pool BP-1100016829-172.17.0.10-1606980108214
2020-12-03 07:21:55,737 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1100016829-172.17.0.10-1606980108214: 4ms
2020-12-03 07:21:55,737 [Thread-229] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1100016829-172.17.0.10-1606980108214 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 3ms
2020-12-03 07:21:55,736 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-72955610-3c7e-4c7c-951e-a6a14c5e58c7): finished scanning block pool BP-1100016829-172.17.0.10-1606980108214
2020-12-03 07:21:55,736 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-3fc583cb-7f40-46a3-bfbe-cbc88b91b532): finished scanning block pool BP-1100016829-172.17.0.10-1606980108214
2020-12-03 07:21:55,736 [Thread-149] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1100016829-172.17.0.10-1606980108214: 5ms
2020-12-03 07:21:55,736 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1100016829-172.17.0.10-1606980108214 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:21:55,736 [Thread-230] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1100016829-172.17.0.10-1606980108214/current/replicas doesn't exist 
2020-12-03 07:21:55,736 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1100016829-172.17.0.10-1606980108214 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:21:55,738 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1100016829-172.17.0.10-1606980108214 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:21:55,738 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-4043d8ae-e217-4451-b41b-c6f4a1d90932): finished scanning block pool BP-1100016829-172.17.0.10-1606980108214
2020-12-03 07:21:55,738 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1100016829-172.17.0.10-1606980108214 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:21:55,737 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1100016829-172.17.0.10-1606980108214 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:21:55,737 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1100016829-172.17.0.10-1606980108214 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:21:55,738 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-f315ba39-e731-4476-b158-45472322d819): finished scanning block pool BP-1100016829-172.17.0.10-1606980108214
2020-12-03 07:21:55,738 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-2737b381-4945-4d6f-abf9-74d86f4ee894): finished scanning block pool BP-1100016829-172.17.0.10-1606980108214
2020-12-03 07:21:55,738 [Thread-230] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-1100016829-172.17.0.10-1606980108214 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 2ms
2020-12-03 07:21:55,739 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-1c271b4a-d89b-4e1c-a0ff-ab9324fd2701): finished scanning block pool BP-1100016829-172.17.0.10-1606980108214
2020-12-03 07:21:55,739 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-d8b288e5-db08-432f-b76c-3eca5f9e8bde): finished scanning block pool BP-1100016829-172.17.0.10-1606980108214
2020-12-03 07:21:55,739 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-026e13dd-35d5-4adf-8b07-491909e719d2): finished scanning block pool BP-1100016829-172.17.0.10-1606980108214
2020-12-03 07:21:55,739 [Thread-127] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-1100016829-172.17.0.10-1606980108214: 7ms
2020-12-03 07:21:55,740 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1100016829-172.17.0.10-1606980108214 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:21:55,740 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-1100016829-172.17.0.10-1606980108214 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:21:55,740 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-663ecb93-4311-4d45-8b9d-dda56e688031): finished scanning block pool BP-1100016829-172.17.0.10-1606980108214
2020-12-03 07:21:55,740 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-b23c426a-754c-4393-8696-07f4de19fa1c): finished scanning block pool BP-1100016829-172.17.0.10-1606980108214
2020-12-03 07:21:55,759 [Thread-149] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 12:55 PM with interval of 21600000ms
2020-12-03 07:21:55,759 [Thread-171] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 7:45 AM with interval of 21600000ms
2020-12-03 07:21:55,759 [Thread-83] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 8:04 AM with interval of 21600000ms
2020-12-03 07:21:55,759 [Thread-105] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 9:13 AM with interval of 21600000ms
2020-12-03 07:21:55,759 [Thread-127] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:40 AM with interval of 21600000ms
2020-12-03 07:21:55,759 [Thread-59] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 7:39 AM with interval of 21600000ms
2020-12-03 07:21:55,764 [IPC Server handler 3 on default port 45230] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:55,764 [Listener at localhost/42839] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:21:55,765 [Listener at localhost/42839] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:21:55,769 [BP-1100016829-172.17.0.10-1606980108214 heartbeating to localhost/127.0.0.1:45230] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1100016829-172.17.0.10-1606980108214 (Datanode Uuid 0b683f72-a473-4822-835d-d3119cedc5f6) service to localhost/127.0.0.1:45230 beginning handshake with NN
2020-12-03 07:21:55,772 [BP-1100016829-172.17.0.10-1606980108214 heartbeating to localhost/127.0.0.1:45230] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1100016829-172.17.0.10-1606980108214 (Datanode Uuid 9b8e6ff5-6652-42d9-b0e3-a3e292609b38) service to localhost/127.0.0.1:45230 beginning handshake with NN
2020-12-03 07:21:55,772 [BP-1100016829-172.17.0.10-1606980108214 heartbeating to localhost/127.0.0.1:45230] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1100016829-172.17.0.10-1606980108214 (Datanode Uuid 0844a5a5-9438-4d1d-94ac-28a738487d03) service to localhost/127.0.0.1:45230 beginning handshake with NN
2020-12-03 07:21:55,772 [BP-1100016829-172.17.0.10-1606980108214 heartbeating to localhost/127.0.0.1:45230] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1100016829-172.17.0.10-1606980108214 (Datanode Uuid 0c65a2b8-68d6-499f-9b6a-8441c2d9c440) service to localhost/127.0.0.1:45230 beginning handshake with NN
2020-12-03 07:21:55,772 [BP-1100016829-172.17.0.10-1606980108214 heartbeating to localhost/127.0.0.1:45230] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1100016829-172.17.0.10-1606980108214 (Datanode Uuid b66a2e06-3db7-4022-a57e-b577adcd540b) service to localhost/127.0.0.1:45230 beginning handshake with NN
2020-12-03 07:21:55,772 [BP-1100016829-172.17.0.10-1606980108214 heartbeating to localhost/127.0.0.1:45230] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-1100016829-172.17.0.10-1606980108214 (Datanode Uuid ab8189f6-cdba-42cf-9d11-d75b6c95a9c7) service to localhost/127.0.0.1:45230 beginning handshake with NN
2020-12-03 07:21:55,775 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-2737b381-4945-4d6f-abf9-74d86f4ee894): no suitable block pools found to scan.  Waiting 1814399961 ms.
2020-12-03 07:21:55,775 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-1c271b4a-d89b-4e1c-a0ff-ab9324fd2701): no suitable block pools found to scan.  Waiting 1814399962 ms.
2020-12-03 07:21:55,775 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-b23c426a-754c-4393-8696-07f4de19fa1c): no suitable block pools found to scan.  Waiting 1814399965 ms.
2020-12-03 07:21:55,775 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-3fc583cb-7f40-46a3-bfbe-cbc88b91b532): no suitable block pools found to scan.  Waiting 1814399958 ms.
2020-12-03 07:21:55,775 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-663ecb93-4311-4d45-8b9d-dda56e688031): no suitable block pools found to scan.  Waiting 1814399965 ms.
2020-12-03 07:21:55,775 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-d8b288e5-db08-432f-b76c-3eca5f9e8bde): no suitable block pools found to scan.  Waiting 1814399962 ms.
2020-12-03 07:21:55,775 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-f315ba39-e731-4476-b158-45472322d819): no suitable block pools found to scan.  Waiting 1814399963 ms.
2020-12-03 07:21:55,775 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-72955610-3c7e-4c7c-951e-a6a14c5e58c7): no suitable block pools found to scan.  Waiting 1814399958 ms.
2020-12-03 07:21:55,775 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-4043d8ae-e217-4451-b41b-c6f4a1d90932): no suitable block pools found to scan.  Waiting 1814399961 ms.
2020-12-03 07:21:55,775 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-f4ef0132-50b8-4d37-ba1f-ef3ba0c4480e): no suitable block pools found to scan.  Waiting 1814399958 ms.
2020-12-03 07:21:55,775 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-67b68069-6b27-4918-9b5e-0a7ff02f0fbb): no suitable block pools found to scan.  Waiting 1814399958 ms.
2020-12-03 07:21:55,775 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-026e13dd-35d5-4adf-8b07-491909e719d2): no suitable block pools found to scan.  Waiting 1814399963 ms.
2020-12-03 07:21:55,785 [IPC Server handler 7 on default port 45230] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:41579, datanodeUuid=0844a5a5-9438-4d1d-94ac-28a738487d03, infoPort=34104, infoSecurePort=0, ipcPort=35306, storageInfo=lv=-57;cid=testClusterID;nsid=842850756;c=1606980108214) storage 0844a5a5-9438-4d1d-94ac-28a738487d03
2020-12-03 07:21:55,787 [IPC Server handler 7 on default port 45230] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41579
2020-12-03 07:21:55,787 [IPC Server handler 7 on default port 45230] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 0844a5a5-9438-4d1d-94ac-28a738487d03 (127.0.0.1:41579).
2020-12-03 07:21:55,789 [IPC Server handler 5 on default port 45230] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:37814, datanodeUuid=0c65a2b8-68d6-499f-9b6a-8441c2d9c440, infoPort=36606, infoSecurePort=0, ipcPort=45822, storageInfo=lv=-57;cid=testClusterID;nsid=842850756;c=1606980108214) storage 0c65a2b8-68d6-499f-9b6a-8441c2d9c440
2020-12-03 07:21:55,789 [IPC Server handler 5 on default port 45230] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:37814
2020-12-03 07:21:55,790 [IPC Server handler 5 on default port 45230] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 0c65a2b8-68d6-499f-9b6a-8441c2d9c440 (127.0.0.1:37814).
2020-12-03 07:21:55,790 [IPC Server handler 4 on default port 45230] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:33473, datanodeUuid=0b683f72-a473-4822-835d-d3119cedc5f6, infoPort=45306, infoSecurePort=0, ipcPort=46034, storageInfo=lv=-57;cid=testClusterID;nsid=842850756;c=1606980108214) storage 0b683f72-a473-4822-835d-d3119cedc5f6
2020-12-03 07:21:55,790 [IPC Server handler 4 on default port 45230] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:33473
2020-12-03 07:21:55,790 [IPC Server handler 4 on default port 45230] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 0b683f72-a473-4822-835d-d3119cedc5f6 (127.0.0.1:33473).
2020-12-03 07:21:55,790 [IPC Server handler 6 on default port 45230] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:45300, datanodeUuid=ab8189f6-cdba-42cf-9d11-d75b6c95a9c7, infoPort=44463, infoSecurePort=0, ipcPort=42839, storageInfo=lv=-57;cid=testClusterID;nsid=842850756;c=1606980108214) storage ab8189f6-cdba-42cf-9d11-d75b6c95a9c7
2020-12-03 07:21:55,791 [IPC Server handler 6 on default port 45230] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:45300
2020-12-03 07:21:55,791 [IPC Server handler 6 on default port 45230] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN ab8189f6-cdba-42cf-9d11-d75b6c95a9c7 (127.0.0.1:45300).
2020-12-03 07:21:55,791 [IPC Server handler 8 on default port 45230] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:38111, datanodeUuid=b66a2e06-3db7-4022-a57e-b577adcd540b, infoPort=38160, infoSecurePort=0, ipcPort=39899, storageInfo=lv=-57;cid=testClusterID;nsid=842850756;c=1606980108214) storage b66a2e06-3db7-4022-a57e-b577adcd540b
2020-12-03 07:21:55,791 [IPC Server handler 8 on default port 45230] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38111
2020-12-03 07:21:55,792 [IPC Server handler 8 on default port 45230] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN b66a2e06-3db7-4022-a57e-b577adcd540b (127.0.0.1:38111).
2020-12-03 07:21:55,792 [IPC Server handler 9 on default port 45230] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:32984, datanodeUuid=9b8e6ff5-6652-42d9-b0e3-a3e292609b38, infoPort=36618, infoSecurePort=0, ipcPort=44632, storageInfo=lv=-57;cid=testClusterID;nsid=842850756;c=1606980108214) storage 9b8e6ff5-6652-42d9-b0e3-a3e292609b38
2020-12-03 07:21:55,792 [IPC Server handler 9 on default port 45230] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:32984
2020-12-03 07:21:55,792 [BP-1100016829-172.17.0.10-1606980108214 heartbeating to localhost/127.0.0.1:45230] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1100016829-172.17.0.10-1606980108214 (Datanode Uuid 0c65a2b8-68d6-499f-9b6a-8441c2d9c440) service to localhost/127.0.0.1:45230 successfully registered with NN
2020-12-03 07:21:55,793 [BP-1100016829-172.17.0.10-1606980108214 heartbeating to localhost/127.0.0.1:45230] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:45230 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-12-03 07:21:55,792 [BP-1100016829-172.17.0.10-1606980108214 heartbeating to localhost/127.0.0.1:45230] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1100016829-172.17.0.10-1606980108214 (Datanode Uuid 0b683f72-a473-4822-835d-d3119cedc5f6) service to localhost/127.0.0.1:45230 successfully registered with NN
2020-12-03 07:21:55,793 [BP-1100016829-172.17.0.10-1606980108214 heartbeating to localhost/127.0.0.1:45230] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:45230 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-12-03 07:21:55,792 [BP-1100016829-172.17.0.10-1606980108214 heartbeating to localhost/127.0.0.1:45230] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1100016829-172.17.0.10-1606980108214 (Datanode Uuid ab8189f6-cdba-42cf-9d11-d75b6c95a9c7) service to localhost/127.0.0.1:45230 successfully registered with NN
2020-12-03 07:21:55,794 [BP-1100016829-172.17.0.10-1606980108214 heartbeating to localhost/127.0.0.1:45230] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:45230 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-12-03 07:21:55,792 [BP-1100016829-172.17.0.10-1606980108214 heartbeating to localhost/127.0.0.1:45230] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1100016829-172.17.0.10-1606980108214 (Datanode Uuid 0844a5a5-9438-4d1d-94ac-28a738487d03) service to localhost/127.0.0.1:45230 successfully registered with NN
2020-12-03 07:21:55,796 [BP-1100016829-172.17.0.10-1606980108214 heartbeating to localhost/127.0.0.1:45230] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:45230 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-12-03 07:21:55,792 [BP-1100016829-172.17.0.10-1606980108214 heartbeating to localhost/127.0.0.1:45230] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1100016829-172.17.0.10-1606980108214 (Datanode Uuid b66a2e06-3db7-4022-a57e-b577adcd540b) service to localhost/127.0.0.1:45230 successfully registered with NN
2020-12-03 07:21:55,792 [IPC Server handler 9 on default port 45230] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 9b8e6ff5-6652-42d9-b0e3-a3e292609b38 (127.0.0.1:32984).
2020-12-03 07:21:55,796 [BP-1100016829-172.17.0.10-1606980108214 heartbeating to localhost/127.0.0.1:45230] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:45230 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-12-03 07:21:55,799 [BP-1100016829-172.17.0.10-1606980108214 heartbeating to localhost/127.0.0.1:45230] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-1100016829-172.17.0.10-1606980108214 (Datanode Uuid 9b8e6ff5-6652-42d9-b0e3-a3e292609b38) service to localhost/127.0.0.1:45230 successfully registered with NN
2020-12-03 07:21:55,799 [BP-1100016829-172.17.0.10-1606980108214 heartbeating to localhost/127.0.0.1:45230] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:45230 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-12-03 07:21:55,826 [IPC Server handler 1 on default port 45230] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-f315ba39-e731-4476-b158-45472322d819 for DN 127.0.0.1:41579
2020-12-03 07:21:55,827 [IPC Server handler 1 on default port 45230] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-026e13dd-35d5-4adf-8b07-491909e719d2 for DN 127.0.0.1:41579
2020-12-03 07:21:55,828 [IPC Server handler 4 on default port 45230] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-72955610-3c7e-4c7c-951e-a6a14c5e58c7 for DN 127.0.0.1:37814
2020-12-03 07:21:55,832 [IPC Server handler 4 on default port 45230] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-3fc583cb-7f40-46a3-bfbe-cbc88b91b532 for DN 127.0.0.1:37814
2020-12-03 07:21:55,832 [IPC Server handler 7 on default port 45230] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-67b68069-6b27-4918-9b5e-0a7ff02f0fbb for DN 127.0.0.1:33473
2020-12-03 07:21:55,833 [IPC Server handler 7 on default port 45230] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-f4ef0132-50b8-4d37-ba1f-ef3ba0c4480e for DN 127.0.0.1:33473
2020-12-03 07:21:55,834 [IPC Server handler 0 on default port 45230] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-663ecb93-4311-4d45-8b9d-dda56e688031 for DN 127.0.0.1:32984
2020-12-03 07:21:55,834 [IPC Server handler 0 on default port 45230] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-b23c426a-754c-4393-8696-07f4de19fa1c for DN 127.0.0.1:32984
2020-12-03 07:21:55,835 [IPC Server handler 3 on default port 45230] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-1c271b4a-d89b-4e1c-a0ff-ab9324fd2701 for DN 127.0.0.1:38111
2020-12-03 07:21:55,835 [IPC Server handler 3 on default port 45230] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d8b288e5-db08-432f-b76c-3eca5f9e8bde for DN 127.0.0.1:38111
2020-12-03 07:21:55,837 [IPC Server handler 2 on default port 45230] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-4043d8ae-e217-4451-b41b-c6f4a1d90932 for DN 127.0.0.1:45300
2020-12-03 07:21:55,837 [IPC Server handler 2 on default port 45230] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-2737b381-4945-4d6f-abf9-74d86f4ee894 for DN 127.0.0.1:45300
2020-12-03 07:21:55,870 [IPC Server handler 7 on default port 45230] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:55,874 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x3bdddb81c8ddf6e4: Processing first storage report for DS-67b68069-6b27-4918-9b5e-0a7ff02f0fbb from datanode 0b683f72-a473-4822-835d-d3119cedc5f6
2020-12-03 07:21:55,876 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x3bdddb81c8ddf6e4: from storage DS-67b68069-6b27-4918-9b5e-0a7ff02f0fbb node DatanodeRegistration(127.0.0.1:33473, datanodeUuid=0b683f72-a473-4822-835d-d3119cedc5f6, infoPort=45306, infoSecurePort=0, ipcPort=46034, storageInfo=lv=-57;cid=testClusterID;nsid=842850756;c=1606980108214), blocks: 0, hasStaleStorage: true, processing time: 2 msecs, invalidatedBlocks: 0
2020-12-03 07:21:55,876 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xc9702f4333079479: Processing first storage report for DS-d8b288e5-db08-432f-b76c-3eca5f9e8bde from datanode b66a2e06-3db7-4022-a57e-b577adcd540b
2020-12-03 07:21:55,876 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xc9702f4333079479: from storage DS-d8b288e5-db08-432f-b76c-3eca5f9e8bde node DatanodeRegistration(127.0.0.1:38111, datanodeUuid=b66a2e06-3db7-4022-a57e-b577adcd540b, infoPort=38160, infoSecurePort=0, ipcPort=39899, storageInfo=lv=-57;cid=testClusterID;nsid=842850756;c=1606980108214), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:55,876 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xc03e1cae85d912a5: Processing first storage report for DS-72955610-3c7e-4c7c-951e-a6a14c5e58c7 from datanode 0c65a2b8-68d6-499f-9b6a-8441c2d9c440
2020-12-03 07:21:55,876 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xc03e1cae85d912a5: from storage DS-72955610-3c7e-4c7c-951e-a6a14c5e58c7 node DatanodeRegistration(127.0.0.1:37814, datanodeUuid=0c65a2b8-68d6-499f-9b6a-8441c2d9c440, infoPort=36606, infoSecurePort=0, ipcPort=45822, storageInfo=lv=-57;cid=testClusterID;nsid=842850756;c=1606980108214), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:55,876 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x5cde34b152c816e1: Processing first storage report for DS-4043d8ae-e217-4451-b41b-c6f4a1d90932 from datanode ab8189f6-cdba-42cf-9d11-d75b6c95a9c7
2020-12-03 07:21:55,876 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x5cde34b152c816e1: from storage DS-4043d8ae-e217-4451-b41b-c6f4a1d90932 node DatanodeRegistration(127.0.0.1:45300, datanodeUuid=ab8189f6-cdba-42cf-9d11-d75b6c95a9c7, infoPort=44463, infoSecurePort=0, ipcPort=42839, storageInfo=lv=-57;cid=testClusterID;nsid=842850756;c=1606980108214), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:55,876 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x7ad87b23562a7bbd: Processing first storage report for DS-b23c426a-754c-4393-8696-07f4de19fa1c from datanode 9b8e6ff5-6652-42d9-b0e3-a3e292609b38
2020-12-03 07:21:55,877 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x7ad87b23562a7bbd: from storage DS-b23c426a-754c-4393-8696-07f4de19fa1c node DatanodeRegistration(127.0.0.1:32984, datanodeUuid=9b8e6ff5-6652-42d9-b0e3-a3e292609b38, infoPort=36618, infoSecurePort=0, ipcPort=44632, storageInfo=lv=-57;cid=testClusterID;nsid=842850756;c=1606980108214), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:21:55,877 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xdfed9113848b5760: Processing first storage report for DS-026e13dd-35d5-4adf-8b07-491909e719d2 from datanode 0844a5a5-9438-4d1d-94ac-28a738487d03
2020-12-03 07:21:55,877 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xdfed9113848b5760: from storage DS-026e13dd-35d5-4adf-8b07-491909e719d2 node DatanodeRegistration(127.0.0.1:41579, datanodeUuid=0844a5a5-9438-4d1d-94ac-28a738487d03, infoPort=34104, infoSecurePort=0, ipcPort=35306, storageInfo=lv=-57;cid=testClusterID;nsid=842850756;c=1606980108214), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:55,877 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x3bdddb81c8ddf6e4: Processing first storage report for DS-f4ef0132-50b8-4d37-ba1f-ef3ba0c4480e from datanode 0b683f72-a473-4822-835d-d3119cedc5f6
2020-12-03 07:21:55,877 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x3bdddb81c8ddf6e4: from storage DS-f4ef0132-50b8-4d37-ba1f-ef3ba0c4480e node DatanodeRegistration(127.0.0.1:33473, datanodeUuid=0b683f72-a473-4822-835d-d3119cedc5f6, infoPort=45306, infoSecurePort=0, ipcPort=46034, storageInfo=lv=-57;cid=testClusterID;nsid=842850756;c=1606980108214), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:55,877 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xc9702f4333079479: Processing first storage report for DS-1c271b4a-d89b-4e1c-a0ff-ab9324fd2701 from datanode b66a2e06-3db7-4022-a57e-b577adcd540b
2020-12-03 07:21:55,877 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xc9702f4333079479: from storage DS-1c271b4a-d89b-4e1c-a0ff-ab9324fd2701 node DatanodeRegistration(127.0.0.1:38111, datanodeUuid=b66a2e06-3db7-4022-a57e-b577adcd540b, infoPort=38160, infoSecurePort=0, ipcPort=39899, storageInfo=lv=-57;cid=testClusterID;nsid=842850756;c=1606980108214), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:55,878 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xc03e1cae85d912a5: Processing first storage report for DS-3fc583cb-7f40-46a3-bfbe-cbc88b91b532 from datanode 0c65a2b8-68d6-499f-9b6a-8441c2d9c440
2020-12-03 07:21:55,878 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xc03e1cae85d912a5: from storage DS-3fc583cb-7f40-46a3-bfbe-cbc88b91b532 node DatanodeRegistration(127.0.0.1:37814, datanodeUuid=0c65a2b8-68d6-499f-9b6a-8441c2d9c440, infoPort=36606, infoSecurePort=0, ipcPort=45822, storageInfo=lv=-57;cid=testClusterID;nsid=842850756;c=1606980108214), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:21:55,878 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x5cde34b152c816e1: Processing first storage report for DS-2737b381-4945-4d6f-abf9-74d86f4ee894 from datanode ab8189f6-cdba-42cf-9d11-d75b6c95a9c7
2020-12-03 07:21:55,878 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x5cde34b152c816e1: from storage DS-2737b381-4945-4d6f-abf9-74d86f4ee894 node DatanodeRegistration(127.0.0.1:45300, datanodeUuid=ab8189f6-cdba-42cf-9d11-d75b6c95a9c7, infoPort=44463, infoSecurePort=0, ipcPort=42839, storageInfo=lv=-57;cid=testClusterID;nsid=842850756;c=1606980108214), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:55,878 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x7ad87b23562a7bbd: Processing first storage report for DS-663ecb93-4311-4d45-8b9d-dda56e688031 from datanode 9b8e6ff5-6652-42d9-b0e3-a3e292609b38
2020-12-03 07:21:55,879 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x7ad87b23562a7bbd: from storage DS-663ecb93-4311-4d45-8b9d-dda56e688031 node DatanodeRegistration(127.0.0.1:32984, datanodeUuid=9b8e6ff5-6652-42d9-b0e3-a3e292609b38, infoPort=36618, infoSecurePort=0, ipcPort=44632, storageInfo=lv=-57;cid=testClusterID;nsid=842850756;c=1606980108214), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:55,879 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xdfed9113848b5760: Processing first storage report for DS-f315ba39-e731-4476-b158-45472322d819 from datanode 0844a5a5-9438-4d1d-94ac-28a738487d03
2020-12-03 07:21:55,879 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xdfed9113848b5760: from storage DS-f315ba39-e731-4476-b158-45472322d819 node DatanodeRegistration(127.0.0.1:41579, datanodeUuid=0844a5a5-9438-4d1d-94ac-28a738487d03, infoPort=34104, infoSecurePort=0, ipcPort=35306, storageInfo=lv=-57;cid=testClusterID;nsid=842850756;c=1606980108214), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:21:55,881 [Listener at localhost/42839] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:21:55,890 [IPC Server handler 2 on default port 45230] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:55,891 [Listener at localhost/42839] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:21:55,899 [BP-1100016829-172.17.0.10-1606980108214 heartbeating to localhost/127.0.0.1:45230] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x3bdddb81c8ddf6e4,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 46 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:21:55,899 [BP-1100016829-172.17.0.10-1606980108214 heartbeating to localhost/127.0.0.1:45230] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xdfed9113848b5760,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 46 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:21:55,899 [BP-1100016829-172.17.0.10-1606980108214 heartbeating to localhost/127.0.0.1:45230] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x7ad87b23562a7bbd,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 46 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:21:55,899 [BP-1100016829-172.17.0.10-1606980108214 heartbeating to localhost/127.0.0.1:45230] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xc03e1cae85d912a5,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 46 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:21:55,900 [BP-1100016829-172.17.0.10-1606980108214 heartbeating to localhost/127.0.0.1:45230] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x5cde34b152c816e1,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 47 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:21:55,899 [BP-1100016829-172.17.0.10-1606980108214 heartbeating to localhost/127.0.0.1:45230] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1100016829-172.17.0.10-1606980108214
2020-12-03 07:21:55,899 [BP-1100016829-172.17.0.10-1606980108214 heartbeating to localhost/127.0.0.1:45230] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1100016829-172.17.0.10-1606980108214
2020-12-03 07:21:55,899 [BP-1100016829-172.17.0.10-1606980108214 heartbeating to localhost/127.0.0.1:45230] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1100016829-172.17.0.10-1606980108214
2020-12-03 07:21:55,901 [BP-1100016829-172.17.0.10-1606980108214 heartbeating to localhost/127.0.0.1:45230] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1100016829-172.17.0.10-1606980108214
2020-12-03 07:21:55,900 [BP-1100016829-172.17.0.10-1606980108214 heartbeating to localhost/127.0.0.1:45230] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1100016829-172.17.0.10-1606980108214
2020-12-03 07:21:55,901 [BP-1100016829-172.17.0.10-1606980108214 heartbeating to localhost/127.0.0.1:45230] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xc9702f4333079479,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 48 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:21:55,904 [BP-1100016829-172.17.0.10-1606980108214 heartbeating to localhost/127.0.0.1:45230] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1100016829-172.17.0.10-1606980108214
2020-12-03 07:21:55,913 [IPC Server handler 3 on default port 45230] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/foo	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:21:55,931 [IPC Server handler 4 on default port 45230] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/foo2	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:21:55,932 [IPC Server handler 7 on default port 45230] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/foo	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:21:55,972 [IPC Server handler 2 on default port 45230] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/foo/bar	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:21:56,010 [IPC Server handler 6 on default port 45230] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(427)) - storageTypes={DISK=3}
2020-12-03 07:21:56,011 [IPC Server handler 6 on default port 45230] DEBUG blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseRemoteRack(719)) - Failed to choose remote rack (location = ~/default-rack), fallback to local rack
org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy$NotEnoughReplicasException: 
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRandom(BlockPlacementPolicyDefault.java:852)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRemoteRack(BlockPlacementPolicyDefault.java:714)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTargetInOrder(BlockPlacementPolicyDefault.java:519)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:437)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:309)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:149)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:174)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2211)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2789)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:892)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:574)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
2020-12-03 07:21:56,014 [IPC Server handler 6 on default port 45230] DEBUG blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseRemoteRack(719)) - Failed to choose remote rack (location = ~/default-rack), fallback to local rack
org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy$NotEnoughReplicasException: 
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRandom(BlockPlacementPolicyDefault.java:852)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRemoteRack(BlockPlacementPolicyDefault.java:714)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTargetInOrder(BlockPlacementPolicyDefault.java:528)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:437)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:309)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:149)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:174)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2211)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2789)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:892)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:574)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
2020-12-03 07:21:56,018 [IPC Server handler 6 on default port 45230] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:38111, 127.0.0.1:33473, 127.0.0.1:32984 for /foo/bar
2020-12-03 07:21:56,035 [Thread-251] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:56,111 [Thread-251] TRACE datatransfer.DataTransferProtocol (Sender.java:send(79)) - Sending DataTransferOp OpWriteBlockProto: header {
  baseHeader {
    block {
      poolId: "BP-1100016829-172.17.0.10-1606980108214"
      blockId: 1073741825
      generationStamp: 1001
      numBytes: 1024
    }
    token {
      identifier: ""
      password: ""
      kind: ""
      service: ""
    }
  }
  clientName: "DFSClient_NONMAPREDUCE_-520700412_1"
}
targets {
  id {
    ipAddr: "127.0.0.1"
    hostName: "127.0.0.1"
    datanodeUuid: "0b683f72-a473-4822-835d-d3119cedc5f6"
    xferPort: 33473
    infoPort: 45306
    ipcPort: 46034
    infoSecurePort: 0
  }
  capacity: 1922244395008
  dfsUsed: 49152
  remaining: 1198444249088
  blockPoolUsed: 49152
  lastUpdate: 1606980115833
  xceiverCount: 1
  location: "/default-rack"
  nonDfsUsed: 626108391424
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 141104756
  lastBlockReportTime: 1606980115878
  lastBlockReportMonotonic: 141104801
  numBlocks: 0
}
targets {
  id {
    ipAddr: "127.0.0.1"
    hostName: "127.0.0.1"
    datanodeUuid: "9b8e6ff5-6652-42d9-b0e3-a3e292609b38"
    xferPort: 32984
    infoPort: 36618
    ipcPort: 44632
    infoSecurePort: 0
  }
  capacity: 1922244395008
  dfsUsed: 49152
  remaining: 1198444249088
  blockPoolUsed: 49152
  lastUpdate: 1606980115835
  xceiverCount: 1
  location: "/default-rack"
  nonDfsUsed: 626108387328
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 141104757
  lastBlockReportTime: 1606980115879
  lastBlockReportMonotonic: 141104802
  numBlocks: 0
}
stage: PIPELINE_SETUP_CREATE
pipelineSize: 3
minBytesRcvd: 0
maxBytesRcvd: 0
latestGenerationStamp: 0
requestedChecksum {
  type: CHECKSUM_CRC32C
  bytesPerChecksum: 512
}
cachingStrategy {
}
storageType: DISK
targetStorageTypes: DISK
targetStorageTypes: DISK
allowLazyPersist: false
pinning: false
targetPinnings: false
storageId: "DS-1c271b4a-d89b-4e1c-a0ff-ab9324fd2701"
targetStorageIds: "DS-67b68069-6b27-4918-9b5e-0a7ff02f0fbb"
targetStorageIds: "DS-663ecb93-4311-4d45-8b9d-dda56e688031"

2020-12-03 07:21:56,114 [DataXceiver for client DFSClient_NONMAPREDUCE_-520700412_1 at /127.0.0.1:50518 [Receiving block BP-1100016829-172.17.0.10-1606980108214:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1100016829-172.17.0.10-1606980108214:blk_1073741825_1001 src: /127.0.0.1:50518 dest: /127.0.0.1:38111
2020-12-03 07:21:56,143 [DataXceiver for client DFSClient_NONMAPREDUCE_-520700412_1 at /127.0.0.1:50518 [Receiving block BP-1100016829-172.17.0.10-1606980108214:blk_1073741825_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:56,146 [DataXceiver for client DFSClient_NONMAPREDUCE_-520700412_1 at /127.0.0.1:50518 [Receiving block BP-1100016829-172.17.0.10-1606980108214:blk_1073741825_1001]] TRACE datatransfer.DataTransferProtocol (Sender.java:send(79)) - Sending DataTransferOp OpWriteBlockProto: header {
  baseHeader {
    block {
      poolId: "BP-1100016829-172.17.0.10-1606980108214"
      blockId: 1073741825
      generationStamp: 1001
      numBytes: 1024
    }
    token {
      identifier: ""
      password: ""
      kind: ""
      service: ""
    }
  }
  clientName: "DFSClient_NONMAPREDUCE_-520700412_1"
}
targets {
  id {
    ipAddr: "127.0.0.1"
    hostName: "127.0.0.1"
    datanodeUuid: "9b8e6ff5-6652-42d9-b0e3-a3e292609b38"
    xferPort: 32984
    infoPort: 36618
    ipcPort: 44632
    infoSecurePort: 0
  }
  capacity: 1922244395008
  dfsUsed: 49152
  remaining: 1198444249088
  blockPoolUsed: 49152
  lastUpdate: 1606980115835
  xceiverCount: 1
  location: "/default-rack"
  nonDfsUsed: 626108387328
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 141104757
  lastBlockReportTime: 1606980115879
  lastBlockReportMonotonic: 141104802
  numBlocks: 0
}
source {
  id {
    ipAddr: ""
    hostName: ""
    datanodeUuid: ""
    xferPort: 0
    infoPort: 0
    ipcPort: 0
    infoSecurePort: 0
  }
  capacity: 0
  dfsUsed: 0
  remaining: 0
  blockPoolUsed: 0
  lastUpdate: 0
  xceiverCount: 0
  nonDfsUsed: 0
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 0
  lastBlockReportTime: 0
  lastBlockReportMonotonic: 0
  numBlocks: 0
}
stage: PIPELINE_SETUP_CREATE
pipelineSize: 3
minBytesRcvd: 0
maxBytesRcvd: 0
latestGenerationStamp: 0
requestedChecksum {
  type: CHECKSUM_CRC32C
  bytesPerChecksum: 512
}
cachingStrategy {
}
storageType: DISK
targetStorageTypes: DISK
allowLazyPersist: false
pinning: false
storageId: "DS-67b68069-6b27-4918-9b5e-0a7ff02f0fbb"
targetStorageIds: "DS-663ecb93-4311-4d45-8b9d-dda56e688031"

2020-12-03 07:21:56,147 [DataXceiver for client DFSClient_NONMAPREDUCE_-520700412_1 at /127.0.0.1:59046 [Receiving block BP-1100016829-172.17.0.10-1606980108214:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1100016829-172.17.0.10-1606980108214:blk_1073741825_1001 src: /127.0.0.1:59046 dest: /127.0.0.1:33473
2020-12-03 07:21:56,148 [DataXceiver for client DFSClient_NONMAPREDUCE_-520700412_1 at /127.0.0.1:59046 [Receiving block BP-1100016829-172.17.0.10-1606980108214:blk_1073741825_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:56,150 [DataXceiver for client DFSClient_NONMAPREDUCE_-520700412_1 at /127.0.0.1:59046 [Receiving block BP-1100016829-172.17.0.10-1606980108214:blk_1073741825_1001]] TRACE datatransfer.DataTransferProtocol (Sender.java:send(79)) - Sending DataTransferOp OpWriteBlockProto: header {
  baseHeader {
    block {
      poolId: "BP-1100016829-172.17.0.10-1606980108214"
      blockId: 1073741825
      generationStamp: 1001
      numBytes: 1024
    }
    token {
      identifier: ""
      password: ""
      kind: ""
      service: ""
    }
  }
  clientName: "DFSClient_NONMAPREDUCE_-520700412_1"
}
source {
  id {
    ipAddr: ""
    hostName: ""
    datanodeUuid: ""
    xferPort: 0
    infoPort: 0
    ipcPort: 0
    infoSecurePort: 0
  }
  capacity: 0
  dfsUsed: 0
  remaining: 0
  blockPoolUsed: 0
  lastUpdate: 0
  xceiverCount: 0
  nonDfsUsed: 0
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 0
  lastBlockReportTime: 0
  lastBlockReportMonotonic: 0
  numBlocks: 0
}
stage: PIPELINE_SETUP_CREATE
pipelineSize: 3
minBytesRcvd: 0
maxBytesRcvd: 0
latestGenerationStamp: 0
requestedChecksum {
  type: CHECKSUM_CRC32C
  bytesPerChecksum: 512
}
cachingStrategy {
}
storageType: DISK
allowLazyPersist: false
pinning: false
storageId: "DS-663ecb93-4311-4d45-8b9d-dda56e688031"

2020-12-03 07:21:56,150 [DataXceiver for client DFSClient_NONMAPREDUCE_-520700412_1 at /127.0.0.1:51610 [Receiving block BP-1100016829-172.17.0.10-1606980108214:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1100016829-172.17.0.10-1606980108214:blk_1073741825_1001 src: /127.0.0.1:51610 dest: /127.0.0.1:32984
2020-12-03 07:21:56,181 [PacketResponder: BP-1100016829-172.17.0.10-1606980108214:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:51610, dest: /127.0.0.1:32984, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-520700412_1, offset: 0, srvID: 9b8e6ff5-6652-42d9-b0e3-a3e292609b38, blockid: BP-1100016829-172.17.0.10-1606980108214:blk_1073741825_1001, duration(ns): 16254606
2020-12-03 07:21:56,182 [PacketResponder: BP-1100016829-172.17.0.10-1606980108214:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1100016829-172.17.0.10-1606980108214:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:21:56,185 [PacketResponder: BP-1100016829-172.17.0.10-1606980108214:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:32984]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59046, dest: /127.0.0.1:33473, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-520700412_1, offset: 0, srvID: 0b683f72-a473-4822-835d-d3119cedc5f6, blockid: BP-1100016829-172.17.0.10-1606980108214:blk_1073741825_1001, duration(ns): 21933854
2020-12-03 07:21:56,186 [PacketResponder: BP-1100016829-172.17.0.10-1606980108214:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:32984]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1100016829-172.17.0.10-1606980108214:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:32984] terminating
2020-12-03 07:21:56,190 [PacketResponder: BP-1100016829-172.17.0.10-1606980108214:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:33473, 127.0.0.1:32984]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:50518, dest: /127.0.0.1:38111, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-520700412_1, offset: 0, srvID: b66a2e06-3db7-4022-a57e-b577adcd540b, blockid: BP-1100016829-172.17.0.10-1606980108214:blk_1073741825_1001, duration(ns): 26878723
2020-12-03 07:21:56,190 [PacketResponder: BP-1100016829-172.17.0.10-1606980108214:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:33473, 127.0.0.1:32984]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1100016829-172.17.0.10-1606980108214:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:33473, 127.0.0.1:32984] terminating
2020-12-03 07:21:56,198 [IPC Server handler 0 on default port 45230] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2995)) - BLOCK* blk_1073741825_1001 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /foo/bar
2020-12-03 07:21:56,603 [IPC Server handler 3 on default port 45230] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /foo/bar is closed by DFSClient_NONMAPREDUCE_-520700412_1
2020-12-03 07:21:56,605 [IPC Server handler 4 on default port 45230] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/foo2	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:21:56,607 [IPC Server handler 7 on default port 45230] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/foo2/bar2	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:21:56,611 [IPC Server handler 2 on default port 45230] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(427)) - storageTypes={DISK=3}
2020-12-03 07:21:56,611 [IPC Server handler 2 on default port 45230] DEBUG blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseRemoteRack(719)) - Failed to choose remote rack (location = ~/default-rack), fallback to local rack
org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy$NotEnoughReplicasException: 
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRandom(BlockPlacementPolicyDefault.java:852)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRemoteRack(BlockPlacementPolicyDefault.java:714)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTargetInOrder(BlockPlacementPolicyDefault.java:519)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:437)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:309)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:149)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:174)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2211)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2789)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:892)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:574)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
2020-12-03 07:21:56,612 [IPC Server handler 2 on default port 45230] DEBUG blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseRemoteRack(719)) - Failed to choose remote rack (location = ~/default-rack), fallback to local rack
org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy$NotEnoughReplicasException: 
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRandom(BlockPlacementPolicyDefault.java:852)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRemoteRack(BlockPlacementPolicyDefault.java:714)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTargetInOrder(BlockPlacementPolicyDefault.java:528)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:437)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:309)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:149)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:174)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2211)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2789)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:892)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:574)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
2020-12-03 07:21:56,612 [IPC Server handler 2 on default port 45230] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741826_1002, replicas=127.0.0.1:38111, 127.0.0.1:37814, 127.0.0.1:41579 for /foo2/bar2
2020-12-03 07:21:56,614 [Thread-260] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:56,618 [Thread-260] TRACE datatransfer.DataTransferProtocol (Sender.java:send(79)) - Sending DataTransferOp OpWriteBlockProto: header {
  baseHeader {
    block {
      poolId: "BP-1100016829-172.17.0.10-1606980108214"
      blockId: 1073741826
      generationStamp: 1002
      numBytes: 1024
    }
    token {
      identifier: ""
      password: ""
      kind: ""
      service: ""
    }
  }
  clientName: "DFSClient_NONMAPREDUCE_-520700412_1"
}
targets {
  id {
    ipAddr: "127.0.0.1"
    hostName: "127.0.0.1"
    datanodeUuid: "0c65a2b8-68d6-499f-9b6a-8441c2d9c440"
    xferPort: 37814
    infoPort: 36606
    ipcPort: 45822
    infoSecurePort: 0
  }
  capacity: 1922244395008
  dfsUsed: 49152
  remaining: 1198444249088
  blockPoolUsed: 49152
  lastUpdate: 1606980115832
  xceiverCount: 1
  location: "/default-rack"
  nonDfsUsed: 626108391424
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 141104755
  lastBlockReportTime: 1606980115878
  lastBlockReportMonotonic: 141104801
  numBlocks: 0
}
targets {
  id {
    ipAddr: "127.0.0.1"
    hostName: "127.0.0.1"
    datanodeUuid: "0844a5a5-9438-4d1d-94ac-28a738487d03"
    xferPort: 41579
    infoPort: 34104
    ipcPort: 35306
    infoSecurePort: 0
  }
  capacity: 1922244395008
  dfsUsed: 49152
  remaining: 1198444249088
  blockPoolUsed: 49152
  lastUpdate: 1606980115828
  xceiverCount: 1
  location: "/default-rack"
  nonDfsUsed: 626108391424
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 141104750
  lastBlockReportTime: 1606980115879
  lastBlockReportMonotonic: 141104802
  numBlocks: 0
}
stage: PIPELINE_SETUP_CREATE
pipelineSize: 3
minBytesRcvd: 0
maxBytesRcvd: 0
latestGenerationStamp: 0
requestedChecksum {
  type: CHECKSUM_CRC32C
  bytesPerChecksum: 512
}
cachingStrategy {
}
storageType: DISK
targetStorageTypes: DISK
targetStorageTypes: DISK
allowLazyPersist: false
pinning: false
targetPinnings: false
storageId: "DS-1c271b4a-d89b-4e1c-a0ff-ab9324fd2701"
targetStorageIds: "DS-72955610-3c7e-4c7c-951e-a6a14c5e58c7"
targetStorageIds: "DS-f315ba39-e731-4476-b158-45472322d819"

2020-12-03 07:21:56,619 [DataXceiver for client DFSClient_NONMAPREDUCE_-520700412_1 at /127.0.0.1:50544 [Receiving block BP-1100016829-172.17.0.10-1606980108214:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1100016829-172.17.0.10-1606980108214:blk_1073741826_1002 src: /127.0.0.1:50544 dest: /127.0.0.1:38111
2020-12-03 07:21:56,620 [DataXceiver for client DFSClient_NONMAPREDUCE_-520700412_1 at /127.0.0.1:50544 [Receiving block BP-1100016829-172.17.0.10-1606980108214:blk_1073741826_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:56,622 [DataXceiver for client DFSClient_NONMAPREDUCE_-520700412_1 at /127.0.0.1:50544 [Receiving block BP-1100016829-172.17.0.10-1606980108214:blk_1073741826_1002]] TRACE datatransfer.DataTransferProtocol (Sender.java:send(79)) - Sending DataTransferOp OpWriteBlockProto: header {
  baseHeader {
    block {
      poolId: "BP-1100016829-172.17.0.10-1606980108214"
      blockId: 1073741826
      generationStamp: 1002
      numBytes: 1024
    }
    token {
      identifier: ""
      password: ""
      kind: ""
      service: ""
    }
  }
  clientName: "DFSClient_NONMAPREDUCE_-520700412_1"
}
targets {
  id {
    ipAddr: "127.0.0.1"
    hostName: "127.0.0.1"
    datanodeUuid: "0844a5a5-9438-4d1d-94ac-28a738487d03"
    xferPort: 41579
    infoPort: 34104
    ipcPort: 35306
    infoSecurePort: 0
  }
  capacity: 1922244395008
  dfsUsed: 49152
  remaining: 1198444249088
  blockPoolUsed: 49152
  lastUpdate: 1606980115828
  xceiverCount: 1
  location: "/default-rack"
  nonDfsUsed: 626108391424
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 141104750
  lastBlockReportTime: 1606980115879
  lastBlockReportMonotonic: 141104802
  numBlocks: 0
}
source {
  id {
    ipAddr: ""
    hostName: ""
    datanodeUuid: ""
    xferPort: 0
    infoPort: 0
    ipcPort: 0
    infoSecurePort: 0
  }
  capacity: 0
  dfsUsed: 0
  remaining: 0
  blockPoolUsed: 0
  lastUpdate: 0
  xceiverCount: 0
  nonDfsUsed: 0
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 0
  lastBlockReportTime: 0
  lastBlockReportMonotonic: 0
  numBlocks: 0
}
stage: PIPELINE_SETUP_CREATE
pipelineSize: 3
minBytesRcvd: 0
maxBytesRcvd: 0
latestGenerationStamp: 0
requestedChecksum {
  type: CHECKSUM_CRC32C
  bytesPerChecksum: 512
}
cachingStrategy {
}
storageType: DISK
targetStorageTypes: DISK
allowLazyPersist: false
pinning: false
storageId: "DS-72955610-3c7e-4c7c-951e-a6a14c5e58c7"
targetStorageIds: "DS-f315ba39-e731-4476-b158-45472322d819"

2020-12-03 07:21:56,625 [DataXceiver for client DFSClient_NONMAPREDUCE_-520700412_1 at /127.0.0.1:33054 [Receiving block BP-1100016829-172.17.0.10-1606980108214:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1100016829-172.17.0.10-1606980108214:blk_1073741826_1002 src: /127.0.0.1:33054 dest: /127.0.0.1:37814
2020-12-03 07:21:56,626 [DataXceiver for client DFSClient_NONMAPREDUCE_-520700412_1 at /127.0.0.1:33054 [Receiving block BP-1100016829-172.17.0.10-1606980108214:blk_1073741826_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:56,627 [DataXceiver for client DFSClient_NONMAPREDUCE_-520700412_1 at /127.0.0.1:33054 [Receiving block BP-1100016829-172.17.0.10-1606980108214:blk_1073741826_1002]] TRACE datatransfer.DataTransferProtocol (Sender.java:send(79)) - Sending DataTransferOp OpWriteBlockProto: header {
  baseHeader {
    block {
      poolId: "BP-1100016829-172.17.0.10-1606980108214"
      blockId: 1073741826
      generationStamp: 1002
      numBytes: 1024
    }
    token {
      identifier: ""
      password: ""
      kind: ""
      service: ""
    }
  }
  clientName: "DFSClient_NONMAPREDUCE_-520700412_1"
}
source {
  id {
    ipAddr: ""
    hostName: ""
    datanodeUuid: ""
    xferPort: 0
    infoPort: 0
    ipcPort: 0
    infoSecurePort: 0
  }
  capacity: 0
  dfsUsed: 0
  remaining: 0
  blockPoolUsed: 0
  lastUpdate: 0
  xceiverCount: 0
  nonDfsUsed: 0
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 0
  lastBlockReportTime: 0
  lastBlockReportMonotonic: 0
  numBlocks: 0
}
stage: PIPELINE_SETUP_CREATE
pipelineSize: 3
minBytesRcvd: 0
maxBytesRcvd: 0
latestGenerationStamp: 0
requestedChecksum {
  type: CHECKSUM_CRC32C
  bytesPerChecksum: 512
}
cachingStrategy {
}
storageType: DISK
allowLazyPersist: false
pinning: false
storageId: "DS-f315ba39-e731-4476-b158-45472322d819"

2020-12-03 07:21:56,628 [DataXceiver for client DFSClient_NONMAPREDUCE_-520700412_1 at /127.0.0.1:52748 [Receiving block BP-1100016829-172.17.0.10-1606980108214:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-1100016829-172.17.0.10-1606980108214:blk_1073741826_1002 src: /127.0.0.1:52748 dest: /127.0.0.1:41579
2020-12-03 07:21:56,639 [PacketResponder: BP-1100016829-172.17.0.10-1606980108214:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:52748, dest: /127.0.0.1:41579, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-520700412_1, offset: 0, srvID: 0844a5a5-9438-4d1d-94ac-28a738487d03, blockid: BP-1100016829-172.17.0.10-1606980108214:blk_1073741826_1002, duration(ns): 8687561
2020-12-03 07:21:56,640 [PacketResponder: BP-1100016829-172.17.0.10-1606980108214:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1100016829-172.17.0.10-1606980108214:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2020-12-03 07:21:56,643 [PacketResponder: BP-1100016829-172.17.0.10-1606980108214:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:41579]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:33054, dest: /127.0.0.1:37814, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-520700412_1, offset: 0, srvID: 0c65a2b8-68d6-499f-9b6a-8441c2d9c440, blockid: BP-1100016829-172.17.0.10-1606980108214:blk_1073741826_1002, duration(ns): 12529480
2020-12-03 07:21:56,644 [PacketResponder: BP-1100016829-172.17.0.10-1606980108214:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:41579]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1100016829-172.17.0.10-1606980108214:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:41579] terminating
2020-12-03 07:21:56,646 [PacketResponder: BP-1100016829-172.17.0.10-1606980108214:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37814, 127.0.0.1:41579]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:50544, dest: /127.0.0.1:38111, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-520700412_1, offset: 0, srvID: b66a2e06-3db7-4022-a57e-b577adcd540b, blockid: BP-1100016829-172.17.0.10-1606980108214:blk_1073741826_1002, duration(ns): 15072576
2020-12-03 07:21:56,647 [PacketResponder: BP-1100016829-172.17.0.10-1606980108214:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37814, 127.0.0.1:41579]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1100016829-172.17.0.10-1606980108214:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:37814, 127.0.0.1:41579] terminating
2020-12-03 07:21:56,649 [IPC Server handler 9 on default port 45230] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /foo2/bar2 is closed by DFSClient_NONMAPREDUCE_-520700412_1
2020-12-03 07:21:56,662 [IPC Server handler 5 on default port 45230] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setStoragePolicy	src=/foo	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:21:56,664 [IPC Server handler 1 on default port 45230] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setStoragePolicy	src=/foo2	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:21:56,672 [Listener at localhost/42839] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:56,672 [Listener at localhost/42839] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.redundancy.interval.seconds(2) assuming SECONDS
2020-12-03 07:21:56,673 [Listener at localhost/42839] INFO  mover.Mover (Mover.java:run(642)) - namenodes = {hdfs://localhost:45230=[/foo/bar, /foo2]}
2020-12-03 07:21:56,741 [IPC Server handler 7 on default port 45230] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/system/mover.id	dst=null	perm=null	proto=rpc
2020-12-03 07:21:56,746 [IPC Server handler 2 on default port 45230] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/system/mover.id	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:21:56,749 [IPC Server handler 6 on default port 45230] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/system/mover.id	dst=null	perm=null	proto=rpc
2020-12-03 07:21:56,752 [Listener at localhost/42839] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:56,752 [Listener at localhost/42839] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:21:56,767 [IPC Server handler 0 on default port 45230] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getDatanodeStorageReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:56,776 [Listener at localhost/42839] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:33473
2020-12-03 07:21:56,776 [Listener at localhost/42839] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38111
2020-12-03 07:21:56,776 [Listener at localhost/42839] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:45300
2020-12-03 07:21:56,777 [Listener at localhost/42839] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:32984
2020-12-03 07:21:56,777 [Listener at localhost/42839] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41579
2020-12-03 07:21:56,777 [Listener at localhost/42839] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:37814
2020-12-03 07:21:56,783 [IPC Server handler 9 on default port 45230] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listSnapshottableDirectory	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:21:56,788 [IPC Server handler 5 on default port 45230] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/foo/bar	dst=null	perm=null	proto=rpc
2020-12-03 07:21:56,811 [Listener at localhost/42839] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741825_1001 with size=1024 from 127.0.0.1:38111:DISK to 127.0.0.1:38111:ARCHIVE through 127.0.0.1:38111
2020-12-03 07:21:56,812 [pool-83-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741825_1001 with size=1024 from 127.0.0.1:38111:DISK to 127.0.0.1:38111:ARCHIVE through 127.0.0.1:38111
2020-12-03 07:21:56,814 [IPC Server handler 8 on default port 45230] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/foo2	dst=null	perm=null	proto=rpc
2020-12-03 07:21:56,816 [Listener at localhost/42839] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741826_1002 with size=1024 from 127.0.0.1:37814:DISK to 127.0.0.1:37814:ARCHIVE through 127.0.0.1:37814
2020-12-03 07:21:56,817 [pool-84-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741826_1002 with size=1024 from 127.0.0.1:37814:DISK to 127.0.0.1:37814:ARCHIVE through 127.0.0.1:37814
2020-12-03 07:21:56,821 [pool-83-thread-1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:56,821 [pool-84-thread-1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:21:56,827 [pool-83-thread-1] TRACE datatransfer.DataTransferProtocol (Sender.java:send(79)) - Sending DataTransferOp OpReplaceBlockProto: header {
  block {
    poolId: "BP-1100016829-172.17.0.10-1606980108214"
    blockId: 1073741825
    generationStamp: 1001
    numBytes: 1024
  }
  token {
    identifier: ""
    password: ""
    kind: ""
    service: ""
  }
}
delHint: "b66a2e06-3db7-4022-a57e-b577adcd540b"
source {
  id {
    ipAddr: "127.0.0.1"
    hostName: "127.0.0.1"
    datanodeUuid: "b66a2e06-3db7-4022-a57e-b577adcd540b"
    xferPort: 38111
    infoPort: 38160
    ipcPort: 39899
    infoSecurePort: 0
  }
  capacity: 1922244395008
  dfsUsed: 49152
  remaining: 1198444249088
  blockPoolUsed: 49152
  lastUpdate: 1606980115836
  xceiverCount: 1
  location: "/default-rack"
  nonDfsUsed: 626108391424
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 141104759
  lastBlockReportTime: 1606980115878
  lastBlockReportMonotonic: 141104801
  numBlocks: 0
}
storageType: ARCHIVE

2020-12-03 07:21:56,827 [pool-84-thread-1] TRACE datatransfer.DataTransferProtocol (Sender.java:send(79)) - Sending DataTransferOp OpReplaceBlockProto: header {
  block {
    poolId: "BP-1100016829-172.17.0.10-1606980108214"
    blockId: 1073741826
    generationStamp: 1002
    numBytes: 1024
  }
  token {
    identifier: ""
    password: ""
    kind: ""
    service: ""
  }
}
delHint: "0c65a2b8-68d6-499f-9b6a-8441c2d9c440"
source {
  id {
    ipAddr: "127.0.0.1"
    hostName: "127.0.0.1"
    datanodeUuid: "0c65a2b8-68d6-499f-9b6a-8441c2d9c440"
    xferPort: 37814
    infoPort: 36606
    ipcPort: 45822
    infoSecurePort: 0
  }
  capacity: 1922244395008
  dfsUsed: 49152
  remaining: 1198444249088
  blockPoolUsed: 49152
  lastUpdate: 1606980115832
  xceiverCount: 1
  location: "/default-rack"
  nonDfsUsed: 626108391424
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 141104755
  lastBlockReportTime: 1606980115878
  lastBlockReportMonotonic: 141104801
  numBlocks: 0
}
storageType: ARCHIVE

2020-12-03 07:21:56,833 [DataXceiver for client /127.0.0.1:33076 [Replacing block BP-1100016829-172.17.0.10-1606980108214:blk_1073741826_1002 from 0c65a2b8-68d6-499f-9b6a-8441c2d9c440]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1186)) - Moved BP-1100016829-172.17.0.10-1606980108214:blk_1073741826_1002 from StorageType DISK to ARCHIVE
2020-12-03 07:21:56,834 [Block report processor] WARN  BlockStateChange (BlockManager.java:addStoredBlock(3356)) - BLOCK* addStoredBlock: block blk_1073741826_1002 moved to storageType ARCHIVE on node 127.0.0.1:37814
2020-12-03 07:21:56,833 [DataXceiver for client /127.0.0.1:50566 [Replacing block BP-1100016829-172.17.0.10-1606980108214:blk_1073741825_1001 from b66a2e06-3db7-4022-a57e-b577adcd540b]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1186)) - Moved BP-1100016829-172.17.0.10-1606980108214:blk_1073741825_1001 from StorageType DISK to ARCHIVE
2020-12-03 07:21:56,843 [Block report processor] WARN  BlockStateChange (BlockManager.java:addStoredBlock(3356)) - BLOCK* addStoredBlock: block blk_1073741825_1001 moved to storageType ARCHIVE on node 127.0.0.1:38111
2020-12-03 07:21:56,843 [pool-83-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741825_1001 with size=1024 from 127.0.0.1:38111:DISK to 127.0.0.1:38111:ARCHIVE through 127.0.0.1:38111
2020-12-03 07:21:56,844 [pool-84-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741826_1002 with size=1024 from 127.0.0.1:37814:DISK to 127.0.0.1:37814:ARCHIVE through 127.0.0.1:37814
2020-12-03 07:22:01,818 [Listener at localhost/42839] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:01,818 [Listener at localhost/42839] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:01,821 [IPC Server handler 9 on default port 45230] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getDatanodeStorageReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:01,823 [Listener at localhost/42839] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38111
2020-12-03 07:22:01,823 [Listener at localhost/42839] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41579
2020-12-03 07:22:01,824 [Listener at localhost/42839] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:33473
2020-12-03 07:22:01,824 [Listener at localhost/42839] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:32984
2020-12-03 07:22:01,824 [Listener at localhost/42839] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:45300
2020-12-03 07:22:01,824 [Listener at localhost/42839] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:37814
2020-12-03 07:22:01,825 [IPC Server handler 5 on default port 45230] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listSnapshottableDirectory	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:01,827 [IPC Server handler 1 on default port 45230] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/foo/bar	dst=null	perm=null	proto=rpc
2020-12-03 07:22:01,828 [Listener at localhost/42839] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741825_1001 with size=1024 from 127.0.0.1:32984:DISK to 127.0.0.1:32984:ARCHIVE through 127.0.0.1:32984
2020-12-03 07:22:01,829 [pool-85-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741825_1001 with size=1024 from 127.0.0.1:32984:DISK to 127.0.0.1:32984:ARCHIVE through 127.0.0.1:32984
2020-12-03 07:22:01,830 [pool-85-thread-1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:01,830 [IPC Server handler 3 on default port 45230] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/foo2	dst=null	perm=null	proto=rpc
2020-12-03 07:22:01,831 [pool-85-thread-1] TRACE datatransfer.DataTransferProtocol (Sender.java:send(79)) - Sending DataTransferOp OpReplaceBlockProto: header {
  block {
    poolId: "BP-1100016829-172.17.0.10-1606980108214"
    blockId: 1073741825
    generationStamp: 1001
    numBytes: 1024
  }
  token {
    identifier: ""
    password: ""
    kind: ""
    service: ""
  }
}
delHint: "9b8e6ff5-6652-42d9-b0e3-a3e292609b38"
source {
  id {
    ipAddr: "127.0.0.1"
    hostName: "127.0.0.1"
    datanodeUuid: "9b8e6ff5-6652-42d9-b0e3-a3e292609b38"
    xferPort: 32984
    infoPort: 36618
    ipcPort: 44632
    infoSecurePort: 0
  }
  capacity: 1922244395008
  dfsUsed: 50191
  remaining: 1198447902720
  blockPoolUsed: 50191
  lastUpdate: 1606980121802
  xceiverCount: 1
  location: "/default-rack"
  nonDfsUsed: 626104736753
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 141110725
  lastBlockReportTime: 1606980115879
  lastBlockReportMonotonic: 141104802
  numBlocks: 0
}
storageType: ARCHIVE

2020-12-03 07:22:01,832 [Listener at localhost/42839] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741826_1002 with size=1024 from 127.0.0.1:41579:DISK to 127.0.0.1:41579:ARCHIVE through 127.0.0.1:41579
2020-12-03 07:22:01,833 [pool-86-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741826_1002 with size=1024 from 127.0.0.1:41579:DISK to 127.0.0.1:41579:ARCHIVE through 127.0.0.1:41579
2020-12-03 07:22:01,834 [pool-86-thread-1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:01,835 [DataXceiver for client /127.0.0.1:51842 [Replacing block BP-1100016829-172.17.0.10-1606980108214:blk_1073741825_1001 from 9b8e6ff5-6652-42d9-b0e3-a3e292609b38]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1186)) - Moved BP-1100016829-172.17.0.10-1606980108214:blk_1073741825_1001 from StorageType DISK to ARCHIVE
2020-12-03 07:22:01,835 [pool-85-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741825_1001 with size=1024 from 127.0.0.1:32984:DISK to 127.0.0.1:32984:ARCHIVE through 127.0.0.1:32984
2020-12-03 07:22:01,836 [pool-86-thread-1] TRACE datatransfer.DataTransferProtocol (Sender.java:send(79)) - Sending DataTransferOp OpReplaceBlockProto: header {
  block {
    poolId: "BP-1100016829-172.17.0.10-1606980108214"
    blockId: 1073741826
    generationStamp: 1002
    numBytes: 1024
  }
  token {
    identifier: ""
    password: ""
    kind: ""
    service: ""
  }
}
delHint: "0844a5a5-9438-4d1d-94ac-28a738487d03"
source {
  id {
    ipAddr: "127.0.0.1"
    hostName: "127.0.0.1"
    datanodeUuid: "0844a5a5-9438-4d1d-94ac-28a738487d03"
    xferPort: 41579
    infoPort: 34104
    ipcPort: 35306
    infoSecurePort: 0
  }
  capacity: 1922244395008
  dfsUsed: 50191
  remaining: 1198447902720
  blockPoolUsed: 50191
  lastUpdate: 1606980121798
  xceiverCount: 1
  location: "/default-rack"
  nonDfsUsed: 626104736753
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 141110721
  lastBlockReportTime: 1606980115879
  lastBlockReportMonotonic: 141104802
  numBlocks: 0
}
storageType: ARCHIVE

2020-12-03 07:22:01,837 [Block report processor] WARN  BlockStateChange (BlockManager.java:addStoredBlock(3356)) - BLOCK* addStoredBlock: block blk_1073741825_1001 moved to storageType ARCHIVE on node 127.0.0.1:32984
2020-12-03 07:22:01,839 [DataXceiver for client /127.0.0.1:52962 [Replacing block BP-1100016829-172.17.0.10-1606980108214:blk_1073741826_1002 from 0844a5a5-9438-4d1d-94ac-28a738487d03]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1186)) - Moved BP-1100016829-172.17.0.10-1606980108214:blk_1073741826_1002 from StorageType DISK to ARCHIVE
2020-12-03 07:22:01,840 [pool-86-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741826_1002 with size=1024 from 127.0.0.1:41579:DISK to 127.0.0.1:41579:ARCHIVE through 127.0.0.1:41579
2020-12-03 07:22:01,841 [Block report processor] WARN  BlockStateChange (BlockManager.java:addStoredBlock(3356)) - BLOCK* addStoredBlock: block blk_1073741826_1002 moved to storageType ARCHIVE on node 127.0.0.1:41579
2020-12-03 07:22:06,834 [Listener at localhost/42839] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:06,834 [Listener at localhost/42839] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-12-03 07:22:06,838 [IPC Server handler 2 on default port 45230] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getDatanodeStorageReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:06,840 [Listener at localhost/42839] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41579
2020-12-03 07:22:06,841 [Listener at localhost/42839] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:37814
2020-12-03 07:22:06,841 [Listener at localhost/42839] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38111
2020-12-03 07:22:06,841 [Listener at localhost/42839] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:33473
2020-12-03 07:22:06,841 [Listener at localhost/42839] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:32984
2020-12-03 07:22:06,842 [Listener at localhost/42839] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:45300
2020-12-03 07:22:06,843 [IPC Server handler 6 on default port 45230] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listSnapshottableDirectory	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:22:06,845 [IPC Server handler 8 on default port 45230] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/foo/bar	dst=null	perm=null	proto=rpc
2020-12-03 07:22:06,847 [Listener at localhost/42839] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741825_1001 with size=1024 from 127.0.0.1:33473:DISK to 127.0.0.1:33473:ARCHIVE through 127.0.0.1:33473
2020-12-03 07:22:06,848 [pool-87-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741825_1001 with size=1024 from 127.0.0.1:33473:DISK to 127.0.0.1:33473:ARCHIVE through 127.0.0.1:33473
2020-12-03 07:22:06,849 [pool-87-thread-1] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:22:06,851 [IPC Server handler 9 on default port 45230] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/foo2	dst=null	perm=null	proto=rpc
2020-12-03 07:22:06,852 [pool-87-thread-1] TRACE datatransfer.DataTransferProtocol (Sender.java:send(79)) - Sending DataTransferOp OpReplaceBlockProto: header {
  block {
    poolId: "BP-1100016829-172.17.0.10-1606980108214"
    blockId: 1073741825
    generationStamp: 1001
    numBytes: 1024
  }
  token {
    identifier: ""
    password: ""
    kind: ""
    service: ""
  }
}
delHint: "0b683f72-a473-4822-835d-d3119cedc5f6"
source {
  id {
    ipAddr: "127.0.0.1"
    hostName: "127.0.0.1"
    datanodeUuid: "0b683f72-a473-4822-835d-d3119cedc5f6"
    xferPort: 33473
    infoPort: 45306
    ipcPort: 46034
    infoSecurePort: 0
  }
  capacity: 1922244395008
  dfsUsed: 50191
  remaining: 1198451646464
  blockPoolUsed: 50191
  lastUpdate: 1606980126795
  xceiverCount: 1
  location: "/default-rack"
  nonDfsUsed: 626100993009
  adminState: NORMAL
  cacheCapacity: 0
  cacheUsed: 0
  lastUpdateMonotonic: 141115718
  lastBlockReportTime: 1606980115878
  lastBlockReportMonotonic: 141104801
  numBlocks: 0
}
storageType: ARCHIVE

2020-12-03 07:22:06,856 [DataXceiver for client /127.0.0.1:59320 [Replacing block BP-1100016829-172.17.0.10-1606980108214:blk_1073741825_1001 from 0b683f72-a473-4822-835d-d3119cedc5f6]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1186)) - Moved BP-1100016829-172.17.0.10-1606980108214:blk_1073741825_1001 from StorageType DISK to ARCHIVE
2020-12-03 07:22:06,856 [pool-87-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741825_1001 with size=1024 from 127.0.0.1:33473:DISK to 127.0.0.1:33473:ARCHIVE through 127.0.0.1:33473
2020-12-03 07:22:06,864 [Block report processor] WARN  BlockStateChange (BlockManager.java:addStoredBlock(3356)) - BLOCK* addStoredBlock: block blk_1073741825_1001 moved to storageType ARCHIVE on node 127.0.0.1:33473
2020-12-03 07:22:07,856 [IPC Server handler 0 on default port 45230] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /system/mover.id is closed by DFSClient_NONMAPREDUCE_-520700412_1
2020-12-03 07:22:07,866 [IPC Server handler 5 on default port 45230] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/system/mover.id	dst=null	perm=null	proto=rpc
Mover Successful: all blocks satisfy the specified storage policy. Exiting...
2020-12-03 07:22:16,872 [BP-1100016829-172.17.0.10-1606980108214 heartbeating to localhost/127.0.0.1:45230] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:45230
2020-12-03 07:22:16,875 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xc9702f433307947a: from storage DS-d8b288e5-db08-432f-b76c-3eca5f9e8bde node DatanodeRegistration(127.0.0.1:38111, datanodeUuid=b66a2e06-3db7-4022-a57e-b577adcd540b, infoPort=38160, infoSecurePort=0, ipcPort=39899, storageInfo=lv=-57;cid=testClusterID;nsid=842850756;c=1606980108214), blocks: 1, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:22:16,875 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xc9702f433307947a: from storage DS-1c271b4a-d89b-4e1c-a0ff-ab9324fd2701 node DatanodeRegistration(127.0.0.1:38111, datanodeUuid=b66a2e06-3db7-4022-a57e-b577adcd540b, infoPort=38160, infoSecurePort=0, ipcPort=39899, storageInfo=lv=-57;cid=testClusterID;nsid=842850756;c=1606980108214), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:16,876 [BP-1100016829-172.17.0.10-1606980108214 heartbeating to localhost/127.0.0.1:45230] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xc9702f433307947a,  containing 2 storage report(s), of which we sent 2. The reports had 2 total blocks and used 1 RPC(s). This took 1 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:16,876 [BP-1100016829-172.17.0.10-1606980108214 heartbeating to localhost/127.0.0.1:45230] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1100016829-172.17.0.10-1606980108214
2020-12-03 07:22:16,973 [BP-1100016829-172.17.0.10-1606980108214 heartbeating to localhost/127.0.0.1:45230] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:45230
2020-12-03 07:22:16,974 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x3bdddb81c8ddf6e5: from storage DS-67b68069-6b27-4918-9b5e-0a7ff02f0fbb node DatanodeRegistration(127.0.0.1:33473, datanodeUuid=0b683f72-a473-4822-835d-d3119cedc5f6, infoPort=45306, infoSecurePort=0, ipcPort=46034, storageInfo=lv=-57;cid=testClusterID;nsid=842850756;c=1606980108214), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:16,974 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x3bdddb81c8ddf6e5: from storage DS-f4ef0132-50b8-4d37-ba1f-ef3ba0c4480e node DatanodeRegistration(127.0.0.1:33473, datanodeUuid=0b683f72-a473-4822-835d-d3119cedc5f6, infoPort=45306, infoSecurePort=0, ipcPort=46034, storageInfo=lv=-57;cid=testClusterID;nsid=842850756;c=1606980108214), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:16,975 [BP-1100016829-172.17.0.10-1606980108214 heartbeating to localhost/127.0.0.1:45230] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x3bdddb81c8ddf6e5,  containing 2 storage report(s), of which we sent 2. The reports had 1 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:16,975 [BP-1100016829-172.17.0.10-1606980108214 heartbeating to localhost/127.0.0.1:45230] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1100016829-172.17.0.10-1606980108214
2020-12-03 07:22:17,073 [BP-1100016829-172.17.0.10-1606980108214 heartbeating to localhost/127.0.0.1:45230] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:45230
2020-12-03 07:22:17,074 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xc03e1cae85d912a6: from storage DS-72955610-3c7e-4c7c-951e-a6a14c5e58c7 node DatanodeRegistration(127.0.0.1:37814, datanodeUuid=0c65a2b8-68d6-499f-9b6a-8441c2d9c440, infoPort=36606, infoSecurePort=0, ipcPort=45822, storageInfo=lv=-57;cid=testClusterID;nsid=842850756;c=1606980108214), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:17,074 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xc03e1cae85d912a6: from storage DS-3fc583cb-7f40-46a3-bfbe-cbc88b91b532 node DatanodeRegistration(127.0.0.1:37814, datanodeUuid=0c65a2b8-68d6-499f-9b6a-8441c2d9c440, infoPort=36606, infoSecurePort=0, ipcPort=45822, storageInfo=lv=-57;cid=testClusterID;nsid=842850756;c=1606980108214), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:17,075 [BP-1100016829-172.17.0.10-1606980108214 heartbeating to localhost/127.0.0.1:45230] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xc03e1cae85d912a6,  containing 2 storage report(s), of which we sent 2. The reports had 1 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:17,075 [BP-1100016829-172.17.0.10-1606980108214 heartbeating to localhost/127.0.0.1:45230] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1100016829-172.17.0.10-1606980108214
2020-12-03 07:22:17,174 [BP-1100016829-172.17.0.10-1606980108214 heartbeating to localhost/127.0.0.1:45230] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:45230
2020-12-03 07:22:17,177 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x7ad87b23562a7bbe: from storage DS-b23c426a-754c-4393-8696-07f4de19fa1c node DatanodeRegistration(127.0.0.1:32984, datanodeUuid=9b8e6ff5-6652-42d9-b0e3-a3e292609b38, infoPort=36618, infoSecurePort=0, ipcPort=44632, storageInfo=lv=-57;cid=testClusterID;nsid=842850756;c=1606980108214), blocks: 1, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:22:17,177 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x7ad87b23562a7bbe: from storage DS-663ecb93-4311-4d45-8b9d-dda56e688031 node DatanodeRegistration(127.0.0.1:32984, datanodeUuid=9b8e6ff5-6652-42d9-b0e3-a3e292609b38, infoPort=36618, infoSecurePort=0, ipcPort=44632, storageInfo=lv=-57;cid=testClusterID;nsid=842850756;c=1606980108214), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:17,178 [BP-1100016829-172.17.0.10-1606980108214 heartbeating to localhost/127.0.0.1:45230] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x7ad87b23562a7bbe,  containing 2 storage report(s), of which we sent 2. The reports had 1 total blocks and used 1 RPC(s). This took 0 msec to generate and 4 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:17,178 [BP-1100016829-172.17.0.10-1606980108214 heartbeating to localhost/127.0.0.1:45230] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1100016829-172.17.0.10-1606980108214
2020-12-03 07:22:17,273 [BP-1100016829-172.17.0.10-1606980108214 heartbeating to localhost/127.0.0.1:45230] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:45230
2020-12-03 07:22:17,275 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xdfed9113848b5761: from storage DS-026e13dd-35d5-4adf-8b07-491909e719d2 node DatanodeRegistration(127.0.0.1:41579, datanodeUuid=0844a5a5-9438-4d1d-94ac-28a738487d03, infoPort=34104, infoSecurePort=0, ipcPort=35306, storageInfo=lv=-57;cid=testClusterID;nsid=842850756;c=1606980108214), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:17,275 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xdfed9113848b5761: from storage DS-f315ba39-e731-4476-b158-45472322d819 node DatanodeRegistration(127.0.0.1:41579, datanodeUuid=0844a5a5-9438-4d1d-94ac-28a738487d03, infoPort=34104, infoSecurePort=0, ipcPort=35306, storageInfo=lv=-57;cid=testClusterID;nsid=842850756;c=1606980108214), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:17,276 [BP-1100016829-172.17.0.10-1606980108214 heartbeating to localhost/127.0.0.1:45230] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xdfed9113848b5761,  containing 2 storage report(s), of which we sent 2. The reports had 1 total blocks and used 1 RPC(s). This took 1 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:17,277 [BP-1100016829-172.17.0.10-1606980108214 heartbeating to localhost/127.0.0.1:45230] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1100016829-172.17.0.10-1606980108214
2020-12-03 07:22:17,376 [BP-1100016829-172.17.0.10-1606980108214 heartbeating to localhost/127.0.0.1:45230] INFO  datanode.DataNode (BPServiceActor.java:offerService(698)) - Forcing a full block report to localhost/127.0.0.1:45230
2020-12-03 07:22:17,378 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x5cde34b152c816e2: from storage DS-4043d8ae-e217-4451-b41b-c6f4a1d90932 node DatanodeRegistration(127.0.0.1:45300, datanodeUuid=ab8189f6-cdba-42cf-9d11-d75b6c95a9c7, infoPort=44463, infoSecurePort=0, ipcPort=42839, storageInfo=lv=-57;cid=testClusterID;nsid=842850756;c=1606980108214), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:17,378 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x5cde34b152c816e2: from storage DS-2737b381-4945-4d6f-abf9-74d86f4ee894 node DatanodeRegistration(127.0.0.1:45300, datanodeUuid=ab8189f6-cdba-42cf-9d11-d75b6c95a9c7, infoPort=44463, infoSecurePort=0, ipcPort=42839, storageInfo=lv=-57;cid=testClusterID;nsid=842850756;c=1606980108214), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:22:17,379 [BP-1100016829-172.17.0.10-1606980108214 heartbeating to localhost/127.0.0.1:45230] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x5cde34b152c816e2,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-12-03 07:22:17,379 [BP-1100016829-172.17.0.10-1606980108214 heartbeating to localhost/127.0.0.1:45230] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1100016829-172.17.0.10-1606980108214
2020-12-03 07:22:17,473 [IPC Server handler 2 on default port 45230] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/	dst=null	perm=null	proto=rpc
2020-12-03 07:22:17,475 [IPC Server handler 4 on default port 45230] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/	dst=null	perm=null	proto=rpc
2020-12-03 07:22:17,477 [IPC Server handler 1 on default port 45230] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/foo	dst=null	perm=null	proto=rpc
2020-12-03 07:22:17,482 [IPC Server handler 6 on default port 45230] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/foo2	dst=null	perm=null	proto=rpc
2020-12-03 07:22:17,485 [IPC Server handler 8 on default port 45230] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/system	dst=null	perm=null	proto=rpc
2020-12-03 07:22:17,488 [IPC Server handler 9 on default port 45230] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/system/mover.id	dst=null	perm=null	proto=rpc
2020-12-03 07:22:17,493 [Listener at localhost/42839] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:22:17,494 [Listener at localhost/42839] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 5
2020-12-03 07:22:17,495 [Listener at localhost/42839] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:22:17,495 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@12f3afb5] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:22:17,496 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-2737b381-4945-4d6f-abf9-74d86f4ee894) exiting.
2020-12-03 07:22:17,496 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-4043d8ae-e217-4451-b41b-c6f4a1d90932) exiting.
2020-12-03 07:22:17,694 [Listener at localhost/42839] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@a23a01d{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:22:17,732 [Listener at localhost/42839] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4acf72b6{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:17,733 [Listener at localhost/42839] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3aaf4f07{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:17,735 [Listener at localhost/42839] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@27dc79f7{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:17,748 [Listener at localhost/42839] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 42839
2020-12-03 07:22:17,765 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:17,765 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:17,767 [BP-1100016829-172.17.0.10-1606980108214 heartbeating to localhost/127.0.0.1:45230] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:17,767 [BP-1100016829-172.17.0.10-1606980108214 heartbeating to localhost/127.0.0.1:45230] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1100016829-172.17.0.10-1606980108214 (Datanode Uuid ab8189f6-cdba-42cf-9d11-d75b6c95a9c7) service to localhost/127.0.0.1:45230
2020-12-03 07:22:17,767 [BP-1100016829-172.17.0.10-1606980108214 heartbeating to localhost/127.0.0.1:45230] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1100016829-172.17.0.10-1606980108214 (Datanode Uuid ab8189f6-cdba-42cf-9d11-d75b6c95a9c7)
2020-12-03 07:22:17,768 [BP-1100016829-172.17.0.10-1606980108214 heartbeating to localhost/127.0.0.1:45230] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1100016829-172.17.0.10-1606980108214
2020-12-03 07:22:17,769 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1100016829-172.17.0.10-1606980108214] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:17,769 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1100016829-172.17.0.10-1606980108214] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:17,777 [Listener at localhost/42839] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:22:17,777 [Listener at localhost/42839] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:22:17,778 [Listener at localhost/42839] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:22:17,778 [Listener at localhost/42839] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:22:17,787 [Listener at localhost/42839] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:22:17,787 [Listener at localhost/42839] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 4
2020-12-03 07:22:17,793 [Listener at localhost/42839] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:22:17,793 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@5949eba8] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:22:17,795 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-f315ba39-e731-4476-b158-45472322d819) exiting.
2020-12-03 07:22:17,795 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-026e13dd-35d5-4adf-8b07-491909e719d2) exiting.
2020-12-03 07:22:17,861 [Listener at localhost/42839] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1bc53649{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:22:17,862 [Listener at localhost/42839] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@88d6f9b{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:17,863 [Listener at localhost/42839] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5167268{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:17,864 [Listener at localhost/42839] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7728643a{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:17,865 [Listener at localhost/42839] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 35306
2020-12-03 07:22:17,894 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:17,895 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:17,895 [BP-1100016829-172.17.0.10-1606980108214 heartbeating to localhost/127.0.0.1:45230] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:17,898 [BP-1100016829-172.17.0.10-1606980108214 heartbeating to localhost/127.0.0.1:45230] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1100016829-172.17.0.10-1606980108214 (Datanode Uuid 0844a5a5-9438-4d1d-94ac-28a738487d03) service to localhost/127.0.0.1:45230
2020-12-03 07:22:17,898 [BP-1100016829-172.17.0.10-1606980108214 heartbeating to localhost/127.0.0.1:45230] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1100016829-172.17.0.10-1606980108214 (Datanode Uuid 0844a5a5-9438-4d1d-94ac-28a738487d03)
2020-12-03 07:22:17,898 [BP-1100016829-172.17.0.10-1606980108214 heartbeating to localhost/127.0.0.1:45230] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1100016829-172.17.0.10-1606980108214
2020-12-03 07:22:17,898 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1100016829-172.17.0.10-1606980108214] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:17,899 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1100016829-172.17.0.10-1606980108214] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:17,903 [Listener at localhost/42839] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:22:17,903 [Listener at localhost/42839] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:22:17,904 [Listener at localhost/42839] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:22:17,905 [Listener at localhost/42839] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:22:17,909 [Listener at localhost/42839] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:22:17,910 [Listener at localhost/42839] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 3
2020-12-03 07:22:17,910 [Listener at localhost/42839] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:22:17,910 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@29539e36] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:22:17,912 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-663ecb93-4311-4d45-8b9d-dda56e688031) exiting.
2020-12-03 07:22:17,912 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-b23c426a-754c-4393-8696-07f4de19fa1c) exiting.
2020-12-03 07:22:17,971 [Listener at localhost/42839] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@37d3d232{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:22:17,974 [Listener at localhost/42839] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@30c0ccff{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:17,977 [Listener at localhost/42839] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@66d23e4a{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:17,977 [Listener at localhost/42839] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@49a64d82{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:17,989 [Listener at localhost/42839] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 44632
2020-12-03 07:22:17,994 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:17,995 [BP-1100016829-172.17.0.10-1606980108214 heartbeating to localhost/127.0.0.1:45230] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:17,995 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:17,995 [BP-1100016829-172.17.0.10-1606980108214 heartbeating to localhost/127.0.0.1:45230] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1100016829-172.17.0.10-1606980108214 (Datanode Uuid 9b8e6ff5-6652-42d9-b0e3-a3e292609b38) service to localhost/127.0.0.1:45230
2020-12-03 07:22:17,997 [BP-1100016829-172.17.0.10-1606980108214 heartbeating to localhost/127.0.0.1:45230] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1100016829-172.17.0.10-1606980108214 (Datanode Uuid 9b8e6ff5-6652-42d9-b0e3-a3e292609b38)
2020-12-03 07:22:17,997 [BP-1100016829-172.17.0.10-1606980108214 heartbeating to localhost/127.0.0.1:45230] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1100016829-172.17.0.10-1606980108214
2020-12-03 07:22:17,998 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1100016829-172.17.0.10-1606980108214] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:17,998 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1100016829-172.17.0.10-1606980108214] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:18,004 [Listener at localhost/42839] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:22:18,005 [Listener at localhost/42839] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:22:18,006 [Listener at localhost/42839] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:22:18,006 [Listener at localhost/42839] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:22:18,011 [Listener at localhost/42839] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:22:18,011 [Listener at localhost/42839] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 2
2020-12-03 07:22:18,011 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@1c25b8a7] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:22:18,011 [Listener at localhost/42839] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:22:18,013 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-3fc583cb-7f40-46a3-bfbe-cbc88b91b532) exiting.
2020-12-03 07:22:18,013 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-72955610-3c7e-4c7c-951e-a6a14c5e58c7) exiting.
2020-12-03 07:22:18,042 [Listener at localhost/42839] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@3d4d3fe7{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:22:18,043 [Listener at localhost/42839] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@65f87a2c{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:18,043 [Listener at localhost/42839] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@70e0accd{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:18,043 [Listener at localhost/42839] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1e11bc55{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:18,045 [Listener at localhost/42839] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 45822
2020-12-03 07:22:18,053 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:18,061 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:18,062 [BP-1100016829-172.17.0.10-1606980108214 heartbeating to localhost/127.0.0.1:45230] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:18,062 [BP-1100016829-172.17.0.10-1606980108214 heartbeating to localhost/127.0.0.1:45230] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1100016829-172.17.0.10-1606980108214 (Datanode Uuid 0c65a2b8-68d6-499f-9b6a-8441c2d9c440) service to localhost/127.0.0.1:45230
2020-12-03 07:22:18,062 [BP-1100016829-172.17.0.10-1606980108214 heartbeating to localhost/127.0.0.1:45230] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1100016829-172.17.0.10-1606980108214 (Datanode Uuid 0c65a2b8-68d6-499f-9b6a-8441c2d9c440)
2020-12-03 07:22:18,062 [BP-1100016829-172.17.0.10-1606980108214 heartbeating to localhost/127.0.0.1:45230] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1100016829-172.17.0.10-1606980108214
2020-12-03 07:22:18,063 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1100016829-172.17.0.10-1606980108214] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:18,063 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1100016829-172.17.0.10-1606980108214] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:18,077 [Listener at localhost/42839] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:22:18,077 [Listener at localhost/42839] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:22:18,080 [Listener at localhost/42839] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:22:18,080 [Listener at localhost/42839] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:22:18,087 [Listener at localhost/42839] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:22:18,087 [Listener at localhost/42839] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 1
2020-12-03 07:22:18,088 [Listener at localhost/42839] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:22:18,088 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@41200e0c] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:22:18,091 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-f4ef0132-50b8-4d37-ba1f-ef3ba0c4480e) exiting.
2020-12-03 07:22:18,091 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-67b68069-6b27-4918-9b5e-0a7ff02f0fbb) exiting.
2020-12-03 07:22:18,126 [Listener at localhost/42839] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@29ad44e3{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:22:18,129 [Listener at localhost/42839] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@15bcf458{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:18,131 [Listener at localhost/42839] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@aec50a1{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:18,132 [Listener at localhost/42839] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@24be2d9c{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:18,148 [Listener at localhost/42839] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 46034
2020-12-03 07:22:18,150 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:18,151 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:18,151 [BP-1100016829-172.17.0.10-1606980108214 heartbeating to localhost/127.0.0.1:45230] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:18,151 [BP-1100016829-172.17.0.10-1606980108214 heartbeating to localhost/127.0.0.1:45230] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1100016829-172.17.0.10-1606980108214 (Datanode Uuid 0b683f72-a473-4822-835d-d3119cedc5f6) service to localhost/127.0.0.1:45230
2020-12-03 07:22:18,152 [BP-1100016829-172.17.0.10-1606980108214 heartbeating to localhost/127.0.0.1:45230] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1100016829-172.17.0.10-1606980108214 (Datanode Uuid 0b683f72-a473-4822-835d-d3119cedc5f6)
2020-12-03 07:22:18,152 [BP-1100016829-172.17.0.10-1606980108214 heartbeating to localhost/127.0.0.1:45230] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1100016829-172.17.0.10-1606980108214
2020-12-03 07:22:18,153 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1100016829-172.17.0.10-1606980108214] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:18,158 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1100016829-172.17.0.10-1606980108214] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:18,171 [Listener at localhost/42839] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:22:18,171 [Listener at localhost/42839] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:22:18,175 [Listener at localhost/42839] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:22:18,175 [Listener at localhost/42839] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:22:18,186 [Listener at localhost/42839] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:22:18,187 [Listener at localhost/42839] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:22:18,188 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@4c6daf0] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:22:18,188 [Listener at localhost/42839] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:22:18,192 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-1c271b4a-d89b-4e1c-a0ff-ab9324fd2701) exiting.
2020-12-03 07:22:18,193 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-d8b288e5-db08-432f-b76c-3eca5f9e8bde) exiting.
2020-12-03 07:22:18,220 [Listener at localhost/42839] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@61526469{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:22:18,221 [Listener at localhost/42839] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@274872f8{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:18,222 [Listener at localhost/42839] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@62e70ea3{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:18,223 [Listener at localhost/42839] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7a7471ce{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:18,225 [Listener at localhost/42839] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 39899
2020-12-03 07:22:18,231 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:18,232 [BP-1100016829-172.17.0.10-1606980108214 heartbeating to localhost/127.0.0.1:45230] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:22:18,232 [BP-1100016829-172.17.0.10-1606980108214 heartbeating to localhost/127.0.0.1:45230] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-1100016829-172.17.0.10-1606980108214 (Datanode Uuid b66a2e06-3db7-4022-a57e-b577adcd540b) service to localhost/127.0.0.1:45230
2020-12-03 07:22:18,236 [BP-1100016829-172.17.0.10-1606980108214 heartbeating to localhost/127.0.0.1:45230] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1100016829-172.17.0.10-1606980108214 (Datanode Uuid b66a2e06-3db7-4022-a57e-b577adcd540b)
2020-12-03 07:22:18,236 [BP-1100016829-172.17.0.10-1606980108214 heartbeating to localhost/127.0.0.1:45230] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-1100016829-172.17.0.10-1606980108214
2020-12-03 07:22:18,237 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:18,238 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1100016829-172.17.0.10-1606980108214] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:18,238 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1100016829-172.17.0.10-1606980108214] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:22:18,259 [Listener at localhost/42839] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:22:18,259 [Listener at localhost/42839] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:22:18,263 [Listener at localhost/42839] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:22:18,264 [Listener at localhost/42839] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:22:18,277 [Listener at localhost/42839] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:22:18,278 [Listener at localhost/42839] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:22:18,278 [Listener at localhost/42839] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:22:18,280 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@45cff11c] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:22:18,280 [Listener at localhost/42839] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 1, 19
2020-12-03 07:22:18,280 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@1b065145] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:22:18,282 [Listener at localhost/42839] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 20 Total time for transactions(ms): 24 Number of transactions batched in Syncs: 3 Number of syncs: 18 SyncTimes(ms): 2 2 
2020-12-03 07:22:18,288 [Listener at localhost/42839] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000020
2020-12-03 07:22:18,290 [Listener at localhost/42839] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000020
2020-12-03 07:22:18,292 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:22:18,292 [CacheReplicationMonitor(523546785)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:22:18,294 [Listener at localhost/42839] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 45230
2020-12-03 07:22:18,300 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:22:18,300 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:22:18,301 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:22:18,301 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:22:18,364 [Listener at localhost/42839] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:22:18,365 [Listener at localhost/42839] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:22:18,367 [Listener at localhost/42839] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@7a3793c7{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:22:18,370 [Listener at localhost/42839] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4c012563{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:22:18,371 [Listener at localhost/42839] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@71687585{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:22:18,371 [Listener at localhost/42839] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5c7bfdc1{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:22:18,375 [Listener at localhost/42839] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-12-03 07:22:18,438 [Listener at localhost/42839] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-12-03 07:22:18,439 [Listener at localhost/42839] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
msx-rc 0
