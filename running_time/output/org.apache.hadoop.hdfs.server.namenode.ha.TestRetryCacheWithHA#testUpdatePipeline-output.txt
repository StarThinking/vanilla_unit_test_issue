2020-12-03 07:20:22,716 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(493)) - starting cluster: numNameNodes=2, numDataNodes=10
2020-12-03 07:20:22,766 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:initMiniDFSCluster(875)) - MiniDFSCluster disabling checkpointing in the Standby node since no HTTP ports have been specified.
2020-12-03 07:20:22,767 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:initMiniDFSCluster(881)) - MiniDFSCluster disabling log-roll triggering in the Standby node since no IPC ports have been specified.
Formatting using clusterid: testClusterID
2020-12-03 07:20:23,680 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:20:23,699 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:20:23,701 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:20:23,702 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:20:23,710 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:20:23,711 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:20:23,711 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:20:23,717 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: minidfs-ns
2020-12-03 07:20:23,717 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: true
2020-12-03 07:20:23,772 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:23,778 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2020-12-03 07:20:23,779 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:20:23,779 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:20:23,786 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:20:23,787 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:20:23
2020-12-03 07:20:23,789 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:20:23,790 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:23,792 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-12-03 07:20:23,792 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:20:23,813 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:20:23,813 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:20:23,822 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:20:23,822 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:20:23,823 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:20:23,823 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:20:23,824 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:20:23,825 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:20:23,825 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:20:23,826 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:20:23,826 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:20:23,827 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:20:23,827 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:20:23,867 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GLOBAL serial map: bits=29 maxEntries=536870911
2020-12-03 07:20:23,868 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - USER serial map: bits=24 maxEntries=16777215
2020-12-03 07:20:23,868 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - GROUP serial map: bits=24 maxEntries=16777215
2020-12-03 07:20:23,869 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:<clinit>(51)) - XATTR serial map: bits=24 maxEntries=16777215
2020-12-03 07:20:23,886 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:20:23,886 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:23,887 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-12-03 07:20:23,887 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:20:23,895 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? true
2020-12-03 07:20:23,896 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:20:23,896 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:20:23,897 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:20:23,906 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:20:23,910 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:20:23,920 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:20:23,920 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:23,921 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-12-03 07:20:23,922 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:20:23,934 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:20:23,935 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:20:23,935 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:20:23,942 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:20:23,942 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:20:23,945 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:20:23,945 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:23,946 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-12-03 07:20:23,946 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:20:24,006 [main] INFO  namenode.FSImage (FSImage.java:format(185)) - Allocated new BlockPoolId: BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:24,125 [main] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-12-03 07:20:24,258 [main] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-12-03 07:20:24,393 [main] INFO  common.Storage (NNStorage.java:format(595)) - Storage directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/shared-edits-0-through-1 has been successfully formatted.
2020-12-03 07:20:24,439 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:20:24,439 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(512)) - Saving image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-12-03 07:20:24,579 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:20:24,579 [FSImageSaver for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(516)) - Image file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .
2020-12-03 07:20:24,697 [main] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-12-03 07:20:24,808 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:copyNameDirs(1264)) - Copying namedir from primary node dir file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 to file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-3
2020-12-03 07:20:24,831 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:copyNameDirs(1264)) - Copying namedir from primary node dir file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 to file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-4
2020-12-03 07:20:24,840 [main] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:20:25,148 [main] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(118)) - Loaded properties from hadoop-metrics2.properties
2020-12-03 07:20:25,254 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-12-03 07:20:25,254 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-12-03 07:20:25,266 [main] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is file:///
2020-12-03 07:20:25,311 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1a942c18] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:25,331 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:20:25,337 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:25,355 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @3878ms
2020-12-03 07:20:25,489 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:25,493 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:20:25,494 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:25,505 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:25,508 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:20:25,508 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:25,509 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:25,543 [main] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:20:25,543 [main] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:20:25,554 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 44731
2020-12-03 07:20:25,556 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:25,607 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@78fa769e{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:25,608 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@54e041a4{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:25,657 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6337c201{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:20:25,666 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2b175c00{HTTP/1.1,[http/1.1]}{localhost:44731}
2020-12-03 07:20:25,666 [main] INFO  server.Server (Server.java:doStart(419)) - Started @4189ms
2020-12-03 07:20:25,677 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:20:25,677 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:20:25,678 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:20:25,678 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:20:25,678 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:20:25,679 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:20:25,679 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:20:25,680 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: minidfs-ns
2020-12-03 07:20:25,680 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: true
2020-12-03 07:20:25,681 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:25,681 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:20:25,681 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:20:25,682 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:20:25,682 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:20:25
2020-12-03 07:20:25,683 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:20:25,683 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:25,683 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:20:25,683 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:20:25,687 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:20:25,688 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:20:25,688 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:20:25,689 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:20:25,689 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:20:25,690 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:20:25,690 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:20:25,691 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:20:25,691 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:20:25,691 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:20:25,692 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:20:25,692 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:20:25,693 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:20:25,694 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:20:25,694 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:25,694 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:20:25,695 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:20:25,700 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? true
2020-12-03 07:20:25,700 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:20:25,700 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:20:25,701 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:20:25,701 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:20:25,701 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:20:25,702 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:20:25,702 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:25,703 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:20:25,703 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:20:25,704 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:20:25,704 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:20:25,705 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:20:25,705 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:20:25,705 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:20:25,706 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:20:25,706 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:25,707 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:20:25,707 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:20:26,002 [main] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 1479@de78f7a5f0cb
2020-12-03 07:20:26,274 [main] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 1479@de78f7a5f0cb
2020-12-03 07:20:26,275 [main] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/shared-edits-0-through-1
2020-12-03 07:20:26,280 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:20:26,281 [main] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:20:26,325 [main] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:20:26,333 [main] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:20:26,333 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-12-03 07:20:26,338 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2020-12-03 07:20:26,339 [main] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:20:26,339 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 628 msecs
2020-12-03 07:20:26,533 [main] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:20:26,577 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:26,591 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:26,859 [Listener at localhost/35507] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:35507 to access this namenode/service.
2020-12-03 07:20:26,862 [Listener at localhost/35507] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:20:26,884 [Listener at localhost/35507] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:20:26,896 [Listener at localhost/35507] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:20:26,896 [Listener at localhost/35507] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:20:26,896 [Listener at localhost/35507] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:20:26,927 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:26,928 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:26,931 [Listener at localhost/35507] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:35507
2020-12-03 07:20:26,934 [Listener at localhost/35507] INFO  namenode.FSNamesystem (FSNamesystem.java:startStandbyServices(1391)) - Starting services required for standby state
2020-12-03 07:20:26,936 [Listener at localhost/35507] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.log-roll.period(-1) assuming SECONDS
2020-12-03 07:20:26,936 [Listener at localhost/35507] INFO  ha.EditLogTailer (EditLogTailer.java:<init>(208)) - Not going to trigger log rolls on active node because dfs.ha.log-roll.period is negative.
2020-12-03 07:20:26,936 [Listener at localhost/35507] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.period.backoff-max(0) assuming SECONDS
2020-12-03 07:20:26,936 [Listener at localhost/35507] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.rolledits.timeout(60) assuming SECONDS
2020-12-03 07:20:26,940 [Listener at localhost/35507] INFO  namenode.NameNode (NameNode.java:createNameNode(1632)) - createNameNode []
2020-12-03 07:20:26,941 [Listener at localhost/35507] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-12-03 07:20:26,941 [Listener at localhost/35507] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is file:///
2020-12-03 07:20:26,950 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@426b6a74] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:26,950 [Listener at localhost/35507] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hdfs at: http://localhost:0
2020-12-03 07:20:26,950 [Listener at localhost/35507] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:26,952 [Listener at localhost/35507] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:26,953 [Listener at localhost/35507] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-12-03 07:20:26,954 [Listener at localhost/35507] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:26,956 [Listener at localhost/35507] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:26,957 [Listener at localhost/35507] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-12-03 07:20:26,958 [Listener at localhost/35507] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:26,958 [Listener at localhost/35507] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:26,960 [Listener at localhost/35507] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(102)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-12-03 07:20:26,960 [Listener at localhost/35507] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(806)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-12-03 07:20:26,961 [Listener at localhost/35507] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 39000
2020-12-03 07:20:26,961 [Listener at localhost/35507] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:26,964 [Listener at localhost/35507] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6b54655f{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:26,965 [Listener at localhost/35507] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7d3430a7{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:26,974 [Listener at localhost/35507] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@e260766{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-12-03 07:20:26,977 [Listener at localhost/35507] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2c3dec30{HTTP/1.1,[http/1.1]}{localhost:39000}
2020-12-03 07:20:26,977 [Listener at localhost/35507] INFO  server.Server (Server.java:doStart(419)) - Started @5500ms
2020-12-03 07:20:26,982 [Listener at localhost/35507] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(229)) - Edit logging is async:true
2020-12-03 07:20:26,982 [Listener at localhost/35507] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(755)) - KeyProvider: null
2020-12-03 07:20:26,983 [Listener at localhost/35507] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(123)) - fsLock is fair: true
2020-12-03 07:20:26,983 [Listener at localhost/35507] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(141)) - Detailed lock hold time metrics enabled: false
2020-12-03 07:20:26,983 [Listener at localhost/35507] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(780)) - fsOwner             = root (auth:SIMPLE)
2020-12-03 07:20:26,984 [Listener at localhost/35507] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(781)) - supergroup          = supergroup
2020-12-03 07:20:26,984 [Listener at localhost/35507] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(782)) - isPermissionEnabled = true
2020-12-03 07:20:26,984 [Listener at localhost/35507] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(791)) - Determined nameservice ID: minidfs-ns
2020-12-03 07:20:26,985 [Listener at localhost/35507] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(793)) - HA Enabled: true
2020-12-03 07:20:26,985 [Listener at localhost/35507] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:26,986 [Listener at localhost/35507] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(303)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-12-03 07:20:26,986 [Listener at localhost/35507] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(311)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-12-03 07:20:26,987 [Listener at localhost/35507] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-12-03 07:20:26,987 [Listener at localhost/35507] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Dec 03 07:20:26
2020-12-03 07:20:26,988 [Listener at localhost/35507] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-12-03 07:20:26,988 [Listener at localhost/35507] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:26,988 [Listener at localhost/35507] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-12-03 07:20:26,989 [Listener at localhost/35507] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-12-03 07:20:27,005 [Listener at localhost/35507] INFO  blockmanagement.BlockManager (BlockManager.java:createSPSManager(5183)) - Storage policy satisfier is disabled
2020-12-03 07:20:27,005 [Listener at localhost/35507] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(595)) - dfs.block.access.token.enable = false
2020-12-03 07:20:27,006 [Listener at localhost/35507] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-12-03 07:20:27,006 [Listener at localhost/35507] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-12-03 07:20:27,006 [Listener at localhost/35507] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-12-03 07:20:27,007 [Listener at localhost/35507] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-12-03 07:20:27,007 [Listener at localhost/35507] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(581)) - defaultReplication         = 3
2020-12-03 07:20:27,007 [Listener at localhost/35507] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(582)) - maxReplication             = 512
2020-12-03 07:20:27,007 [Listener at localhost/35507] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(583)) - minReplication             = 1
2020-12-03 07:20:27,008 [Listener at localhost/35507] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(584)) - maxReplicationStreams      = 2
2020-12-03 07:20:27,008 [Listener at localhost/35507] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(585)) - redundancyRecheckInterval  = 3000ms
2020-12-03 07:20:27,008 [Listener at localhost/35507] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(586)) - encryptDataTransfer        = false
2020-12-03 07:20:27,008 [Listener at localhost/35507] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(587)) - maxNumBlocksToLog          = 1000
2020-12-03 07:20:27,009 [Listener at localhost/35507] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-12-03 07:20:27,009 [Listener at localhost/35507] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:27,010 [Listener at localhost/35507] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-12-03 07:20:27,010 [Listener at localhost/35507] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-12-03 07:20:27,018 [Listener at localhost/35507] INFO  namenode.FSDirectory (FSDirectory.java:<init>(290)) - ACLs enabled? true
2020-12-03 07:20:27,018 [Listener at localhost/35507] INFO  namenode.FSDirectory (FSDirectory.java:<init>(294)) - POSIX ACL inheritance enabled? true
2020-12-03 07:20:27,018 [Listener at localhost/35507] INFO  namenode.FSDirectory (FSDirectory.java:<init>(298)) - XAttrs enabled? true
2020-12-03 07:20:27,019 [Listener at localhost/35507] INFO  namenode.NameNode (FSDirectory.java:<init>(362)) - Caching file names occurring more than 10 times
2020-12-03 07:20:27,019 [Listener at localhost/35507] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-12-03 07:20:27,019 [Listener at localhost/35507] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-12-03 07:20:27,019 [Listener at localhost/35507] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-12-03 07:20:27,020 [Listener at localhost/35507] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:27,020 [Listener at localhost/35507] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-12-03 07:20:27,020 [Listener at localhost/35507] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-12-03 07:20:27,023 [Listener at localhost/35507] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-12-03 07:20:27,024 [Listener at localhost/35507] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-12-03 07:20:27,024 [Listener at localhost/35507] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-12-03 07:20:27,024 [Listener at localhost/35507] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(996)) - Retry cache on namenode is enabled
2020-12-03 07:20:27,024 [Listener at localhost/35507] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(1004)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-12-03 07:20:27,024 [Listener at localhost/35507] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-12-03 07:20:27,025 [Listener at localhost/35507] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-12-03 07:20:27,025 [Listener at localhost/35507] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-12-03 07:20:27,025 [Listener at localhost/35507] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-12-03 07:20:27,241 [Listener at localhost/35507] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-3/in_use.lock acquired by nodename 1479@de78f7a5f0cb
2020-12-03 07:20:27,490 [Listener at localhost/35507] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-4/in_use.lock acquired by nodename 1479@de78f7a5f0cb
2020-12-03 07:20:27,491 [Listener at localhost/35507] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/shared-edits-0-through-1
2020-12-03 07:20:27,495 [Listener at localhost/35507] INFO  namenode.FSImage (FSImage.java:loadFSImage(733)) - No edit log streams selected.
2020-12-03 07:20:27,496 [Listener at localhost/35507] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(797)) - Planning to load image: FSImageFile(file=/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-3/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-12-03 07:20:27,498 [Listener at localhost/35507] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(234)) - Loading 1 INodes.
2020-12-03 07:20:27,500 [Listener at localhost/35507] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(246)) - Loaded FSImage in 0 seconds.
2020-12-03 07:20:27,501 [Listener at localhost/35507] INFO  namenode.FSImage (FSImage.java:loadFSImage(978)) - Loaded image for txid 0 from /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-3/current/fsimage_0000000000000000000
2020-12-03 07:20:27,501 [Listener at localhost/35507] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1110)) - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2020-12-03 07:20:27,502 [Listener at localhost/35507] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-12-03 07:20:27,502 [Listener at localhost/35507] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(727)) - Finished loading FSImage in 475 msecs
2020-12-03 07:20:27,503 [Listener at localhost/35507] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(448)) - RPC server is binding to localhost:0
2020-12-03 07:20:27,504 [Listener at localhost/35507] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:27,505 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:27,510 [Listener at localhost/40176] INFO  namenode.NameNode (NameNode.java:initialize(722)) - Clients are to use localhost:40176 to access this namenode/service.
2020-12-03 07:20:27,511 [Listener at localhost/40176] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5090)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-12-03 07:20:27,529 [Listener at localhost/40176] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-12-03 07:20:27,531 [Listener at localhost/40176] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(400)) - STATE* Leaving safe mode after 0 secs
2020-12-03 07:20:27,532 [Listener at localhost/40176] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(406)) - STATE* Network topology has 0 racks and 0 datanodes
2020-12-03 07:20:27,532 [Listener at localhost/40176] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(408)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-12-03 07:20:27,539 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:27,539 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:27,542 [Listener at localhost/40176] INFO  namenode.NameNode (NameNode.java:startCommonServices(828)) - NameNode RPC up at: localhost/127.0.0.1:40176
2020-12-03 07:20:27,543 [Listener at localhost/40176] INFO  namenode.FSNamesystem (FSNamesystem.java:startStandbyServices(1391)) - Starting services required for standby state
2020-12-03 07:20:27,543 [Listener at localhost/40176] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.log-roll.period(-1) assuming SECONDS
2020-12-03 07:20:27,543 [Listener at localhost/40176] INFO  ha.EditLogTailer (EditLogTailer.java:<init>(208)) - Not going to trigger log rolls on active node because dfs.ha.log-roll.period is negative.
2020-12-03 07:20:27,543 [Listener at localhost/40176] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.period.backoff-max(0) assuming SECONDS
2020-12-03 07:20:27,544 [Listener at localhost/40176] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.rolledits.timeout(60) assuming SECONDS
2020-12-03 07:20:27,557 [Listener at localhost/40176] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:20:27,578 [Listener at localhost/40176] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:20:27,596 [Listener at localhost/40176] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:20:27,602 [Listener at localhost/40176] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:27,608 [Listener at localhost/40176] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:27,612 [Listener at localhost/40176] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:27,619 [Listener at localhost/40176] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:27,620 [Listener at localhost/40176] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:27,627 [Listener at localhost/40176] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:27,637 [Listener at localhost/40176] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:34066
2020-12-03 07:20:27,641 [Listener at localhost/40176] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:27,641 [Listener at localhost/40176] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:27,668 [Listener at localhost/40176] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:27,671 [Listener at localhost/40176] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:27,672 [Listener at localhost/40176] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:27,672 [Listener at localhost/40176] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:27,676 [Listener at localhost/40176] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:27,677 [Listener at localhost/40176] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:27,677 [Listener at localhost/40176] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:27,677 [Listener at localhost/40176] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:27,681 [Listener at localhost/40176] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 44389
2020-12-03 07:20:27,681 [Listener at localhost/40176] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:27,683 [Listener at localhost/40176] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@165b8a71{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:27,684 [Listener at localhost/40176] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2f058b8a{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:27,693 [Listener at localhost/40176] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@452ba1db{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:20:27,693 [Listener at localhost/40176] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2289aca5{HTTP/1.1,[http/1.1]}{localhost:44389}
2020-12-03 07:20:27,694 [Listener at localhost/40176] INFO  server.Server (Server.java:doStart(419)) - Started @6217ms
2020-12-03 07:20:28,035 [Listener at localhost/40176] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:40284
2020-12-03 07:20:28,242 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5489c777] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:28,244 [Listener at localhost/40176] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:28,244 [Listener at localhost/40176] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:28,265 [Listener at localhost/40176] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:28,266 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:28,273 [Listener at localhost/43592] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:43592
2020-12-03 07:20:28,287 [Listener at localhost/43592] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: minidfs-ns
2020-12-03 07:20:28,289 [Listener at localhost/43592] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: minidfs-ns
2020-12-03 07:20:28,304 [Thread-88] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40176 starting to offer service
2020-12-03 07:20:28,304 [Thread-87] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35507 starting to offer service
2020-12-03 07:20:28,314 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:28,314 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:28,319 [Listener at localhost/43592] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:20:28,320 [Listener at localhost/43592] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:20:28,321 [Listener at localhost/43592] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:20:28,323 [Listener at localhost/43592] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:28,324 [Listener at localhost/43592] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:28,324 [Listener at localhost/43592] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:28,325 [Listener at localhost/43592] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:28,325 [Listener at localhost/43592] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:28,325 [Listener at localhost/43592] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:28,326 [Listener at localhost/43592] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:35105
2020-12-03 07:20:28,326 [Listener at localhost/43592] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:28,326 [Listener at localhost/43592] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:28,328 [Listener at localhost/43592] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:28,329 [Listener at localhost/43592] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:28,330 [Listener at localhost/43592] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:28,331 [Listener at localhost/43592] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:28,333 [Listener at localhost/43592] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:28,334 [Listener at localhost/43592] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:28,334 [Listener at localhost/43592] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:28,334 [Listener at localhost/43592] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:28,335 [Listener at localhost/43592] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 35222
2020-12-03 07:20:28,335 [Listener at localhost/43592] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:28,339 [Listener at localhost/43592] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5bbc9f97{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:28,340 [Listener at localhost/43592] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@41382722{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:28,348 [Listener at localhost/43592] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@c41709a{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:20:28,349 [Listener at localhost/43592] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7db0565c{HTTP/1.1,[http/1.1]}{localhost:35222}
2020-12-03 07:20:28,349 [Listener at localhost/43592] INFO  server.Server (Server.java:doStart(419)) - Started @6872ms
2020-12-03 07:20:28,445 [Listener at localhost/43592] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:43631
2020-12-03 07:20:28,445 [Listener at localhost/43592] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:28,446 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@52eacb4b] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:28,446 [Listener at localhost/43592] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:28,450 [Listener at localhost/43592] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:28,452 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:28,457 [Listener at localhost/41061] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:41061
2020-12-03 07:20:28,468 [Listener at localhost/41061] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: minidfs-ns
2020-12-03 07:20:28,469 [Listener at localhost/41061] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: minidfs-ns
2020-12-03 07:20:28,542 [Thread-113] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35507 starting to offer service
2020-12-03 07:20:28,549 [Thread-114] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40176 starting to offer service
2020-12-03 07:20:28,551 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:28,551 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:28,558 [Listener at localhost/41061] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:20:28,559 [Listener at localhost/41061] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:20:28,560 [Listener at localhost/41061] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:20:28,562 [Listener at localhost/41061] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:28,563 [Listener at localhost/41061] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:28,563 [Listener at localhost/41061] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:28,564 [Listener at localhost/41061] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:28,564 [Listener at localhost/41061] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:28,564 [Listener at localhost/41061] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:28,565 [Listener at localhost/41061] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:40799
2020-12-03 07:20:28,565 [Listener at localhost/41061] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:28,565 [Listener at localhost/41061] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:28,567 [Listener at localhost/41061] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:28,568 [Listener at localhost/41061] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:28,569 [Listener at localhost/41061] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:28,569 [Listener at localhost/41061] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:28,573 [Listener at localhost/41061] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:28,575 [Listener at localhost/41061] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:28,575 [Listener at localhost/41061] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:28,575 [Listener at localhost/41061] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:28,577 [Listener at localhost/41061] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 40646
2020-12-03 07:20:28,577 [Listener at localhost/41061] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:28,581 [Listener at localhost/41061] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@433ffad1{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:28,582 [Listener at localhost/41061] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2575f671{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:28,607 [Listener at localhost/41061] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1b39fd82{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:20:28,609 [Listener at localhost/41061] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3e2fc448{HTTP/1.1,[http/1.1]}{localhost:40646}
2020-12-03 07:20:28,609 [Listener at localhost/41061] INFO  server.Server (Server.java:doStart(419)) - Started @7132ms
2020-12-03 07:20:28,654 [Listener at localhost/41061] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:40487
2020-12-03 07:20:28,663 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@588ab592] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:28,666 [Listener at localhost/41061] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:28,666 [Listener at localhost/41061] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:28,667 [Listener at localhost/41061] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:28,675 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:28,679 [Listener at localhost/35855] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:35855
2020-12-03 07:20:28,685 [Listener at localhost/35855] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: minidfs-ns
2020-12-03 07:20:28,685 [Listener at localhost/35855] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: minidfs-ns
2020-12-03 07:20:28,686 [Thread-136] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35507 starting to offer service
2020-12-03 07:20:28,692 [Thread-137] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40176 starting to offer service
2020-12-03 07:20:28,694 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:28,694 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:28,702 [Listener at localhost/35855] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 3 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:20:28,704 [Listener at localhost/35855] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:20:28,721 [Listener at localhost/35855] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:20:28,722 [Listener at localhost/35855] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:28,723 [Listener at localhost/35855] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:28,723 [Thread-113] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:28,723 [Listener at localhost/35855] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:28,723 [Thread-87] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:28,725 [Listener at localhost/35855] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:28,725 [Listener at localhost/35855] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:28,726 [Listener at localhost/35855] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:28,728 [Listener at localhost/35855] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:34525
2020-12-03 07:20:28,728 [Listener at localhost/35855] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:28,729 [Listener at localhost/35855] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:28,729 [Thread-136] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:28,730 [Listener at localhost/35855] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:28,733 [Listener at localhost/35855] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:28,734 [Listener at localhost/35855] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:28,734 [Listener at localhost/35855] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:28,736 [Listener at localhost/35855] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:28,737 [Listener at localhost/35855] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:28,737 [Listener at localhost/35855] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:28,737 [Listener at localhost/35855] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:28,738 [Listener at localhost/35855] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 34918
2020-12-03 07:20:28,738 [Listener at localhost/35855] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:28,740 [Listener at localhost/35855] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@58783f6c{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:28,741 [Listener at localhost/35855] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@512d92b{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:28,748 [Listener at localhost/35855] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1dfd5f51{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:20:28,749 [Listener at localhost/35855] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3c321bdb{HTTP/1.1,[http/1.1]}{localhost:34918}
2020-12-03 07:20:28,749 [Listener at localhost/35855] INFO  server.Server (Server.java:doStart(419)) - Started @7272ms
2020-12-03 07:20:28,776 [Thread-136] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 1479@de78f7a5f0cb
2020-12-03 07:20:28,776 [Thread-113] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 1479@de78f7a5f0cb
2020-12-03 07:20:28,776 [Thread-87] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 1479@de78f7a5f0cb
2020-12-03 07:20:28,830 [Thread-136] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 is not formatted for namespace 989125680. Formatting...
2020-12-03 07:20:28,832 [Thread-136] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-a225e481-cea1-416c-80ae-569f36dd3f21 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 
2020-12-03 07:20:28,833 [Thread-87] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 989125680. Formatting...
2020-12-03 07:20:28,833 [Thread-113] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 is not formatted for namespace 989125680. Formatting...
2020-12-03 07:20:28,834 [Thread-113] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-3af5a235-4bf3-49e0-9488-a4f87533e8a2 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 
2020-12-03 07:20:28,833 [Thread-87] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-1cb0cc9b-9989-4e43-b52d-6995994c4fc1 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-12-03 07:20:28,838 [Listener at localhost/35855] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:45210
2020-12-03 07:20:28,839 [Listener at localhost/35855] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:28,839 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3abd581e] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:28,839 [Listener at localhost/35855] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:28,840 [Listener at localhost/35855] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:28,841 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:28,844 [Listener at localhost/45065] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:45065
2020-12-03 07:20:28,849 [Listener at localhost/45065] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: minidfs-ns
2020-12-03 07:20:28,850 [Listener at localhost/45065] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: minidfs-ns
2020-12-03 07:20:28,851 [Thread-159] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35507 starting to offer service
2020-12-03 07:20:28,851 [Thread-160] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40176 starting to offer service
2020-12-03 07:20:28,854 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:28,854 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:28,863 [Listener at localhost/45065] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 4 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:20:28,864 [Listener at localhost/45065] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:20:28,865 [Listener at localhost/45065] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:20:28,865 [Thread-159] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:28,867 [Listener at localhost/45065] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:28,867 [Listener at localhost/45065] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:28,868 [Listener at localhost/45065] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:28,868 [Listener at localhost/45065] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:28,868 [Listener at localhost/45065] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:28,869 [Listener at localhost/45065] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:28,869 [Listener at localhost/45065] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:38706
2020-12-03 07:20:28,870 [Listener at localhost/45065] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:28,870 [Listener at localhost/45065] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:28,871 [Listener at localhost/45065] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:28,873 [Listener at localhost/45065] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:28,874 [Listener at localhost/45065] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:28,874 [Listener at localhost/45065] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:28,876 [Listener at localhost/45065] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:28,877 [Listener at localhost/45065] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:28,886 [Listener at localhost/45065] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:28,888 [Listener at localhost/45065] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:28,889 [Listener at localhost/45065] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 33079
2020-12-03 07:20:28,889 [Listener at localhost/45065] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:28,893 [Listener at localhost/45065] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@323e8306{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:28,894 [Listener at localhost/45065] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4acf72b6{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:28,903 [Listener at localhost/45065] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7bfc3126{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:20:28,904 [Listener at localhost/45065] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3e792ce3{HTTP/1.1,[http/1.1]}{localhost:33079}
2020-12-03 07:20:28,905 [Listener at localhost/45065] INFO  server.Server (Server.java:doStart(419)) - Started @7428ms
2020-12-03 07:20:28,919 [Listener at localhost/45065] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:40710
2020-12-03 07:20:28,920 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@26f143ed] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:28,920 [Listener at localhost/45065] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:28,920 [Listener at localhost/45065] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:28,921 [Listener at localhost/45065] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:28,922 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:28,924 [Thread-159] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/in_use.lock acquired by nodename 1479@de78f7a5f0cb
2020-12-03 07:20:28,924 [Thread-159] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 is not formatted for namespace 989125680. Formatting...
2020-12-03 07:20:28,925 [Thread-159] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-f47ecebd-23fc-4bb6-9f5f-7463b5001b37 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 
2020-12-03 07:20:28,927 [Listener at localhost/38901] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:38901
2020-12-03 07:20:28,932 [Listener at localhost/38901] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: minidfs-ns
2020-12-03 07:20:28,933 [Listener at localhost/38901] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: minidfs-ns
2020-12-03 07:20:28,933 [Thread-182] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35507 starting to offer service
2020-12-03 07:20:28,933 [Thread-183] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40176 starting to offer service
2020-12-03 07:20:28,943 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:28,944 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:28,948 [Listener at localhost/38901] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 5 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:20:28,950 [Listener at localhost/38901] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:20:28,951 [Listener at localhost/38901] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:20:28,958 [Thread-182] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:28,960 [Listener at localhost/38901] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:28,961 [Listener at localhost/38901] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:28,961 [Listener at localhost/38901] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:28,966 [Listener at localhost/38901] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:28,967 [Listener at localhost/38901] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:28,967 [Listener at localhost/38901] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:28,968 [Listener at localhost/38901] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:40778
2020-12-03 07:20:28,968 [Listener at localhost/38901] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:28,968 [Listener at localhost/38901] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:28,970 [Listener at localhost/38901] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:28,972 [Listener at localhost/38901] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:28,972 [Listener at localhost/38901] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:28,973 [Listener at localhost/38901] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:28,975 [Listener at localhost/38901] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:28,976 [Listener at localhost/38901] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:28,976 [Listener at localhost/38901] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:28,976 [Listener at localhost/38901] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:28,978 [Listener at localhost/38901] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 45761
2020-12-03 07:20:28,978 [Listener at localhost/38901] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:28,981 [Listener at localhost/38901] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6bd51ed8{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:28,981 [Listener at localhost/38901] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@51abf713{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:28,991 [Listener at localhost/38901] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@85ec632{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:20:28,992 [Listener at localhost/38901] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1c05a54d{HTTP/1.1,[http/1.1]}{localhost:45761}
2020-12-03 07:20:28,993 [Listener at localhost/38901] INFO  server.Server (Server.java:doStart(419)) - Started @7516ms
2020-12-03 07:20:29,009 [Thread-182] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/in_use.lock acquired by nodename 1479@de78f7a5f0cb
2020-12-03 07:20:29,009 [Thread-182] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 is not formatted for namespace 989125680. Formatting...
2020-12-03 07:20:29,010 [Thread-182] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-c7bc2dbc-457f-4ca9-86cc-267ab86263f8 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 
2020-12-03 07:20:29,011 [Listener at localhost/38901] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:37234
2020-12-03 07:20:29,012 [Listener at localhost/38901] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:29,012 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5fd9b663] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:29,012 [Listener at localhost/38901] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:29,012 [Listener at localhost/38901] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:29,013 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:29,017 [Listener at localhost/35318] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:35318
2020-12-03 07:20:29,022 [Listener at localhost/35318] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: minidfs-ns
2020-12-03 07:20:29,023 [Listener at localhost/35318] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: minidfs-ns
2020-12-03 07:20:29,024 [Thread-205] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35507 starting to offer service
2020-12-03 07:20:29,024 [Thread-206] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40176 starting to offer service
2020-12-03 07:20:29,032 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:29,032 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:29,035 [Thread-205] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:29,040 [Listener at localhost/35318] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 6 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:20:29,041 [Listener at localhost/35318] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:20:29,042 [Listener at localhost/35318] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:20:29,043 [Listener at localhost/35318] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:29,046 [Listener at localhost/35318] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:29,047 [Listener at localhost/35318] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:29,047 [Listener at localhost/35318] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:29,048 [Listener at localhost/35318] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:29,048 [Listener at localhost/35318] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:29,049 [Listener at localhost/35318] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:34003
2020-12-03 07:20:29,049 [Listener at localhost/35318] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:29,049 [Listener at localhost/35318] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:29,051 [Listener at localhost/35318] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:29,052 [Listener at localhost/35318] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:29,053 [Listener at localhost/35318] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:29,053 [Listener at localhost/35318] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:29,055 [Listener at localhost/35318] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:29,056 [Listener at localhost/35318] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:29,056 [Listener at localhost/35318] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:29,056 [Listener at localhost/35318] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:29,057 [Listener at localhost/35318] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 37848
2020-12-03 07:20:29,057 [Listener at localhost/35318] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:29,060 [Thread-136] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 1479@de78f7a5f0cb
2020-12-03 07:20:29,061 [Thread-136] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 is not formatted for namespace 989125680. Formatting...
2020-12-03 07:20:29,061 [Thread-136] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-2eb61706-9d88-4c82-b7f4-94ef4c91ca90 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 
2020-12-03 07:20:29,062 [Listener at localhost/35318] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@17ae98d7{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:29,063 [Listener at localhost/35318] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6ac4944a{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:29,069 [Listener at localhost/35318] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1e34c607{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:20:29,071 [Listener at localhost/35318] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@5215cd9a{HTTP/1.1,[http/1.1]}{localhost:37848}
2020-12-03 07:20:29,071 [Listener at localhost/35318] INFO  server.Server (Server.java:doStart(419)) - Started @7594ms
2020-12-03 07:20:29,090 [Listener at localhost/35318] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:39576
2020-12-03 07:20:29,091 [Listener at localhost/35318] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:29,091 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@31198ceb] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:29,091 [Listener at localhost/35318] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:29,092 [Listener at localhost/35318] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:29,093 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:29,098 [Listener at localhost/35791] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:35791
2020-12-03 07:20:29,103 [Thread-205] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/in_use.lock acquired by nodename 1479@de78f7a5f0cb
2020-12-03 07:20:29,103 [Thread-113] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 1479@de78f7a5f0cb
2020-12-03 07:20:29,103 [Thread-205] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 is not formatted for namespace 989125680. Formatting...
2020-12-03 07:20:29,103 [Thread-87] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 1479@de78f7a5f0cb
2020-12-03 07:20:29,104 [Thread-205] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-6ed681d4-7b32-434e-9b37-4319562525f7 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 
2020-12-03 07:20:29,103 [Thread-113] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 is not formatted for namespace 989125680. Formatting...
2020-12-03 07:20:29,104 [Thread-87] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 989125680. Formatting...
2020-12-03 07:20:29,104 [Thread-113] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-e34a2eee-43a4-47ce-b10e-ce5fedc28869 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 
2020-12-03 07:20:29,104 [Thread-87] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-efa2376a-10cf-46b0-adee-6d1ceaed342c for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-12-03 07:20:29,106 [Listener at localhost/35791] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: minidfs-ns
2020-12-03 07:20:29,107 [Listener at localhost/35791] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: minidfs-ns
2020-12-03 07:20:29,107 [Thread-228] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35507 starting to offer service
2020-12-03 07:20:29,108 [Thread-229] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40176 starting to offer service
2020-12-03 07:20:29,109 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:29,110 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:29,114 [Listener at localhost/35791] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 7 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:20:29,116 [Thread-229] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:29,117 [Listener at localhost/35791] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:20:29,117 [Listener at localhost/35791] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:20:29,118 [Listener at localhost/35791] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:29,119 [Listener at localhost/35791] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:29,119 [Listener at localhost/35791] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:29,119 [Listener at localhost/35791] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:29,120 [Listener at localhost/35791] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:29,120 [Listener at localhost/35791] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:29,121 [Listener at localhost/35791] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:38056
2020-12-03 07:20:29,121 [Listener at localhost/35791] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:29,121 [Listener at localhost/35791] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:29,122 [Listener at localhost/35791] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:29,124 [Listener at localhost/35791] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:29,125 [Listener at localhost/35791] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:29,125 [Listener at localhost/35791] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:29,127 [Listener at localhost/35791] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:29,127 [Listener at localhost/35791] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:29,127 [Listener at localhost/35791] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:29,128 [Listener at localhost/35791] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:29,129 [Listener at localhost/35791] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 38587
2020-12-03 07:20:29,129 [Listener at localhost/35791] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:29,134 [Listener at localhost/35791] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@30457e14{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:29,138 [Listener at localhost/35791] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@632aa1a3{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:29,149 [Listener at localhost/35791] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@251ebf23{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:20:29,150 [Listener at localhost/35791] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@29b732a2{HTTP/1.1,[http/1.1]}{localhost:38587}
2020-12-03 07:20:29,150 [Listener at localhost/35791] INFO  server.Server (Server.java:doStart(419)) - Started @7673ms
2020-12-03 07:20:29,196 [Thread-159] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/in_use.lock acquired by nodename 1479@de78f7a5f0cb
2020-12-03 07:20:29,196 [Thread-159] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 is not formatted for namespace 989125680. Formatting...
2020-12-03 07:20:29,203 [Thread-229] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/in_use.lock acquired by nodename 1479@de78f7a5f0cb
2020-12-03 07:20:29,203 [Thread-229] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 is not formatted for namespace 989125680. Formatting...
2020-12-03 07:20:29,204 [Thread-159] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-9f1b799a-562e-4944-90f0-914891761857 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 
2020-12-03 07:20:29,204 [Thread-229] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-f4bfacf8-7145-4886-a5f1-fd5fa3f79dee for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 
2020-12-03 07:20:29,235 [Thread-136] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:29,236 [Thread-136] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:29,236 [Thread-136] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 and block pool id BP-917657629-172.17.0.7-1606980023984 is not formatted. Formatting ...
2020-12-03 07:20:29,236 [Thread-136] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-917657629-172.17.0.7-1606980023984 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-917657629-172.17.0.7-1606980023984/current
2020-12-03 07:20:29,287 [Listener at localhost/35791] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:43290
2020-12-03 07:20:29,287 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@51671b08] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:29,287 [Listener at localhost/35791] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:29,288 [Listener at localhost/35791] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:29,288 [Listener at localhost/35791] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:29,289 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:29,293 [Listener at localhost/34061] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:34061
2020-12-03 07:20:29,298 [Listener at localhost/34061] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: minidfs-ns
2020-12-03 07:20:29,299 [Listener at localhost/34061] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: minidfs-ns
2020-12-03 07:20:29,300 [Thread-251] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35507 starting to offer service
2020-12-03 07:20:29,300 [Thread-252] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40176 starting to offer service
2020-12-03 07:20:29,302 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:29,302 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:29,307 [Thread-251] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:29,308 [Thread-182] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/in_use.lock acquired by nodename 1479@de78f7a5f0cb
2020-12-03 07:20:29,310 [Thread-182] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 is not formatted for namespace 989125680. Formatting...
2020-12-03 07:20:29,310 [Listener at localhost/34061] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 8 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:20:29,310 [Thread-182] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-5ccec8a5-859f-4fa7-857a-b7c956cf3535 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 
2020-12-03 07:20:29,312 [Listener at localhost/34061] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:20:29,312 [Listener at localhost/34061] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:20:29,314 [Listener at localhost/34061] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:29,318 [Listener at localhost/34061] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:29,318 [Listener at localhost/34061] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:29,322 [Listener at localhost/34061] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:29,323 [Listener at localhost/34061] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:29,323 [Listener at localhost/34061] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:29,324 [Listener at localhost/34061] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:33456
2020-12-03 07:20:29,324 [Listener at localhost/34061] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:29,324 [Listener at localhost/34061] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:29,326 [Listener at localhost/34061] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:29,327 [Thread-113] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:29,328 [Thread-113] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:29,328 [Thread-113] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 and block pool id BP-917657629-172.17.0.7-1606980023984 is not formatted. Formatting ...
2020-12-03 07:20:29,328 [Listener at localhost/34061] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:29,328 [Thread-113] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-917657629-172.17.0.7-1606980023984 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-917657629-172.17.0.7-1606980023984/current
2020-12-03 07:20:29,329 [Thread-87] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:29,329 [Thread-87] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:29,329 [Listener at localhost/34061] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:29,329 [Thread-87] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-917657629-172.17.0.7-1606980023984 is not formatted. Formatting ...
2020-12-03 07:20:29,329 [Listener at localhost/34061] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:29,329 [Thread-87] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-917657629-172.17.0.7-1606980023984 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-917657629-172.17.0.7-1606980023984/current
2020-12-03 07:20:29,332 [Listener at localhost/34061] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:29,333 [Listener at localhost/34061] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:29,333 [Listener at localhost/34061] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:29,333 [Listener at localhost/34061] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:29,334 [Listener at localhost/34061] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 35922
2020-12-03 07:20:29,334 [Listener at localhost/34061] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:29,336 [Listener at localhost/34061] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@53cdecf6{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:29,337 [Listener at localhost/34061] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@62b3df3a{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:29,343 [Listener at localhost/34061] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5298dead{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:20:29,345 [Listener at localhost/34061] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@553f3b6e{HTTP/1.1,[http/1.1]}{localhost:35922}
2020-12-03 07:20:29,345 [Listener at localhost/34061] INFO  server.Server (Server.java:doStart(419)) - Started @7868ms
2020-12-03 07:20:29,368 [Listener at localhost/34061] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:44675
2020-12-03 07:20:29,368 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4e406694] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:29,368 [Listener at localhost/34061] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:29,369 [Listener at localhost/34061] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:29,369 [Listener at localhost/34061] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:29,370 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:29,375 [Listener at localhost/45886] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:45886
2020-12-03 07:20:29,382 [Listener at localhost/45886] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: minidfs-ns
2020-12-03 07:20:29,383 [Listener at localhost/45886] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: minidfs-ns
2020-12-03 07:20:29,384 [Thread-274] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35507 starting to offer service
2020-12-03 07:20:29,384 [Thread-275] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40176 starting to offer service
2020-12-03 07:20:29,386 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:29,387 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:29,408 [Listener at localhost/45886] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1659)) - Starting DataNode 9 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19,[DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20
2020-12-03 07:20:29,409 [Listener at localhost/45886] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19
2020-12-03 07:20:29,410 [Listener at localhost/45886] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20
2020-12-03 07:20:29,448 [Thread-251] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/in_use.lock acquired by nodename 1479@de78f7a5f0cb
2020-12-03 07:20:29,449 [Thread-251] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 is not formatted for namespace 989125680. Formatting...
2020-12-03 07:20:29,449 [Thread-251] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-7b973780-45b9-48aa-b1ae-2b36eece14ee for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 
2020-12-03 07:20:29,449 [Thread-205] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/in_use.lock acquired by nodename 1479@de78f7a5f0cb
2020-12-03 07:20:29,449 [Listener at localhost/45886] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-12-03 07:20:29,453 [Thread-205] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 is not formatted for namespace 989125680. Formatting...
2020-12-03 07:20:29,452 [Thread-275] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:29,454 [Thread-205] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-3df7a241-42d4-46b6-9ce4-8b28b0d79357 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 
2020-12-03 07:20:29,455 [Listener at localhost/45886] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:29,455 [Listener at localhost/45886] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-12-03 07:20:29,456 [Listener at localhost/45886] INFO  datanode.DataNode (DataNode.java:<init>(500)) - Configured hostname is 127.0.0.1
2020-12-03 07:20:29,456 [Listener at localhost/45886] INFO  common.Util (Util.java:isDiskStatsEnabled(395)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-12-03 07:20:29,457 [Listener at localhost/45886] INFO  datanode.DataNode (DataNode.java:startDataNode(1400)) - Starting DataNode with maxLockedMemory = 0
2020-12-03 07:20:29,457 [Listener at localhost/45886] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1148)) - Opened streaming server at /127.0.0.1:37871
2020-12-03 07:20:29,457 [Listener at localhost/45886] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-12-03 07:20:29,458 [Listener at localhost/45886] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-12-03 07:20:29,459 [Listener at localhost/45886] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:29,461 [Listener at localhost/45886] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-12-03 07:20:29,461 [Listener at localhost/45886] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-12-03 07:20:29,462 [Listener at localhost/45886] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1072)) - Web server is in development mode. Resources will be read from the source tree.
2020-12-03 07:20:29,462 [Thread-159] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:29,462 [Thread-159] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:29,463 [Thread-159] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 and block pool id BP-917657629-172.17.0.7-1606980023984 is not formatted. Formatting ...
2020-12-03 07:20:29,463 [Thread-159] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-917657629-172.17.0.7-1606980023984 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-917657629-172.17.0.7-1606980023984/current
2020-12-03 07:20:29,465 [Listener at localhost/45886] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(990)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-12-03 07:20:29,466 [Listener at localhost/45886] INFO  http.HttpServer2 (HttpServer2.java:addFilter(963)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-12-03 07:20:29,466 [Listener at localhost/45886] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-12-03 07:20:29,466 [Listener at localhost/45886] INFO  http.HttpServer2 (HttpServer2.java:addFilter(973)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-12-03 07:20:29,467 [Listener at localhost/45886] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1206)) - Jetty bound to port 37842
2020-12-03 07:20:29,467 [Listener at localhost/45886] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-12-03 07:20:29,470 [Listener at localhost/45886] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@60222fd8{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-12-03 07:20:29,471 [Listener at localhost/45886] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@26f1249d{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-12-03 07:20:29,479 [Listener at localhost/45886] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@36c54a56{/,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-12-03 07:20:29,481 [Listener at localhost/45886] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3359c978{HTTP/1.1,[http/1.1]}{localhost:37842}
2020-12-03 07:20:29,481 [Listener at localhost/45886] INFO  server.Server (Server.java:doStart(419)) - Started @8004ms
2020-12-03 07:20:29,497 [Listener at localhost/45886] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:40670
2020-12-03 07:20:29,498 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@73386d72] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-12-03 07:20:29,498 [Listener at localhost/45886] INFO  datanode.DataNode (DataNode.java:startDataNode(1428)) - dnUserName = root
2020-12-03 07:20:29,498 [Listener at localhost/45886] INFO  datanode.DataNode (DataNode.java:startDataNode(1429)) - supergroup = supergroup
2020-12-03 07:20:29,499 [Listener at localhost/45886] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2020-12-03 07:20:29,500 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1219)) - Starting Socket Reader #1 for port 0
2020-12-03 07:20:29,505 [Listener at localhost/43638] INFO  datanode.DataNode (DataNode.java:initIpcServer(1034)) - Opened IPC server at /127.0.0.1:43638
2020-12-03 07:20:29,512 [Listener at localhost/43638] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: minidfs-ns
2020-12-03 07:20:29,512 [Listener at localhost/43638] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: minidfs-ns
2020-12-03 07:20:29,513 [Thread-298] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40176 starting to offer service
2020-12-03 07:20:29,515 [Thread-297] INFO  datanode.DataNode (BPServiceActor.java:run(817)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35507 starting to offer service
2020-12-03 07:20:29,515 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1460)) - IPC Server Responder: starting
2020-12-03 07:20:29,515 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1298)) - IPC Server listener on 0: starting
2020-12-03 07:20:29,531 [Thread-298] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-12-03 07:20:29,538 [Thread-136] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:29,538 [Thread-136] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:29,538 [Thread-136] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 and block pool id BP-917657629-172.17.0.7-1606980023984 is not formatted. Formatting ...
2020-12-03 07:20:29,539 [Thread-136] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-917657629-172.17.0.7-1606980023984 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-917657629-172.17.0.7-1606980023984/current
2020-12-03 07:20:29,606 [Thread-229] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/in_use.lock acquired by nodename 1479@de78f7a5f0cb
2020-12-03 07:20:29,606 [Thread-275] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/in_use.lock acquired by nodename 1479@de78f7a5f0cb
2020-12-03 07:20:29,607 [Thread-229] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 is not formatted for namespace 989125680. Formatting...
2020-12-03 07:20:29,607 [Thread-275] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 is not formatted for namespace 989125680. Formatting...
2020-12-03 07:20:29,609 [Thread-229] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-9024d8af-e369-46b9-b368-4cf2f932788f for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 
2020-12-03 07:20:29,609 [Thread-275] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-36362941-3af0-4d97-975d-6c63a7fd314f for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 
2020-12-03 07:20:29,617 [Thread-113] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:29,617 [Thread-182] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:29,617 [Thread-113] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:29,617 [Thread-182] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:29,618 [Thread-113] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 and block pool id BP-917657629-172.17.0.7-1606980023984 is not formatted. Formatting ...
2020-12-03 07:20:29,618 [Thread-182] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 and block pool id BP-917657629-172.17.0.7-1606980023984 is not formatted. Formatting ...
2020-12-03 07:20:29,618 [Thread-113] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-917657629-172.17.0.7-1606980023984 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-917657629-172.17.0.7-1606980023984/current
2020-12-03 07:20:29,618 [Thread-182] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-917657629-172.17.0.7-1606980023984 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-917657629-172.17.0.7-1606980023984/current
2020-12-03 07:20:29,619 [Thread-87] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:29,619 [Thread-87] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:29,620 [Thread-87] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-917657629-172.17.0.7-1606980023984 is not formatted. Formatting ...
2020-12-03 07:20:29,620 [Thread-87] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-917657629-172.17.0.7-1606980023984 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-917657629-172.17.0.7-1606980023984/current
2020-12-03 07:20:29,696 [Thread-298] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19/in_use.lock acquired by nodename 1479@de78f7a5f0cb
2020-12-03 07:20:29,696 [Thread-298] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19 is not formatted for namespace 989125680. Formatting...
2020-12-03 07:20:29,699 [Thread-298] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-e494c4c0-84f6-42dd-92d8-d29ca6c47e4b for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19 
2020-12-03 07:20:29,764 [Thread-205] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:29,765 [Thread-159] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:29,765 [Thread-205] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:29,765 [Thread-159] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:29,765 [Thread-205] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 and block pool id BP-917657629-172.17.0.7-1606980023984 is not formatted. Formatting ...
2020-12-03 07:20:29,765 [Thread-159] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 and block pool id BP-917657629-172.17.0.7-1606980023984 is not formatted. Formatting ...
2020-12-03 07:20:29,765 [Thread-205] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-917657629-172.17.0.7-1606980023984 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-917657629-172.17.0.7-1606980023984/current
2020-12-03 07:20:29,766 [Thread-159] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-917657629-172.17.0.7-1606980023984 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-917657629-172.17.0.7-1606980023984/current
2020-12-03 07:20:29,841 [Thread-136] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=989125680;bpid=BP-917657629-172.17.0.7-1606980023984;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=989125680;c=1606980023984;bpid=BP-917657629-172.17.0.7-1606980023984;dnuuid=null
2020-12-03 07:20:29,932 [Thread-251] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/in_use.lock acquired by nodename 1479@de78f7a5f0cb
2020-12-03 07:20:29,933 [Thread-113] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=989125680;bpid=BP-917657629-172.17.0.7-1606980023984;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=989125680;c=1606980023984;bpid=BP-917657629-172.17.0.7-1606980023984;dnuuid=null
2020-12-03 07:20:29,933 [Thread-87] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=989125680;bpid=BP-917657629-172.17.0.7-1606980023984;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=989125680;c=1606980023984;bpid=BP-917657629-172.17.0.7-1606980023984;dnuuid=null
2020-12-03 07:20:29,933 [Thread-251] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 is not formatted for namespace 989125680. Formatting...
2020-12-03 07:20:29,934 [Thread-251] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-8870a112-92dc-4859-a282-7b7b8fc69dbd for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 
2020-12-03 07:20:29,946 [Thread-182] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:29,946 [Thread-229] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:29,946 [Thread-182] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:29,947 [Thread-229] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:29,947 [Thread-182] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 and block pool id BP-917657629-172.17.0.7-1606980023984 is not formatted. Formatting ...
2020-12-03 07:20:29,947 [Thread-229] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 and block pool id BP-917657629-172.17.0.7-1606980023984 is not formatted. Formatting ...
2020-12-03 07:20:29,947 [Thread-182] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-917657629-172.17.0.7-1606980023984 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-917657629-172.17.0.7-1606980023984/current
2020-12-03 07:20:29,947 [Thread-229] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-917657629-172.17.0.7-1606980023984 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-917657629-172.17.0.7-1606980023984/current
2020-12-03 07:20:30,051 [IPC Server handler 1 on default port 35507] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:30,063 [Listener at localhost/43638] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:30,063 [Listener at localhost/43638] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:30,067 [Thread-275] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/in_use.lock acquired by nodename 1479@de78f7a5f0cb
2020-12-03 07:20:30,067 [Thread-159] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=989125680;bpid=BP-917657629-172.17.0.7-1606980023984;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=989125680;c=1606980023984;bpid=BP-917657629-172.17.0.7-1606980023984;dnuuid=null
2020-12-03 07:20:30,068 [Thread-275] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 is not formatted for namespace 989125680. Formatting...
2020-12-03 07:20:30,069 [Thread-275] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-ceb133f8-e092-4bb0-bdaf-62de04a9fde9 for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 
2020-12-03 07:20:30,078 [Thread-205] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:30,078 [Thread-205] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:30,079 [Thread-205] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 and block pool id BP-917657629-172.17.0.7-1606980023984 is not formatted. Formatting ...
2020-12-03 07:20:30,079 [Thread-205] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-917657629-172.17.0.7-1606980023984 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-917657629-172.17.0.7-1606980023984/current
2020-12-03 07:20:30,137 [Thread-298] INFO  common.Storage (Storage.java:tryLock(923)) - Lock on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20/in_use.lock acquired by nodename 1479@de78f7a5f0cb
2020-12-03 07:20:30,138 [Thread-298] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20 is not formatted for namespace 989125680. Formatting...
2020-12-03 07:20:30,139 [Thread-136] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID d536f9db-cc03-4d10-befe-81c328136fc6
2020-12-03 07:20:30,139 [Thread-298] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-7f216f4d-5fbf-45d0-8c6a-456ab6675b7c for directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20 
2020-12-03 07:20:30,167 [IPC Server handler 2 on default port 35507] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:30,168 [Listener at localhost/43638] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:30,168 [Listener at localhost/43638] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:30,191 [Thread-113] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID aac3269e-0132-46b9-826f-593ec51a470c
2020-12-03 07:20:30,191 [Thread-182] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=989125680;bpid=BP-917657629-172.17.0.7-1606980023984;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=989125680;c=1606980023984;bpid=BP-917657629-172.17.0.7-1606980023984;dnuuid=null
2020-12-03 07:20:30,191 [Thread-87] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID a9577885-35e8-4740-8041-adbd3b637e00
2020-12-03 07:20:30,202 [Thread-229] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:30,202 [Thread-251] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:30,202 [Thread-229] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:30,202 [Thread-251] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:30,202 [Thread-229] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 and block pool id BP-917657629-172.17.0.7-1606980023984 is not formatted. Formatting ...
2020-12-03 07:20:30,202 [Thread-251] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 and block pool id BP-917657629-172.17.0.7-1606980023984 is not formatted. Formatting ...
2020-12-03 07:20:30,202 [Thread-229] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-917657629-172.17.0.7-1606980023984 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-917657629-172.17.0.7-1606980023984/current
2020-12-03 07:20:30,202 [Thread-251] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-917657629-172.17.0.7-1606980023984 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-917657629-172.17.0.7-1606980023984/current
2020-12-03 07:20:30,270 [IPC Server handler 4 on default port 35507] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:30,271 [Listener at localhost/43638] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:30,271 [Listener at localhost/43638] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:30,273 [Thread-136] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-a225e481-cea1-416c-80ae-569f36dd3f21
2020-12-03 07:20:30,273 [Thread-113] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-3af5a235-4bf3-49e0-9488-a4f87533e8a2
2020-12-03 07:20:30,274 [Thread-87] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-1cb0cc9b-9989-4e43-b52d-6995994c4fc1
2020-12-03 07:20:30,274 [Thread-136] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, StorageType: DISK
2020-12-03 07:20:30,275 [Thread-87] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-12-03 07:20:30,274 [Thread-113] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: DISK
2020-12-03 07:20:30,276 [Thread-136] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-2eb61706-9d88-4c82-b7f4-94ef4c91ca90
2020-12-03 07:20:30,277 [Thread-136] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, StorageType: DISK
2020-12-03 07:20:30,278 [Thread-87] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-efa2376a-10cf-46b0-adee-6d1ceaed342c
2020-12-03 07:20:30,278 [Thread-87] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-12-03 07:20:30,280 [Thread-113] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-e34a2eee-43a4-47ce-b10e-ce5fedc28869
2020-12-03 07:20:30,280 [Thread-113] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: DISK
2020-12-03 07:20:30,284 [Thread-87] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:30,284 [Thread-136] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:30,284 [Thread-113] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:30,290 [Thread-87] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:20:30,291 [Thread-113] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:20:30,292 [Thread-136] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:20:30,298 [Thread-113] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:20:30,298 [Thread-87] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:20:30,298 [Thread-136] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:20:30,300 [Thread-87] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:20:30,300 [Thread-136] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:20:30,300 [Thread-113] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:20:30,301 [Thread-136] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:20:30,301 [Thread-87] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:20:30,302 [Thread-113] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:20:30,303 [Thread-87] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:30,303 [Thread-136] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:30,303 [Thread-113] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:30,304 [Thread-318] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:20:30,304 [Thread-319] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:20:30,304 [Thread-320] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:20:30,304 [Thread-322] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:20:30,304 [Thread-321] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:20:30,304 [Thread-323] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:20:30,326 [Thread-205] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=989125680;bpid=BP-917657629-172.17.0.7-1606980023984;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=989125680;c=1606980023984;bpid=BP-917657629-172.17.0.7-1606980023984;dnuuid=null
2020-12-03 07:20:30,331 [Thread-159] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 250bafb2-f716-457e-8310-96d333f0e360
2020-12-03 07:20:30,339 [Thread-275] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:30,340 [Thread-275] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:30,340 [Thread-275] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 and block pool id BP-917657629-172.17.0.7-1606980023984 is not formatted. Formatting ...
2020-12-03 07:20:30,340 [Thread-275] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-917657629-172.17.0.7-1606980023984 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-917657629-172.17.0.7-1606980023984/current
2020-12-03 07:20:30,364 [Thread-159] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-f47ecebd-23fc-4bb6-9f5f-7463b5001b37
2020-12-03 07:20:30,365 [Thread-159] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, StorageType: DISK
2020-12-03 07:20:30,371 [Thread-159] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-9f1b799a-562e-4944-90f0-914891761857
2020-12-03 07:20:30,379 [Thread-159] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, StorageType: DISK
2020-12-03 07:20:30,380 [IPC Server handler 5 on default port 35507] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:30,380 [Thread-159] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:30,381 [Listener at localhost/43638] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:30,381 [Listener at localhost/43638] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:30,381 [Thread-159] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:20:30,382 [Thread-322] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-917657629-172.17.0.7-1606980023984 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 78ms
2020-12-03 07:20:30,383 [Thread-159] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:20:30,384 [Thread-159] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:20:30,384 [Thread-323] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-917657629-172.17.0.7-1606980023984 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 79ms
2020-12-03 07:20:30,384 [Thread-159] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:20:30,383 [Thread-320] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-917657629-172.17.0.7-1606980023984 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 79ms
2020-12-03 07:20:30,386 [Thread-159] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:30,386 [Thread-113] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-917657629-172.17.0.7-1606980023984: 83ms
2020-12-03 07:20:30,386 [Thread-319] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-917657629-172.17.0.7-1606980023984 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 82ms
2020-12-03 07:20:30,387 [Thread-332] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-12-03 07:20:30,387 [Thread-87] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-917657629-172.17.0.7-1606980023984: 83ms
2020-12-03 07:20:30,389 [Thread-318] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-917657629-172.17.0.7-1606980023984 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 85ms
2020-12-03 07:20:30,389 [Thread-333] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-12-03 07:20:30,389 [Thread-334] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-12-03 07:20:30,389 [Thread-335] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-12-03 07:20:30,389 [Thread-334] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-917657629-172.17.0.7-1606980023984/current/replicas doesn't exist 
2020-12-03 07:20:30,389 [Thread-337] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-12-03 07:20:30,389 [Thread-336] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-12-03 07:20:30,390 [Thread-337] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-917657629-172.17.0.7-1606980023984/current/replicas doesn't exist 
2020-12-03 07:20:30,390 [Thread-336] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-917657629-172.17.0.7-1606980023984/current/replicas doesn't exist 
2020-12-03 07:20:30,389 [Thread-335] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-917657629-172.17.0.7-1606980023984/current/replicas doesn't exist 
2020-12-03 07:20:30,390 [Thread-321] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-917657629-172.17.0.7-1606980023984 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 86ms
2020-12-03 07:20:30,391 [Thread-136] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-917657629-172.17.0.7-1606980023984: 88ms
2020-12-03 07:20:30,392 [Thread-338] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-12-03 07:20:30,392 [Thread-339] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-12-03 07:20:30,392 [Thread-338] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-917657629-172.17.0.7-1606980023984/current/replicas doesn't exist 
2020-12-03 07:20:30,392 [Thread-339] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-917657629-172.17.0.7-1606980023984/current/replicas doesn't exist 
2020-12-03 07:20:30,394 [Thread-337] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 4ms
2020-12-03 07:20:30,394 [Thread-336] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 4ms
2020-12-03 07:20:30,396 [Thread-335] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 6ms
2020-12-03 07:20:30,396 [Thread-334] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 7ms
2020-12-03 07:20:30,396 [Thread-338] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 3ms
2020-12-03 07:20:30,396 [Thread-113] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-917657629-172.17.0.7-1606980023984: 7ms
2020-12-03 07:20:30,397 [Thread-339] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 5ms
2020-12-03 07:20:30,397 [Thread-87] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-917657629-172.17.0.7-1606980023984: 9ms
2020-12-03 07:20:30,397 [Thread-136] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-917657629-172.17.0.7-1606980023984: 6ms
2020-12-03 07:20:30,399 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-12-03 07:20:30,400 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-12-03 07:20:30,400 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-12-03 07:20:30,400 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-12-03 07:20:30,400 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-12-03 07:20:30,401 [Thread-298] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:30,400 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-12-03 07:20:30,401 [Thread-298] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19/current/BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:30,402 [Thread-298] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19 and block pool id BP-917657629-172.17.0.7-1606980023984 is not formatted. Formatting ...
2020-12-03 07:20:30,402 [Thread-298] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-917657629-172.17.0.7-1606980023984 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19/current/BP-917657629-172.17.0.7-1606980023984/current
2020-12-03 07:20:30,402 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-a225e481-cea1-416c-80ae-569f36dd3f21): finished scanning block pool BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:30,402 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-1cb0cc9b-9989-4e43-b52d-6995994c4fc1): finished scanning block pool BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:30,402 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-3af5a235-4bf3-49e0-9488-a4f87533e8a2): finished scanning block pool BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:30,402 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-2eb61706-9d88-4c82-b7f4-94ef4c91ca90): finished scanning block pool BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:30,402 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-e34a2eee-43a4-47ce-b10e-ce5fedc28869): finished scanning block pool BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:30,402 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-efa2376a-10cf-46b0-adee-6d1ceaed342c): finished scanning block pool BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:30,426 [Thread-333] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-917657629-172.17.0.7-1606980023984 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 38ms
2020-12-03 07:20:30,428 [Thread-332] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-917657629-172.17.0.7-1606980023984 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 42ms
2020-12-03 07:20:30,428 [Thread-159] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-917657629-172.17.0.7-1606980023984: 42ms
2020-12-03 07:20:30,429 [Thread-348] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-12-03 07:20:30,429 [Thread-349] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-12-03 07:20:30,429 [Thread-348] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-917657629-172.17.0.7-1606980023984/current/replicas doesn't exist 
2020-12-03 07:20:30,430 [Thread-349] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-917657629-172.17.0.7-1606980023984/current/replicas doesn't exist 
2020-12-03 07:20:30,430 [Thread-348] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 0ms
2020-12-03 07:20:30,430 [Thread-349] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 1ms
2020-12-03 07:20:30,430 [Thread-159] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-917657629-172.17.0.7-1606980023984: 2ms
2020-12-03 07:20:30,431 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-12-03 07:20:30,431 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-12-03 07:20:30,431 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-a225e481-cea1-416c-80ae-569f36dd3f21): no suitable block pools found to scan.  Waiting 1814399968 ms.
2020-12-03 07:20:30,431 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-2eb61706-9d88-4c82-b7f4-94ef4c91ca90): no suitable block pools found to scan.  Waiting 1814399968 ms.
2020-12-03 07:20:30,431 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-e34a2eee-43a4-47ce-b10e-ce5fedc28869): no suitable block pools found to scan.  Waiting 1814399969 ms.
2020-12-03 07:20:30,431 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-f47ecebd-23fc-4bb6-9f5f-7463b5001b37): finished scanning block pool BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:30,431 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-9f1b799a-562e-4944-90f0-914891761857): finished scanning block pool BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:30,431 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-efa2376a-10cf-46b0-adee-6d1ceaed342c): no suitable block pools found to scan.  Waiting 1814399969 ms.
2020-12-03 07:20:30,431 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-1cb0cc9b-9989-4e43-b52d-6995994c4fc1): no suitable block pools found to scan.  Waiting 1814399968 ms.
2020-12-03 07:20:30,431 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-3af5a235-4bf3-49e0-9488-a4f87533e8a2): no suitable block pools found to scan.  Waiting 1814399968 ms.
2020-12-03 07:20:30,432 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-f47ecebd-23fc-4bb6-9f5f-7463b5001b37): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:20:30,432 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-9f1b799a-562e-4944-90f0-914891761857): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:20:30,433 [Thread-136] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:08 AM with interval of 21600000ms
2020-12-03 07:20:30,433 [Thread-87] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:13 AM with interval of 21600000ms
2020-12-03 07:20:30,433 [Thread-113] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:20 AM with interval of 21600000ms
2020-12-03 07:20:30,433 [Thread-159] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:09 AM with interval of 21600000ms
2020-12-03 07:20:30,441 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid d536f9db-cc03-4d10-befe-81c328136fc6) service to localhost/127.0.0.1:40176 beginning handshake with NN
2020-12-03 07:20:30,441 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid a9577885-35e8-4740-8041-adbd3b637e00) service to localhost/127.0.0.1:35507 beginning handshake with NN
2020-12-03 07:20:30,441 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid aac3269e-0132-46b9-826f-593ec51a470c) service to localhost/127.0.0.1:35507 beginning handshake with NN
2020-12-03 07:20:30,441 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid 250bafb2-f716-457e-8310-96d333f0e360) service to localhost/127.0.0.1:40176 beginning handshake with NN
2020-12-03 07:20:30,441 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid a9577885-35e8-4740-8041-adbd3b637e00) service to localhost/127.0.0.1:40176 beginning handshake with NN
2020-12-03 07:20:30,441 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid 250bafb2-f716-457e-8310-96d333f0e360) service to localhost/127.0.0.1:35507 beginning handshake with NN
2020-12-03 07:20:30,441 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid d536f9db-cc03-4d10-befe-81c328136fc6) service to localhost/127.0.0.1:35507 beginning handshake with NN
2020-12-03 07:20:30,441 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid aac3269e-0132-46b9-826f-593ec51a470c) service to localhost/127.0.0.1:40176 beginning handshake with NN
2020-12-03 07:20:30,444 [Thread-182] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 4ea78e77-6418-4b63-8f69-9cb494a0609e
2020-12-03 07:20:30,444 [Thread-229] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=989125680;bpid=BP-917657629-172.17.0.7-1606980023984;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=989125680;c=1606980023984;bpid=BP-917657629-172.17.0.7-1606980023984;dnuuid=null
2020-12-03 07:20:30,447 [Thread-182] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-c7bc2dbc-457f-4ca9-86cc-267ab86263f8
2020-12-03 07:20:30,447 [Thread-182] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, StorageType: DISK
2020-12-03 07:20:30,454 [Thread-182] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-5ccec8a5-859f-4fa7-857a-b7c956cf3535
2020-12-03 07:20:30,454 [Thread-182] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, StorageType: DISK
2020-12-03 07:20:30,455 [Thread-182] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:30,457 [IPC Server handler 6 on default port 35507] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34066, datanodeUuid=a9577885-35e8-4740-8041-adbd3b637e00, infoPort=40284, infoSecurePort=0, ipcPort=43592, storageInfo=lv=-57;cid=testClusterID;nsid=989125680;c=1606980023984) storage a9577885-35e8-4740-8041-adbd3b637e00
2020-12-03 07:20:30,457 [IPC Server handler 0 on default port 40176] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34525, datanodeUuid=250bafb2-f716-457e-8310-96d333f0e360, infoPort=45210, infoSecurePort=0, ipcPort=45065, storageInfo=lv=-57;cid=testClusterID;nsid=989125680;c=1606980023984) storage 250bafb2-f716-457e-8310-96d333f0e360
2020-12-03 07:20:30,458 [Thread-182] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:20:30,459 [Thread-182] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:20:30,459 [Thread-182] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:20:30,459 [Thread-182] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:20:30,459 [Thread-182] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:30,460 [Thread-358] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-12-03 07:20:30,460 [IPC Server handler 6 on default port 35507] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:34066
2020-12-03 07:20:30,460 [Thread-359] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-12-03 07:20:30,460 [IPC Server handler 0 on default port 40176] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:34525
2020-12-03 07:20:30,460 [IPC Server handler 0 on default port 40176] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 250bafb2-f716-457e-8310-96d333f0e360 (127.0.0.1:34525).
2020-12-03 07:20:30,460 [IPC Server handler 6 on default port 35507] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN a9577885-35e8-4740-8041-adbd3b637e00 (127.0.0.1:34066).
2020-12-03 07:20:30,463 [Thread-251] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:30,463 [Thread-251] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:30,464 [Thread-251] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 and block pool id BP-917657629-172.17.0.7-1606980023984 is not formatted. Formatting ...
2020-12-03 07:20:30,464 [Thread-251] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-917657629-172.17.0.7-1606980023984 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-917657629-172.17.0.7-1606980023984/current
2020-12-03 07:20:30,465 [IPC Server handler 7 on default port 35507] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34525, datanodeUuid=250bafb2-f716-457e-8310-96d333f0e360, infoPort=45210, infoSecurePort=0, ipcPort=45065, storageInfo=lv=-57;cid=testClusterID;nsid=989125680;c=1606980023984) storage 250bafb2-f716-457e-8310-96d333f0e360
2020-12-03 07:20:30,465 [IPC Server handler 7 on default port 35507] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:34525
2020-12-03 07:20:30,466 [IPC Server handler 7 on default port 35507] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 250bafb2-f716-457e-8310-96d333f0e360 (127.0.0.1:34525).
2020-12-03 07:20:30,466 [IPC Server handler 1 on default port 40176] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35105, datanodeUuid=aac3269e-0132-46b9-826f-593ec51a470c, infoPort=43631, infoSecurePort=0, ipcPort=41061, storageInfo=lv=-57;cid=testClusterID;nsid=989125680;c=1606980023984) storage aac3269e-0132-46b9-826f-593ec51a470c
2020-12-03 07:20:30,467 [IPC Server handler 8 on default port 35507] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35105, datanodeUuid=aac3269e-0132-46b9-826f-593ec51a470c, infoPort=43631, infoSecurePort=0, ipcPort=41061, storageInfo=lv=-57;cid=testClusterID;nsid=989125680;c=1606980023984) storage aac3269e-0132-46b9-826f-593ec51a470c
2020-12-03 07:20:30,467 [IPC Server handler 1 on default port 40176] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:35105
2020-12-03 07:20:30,467 [IPC Server handler 8 on default port 35507] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:35105
2020-12-03 07:20:30,468 [IPC Server handler 8 on default port 35507] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN aac3269e-0132-46b9-826f-593ec51a470c (127.0.0.1:35105).
2020-12-03 07:20:30,468 [IPC Server handler 1 on default port 40176] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN aac3269e-0132-46b9-826f-593ec51a470c (127.0.0.1:35105).
2020-12-03 07:20:30,468 [IPC Server handler 9 on default port 35507] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:40799, datanodeUuid=d536f9db-cc03-4d10-befe-81c328136fc6, infoPort=40487, infoSecurePort=0, ipcPort=35855, storageInfo=lv=-57;cid=testClusterID;nsid=989125680;c=1606980023984) storage d536f9db-cc03-4d10-befe-81c328136fc6
2020-12-03 07:20:30,468 [IPC Server handler 9 on default port 40176] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34066, datanodeUuid=a9577885-35e8-4740-8041-adbd3b637e00, infoPort=40284, infoSecurePort=0, ipcPort=43592, storageInfo=lv=-57;cid=testClusterID;nsid=989125680;c=1606980023984) storage a9577885-35e8-4740-8041-adbd3b637e00
2020-12-03 07:20:30,468 [IPC Server handler 9 on default port 35507] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:40799
2020-12-03 07:20:30,468 [IPC Server handler 9 on default port 40176] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:34066
2020-12-03 07:20:30,468 [IPC Server handler 9 on default port 35507] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN d536f9db-cc03-4d10-befe-81c328136fc6 (127.0.0.1:40799).
2020-12-03 07:20:30,469 [IPC Server handler 9 on default port 40176] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN a9577885-35e8-4740-8041-adbd3b637e00 (127.0.0.1:34066).
2020-12-03 07:20:30,469 [IPC Server handler 2 on default port 40176] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:40799, datanodeUuid=d536f9db-cc03-4d10-befe-81c328136fc6, infoPort=40487, infoSecurePort=0, ipcPort=35855, storageInfo=lv=-57;cid=testClusterID;nsid=989125680;c=1606980023984) storage d536f9db-cc03-4d10-befe-81c328136fc6
2020-12-03 07:20:30,469 [IPC Server handler 2 on default port 40176] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:40799
2020-12-03 07:20:30,470 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid aac3269e-0132-46b9-826f-593ec51a470c) service to localhost/127.0.0.1:40176 successfully registered with NN
2020-12-03 07:20:30,470 [IPC Server handler 2 on default port 40176] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN d536f9db-cc03-4d10-befe-81c328136fc6 (127.0.0.1:40799).
2020-12-03 07:20:30,470 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid aac3269e-0132-46b9-826f-593ec51a470c) service to localhost/127.0.0.1:35507 successfully registered with NN
2020-12-03 07:20:30,470 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid a9577885-35e8-4740-8041-adbd3b637e00) service to localhost/127.0.0.1:35507 successfully registered with NN
2020-12-03 07:20:30,470 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid d536f9db-cc03-4d10-befe-81c328136fc6) service to localhost/127.0.0.1:35507 successfully registered with NN
2020-12-03 07:20:30,470 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid 250bafb2-f716-457e-8310-96d333f0e360) service to localhost/127.0.0.1:40176 successfully registered with NN
2020-12-03 07:20:30,470 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:35507 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:30,470 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:35507 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:30,470 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:35507 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:30,470 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid a9577885-35e8-4740-8041-adbd3b637e00) service to localhost/127.0.0.1:40176 successfully registered with NN
2020-12-03 07:20:30,470 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid 250bafb2-f716-457e-8310-96d333f0e360) service to localhost/127.0.0.1:35507 successfully registered with NN
2020-12-03 07:20:30,470 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:40176 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:30,471 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:35507 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:30,471 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid d536f9db-cc03-4d10-befe-81c328136fc6) service to localhost/127.0.0.1:40176 successfully registered with NN
2020-12-03 07:20:30,471 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:40176 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:30,470 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:40176 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:30,471 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:40176 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:30,502 [IPC Server handler 0 on default port 35507] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:30,509 [Listener at localhost/43638] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:30,510 [Listener at localhost/43638] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:30,510 [Thread-359] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-917657629-172.17.0.7-1606980023984 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 50ms
2020-12-03 07:20:30,512 [Thread-358] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-917657629-172.17.0.7-1606980023984 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 52ms
2020-12-03 07:20:30,513 [Thread-182] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-917657629-172.17.0.7-1606980023984: 54ms
2020-12-03 07:20:30,528 [IPC Server handler 1 on default port 35507] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-3af5a235-4bf3-49e0-9488-a4f87533e8a2 for DN 127.0.0.1:35105
2020-12-03 07:20:30,530 [IPC Server handler 1 on default port 35507] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-e34a2eee-43a4-47ce-b10e-ce5fedc28869 for DN 127.0.0.1:35105
2020-12-03 07:20:30,535 [IPC Server handler 2 on default port 35507] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-1cb0cc9b-9989-4e43-b52d-6995994c4fc1 for DN 127.0.0.1:34066
2020-12-03 07:20:30,537 [Thread-363] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-12-03 07:20:30,539 [IPC Server handler 2 on default port 35507] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-efa2376a-10cf-46b0-adee-6d1ceaed342c for DN 127.0.0.1:34066
2020-12-03 07:20:30,547 [IPC Server handler 4 on default port 35507] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-a225e481-cea1-416c-80ae-569f36dd3f21 for DN 127.0.0.1:40799
2020-12-03 07:20:30,547 [IPC Server handler 4 on default port 35507] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-2eb61706-9d88-4c82-b7f4-94ef4c91ca90 for DN 127.0.0.1:40799
2020-12-03 07:20:30,538 [Thread-362] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-12-03 07:20:30,548 [Thread-362] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-917657629-172.17.0.7-1606980023984/current/replicas doesn't exist 
2020-12-03 07:20:30,549 [Thread-362] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 0ms
2020-12-03 07:20:30,546 [Thread-363] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-917657629-172.17.0.7-1606980023984/current/replicas doesn't exist 
2020-12-03 07:20:30,551 [IPC Server handler 3 on default port 40176] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-1cb0cc9b-9989-4e43-b52d-6995994c4fc1 for DN 127.0.0.1:34066
2020-12-03 07:20:30,552 [IPC Server handler 3 on default port 40176] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-efa2376a-10cf-46b0-adee-6d1ceaed342c for DN 127.0.0.1:34066
2020-12-03 07:20:30,551 [Thread-205] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID a5cf5fbb-7d73-4dc3-b054-00e46e141155
2020-12-03 07:20:30,552 [IPC Server handler 3 on default port 35507] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-f47ecebd-23fc-4bb6-9f5f-7463b5001b37 for DN 127.0.0.1:34525
2020-12-03 07:20:30,552 [IPC Server handler 3 on default port 35507] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-9f1b799a-562e-4944-90f0-914891761857 for DN 127.0.0.1:34525
2020-12-03 07:20:30,552 [Thread-363] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 5ms
2020-12-03 07:20:30,553 [Thread-182] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-917657629-172.17.0.7-1606980023984: 40ms
2020-12-03 07:20:30,563 [IPC Server handler 4 on default port 40176] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-a225e481-cea1-416c-80ae-569f36dd3f21 for DN 127.0.0.1:40799
2020-12-03 07:20:30,565 [IPC Server handler 4 on default port 40176] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-2eb61706-9d88-4c82-b7f4-94ef4c91ca90 for DN 127.0.0.1:40799
2020-12-03 07:20:30,565 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-12-03 07:20:30,566 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-12-03 07:20:30,566 [IPC Server handler 5 on default port 40176] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-f47ecebd-23fc-4bb6-9f5f-7463b5001b37 for DN 127.0.0.1:34525
2020-12-03 07:20:30,567 [Thread-182] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 10:36 AM with interval of 21600000ms
2020-12-03 07:20:30,567 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-c7bc2dbc-457f-4ca9-86cc-267ab86263f8): finished scanning block pool BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:30,567 [IPC Server handler 5 on default port 40176] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-9f1b799a-562e-4944-90f0-914891761857 for DN 127.0.0.1:34525
2020-12-03 07:20:30,567 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-5ccec8a5-859f-4fa7-857a-b7c956cf3535): finished scanning block pool BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:30,568 [IPC Server handler 6 on default port 40176] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-3af5a235-4bf3-49e0-9488-a4f87533e8a2 for DN 127.0.0.1:35105
2020-12-03 07:20:30,570 [IPC Server handler 6 on default port 40176] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-e34a2eee-43a4-47ce-b10e-ce5fedc28869 for DN 127.0.0.1:35105
2020-12-03 07:20:30,570 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid 4ea78e77-6418-4b63-8f69-9cb494a0609e) service to localhost/127.0.0.1:40176 beginning handshake with NN
2020-12-03 07:20:30,570 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid 4ea78e77-6418-4b63-8f69-9cb494a0609e) service to localhost/127.0.0.1:35507 beginning handshake with NN
2020-12-03 07:20:30,571 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-c7bc2dbc-457f-4ca9-86cc-267ab86263f8): no suitable block pools found to scan.  Waiting 1814399994 ms.
2020-12-03 07:20:30,578 [IPC Server handler 7 on default port 40176] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:38706, datanodeUuid=4ea78e77-6418-4b63-8f69-9cb494a0609e, infoPort=40710, infoSecurePort=0, ipcPort=38901, storageInfo=lv=-57;cid=testClusterID;nsid=989125680;c=1606980023984) storage 4ea78e77-6418-4b63-8f69-9cb494a0609e
2020-12-03 07:20:30,579 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-5ccec8a5-859f-4fa7-857a-b7c956cf3535): no suitable block pools found to scan.  Waiting 1814399984 ms.
2020-12-03 07:20:30,579 [IPC Server handler 7 on default port 40176] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38706
2020-12-03 07:20:30,579 [IPC Server handler 7 on default port 40176] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 4ea78e77-6418-4b63-8f69-9cb494a0609e (127.0.0.1:38706).
2020-12-03 07:20:30,579 [IPC Server handler 5 on default port 35507] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:38706, datanodeUuid=4ea78e77-6418-4b63-8f69-9cb494a0609e, infoPort=40710, infoSecurePort=0, ipcPort=38901, storageInfo=lv=-57;cid=testClusterID;nsid=989125680;c=1606980023984) storage 4ea78e77-6418-4b63-8f69-9cb494a0609e
2020-12-03 07:20:30,580 [IPC Server handler 5 on default port 35507] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38706
2020-12-03 07:20:30,580 [IPC Server handler 5 on default port 35507] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 4ea78e77-6418-4b63-8f69-9cb494a0609e (127.0.0.1:38706).
2020-12-03 07:20:30,581 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid 4ea78e77-6418-4b63-8f69-9cb494a0609e) service to localhost/127.0.0.1:40176 successfully registered with NN
2020-12-03 07:20:30,581 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:40176 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:30,582 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid 4ea78e77-6418-4b63-8f69-9cb494a0609e) service to localhost/127.0.0.1:35507 successfully registered with NN
2020-12-03 07:20:30,582 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:35507 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:30,586 [Thread-205] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-6ed681d4-7b32-434e-9b37-4319562525f7
2020-12-03 07:20:30,586 [Thread-205] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, StorageType: DISK
2020-12-03 07:20:30,587 [Thread-275] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:30,588 [Thread-275] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:30,588 [Thread-275] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 and block pool id BP-917657629-172.17.0.7-1606980023984 is not formatted. Formatting ...
2020-12-03 07:20:30,588 [Thread-275] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-917657629-172.17.0.7-1606980023984 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-917657629-172.17.0.7-1606980023984/current
2020-12-03 07:20:30,589 [Thread-205] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-3df7a241-42d4-46b6-9ce4-8b28b0d79357
2020-12-03 07:20:30,595 [Thread-205] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, StorageType: DISK
2020-12-03 07:20:30,612 [Thread-298] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:30,613 [Thread-298] INFO  common.Storage (Storage.java:lock(882)) - Locking is disabled for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20/current/BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:30,613 [Thread-298] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20 and block pool id BP-917657629-172.17.0.7-1606980023984 is not formatted. Formatting ...
2020-12-03 07:20:30,613 [Thread-298] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-917657629-172.17.0.7-1606980023984 directory /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20/current/BP-917657629-172.17.0.7-1606980023984/current
2020-12-03 07:20:30,615 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x7daa90b499a93ab1: Processing first storage report for DS-f47ecebd-23fc-4bb6-9f5f-7463b5001b37 from datanode 250bafb2-f716-457e-8310-96d333f0e360
2020-12-03 07:20:30,617 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x7daa90b499a93ab1: from storage DS-f47ecebd-23fc-4bb6-9f5f-7463b5001b37 node DatanodeRegistration(127.0.0.1:34525, datanodeUuid=250bafb2-f716-457e-8310-96d333f0e360, infoPort=45210, infoSecurePort=0, ipcPort=45065, storageInfo=lv=-57;cid=testClusterID;nsid=989125680;c=1606980023984), blocks: 0, hasStaleStorage: true, processing time: 2 msecs, invalidatedBlocks: 0
2020-12-03 07:20:30,619 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x23ea98da11f68e2a: Processing first storage report for DS-1cb0cc9b-9989-4e43-b52d-6995994c4fc1 from datanode a9577885-35e8-4740-8041-adbd3b637e00
2020-12-03 07:20:30,620 [IPC Server handler 7 on default port 35507] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:30,620 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x23ea98da11f68e2a: from storage DS-1cb0cc9b-9989-4e43-b52d-6995994c4fc1 node DatanodeRegistration(127.0.0.1:34066, datanodeUuid=a9577885-35e8-4740-8041-adbd3b637e00, infoPort=40284, infoSecurePort=0, ipcPort=43592, storageInfo=lv=-57;cid=testClusterID;nsid=989125680;c=1606980023984), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:30,620 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x7daa90b499a93ab1: Processing first storage report for DS-9f1b799a-562e-4944-90f0-914891761857 from datanode 250bafb2-f716-457e-8310-96d333f0e360
2020-12-03 07:20:30,620 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x7daa90b499a93ab1: from storage DS-9f1b799a-562e-4944-90f0-914891761857 node DatanodeRegistration(127.0.0.1:34525, datanodeUuid=250bafb2-f716-457e-8310-96d333f0e360, infoPort=45210, infoSecurePort=0, ipcPort=45065, storageInfo=lv=-57;cid=testClusterID;nsid=989125680;c=1606980023984), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:30,620 [Thread-205] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:30,621 [Listener at localhost/43638] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:30,621 [Listener at localhost/43638] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:30,622 [Thread-205] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:20:30,620 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xb0d70f035b38e5a3: Processing first storage report for DS-e34a2eee-43a4-47ce-b10e-ce5fedc28869 from datanode aac3269e-0132-46b9-826f-593ec51a470c
2020-12-03 07:20:30,623 [IPC Server handler 8 on default port 35507] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c7bc2dbc-457f-4ca9-86cc-267ab86263f8 for DN 127.0.0.1:38706
2020-12-03 07:20:30,623 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xb0d70f035b38e5a3: from storage DS-e34a2eee-43a4-47ce-b10e-ce5fedc28869 node DatanodeRegistration(127.0.0.1:35105, datanodeUuid=aac3269e-0132-46b9-826f-593ec51a470c, infoPort=43631, infoSecurePort=0, ipcPort=41061, storageInfo=lv=-57;cid=testClusterID;nsid=989125680;c=1606980023984), blocks: 0, hasStaleStorage: true, processing time: 2 msecs, invalidatedBlocks: 0
2020-12-03 07:20:30,623 [IPC Server handler 8 on default port 35507] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-5ccec8a5-859f-4fa7-857a-b7c956cf3535 for DN 127.0.0.1:38706
2020-12-03 07:20:30,623 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x10d92eafc6197f72: Processing first storage report for DS-a225e481-cea1-416c-80ae-569f36dd3f21 from datanode d536f9db-cc03-4d10-befe-81c328136fc6
2020-12-03 07:20:30,624 [Thread-205] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:20:30,624 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x5ffc3f5dcfa35de0: Processing first storage report for DS-1cb0cc9b-9989-4e43-b52d-6995994c4fc1 from datanode a9577885-35e8-4740-8041-adbd3b637e00
2020-12-03 07:20:30,624 [Thread-205] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:20:30,624 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x10d92eafc6197f72: from storage DS-a225e481-cea1-416c-80ae-569f36dd3f21 node DatanodeRegistration(127.0.0.1:40799, datanodeUuid=d536f9db-cc03-4d10-befe-81c328136fc6, infoPort=40487, infoSecurePort=0, ipcPort=35855, storageInfo=lv=-57;cid=testClusterID;nsid=989125680;c=1606980023984), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:30,627 [Thread-205] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:20:30,626 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x5ffc3f5dcfa35de0: from storage DS-1cb0cc9b-9989-4e43-b52d-6995994c4fc1 node DatanodeRegistration(127.0.0.1:34066, datanodeUuid=a9577885-35e8-4740-8041-adbd3b637e00, infoPort=40284, infoSecurePort=0, ipcPort=43592, storageInfo=lv=-57;cid=testClusterID;nsid=989125680;c=1606980023984), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:30,628 [Thread-205] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:30,629 [IPC Server handler 2 on default port 40176] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c7bc2dbc-457f-4ca9-86cc-267ab86263f8 for DN 127.0.0.1:38706
2020-12-03 07:20:30,629 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xa2d43ec7a1484be4: Processing first storage report for DS-e34a2eee-43a4-47ce-b10e-ce5fedc28869 from datanode aac3269e-0132-46b9-826f-593ec51a470c
2020-12-03 07:20:30,629 [IPC Server handler 2 on default port 40176] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-5ccec8a5-859f-4fa7-857a-b7c956cf3535 for DN 127.0.0.1:38706
2020-12-03 07:20:30,629 [Thread-369] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11...
2020-12-03 07:20:30,629 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xa2d43ec7a1484be4: from storage DS-e34a2eee-43a4-47ce-b10e-ce5fedc28869 node DatanodeRegistration(127.0.0.1:35105, datanodeUuid=aac3269e-0132-46b9-826f-593ec51a470c, infoPort=43631, infoSecurePort=0, ipcPort=41061, storageInfo=lv=-57;cid=testClusterID;nsid=989125680;c=1606980023984), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:30,630 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x23ea98da11f68e2a: Processing first storage report for DS-efa2376a-10cf-46b0-adee-6d1ceaed342c from datanode a9577885-35e8-4740-8041-adbd3b637e00
2020-12-03 07:20:30,630 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x7cf4d9172de35847: Processing first storage report for DS-f47ecebd-23fc-4bb6-9f5f-7463b5001b37 from datanode 250bafb2-f716-457e-8310-96d333f0e360
2020-12-03 07:20:30,630 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x7cf4d9172de35847: from storage DS-f47ecebd-23fc-4bb6-9f5f-7463b5001b37 node DatanodeRegistration(127.0.0.1:34525, datanodeUuid=250bafb2-f716-457e-8310-96d333f0e360, infoPort=45210, infoSecurePort=0, ipcPort=45065, storageInfo=lv=-57;cid=testClusterID;nsid=989125680;c=1606980023984), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:20:30,630 [Thread-370] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12...
2020-12-03 07:20:30,630 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x23ea98da11f68e2a: from storage DS-efa2376a-10cf-46b0-adee-6d1ceaed342c node DatanodeRegistration(127.0.0.1:34066, datanodeUuid=a9577885-35e8-4740-8041-adbd3b637e00, infoPort=40284, infoSecurePort=0, ipcPort=43592, storageInfo=lv=-57;cid=testClusterID;nsid=989125680;c=1606980023984), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:20:30,631 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xb0d70f035b38e5a3: Processing first storage report for DS-3af5a235-4bf3-49e0-9488-a4f87533e8a2 from datanode aac3269e-0132-46b9-826f-593ec51a470c
2020-12-03 07:20:30,632 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xb0d70f035b38e5a3: from storage DS-3af5a235-4bf3-49e0-9488-a4f87533e8a2 node DatanodeRegistration(127.0.0.1:35105, datanodeUuid=aac3269e-0132-46b9-826f-593ec51a470c, infoPort=43631, infoSecurePort=0, ipcPort=41061, storageInfo=lv=-57;cid=testClusterID;nsid=989125680;c=1606980023984), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:30,632 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x10d92eafc6197f72: Processing first storage report for DS-2eb61706-9d88-4c82-b7f4-94ef4c91ca90 from datanode d536f9db-cc03-4d10-befe-81c328136fc6
2020-12-03 07:20:30,632 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x10d92eafc6197f72: from storage DS-2eb61706-9d88-4c82-b7f4-94ef4c91ca90 node DatanodeRegistration(127.0.0.1:40799, datanodeUuid=d536f9db-cc03-4d10-befe-81c328136fc6, infoPort=40487, infoSecurePort=0, ipcPort=35855, storageInfo=lv=-57;cid=testClusterID;nsid=989125680;c=1606980023984), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:30,633 [Thread-229] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID 89347142-edad-4d29-b15f-e4c40718e489
2020-12-03 07:20:30,634 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xb10b51352d39064: Processing first storage report for DS-a225e481-cea1-416c-80ae-569f36dd3f21 from datanode d536f9db-cc03-4d10-befe-81c328136fc6
2020-12-03 07:20:30,634 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xb10b51352d39064: from storage DS-a225e481-cea1-416c-80ae-569f36dd3f21 node DatanodeRegistration(127.0.0.1:40799, datanodeUuid=d536f9db-cc03-4d10-befe-81c328136fc6, infoPort=40487, infoSecurePort=0, ipcPort=35855, storageInfo=lv=-57;cid=testClusterID;nsid=989125680;c=1606980023984), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:30,634 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x5ffc3f5dcfa35de0: Processing first storage report for DS-efa2376a-10cf-46b0-adee-6d1ceaed342c from datanode a9577885-35e8-4740-8041-adbd3b637e00
2020-12-03 07:20:30,634 [Thread-251] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=989125680;bpid=BP-917657629-172.17.0.7-1606980023984;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=989125680;c=1606980023984;bpid=BP-917657629-172.17.0.7-1606980023984;dnuuid=null
2020-12-03 07:20:30,634 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x5ffc3f5dcfa35de0: from storage DS-efa2376a-10cf-46b0-adee-6d1ceaed342c node DatanodeRegistration(127.0.0.1:34066, datanodeUuid=a9577885-35e8-4740-8041-adbd3b637e00, infoPort=40284, infoSecurePort=0, ipcPort=43592, storageInfo=lv=-57;cid=testClusterID;nsid=989125680;c=1606980023984), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:30,634 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x9139616582c5c405: Processing first storage report for DS-c7bc2dbc-457f-4ca9-86cc-267ab86263f8 from datanode 4ea78e77-6418-4b63-8f69-9cb494a0609e
2020-12-03 07:20:30,635 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x9139616582c5c405: from storage DS-c7bc2dbc-457f-4ca9-86cc-267ab86263f8 node DatanodeRegistration(127.0.0.1:38706, datanodeUuid=4ea78e77-6418-4b63-8f69-9cb494a0609e, infoPort=40710, infoSecurePort=0, ipcPort=38901, storageInfo=lv=-57;cid=testClusterID;nsid=989125680;c=1606980023984), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:30,635 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xa2d43ec7a1484be4: Processing first storage report for DS-3af5a235-4bf3-49e0-9488-a4f87533e8a2 from datanode aac3269e-0132-46b9-826f-593ec51a470c
2020-12-03 07:20:30,635 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xa2d43ec7a1484be4: from storage DS-3af5a235-4bf3-49e0-9488-a4f87533e8a2 node DatanodeRegistration(127.0.0.1:35105, datanodeUuid=aac3269e-0132-46b9-826f-593ec51a470c, infoPort=43631, infoSecurePort=0, ipcPort=41061, storageInfo=lv=-57;cid=testClusterID;nsid=989125680;c=1606980023984), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:30,635 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xb10b51352d39064: Processing first storage report for DS-2eb61706-9d88-4c82-b7f4-94ef4c91ca90 from datanode d536f9db-cc03-4d10-befe-81c328136fc6
2020-12-03 07:20:30,635 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xb10b51352d39064: from storage DS-2eb61706-9d88-4c82-b7f4-94ef4c91ca90 node DatanodeRegistration(127.0.0.1:40799, datanodeUuid=d536f9db-cc03-4d10-befe-81c328136fc6, infoPort=40487, infoSecurePort=0, ipcPort=35855, storageInfo=lv=-57;cid=testClusterID;nsid=989125680;c=1606980023984), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:30,635 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x7cf4d9172de35847: Processing first storage report for DS-9f1b799a-562e-4944-90f0-914891761857 from datanode 250bafb2-f716-457e-8310-96d333f0e360
2020-12-03 07:20:30,635 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xdbab038abebfc500: Processing first storage report for DS-c7bc2dbc-457f-4ca9-86cc-267ab86263f8 from datanode 4ea78e77-6418-4b63-8f69-9cb494a0609e
2020-12-03 07:20:30,636 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x7cf4d9172de35847: from storage DS-9f1b799a-562e-4944-90f0-914891761857 node DatanodeRegistration(127.0.0.1:34525, datanodeUuid=250bafb2-f716-457e-8310-96d333f0e360, infoPort=45210, infoSecurePort=0, ipcPort=45065, storageInfo=lv=-57;cid=testClusterID;nsid=989125680;c=1606980023984), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:30,636 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xdbab038abebfc500: from storage DS-c7bc2dbc-457f-4ca9-86cc-267ab86263f8 node DatanodeRegistration(127.0.0.1:38706, datanodeUuid=4ea78e77-6418-4b63-8f69-9cb494a0609e, infoPort=40710, infoSecurePort=0, ipcPort=38901, storageInfo=lv=-57;cid=testClusterID;nsid=989125680;c=1606980023984), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:30,636 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x9139616582c5c405: Processing first storage report for DS-5ccec8a5-859f-4fa7-857a-b7c956cf3535 from datanode 4ea78e77-6418-4b63-8f69-9cb494a0609e
2020-12-03 07:20:30,636 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xdbab038abebfc500: Processing first storage report for DS-5ccec8a5-859f-4fa7-857a-b7c956cf3535 from datanode 4ea78e77-6418-4b63-8f69-9cb494a0609e
2020-12-03 07:20:30,636 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x9139616582c5c405: from storage DS-5ccec8a5-859f-4fa7-857a-b7c956cf3535 node DatanodeRegistration(127.0.0.1:38706, datanodeUuid=4ea78e77-6418-4b63-8f69-9cb494a0609e, infoPort=40710, infoSecurePort=0, ipcPort=38901, storageInfo=lv=-57;cid=testClusterID;nsid=989125680;c=1606980023984), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:20:30,636 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xdbab038abebfc500: from storage DS-5ccec8a5-859f-4fa7-857a-b7c956cf3535 node DatanodeRegistration(127.0.0.1:38706, datanodeUuid=4ea78e77-6418-4b63-8f69-9cb494a0609e, infoPort=40710, infoSecurePort=0, ipcPort=38901, storageInfo=lv=-57;cid=testClusterID;nsid=989125680;c=1606980023984), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:30,637 [Thread-229] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-f4bfacf8-7145-4886-a5f1-fd5fa3f79dee
2020-12-03 07:20:30,645 [Thread-229] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, StorageType: DISK
2020-12-03 07:20:30,647 [Thread-229] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-9024d8af-e369-46b9-b368-4cf2f932788f
2020-12-03 07:20:30,647 [Thread-229] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, StorageType: DISK
2020-12-03 07:20:30,649 [Thread-229] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:30,652 [Thread-229] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:20:30,653 [Thread-229] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:20:30,653 [Thread-229] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:20:30,653 [Thread-229] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:20:30,654 [Thread-229] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:30,654 [Thread-375] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13...
2020-12-03 07:20:30,655 [Thread-376] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14...
2020-12-03 07:20:30,667 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x10d92eafc6197f72,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 6 msec to generate and 81 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:20:30,667 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xa2d43ec7a1484be4,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 8 msec to generate and 80 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:20:30,667 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x5ffc3f5dcfa35de0,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 6 msec to generate and 82 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:20:30,667 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x7cf4d9172de35847,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 6 msec to generate and 81 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:20:30,667 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xb10b51352d39064,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 6 msec to generate and 81 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:20:30,667 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x23ea98da11f68e2a,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 6 msec to generate and 81 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:20:30,667 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xdbab038abebfc500,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 34 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:20:30,667 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xb0d70f035b38e5a3,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 5 msec to generate and 82 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:20:30,669 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x9139616582c5c405,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 39 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:20:30,667 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x7daa90b499a93ab1,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 6 msec to generate and 81 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:20:30,690 [Thread-370] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-917657629-172.17.0.7-1606980023984 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12: 59ms
2020-12-03 07:20:30,705 [Thread-369] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-917657629-172.17.0.7-1606980023984 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11: 75ms
2020-12-03 07:20:30,723 [Thread-205] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-917657629-172.17.0.7-1606980023984: 94ms
2020-12-03 07:20:30,724 [IPC Server handler 4 on default port 35507] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:30,725 [Thread-379] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11...
2020-12-03 07:20:30,725 [Thread-379] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-917657629-172.17.0.7-1606980023984/current/replicas doesn't exist 
2020-12-03 07:20:30,726 [Thread-379] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11: 0ms
2020-12-03 07:20:30,726 [Thread-380] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12...
2020-12-03 07:20:30,727 [Thread-380] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-917657629-172.17.0.7-1606980023984/current/replicas doesn't exist 
2020-12-03 07:20:30,727 [Thread-380] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12: 1ms
2020-12-03 07:20:30,727 [Thread-205] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-917657629-172.17.0.7-1606980023984: 3ms
2020-12-03 07:20:30,728 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-12-03 07:20:30,728 [Listener at localhost/43638] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:30,728 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-3df7a241-42d4-46b6-9ce4-8b28b0d79357): finished scanning block pool BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:30,729 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-3df7a241-42d4-46b6-9ce4-8b28b0d79357): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:20:30,728 [Listener at localhost/43638] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:30,730 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-12-03 07:20:30,730 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-6ed681d4-7b32-434e-9b37-4319562525f7): finished scanning block pool BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:30,731 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-6ed681d4-7b32-434e-9b37-4319562525f7): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:20:30,730 [Thread-205] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:40 AM with interval of 21600000ms
2020-12-03 07:20:30,738 [Thread-376] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-917657629-172.17.0.7-1606980023984 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14: 84ms
2020-12-03 07:20:30,747 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid a5cf5fbb-7d73-4dc3-b054-00e46e141155) service to localhost/127.0.0.1:40176 beginning handshake with NN
2020-12-03 07:20:30,748 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid a5cf5fbb-7d73-4dc3-b054-00e46e141155) service to localhost/127.0.0.1:35507 beginning handshake with NN
2020-12-03 07:20:30,749 [IPC Server handler 5 on default port 40176] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:40778, datanodeUuid=a5cf5fbb-7d73-4dc3-b054-00e46e141155, infoPort=37234, infoSecurePort=0, ipcPort=35318, storageInfo=lv=-57;cid=testClusterID;nsid=989125680;c=1606980023984) storage a5cf5fbb-7d73-4dc3-b054-00e46e141155
2020-12-03 07:20:30,749 [IPC Server handler 5 on default port 40176] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:40778
2020-12-03 07:20:30,749 [IPC Server handler 5 on default port 40176] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN a5cf5fbb-7d73-4dc3-b054-00e46e141155 (127.0.0.1:40778).
2020-12-03 07:20:30,750 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid a5cf5fbb-7d73-4dc3-b054-00e46e141155) service to localhost/127.0.0.1:40176 successfully registered with NN
2020-12-03 07:20:30,751 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:40176 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:30,758 [Thread-298] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=989125680;bpid=BP-917657629-172.17.0.7-1606980023984;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=989125680;c=1606980023984;bpid=BP-917657629-172.17.0.7-1606980023984;dnuuid=null
2020-12-03 07:20:30,758 [Thread-275] INFO  datanode.DataNode (DataNode.java:initStorage(1746)) - Setting up storage: nsid=989125680;bpid=BP-917657629-172.17.0.7-1606980023984;lv=-57;nsInfo=lv=-65;cid=testClusterID;nsid=989125680;c=1606980023984;bpid=BP-917657629-172.17.0.7-1606980023984;dnuuid=null
2020-12-03 07:20:30,762 [IPC Server handler 3 on default port 35507] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:40778, datanodeUuid=a5cf5fbb-7d73-4dc3-b054-00e46e141155, infoPort=37234, infoSecurePort=0, ipcPort=35318, storageInfo=lv=-57;cid=testClusterID;nsid=989125680;c=1606980023984) storage a5cf5fbb-7d73-4dc3-b054-00e46e141155
2020-12-03 07:20:30,763 [IPC Server handler 3 on default port 35507] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:40778
2020-12-03 07:20:30,763 [IPC Server handler 3 on default port 35507] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN a5cf5fbb-7d73-4dc3-b054-00e46e141155 (127.0.0.1:40778).
2020-12-03 07:20:30,767 [Thread-375] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-917657629-172.17.0.7-1606980023984 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13: 112ms
2020-12-03 07:20:30,770 [Thread-229] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-917657629-172.17.0.7-1606980023984: 116ms
2020-12-03 07:20:30,774 [Thread-384] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13...
2020-12-03 07:20:30,774 [Thread-384] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-917657629-172.17.0.7-1606980023984/current/replicas doesn't exist 
2020-12-03 07:20:30,775 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid a5cf5fbb-7d73-4dc3-b054-00e46e141155) service to localhost/127.0.0.1:35507 successfully registered with NN
2020-12-03 07:20:30,776 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:35507 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:30,778 [Thread-384] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13: 4ms
2020-12-03 07:20:30,778 [Thread-385] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14...
2020-12-03 07:20:30,778 [Thread-385] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-917657629-172.17.0.7-1606980023984/current/replicas doesn't exist 
2020-12-03 07:20:30,779 [Thread-385] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14: 1ms
2020-12-03 07:20:30,779 [Thread-229] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-917657629-172.17.0.7-1606980023984: 9ms
2020-12-03 07:20:30,780 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-12-03 07:20:30,780 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-f4bfacf8-7145-4886-a5f1-fd5fa3f79dee): finished scanning block pool BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:30,780 [Thread-229] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 10:04 AM with interval of 21600000ms
2020-12-03 07:20:30,781 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-f4bfacf8-7145-4886-a5f1-fd5fa3f79dee): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:20:30,788 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-12-03 07:20:30,788 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-9024d8af-e369-46b9-b368-4cf2f932788f): finished scanning block pool BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:30,789 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-9024d8af-e369-46b9-b368-4cf2f932788f): no suitable block pools found to scan.  Waiting 1814399991 ms.
2020-12-03 07:20:30,789 [IPC Server handler 5 on default port 35507] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-6ed681d4-7b32-434e-9b37-4319562525f7 for DN 127.0.0.1:40778
2020-12-03 07:20:30,789 [IPC Server handler 5 on default port 35507] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-3df7a241-42d4-46b6-9ce4-8b28b0d79357 for DN 127.0.0.1:40778
2020-12-03 07:20:30,798 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid 89347142-edad-4d29-b15f-e4c40718e489) service to localhost/127.0.0.1:35507 beginning handshake with NN
2020-12-03 07:20:30,801 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xa2358a42662891dd: Processing first storage report for DS-6ed681d4-7b32-434e-9b37-4319562525f7 from datanode a5cf5fbb-7d73-4dc3-b054-00e46e141155
2020-12-03 07:20:30,801 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xa2358a42662891dd: from storage DS-6ed681d4-7b32-434e-9b37-4319562525f7 node DatanodeRegistration(127.0.0.1:40778, datanodeUuid=a5cf5fbb-7d73-4dc3-b054-00e46e141155, infoPort=37234, infoSecurePort=0, ipcPort=35318, storageInfo=lv=-57;cid=testClusterID;nsid=989125680;c=1606980023984), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:30,802 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xa2358a42662891dd: Processing first storage report for DS-3df7a241-42d4-46b6-9ce4-8b28b0d79357 from datanode a5cf5fbb-7d73-4dc3-b054-00e46e141155
2020-12-03 07:20:30,802 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xa2358a42662891dd: from storage DS-3df7a241-42d4-46b6-9ce4-8b28b0d79357 node DatanodeRegistration(127.0.0.1:40778, datanodeUuid=a5cf5fbb-7d73-4dc3-b054-00e46e141155, infoPort=37234, infoSecurePort=0, ipcPort=35318, storageInfo=lv=-57;cid=testClusterID;nsid=989125680;c=1606980023984), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:30,803 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid 89347142-edad-4d29-b15f-e4c40718e489) service to localhost/127.0.0.1:40176 beginning handshake with NN
2020-12-03 07:20:30,803 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xa2358a42662891dd,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 6 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:20:30,804 [IPC Server handler 8 on default port 35507] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34003, datanodeUuid=89347142-edad-4d29-b15f-e4c40718e489, infoPort=39576, infoSecurePort=0, ipcPort=35791, storageInfo=lv=-57;cid=testClusterID;nsid=989125680;c=1606980023984) storage 89347142-edad-4d29-b15f-e4c40718e489
2020-12-03 07:20:30,804 [IPC Server handler 8 on default port 35507] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:34003
2020-12-03 07:20:30,804 [IPC Server handler 3 on default port 40176] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-6ed681d4-7b32-434e-9b37-4319562525f7 for DN 127.0.0.1:40778
2020-12-03 07:20:30,804 [IPC Server handler 8 on default port 35507] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 89347142-edad-4d29-b15f-e4c40718e489 (127.0.0.1:34003).
2020-12-03 07:20:30,804 [IPC Server handler 3 on default port 40176] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-3df7a241-42d4-46b6-9ce4-8b28b0d79357 for DN 127.0.0.1:40778
2020-12-03 07:20:30,805 [IPC Server handler 6 on default port 40176] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34003, datanodeUuid=89347142-edad-4d29-b15f-e4c40718e489, infoPort=39576, infoSecurePort=0, ipcPort=35791, storageInfo=lv=-57;cid=testClusterID;nsid=989125680;c=1606980023984) storage 89347142-edad-4d29-b15f-e4c40718e489
2020-12-03 07:20:30,805 [IPC Server handler 6 on default port 40176] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:34003
2020-12-03 07:20:30,805 [IPC Server handler 6 on default port 40176] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 89347142-edad-4d29-b15f-e4c40718e489 (127.0.0.1:34003).
2020-12-03 07:20:30,805 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid 89347142-edad-4d29-b15f-e4c40718e489) service to localhost/127.0.0.1:35507 successfully registered with NN
2020-12-03 07:20:30,805 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:35507 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:30,807 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid 89347142-edad-4d29-b15f-e4c40718e489) service to localhost/127.0.0.1:40176 successfully registered with NN
2020-12-03 07:20:30,808 [Thread-251] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID cb57b908-c67e-442d-9c8c-363640b27bef
2020-12-03 07:20:30,809 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:40176 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:30,810 [IPC Server handler 9 on default port 35507] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-f4bfacf8-7145-4886-a5f1-fd5fa3f79dee for DN 127.0.0.1:34003
2020-12-03 07:20:30,811 [IPC Server handler 9 on default port 35507] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-9024d8af-e369-46b9-b368-4cf2f932788f for DN 127.0.0.1:34003
2020-12-03 07:20:30,813 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x96f0ff21bacb74a4: Processing first storage report for DS-6ed681d4-7b32-434e-9b37-4319562525f7 from datanode a5cf5fbb-7d73-4dc3-b054-00e46e141155
2020-12-03 07:20:30,814 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x96f0ff21bacb74a4: from storage DS-6ed681d4-7b32-434e-9b37-4319562525f7 node DatanodeRegistration(127.0.0.1:40778, datanodeUuid=a5cf5fbb-7d73-4dc3-b054-00e46e141155, infoPort=37234, infoSecurePort=0, ipcPort=35318, storageInfo=lv=-57;cid=testClusterID;nsid=989125680;c=1606980023984), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:30,815 [IPC Server handler 2 on default port 40176] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-f4bfacf8-7145-4886-a5f1-fd5fa3f79dee for DN 127.0.0.1:34003
2020-12-03 07:20:30,815 [IPC Server handler 2 on default port 40176] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-9024d8af-e369-46b9-b368-4cf2f932788f for DN 127.0.0.1:34003
2020-12-03 07:20:30,817 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x96f0ff21bacb74a4: Processing first storage report for DS-3df7a241-42d4-46b6-9ce4-8b28b0d79357 from datanode a5cf5fbb-7d73-4dc3-b054-00e46e141155
2020-12-03 07:20:30,817 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x96f0ff21bacb74a4: from storage DS-3df7a241-42d4-46b6-9ce4-8b28b0d79357 node DatanodeRegistration(127.0.0.1:40778, datanodeUuid=a5cf5fbb-7d73-4dc3-b054-00e46e141155, infoPort=37234, infoSecurePort=0, ipcPort=35318, storageInfo=lv=-57;cid=testClusterID;nsid=989125680;c=1606980023984), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:20:30,817 [Thread-251] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-7b973780-45b9-48aa-b1ae-2b36eece14ee
2020-12-03 07:20:30,819 [Thread-251] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, StorageType: DISK
2020-12-03 07:20:30,822 [Thread-251] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-8870a112-92dc-4859-a282-7b7b8fc69dbd
2020-12-03 07:20:30,822 [Thread-251] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, StorageType: DISK
2020-12-03 07:20:30,824 [Thread-251] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:30,826 [Thread-251] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:20:30,827 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xf7fff46f315b2c3: Processing first storage report for DS-f4bfacf8-7145-4886-a5f1-fd5fa3f79dee from datanode 89347142-edad-4d29-b15f-e4c40718e489
2020-12-03 07:20:30,827 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xfbd6283293f46aa6: Processing first storage report for DS-f4bfacf8-7145-4886-a5f1-fd5fa3f79dee from datanode 89347142-edad-4d29-b15f-e4c40718e489
2020-12-03 07:20:30,827 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xfbd6283293f46aa6: from storage DS-f4bfacf8-7145-4886-a5f1-fd5fa3f79dee node DatanodeRegistration(127.0.0.1:34003, datanodeUuid=89347142-edad-4d29-b15f-e4c40718e489, infoPort=39576, infoSecurePort=0, ipcPort=35791, storageInfo=lv=-57;cid=testClusterID;nsid=989125680;c=1606980023984), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:20:30,827 [Thread-251] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:20:30,827 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xfbd6283293f46aa6: Processing first storage report for DS-9024d8af-e369-46b9-b368-4cf2f932788f from datanode 89347142-edad-4d29-b15f-e4c40718e489
2020-12-03 07:20:30,827 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xfbd6283293f46aa6: from storage DS-9024d8af-e369-46b9-b368-4cf2f932788f node DatanodeRegistration(127.0.0.1:34003, datanodeUuid=89347142-edad-4d29-b15f-e4c40718e489, infoPort=39576, infoSecurePort=0, ipcPort=35791, storageInfo=lv=-57;cid=testClusterID;nsid=989125680;c=1606980023984), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:30,827 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xf7fff46f315b2c3: from storage DS-f4bfacf8-7145-4886-a5f1-fd5fa3f79dee node DatanodeRegistration(127.0.0.1:34003, datanodeUuid=89347142-edad-4d29-b15f-e4c40718e489, infoPort=39576, infoSecurePort=0, ipcPort=35791, storageInfo=lv=-57;cid=testClusterID;nsid=989125680;c=1606980023984), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:30,827 [Thread-251] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:20:30,828 [Thread-251] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:20:30,828 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xf7fff46f315b2c3: Processing first storage report for DS-9024d8af-e369-46b9-b368-4cf2f932788f from datanode 89347142-edad-4d29-b15f-e4c40718e489
2020-12-03 07:20:30,838 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xf7fff46f315b2c3: from storage DS-9024d8af-e369-46b9-b368-4cf2f932788f node DatanodeRegistration(127.0.0.1:34003, datanodeUuid=89347142-edad-4d29-b15f-e4c40718e489, infoPort=39576, infoSecurePort=0, ipcPort=35791, storageInfo=lv=-57;cid=testClusterID;nsid=989125680;c=1606980023984), blocks: 0, hasStaleStorage: false, processing time: 10 msecs, invalidatedBlocks: 0
2020-12-03 07:20:30,836 [Thread-251] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:30,839 [IPC Server handler 0 on default port 35507] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:30,839 [Thread-392] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16...
2020-12-03 07:20:30,839 [Thread-391] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15...
2020-12-03 07:20:30,840 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xf7fff46f315b2c3,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 20 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:20:30,841 [Listener at localhost/43638] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:30,841 [Listener at localhost/43638] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:30,849 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xfbd6283293f46aa6,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 28 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:20:30,851 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x96f0ff21bacb74a4,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 44 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:20:30,890 [Thread-392] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-917657629-172.17.0.7-1606980023984 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16: 51ms
2020-12-03 07:20:30,890 [Thread-391] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-917657629-172.17.0.7-1606980023984 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15: 50ms
2020-12-03 07:20:30,892 [Thread-251] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-917657629-172.17.0.7-1606980023984: 53ms
2020-12-03 07:20:30,892 [Thread-395] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15...
2020-12-03 07:20:30,892 [Thread-396] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16...
2020-12-03 07:20:30,892 [Thread-395] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-917657629-172.17.0.7-1606980023984/current/replicas doesn't exist 
2020-12-03 07:20:30,892 [Thread-396] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-917657629-172.17.0.7-1606980023984/current/replicas doesn't exist 
2020-12-03 07:20:30,893 [Thread-395] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15: 0ms
2020-12-03 07:20:30,893 [Thread-396] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16: 0ms
2020-12-03 07:20:30,893 [Thread-251] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-917657629-172.17.0.7-1606980023984: 2ms
2020-12-03 07:20:30,893 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-12-03 07:20:30,894 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-12-03 07:20:30,894 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-7b973780-45b9-48aa-b1ae-2b36eece14ee): finished scanning block pool BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:30,894 [Thread-251] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 7:48 AM with interval of 21600000ms
2020-12-03 07:20:30,894 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-8870a112-92dc-4859-a282-7b7b8fc69dbd): finished scanning block pool BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:30,894 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-7b973780-45b9-48aa-b1ae-2b36eece14ee): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:20:30,896 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid cb57b908-c67e-442d-9c8c-363640b27bef) service to localhost/127.0.0.1:35507 beginning handshake with NN
2020-12-03 07:20:30,896 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid cb57b908-c67e-442d-9c8c-363640b27bef) service to localhost/127.0.0.1:40176 beginning handshake with NN
2020-12-03 07:20:30,897 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-8870a112-92dc-4859-a282-7b7b8fc69dbd): no suitable block pools found to scan.  Waiting 1814399996 ms.
2020-12-03 07:20:30,898 [IPC Server handler 9 on default port 40176] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:38056, datanodeUuid=cb57b908-c67e-442d-9c8c-363640b27bef, infoPort=43290, infoSecurePort=0, ipcPort=34061, storageInfo=lv=-57;cid=testClusterID;nsid=989125680;c=1606980023984) storage cb57b908-c67e-442d-9c8c-363640b27bef
2020-12-03 07:20:30,898 [IPC Server handler 1 on default port 35507] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:38056, datanodeUuid=cb57b908-c67e-442d-9c8c-363640b27bef, infoPort=43290, infoSecurePort=0, ipcPort=34061, storageInfo=lv=-57;cid=testClusterID;nsid=989125680;c=1606980023984) storage cb57b908-c67e-442d-9c8c-363640b27bef
2020-12-03 07:20:30,898 [IPC Server handler 9 on default port 40176] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38056
2020-12-03 07:20:30,901 [IPC Server handler 1 on default port 35507] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38056
2020-12-03 07:20:30,901 [IPC Server handler 9 on default port 40176] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN cb57b908-c67e-442d-9c8c-363640b27bef (127.0.0.1:38056).
2020-12-03 07:20:30,901 [IPC Server handler 1 on default port 35507] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN cb57b908-c67e-442d-9c8c-363640b27bef (127.0.0.1:38056).
2020-12-03 07:20:30,902 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid cb57b908-c67e-442d-9c8c-363640b27bef) service to localhost/127.0.0.1:40176 successfully registered with NN
2020-12-03 07:20:30,902 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid cb57b908-c67e-442d-9c8c-363640b27bef) service to localhost/127.0.0.1:35507 successfully registered with NN
2020-12-03 07:20:30,902 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:40176 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:30,902 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:35507 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:30,906 [Thread-298] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID fdeabe37-b020-4cdf-a421-01807757b061
2020-12-03 07:20:30,906 [Thread-275] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1546)) - Generated and persisted new Datanode UUID cb4aef3f-7b04-4877-92e5-64465e132825
2020-12-03 07:20:30,907 [IPC Server handler 8 on default port 40176] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-7b973780-45b9-48aa-b1ae-2b36eece14ee for DN 127.0.0.1:38056
2020-12-03 07:20:30,907 [IPC Server handler 6 on default port 35507] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-7b973780-45b9-48aa-b1ae-2b36eece14ee for DN 127.0.0.1:38056
2020-12-03 07:20:30,909 [IPC Server handler 8 on default port 40176] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-8870a112-92dc-4859-a282-7b7b8fc69dbd for DN 127.0.0.1:38056
2020-12-03 07:20:30,909 [IPC Server handler 6 on default port 35507] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-8870a112-92dc-4859-a282-7b7b8fc69dbd for DN 127.0.0.1:38056
2020-12-03 07:20:30,911 [Thread-298] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-e494c4c0-84f6-42dd-92d8-d29ca6c47e4b
2020-12-03 07:20:30,913 [Thread-298] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19, StorageType: DISK
2020-12-03 07:20:30,915 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x175cddc250a96428: Processing first storage report for DS-8870a112-92dc-4859-a282-7b7b8fc69dbd from datanode cb57b908-c67e-442d-9c8c-363640b27bef
2020-12-03 07:20:30,915 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x4bc6d017004a8e1b: Processing first storage report for DS-8870a112-92dc-4859-a282-7b7b8fc69dbd from datanode cb57b908-c67e-442d-9c8c-363640b27bef
2020-12-03 07:20:30,916 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x175cddc250a96428: from storage DS-8870a112-92dc-4859-a282-7b7b8fc69dbd node DatanodeRegistration(127.0.0.1:38056, datanodeUuid=cb57b908-c67e-442d-9c8c-363640b27bef, infoPort=43290, infoSecurePort=0, ipcPort=34061, storageInfo=lv=-57;cid=testClusterID;nsid=989125680;c=1606980023984), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:30,916 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x4bc6d017004a8e1b: from storage DS-8870a112-92dc-4859-a282-7b7b8fc69dbd node DatanodeRegistration(127.0.0.1:38056, datanodeUuid=cb57b908-c67e-442d-9c8c-363640b27bef, infoPort=43290, infoSecurePort=0, ipcPort=34061, storageInfo=lv=-57;cid=testClusterID;nsid=989125680;c=1606980023984), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:30,916 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x175cddc250a96428: Processing first storage report for DS-7b973780-45b9-48aa-b1ae-2b36eece14ee from datanode cb57b908-c67e-442d-9c8c-363640b27bef
2020-12-03 07:20:30,916 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x4bc6d017004a8e1b: Processing first storage report for DS-7b973780-45b9-48aa-b1ae-2b36eece14ee from datanode cb57b908-c67e-442d-9c8c-363640b27bef
2020-12-03 07:20:30,916 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x175cddc250a96428: from storage DS-7b973780-45b9-48aa-b1ae-2b36eece14ee node DatanodeRegistration(127.0.0.1:38056, datanodeUuid=cb57b908-c67e-442d-9c8c-363640b27bef, infoPort=43290, infoSecurePort=0, ipcPort=34061, storageInfo=lv=-57;cid=testClusterID;nsid=989125680;c=1606980023984), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:30,916 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x4bc6d017004a8e1b: from storage DS-7b973780-45b9-48aa-b1ae-2b36eece14ee node DatanodeRegistration(127.0.0.1:38056, datanodeUuid=cb57b908-c67e-442d-9c8c-363640b27bef, infoPort=43290, infoSecurePort=0, ipcPort=34061, storageInfo=lv=-57;cid=testClusterID;nsid=989125680;c=1606980023984), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:30,917 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x175cddc250a96428,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 7 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:20:30,925 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x4bc6d017004a8e1b,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 5 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:20:30,926 [Thread-298] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-7f216f4d-5fbf-45d0-8c6a-456ab6675b7c
2020-12-03 07:20:30,927 [Thread-298] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20, StorageType: DISK
2020-12-03 07:20:30,928 [Thread-275] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-36362941-3af0-4d97-975d-6c63a7fd314f
2020-12-03 07:20:30,931 [Thread-298] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:30,932 [Thread-298] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19
2020-12-03 07:20:30,933 [Thread-298] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19
2020-12-03 07:20:30,934 [Thread-298] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20
2020-12-03 07:20:30,934 [Thread-298] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20
2020-12-03 07:20:30,934 [Thread-298] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:30,935 [Thread-403] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19...
2020-12-03 07:20:30,936 [Thread-275] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, StorageType: DISK
2020-12-03 07:20:30,936 [Thread-404] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20...
2020-12-03 07:20:30,943 [IPC Server handler 3 on default port 35507] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:30,945 [Listener at localhost/43638] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:30,946 [Listener at localhost/43638] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:30,946 [Thread-275] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(304)) - Added new volume: DS-ceb133f8-e092-4bb0-bdaf-62de04a9fde9
2020-12-03 07:20:30,946 [Thread-275] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, StorageType: DISK
2020-12-03 07:20:30,947 [Thread-275] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-12-03 07:20:30,955 [Thread-275] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:20:30,956 [Thread-275] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:20:31,018 [Thread-275] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:20:31,018 [Thread-275] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(222)) - Scheduled health check for volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:20:31,018 [Thread-275] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:31,025 [Thread-408] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17...
2020-12-03 07:20:31,025 [Thread-409] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(406)) - Scanning block pool BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18...
2020-12-03 07:20:31,049 [Thread-403] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-917657629-172.17.0.7-1606980023984 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19: 115ms
2020-12-03 07:20:31,049 [Thread-404] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-917657629-172.17.0.7-1606980023984 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20: 110ms
2020-12-03 07:20:31,056 [Thread-298] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-917657629-172.17.0.7-1606980023984: 122ms
2020-12-03 07:20:31,060 [Thread-412] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19...
2020-12-03 07:20:31,061 [Thread-413] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20...
2020-12-03 07:20:31,062 [Thread-412] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19/current/BP-917657629-172.17.0.7-1606980023984/current/replicas doesn't exist 
2020-12-03 07:20:31,062 [Thread-413] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20/current/BP-917657629-172.17.0.7-1606980023984/current/replicas doesn't exist 
2020-12-03 07:20:31,062 [Thread-413] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20: 0ms
2020-12-03 07:20:31,062 [IPC Server handler 5 on default port 35507] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:31,063 [Thread-412] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19: 2ms
2020-12-03 07:20:31,064 [Thread-298] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-917657629-172.17.0.7-1606980023984: 4ms
2020-12-03 07:20:31,064 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20
2020-12-03 07:20:31,064 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19
2020-12-03 07:20:31,064 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20, DS-7f216f4d-5fbf-45d0-8c6a-456ab6675b7c): finished scanning block pool BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:31,064 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19, DS-e494c4c0-84f6-42dd-92d8-d29ca6c47e4b): finished scanning block pool BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:31,064 [Thread-298] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 11:41 AM with interval of 21600000ms
2020-12-03 07:20:31,065 [Listener at localhost/43638] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2782)) - dnInfo.length != numDataNodes
2020-12-03 07:20:31,065 [Listener at localhost/43638] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2703)) - Waiting for cluster to become active
2020-12-03 07:20:31,065 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20, DS-7f216f4d-5fbf-45d0-8c6a-456ab6675b7c): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:20:31,065 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19, DS-e494c4c0-84f6-42dd-92d8-d29ca6c47e4b): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-12-03 07:20:31,067 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid fdeabe37-b020-4cdf-a421-01807757b061) service to localhost/127.0.0.1:35507 beginning handshake with NN
2020-12-03 07:20:31,067 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid fdeabe37-b020-4cdf-a421-01807757b061) service to localhost/127.0.0.1:40176 beginning handshake with NN
2020-12-03 07:20:31,069 [IPC Server handler 7 on default port 35507] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:37871, datanodeUuid=fdeabe37-b020-4cdf-a421-01807757b061, infoPort=40670, infoSecurePort=0, ipcPort=43638, storageInfo=lv=-57;cid=testClusterID;nsid=989125680;c=1606980023984) storage fdeabe37-b020-4cdf-a421-01807757b061
2020-12-03 07:20:31,069 [IPC Server handler 7 on default port 35507] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:37871
2020-12-03 07:20:31,069 [IPC Server handler 7 on default port 35507] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN fdeabe37-b020-4cdf-a421-01807757b061 (127.0.0.1:37871).
2020-12-03 07:20:31,070 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid fdeabe37-b020-4cdf-a421-01807757b061) service to localhost/127.0.0.1:35507 successfully registered with NN
2020-12-03 07:20:31,070 [IPC Server handler 4 on default port 40176] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:37871, datanodeUuid=fdeabe37-b020-4cdf-a421-01807757b061, infoPort=40670, infoSecurePort=0, ipcPort=43638, storageInfo=lv=-57;cid=testClusterID;nsid=989125680;c=1606980023984) storage fdeabe37-b020-4cdf-a421-01807757b061
2020-12-03 07:20:31,070 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:35507 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:31,071 [IPC Server handler 4 on default port 40176] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:37871
2020-12-03 07:20:31,071 [IPC Server handler 4 on default port 40176] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN fdeabe37-b020-4cdf-a421-01807757b061 (127.0.0.1:37871).
2020-12-03 07:20:31,074 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid fdeabe37-b020-4cdf-a421-01807757b061) service to localhost/127.0.0.1:40176 successfully registered with NN
2020-12-03 07:20:31,074 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:40176 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:31,075 [IPC Server handler 8 on default port 35507] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-e494c4c0-84f6-42dd-92d8-d29ca6c47e4b for DN 127.0.0.1:37871
2020-12-03 07:20:31,076 [IPC Server handler 8 on default port 35507] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-7f216f4d-5fbf-45d0-8c6a-456ab6675b7c for DN 127.0.0.1:37871
2020-12-03 07:20:31,078 [IPC Server handler 5 on default port 40176] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-e494c4c0-84f6-42dd-92d8-d29ca6c47e4b for DN 127.0.0.1:37871
2020-12-03 07:20:31,078 [IPC Server handler 5 on default port 40176] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-7f216f4d-5fbf-45d0-8c6a-456ab6675b7c for DN 127.0.0.1:37871
2020-12-03 07:20:31,079 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x5f2465cb9530f1ff: Processing first storage report for DS-e494c4c0-84f6-42dd-92d8-d29ca6c47e4b from datanode fdeabe37-b020-4cdf-a421-01807757b061
2020-12-03 07:20:31,079 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x5f2465cb9530f1ff: from storage DS-e494c4c0-84f6-42dd-92d8-d29ca6c47e4b node DatanodeRegistration(127.0.0.1:37871, datanodeUuid=fdeabe37-b020-4cdf-a421-01807757b061, infoPort=40670, infoSecurePort=0, ipcPort=43638, storageInfo=lv=-57;cid=testClusterID;nsid=989125680;c=1606980023984), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:20:31,079 [Thread-408] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-917657629-172.17.0.7-1606980023984 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17: 55ms
2020-12-03 07:20:31,079 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x5f2465cb9530f1ff: Processing first storage report for DS-7f216f4d-5fbf-45d0-8c6a-456ab6675b7c from datanode fdeabe37-b020-4cdf-a421-01807757b061
2020-12-03 07:20:31,079 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x5f2465cb9530f1ff: from storage DS-7f216f4d-5fbf-45d0-8c6a-456ab6675b7c node DatanodeRegistration(127.0.0.1:37871, datanodeUuid=fdeabe37-b020-4cdf-a421-01807757b061, infoPort=40670, infoSecurePort=0, ipcPort=43638, storageInfo=lv=-57;cid=testClusterID;nsid=989125680;c=1606980023984), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:31,081 [Thread-409] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(411)) - Time taken to scan block pool BP-917657629-172.17.0.7-1606980023984 on /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18: 56ms
2020-12-03 07:20:31,081 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xf4f16df38d737532: Processing first storage report for DS-e494c4c0-84f6-42dd-92d8-d29ca6c47e4b from datanode fdeabe37-b020-4cdf-a421-01807757b061
2020-12-03 07:20:31,081 [Thread-275] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(431)) - Total time to scan all replicas for block pool BP-917657629-172.17.0.7-1606980023984: 58ms
2020-12-03 07:20:31,081 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xf4f16df38d737532: from storage DS-e494c4c0-84f6-42dd-92d8-d29ca6c47e4b node DatanodeRegistration(127.0.0.1:37871, datanodeUuid=fdeabe37-b020-4cdf-a421-01807757b061, infoPort=40670, infoSecurePort=0, ipcPort=43638, storageInfo=lv=-57;cid=testClusterID;nsid=989125680;c=1606980023984), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-12-03 07:20:31,081 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xf4f16df38d737532: Processing first storage report for DS-7f216f4d-5fbf-45d0-8c6a-456ab6675b7c from datanode fdeabe37-b020-4cdf-a421-01807757b061
2020-12-03 07:20:31,081 [Thread-417] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17...
2020-12-03 07:20:31,082 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xf4f16df38d737532: from storage DS-7f216f4d-5fbf-45d0-8c6a-456ab6675b7c node DatanodeRegistration(127.0.0.1:37871, datanodeUuid=fdeabe37-b020-4cdf-a421-01807757b061, infoPort=40670, infoSecurePort=0, ipcPort=43638, storageInfo=lv=-57;cid=testClusterID;nsid=989125680;c=1606980023984), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:31,082 [Thread-418] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(199)) - Adding replicas to map for block pool BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18...
2020-12-03 07:20:31,082 [Thread-417] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-917657629-172.17.0.7-1606980023984/current/replicas doesn't exist 
2020-12-03 07:20:31,082 [Thread-418] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(876)) - Replica Cache file: /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-917657629-172.17.0.7-1606980023984/current/replicas doesn't exist 
2020-12-03 07:20:31,082 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xf4f16df38d737532,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:20:31,082 [Thread-418] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18: 1ms
2020-12-03 07:20:31,082 [Thread-417] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(204)) - Time to add replicas to map for block pool BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17: 1ms
2020-12-03 07:20:31,088 [Thread-275] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(225)) - Total time to add all replicas to map for block pool BP-917657629-172.17.0.7-1606980023984: 7ms
2020-12-03 07:20:31,088 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x5f2465cb9530f1ff,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 12 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:20:31,089 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-12-03 07:20:31,089 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(381)) - Now scanning bpid BP-917657629-172.17.0.7-1606980023984 on volume /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-12-03 07:20:31,089 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-36362941-3af0-4d97-975d-6c63a7fd314f): finished scanning block pool BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:31,089 [Thread-275] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(284)) - Periodic Directory Tree Verification scan starting at 12/3/20 10:58 AM with interval of 21600000ms
2020-12-03 07:20:31,089 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(539)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-ceb133f8-e092-4bb0-bdaf-62de04a9fde9): finished scanning block pool BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:31,091 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-36362941-3af0-4d97-975d-6c63a7fd314f): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-12-03 07:20:31,091 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid cb4aef3f-7b04-4877-92e5-64465e132825) service to localhost/127.0.0.1:40176 beginning handshake with NN
2020-12-03 07:20:31,092 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(398)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-ceb133f8-e092-4bb0-bdaf-62de04a9fde9): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-12-03 07:20:31,092 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] INFO  datanode.DataNode (BPServiceActor.java:register(767)) - Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid cb4aef3f-7b04-4877-92e5-64465e132825) service to localhost/127.0.0.1:35507 beginning handshake with NN
2020-12-03 07:20:31,093 [IPC Server handler 6 on default port 40176] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:33456, datanodeUuid=cb4aef3f-7b04-4877-92e5-64465e132825, infoPort=44675, infoSecurePort=0, ipcPort=45886, storageInfo=lv=-57;cid=testClusterID;nsid=989125680;c=1606980023984) storage cb4aef3f-7b04-4877-92e5-64465e132825
2020-12-03 07:20:31,094 [IPC Server handler 6 on default port 40176] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:33456
2020-12-03 07:20:31,094 [IPC Server handler 6 on default port 40176] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN cb4aef3f-7b04-4877-92e5-64465e132825 (127.0.0.1:33456).
2020-12-03 07:20:31,093 [IPC Server handler 2 on default port 35507] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1042)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:33456, datanodeUuid=cb4aef3f-7b04-4877-92e5-64465e132825, infoPort=44675, infoSecurePort=0, ipcPort=45886, storageInfo=lv=-57;cid=testClusterID;nsid=989125680;c=1606980023984) storage cb4aef3f-7b04-4877-92e5-64465e132825
2020-12-03 07:20:31,094 [IPC Server handler 2 on default port 35507] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:33456
2020-12-03 07:20:31,095 [IPC Server handler 2 on default port 35507] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN cb4aef3f-7b04-4877-92e5-64465e132825 (127.0.0.1:33456).
2020-12-03 07:20:31,095 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid cb4aef3f-7b04-4877-92e5-64465e132825) service to localhost/127.0.0.1:40176 successfully registered with NN
2020-12-03 07:20:31,095 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:40176 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:31,097 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] INFO  datanode.DataNode (BPServiceActor.java:register(786)) - Block pool Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid cb4aef3f-7b04-4877-92e5-64465e132825) service to localhost/127.0.0.1:35507 successfully registered with NN
2020-12-03 07:20:31,097 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] INFO  datanode.DataNode (BPServiceActor.java:offerService(616)) - For namenode localhost/127.0.0.1:35507 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-12-03 07:20:31,102 [IPC Server handler 2 on default port 40176] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-36362941-3af0-4d97-975d-6c63a7fd314f for DN 127.0.0.1:33456
2020-12-03 07:20:31,102 [IPC Server handler 2 on default port 40176] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-ceb133f8-e092-4bb0-bdaf-62de04a9fde9 for DN 127.0.0.1:33456
2020-12-03 07:20:31,105 [IPC Server handler 0 on default port 35507] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-36362941-3af0-4d97-975d-6c63a7fd314f for DN 127.0.0.1:33456
2020-12-03 07:20:31,106 [IPC Server handler 0 on default port 35507] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-ceb133f8-e092-4bb0-bdaf-62de04a9fde9 for DN 127.0.0.1:33456
2020-12-03 07:20:31,107 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xfc64a6f936802997: Processing first storage report for DS-36362941-3af0-4d97-975d-6c63a7fd314f from datanode cb4aef3f-7b04-4877-92e5-64465e132825
2020-12-03 07:20:31,107 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xfc64a6f936802997: from storage DS-36362941-3af0-4d97-975d-6c63a7fd314f node DatanodeRegistration(127.0.0.1:33456, datanodeUuid=cb4aef3f-7b04-4877-92e5-64465e132825, infoPort=44675, infoSecurePort=0, ipcPort=45886, storageInfo=lv=-57;cid=testClusterID;nsid=989125680;c=1606980023984), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:31,107 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0xfc64a6f936802997: Processing first storage report for DS-ceb133f8-e092-4bb0-bdaf-62de04a9fde9 from datanode cb4aef3f-7b04-4877-92e5-64465e132825
2020-12-03 07:20:31,108 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0xfc64a6f936802997: from storage DS-ceb133f8-e092-4bb0-bdaf-62de04a9fde9 node DatanodeRegistration(127.0.0.1:33456, datanodeUuid=cb4aef3f-7b04-4877-92e5-64465e132825, infoPort=44675, infoSecurePort=0, ipcPort=45886, storageInfo=lv=-57;cid=testClusterID;nsid=989125680;c=1606980023984), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:31,109 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x552351a8083a80ae: Processing first storage report for DS-36362941-3af0-4d97-975d-6c63a7fd314f from datanode cb4aef3f-7b04-4877-92e5-64465e132825
2020-12-03 07:20:31,109 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x552351a8083a80ae: from storage DS-36362941-3af0-4d97-975d-6c63a7fd314f node DatanodeRegistration(127.0.0.1:33456, datanodeUuid=cb4aef3f-7b04-4877-92e5-64465e132825, infoPort=44675, infoSecurePort=0, ipcPort=45886, storageInfo=lv=-57;cid=testClusterID;nsid=989125680;c=1606980023984), blocks: 0, hasStaleStorage: true, processing time: 2 msecs, invalidatedBlocks: 0
2020-12-03 07:20:31,109 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0xfc64a6f936802997,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 4 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:20:31,109 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2648)) - BLOCK* processReport 0x552351a8083a80ae: Processing first storage report for DS-ceb133f8-e092-4bb0-bdaf-62de04a9fde9 from datanode cb4aef3f-7b04-4877-92e5-64465e132825
2020-12-03 07:20:31,109 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2677)) - BLOCK* processReport 0x552351a8083a80ae: from storage DS-ceb133f8-e092-4bb0-bdaf-62de04a9fde9 node DatanodeRegistration(127.0.0.1:33456, datanodeUuid=cb4aef3f-7b04-4877-92e5-64465e132825, infoPort=44675, infoSecurePort=0, ipcPort=45886, storageInfo=lv=-57;cid=testClusterID;nsid=989125680;c=1606980023984), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-12-03 07:20:31,110 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] INFO  datanode.DataNode (BPServiceActor.java:blockReport(424)) - Successfully sent block report 0x552351a8083a80ae,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back no commands.
2020-12-03 07:20:31,166 [IPC Server handler 6 on default port 35507] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:31,176 [IPC Server handler 7 on default port 40176] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:31,178 [Listener at localhost/43638] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:20:31,189 [IPC Server handler 4 on default port 35507] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:31,195 [IPC Server handler 9 on default port 40176] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-12-03 07:20:31,198 [Listener at localhost/43638] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2758)) - Cluster is active
2020-12-03 07:20:31,200 [Listener at localhost/43638] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:20:31,201 [Edit log tailer] WARN  ha.EditLogTailer (EditLogTailer.java:doWork(528)) - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.sleep(EditLogTailer.java:433)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:526)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:440)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:457)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:484)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:453)
2020-12-03 07:20:31,206 [Listener at localhost/43638] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:20:31,208 [Listener at localhost/43638] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/shared-edits-0-through-1/current
2020-12-03 07:20:31,208 [Listener at localhost/43638] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-12-03 07:20:31,209 [Listener at localhost/43638] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-12-03 07:20:31,209 [Listener at localhost/43638] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1233)) - Catching up to latest edits from old active before taking over writer role in edits logs
2020-12-03 07:20:31,212 [Listener at localhost/43638] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:markAllDatanodesStale(1840)) - Marking all datanodes as stale
2020-12-03 07:20:31,231 [Listener at localhost/43638] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1244)) - Reprocessing replication and invalidation queues
2020-12-03 07:20:31,231 [Listener at localhost/43638] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:20:31,276 [Listener at localhost/43638] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1255)) - Will take over writing edit logs at txnid 1
2020-12-03 07:20:31,280 [Listener at localhost/43638] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 1
2020-12-03 07:20:31,308 [Listener at localhost/43638] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:20:31,315 [Listener at localhost/43638] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 5 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:20:31,322 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 0
2020-12-03 07:20:31,322 [CacheReplicationMonitor(500731340)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:20:31,322 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:20:31,322 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:20:31,323 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:20:31,323 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 0
2020-12-03 07:20:31,323 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 46 msec
2020-12-03 07:20:31,366 [IPC Server handler 3 on default port 35507] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-12-03 07:20:31,412 [IPC Server handler 5 on default port 35507] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/testfile	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-12-03 07:20:31,476 [IPC Server handler 7 on default port 35507] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:40799, 127.0.0.1:40778, 127.0.0.1:34003, 127.0.0.1:34066, 127.0.0.1:34525, 127.0.0.1:37871, 127.0.0.1:38056, 127.0.0.1:38706, 127.0.0.1:35105, 127.0.0.1:33456 for /testfile
2020-12-03 07:20:31,521 [Thread-430] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:31,602 [DataXceiver for client DFSClient_NONMAPREDUCE_2135733897_1 at /127.0.0.1:41606 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-917657629-172.17.0.7-1606980023984:blk_1073741825_1001 src: /127.0.0.1:41606 dest: /127.0.0.1:40799
2020-12-03 07:20:31,632 [DataXceiver for client DFSClient_NONMAPREDUCE_2135733897_1 at /127.0.0.1:41606 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741825_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:31,635 [DataXceiver for client DFSClient_NONMAPREDUCE_2135733897_1 at /127.0.0.1:33250 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-917657629-172.17.0.7-1606980023984:blk_1073741825_1001 src: /127.0.0.1:33250 dest: /127.0.0.1:40778
2020-12-03 07:20:31,640 [DataXceiver for client DFSClient_NONMAPREDUCE_2135733897_1 at /127.0.0.1:33250 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741825_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:31,644 [DataXceiver for client DFSClient_NONMAPREDUCE_2135733897_1 at /127.0.0.1:45488 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-917657629-172.17.0.7-1606980023984:blk_1073741825_1001 src: /127.0.0.1:45488 dest: /127.0.0.1:34003
2020-12-03 07:20:31,645 [DataXceiver for client DFSClient_NONMAPREDUCE_2135733897_1 at /127.0.0.1:45488 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741825_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:31,650 [DataXceiver for client DFSClient_NONMAPREDUCE_2135733897_1 at /127.0.0.1:37078 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-917657629-172.17.0.7-1606980023984:blk_1073741825_1001 src: /127.0.0.1:37078 dest: /127.0.0.1:34066
2020-12-03 07:20:31,651 [DataXceiver for client DFSClient_NONMAPREDUCE_2135733897_1 at /127.0.0.1:37078 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741825_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:31,654 [DataXceiver for client DFSClient_NONMAPREDUCE_2135733897_1 at /127.0.0.1:34648 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-917657629-172.17.0.7-1606980023984:blk_1073741825_1001 src: /127.0.0.1:34648 dest: /127.0.0.1:34525
2020-12-03 07:20:31,655 [DataXceiver for client DFSClient_NONMAPREDUCE_2135733897_1 at /127.0.0.1:34648 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741825_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:31,661 [DataXceiver for client DFSClient_NONMAPREDUCE_2135733897_1 at /127.0.0.1:36966 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-917657629-172.17.0.7-1606980023984:blk_1073741825_1001 src: /127.0.0.1:36966 dest: /127.0.0.1:37871
2020-12-03 07:20:31,662 [DataXceiver for client DFSClient_NONMAPREDUCE_2135733897_1 at /127.0.0.1:36966 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741825_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:31,668 [DataXceiver for client DFSClient_NONMAPREDUCE_2135733897_1 at /127.0.0.1:58932 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-917657629-172.17.0.7-1606980023984:blk_1073741825_1001 src: /127.0.0.1:58932 dest: /127.0.0.1:38056
2020-12-03 07:20:31,670 [DataXceiver for client DFSClient_NONMAPREDUCE_2135733897_1 at /127.0.0.1:58932 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741825_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:31,673 [DataXceiver for client DFSClient_NONMAPREDUCE_2135733897_1 at /127.0.0.1:49868 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-917657629-172.17.0.7-1606980023984:blk_1073741825_1001 src: /127.0.0.1:49868 dest: /127.0.0.1:38706
2020-12-03 07:20:31,675 [DataXceiver for client DFSClient_NONMAPREDUCE_2135733897_1 at /127.0.0.1:49868 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741825_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:31,684 [DataXceiver for client DFSClient_NONMAPREDUCE_2135733897_1 at /127.0.0.1:38228 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-917657629-172.17.0.7-1606980023984:blk_1073741825_1001 src: /127.0.0.1:38228 dest: /127.0.0.1:35105
2020-12-03 07:20:31,685 [DataXceiver for client DFSClient_NONMAPREDUCE_2135733897_1 at /127.0.0.1:38228 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741825_1001]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:31,686 [DataXceiver for client DFSClient_NONMAPREDUCE_2135733897_1 at /127.0.0.1:46442 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-917657629-172.17.0.7-1606980023984:blk_1073741825_1001 src: /127.0.0.1:46442 dest: /127.0.0.1:33456
2020-12-03 07:20:31,822 [PacketResponder: BP-917657629-172.17.0.7-1606980023984:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:46442, dest: /127.0.0.1:33456, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2135733897_1, offset: 0, srvID: cb4aef3f-7b04-4877-92e5-64465e132825, blockid: BP-917657629-172.17.0.7-1606980023984:blk_1073741825_1001, duration(ns): 55647615
2020-12-03 07:20:31,823 [PacketResponder: BP-917657629-172.17.0.7-1606980023984:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-917657629-172.17.0.7-1606980023984:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-12-03 07:20:31,826 [PacketResponder: BP-917657629-172.17.0.7-1606980023984:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:33456]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38228, dest: /127.0.0.1:35105, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2135733897_1, offset: 0, srvID: aac3269e-0132-46b9-826f-593ec51a470c, blockid: BP-917657629-172.17.0.7-1606980023984:blk_1073741825_1001, duration(ns): 126854126
2020-12-03 07:20:31,826 [PacketResponder: BP-917657629-172.17.0.7-1606980023984:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:33456]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-917657629-172.17.0.7-1606980023984:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:33456] terminating
2020-12-03 07:20:31,829 [PacketResponder: BP-917657629-172.17.0.7-1606980023984:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:35105, 127.0.0.1:33456]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:49868, dest: /127.0.0.1:38706, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2135733897_1, offset: 0, srvID: 4ea78e77-6418-4b63-8f69-9cb494a0609e, blockid: BP-917657629-172.17.0.7-1606980023984:blk_1073741825_1001, duration(ns): 129243194
2020-12-03 07:20:31,829 [PacketResponder: BP-917657629-172.17.0.7-1606980023984:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:35105, 127.0.0.1:33456]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-917657629-172.17.0.7-1606980023984:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:35105, 127.0.0.1:33456] terminating
2020-12-03 07:20:31,831 [PacketResponder: BP-917657629-172.17.0.7-1606980023984:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=3:[127.0.0.1:38706, 127.0.0.1:35105, 127.0.0.1:33456]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58932, dest: /127.0.0.1:38056, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2135733897_1, offset: 0, srvID: cb57b908-c67e-442d-9c8c-363640b27bef, blockid: BP-917657629-172.17.0.7-1606980023984:blk_1073741825_1001, duration(ns): 117770485
2020-12-03 07:20:31,832 [PacketResponder: BP-917657629-172.17.0.7-1606980023984:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=3:[127.0.0.1:38706, 127.0.0.1:35105, 127.0.0.1:33456]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-917657629-172.17.0.7-1606980023984:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=3:[127.0.0.1:38706, 127.0.0.1:35105, 127.0.0.1:33456] terminating
2020-12-03 07:20:31,834 [PacketResponder: BP-917657629-172.17.0.7-1606980023984:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=4:[127.0.0.1:38056, 127.0.0.1:38706, 127.0.0.1:35105, 127.0.0.1:33456]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:36966, dest: /127.0.0.1:37871, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2135733897_1, offset: 0, srvID: fdeabe37-b020-4cdf-a421-01807757b061, blockid: BP-917657629-172.17.0.7-1606980023984:blk_1073741825_1001, duration(ns): 134445726
2020-12-03 07:20:31,835 [PacketResponder: BP-917657629-172.17.0.7-1606980023984:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=4:[127.0.0.1:38056, 127.0.0.1:38706, 127.0.0.1:35105, 127.0.0.1:33456]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-917657629-172.17.0.7-1606980023984:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=4:[127.0.0.1:38056, 127.0.0.1:38706, 127.0.0.1:35105, 127.0.0.1:33456] terminating
2020-12-03 07:20:31,841 [PacketResponder: BP-917657629-172.17.0.7-1606980023984:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=5:[127.0.0.1:37871, 127.0.0.1:38056, 127.0.0.1:38706, 127.0.0.1:35105, 127.0.0.1:33456]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:34648, dest: /127.0.0.1:34525, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2135733897_1, offset: 0, srvID: 250bafb2-f716-457e-8310-96d333f0e360, blockid: BP-917657629-172.17.0.7-1606980023984:blk_1073741825_1001, duration(ns): 127560035
2020-12-03 07:20:31,842 [PacketResponder: BP-917657629-172.17.0.7-1606980023984:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=5:[127.0.0.1:37871, 127.0.0.1:38056, 127.0.0.1:38706, 127.0.0.1:35105, 127.0.0.1:33456]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-917657629-172.17.0.7-1606980023984:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=5:[127.0.0.1:37871, 127.0.0.1:38056, 127.0.0.1:38706, 127.0.0.1:35105, 127.0.0.1:33456] terminating
2020-12-03 07:20:31,844 [PacketResponder: BP-917657629-172.17.0.7-1606980023984:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=6:[127.0.0.1:34525, 127.0.0.1:37871, 127.0.0.1:38056, 127.0.0.1:38706, 127.0.0.1:35105, 127.0.0.1:33456]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37078, dest: /127.0.0.1:34066, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2135733897_1, offset: 0, srvID: a9577885-35e8-4740-8041-adbd3b637e00, blockid: BP-917657629-172.17.0.7-1606980023984:blk_1073741825_1001, duration(ns): 144754129
2020-12-03 07:20:31,845 [PacketResponder: BP-917657629-172.17.0.7-1606980023984:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=6:[127.0.0.1:34525, 127.0.0.1:37871, 127.0.0.1:38056, 127.0.0.1:38706, 127.0.0.1:35105, 127.0.0.1:33456]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-917657629-172.17.0.7-1606980023984:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=6:[127.0.0.1:34525, 127.0.0.1:37871, 127.0.0.1:38056, 127.0.0.1:38706, 127.0.0.1:35105, 127.0.0.1:33456] terminating
2020-12-03 07:20:31,847 [PacketResponder: BP-917657629-172.17.0.7-1606980023984:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=7:[127.0.0.1:34066, 127.0.0.1:34525, 127.0.0.1:37871, 127.0.0.1:38056, 127.0.0.1:38706, 127.0.0.1:35105, 127.0.0.1:33456]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:45488, dest: /127.0.0.1:34003, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2135733897_1, offset: 0, srvID: 89347142-edad-4d29-b15f-e4c40718e489, blockid: BP-917657629-172.17.0.7-1606980023984:blk_1073741825_1001, duration(ns): 147459397
2020-12-03 07:20:31,848 [PacketResponder: BP-917657629-172.17.0.7-1606980023984:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=7:[127.0.0.1:34066, 127.0.0.1:34525, 127.0.0.1:37871, 127.0.0.1:38056, 127.0.0.1:38706, 127.0.0.1:35105, 127.0.0.1:33456]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-917657629-172.17.0.7-1606980023984:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=7:[127.0.0.1:34066, 127.0.0.1:34525, 127.0.0.1:37871, 127.0.0.1:38056, 127.0.0.1:38706, 127.0.0.1:35105, 127.0.0.1:33456] terminating
2020-12-03 07:20:31,850 [PacketResponder: BP-917657629-172.17.0.7-1606980023984:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=8:[127.0.0.1:34003, 127.0.0.1:34066, 127.0.0.1:34525, 127.0.0.1:37871, 127.0.0.1:38056, 127.0.0.1:38706, 127.0.0.1:35105, 127.0.0.1:33456]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:33250, dest: /127.0.0.1:40778, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2135733897_1, offset: 0, srvID: a5cf5fbb-7d73-4dc3-b054-00e46e141155, blockid: BP-917657629-172.17.0.7-1606980023984:blk_1073741825_1001, duration(ns): 150289427
2020-12-03 07:20:31,851 [PacketResponder: BP-917657629-172.17.0.7-1606980023984:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=8:[127.0.0.1:34003, 127.0.0.1:34066, 127.0.0.1:34525, 127.0.0.1:37871, 127.0.0.1:38056, 127.0.0.1:38706, 127.0.0.1:35105, 127.0.0.1:33456]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-917657629-172.17.0.7-1606980023984:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=8:[127.0.0.1:34003, 127.0.0.1:34066, 127.0.0.1:34525, 127.0.0.1:37871, 127.0.0.1:38056, 127.0.0.1:38706, 127.0.0.1:35105, 127.0.0.1:33456] terminating
2020-12-03 07:20:31,856 [PacketResponder: BP-917657629-172.17.0.7-1606980023984:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=9:[127.0.0.1:40778, 127.0.0.1:34003, 127.0.0.1:34066, 127.0.0.1:34525, 127.0.0.1:37871, 127.0.0.1:38056, 127.0.0.1:38706, 127.0.0.1:35105, 127.0.0.1:33456]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41606, dest: /127.0.0.1:40799, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2135733897_1, offset: 0, srvID: d536f9db-cc03-4d10-befe-81c328136fc6, blockid: BP-917657629-172.17.0.7-1606980023984:blk_1073741825_1001, duration(ns): 156054867
2020-12-03 07:20:31,857 [PacketResponder: BP-917657629-172.17.0.7-1606980023984:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=9:[127.0.0.1:40778, 127.0.0.1:34003, 127.0.0.1:34066, 127.0.0.1:34525, 127.0.0.1:37871, 127.0.0.1:38056, 127.0.0.1:38706, 127.0.0.1:35105, 127.0.0.1:33456]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-917657629-172.17.0.7-1606980023984:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=9:[127.0.0.1:40778, 127.0.0.1:34003, 127.0.0.1:34066, 127.0.0.1:34525, 127.0.0.1:37871, 127.0.0.1:38056, 127.0.0.1:38706, 127.0.0.1:35105, 127.0.0.1:33456] terminating
2020-12-03 07:20:31,866 [IPC Server handler 0 on default port 35507] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2948)) - DIR* completeFile: /testfile is closed by DFSClient_NONMAPREDUCE_2135733897_1
2020-12-03 07:20:31,877 [IPC Server handler 1 on default port 35507] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=append	src=/testfile	dst=null	perm=null	proto=rpc
2020-12-03 07:20:31,901 [IPC Server handler 4 on default port 35507] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(798)) - BLOCK* allocate blk_1073741826_1002, replicas=127.0.0.1:35105, 127.0.0.1:37871, 127.0.0.1:34066, 127.0.0.1:38706, 127.0.0.1:34525, 127.0.0.1:40778, 127.0.0.1:33456, 127.0.0.1:40799, 127.0.0.1:38056, 127.0.0.1:34003 for /testfile
2020-12-03 07:20:31,914 [Thread-453] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:31,920 [DataXceiver for client DFSClient_NONMAPREDUCE_2062259203_2224 at /127.0.0.1:38236 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002 src: /127.0.0.1:38236 dest: /127.0.0.1:35105
2020-12-03 07:20:31,921 [DataXceiver for client DFSClient_NONMAPREDUCE_2062259203_2224 at /127.0.0.1:38236 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:31,927 [DataXceiver for client DFSClient_NONMAPREDUCE_2062259203_2224 at /127.0.0.1:36982 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002 src: /127.0.0.1:36982 dest: /127.0.0.1:37871
2020-12-03 07:20:31,928 [DataXceiver for client DFSClient_NONMAPREDUCE_2062259203_2224 at /127.0.0.1:36982 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:31,932 [DataXceiver for client DFSClient_NONMAPREDUCE_2062259203_2224 at /127.0.0.1:37100 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002 src: /127.0.0.1:37100 dest: /127.0.0.1:34066
2020-12-03 07:20:31,938 [DataXceiver for client DFSClient_NONMAPREDUCE_2062259203_2224 at /127.0.0.1:37100 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:31,940 [DataXceiver for client DFSClient_NONMAPREDUCE_2062259203_2224 at /127.0.0.1:49884 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002 src: /127.0.0.1:49884 dest: /127.0.0.1:38706
2020-12-03 07:20:31,941 [DataXceiver for client DFSClient_NONMAPREDUCE_2062259203_2224 at /127.0.0.1:49884 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:31,950 [DataXceiver for client DFSClient_NONMAPREDUCE_2062259203_2224 at /127.0.0.1:34716 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002 src: /127.0.0.1:34716 dest: /127.0.0.1:34525
2020-12-03 07:20:31,956 [DataXceiver for client DFSClient_NONMAPREDUCE_2062259203_2224 at /127.0.0.1:34716 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:31,958 [DataXceiver for client DFSClient_NONMAPREDUCE_2062259203_2224 at /127.0.0.1:33348 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002 src: /127.0.0.1:33348 dest: /127.0.0.1:40778
2020-12-03 07:20:31,961 [DataXceiver for client DFSClient_NONMAPREDUCE_2062259203_2224 at /127.0.0.1:33348 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:31,962 [DataXceiver for client DFSClient_NONMAPREDUCE_2062259203_2224 at /127.0.0.1:46526 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002 src: /127.0.0.1:46526 dest: /127.0.0.1:33456
2020-12-03 07:20:31,966 [DataXceiver for client DFSClient_NONMAPREDUCE_2062259203_2224 at /127.0.0.1:46526 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:31,967 [DataXceiver for client DFSClient_NONMAPREDUCE_2062259203_2224 at /127.0.0.1:41710 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002 src: /127.0.0.1:41710 dest: /127.0.0.1:40799
2020-12-03 07:20:31,976 [DataXceiver for client DFSClient_NONMAPREDUCE_2062259203_2224 at /127.0.0.1:41710 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:31,979 [DataXceiver for client DFSClient_NONMAPREDUCE_2062259203_2224 at /127.0.0.1:59026 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002 src: /127.0.0.1:59026 dest: /127.0.0.1:38056
2020-12-03 07:20:31,986 [DataXceiver for client DFSClient_NONMAPREDUCE_2062259203_2224 at /127.0.0.1:59026 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002]] INFO  sasl.SaslDataTransferClient (SaslDataTransferClient.java:checkTrustAndSend(239)) - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2020-12-03 07:20:31,987 [DataXceiver for client DFSClient_NONMAPREDUCE_2062259203_2224 at /127.0.0.1:45592 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(747)) - Receiving BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002 src: /127.0.0.1:45592 dest: /127.0.0.1:34003
2020-12-03 07:20:32,706 [DataXceiver for client DFSClient_NONMAPREDUCE_2062259203_2224 at /127.0.0.1:33348 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002]] WARN  datanode.DataNode (BlockReceiver.java:flushOrSync(440)) - Slow flushOrSync took 712ms (threshold=300ms), isSync:true, flushTotalNanos=19262ns, volume=file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/, blockId=1073741826
2020-12-03 07:20:32,706 [DataXceiver for client DFSClient_NONMAPREDUCE_2062259203_2224 at /127.0.0.1:49884 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002]] WARN  datanode.DataNode (BlockReceiver.java:flushOrSync(440)) - Slow flushOrSync took 712ms (threshold=300ms), isSync:true, flushTotalNanos=18236ns, volume=file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/, blockId=1073741826
2020-12-03 07:20:32,706 [DataXceiver for client DFSClient_NONMAPREDUCE_2062259203_2224 at /127.0.0.1:34716 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002]] WARN  datanode.DataNode (BlockReceiver.java:flushOrSync(440)) - Slow flushOrSync took 712ms (threshold=300ms), isSync:true, flushTotalNanos=19572ns, volume=file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/, blockId=1073741826
2020-12-03 07:20:32,706 [DataXceiver for client DFSClient_NONMAPREDUCE_2062259203_2224 at /127.0.0.1:46526 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002]] WARN  datanode.DataNode (BlockReceiver.java:flushOrSync(440)) - Slow flushOrSync took 712ms (threshold=300ms), isSync:true, flushTotalNanos=20637ns, volume=file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/, blockId=1073741826
2020-12-03 07:20:32,706 [DataXceiver for client DFSClient_NONMAPREDUCE_2062259203_2224 at /127.0.0.1:41710 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002]] WARN  datanode.DataNode (BlockReceiver.java:flushOrSync(440)) - Slow flushOrSync took 712ms (threshold=300ms), isSync:true, flushTotalNanos=16845ns, volume=file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/, blockId=1073741826
2020-12-03 07:20:32,706 [DataXceiver for client DFSClient_NONMAPREDUCE_2062259203_2224 at /127.0.0.1:37100 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002]] WARN  datanode.DataNode (BlockReceiver.java:flushOrSync(440)) - Slow flushOrSync took 712ms (threshold=300ms), isSync:true, flushTotalNanos=18895ns, volume=file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/, blockId=1073741826
2020-12-03 07:20:32,710 [DataXceiver for client DFSClient_NONMAPREDUCE_2062259203_2224 at /127.0.0.1:45592 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002]] WARN  datanode.DataNode (BlockReceiver.java:flushOrSync(440)) - Slow flushOrSync took 711ms (threshold=300ms), isSync:true, flushTotalNanos=26345ns, volume=file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/, blockId=1073741826
2020-12-03 07:20:32,706 [DataXceiver for client DFSClient_NONMAPREDUCE_2062259203_2224 at /127.0.0.1:36982 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002]] WARN  datanode.DataNode (BlockReceiver.java:flushOrSync(440)) - Slow flushOrSync took 713ms (threshold=300ms), isSync:true, flushTotalNanos=20152ns, volume=file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20/, blockId=1073741826
2020-12-03 07:20:32,706 [DataXceiver for client DFSClient_NONMAPREDUCE_2062259203_2224 at /127.0.0.1:59026 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002]] WARN  datanode.DataNode (BlockReceiver.java:flushOrSync(440)) - Slow flushOrSync took 711ms (threshold=300ms), isSync:true, flushTotalNanos=17693ns, volume=file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/, blockId=1073741826
2020-12-03 07:20:32,706 [DataXceiver for client DFSClient_NONMAPREDUCE_2062259203_2224 at /127.0.0.1:38236 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002]] WARN  datanode.DataNode (BlockReceiver.java:flushOrSync(440)) - Slow flushOrSync took 713ms (threshold=300ms), isSync:true, flushTotalNanos=22344ns, volume=file:/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/, blockId=1073741826
2020-12-03 07:20:32,732 [IPC Server handler 6 on default port 35507] INFO  hdfs.StateChange (FSNamesystem.java:fsync(3361)) - BLOCK* fsync: /testfile for DFSClient_NONMAPREDUCE_2062259203_2224
2020-12-03 07:20:32,740 [IPC Server handler 9 on default port 35507] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8074)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/testfile	dst=null	perm=null	proto=rpc
2020-12-03 07:20:32,762 [IPC Server handler 2 on default port 35507] INFO  namenode.FSNamesystem (FSNamesystem.java:updatePipeline(5430)) - updatePipeline(blk_1073741826_1002, newGS=1003, newLength=100, newNodes=[127.0.0.1:40799, 127.0.0.1:38056], client=DFSClient_NONMAPREDUCE_2062259203_2224)
2020-12-03 07:20:32,763 [IPC Server handler 2 on default port 35507] INFO  namenode.FSNamesystem (FSNamesystem.java:updatePipeline(5448)) - updatePipeline(blk_1073741826_1002 => blk_1073741826_1003) success
2020-12-03 07:20:32,767 [Thread-476] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - java.net.UnknownHostException: Fake Exception, while invoking ClientNamenodeProtocolTranslatorPB.updatePipeline over localhost/127.0.0.1:35507. Trying to failover immediately.
2020-12-03 07:20:32,775 [Thread-476] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.StandbyException): Operation category WRITE is not supported in state standby. Visit https://s.apache.org/sbnn-error
	at org.apache.hadoop.hdfs.server.namenode.ha.StandbyState.checkOperation(StandbyState.java:98)
	at org.apache.hadoop.hdfs.server.namenode.NameNode$NameNodeHAContext.checkOperation(NameNode.java:2021)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkOperation(FSNamesystem.java:1449)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.updatePipeline(NameNodeRpcServer.java:975)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.updatePipeline(ClientNamenodeProtocolServerSideTranslatorPB.java:1124)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
, while invoking ClientNamenodeProtocolTranslatorPB.updatePipeline over localhost/127.0.0.1:40176 after 1 failover attempts. Trying to failover after sleeping for 1363ms.
2020-12-03 07:20:33,482 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid a9577885-35e8-4740-8041-adbd3b637e00) service to localhost/127.0.0.1:35507 trying to claim ACTIVE state with txid=13
2020-12-03 07:20:33,482 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid a9577885-35e8-4740-8041-adbd3b637e00) service to localhost/127.0.0.1:35507
2020-12-03 07:20:33,482 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid d536f9db-cc03-4d10-befe-81c328136fc6) service to localhost/127.0.0.1:35507 trying to claim ACTIVE state with txid=13
2020-12-03 07:20:33,483 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid d536f9db-cc03-4d10-befe-81c328136fc6) service to localhost/127.0.0.1:35507
2020-12-03 07:20:33,483 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid aac3269e-0132-46b9-826f-593ec51a470c) service to localhost/127.0.0.1:35507 trying to claim ACTIVE state with txid=13
2020-12-03 07:20:33,483 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid 250bafb2-f716-457e-8310-96d333f0e360) service to localhost/127.0.0.1:35507 trying to claim ACTIVE state with txid=13
2020-12-03 07:20:33,483 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid 250bafb2-f716-457e-8310-96d333f0e360) service to localhost/127.0.0.1:35507
2020-12-03 07:20:33,483 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid aac3269e-0132-46b9-826f-593ec51a470c) service to localhost/127.0.0.1:35507
2020-12-03 07:20:33,591 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid 4ea78e77-6418-4b63-8f69-9cb494a0609e) service to localhost/127.0.0.1:35507 trying to claim ACTIVE state with txid=13
2020-12-03 07:20:33,591 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid 4ea78e77-6418-4b63-8f69-9cb494a0609e) service to localhost/127.0.0.1:35507
2020-12-03 07:20:33,755 [Thread-429] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:20:33,756 [Thread-429] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 1, 13
2020-12-03 07:20:33,756 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@6daf2337] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:20:33,756 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@2b8d084] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:20:33,756 [Thread-429] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 14 Total time for transactions(ms): 28 Number of transactions batched in Syncs: 1 Number of syncs: 14 SyncTimes(ms): 13 4 1 
2020-12-03 07:20:33,758 [Thread-429] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/shared-edits-0-through-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/shared-edits-0-through-1/current/edits_0000000000000000001-0000000000000000014
2020-12-03 07:20:33,760 [Thread-429] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000014
2020-12-03 07:20:33,761 [Thread-429] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000014
2020-12-03 07:20:33,761 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:20:33,834 [CacheReplicationMonitor(500731340)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:20:33,838 [Thread-429] INFO  namenode.FSNamesystem (FSNamesystem.java:startStandbyServices(1391)) - Starting services required for standby state
2020-12-03 07:20:33,838 [Thread-429] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.log-roll.period(-1) assuming SECONDS
2020-12-03 07:20:33,838 [Thread-429] INFO  ha.EditLogTailer (EditLogTailer.java:<init>(208)) - Not going to trigger log rolls on active node because dfs.ha.log-roll.period is negative.
2020-12-03 07:20:33,838 [Thread-429] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.period.backoff-max(0) assuming SECONDS
2020-12-03 07:20:33,839 [Thread-429] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1395)) - No unit for dfs.ha.tail-edits.rolledits.timeout(60) assuming SECONDS
2020-12-03 07:20:33,839 [Thread-429] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:20:33,841 [Edit log tailer] WARN  ha.EditLogTailer (EditLogTailer.java:doWork(528)) - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.sleep(EditLogTailer.java:433)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:526)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:440)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:457)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:484)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:453)
2020-12-03 07:20:33,842 [Thread-429] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1222)) - Starting services required for active state
2020-12-03 07:20:33,843 [Thread-429] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/shared-edits-0-through-1/current
2020-12-03 07:20:33,843 [Thread-429] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-3/current
2020-12-03 07:20:33,843 [Thread-429] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(428)) - Recovering unfinalized segments in /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-4/current
2020-12-03 07:20:33,843 [Thread-429] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1233)) - Catching up to latest edits from old active before taking over writer role in edits logs
2020-12-03 07:20:33,851 [Thread-429] INFO  namenode.FSImage (FSImage.java:loadEdits(910)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@6cfb4a69 expecting start txid #1
2020-12-03 07:20:33,851 [Thread-429] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(178)) - Start loading edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/shared-edits-0-through-1/current/edits_0000000000000000001-0000000000000000014 maxTxnsToRead = 9223372036854775807
2020-12-03 07:20:33,852 [Thread-429] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(186)) - Fast-forwarding stream '/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/shared-edits-0-through-1/current/edits_0000000000000000001-0000000000000000014' to transaction ID 1
2020-12-03 07:20:33,902 [Thread-429] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(188)) - Loaded 1 edits file(s) (the last named /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/shared-edits-0-through-1/current/edits_0000000000000000001-0000000000000000014) of total size 785.0, total edits 14.0, total load time 21.0 ms
2020-12-03 07:20:33,903 [Thread-429] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:markAllDatanodesStale(1840)) - Marking all datanodes as stale
2020-12-03 07:20:33,916 [Thread-429] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1244)) - Reprocessing replication and invalidation queues
2020-12-03 07:20:33,917 [Thread-429] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4922)) - initializing replication queues
2020-12-03 07:20:33,917 [Thread-429] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1255)) - Will take over writing edit logs at txnid 15
2020-12-03 07:20:33,917 [Thread-429] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1365)) - Starting log segment at 15
2020-12-03 07:20:33,927 [Thread-429] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(777)) - Initializing quota with 4 thread(s)
2020-12-03 07:20:33,928 [Thread-429] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(786)) - Quota initialization completed in 1 milliseconds
name space=2
storage space=20480
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-12-03 07:20:33,930 [Thread-429] INFO  ha.TestRetryCacheWithHA (TestRetryCacheWithHA.java:testClientRetryWithFailover(1333)) - Setting block to false
2020-12-03 07:20:33,931 [CacheReplicationMonitor(1111996723)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-12-03 07:20:33,935 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3585)) - Total number of blocks            = 2
2020-12-03 07:20:33,936 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3586)) - Number of invalid blocks          = 0
2020-12-03 07:20:33,936 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3587)) - Number of under-replicated blocks = 0
2020-12-03 07:20:33,936 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3588)) - Number of  over-replicated blocks = 0
2020-12-03 07:20:33,936 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3590)) - Number of blocks being written    = 1
2020-12-03 07:20:33,936 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3593)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 18 msec
2020-12-03 07:20:33,938 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid cb57b908-c67e-442d-9c8c-363640b27bef) service to localhost/127.0.0.1:40176 trying to claim ACTIVE state with txid=15
2020-12-03 07:20:33,938 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid cb57b908-c67e-442d-9c8c-363640b27bef) service to localhost/127.0.0.1:40176
2020-12-03 07:20:34,078 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid fdeabe37-b020-4cdf-a421-01807757b061) service to localhost/127.0.0.1:40176 trying to claim ACTIVE state with txid=15
2020-12-03 07:20:34,078 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid fdeabe37-b020-4cdf-a421-01807757b061) service to localhost/127.0.0.1:40176
2020-12-03 07:20:34,099 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid cb4aef3f-7b04-4877-92e5-64465e132825) service to localhost/127.0.0.1:40176 trying to claim ACTIVE state with txid=15
2020-12-03 07:20:34,099 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid cb4aef3f-7b04-4877-92e5-64465e132825) service to localhost/127.0.0.1:40176
2020-12-03 07:20:34,141 [Thread-476] INFO  retry.RetryInvocationHandler (RetryInvocationHandler.java:log(411)) - org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.StandbyException): Operation category WRITE is not supported in state standby. Visit https://s.apache.org/sbnn-error
	at org.apache.hadoop.hdfs.server.namenode.ha.StandbyState.checkOperation(StandbyState.java:98)
	at org.apache.hadoop.hdfs.server.namenode.NameNode$NameNodeHAContext.checkOperation(NameNode.java:2021)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkOperation(FSNamesystem.java:1449)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.updatePipeline(NameNodeRpcServer.java:975)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.updatePipeline(ClientNamenodeProtocolServerSideTranslatorPB.java:1124)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)
, while invoking ClientNamenodeProtocolTranslatorPB.updatePipeline over localhost/127.0.0.1:35507 after 2 failover attempts. Trying to failover after sleeping for 2399ms.
2020-12-03 07:20:36,473 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(596)) - Namenode Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid 250bafb2-f716-457e-8310-96d333f0e360) service to localhost/127.0.0.1:35507 relinquishing ACTIVE state with txid=14
2020-12-03 07:20:36,473 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(596)) - Namenode Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid d536f9db-cc03-4d10-befe-81c328136fc6) service to localhost/127.0.0.1:35507 relinquishing ACTIVE state with txid=14
2020-12-03 07:20:36,473 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(596)) - Namenode Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid a9577885-35e8-4740-8041-adbd3b637e00) service to localhost/127.0.0.1:35507 relinquishing ACTIVE state with txid=14
2020-12-03 07:20:36,476 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(596)) - Namenode Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid aac3269e-0132-46b9-826f-593ec51a470c) service to localhost/127.0.0.1:35507 relinquishing ACTIVE state with txid=14
2020-12-03 07:20:36,476 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid a9577885-35e8-4740-8041-adbd3b637e00) service to localhost/127.0.0.1:40176 trying to claim ACTIVE state with txid=15
2020-12-03 07:20:36,476 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid a9577885-35e8-4740-8041-adbd3b637e00) service to localhost/127.0.0.1:40176
2020-12-03 07:20:36,476 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid d536f9db-cc03-4d10-befe-81c328136fc6) service to localhost/127.0.0.1:40176 trying to claim ACTIVE state with txid=15
2020-12-03 07:20:36,476 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid aac3269e-0132-46b9-826f-593ec51a470c) service to localhost/127.0.0.1:40176 trying to claim ACTIVE state with txid=15
2020-12-03 07:20:36,476 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid d536f9db-cc03-4d10-befe-81c328136fc6) service to localhost/127.0.0.1:40176
2020-12-03 07:20:36,476 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid 250bafb2-f716-457e-8310-96d333f0e360) service to localhost/127.0.0.1:40176 trying to claim ACTIVE state with txid=15
2020-12-03 07:20:36,476 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid aac3269e-0132-46b9-826f-593ec51a470c) service to localhost/127.0.0.1:40176
2020-12-03 07:20:36,477 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid 250bafb2-f716-457e-8310-96d333f0e360) service to localhost/127.0.0.1:40176
2020-12-03 07:20:36,545 [DataStreamer for file /testfile block BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002] WARN  hdfs.DataStreamer (DataStreamer.java:closeResponder(988)) - Caught exception
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1252)
	at java.lang.Thread.join(Thread.java:1326)
	at org.apache.hadoop.hdfs.DataStreamer.closeResponder(DataStreamer.java:986)
	at org.apache.hadoop.hdfs.DataStreamer.closeInternal(DataStreamer.java:847)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:843)
2020-12-03 07:20:36,548 [Thread-476] INFO  ha.TestRetryCacheWithHA (TestRetryCacheWithHA.java:run(1311)) - Operation updatePipeline finished
2020-12-03 07:20:36,548 [DataXceiver for client DFSClient_NONMAPREDUCE_2062259203_2224 at /127.0.0.1:38236 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002]] INFO  datanode.DataNode (BlockReceiver.java:receiveBlock(1010)) - Exception for BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002
java.io.IOException: Premature EOF from inputStream
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:212)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:908)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:20:36,548 [Thread-429] INFO  ha.TestRetryCacheWithHA (TestRetryCacheWithHA.java:testClientRetryWithFailover(1340)) - Got the result of updatePipeline: SUCCESS
2020-12-03 07:20:36,549 [PacketResponder: BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=9:[127.0.0.1:37871, 127.0.0.1:34066, 127.0.0.1:38706, 127.0.0.1:34525, 127.0.0.1:40778, 127.0.0.1:33456, 127.0.0.1:40799, 127.0.0.1:38056, 127.0.0.1:34003]] INFO  datanode.DataNode (BlockReceiver.java:run(1470)) - PacketResponder: BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=9:[127.0.0.1:37871, 127.0.0.1:34066, 127.0.0.1:38706, 127.0.0.1:34525, 127.0.0.1:40778, 127.0.0.1:33456, 127.0.0.1:40799, 127.0.0.1:38056, 127.0.0.1:34003]: Thread is interrupted.
2020-12-03 07:20:36,549 [PacketResponder: BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=9:[127.0.0.1:37871, 127.0.0.1:34066, 127.0.0.1:38706, 127.0.0.1:34525, 127.0.0.1:40778, 127.0.0.1:33456, 127.0.0.1:40799, 127.0.0.1:38056, 127.0.0.1:34003]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=9:[127.0.0.1:37871, 127.0.0.1:34066, 127.0.0.1:38706, 127.0.0.1:34525, 127.0.0.1:40778, 127.0.0.1:33456, 127.0.0.1:40799, 127.0.0.1:38056, 127.0.0.1:34003] terminating
2020-12-03 07:20:36,549 [DataXceiver for client DFSClient_NONMAPREDUCE_2062259203_2224 at /127.0.0.1:38236 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(939)) - opWriteBlock BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002 received exception java.io.IOException: Premature EOF from inputStream
2020-12-03 07:20:36,550 [Listener at localhost/43638] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(2049)) - Shutting down the Mini HDFS Cluster
2020-12-03 07:20:36,551 [Listener at localhost/43638] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 9
2020-12-03 07:20:36,551 [Listener at localhost/43638] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:36,552 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@23aae55] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:36,552 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19, DS-e494c4c0-84f6-42dd-92d8-d29ca6c47e4b) exiting.
2020-12-03 07:20:36,552 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20, DS-7f216f4d-5fbf-45d0-8c6a-456ab6675b7c) exiting.
2020-12-03 07:20:36,554 [DataXceiver for client DFSClient_NONMAPREDUCE_2062259203_2224 at /127.0.0.1:38236 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:35105:DataXceiver error processing WRITE_BLOCK operation  src: /127.0.0.1:38236 dst: /127.0.0.1:35105
java.io.IOException: Premature EOF from inputStream
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:212)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:908)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:20:36,582 [Listener at localhost/43638] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@36c54a56{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:36,583 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid 4ea78e77-6418-4b63-8f69-9cb494a0609e) service to localhost/127.0.0.1:40176 trying to claim ACTIVE state with txid=15
2020-12-03 07:20:36,584 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(590)) - Namenode Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid 4ea78e77-6418-4b63-8f69-9cb494a0609e) service to localhost/127.0.0.1:40176 taking over ACTIVE state from Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid 4ea78e77-6418-4b63-8f69-9cb494a0609e) service to localhost/127.0.0.1:35507 at higher txid=15
2020-12-03 07:20:36,587 [Listener at localhost/43638] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@3359c978{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:36,587 [Listener at localhost/43638] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@26f1249d{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:36,588 [Listener at localhost/43638] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@60222fd8{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:36,591 [Listener at localhost/43638] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 43638
2020-12-03 07:20:36,591 [PacketResponder: BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=8:[127.0.0.1:34066, 127.0.0.1:38706, 127.0.0.1:34525, 127.0.0.1:40778, 127.0.0.1:33456, 127.0.0.1:40799, 127.0.0.1:38056, 127.0.0.1:34003]] INFO  datanode.DataNode (BlockReceiver.java:run(1470)) - PacketResponder: BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=8:[127.0.0.1:34066, 127.0.0.1:38706, 127.0.0.1:34525, 127.0.0.1:40778, 127.0.0.1:33456, 127.0.0.1:40799, 127.0.0.1:38056, 127.0.0.1:34003]: Thread is interrupted.
2020-12-03 07:20:36,593 [PacketResponder: BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=8:[127.0.0.1:34066, 127.0.0.1:38706, 127.0.0.1:34525, 127.0.0.1:40778, 127.0.0.1:33456, 127.0.0.1:40799, 127.0.0.1:38056, 127.0.0.1:34003]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=8:[127.0.0.1:34066, 127.0.0.1:38706, 127.0.0.1:34525, 127.0.0.1:40778, 127.0.0.1:33456, 127.0.0.1:40799, 127.0.0.1:38056, 127.0.0.1:34003] terminating
2020-12-03 07:20:36,591 [DataXceiver for client DFSClient_NONMAPREDUCE_2062259203_2224 at /127.0.0.1:36982 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002]] INFO  datanode.DataNode (BlockReceiver.java:receiveBlock(1010)) - Exception for BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 60000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:157)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:345)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:210)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:908)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:20:36,597 [DataXceiver for client DFSClient_NONMAPREDUCE_2062259203_2224 at /127.0.0.1:36982 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(939)) - opWriteBlock BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002 received exception java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 60000 millis timeout left.
2020-12-03 07:20:36,597 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:36,597 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:36,599 [DataXceiver for client DFSClient_NONMAPREDUCE_2062259203_2224 at /127.0.0.1:36982 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:37871:DataXceiver error processing WRITE_BLOCK operation  src: /127.0.0.1:36982 dst: /127.0.0.1:37871
java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[closed]. 60000 millis timeout left.
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:342)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:157)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:345)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:210)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:908)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:20:36,600 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:36,600 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:36,600 [DataXceiver for client DFSClient_NONMAPREDUCE_2062259203_2224 at /127.0.0.1:37100 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002]] INFO  datanode.DataNode (BlockReceiver.java:receiveBlock(1010)) - Exception for BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002
java.io.IOException: Premature EOF from inputStream
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:212)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:908)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:20:36,602 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid fdeabe37-b020-4cdf-a421-01807757b061) service to localhost/127.0.0.1:35507
2020-12-03 07:20:36,602 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid fdeabe37-b020-4cdf-a421-01807757b061) service to localhost/127.0.0.1:40176
2020-12-03 07:20:36,602 [PacketResponder: BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=7:[127.0.0.1:38706, 127.0.0.1:34525, 127.0.0.1:40778, 127.0.0.1:33456, 127.0.0.1:40799, 127.0.0.1:38056, 127.0.0.1:34003]] INFO  datanode.DataNode (BlockReceiver.java:run(1470)) - PacketResponder: BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=7:[127.0.0.1:38706, 127.0.0.1:34525, 127.0.0.1:40778, 127.0.0.1:33456, 127.0.0.1:40799, 127.0.0.1:38056, 127.0.0.1:34003]: Thread is interrupted.
2020-12-03 07:20:36,602 [PacketResponder: BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=7:[127.0.0.1:38706, 127.0.0.1:34525, 127.0.0.1:40778, 127.0.0.1:33456, 127.0.0.1:40799, 127.0.0.1:38056, 127.0.0.1:34003]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=7:[127.0.0.1:38706, 127.0.0.1:34525, 127.0.0.1:40778, 127.0.0.1:33456, 127.0.0.1:40799, 127.0.0.1:38056, 127.0.0.1:34003] terminating
2020-12-03 07:20:36,603 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid fdeabe37-b020-4cdf-a421-01807757b061)
2020-12-03 07:20:36,604 [DataXceiver for client DFSClient_NONMAPREDUCE_2062259203_2224 at /127.0.0.1:37100 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(939)) - opWriteBlock BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002 received exception java.io.IOException: Premature EOF from inputStream
2020-12-03 07:20:36,604 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:36,605 [DataXceiver for client DFSClient_NONMAPREDUCE_2062259203_2224 at /127.0.0.1:37100 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:34066:DataXceiver error processing WRITE_BLOCK operation  src: /127.0.0.1:37100 dst: /127.0.0.1:34066
java.io.IOException: Premature EOF from inputStream
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:212)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:908)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:20:36,605 [DataXceiver for client DFSClient_NONMAPREDUCE_2062259203_2224 at /127.0.0.1:49884 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002]] INFO  datanode.DataNode (BlockReceiver.java:receiveBlock(1010)) - Exception for BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002
java.io.IOException: Premature EOF from inputStream
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:212)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:908)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:20:36,606 [PacketResponder: BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=6:[127.0.0.1:34525, 127.0.0.1:40778, 127.0.0.1:33456, 127.0.0.1:40799, 127.0.0.1:38056, 127.0.0.1:34003]] INFO  datanode.DataNode (BlockReceiver.java:run(1470)) - PacketResponder: BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=6:[127.0.0.1:34525, 127.0.0.1:40778, 127.0.0.1:33456, 127.0.0.1:40799, 127.0.0.1:38056, 127.0.0.1:34003]: Thread is interrupted.
2020-12-03 07:20:36,606 [PacketResponder: BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=6:[127.0.0.1:34525, 127.0.0.1:40778, 127.0.0.1:33456, 127.0.0.1:40799, 127.0.0.1:38056, 127.0.0.1:34003]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=6:[127.0.0.1:34525, 127.0.0.1:40778, 127.0.0.1:33456, 127.0.0.1:40799, 127.0.0.1:38056, 127.0.0.1:34003] terminating
2020-12-03 07:20:36,606 [DataXceiver for client DFSClient_NONMAPREDUCE_2062259203_2224 at /127.0.0.1:49884 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(939)) - opWriteBlock BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002 received exception java.io.IOException: Premature EOF from inputStream
2020-12-03 07:20:36,607 [DataXceiver for client DFSClient_NONMAPREDUCE_2062259203_2224 at /127.0.0.1:49884 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:38706:DataXceiver error processing WRITE_BLOCK operation  src: /127.0.0.1:49884 dst: /127.0.0.1:38706
java.io.IOException: Premature EOF from inputStream
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:212)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:908)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:20:36,607 [DataXceiver for client DFSClient_NONMAPREDUCE_2062259203_2224 at /127.0.0.1:34716 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002]] INFO  datanode.DataNode (BlockReceiver.java:receiveBlock(1010)) - Exception for BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002
java.io.IOException: Premature EOF from inputStream
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:212)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:908)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:20:36,613 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19/current/BP-917657629-172.17.0.7-1606980023984] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:36,614 [PacketResponder: BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=5:[127.0.0.1:40778, 127.0.0.1:33456, 127.0.0.1:40799, 127.0.0.1:38056, 127.0.0.1:34003]] INFO  datanode.DataNode (BlockReceiver.java:run(1470)) - PacketResponder: BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=5:[127.0.0.1:40778, 127.0.0.1:33456, 127.0.0.1:40799, 127.0.0.1:38056, 127.0.0.1:34003]: Thread is interrupted.
2020-12-03 07:20:36,614 [PacketResponder: BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=5:[127.0.0.1:40778, 127.0.0.1:33456, 127.0.0.1:40799, 127.0.0.1:38056, 127.0.0.1:34003]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=5:[127.0.0.1:40778, 127.0.0.1:33456, 127.0.0.1:40799, 127.0.0.1:38056, 127.0.0.1:34003] terminating
2020-12-03 07:20:36,614 [DataXceiver for client DFSClient_NONMAPREDUCE_2062259203_2224 at /127.0.0.1:34716 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(939)) - opWriteBlock BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002 received exception java.io.IOException: Premature EOF from inputStream
2020-12-03 07:20:36,615 [DataXceiver for client DFSClient_NONMAPREDUCE_2062259203_2224 at /127.0.0.1:34716 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:34525:DataXceiver error processing WRITE_BLOCK operation  src: /127.0.0.1:34716 dst: /127.0.0.1:34525
java.io.IOException: Premature EOF from inputStream
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:212)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:908)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:20:36,615 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20/current/BP-917657629-172.17.0.7-1606980023984] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:36,615 [DataXceiver for client DFSClient_NONMAPREDUCE_2062259203_2224 at /127.0.0.1:33348 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002]] INFO  datanode.DataNode (BlockReceiver.java:receiveBlock(1010)) - Exception for BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002
java.io.IOException: Premature EOF from inputStream
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:212)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:908)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:20:36,624 [Listener at localhost/43638] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:36,624 [PacketResponder: BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=4:[127.0.0.1:33456, 127.0.0.1:40799, 127.0.0.1:38056, 127.0.0.1:34003]] INFO  datanode.DataNode (BlockReceiver.java:run(1470)) - PacketResponder: BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=4:[127.0.0.1:33456, 127.0.0.1:40799, 127.0.0.1:38056, 127.0.0.1:34003]: Thread is interrupted.
2020-12-03 07:20:36,624 [PacketResponder: BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=4:[127.0.0.1:33456, 127.0.0.1:40799, 127.0.0.1:38056, 127.0.0.1:34003]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=4:[127.0.0.1:33456, 127.0.0.1:40799, 127.0.0.1:38056, 127.0.0.1:34003] terminating
2020-12-03 07:20:36,624 [Listener at localhost/43638] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:36,624 [DataXceiver for client DFSClient_NONMAPREDUCE_2062259203_2224 at /127.0.0.1:33348 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(939)) - opWriteBlock BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002 received exception java.io.IOException: Premature EOF from inputStream
2020-12-03 07:20:36,625 [Listener at localhost/43638] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:36,625 [Listener at localhost/43638] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:36,625 [DataXceiver for client DFSClient_NONMAPREDUCE_2062259203_2224 at /127.0.0.1:33348 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:40778:DataXceiver error processing WRITE_BLOCK operation  src: /127.0.0.1:33348 dst: /127.0.0.1:40778
java.io.IOException: Premature EOF from inputStream
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:212)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:908)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:20:36,626 [DataXceiver for client DFSClient_NONMAPREDUCE_2062259203_2224 at /127.0.0.1:46526 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002]] INFO  datanode.DataNode (BlockReceiver.java:receiveBlock(1010)) - Exception for BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002
java.io.IOException: Premature EOF from inputStream
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:212)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:908)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:20:36,627 [PacketResponder: BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=3:[127.0.0.1:40799, 127.0.0.1:38056, 127.0.0.1:34003]] INFO  datanode.DataNode (BlockReceiver.java:run(1470)) - PacketResponder: BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=3:[127.0.0.1:40799, 127.0.0.1:38056, 127.0.0.1:34003]: Thread is interrupted.
2020-12-03 07:20:36,628 [PacketResponder: BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=3:[127.0.0.1:40799, 127.0.0.1:38056, 127.0.0.1:34003]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=3:[127.0.0.1:40799, 127.0.0.1:38056, 127.0.0.1:34003] terminating
2020-12-03 07:20:36,628 [DataXceiver for client DFSClient_NONMAPREDUCE_2062259203_2224 at /127.0.0.1:46526 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(939)) - opWriteBlock BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002 received exception java.io.IOException: Premature EOF from inputStream
2020-12-03 07:20:36,628 [DataXceiver for client DFSClient_NONMAPREDUCE_2062259203_2224 at /127.0.0.1:41710 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002]] INFO  datanode.DataNode (BlockReceiver.java:receiveBlock(1010)) - Exception for BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002
java.io.IOException: Premature EOF from inputStream
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:212)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:908)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:20:36,628 [DataXceiver for client DFSClient_NONMAPREDUCE_2062259203_2224 at /127.0.0.1:46526 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:33456:DataXceiver error processing WRITE_BLOCK operation  src: /127.0.0.1:46526 dst: /127.0.0.1:33456
java.io.IOException: Premature EOF from inputStream
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:212)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:908)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:20:36,632 [PacketResponder: BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:38056, 127.0.0.1:34003]] INFO  datanode.DataNode (BlockReceiver.java:run(1470)) - PacketResponder: BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:38056, 127.0.0.1:34003]: Thread is interrupted.
2020-12-03 07:20:36,632 [PacketResponder: BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:38056, 127.0.0.1:34003]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:38056, 127.0.0.1:34003] terminating
2020-12-03 07:20:36,632 [Listener at localhost/43638] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:36,633 [DataXceiver for client DFSClient_NONMAPREDUCE_2062259203_2224 at /127.0.0.1:41710 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(939)) - opWriteBlock BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002 received exception java.io.IOException: Premature EOF from inputStream
2020-12-03 07:20:36,633 [Listener at localhost/43638] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 8
2020-12-03 07:20:36,633 [DataXceiver for client DFSClient_NONMAPREDUCE_2062259203_2224 at /127.0.0.1:59026 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002]] INFO  datanode.DataNode (BlockReceiver.java:receiveBlock(1010)) - Exception for BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002
java.io.IOException: Premature EOF from inputStream
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:212)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:908)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:20:36,633 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@3b0f7d9d] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:36,633 [Listener at localhost/43638] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:36,633 [DataXceiver for client DFSClient_NONMAPREDUCE_2062259203_2224 at /127.0.0.1:41710 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:40799:DataXceiver error processing WRITE_BLOCK operation  src: /127.0.0.1:41710 dst: /127.0.0.1:40799
java.io.IOException: Premature EOF from inputStream
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:212)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:908)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:20:36,635 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-ceb133f8-e092-4bb0-bdaf-62de04a9fde9) exiting.
2020-12-03 07:20:36,635 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-36362941-3af0-4d97-975d-6c63a7fd314f) exiting.
2020-12-03 07:20:36,634 [PacketResponder: BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34003]] INFO  datanode.DataNode (BlockReceiver.java:run(1470)) - PacketResponder: BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34003]: Thread is interrupted.
2020-12-03 07:20:36,636 [PacketResponder: BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34003]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34003] terminating
2020-12-03 07:20:36,636 [DataXceiver for client DFSClient_NONMAPREDUCE_2062259203_2224 at /127.0.0.1:59026 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(939)) - opWriteBlock BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002 received exception java.io.IOException: Premature EOF from inputStream
2020-12-03 07:20:36,637 [DataXceiver for client DFSClient_NONMAPREDUCE_2062259203_2224 at /127.0.0.1:59026 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:38056:DataXceiver error processing WRITE_BLOCK operation  src: /127.0.0.1:59026 dst: /127.0.0.1:38056
java.io.IOException: Premature EOF from inputStream
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:212)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:908)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:20:36,637 [DataXceiver for client DFSClient_NONMAPREDUCE_2062259203_2224 at /127.0.0.1:45592 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002]] INFO  datanode.DataNode (BlockReceiver.java:receiveBlock(1010)) - Exception for BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002
java.io.IOException: Premature EOF from inputStream
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:212)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:908)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:20:36,638 [PacketResponder: BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1470)) - PacketResponder: BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002, type=LAST_IN_PIPELINE: Thread is interrupted.
2020-12-03 07:20:36,638 [PacketResponder: BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2020-12-03 07:20:36,638 [DataXceiver for client DFSClient_NONMAPREDUCE_2062259203_2224 at /127.0.0.1:45592 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(939)) - opWriteBlock BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002 received exception java.io.IOException: Premature EOF from inputStream
2020-12-03 07:20:36,639 [DataXceiver for client DFSClient_NONMAPREDUCE_2062259203_2224 at /127.0.0.1:45592 [Receiving block BP-917657629-172.17.0.7-1606980023984:blk_1073741826_1002]] ERROR datanode.DataNode (DataXceiver.java:run(324)) - 127.0.0.1:34003:DataXceiver error processing WRITE_BLOCK operation  src: /127.0.0.1:45592 dst: /127.0.0.1:34003
java.io.IOException: Premature EOF from inputStream
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:212)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:211)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:528)
	at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:971)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:908)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:173)
	at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:107)
	at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:292)
	at java.lang.Thread.run(Thread.java:748)
2020-12-03 07:20:36,659 [Listener at localhost/43638] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5298dead{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:36,661 [Listener at localhost/43638] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@553f3b6e{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:36,661 [Listener at localhost/43638] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@62b3df3a{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:36,662 [Listener at localhost/43638] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@53cdecf6{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:36,663 [Listener at localhost/43638] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 45886
2020-12-03 07:20:36,673 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:36,674 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:36,689 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:36,689 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid cb4aef3f-7b04-4877-92e5-64465e132825) service to localhost/127.0.0.1:35507
2020-12-03 07:20:36,689 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:36,689 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid cb4aef3f-7b04-4877-92e5-64465e132825) service to localhost/127.0.0.1:40176
2020-12-03 07:20:36,689 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid cb4aef3f-7b04-4877-92e5-64465e132825)
2020-12-03 07:20:36,689 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:36,690 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-917657629-172.17.0.7-1606980023984] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:36,692 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-917657629-172.17.0.7-1606980023984] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:36,699 [Listener at localhost/43638] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:36,699 [Listener at localhost/43638] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:36,700 [Listener at localhost/43638] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:36,700 [Listener at localhost/43638] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:36,702 [Listener at localhost/43638] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:36,703 [Listener at localhost/43638] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 7
2020-12-03 07:20:36,704 [Listener at localhost/43638] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:36,704 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@54e81b21] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:36,705 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-7b973780-45b9-48aa-b1ae-2b36eece14ee) exiting.
2020-12-03 07:20:36,705 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-8870a112-92dc-4859-a282-7b7b8fc69dbd) exiting.
2020-12-03 07:20:36,736 [Listener at localhost/43638] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@251ebf23{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:36,737 [Listener at localhost/43638] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@29b732a2{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:36,737 [Listener at localhost/43638] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@632aa1a3{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:36,737 [Listener at localhost/43638] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@30457e14{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:36,738 [Listener at localhost/43638] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 34061
2020-12-03 07:20:36,741 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:36,742 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:36,742 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:36,742 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid cb57b908-c67e-442d-9c8c-363640b27bef) service to localhost/127.0.0.1:40176
2020-12-03 07:20:36,742 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:36,742 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid cb57b908-c67e-442d-9c8c-363640b27bef) service to localhost/127.0.0.1:35507
2020-12-03 07:20:36,744 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid cb57b908-c67e-442d-9c8c-363640b27bef)
2020-12-03 07:20:36,745 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:36,745 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-917657629-172.17.0.7-1606980023984] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:36,746 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-917657629-172.17.0.7-1606980023984] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:36,753 [Listener at localhost/43638] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:36,754 [Listener at localhost/43638] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:36,756 [Listener at localhost/43638] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:36,756 [Listener at localhost/43638] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:36,759 [Listener at localhost/43638] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:36,760 [Listener at localhost/43638] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 6
2020-12-03 07:20:36,760 [Listener at localhost/43638] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:36,760 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@d71adc2] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:36,760 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid a5cf5fbb-7d73-4dc3-b054-00e46e141155) service to localhost/127.0.0.1:40176 trying to claim ACTIVE state with txid=15
2020-12-03 07:20:36,762 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid a5cf5fbb-7d73-4dc3-b054-00e46e141155) service to localhost/127.0.0.1:40176
2020-12-03 07:20:36,762 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-9024d8af-e369-46b9-b368-4cf2f932788f) exiting.
2020-12-03 07:20:36,762 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-f4bfacf8-7145-4886-a5f1-fd5fa3f79dee) exiting.
2020-12-03 07:20:36,791 [Listener at localhost/43638] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1e34c607{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:36,792 [Listener at localhost/43638] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@5215cd9a{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:36,792 [Listener at localhost/43638] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6ac4944a{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:36,792 [Listener at localhost/43638] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@17ae98d7{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:36,794 [Listener at localhost/43638] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 35791
2020-12-03 07:20:36,798 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:36,798 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:36,798 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:36,798 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:36,798 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid 89347142-edad-4d29-b15f-e4c40718e489) service to localhost/127.0.0.1:40176
2020-12-03 07:20:36,801 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid 89347142-edad-4d29-b15f-e4c40718e489) service to localhost/127.0.0.1:35507
2020-12-03 07:20:36,801 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid 89347142-edad-4d29-b15f-e4c40718e489)
2020-12-03 07:20:36,802 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:36,803 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-917657629-172.17.0.7-1606980023984] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:36,805 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-917657629-172.17.0.7-1606980023984] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:36,812 [Listener at localhost/43638] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:36,812 [Listener at localhost/43638] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:36,813 [Listener at localhost/43638] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:36,813 [Listener at localhost/43638] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:36,817 [Listener at localhost/43638] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:36,818 [Listener at localhost/43638] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 5
2020-12-03 07:20:36,818 [Listener at localhost/43638] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:36,818 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@f325091] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:36,821 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-3df7a241-42d4-46b6-9ce4-8b28b0d79357) exiting.
2020-12-03 07:20:36,821 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-6ed681d4-7b32-434e-9b37-4319562525f7) exiting.
2020-12-03 07:20:36,844 [Listener at localhost/43638] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@85ec632{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:36,845 [Listener at localhost/43638] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@1c05a54d{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:36,846 [Listener at localhost/43638] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@51abf713{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:36,847 [Listener at localhost/43638] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6bd51ed8{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:36,848 [Listener at localhost/43638] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 35318
2020-12-03 07:20:36,852 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:36,852 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:36,855 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:36,856 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid a5cf5fbb-7d73-4dc3-b054-00e46e141155) service to localhost/127.0.0.1:35507
2020-12-03 07:20:36,856 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:36,856 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid a5cf5fbb-7d73-4dc3-b054-00e46e141155) service to localhost/127.0.0.1:40176
2020-12-03 07:20:36,856 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid a5cf5fbb-7d73-4dc3-b054-00e46e141155)
2020-12-03 07:20:36,856 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:36,857 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-917657629-172.17.0.7-1606980023984] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:36,861 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-917657629-172.17.0.7-1606980023984] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:36,872 [Listener at localhost/43638] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:36,872 [Listener at localhost/43638] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:36,874 [Listener at localhost/43638] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:36,874 [Listener at localhost/43638] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:36,879 [Listener at localhost/43638] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:36,879 [Listener at localhost/43638] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 4
2020-12-03 07:20:36,879 [Listener at localhost/43638] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:36,879 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@6ca320ab] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:36,882 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-c7bc2dbc-457f-4ca9-86cc-267ab86263f8) exiting.
2020-12-03 07:20:36,882 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-5ccec8a5-859f-4fa7-857a-b7c956cf3535) exiting.
2020-12-03 07:20:36,911 [Listener at localhost/43638] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@7bfc3126{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:36,912 [Listener at localhost/43638] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@3e792ce3{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:36,913 [Listener at localhost/43638] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4acf72b6{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:36,913 [Listener at localhost/43638] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@323e8306{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:36,914 [Listener at localhost/43638] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 38901
2020-12-03 07:20:36,918 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:36,921 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:36,922 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:36,922 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:36,922 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid 4ea78e77-6418-4b63-8f69-9cb494a0609e) service to localhost/127.0.0.1:40176
2020-12-03 07:20:36,922 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid 4ea78e77-6418-4b63-8f69-9cb494a0609e) service to localhost/127.0.0.1:35507
2020-12-03 07:20:36,922 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid 4ea78e77-6418-4b63-8f69-9cb494a0609e)
2020-12-03 07:20:36,923 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:36,924 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-917657629-172.17.0.7-1606980023984] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:36,924 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-917657629-172.17.0.7-1606980023984] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:36,936 [Listener at localhost/43638] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:36,937 [Listener at localhost/43638] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:36,939 [Listener at localhost/43638] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:36,940 [Listener at localhost/43638] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:36,945 [Listener at localhost/43638] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:36,945 [Listener at localhost/43638] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 3
2020-12-03 07:20:36,946 [Listener at localhost/43638] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:36,946 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@54e7391d] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:36,949 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-f47ecebd-23fc-4bb6-9f5f-7463b5001b37) exiting.
2020-12-03 07:20:36,949 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-9f1b799a-562e-4944-90f0-914891761857) exiting.
2020-12-03 07:20:36,973 [Listener at localhost/43638] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1dfd5f51{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:36,973 [Listener at localhost/43638] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@3c321bdb{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:36,974 [Listener at localhost/43638] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@512d92b{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:36,974 [Listener at localhost/43638] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@58783f6c{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:36,976 [Listener at localhost/43638] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 45065
2020-12-03 07:20:36,981 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:36,981 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:36,981 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:36,984 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:36,984 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid 250bafb2-f716-457e-8310-96d333f0e360) service to localhost/127.0.0.1:40176
2020-12-03 07:20:36,984 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid 250bafb2-f716-457e-8310-96d333f0e360) service to localhost/127.0.0.1:35507
2020-12-03 07:20:36,984 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid 250bafb2-f716-457e-8310-96d333f0e360)
2020-12-03 07:20:36,984 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:36,985 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-917657629-172.17.0.7-1606980023984] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:36,986 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-917657629-172.17.0.7-1606980023984] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:37,024 [Listener at localhost/43638] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:37,028 [Listener at localhost/43638] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:37,035 [Listener at localhost/43638] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:37,035 [Listener at localhost/43638] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:37,042 [Listener at localhost/43638] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:37,042 [Listener at localhost/43638] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 2
2020-12-03 07:20:37,043 [Listener at localhost/43638] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:37,043 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@781e7326] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:37,047 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-2eb61706-9d88-4c82-b7f4-94ef4c91ca90) exiting.
2020-12-03 07:20:37,047 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-a225e481-cea1-416c-80ae-569f36dd3f21) exiting.
2020-12-03 07:20:37,070 [Listener at localhost/43638] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1b39fd82{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:37,072 [Listener at localhost/43638] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@3e2fc448{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:37,072 [Listener at localhost/43638] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2575f671{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:37,073 [Listener at localhost/43638] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@433ffad1{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:37,075 [Listener at localhost/43638] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 35855
2020-12-03 07:20:37,080 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:37,085 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:37,085 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:37,085 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:37,085 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid d536f9db-cc03-4d10-befe-81c328136fc6) service to localhost/127.0.0.1:35507
2020-12-03 07:20:37,085 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid d536f9db-cc03-4d10-befe-81c328136fc6) service to localhost/127.0.0.1:40176
2020-12-03 07:20:37,086 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid d536f9db-cc03-4d10-befe-81c328136fc6)
2020-12-03 07:20:37,086 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:37,086 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-917657629-172.17.0.7-1606980023984] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:37,087 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-917657629-172.17.0.7-1606980023984] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:37,094 [Listener at localhost/43638] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:37,094 [Listener at localhost/43638] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:37,097 [Listener at localhost/43638] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:37,097 [Listener at localhost/43638] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:37,103 [Listener at localhost/43638] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:37,104 [Listener at localhost/43638] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 1
2020-12-03 07:20:37,104 [Listener at localhost/43638] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:37,104 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@345e5a17] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:37,108 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-3af5a235-4bf3-49e0-9488-a4f87533e8a2) exiting.
2020-12-03 07:20:37,108 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-e34a2eee-43a4-47ce-b10e-ce5fedc28869) exiting.
2020-12-03 07:20:37,127 [Listener at localhost/43638] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@c41709a{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:37,128 [Listener at localhost/43638] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7db0565c{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:37,128 [Listener at localhost/43638] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@41382722{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:37,129 [Listener at localhost/43638] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5bbc9f97{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:37,130 [Listener at localhost/43638] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 41061
2020-12-03 07:20:37,138 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:37,138 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:37,138 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:37,138 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:37,138 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid aac3269e-0132-46b9-826f-593ec51a470c) service to localhost/127.0.0.1:40176
2020-12-03 07:20:37,138 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid aac3269e-0132-46b9-826f-593ec51a470c) service to localhost/127.0.0.1:35507
2020-12-03 07:20:37,146 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid aac3269e-0132-46b9-826f-593ec51a470c)
2020-12-03 07:20:37,146 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:37,147 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-917657629-172.17.0.7-1606980023984] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:37,158 [Listener at localhost/43638] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:37,158 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-917657629-172.17.0.7-1606980023984] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:37,159 [Listener at localhost/43638] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:37,169 [Listener at localhost/43638] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:37,169 [Listener at localhost/43638] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:37,181 [Listener at localhost/43638] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:37,182 [Listener at localhost/43638] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2097)) - Shutting down DataNode 0
2020-12-03 07:20:37,182 [Listener at localhost/43638] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(343)) - DirectoryScanner: shutdown has been called
2020-12-03 07:20:37,182 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@7e242b4d] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-12-03 07:20:37,188 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-efa2376a-10cf-46b0-adee-6d1ceaed342c) exiting.
2020-12-03 07:20:37,188 [VolumeScannerThread(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(637)) - VolumeScanner(/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-1cb0cc9b-9989-4e43-b52d-6995994c4fc1) exiting.
2020-12-03 07:20:37,212 [Listener at localhost/43638] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@452ba1db{/,null,UNAVAILABLE}{/datanode}
2020-12-03 07:20:37,213 [Listener at localhost/43638] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2289aca5{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:37,214 [Listener at localhost/43638] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2f058b8a{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:37,214 [Listener at localhost/43638] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@165b8a71{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:37,215 [Listener at localhost/43638] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 43592
2020-12-03 07:20:37,223 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:37,223 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:37,233 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:37,233 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-12-03 07:20:37,233 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:35507] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid a9577885-35e8-4740-8041-adbd3b637e00) service to localhost/127.0.0.1:35507
2020-12-03 07:20:37,233 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] WARN  datanode.DataNode (BPServiceActor.java:run(860)) - Ending block pool service for: Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid a9577885-35e8-4740-8041-adbd3b637e00) service to localhost/127.0.0.1:40176
2020-12-03 07:20:37,233 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-917657629-172.17.0.7-1606980023984 (Datanode Uuid a9577885-35e8-4740-8041-adbd3b637e00)
2020-12-03 07:20:37,234 [BP-917657629-172.17.0.7-1606980023984 heartbeating to localhost/127.0.0.1:40176] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2814)) - Removing block pool BP-917657629-172.17.0.7-1606980023984
2020-12-03 07:20:37,235 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-917657629-172.17.0.7-1606980023984] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:37,235 [refreshUsed-/root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-917657629-172.17.0.7-1606980023984] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-12-03 07:20:37,250 [Listener at localhost/43638] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(193)) - Shutting down all async disk service threads
2020-12-03 07:20:37,251 [Listener at localhost/43638] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(201)) - All async disk service threads have been shut down
2020-12-03 07:20:37,258 [Listener at localhost/43638] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(177)) - Shutting down all async lazy persist service threads
2020-12-03 07:20:37,258 [Listener at localhost/43638] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(184)) - All async lazy persist service threads have been shut down
2020-12-03 07:20:37,319 [Listener at localhost/43638] INFO  datanode.DataNode (DataNode.java:shutdown(2164)) - Shutdown complete.
2020-12-03 07:20:37,319 [Listener at localhost/43638] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:20:37,320 [Listener at localhost/43638] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:20:37,328 [Edit log tailer] WARN  ha.EditLogTailer (EditLogTailer.java:doWork(528)) - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.sleep(EditLogTailer.java:433)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:526)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:440)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:457)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:484)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:453)
2020-12-03 07:20:37,329 [Listener at localhost/43638] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 35507
2020-12-03 07:20:37,331 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:37,331 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:20:37,331 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:20:37,342 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:37,417 [Listener at localhost/43638] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:20:37,418 [Listener at localhost/43638] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:20:37,419 [Listener at localhost/43638] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6337c201{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:20:37,421 [Listener at localhost/43638] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2b175c00{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:37,421 [Listener at localhost/43638] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@54e041a4{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:37,421 [Listener at localhost/43638] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@78fa769e{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:37,445 [Listener at localhost/43638] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2130)) - Shutting down the namenode
2020-12-03 07:20:37,445 [Listener at localhost/43638] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:20:37,445 [Listener at localhost/43638] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1410)) - Ending log segment 15, 15
2020-12-03 07:20:37,445 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@7b7bb48b] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4198)) - LazyPersistFileScrubber was interrupted, exiting
2020-12-03 07:20:37,445 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@620c7383] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4107)) - NameNodeEditLogRoller was interrupted, exiting
2020-12-03 07:20:37,466 [Listener at localhost/43638] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(778)) - Number of transactions: 2 Total time for transactions(ms): 23 Number of transactions batched in Syncs: 14 Number of syncs: 3 SyncTimes(ms): 1 2 2 
2020-12-03 07:20:37,474 [Listener at localhost/43638] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/shared-edits-0-through-1/current/edits_inprogress_0000000000000000015 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/shared-edits-0-through-1/current/edits_0000000000000000015-0000000000000000016
2020-12-03 07:20:37,479 [Listener at localhost/43638] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-3/current/edits_inprogress_0000000000000000015 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-3/current/edits_0000000000000000015-0000000000000000016
2020-12-03 07:20:37,487 [Listener at localhost/43638] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(145)) - Finalizing edits file /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-4/current/edits_inprogress_0000000000000000015 -> /root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-4/current/edits_0000000000000000015-0000000000000000016
2020-12-03 07:20:37,488 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-12-03 07:20:37,488 [CacheReplicationMonitor(1111996723)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-12-03 07:20:37,488 [Listener at localhost/43638] INFO  ipc.Server (Server.java:stop(3359)) - Stopping server on 40176
2020-12-03 07:20:37,498 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1330)) - Stopping IPC Server listener on 0
2020-12-03 07:20:37,498 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1465)) - Stopping IPC Server Responder
2020-12-03 07:20:37,498 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4687)) - Stopping RedundancyMonitor.
2020-12-03 07:20:37,498 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4722)) - Stopping thread.
2020-12-03 07:20:37,549 [Listener at localhost/43638] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1334)) - Stopping services started for active state
2020-12-03 07:20:37,550 [Listener at localhost/43638] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1434)) - Stopping services started for standby state
2020-12-03 07:20:37,552 [Listener at localhost/43638] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@e260766{/,null,UNAVAILABLE}{/hdfs}
2020-12-03 07:20:37,554 [Listener at localhost/43638] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2c3dec30{HTTP/1.1,[http/1.1]}{localhost:0}
2020-12-03 07:20:37,555 [Listener at localhost/43638] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7d3430a7{/static,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-12-03 07:20:37,555 [Listener at localhost/43638] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6b54655f{/logs,file:///root/hadoop-3.2.1-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-12-03 07:20:37,557 [Listener at localhost/43638] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-12-03 07:20:37,558 [Listener at localhost/43638] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-12-03 07:20:37,559 [Listener at localhost/43638] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
msx-rc 0
